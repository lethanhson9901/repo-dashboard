{
  "metadata": {
    "last_updated": "2026-02-11 03:29:59",
    "time_filter": "week",
    "subreddit": "netsec",
    "total_items": 20,
    "total_comments": 77,
    "file_size_bytes": 115331
  },
  "items": [
    {
      "id": "1qw4sfa",
      "title": "Recreating uncensored Epstein PDFs from raw encoded attachments... or trying to, anyway",
      "subreddit": "netsec",
      "url": "https://neosmart.net/blog/recreating-epstein-pdfs-from-raw-encoded-attachments/",
      "author": "mqudsi",
      "created_utc": "2026-02-04 23:32:30",
      "score": 760,
      "num_comments": 78,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qw4sfa/recreating_uncensored_epstein_pdfs_from_raw/",
      "domain": "neosmart.net",
      "is_self": false,
      "comments": [
        {
          "id": "o3molh5",
          "author": "a_random_superhero",
          "text": "I think the way to do it is to make a classifier. \n\nSince you know the compression and font used, you can build sets of characters with varying levels of compression. Then grab some characters from the document and compare against the compressed corpus. That should get you in the ballpark for identification. After that, it‚Äôs a pixel comparison contest where each potential character is compared against the ballpark set. If something is too close to call or doesn‚Äôt match at all, then flag for manual review.",
          "score": 125,
          "created_utc": "2026-02-05 00:20:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mrkgi",
              "author": "mqudsi",
              "text": "That‚Äôs pretty much where I ended up, too. I had just spent too much time on this at a busy moment in my life and couldn‚Äôt afford to sink the dev time into this. Although writing it up probably took as long as that would have taken, lol.\n\nUPDATE:\n\nI ended up solving it [by training a CNN](https://neosmart.net/blog/efta00400459-has-been-cracked-dbc12-pdf-liberated/) as a classifier.",
              "score": 66,
              "created_utc": "2026-02-05 00:36:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3rubso",
                  "author": "cccanterbury",
                  "text": "I am fully convinced you hacked this all the way and then posted this so you wouldn't get in trouble.",
                  "score": 11,
                  "created_utc": "2026-02-05 19:43:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qtj31",
                  "author": "LoveCyberSecs",
                  "text": "Ain't nothin wrong with measuring twice before cutting.",
                  "score": 6,
                  "created_utc": "2026-02-05 16:53:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3vdpl8",
                  "author": "Games_sans_frontiers",
                  "text": "Thank you for writing it up though. It was really interesting being stepped through the thought process.",
                  "score": 2,
                  "created_utc": "2026-02-06 08:53:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4kgxt7",
                  "author": "josephjosephson",
                  "text": "Bless you; hope others can continue what you‚Äôve done with  all the files. Not sure how you can properly handle worth-while redactions of actual victims though. Tawfeeq.",
                  "score": 1,
                  "created_utc": "2026-02-10 05:40:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3pmnam",
              "author": "wigglyworm91",
              "text": "I was able to get pretty decent-ish results with https://github.com/wigglyworm91/courier-new-ocr without even pregenerating compressed data (like 95% accuracy and no confidently incorrect guesses), but I don't think that's good enough to handle the compressed data sections.",
              "score": 18,
              "created_utc": "2026-02-05 13:17:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3t5vim",
                  "author": "hyperblaster",
                  "text": "Nice work there! Using KMeans clustering to restrict the classifier to the 64 chars in base64 is smart. \n\nYou're reading in the individual glyphs into cv2 as grayscale. DCT artifacts and color fringing might be critical here, so maybe retain full color?",
                  "score": 4,
                  "created_utc": "2026-02-05 23:39:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3sfyaw",
                  "author": "eth0izzle",
                  "text": "Can you share the labels ",
                  "score": 2,
                  "created_utc": "2026-02-05 21:26:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ah4ka",
              "author": "PM-ME-UR-DARKNESS",
              "text": "Holy fuckin shit y'all gonna be using AI to unredact the Epstein files lmao",
              "score": 1,
              "created_utc": "2026-02-08 18:10:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4kigzz",
                  "author": "Real_Perspective_384",
                  "text": "crazy times!",
                  "score": 1,
                  "created_utc": "2026-02-10 05:52:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3o9p0c",
          "author": "thenickdude",
          "text": "If you can manage to get your PDF decoder into the loop, it seems like a backtracking search would solve this one. i.e turn every confusable character into a branch point, and when you hit a PDF decode error, backtrack to the previous branch to try the next alternative.",
          "score": 27,
          "created_utc": "2026-02-05 06:18:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qj5e7",
              "author": "mqudsi",
              "text": "Someone suggested a harness with AFL (the fuzzer) hooking into poppler or any other PDF library. Clever, but also kind of the inverse of the usual fuzzer goal. It might be hard to constrain it to only make changes that converge to success rather than diverge to different failure modes.",
              "score": 9,
              "created_utc": "2026-02-05 16:05:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qu0cf",
          "author": "voronaam",
          "text": "FYI, I also went this route and decided that rather than OCR'ing the PDF, I'll just go and fix all the OCR mistakes by hand.\n\nI wrote a little utility to make it easier.\n\nHere is a screenshot: https://imgur.com/screenshot-gTnNrkW\n\nHere is the code: https://github.com/voronaam/pdfbase64tofile\n\nIt is kind of working. I have EXIF fully repaired for EFTA01012650.pdf file I was working on and the first scanline is showing up (with some extra JPEG artifacts though).\n\nIt takes me about an hour per page to fix it. I am currently on page 8 of that file. It is 456 pages of base64 for two photos. At this rate (I can do this for a couple of hours a day here and there) it will take me about a year to fix the files.\n\nWhat I need, if anybody is willing to help, is a library to work with corrupted JPEG. I need it to report the problems with the decoded JPEG and their offsets. The latter part is crucial. Knowing where the data is corrupted I can find it in the PDF file and fix the OCR mistakes. Currently I see all the libraries report errors like `Error in decoding MCU. Reason Marker UNKNOWN(67) found in bitstream, possibly corrupt jpeg`. I mean, cool, the byte 67 is wrong. I can fix it. Can you tell me which one? And is it even a 0x67 or not?\n\nAlso, if anyone wants to train a classifier model for better OCR, you'd need those cleaned up files for training. I have pushed the ones I have so far to the repo.",
          "score": 22,
          "created_utc": "2026-02-05 16:55:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r2fpx",
              "author": "voronaam",
              "text": "I guess I'll elaborate on what's going on with the screenshot in case someone wants to write a full featured utility or a website and crowdsource this.\n\n1. Top section is the PDF rendered. It has a thick green cursor under the current character - matching the position of the character in the editable text below automatically.\n2. Below that is the OCR'd text from the PDF. Markers to the left of each line indicate if the line looks \"clean\" or not. It is green when the line is exactly 76 characters of base64. It is orange if there are any \"weird\" characters present and just grey if just the length is wrong.\n\nThe fields are specifically limited in height to just a couple of lines each - to help keep focus on just a few lines.\n\nSave button on top allow for saving the OCR'd text (just in `page008.txt` in the current folder). There is also a \"Display\" button that runs a script that converts those files into a JPEG with whatever pipeline you had in mind.\n\nI also added a button to jump to the next character in the `I/l/1` set - the most commonly mixed up by the OCR. So it allows for quick jumps to the most likely errored out letters.",
              "score": 8,
              "created_utc": "2026-02-05 17:35:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3umr0e",
              "author": "survivalist_guy",
              "text": "In rust too, no less. Nice work. Thanks for the contribution, I'm working on a few paths for the OCR so I'll take a look.",
              "score": 4,
              "created_utc": "2026-02-06 05:02:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3updux",
                  "author": "voronaam",
                  "text": "Well, I knew that I'll be loading corrupted JPEG into memory - with pretty much guaranteed buffer under- and overruns. That is pretty much a textbook case for a memory-safe language.\n\nFirst time doing any GUI in Rust though. It is ugly :)\n\nAlso, sharing it just in case: https://albmac.github.io/JPEGVisualRepairTool/ I am not the author, but this tool is the best I found so far to examine the corrupted JPEG files. It highlights troubles MCUs and shows they binary offsets in the JPEG file. I added a \"Jump to Hex\" button to my app - doing some basic math to convert that offset into base64 text position.",
                  "score": 3,
                  "created_utc": "2026-02-06 05:21:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o41yl4l",
              "author": "Kokuten",
              "text": "Ahh I see you are still at it. Great work!",
              "score": 2,
              "created_utc": "2026-02-07 09:19:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o420sn5",
                  "author": "voronaam",
                  "text": "Thank you. The key was finding this tool: https://albmac.github.io/JPEGVisualRepairTool/JPEGVisualRepairTool.html\n\nIt highlights troubled areas in a JPEG file and even gives me the byte offset of their location in file. With just some basic math I am able to jump to that spot in the base64 file and look for OCR errors.\n\nIt goes much faster when I know which areas look good enough already and which ones still need a bit of attention",
                  "score": 1,
                  "created_utc": "2026-02-07 09:41:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3n8u50",
          "author": "MartinVanBallin",
          "text": "Nice write up! I was actually trying this last night with some encoded jpegs in the emails. I agree the OCR is really poorly done by the DOJ!",
          "score": 17,
          "created_utc": "2026-02-05 02:15:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3s2ins",
              "author": "originaltexter",
              "text": "Same. Those files named \"unnamed\" with no file extension have a lot in them. I recovered two images from one of them just now. couple more last night of some police cars staking out one of his properties and a photo of an alleged private investigator who JE's PI photographed for him.",
              "score": 7,
              "created_utc": "2026-02-05 20:22:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40zusg",
                  "author": "No_Judge_4307",
                  "text": "Where did you find the files marked as \"unnamed\"?",
                  "score": 1,
                  "created_utc": "2026-02-07 04:18:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41c70m",
                  "author": "Lower-Collection-828",
                  "text": "can you share them?",
                  "score": 1,
                  "created_utc": "2026-02-07 05:51:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rmxa6",
          "author": "BCMM",
          "text": ">¬†No problem, I‚Äôll just use imagemagick/ghostscript¬†to convert the PDF into individual PNG images (to avoid further generational loss)\n\n\nBut this isn't lossless! The PDF will be rasterised at a resolution which is unlikely to match the resolution of the embedded images.\n\n\nIt's good that you're encoding the result to a lossless format, but it's the result of resizing a raster image.\n\n\nInstead, use `pdfimages`, from poppler-utils, to extract the images directly from the PDF.",
          "score": 15,
          "created_utc": "2026-02-05 19:08:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rpofa",
              "author": "mqudsi",
              "text": "Ahhh! Great catch!",
              "score": 13,
              "created_utc": "2026-02-05 19:21:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3y564b",
                  "author": "BCMM",
                  "text": "> But in the Epstein PDFs released by the DoJ, we only have low-quality JPEG scans at a fairly small point size.\n\nFurthermore, I don't think these are scans. I think they're digital all the way, equivalent to screenshots of rendered text. (My guess would be that they used the Print to PDF feature in whatever email software they are using, applied redactions to the output, and then rasterised the result because they don't know how else to stop fucking up the redaction process.)\n\n**I believe this opens up new possibilities for accurate OCR.**\n\nI say they're not scans because:\n\n1. I couldn't find any dust (e.g. random grey pixels between lines of text)\n2. Lines of text are perfectly horizontal\n3. If you zoom in, the antialiasing looks like it's in its original condition\n\nHaving extracted the images, without compression or resizing artefacts, I observe the following:\n\nUnfortunately, it is *not* the case that the same character always renders to the exact same pixels. This is because a single column of monospaced characters has a non-integer width (it's about 7.8px).\n\nHowever, rows appear to have a height of *exactly* 15px. If we're lucky, this means that, when the same character occurs *in the same column*, it reliably produces the same pixels.\n\nNow, I admit that I've only tested with a very small number of examples, manually, using the colour picker in GIMP. But the above does appear to be true! Hopefully, this means that we're working with a finite number of pixmap representations of each character.\n\nIn fact, I think the width is *exactly* 7.8px, giving us only five possible variants of each character. This is subject to the same caveat about very light testing, but for example, the first and last characters in `there if it` are rendered totally identically. The same holds true for the 2^nd and 16^th `I`s in that long run of `ICAg` at the end.\n\nSo, I believe it is possible to do a sort of dumb \"OCR\" on this by splitting it up in to regular (well, predictably irregular) tiles, and checking a library of reference tiles for an exact match for each tile. We would only need 64√ó5=320 reference tiles. It seems relatively likely that there's existing software that takes this approach, but I haven't looked for it yet.",
                  "score": 10,
                  "created_utc": "2026-02-06 18:45:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xm0zd",
                  "author": "BCMM",
                  "text": "Now that I've actually looked at the PDF, I have another couple of quibbles about the images:\n\n> But in the Epstein PDFs released by the DoJ, we only have low-quality JPEG scans at a fairly small point size.\n\nThe images in EFTA00400459.pdf are losslessly encoded, in a way that's equivalent to PNG (but not identical - the rest of this comment will be excessive technical detail on that).\n\nIn PDF, images are not represented by directly embedding image files in familiar formats (unlike e.g. images in OOXML). Instead, an image is a *stream object*, i.e. a sequence of binary bytes, which must be interpreted according to the dimensions and pixel format specified in a *dictionary* which occurs just before the stream. For compression, the dictionary may also specify *filters*, which are applied before said interpretation.\n\nPDF supports a filter called DCTDecode, which is very similar to JPEG, but it isn't used in EFTA00400459.pdf.\n\nAll image streams in EFTA00400459.pdf have a dictionary a bit like this:\n\n    <</Type /XObject /Subtype /Image /Name /Im0 /Filter [/FlateDecode ] /Width 816 /Height 1056 /ColorSpace 10 0 R /BitsPerComponent 8 /Length 9 0 R >> \n\n\n`/Filter [/FlateDecode ]` means the stream should be decompressed using the DEFLATE algorithm. While the compression technology is identical to PNG, it's not actually a PNG because there no PNG header, no \"chunks\", etc.",
                  "score": 5,
                  "created_utc": "2026-02-06 17:14:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ula48",
              "author": "survivalist_guy",
              "text": "Thank you! I've been using PyMuPDF. Also been trying Azure Document Intelligence a try, we'll see how that goes.",
              "score": 1,
              "created_utc": "2026-02-06 04:51:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3vf4as",
          "author": "dinopio",
          "text": "Decoded files [https://limewire.com/d/a7olB#WnVBT78Q9v](https://limewire.com/d/a7olB#WnVBT78Q9v) ",
          "score": 16,
          "created_utc": "2026-02-06 09:07:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3vf9v2",
              "author": "dinopio",
              "text": "code from [https://github.com/KoKuToru/extract\\_attachment\\_EFTA00400459](https://github.com/KoKuToru/extract_attachment_EFTA00400459) ",
              "score": 9,
              "created_utc": "2026-02-06 09:08:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o42ok2b",
              "author": "_ManWithNoMemories_",
              "text": "The link does not work",
              "score": 0,
              "created_utc": "2026-02-07 13:09:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ro30m",
          "author": "eth0izzle",
          "text": "The Content ID of the email attachment is ends with cpusers.carillon.local, which suggests it originated from a local AD + Exchange environment. Could Carillion be the British multinational that went bust in 2018? [https://en.wikipedia.org/wiki/Carillion](https://en.wikipedia.org/wiki/Carillion)",
          "score": 5,
          "created_utc": "2026-02-05 19:14:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mwnpa",
          "author": "badteeth3000",
          "text": "naive idea : would photorec be of use vs qpdf? lol, it helped me when I had a cd with sun damage full of jpg files and it definitely works on pdfs..",
          "score": 10,
          "created_utc": "2026-02-05 01:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vwel4",
          "author": "Dracozirion",
          "text": "[https://github.com/KoKuToru/extract\\_attachment\\_EFTA00400459](https://github.com/KoKuToru/extract_attachment_EFTA00400459)",
          "score": 5,
          "created_utc": "2026-02-06 11:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3odjxi",
          "author": "Headz0r",
          "text": "The first question should be: What are we decoding?\nIf its a PDF with text this will mostly be Postscript commands.\n\nMost information would be between parenthesis: https://www.researchgate.net/publication/2416848/figure/fig1/AS:669440576348168@1536618479267/Conversion-from-PostScript-a-PostScript-file-the-text-extracted-from-it-and-a.png\n\nThis also gives you some hints of what are possible valid commands outside of parenthesis.",
          "score": 4,
          "created_utc": "2026-02-05 06:52:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qikg5",
              "author": "mqudsi",
              "text": "It is a PDF (that much is for sure). But, as with most PDF files, the actual PostScript is flate-compressed so the \"apparent\" contents of the PDF are binary, not text (except for some headers and stuff, such as the XML in the screenshot towards the end of the article).",
              "score": 6,
              "created_utc": "2026-02-05 16:02:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3osnti",
          "author": "perplexes_",
          "text": "If it‚Äôs just 1 vs l, you could brute force - try all possible combinations and see which ones come out as good PDFs",
          "score": 4,
          "created_utc": "2026-02-05 09:13:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40jiy2",
              "author": "Ok-Present1566",
              "text": "2^x grows very fast.  That is almost certainly totally practically infeasible if x is 24 or higher",
              "score": 2,
              "created_utc": "2026-02-07 02:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uwa93",
          "author": "euclidity",
          "text": "Was able to get very similar looking lossy character strings by:\n\n- Generating a known base64 dataset\n- Pasting it into a document with 0.5 margins, 0.5 line spacing, courier new in size 10, and printing it to pdf\n- pdftoppm test.pdf output -jpeg -jpegopt quality=100 -r 80\n- print to pdf again on the images\n- compare the final pdf to the reference epstein pdf\n- repeat with different jpeg options on pdftoppm until the glyphs look as close to the epstein reference as possible\n\nCould be used to train a custom OCR/tesseract on equivalent looking data but with known matching real text.",
          "score": 3,
          "created_utc": "2026-02-06 06:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3nbsfx",
          "author": "walkention",
          "text": "If you have a fairly decent GPU at home or feel like paying for cloud resources, what about an LLM OCR like this?\n https://huggingface.co/deepseek-ai/DeepSeek-OCR-2\n\nI was going to try and load this into my homelab LLM and see how it does.\n\nAlso, there are several companies doing AI OCR that could potentially https://www.docupipe.ai/ seems promising.",
          "score": 10,
          "created_utc": "2026-02-05 02:32:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nh1b1",
              "author": "duckne55",
              "text": "paddleOCR is also ML based and very easy to use as theres a python package [https://github.com/PaddlePaddle/PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)  \nBut the same issues with distinguishing lowercase \\`L\\` and \\`1\\` applies I think",
              "score": 6,
              "created_utc": "2026-02-05 03:01:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ns592",
                  "author": "walkention",
                  "text": "I saw PaddleOCR as well and will likely give it a try. I quickly tried running the image OP has at the top of the article (which is pretty low quality to be honest) through deepseek-ocr-2. It did pretty well, but I did notice it added unnecessary spaces and randomly changed character case in places, had some trouble with zero and capital O, and definitely can't handle lowercase L and 1 at that resolution. I'll have to try on the pages extracted from the original PDF.",
                  "score": 5,
                  "created_utc": "2026-02-05 04:10:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o413v0z",
          "author": "buttfuckingchrist",
          "text": "Not sure if it saw these or not but could be useful for understanding how the docs were instructed to be redacted using adobe: https://www.bloomberg.com/news/newsletters/2026-02-06/epstein-files-review-was-chaotic",
          "score": 2,
          "created_utc": "2026-02-07 04:47:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41xwvh",
          "author": "Kokuten",
          "text": "There are even more similar files. There are base64 encoded iphone pictures from 2018. Look at this thread: [https://www.reddit.com/r/Epstein/comments/1qu9az2/theres\\_unredacted\\_attachments\\_as\\_base64\\_in\\_some/](https://www.reddit.com/r/Epstein/comments/1qu9az2/theres_unredacted_attachments_as_base64_in_some/)  \nAre you able to decode them aswell? ",
          "score": 2,
          "created_utc": "2026-02-07 09:12:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49lgm8",
              "author": "mqudsi",
              "text": "That's an audio recording. *Theoretically* decodable, but MP4 containers are *incredibly* brittle (they're very shitty for long-term storage guarantees and resilience). You'd have to get all the bytes right.\n\nUnfortunately, this document is using a proportional (non-monospaced or \"regular\") font, which makes extraction harder. But it's still technically doable!",
              "score": 2,
              "created_utc": "2026-02-08 15:36:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o479mor",
          "author": "Less_Grapefruit_302",
          "text": "I created a custom OCR model specifically trained on the epstein files and was able to successfully decode EFTA00400459. Know of any more base64 blobs in the epstein files?\n\n[https://github.com/vExcess/epstein-ocr](https://github.com/vExcess/epstein-ocr)",
          "score": 2,
          "created_utc": "2026-02-08 04:37:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49l656",
              "author": "mqudsi",
              "text": "Nice work, I did the same with a CNN: https://github.com/mqudsi/monospace-ocr\n\nUnfortunately the training doesn't carry over to other base64 documents perfectly, even those using the same font family and size, in the same layout. Some of the other documents have \"smearing\" around the 1 vs l that makes it even harder üò≠",
              "score": 1,
              "created_utc": "2026-02-08 15:35:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4dqq9e",
                  "author": "Routine_Drummer1543",
                  "text": "Nice work, to both of you. This & the blog post throughly nerd-snipped me. Heh.\n\nI had made some headway cropping the images to only contain the b64 chars, then using tesseract and Apple's \"live text\", then comparing the two. I also cropped the b64 to single lines at a time, and used tesseract with `--psm 13, which did slightly better. I was then diffing the 3 outputs & selecting chars they disagreed on to manually correct. Unsurprisingly, it was a lot.\n\nI had also thought to train tesseract directly on Courier New, but hadn't gotten that far yet. Another thought was to train something like eigenfaces (eigenvalue decomposition) on the first couple of pages, cropped per character. I'm almost surprised tesseract doesn't have a way to specify both the allowed character set and a specific pattern of just those characters.",
                  "score": 1,
                  "created_utc": "2026-02-09 04:38:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o49lmtp",
              "author": "munogabba",
              "text": "look how causual this post is \n\namazing work",
              "score": 1,
              "created_utc": "2026-02-08 15:37:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o497gfi",
          "author": "tilrman",
          "text": "It's like Bletchley Park all over again.¬†",
          "score": 2,
          "created_utc": "2026-02-08 14:20:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wprwr",
          "author": "Yamisheiki",
          "text": "Does knowing Trump is the most hidden word help ? ",
          "score": 2,
          "created_utc": "2026-02-06 14:39:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qd0nj",
          "author": "pinxi",
          "text": "Here is a different way. Think of these like images going into a machine learning algorithm. So like matching different kinds of dogs, specific eye color, etc, the model treats the text like a image. Models are very good at this and continually get better with more data to train on. \n\nWe did this with regalory checks on legacy transactions that were basically massive strings with no headers or meta data.  It works very well.",
          "score": 1,
          "created_utc": "2026-02-05 15:37:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qhfr5",
              "author": "pinxi",
              "text": "Something like:\n\n1.\tImages ‚Üí Object store ‚Äì Raw images + unique ID  \n  ‚Ä¢\tMetadata ‚Üí Graph ‚Äì Image details.  \n  ‚Ä¢\tImages ‚Üí Patterns ‚Äì Image patterns.  \n2.\tPatterns ‚Üí Matches ‚Äì Similar images.  \n  ‚Ä¢\tDetails ‚Üí Documents ‚Äì Reference and analysis.  \n3.\tLinks ‚Üí Graph ‚Äì Context and relationships.  \n  ‚Ä¢\tHuman check ‚Äì Verify matches, reduce errors.  \n4.\tGraph ‚Üí LLM ‚Äì Uncover the bastards!",
              "score": 3,
              "created_utc": "2026-02-05 15:57:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qie5d",
                  "author": "pinxi",
                  "text": "With a graph db you could also add things like tweets and other feeds to provide more context of who is who and how they relate. Check out arangodb (doc, vector, and graph) or some of the cloud services.",
                  "score": 2,
                  "created_utc": "2026-02-05 16:01:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qo5a0",
                  "author": "zoopysreign",
                  "text": "I need you to teach me your ways please",
                  "score": 1,
                  "created_utc": "2026-02-05 16:28:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3vtb6e",
          "author": "ArgonWilde",
          "text": "I wonder if ell is a generally darker character than one? If you were to box in each character and average out the darkness of that box... Which is darker?\n\nOr, if you average the darkness of each row of pixels, ell would have more darkness at the top vs one which would be more consistent along the height of the serif.\n\nSo, we need a solution that exports out each character, in serial, as an X, Y box, which then averages out the darkness of the box, either in total, or graphed out along the Y axis, then classify which is which into a dataset, and then use that dataset for the remaining files. ü§î",
          "score": 1,
          "created_utc": "2026-02-06 11:17:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4336ov",
          "author": "Low_Lifeguard_7110",
          "text": "Can someone please make a archieve of the pics and share the link please or can u send any that u have done",
          "score": 1,
          "created_utc": "2026-02-07 14:36:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ogibe",
          "author": "404llm",
          "text": "You use a OCR api to process all files [https://jigsawstack.com/vocr](https://jigsawstack.com/vocr)",
          "score": 0,
          "created_utc": "2026-02-05 07:18:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qiqgo",
              "author": "mqudsi",
              "text": "As mentioned in the article, I used multiple OCR solutions, including open source OCR software, commercial OCR applications, and the hosted Amazon Textract OCR API. None did a good enough job.",
              "score": 5,
              "created_utc": "2026-02-05 16:03:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3un35k",
                  "author": "survivalist_guy",
                  "text": "Would OCR by committee be feasible? Most votes wins or something like that?  \nI'm giving Azure Document Intelligence a shot right now, but I don't have the highest hopes.",
                  "score": 1,
                  "created_utc": "2026-02-06 05:04:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxp66x",
      "title": "AI Agents‚Äô Most Downloaded Skill Is Discovered to Be an Infostealer",
      "subreddit": "netsec",
      "url": "https://www.infostealers.com/article/ai-agents-most-downloaded-skill-is-discovered-to-be-an-infostealer/",
      "author": "Malwarebeasts",
      "created_utc": "2026-02-06 18:10:48",
      "score": 107,
      "num_comments": 12,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxp66x/ai_agents_most_downloaded_skill_is_discovered_to/",
      "domain": "infostealers.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3ye81a",
          "author": "ruibranco",
          "text": "This is basically npm supply chain attacks all over again but worse because AI agents often run with elevated permissions and access to credentials by design. At least with npm packages there's some expectation that you audit what you install. These \"skill\" marketplaces are actively encouraging people to plug in third party code that gets executed with whatever access the agent has. We learned nothing from the dependency confusion era apparently.",
          "score": 53,
          "created_utc": "2026-02-06 19:29:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yvg89",
              "author": "whomthefuckisthat",
              "text": "That‚Äôs it. Back to downloading executable mp4s from limewire.",
              "score": 20,
              "created_utc": "2026-02-06 20:55:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4094x9",
                  "author": "TheG0AT0fAllTime",
                  "text": "Better days :(",
                  "score": 5,
                  "created_utc": "2026-02-07 01:26:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3z443k",
              "author": "RockinOneThreeTwo",
              "text": "> We learned nothing from the dependency confusion era apparently.¬†\n\n\nI imagine because the people who are doing this \"Agentic AI skills\" shit voluntarily and the people who were part of that era -- and understood what the problem was back then -- can be represented on a Venn diagram as two completely separate circles.",
              "score": 15,
              "created_utc": "2026-02-06 21:38:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3zy5bq",
              "author": "1esproc",
              "text": "> At least with npm packages there's some expectation that you audit what you install\n\nHahaha....ah. Good one.",
              "score": 7,
              "created_utc": "2026-02-07 00:21:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3zf66f",
              "author": "roastbits",
              "text": "Npm supply chain attacks still going strong",
              "score": 2,
              "created_utc": "2026-02-06 22:34:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xzr5e",
          "author": "Marshall_Lawson",
          "text": "site is not loading for me but archive loaded it\n\n\nhttps://archive.ph/Sa4bJ",
          "score": 5,
          "created_utc": "2026-02-06 18:20:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3z2zmo",
              "author": "thenickdude",
              "text": "It's just blogspam anyway, this is the original research:\n\nhttps://1password.com/blog/from-magic-to-malware-how-openclaws-agent-skills-become-an-attack-surface",
              "score": 30,
              "created_utc": "2026-02-06 21:32:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3z39qa",
                  "author": "Marshall_Lawson",
                  "text": "thanks",
                  "score": 5,
                  "created_utc": "2026-02-06 21:34:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o413uz8",
          "author": "AiChatPrime",
          "text": "Not surprising! \n\nAs soon as agents can browse, download, and execute tools, they become just another malware delivery layer.\n\nThe risk isn't \"AI going rogue\", it is automation making old attack faster and harder to attribute.",
          "score": 2,
          "created_utc": "2026-02-07 04:47:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40qtf7",
          "author": "tombob51",
          "text": "What an atrociously bad article. I really do not care about any completely unrelated attacks from years ago. This entire article is literally scarebait to sell that company's \"protection\" services.\n\nWhich is so stupid because this IS an actually interesting piece of news, and there are other sites covering it with 1000x better writing skills.",
          "score": 5,
          "created_utc": "2026-02-07 03:17:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxdzcu",
      "title": "The RCE that AMD won't fix!",
      "subreddit": "netsec",
      "url": "https://mrbruh.com/amd/",
      "author": "moviuro",
      "created_utc": "2026-02-06 10:22:22",
      "score": 99,
      "num_comments": 38,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxdzcu/the_rce_that_amd_wont_fix/",
      "domain": "mrbruh.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3vvm9n",
          "author": "NamedBird",
          "text": "Nothing wrong with HTTP downloads of large files, *as long as you check the hash afterwards!!!*\n\nThat this didn't happen is just plain negligence, if exploited, they'd be liable in my eyes.",
          "score": 36,
          "created_utc": "2026-02-06 11:36:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x0jyl",
              "author": "ApertureNext",
              "text": "Not true and it's been proven by the apt package manager. They also believed HTTP was fine until they got a MITM redirect vulnerability against their connections. \n\nThere's no reason not to use HTTPS by default. I have nothing against HTTP as a fallback that can be enabled manually, but it should not be default.",
              "score": 9,
              "created_utc": "2026-02-06 15:33:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x2zqr",
                  "author": "NMCMXIII",
                  "text": "http is fine if you do everything right.¬†\n\n\nthe advantage of https is two fold:\n1 - most people dont mess with its defaults or implementation, so they dont f' it up too often, and the folks working on the servers/clients are scared of f' up because its a bit of their \"you have one job'\n\n\n2 - you still add signatures, etc in addition, so now you've two layers of verification instead of one",
                  "score": 7,
                  "created_utc": "2026-02-06 15:45:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3x26gy",
                  "author": "NamedBird",
                  "text": "Can i have a source for that?\n\nYou want to cache large files, especially in big computer fleets. And HTTP makes this easy.  \n(Of course, you *do* need to use a secure channel for version checking and metadata retrieval.)",
                  "score": 4,
                  "created_utc": "2026-02-06 15:41:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3waha2",
              "author": "FlamboyantKoala",
              "text": "If you mitm the download could you not also mitm the hash? ¬†I assume valid file hashes have to be stored somewhere",
              "score": 19,
              "created_utc": "2026-02-06 13:17:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3woqw9",
                  "author": "kopkaas2000",
                  "text": "In this specific case the metadata for the update was served over https, so a checksum could have worked.",
                  "score": 23,
                  "created_utc": "2026-02-06 14:34:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3wbpha",
                  "author": "Haniasita",
                  "text": "you're right, and the true solution is to implement TLS + certificates",
                  "score": 6,
                  "created_utc": "2026-02-06 13:24:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3winku",
              "author": "Jeoh",
              "text": "There's zero reason whatsoever to use HTTP. ",
              "score": -1,
              "created_utc": "2026-02-06 14:02:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ws1fp",
                  "author": "3MU6quo0pC7du5YPBGBI",
                  "text": "> There's zero reason whatsoever to use HTTP.\n\nIt allows transparent caching for large file distribution (e.g. see LANCache for Steam and other games). For something like AMD drivers that probably isn't a very big benefit though, and doing that without validating the downloaded binary is stupid.",
                  "score": 15,
                  "created_utc": "2026-02-06 14:51:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3vntnp",
          "author": "Jeoh",
          "text": "tl;dr AMD uses HTTP to download updates, doesn't perform any kind of validation they're downloading what they hope they're downloading. Why is it an issue? See [Notepad++ MitM attack](https://notepad-plus-plus.org/news/hijacked-incident-info-update/).",
          "score": 67,
          "created_utc": "2026-02-06 10:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wiruk",
              "author": "Arszilla",
              "text": "Notepad++‚Äôs is not ‚Äúas MitM‚Äù as AMD‚Äôs. In case of Notepad++:\n1. The connection is HTTPS\n2. The Chinese TA has compromised the server the downloads were available on\n3. The Chinese TA selectively redirected connections to the malicious version\n\nIt‚Äôs not a fair comparison.",
              "score": 40,
              "created_utc": "2026-02-06 14:03:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3w3ihd",
              "author": "JAD2017",
              "text": "I was going to say that I thankfully never update anything using the programs, but I do. Antivirus, for instance, firmware update for SSD. I just realised we put a lot of trust in our daily use programs because they are from reputable companies. This is just so messed up lol",
              "score": 5,
              "created_utc": "2026-02-06 12:34:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3w8n95",
          "author": "woolharbor",
          "text": "This after the Notepad++ attack, ugh.\n\nI'm so mad at updaters not checking signatures.\n\nAll software downloads should have signatures, even manual ones.",
          "score": 8,
          "created_utc": "2026-02-06 13:06:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vpr0u",
          "author": "ruibranco",
          "text": "Using plain HTTP for software updates in 2026 is genuinely indefensible, especially for a driver updater that runs with elevated privileges. The attack surface here is massive since anyone on the same network can MitM the update check and serve a malicious payload. This is the exact same class of vulnerability that hit Notepad++ and eScan antivirus before, and the fix is always the same: TLS plus code signing verification. The fact that AMD apparently considers this not worth fixing is wild given that their updater runs as SYSTEM on Windows. Any corporate network with ARP spoofing capability or a compromised gateway becomes an instant RCE vector against every machine running AMD's software.",
          "score": 36,
          "created_utc": "2026-02-06 10:47:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3w0eox",
              "author": "angellus",
              "text": "Many Linux distros still use http for downloads. It is literally what package signing is used for. Packages are signed with a key that the package manger knows about and it verifies ever package to make sure it is not tampered with.",
              "score": 19,
              "created_utc": "2026-02-06 12:12:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3w89eb",
                  "author": "JAD2017",
                  "text": "The issue here is that AMD isn't using any kind of verification mechanism, not the protocol itself.\n\nThen again, why use unencripted protocols when you can be safe instead? I don't get it.",
                  "score": 11,
                  "created_utc": "2026-02-06 13:04:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3x2am0",
                  "author": "ApertureNext",
                  "text": "I don't see how that's excusable? So you're exposing what packages you're installing to your ISP. \n\nAlso apt has had an MITM vulnerability which wouldn't have happened if they just used HTTPS back then.",
                  "score": 3,
                  "created_utc": "2026-02-06 15:42:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vqogs",
              "author": "moviuro",
              "text": "Windows' (and macOS for that matter too) lack of decent package management is a blight on modern infrastructure.\n\nAnd if/when they ever deliver anything remotely decent, app providers will need to deliver, which is another insurmontable hurdle.\n\nNothing to do, except block HTTP at the networking level?..",
              "score": 2,
              "created_utc": "2026-02-06 10:55:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wk7nl",
          "author": "dookie1481",
          "text": "This is why bug bounty scopes should not be unnecessarily restrictive. This is a legitimate problem closed by a triager who is just going off of a checklist. Hopefully someone in AMD security will reassess when they see this.",
          "score": 7,
          "created_utc": "2026-02-06 14:10:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yrm2j",
              "author": "AxonsAndDendrites",
              "text": "It's unfortunate that some companies consider \"not worth paying a bounty for\" equivalent to \"not worth fixing\".",
              "score": 1,
              "created_utc": "2026-02-06 20:35:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3z77jh",
                  "author": "bobalob_wtf",
                  "text": "Closed out of scope does not necessarily mean \"won't fix\"",
                  "score": 2,
                  "created_utc": "2026-02-06 21:53:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3w4klr",
          "author": "ukindom",
          "text": "I don't like how graphic drivers (both NVidia and AMD) handle updates themselves, so I get a notification, download full package and install offline.\n\nIn the light of this article, I see how my method is more secure, but it's more tedious",
          "score": 3,
          "created_utc": "2026-02-06 12:41:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3w8ug7",
              "author": "JAD2017",
              "text": "I've always updated GPU drivers manually, never from the program. Same goes for chipset updates or bios updates. But there are things in our computers that we actually trust the programs, such as the antivirus, games, professional suites for content creation or other kind of corporate programs.\n\nWe put a lot of faith in companies just because they are reputable, only to find out they don't really care about our security like AMD just did with this.",
              "score": 1,
              "created_utc": "2026-02-06 13:08:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xf1or",
          "author": "BurnoutEyes",
          "text": "And there's already a semi-ancient framework to exploit this style of bugs, [ISR EvilGrade](https://github.com/infobyte/evilgrade)",
          "score": 1,
          "created_utc": "2026-02-06 16:41:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d54el",
          "author": "enceladus7",
          "text": "Disclosure got some traction? Post now says:\n\n> Temporarily taken down due to a request, will be back at a later date :)",
          "score": 1,
          "created_utc": "2026-02-09 02:31:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzzxv2",
      "title": "Open Security Architecture - 15 new security patterns with NIST 800-53 mappings (free, CC BY-SA 4.0)",
      "subreddit": "netsec",
      "url": "https://www.opensecurityarchitecture.org",
      "author": "cyberruss",
      "created_utc": "2026-02-09 09:38:05",
      "score": 59,
      "num_comments": 15,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qzzxv2/open_security_architecture_15_new_security/",
      "domain": "opensecurityarchitecture.org",
      "is_self": false,
      "comments": [
        {
          "id": "o4epz2o",
          "author": "IntrepidAbroad",
          "text": "This is nice and clearly a huge amount of work that's gone into it to get it updated - appreciate the sharing. I am going to use it to assess some of my current work around building agentic systems and will try to give feedback afterwards as I've got quite a few years in both software engineering and security.",
          "score": 8,
          "created_utc": "2026-02-09 09:50:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4erl4t",
              "author": "cyberruss",
              "text": "Cheers and thanks for the feedback. Please let us know how it goes and we will feed any learnings back into the patterns. With enough eyes all security patterns (and bugs) are shallow :)",
              "score": 4,
              "created_utc": "2026-02-09 10:06:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4evhet",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-02-09 10:43:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eworl",
              "author": "cyberruss",
              "text": "That's good to hear. The compliance side is one of the strong parts in my view too, we're playing with the idea of extending to more regulatory mappings e.g. IOSCO, HIPAA, MAS etc.. if there's stuff you want to see first let us know and we prioritise.",
              "score": 1,
              "created_utc": "2026-02-09 10:55:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ijwrf",
          "author": "Zaxim",
          "text": "This is very useful. Thanks for putting this together!",
          "score": 2,
          "created_utc": "2026-02-09 22:41:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lmnru",
              "author": "cyberruss",
              "text": "üôè",
              "score": 1,
              "created_utc": "2026-02-10 11:57:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f0duu",
          "author": "Comfortable-Site8626",
          "text": "This is actually pretty useful. I like that the patterns start from real threat scenarios instead of just mapping controls for compliance.\n\nThe AI and DevOps pipeline pieces feel especially relevant right now. This reads more like something you‚Äôd use in an architecture review than another checkbox framework, which is a good thing.",
          "score": 4,
          "created_utc": "2026-02-09 11:28:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f3kq0",
              "author": "cyberruss",
              "text": "All the founders were architects, it probably helps :)",
              "score": 4,
              "created_utc": "2026-02-09 11:54:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4i2bnk",
          "author": "atxweirdo",
          "text": "O man I this is soooo good. I'll definitely be testing this out this week. \n\nWould love to see something similar with iso42001",
          "score": 1,
          "created_utc": "2026-02-09 21:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i3yad",
              "author": "cyberruss",
              "text": "Appreciate the feedback, we‚Äôll check that out and see if there is anything we can do‚Ä¶",
              "score": 2,
              "created_utc": "2026-02-09 21:21:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4gqbpk",
          "author": "ForeignGreen3488",
          "text": "This is excellent work! The Secure AI Integration and API Security patterns are particularly relevant given the rapid adoption of AI APIs in production environments.\n\nWe've been seeing a significant increase in model extraction attacks and API abuse targeting AI infrastructure. The delegation chain exploitation pattern you mentioned is especially critical - many organizations don't realize that their AI service providers can be compromised through indirect API calls.\n\nFrom our experience implementing AI API security solutions, the OWASP API Top 10 mappings to NIST controls are spot-on. We've found that:\n\n1. Broken Object Level Authorization (A01:2021) is the most common vulnerability in AI APIs - many systems don't properly validate that users can only access their own model outputs and training data.\n\n2. Security Misconfiguration (A05:2021) is rampant in AI deployments - default API keys, overly permissive CORS policies, and lack of rate limiting are common issues.\n\n3. Server-Side Request Forgery (A10:2021) becomes particularly dangerous with AI APIs since they often make downstream calls to multiple services.\n\nThe shadow AI problem you mentioned is also growing - employees using unauthorized AI services that bypass corporate security controls entirely.\n\nYour NIST 800-53 mappings provide a great foundation for organizations to build comprehensive AI security programs. The free self-assessment tool is particularly valuable for teams starting their AI security journey.\n\nHave you considered adding patterns specifically for:\n- Model extraction detection and prevention\n- AI API usage monitoring and anomaly detection\n- Data privacy compliance in AI systems (GDPR Article 22, etc.)\n\nThis work fills a critical gap in the security community. Thank you for making it freely available!",
          "score": -1,
          "created_utc": "2026-02-09 17:21:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4h4ci6",
              "author": "cyberruss",
              "text": "Thanks for the detailed feedback. Some of those areas are on the roadmap -- model supply chain and AI-specific monitoring in particular. Appreciate the suggestions.",
              "score": 0,
              "created_utc": "2026-02-09 18:27:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4hrsg7",
                  "author": "ForeignGreen3488",
                  "text": "Great to hear those areas are on the roadmap! Model supply chain security is becoming critical as organizations start building AI systems that depend on third-party models and datasets.\n\nThe AI-specific monitoring piece is particularly interesting. Most teams I work with are still using traditional API monitoring tools that weren't designed for AI-specific threats like prompt injection attempts or model extraction patterns. Having monitoring that can distinguish between legitimate AI usage patterns and potential abuse would be a game-changer.\n\nAre you finding that organizations are struggling more with the technical implementation of these controls, or with the governance/process side of getting security teams and ML teams to work together effectively?\n\nThe collaboration between security and ML teams seems to be a recurring challenge in AI security implementations.",
                  "score": 0,
                  "created_utc": "2026-02-09 20:21:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4gxkzc",
          "author": "ForeignGreen3488",
          "text": "This is excellent work. The Secure AI Integration pattern is particularly timely - we're seeing a massive increase in AI API usage across industries, but most organizations don't realize they're exposing themselves to model extraction attacks through their API integrations.\n\nThe OWASP API Top 10 mapping to NIST controls is also crucial. Many companies focus on traditional API security (authentication, rate limiting) but miss AI-specific threats like prompt injection, model inversion, and training data leakage.\n\nYour interactive SVG approach with control badges linking to full descriptions is exactly what practitioners need. Most compliance frameworks are static documents, but security teams need actionable, context-aware guidance.\n\nHave you considered adding patterns for:\n- AI model supply chain security (third-party model vetting)\n- Continuous AI model monitoring for drift and degradation\n- API key lifecycle management in AI contexts\n\nThis would complement the excellent foundation you've built and address emerging threats we're seeing in production AI deployments.",
          "score": -2,
          "created_utc": "2026-02-09 17:55:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyl3yf",
      "title": "New OSS secret scanner: Kingfisher (Rust) validates exposed creds + maps permissions",
      "subreddit": "netsec",
      "url": "https://www.mongodb.com/company/blog/product-release-announcements/introducing-kingfisher-real-time-secret-detection-validation",
      "author": "micksmix",
      "created_utc": "2026-02-07 18:18:41",
      "score": 37,
      "num_comments": 15,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qyl3yf/new_oss_secret_scanner_kingfisher_rust_validates/",
      "domain": "mongodb.com",
      "is_self": false,
      "comments": [
        {
          "id": "o44ljgw",
          "author": "ruibranco",
          "text": "The blast radius mapping is what sets this apart for me. Most scanners just find the secret and call it a day, but knowing what a leaked key can actually access changes how you prioritize remediation completely. Smart call using tree-sitter for context too, regex-only approaches are false positive machines.\n\n  \nHow's CI integration look? Any plans for a pre-commit hook mode?",
          "score": 8,
          "created_utc": "2026-02-07 19:08:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45ntmi",
              "author": "micksmix",
              "text": "It supports pre-commit hooks natively, via the precommit framework, or via husky:  \n[https://github.com/mongodb/kingfisher/blob/main/docs/INSTALLATION.md#pre-commit-hooks](https://github.com/mongodb/kingfisher/blob/main/docs/INSTALLATION.md#pre-commit-hooks)\n\n",
              "score": 2,
              "created_utc": "2026-02-07 22:33:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o47xtvu",
          "author": "AiChatPrime",
          "text": "The validation + access mapping is powerful, but I think the real value is exposing how bad most orgs' IAM actually is.\n\nIn a lot of environments, \"blasts radius\" just means \"everything\" because service accounts are over privileged and reused across pipelines. Tools like this end up acting more as an audit mirror than just a scanner.\n\nAlso worth noting that real-time validation itself needs tight controls, if the scanner is hitting provider APIs at scale, that's another system that now needs secrets, rate limits, logging, and abuse monitoring.",
          "score": 1,
          "created_utc": "2026-02-08 08:04:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4alo2s",
              "author": "micksmix",
              "text": "Agreed on both points. In a lot of orgs the \"blast radius\" being \"everything\" is just the uncomfortable truth about over-privileged, reused service accounts, and access mapping makes that visible fast.\n\nAlso agreed that validation needs controls, which is why it is optional and can be disabled with `--no-validate`.   \n  \nEach finding report also provides a one-off validate command (`kingfisher validate --rule github \"ghp_...\"`) so you can re-check just that credential on demand, which makes it easy to script validation in a surgical, least-noisy way.\n\nWhen you do enable it, Kingfisher already de-duplicates findings (by default) so it issues far fewer network requests than most scanners, largely because Kingfisher focuses on detection accuracy and, by design, avoids re-validating the same thing over and over.\n\n[https://github.com/mongodb/kingfisher/blob/main/docs/COMPARISON.md#network-requests-comparison](https://github.com/mongodb/kingfisher/blob/main/docs/COMPARISON.md#network-requests-comparison)",
              "score": 2,
              "created_utc": "2026-02-08 18:31:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eh27x",
          "author": "gunni",
          "text": "I wish all these credentials would have an api call to revoke themselves just like you can use a certificates private key to revoke the certificate, that way these scanners could just send the revoke command for the keys.\n\nMaybe put a delay on the revocation so that the owner could react to the event but don't let them ever get away with ignoring it.",
          "score": 1,
          "created_utc": "2026-02-09 08:21:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4gbutu",
              "author": "micksmix",
              "text": "Kingfisher supports revoking credentials, currently for AWS, GCP, GitHub, GitLab, Slack, NPM, BuildKite, Sendgrid, and Tailscale (with more coming).\n\n[https://github.com/mongodb/kingfisher?tab=readme-ov-file#direct-secret-validation--revocation](https://github.com/mongodb/kingfisher?tab=readme-ov-file#direct-secret-validation--revocation)",
              "score": 1,
              "created_utc": "2026-02-09 16:12:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ksq9d",
          "author": "ForeignGreen3488",
          "text": "Great tool! The real-time validation against provider APIs is a game-changer for prioritizing actual security risks. As someone building API security solutions, I particularly appreciate the on-prem design - shipping secrets to third parties has always been a major concern for organizations.\n\nThe blast radius mapping feature is especially valuable. Most secret scanners just find credentials, but understanding the actual impact of a leaked credential is what security teams really need for risk assessment.\n\nHave you considered adding behavioral analysis for API usage patterns? We're finding that detecting anomalous API access patterns can often identify compromised credentials before they're even discovered in code repositories.",
          "score": 1,
          "created_utc": "2026-02-10 07:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47n0at",
          "author": "cryotic",
          "text": "Name collision, that‚Äôs confusing",
          "score": 1,
          "created_utc": "2026-02-08 06:25:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dwixd",
              "author": "micksmix",
              "text": "As we all know, the two hardest problems in computer science are cache invalidation, naming things, and off-by-one errors. üòÑ\n\nTotally fair callout... Kingfisher definitely collides with a bunch of unrelated stuff (the bird, the beer, the airline, the Swift library, etc.). I'm hoping when used in a security context, it will be clear ü§û",
              "score": 0,
              "created_utc": "2026-02-09 05:20:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4e0ve6",
                  "author": "cryotic",
                  "text": "Strong collision in the security context to consider: [https://github.com/rsmusllp/king-phisher](https://github.com/rsmusllp/king-phisher)  \n",
                  "score": 1,
                  "created_utc": "2026-02-09 05:54:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o466ooj",
          "author": "37b",
          "text": "We are looking at switching to this from Nosey Parker. How are false positives managed?",
          "score": 1,
          "created_utc": "2026-02-08 00:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47w314",
              "author": "micksmix",
              "text": "Kingfisher reduces false positives a couple of ways:\n\n* **Service/API validation**: Kingfisher‚Äôs rules include HTTP/service‚Äëspecific validation checks (AWS, Azure, GCP, etc.) so it can confirm whether a detected string is actually a live credential, which helps filter noise beyond regex‚Äëonly matches.\n* **Confidence thresholds**: You can set `--confidence` to high/medium/low to exclude lower‚Äëconfidence hits (often the noisiest). Be default Kingfisher runs with \\`--confidence medium\\` which excludes low confidence rules.\n* **Skip known false positives**: Use `--skip-regex` and/or `--skip-word` to suppress known benign patterns, including inline ignores in code; both match against the secret value and surrounding context so you can be precise.\n* **Inline ignore directives**: Add `kingfisher:ignore` anywhere on the same line as a finding to silence it. (see https://github.com/mongodb/kingfisher/blob/main/docs/ADVANCED.md#inline-ignore-directives)\n* **Baseline management**: Create a baseline of existing findings so future scans only report *new* issues; great for large repos with legacy noise. (see https://github.com/mongodb/kingfisher/blob/main/docs/BASELINE.md)",
              "score": 1,
              "created_utc": "2026-02-08 07:48:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44v985",
          "author": "timmy166",
          "text": "Nice! All you lurkers pay attention, the tool reads to be the real deal and can be the defacto OSS secrets scanner:\n\n- Active Validation (like trufflehog) \n- Tree-sitter with hyperspace: Rust/C++ is faster than Golang‚Äôs regex engine\n- Apache 2 beats GPL3",
          "score": -5,
          "created_utc": "2026-02-07 19:58:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qz67d1",
      "title": "macOS Touch ID/Bio-metric kill switch like iPhone has - PanicLock",
      "subreddit": "netsec",
      "url": "https://paniclock.github.io/",
      "author": "seanieb",
      "created_utc": "2026-02-08 11:04:25",
      "score": 34,
      "num_comments": 8,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qz67d1/macos_touch_idbiometric_kill_switch_like_iphone/",
      "domain": "paniclock.github.io",
      "is_self": false,
      "comments": [
        {
          "id": "o48h685",
          "author": "seanieb",
          "text": "In the US police can force you to unlock your Apple laptop by putting your finger on Touch-ID. \n\nOn iOS you can squeeze the side buttons and Face ID's gone. Two seconds, works in your pocket. macOS has nothing like it.\n\nPanicLock sits in your menu bar. One click (or keyboard shortcut)locks the screen but asks for a password. When you log back in Touch ID will still be active. Free, opensource, notarized and no data collection.\n\nThere's good reasons to keep Touch ID on day-to-day. It stops people watching you type your password, cameras catching it, that sort of thing. This is just for when you need to turn it off quickly and easily. ",
          "score": 16,
          "created_utc": "2026-02-08 11:07:19",
          "is_submitter": true,
          "replies": [
            {
              "id": "o48se06",
              "author": "csonka",
              "text": "Would be good to link to an article to explain how to do the thing in iOS.",
              "score": 0,
              "created_utc": "2026-02-08 12:43:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48re4b",
          "author": "cloudzhq",
          "text": "Nice initiative. Going to add it to a certain list of bookmarks.",
          "score": 2,
          "created_utc": "2026-02-08 12:35:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48rnrt",
              "author": "seanieb",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-08 12:37:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48rxtd",
          "author": "csonka",
          "text": "This looks like something Patrick Wardle would make.\nVery nice.\n\nWas the website made using AI? It has that feel.",
          "score": 1,
          "created_utc": "2026-02-08 12:39:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48u74x",
              "author": "seanieb",
              "text": "Thank you. That's a very nice complement. I'm a big Patrick Wardle fan. I saw him at DefCon this year, and it was the talk that convinced me I could actually start making Mac Apps. I use their BlockBlock, Whats Your Sign and Lulu apps. It would be great if Patrick/Objective-See cloned my app and maintained as their own. I'd love that.   \n  \nAnd yes, nice catch, the webpage was made using AI, Claude Code Opus 4.5 and I made edits using Githubs Co-Pilot  Agent (it generates screenshots of the changes in the PR).  I dunno if I could spot an AI generated site without looking at the git commit history/comments. The first version of the webpage was made by hand, and it looked like trash. You can see it in the git repo.",
              "score": 3,
              "created_utc": "2026-02-08 12:56:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49y6mo",
                  "author": "the91fwy",
                  "text": "I think if you replaced the emoji with font awesome you would lose most of that ‚ÄúAI vibe‚Äù",
                  "score": 1,
                  "created_utc": "2026-02-08 16:39:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o49u7aq",
          "author": "ruibranco",
          "text": "Same threat model applies at border crossings ‚Äî CBP can compel biometrics without a warrant but not a memorized password. This plus FileVault is a solid baseline for anyone traveling with sensitive client data.",
          "score": 1,
          "created_utc": "2026-02-08 16:20:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0h42m",
      "title": "Augustus: Open Source LLM Prompt Injection Tool",
      "subreddit": "netsec",
      "url": "https://www.praetorian.com/blog/introducing-augustus-open-source-llm-prompt-injection/",
      "author": "Praetorian_Security",
      "created_utc": "2026-02-09 21:26:21",
      "score": 31,
      "num_comments": 10,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r0h42m/augustus_open_source_llm_prompt_injection_tool/",
      "domain": "praetorian.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4ic7zr",
          "author": "voronaam",
          "text": "Interesting idea. I do not see an option for specifying authentication header (cookie?) Some chatbot APIs are behind some basic authentication\n\nDo you have support for extra headers in the request?",
          "score": 10,
          "created_utc": "2026-02-09 22:02:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4icvg6",
              "author": "Praetorian_Security",
              "text": "Hi Voronaam, great question...\n\nAugustus does support custom headers via the REST generator. You can pass arbitrary headers (auth tokens, cookies, API keys, etc.) through the `--config` flag:\n\n    augustus scan rest.Rest \\\n      --probe dan.Dan \\\n      --config '{\n        \"uri\": \"https://your-endpoint.com/v1/chat\",\n        \"headers\": {\n          \"Authorization\": \"Bearer YOUR_TOKEN\",\n          \"Cookie\": \"session=abc123\",\n          \"X-Custom-Auth\": \"whatever-you-need\"\n        },\n        \"req_template_json_object\": {\n          \"model\": \"your-model\",\n          \"messages\": [{\"role\": \"user\", \"content\": \"$INPUT\"}]\n        },\n        \"response_json\": true,\n        \"response_json_field\": \"$.choices[0].message.content\"\n      }'\n\nThe REST generator is pretty flexible ... supports custom request templates with `$INPUT` placeholders, JSONPath response extraction, SSE streaming, and proxy routing. So even if the chatbot API isn't OpenAI-compatible, you can configure the request/response format to match whatever you're testing against.",
              "score": -14,
              "created_utc": "2026-02-09 22:05:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iej3x",
                  "author": "voronaam",
                  "text": "You know, you could've answered it yourself ;)",
                  "score": 21,
                  "created_utc": "2026-02-09 22:14:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4j56g5",
                  "author": "TheG0AT0fAllTime",
                  "text": "Oh fucking dear. When is this sub going to hard-ban people who cannot think with their brain anymore?",
                  "score": 18,
                  "created_utc": "2026-02-10 00:38:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4l25x9",
          "author": "thedudeonblockchain",
          "text": "been thinking about this kind of thing lately especially since more security tools are integrating llms into their analysis pipelines. would be curious to see how it handles indirect injection through code comments in source being analyzed - that's probably the most realistic attack surface for dev-facing tools",
          "score": 3,
          "created_utc": "2026-02-10 08:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l8c3f",
          "author": "vornamemitd",
          "text": "What's the benefit over e.g., Promptfoo?",
          "score": 3,
          "created_utc": "2026-02-10 09:52:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r14rlh",
      "title": "Adbleed: partially de-anonymizing VPN users with adblock filter lists",
      "subreddit": "netsec",
      "url": "https://melvin.ovh/adbleed/",
      "author": "TroubleNo3411",
      "created_utc": "2026-02-10 16:04:25",
      "score": 30,
      "num_comments": 3,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r14rlh/adbleed_partially_deanonymizing_vpn_users_with/",
      "domain": "melvin.ovh",
      "is_self": false,
      "comments": [
        {
          "id": "o4pkqhd",
          "author": "Pharisaeus",
          "text": "A bit of a stretch to call this de-anonymizing.",
          "score": 2,
          "created_utc": "2026-02-10 23:52:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4oo39q",
          "author": "kwiksi1ver",
          "text": "Besides browser performance would enabling every list help or make you even more unique?",
          "score": 1,
          "created_utc": "2026-02-10 21:06:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plcur",
              "author": "Pharisaeus",
              "text": "I think it would make you stand out even more. It might prevent leaking information, but on the other hand it will make fingerprinting and tracking you much easier. So I won't know what country you're from, but I will know it's you wherever you go. A bit like wearing a ski mask to the beach in the summer - no one knows your face, but everyone know it's you...",
              "score": 3,
              "created_utc": "2026-02-10 23:55:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxawcm",
      "title": "Hacking a cheap Wi-Fi toy drone",
      "subreddit": "netsec",
      "url": "https://journal.farhaan.me/hacking-chinese-toy-dronea17",
      "author": "fhackdroid",
      "created_utc": "2026-02-06 07:10:15",
      "score": 26,
      "num_comments": 5,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxawcm/hacking_a_cheap_wifi_toy_drone/",
      "domain": "journal.farhaan.me",
      "is_self": false,
      "comments": [
        {
          "id": "o3we8j4",
          "author": "ruibranco",
          "text": "Raw UDP with zero auth or encryption is wild but honestly expected for this price point. The scary part is that anyone on the same Wi-Fi range could just send control packets and hijack the thing mid-flight. Good writeup though, these cheap IoT teardowns are always a goldmine for understanding how little thought goes into security at the consumer hardware level.",
          "score": 5,
          "created_utc": "2026-02-06 13:38:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x9h5q",
              "author": "sdrawkcabineter",
              "text": ">Raw UDP with zero auth or encryption is wild\n\n\"No no, you're being ignorant. It's a really long OTP used as a continuous port knock...\"",
              "score": 2,
              "created_utc": "2026-02-06 16:16:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4f642j",
                  "author": "fhackdroid",
                  "text": "hahahah! yuss!",
                  "score": 2,
                  "created_utc": "2026-02-09 12:14:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4f686a",
              "author": "fhackdroid",
              "text": "Yup I got to learn so many nuiance about how the firmwares are written and how the controllers actually work.",
              "score": 1,
              "created_utc": "2026-02-09 12:15:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o47z7e4",
          "author": "AiChatPrime",
          "text": "That shows up all over cheap IoT. No auth, no update story.\n\nIt's fine when it's a toy on a bench. It's a problem once it's sitting on a real network for 2 years and nobody remembers it exists.",
          "score": 1,
          "created_utc": "2026-02-08 08:17:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyfxlw",
      "title": "trappsec: open source framework for API deception",
      "subreddit": "netsec",
      "url": "https://trappsec.dev",
      "author": "nikhil-salgaonkar",
      "created_utc": "2026-02-07 14:59:42",
      "score": 22,
      "num_comments": 6,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qyfxlw/trappsec_open_source_framework_for_api_deception/",
      "domain": "trappsec.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o43eiq2",
          "author": "webrnaster",
          "text": "Clever idea, it made me smile.\n\nI've considered putting \"is_admin\" in a server header and if someone actually took the time to flip it from false to true, they'd get redirected to a fake login page . Time is the one of the best defenses. \n\nReminds me of nmap scans that just respond with yes for every port. \n\nWhat is the action someone would take on an IP address that was probing these endpoints? Would a security spend be better focused on securing the real endpoints that exist versus creating a maze? Then again getting any insight into a potential attacker is useful. \n\nSeems like false positives and alert overload could be an issue due to scanners and bots.",
          "score": 3,
          "created_utc": "2026-02-07 15:36:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43gr21",
              "author": "nikhil-salgaonkar",
              "text": "Thanks!\n\nSo, alerts are only raised if the attacker uses an authenticated session (valid credentials or API keys)\n\nThe framework has something called auth-aware responses. Just like real APIs would respond with some needs authn/authzn error, so would the decoy routes defined here leading the attacker to believe that it's just another API endpoint that needs authentication. The key is in making the deception boring.\n\nunauthenticated hits are logged as signals leaving their usage to the discretion of the monitoring team. Personally, my thought process was more around catching people poking for business logic flaws and not scanners.",
              "score": 3,
              "created_utc": "2026-02-07 15:47:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4418pf",
              "author": "peiggs",
              "text": "I think from an AppSec perspective, this isn‚Äôt the greatest idea. Sure, you have a high fidelity alert. But, the fake login page is only going to keep the bad actor interested longer. They will probably try elsewhere on your site instead of moving onto the next one.",
              "score": 1,
              "created_utc": "2026-02-07 17:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o443hjl",
                  "author": "nikhil-salgaonkar",
                  "text": "I wouldn't recommend fake login pages as a decoy to anyone. The framework offers better avenues for deception. That aside, my perspective is that if someone is actively mapping your API surface, they're going to try adjacent routes regardless. The framework helps you instrument your application to detect reconnaissance that's happening and make it visible.",
                  "score": 2,
                  "created_utc": "2026-02-07 17:39:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qvvin8",
      "title": "Kernel-Level Stealthy Observation of TTY Streams",
      "subreddit": "netsec",
      "url": "https://blog.cybervelia.com/p/kernel-level-stealthy-observation-of-tty-streams",
      "author": "thnew_mammoth",
      "created_utc": "2026-02-04 17:52:13",
      "score": 22,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qvvin8/kernellevel_stealthy_observation_of_tty_streams/",
      "domain": "blog.cybervelia.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3n5fm7",
          "author": "ruibranco",
          "text": "Neat starting point. The kprobes approach being visible in /sys/kernel/debug/kprobes/list is the obvious weakness though ‚Äî trivially detectable with a periodic check. The eBPF evolution of this is where it gets more interesting for red teams: bpf\\_probe\\_read\\_user attached to tty\\_write achieves the same interception without a loadable module, and detection shifts to bpftool prog list which far fewer defenders are monitoring.",
          "score": 5,
          "created_utc": "2026-02-05 01:56:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sjgbz",
          "author": "AYamHah",
          "text": "Great work on this research and write up. Interested in what blue teamers think of this.",
          "score": 1,
          "created_utc": "2026-02-05 21:43:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qw2mw8",
      "title": "2026: New N8N RCE Deep Dive into CVE-2026-25049",
      "subreddit": "netsec",
      "url": "https://blog.securelayer7.net/cve-2026-25049/",
      "author": "appsec1337",
      "created_utc": "2026-02-04 22:07:46",
      "score": 21,
      "num_comments": 2,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qw2mw8/2026_new_n8n_rce_deep_dive_into_cve202625049/",
      "domain": "blog.securelayer7.net",
      "is_self": false,
      "comments": [
        {
          "id": "o3m2lzx",
          "author": "ruibranco",
          "text": "The public webhook attack surface is the part that should concern anyone self-hosting n8n. A lot of people expose n8n directly or behind a simple reverse proxy without any additional auth layer on the webhook paths, assuming the workflow-level authentication is sufficient. Getting RCE through JavaScript destructuring abuse in the expression evaluator is a nasty primitive because n8n's whole value proposition is running arbitrary integrations ‚Äî meaning the blast radius post-exploitation is enormous (API keys, database credentials, cloud tokens for every connected service).\n\n  \nThis is also a good reminder that sandboxing JavaScript execution in Node.js is fundamentally hard. n8n uses vm2 (or did, before it was abandoned) and later moved to isolated-vm, but expression evaluation paths sometimes bypass the sandbox entirely. The Code node vs expression evaluation have different trust boundaries that aren't always obvious.\n\n  \nFor anyone running n8n in production: put it behind a VPN or zero-trust proxy (Cloudflare Access, Tailscale, etc.), never expose webhook endpoints to the raw internet without rate limiting and input validation at the edge, and treat the n8n process as fully privileged in your threat model.",
          "score": 6,
          "created_utc": "2026-02-04 22:22:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o416kvp",
          "author": "AiChatPrime",
          "text": "Low-code tools like n8n are turning into real infrastructure, but most orgs still treat them like toys. RCE here is a big deal especially since these systems usually have broad internal access.",
          "score": 1,
          "created_utc": "2026-02-07 05:07:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwtzyn",
      "title": "Django SQL Injection in RasterField lookup (CVE-2026-1207)",
      "subreddit": "netsec",
      "url": "https://vulnerabletarget.com/VT-2026-1207",
      "author": "c0daman",
      "created_utc": "2026-02-05 18:54:56",
      "score": 21,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qwtzyn/django_sql_injection_in_rasterfield_lookup/",
      "domain": "vulnerabletarget.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3sfmmd",
          "author": "ruibranco",
          "text": "Worth noting that RasterField is part of django.contrib.gis, so this only affects projects using GeoDjango with PostGIS raster support. The attack surface is narrower than a typical Django SQLi since you'd need to pass user-controlled input into raster-specific lookups. That said, if you're running a mapping or GIS application that takes user input for spatial queries, this is a critical one to patch. Always good to see Django's security team catching these in the ORM's less-traveled corners.",
          "score": 6,
          "created_utc": "2026-02-05 21:25:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy0mjx",
      "title": "crypto-scanner: Open-source CLI tool to find quantum-vulnerable cryptography in your codebase",
      "subreddit": "netsec",
      "url": "https://pypi.org/project/crypto-scanner/",
      "author": "MindlessConclusion42",
      "created_utc": "2026-02-07 01:41:45",
      "score": 15,
      "num_comments": 6,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qy0mjx/cryptoscanner_opensource_cli_tool_to_find/",
      "domain": "pypi.org",
      "is_self": false,
      "comments": [
        {
          "id": "o42jvhk",
          "author": "ukindom",
          "text": "\nI like to ask what is the _severity_ of this problem? Many algorithms included modifications to mitigate post-quantum calculations, and upgrade burden to at least support (I don't mention to migrate users) is enormous.\n\nAdditionally, I'd like new algorithms to be added to platforms such as GitHub to auth.\n\nAnd what's about GPG? I believe it also susceptive as well.",
          "score": 2,
          "created_utc": "2026-02-07 12:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o490yzk",
              "author": "MindlessConclusion42",
              "text": "Great questions, let me take them one at a time.\n\nSeverity ‚Äî right now the 4-tier system is based on NIST's post-quantum vulnerability classifications. You're right that the migration burden is a huge factor that isn't captured in a simple \"critical/high/medium/low\" label. I'm considering adding a `migration_complexity` field to the JSON output so teams can prioritize by effort, not just risk.\n\nNew algorithms on platforms like GitHub auth ‚Äî agreed, detection for newer PQC-compatible algorithms is on the roadmap. Right now it catches what's vulnerable, but flagging what's *already migrated* would be just as useful.\n\nGPG ‚Äî yes, most GPG keys in the wild are RSA or classical ECC, both quantum-vulnerable. Adding GPG keyring scanning is a solid idea. I'll open an issue for it.\n\nThanks ‚Äî this is exactly the kind of feedback that makes the tool better.",
              "score": 1,
              "created_utc": "2026-02-08 13:41:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49ic43",
                  "author": "ukindom",
                  "text": "Additional questions are about non-technical cost and general availability. \n\nLet‚Äôs say I hijacked a database with such keys and want to crack them open\n\n1. What is the cost to have such computer without pinging back to a mother company? \n2. How to buy such computer to weaponise it without much attention? \n3. What are electricity and infrastructure (including occupied space and weight) costs to hide myself in a landscape and move myself from time to time?\n4. What is the time (average) to find pairs to reveal primes?\n‚Ä¶",
                  "score": 1,
                  "created_utc": "2026-02-08 15:20:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o42ixat",
          "author": "ukindom",
          "text": "Please modify exclusions to make them global and per-language. E.g. `target` should be excluded from Rust project, but shouldn't from Java or Python project.",
          "score": 1,
          "created_utc": "2026-02-07 12:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o490oxy",
              "author": "MindlessConclusion42",
              "text": "Good catch ‚Äî you're right that `target/` is noise in Rust but could be meaningful elsewhere. Exclusions are global right now which is lazy on my part.\n\nI'm adding per-language exclusion profiles with sensible defaults. \n\nAppreciate the feedback.\n\nTracking it here: [https://github.com/mbennett-labs/crypto-scanner/issues/1](https://github.com/mbennett-labs/crypto-scanner/issues/1)",
              "score": 1,
              "created_utc": "2026-02-08 13:39:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m6h8z",
          "author": "thedudeonblockchain",
          "text": "this is especially relevant for anyone working in the blockchain and cryptocurrency space where the entire security model is built on ecdsa and eddsa. unlike most enterprise systems where you can rotate keys and update tls certs, blockchain addresses are permanent public commitments to specific cryptographic assumptions - every address with a balance is essentially a public challenge that says 'break secp256k1 and take my money.' the harvest-now-decrypt-later threat is real for high-value wallets since the public key is exposed the moment you make your first outbound transaction, and those keys will be sitting on a public ledger indefinitely. the migration challenge for on-chain assets is also orders of magnitude harder than migrating a web service because you need every individual wallet holder to move their funds to a quantum-resistant address, and anyone who doesn't (lost keys, inactive wallets, forgotten accounts) loses everything. i'd be curious to see how this scanner handles smart contract codebases specifically - a lot of solidity and rust programs implement their own signature verification logic or use non-standard curves, and those patterns might not get caught by the standard detection rules. would also be interesting to add detection for hash-based commitments that rely on collision resistance assumptions that quantum could weaken, since keccak256 and sha256 are used extensively in merkle trees and storage proofs across every major chain",
          "score": 1,
          "created_utc": "2026-02-10 14:02:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1bswg",
      "title": "I let Claude Code with 150+ offensive security MCP tools loose on my homelab",
      "subreddit": "netsec",
      "url": "https://www.credrelay.com/p/claude-code-homelab-hack?draft=true",
      "author": "Mindless-Study1898",
      "created_utc": "2026-02-10 20:15:26",
      "score": 14,
      "num_comments": 12,
      "upvote_ratio": 0.66,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r1bswg/i_let_claude_code_with_150_offensive_security_mcp/",
      "domain": "credrelay.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4og6nk",
          "author": "vornamemitd",
          "text": "Coincidence or is the OpenClaw-based anime helper the actual message? Don't use Hexstrike via MCP - configure the lobster properly and let it build the right skills themselves? There are quite the number of tools out there that do way better. Nice collection: [https://github.com/EvanThomasLuke/Awesome-AI-Hacking-Agents](https://github.com/EvanThomasLuke/Awesome-AI-Hacking-Agents)",
          "score": 9,
          "created_utc": "2026-02-10 20:29:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oy2a2",
              "author": "Mindless-Study1898",
              "text": "That's one thing I think is that you can just throw OpenClaw on Kali instead of using Hexstrike to wrap kali in an mcp server. Thanks for the list.",
              "score": 4,
              "created_utc": "2026-02-10 21:52:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4oyn7x",
                  "author": "vornamemitd",
                  "text": "Next project coming up? :)",
                  "score": 3,
                  "created_utc": "2026-02-10 21:55:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4p8vkr",
          "author": "Electronic_Amphibian",
          "text": "I tried something similar a while ago. I found it was pretty helpful for some things but required a lot of direction and arguing that it was in fact legal for it to do what I asked.\n\nIt wasn't great at \"hacking\" stuff but it was pretty good at setting things up e.g. go install x, y, z on host a.b.c.d and start a code scan against git://blah.",
          "score": 4,
          "created_utc": "2026-02-10 22:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4peq3q",
              "author": "Mindless-Study1898",
              "text": "It's still basically the same but the mcp wrapper that hexstrike has does help the LLM use the tools better I think. I'm curious what would happen if you just asked OpenClaw to give it a shot with a frontier model on a kali vm.",
              "score": 1,
              "created_utc": "2026-02-10 23:18:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pno0h",
          "author": "Dangle76",
          "text": "To save context you can also use an agents.md file to describe what CLI tools are available and what you‚Äôd use them for, and to use -h to understand how to invoke it.\n\nMCP servers eat up a lot of context because they load all of their tools into context on initialization.\n\nUsing the former method it only uses context when it needs to use the tool.",
          "score": 4,
          "created_utc": "2026-02-11 00:08:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pp2m7",
          "author": "hankyone",
          "text": "You don‚Äôt need MCPs, agents can run existing CLI tools just fine",
          "score": 3,
          "created_utc": "2026-02-11 00:16:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4q59fn",
              "author": "Mindless-Study1898",
              "text": "Yep! I think MCP servers are not needed for CLI tools anymore.",
              "score": 1,
              "created_utc": "2026-02-11 01:52:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4qi62c",
                  "author": "__jent",
                  "text": "I actually explored this in depth with a tool I made: [https://github.com/go-appsec/toolbox](https://github.com/go-appsec/toolbox)\n\nHaving the same assumption as you and u/hankyone, it initially started out as a CLI which the agent would be expected to discover the usage of through \\`help\\` commands.  Unfortunately my finding is that agents are not good with CLI's that are not common knowledge.  A CLI that they intrinsically understand they use well, but a CLI which they must learn how to use is different, and in that case MCP does perform better.\n\nMany agents would use help to discover usage at the start, but then would stop and instead try to assume usage. Often resulting in trial and error that used more tokens than MCP would use just putting usage up front.\n\nAfter a fair bit of testing, I did find that the MCP overall was more reliable and did use less tokens (the savings of tokens in usage and tool descriptions did not make up for less reliable tool usage).  Now I focus the CLI on human usage and the MCP on agent usage.\n\nMCP does have an API for dynamic tool loading, which may be the ultimate answer, but support is still too new to comment on right now.\n\nLet me know if you have other experiences, or any advice I should try out in my project. I am going to continue to explore this space for a while.",
                  "score": 2,
                  "created_utc": "2026-02-11 03:10:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qza4lh",
      "title": "Defense Evasion: The Service Run Failed Successfully",
      "subreddit": "netsec",
      "url": "https://www.zerosalarium.com/2026/02/Defense-Evasion-The-service-run-failed-successfully.html",
      "author": "Cold-Dinosaur",
      "created_utc": "2026-02-08 14:21:01",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qza4lh/defense_evasion_the_service_run_failed/",
      "domain": "zerosalarium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4e0y27",
          "author": "AiChatPrime",
          "text": "\"Service Failure\" abuse is one of those things that sits in plain sites for years and still gets missed in most hardening guides. Everyone watching \"ImagePath\" and \"Registry\", almost nobody reviews failure action.\n\nGreat reminder that \"crash\" is often the hardest part of these chains, not execution itself.",
          "score": 1,
          "created_utc": "2026-02-09 05:55:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzwqa7",
      "title": "klint - Linux Kernel Security Scanner",
      "subreddit": "netsec",
      "url": "http://saturnine.cc/klint",
      "author": "Short_Radio_1450",
      "created_utc": "2026-02-09 06:20:43",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qzwqa7/klint_linux_kernel_security_scanner/",
      "domain": "saturnine.cc",
      "is_self": false,
      "comments": [
        {
          "id": "o4efdf4",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -6,
          "created_utc": "2026-02-09 08:04:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4elfsj",
              "author": "ptweezy",
              "text": "AI slop",
              "score": 6,
              "created_utc": "2026-02-09 09:04:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r01the",
      "title": "On the risk of destructive bricking attacks against OT devices (part 1)",
      "subreddit": "netsec",
      "url": "https://www.midnightblue.nl/blog/have-you-tried-turning-it-off-and-on-again-part-1",
      "author": "2ROT13",
      "created_utc": "2026-02-09 11:30:25",
      "score": 12,
      "num_comments": 1,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r01the/on_the_risk_of_destructive_bricking_attacks/",
      "domain": "midnightblue.nl",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qweadr",
      "title": "CVE-2025-11730: Remote Code Execution via DDNS configuration in ZYXEL ATP/USG Series (V5.41)",
      "subreddit": "netsec",
      "url": "https://rainpwn.blog/blog/cve-2025-11730/",
      "author": "Advanced_Rough8330",
      "created_utc": "2026-02-05 06:53:41",
      "score": 11,
      "num_comments": 1,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qweadr/cve202511730_remote_code_execution_via_ddns/",
      "domain": "rainpwn.blog",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qxdxjy",
      "title": "Experiment demonstrates Al-generated identities bypassing KYC-based verification systems",
      "subreddit": "netsec",
      "url": "https://mpost.io/humanity-protocol-experiment-reveals-how-ai-can-bypass-kyc-and-exploit-digital-trust/",
      "author": "Gullible_Bet_7899",
      "created_utc": "2026-02-06 10:19:25",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxdxjy/experiment_demonstrates_algenerated_identities/",
      "domain": "mpost.io",
      "is_self": false,
      "comments": [
        {
          "id": "o3vyb49",
          "author": "AiChatPrime",
          "text": "The problem isn't that AI can fake identities, it's that most KY is still designed as a one-time check. Trust is treated as a static state, when it should be something continuously evaluated over time. AI just makes that gap obvious.",
          "score": 6,
          "created_utc": "2026-02-06 11:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z7nnc",
          "author": "ruibranco",
          "text": "KYC was already fragile before generative AI entered the picture. Sophisticated fraudsters have been beating document checks and liveness detection for years, AI just made it cheap and scalable enough that anyone can do it now. The fundamental issue is that the entire verification model is built on \"present a document and show your face,\" which becomes meaningless when both can be synthesized on demand. Until identity verification moves beyond static document checks to something cryptographically anchored, this is just going to keep getting worse.",
          "score": 5,
          "created_utc": "2026-02-06 21:55:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46dfze",
          "author": "Wonder_Weenis",
          "text": "Every tech CEO on the planet claiming most human jobs are going to be replaced by ai\n\nand you're telling me the ai can't identify stop signs?\n\nPick one.¬†",
          "score": 2,
          "created_utc": "2026-02-08 01:07:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}