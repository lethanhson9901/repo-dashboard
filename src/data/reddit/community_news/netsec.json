{
  "metadata": {
    "last_updated": "2026-02-09 09:19:58",
    "time_filter": "week",
    "subreddit": "netsec",
    "total_items": 20,
    "total_comments": 68,
    "file_size_bytes": 102111
  },
  "items": [
    {
      "id": "1qw4sfa",
      "title": "Recreating uncensored Epstein PDFs from raw encoded attachments... or trying to, anyway",
      "subreddit": "netsec",
      "url": "https://neosmart.net/blog/recreating-epstein-pdfs-from-raw-encoded-attachments/",
      "author": "mqudsi",
      "created_utc": "2026-02-04 23:32:30",
      "score": 741,
      "num_comments": 73,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qw4sfa/recreating_uncensored_epstein_pdfs_from_raw/",
      "domain": "neosmart.net",
      "is_self": false,
      "comments": [
        {
          "id": "o3molh5",
          "author": "a_random_superhero",
          "text": "I think the way to do it is to make a classifier. \n\nSince you know the compression and font used, you can build sets of characters with varying levels of compression. Then grab some characters from the document and compare against the compressed corpus. That should get you in the ballpark for identification. After that, it‚Äôs a pixel comparison contest where each potential character is compared against the ballpark set. If something is too close to call or doesn‚Äôt match at all, then flag for manual review.",
          "score": 127,
          "created_utc": "2026-02-05 00:20:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mrkgi",
              "author": "mqudsi",
              "text": "That‚Äôs pretty much where I ended up, too. I had just spent too much time on this at a busy moment in my life and couldn‚Äôt afford to sink the dev time into this. Although writing it up probably took as long as that would have taken, lol.\n\nUPDATE:\n\nI ended up solving it [by training a CNN](https://neosmart.net/blog/efta00400459-has-been-cracked-dbc12-pdf-liberated/) as a classifier.",
              "score": 66,
              "created_utc": "2026-02-05 00:36:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3rubso",
                  "author": "cccanterbury",
                  "text": "I am fully convinced you hacked this all the way and then posted this so you wouldn't get in trouble.",
                  "score": 9,
                  "created_utc": "2026-02-05 19:43:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qtj31",
                  "author": "LoveCyberSecs",
                  "text": "Ain't nothin wrong with measuring twice before cutting.",
                  "score": 3,
                  "created_utc": "2026-02-05 16:53:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3vdpl8",
                  "author": "Games_sans_frontiers",
                  "text": "Thank you for writing it up though. It was really interesting being stepped through the thought process.",
                  "score": 2,
                  "created_utc": "2026-02-06 08:53:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3pmnam",
              "author": "wigglyworm91",
              "text": "I was able to get pretty decent-ish results with https://github.com/wigglyworm91/courier-new-ocr without even pregenerating compressed data (like 95% accuracy and no confidently incorrect guesses), but I don't think that's good enough to handle the compressed data sections.",
              "score": 17,
              "created_utc": "2026-02-05 13:17:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3t5vim",
                  "author": "hyperblaster",
                  "text": "Nice work there! Using KMeans clustering to restrict the classifier to the 64 chars in base64 is smart. \n\nYou're reading in the individual glyphs into cv2 as grayscale. DCT artifacts and color fringing might be critical here, so maybe retain full color?",
                  "score": 5,
                  "created_utc": "2026-02-05 23:39:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3sfyaw",
                  "author": "eth0izzle",
                  "text": "Can you share the labels ",
                  "score": 2,
                  "created_utc": "2026-02-05 21:26:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ah4ka",
              "author": "PM-ME-UR-DARKNESS",
              "text": "Holy fuckin shit y'all gonna be using AI to unredact the Epstein files lmao",
              "score": 1,
              "created_utc": "2026-02-08 18:10:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o9p0c",
          "author": "thenickdude",
          "text": "If you can manage to get your PDF decoder into the loop, it seems like a backtracking search would solve this one. i.e turn every confusable character into a branch point, and when you hit a PDF decode error, backtrack to the previous branch to try the next alternative.",
          "score": 26,
          "created_utc": "2026-02-05 06:18:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qj5e7",
              "author": "mqudsi",
              "text": "Someone suggested a harness with AFL (the fuzzer) hooking into poppler or any other PDF library. Clever, but also kind of the inverse of the usual fuzzer goal. It might be hard to constrain it to only make changes that converge to success rather than diverge to different failure modes.",
              "score": 7,
              "created_utc": "2026-02-05 16:05:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qu0cf",
          "author": "voronaam",
          "text": "FYI, I also went this route and decided that rather than OCR'ing the PDF, I'll just go and fix all the OCR mistakes by hand.\n\nI wrote a little utility to make it easier.\n\nHere is a screenshot: https://imgur.com/screenshot-gTnNrkW\n\nHere is the code: https://github.com/voronaam/pdfbase64tofile\n\nIt is kind of working. I have EXIF fully repaired for EFTA01012650.pdf file I was working on and the first scanline is showing up (with some extra JPEG artifacts though).\n\nIt takes me about an hour per page to fix it. I am currently on page 8 of that file. It is 456 pages of base64 for two photos. At this rate (I can do this for a couple of hours a day here and there) it will take me about a year to fix the files.\n\nWhat I need, if anybody is willing to help, is a library to work with corrupted JPEG. I need it to report the problems with the decoded JPEG and their offsets. The latter part is crucial. Knowing where the data is corrupted I can find it in the PDF file and fix the OCR mistakes. Currently I see all the libraries report errors like `Error in decoding MCU. Reason Marker UNKNOWN(67) found in bitstream, possibly corrupt jpeg`. I mean, cool, the byte 67 is wrong. I can fix it. Can you tell me which one? And is it even a 0x67 or not?\n\nAlso, if anyone wants to train a classifier model for better OCR, you'd need those cleaned up files for training. I have pushed the ones I have so far to the repo.",
          "score": 23,
          "created_utc": "2026-02-05 16:55:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r2fpx",
              "author": "voronaam",
              "text": "I guess I'll elaborate on what's going on with the screenshot in case someone wants to write a full featured utility or a website and crowdsource this.\n\n1. Top section is the PDF rendered. It has a thick green cursor under the current character - matching the position of the character in the editable text below automatically.\n2. Below that is the OCR'd text from the PDF. Markers to the left of each line indicate if the line looks \"clean\" or not. It is green when the line is exactly 76 characters of base64. It is orange if there are any \"weird\" characters present and just grey if just the length is wrong.\n\nThe fields are specifically limited in height to just a couple of lines each - to help keep focus on just a few lines.\n\nSave button on top allow for saving the OCR'd text (just in `page008.txt` in the current folder). There is also a \"Display\" button that runs a script that converts those files into a JPEG with whatever pipeline you had in mind.\n\nI also added a button to jump to the next character in the `I/l/1` set - the most commonly mixed up by the OCR. So it allows for quick jumps to the most likely errored out letters.",
              "score": 7,
              "created_utc": "2026-02-05 17:35:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3umr0e",
              "author": "survivalist_guy",
              "text": "In rust too, no less. Nice work. Thanks for the contribution, I'm working on a few paths for the OCR so I'll take a look.",
              "score": 6,
              "created_utc": "2026-02-06 05:02:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3updux",
                  "author": "voronaam",
                  "text": "Well, I knew that I'll be loading corrupted JPEG into memory - with pretty much guaranteed buffer under- and overruns. That is pretty much a textbook case for a memory-safe language.\n\nFirst time doing any GUI in Rust though. It is ugly :)\n\nAlso, sharing it just in case: https://albmac.github.io/JPEGVisualRepairTool/ I am not the author, but this tool is the best I found so far to examine the corrupted JPEG files. It highlights troubles MCUs and shows they binary offsets in the JPEG file. I added a \"Jump to Hex\" button to my app - doing some basic math to convert that offset into base64 text position.",
                  "score": 3,
                  "created_utc": "2026-02-06 05:21:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o41yl4l",
              "author": "Kokuten",
              "text": "Ahh I see you are still at it. Great work!",
              "score": 2,
              "created_utc": "2026-02-07 09:19:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o420sn5",
                  "author": "voronaam",
                  "text": "Thank you. The key was finding this tool: https://albmac.github.io/JPEGVisualRepairTool/JPEGVisualRepairTool.html\n\nIt highlights troubled areas in a JPEG file and even gives me the byte offset of their location in file. With just some basic math I am able to jump to that spot in the base64 file and look for OCR errors.\n\nIt goes much faster when I know which areas look good enough already and which ones still need a bit of attention",
                  "score": 1,
                  "created_utc": "2026-02-07 09:41:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3n8u50",
          "author": "MartinVanBallin",
          "text": "Nice write up! I was actually trying this last night with some encoded jpegs in the emails. I agree the OCR is really poorly done by the DOJ!",
          "score": 18,
          "created_utc": "2026-02-05 02:15:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3s2ins",
              "author": "originaltexter",
              "text": "Same. Those files named \"unnamed\" with no file extension have a lot in them. I recovered two images from one of them just now. couple more last night of some police cars staking out one of his properties and a photo of an alleged private investigator who JE's PI photographed for him.",
              "score": 6,
              "created_utc": "2026-02-05 20:22:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40zusg",
                  "author": "No_Judge_4307",
                  "text": "Where did you find the files marked as \"unnamed\"?",
                  "score": 1,
                  "created_utc": "2026-02-07 04:18:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41c70m",
                  "author": "Lower-Collection-828",
                  "text": "can you share them?",
                  "score": 1,
                  "created_utc": "2026-02-07 05:51:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rmxa6",
          "author": "BCMM",
          "text": ">¬†No problem, I‚Äôll just use imagemagick/ghostscript¬†to convert the PDF into individual PNG images (to avoid further generational loss)\n\n\nBut this isn't lossless! The PDF will be rasterised at a resolution which is unlikely to match the resolution of the embedded images.\n\n\nIt's good that you're encoding the result to a lossless format, but it's the result of resizing a raster image.\n\n\nInstead, use `pdfimages`, from poppler-utils, to extract the images directly from the PDF.",
          "score": 16,
          "created_utc": "2026-02-05 19:08:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rpofa",
              "author": "mqudsi",
              "text": "Ahhh! Great catch!",
              "score": 14,
              "created_utc": "2026-02-05 19:21:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3y564b",
                  "author": "BCMM",
                  "text": "> But in the Epstein PDFs released by the DoJ, we only have low-quality JPEG scans at a fairly small point size.\n\nFurthermore, I don't think these are scans. I think they're digital all the way, equivalent to screenshots of rendered text. (My guess would be that they used the Print to PDF feature in whatever email software they are using, applied redactions to the output, and then rasterised the result because they don't know how else to stop fucking up the redaction process.)\n\n**I believe this opens up new possibilities for accurate OCR.**\n\nI say they're not scans because:\n\n1. I couldn't find any dust (e.g. random grey pixels between lines of text)\n2. Lines of text are perfectly horizontal\n3. If you zoom in, the antialiasing looks like it's in its original condition\n\nHaving extracted the images, without compression or resizing artefacts, I observe the following:\n\nUnfortunately, it is *not* the case that the same character always renders to the exact same pixels. This is because a single column of monospaced characters has a non-integer width (it's about 7.8px).\n\nHowever, rows appear to have a height of *exactly* 15px. If we're lucky, this means that, when the same character occurs *in the same column*, it reliably produces the same pixels.\n\nNow, I admit that I've only tested with a very small number of examples, manually, using the colour picker in GIMP. But the above does appear to be true! Hopefully, this means that we're working with a finite number of pixmap representations of each character.\n\nIn fact, I think the width is *exactly* 7.8px, giving us only five possible variants of each character. This is subject to the same caveat about very light testing, but for example, the first and last characters in `there if it` are rendered totally identically. The same holds true for the 2^nd and 16^th `I`s in that long run of `ICAg` at the end.\n\nSo, I believe it is possible to do a sort of dumb \"OCR\" on this by splitting it up in to regular (well, predictably irregular) tiles, and checking a library of reference tiles for an exact match for each tile. We would only need 64√ó5=320 reference tiles. It seems relatively likely that there's existing software that takes this approach, but I haven't looked for it yet.",
                  "score": 10,
                  "created_utc": "2026-02-06 18:45:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xm0zd",
                  "author": "BCMM",
                  "text": "Now that I've actually looked at the PDF, I have another couple of quibbles about the images:\n\n> But in the Epstein PDFs released by the DoJ, we only have low-quality JPEG scans at a fairly small point size.\n\nThe images in EFTA00400459.pdf are losslessly encoded, in a way that's equivalent to PNG (but not identical - the rest of this comment will be excessive technical detail on that).\n\nIn PDF, images are not represented by directly embedding image files in familiar formats (unlike e.g. images in OOXML). Instead, an image is a *stream object*, i.e. a sequence of binary bytes, which must be interpreted according to the dimensions and pixel format specified in a *dictionary* which occurs just before the stream. For compression, the dictionary may also specify *filters*, which are applied before said interpretation.\n\nPDF supports a filter called DCTDecode, which is very similar to JPEG, but it isn't used in EFTA00400459.pdf.\n\nAll image streams in EFTA00400459.pdf have a dictionary a bit like this:\n\n    <</Type /XObject /Subtype /Image /Name /Im0 /Filter [/FlateDecode ] /Width 816 /Height 1056 /ColorSpace 10 0 R /BitsPerComponent 8 /Length 9 0 R >> \n\n\n`/Filter [/FlateDecode ]` means the stream should be decompressed using the DEFLATE algorithm. While the compression technology is identical to PNG, it's not actually a PNG because there no PNG header, no \"chunks\", etc.",
                  "score": 6,
                  "created_utc": "2026-02-06 17:14:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ula48",
              "author": "survivalist_guy",
              "text": "Thank you! I've been using PyMuPDF. Also been trying Azure Document Intelligence a try, we'll see how that goes.",
              "score": 1,
              "created_utc": "2026-02-06 04:51:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3vf4as",
          "author": "dinopio",
          "text": "Decoded files [https://limewire.com/d/a7olB#WnVBT78Q9v](https://limewire.com/d/a7olB#WnVBT78Q9v) ",
          "score": 16,
          "created_utc": "2026-02-06 09:07:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3vf9v2",
              "author": "dinopio",
              "text": "code from [https://github.com/KoKuToru/extract\\_attachment\\_EFTA00400459](https://github.com/KoKuToru/extract_attachment_EFTA00400459) ",
              "score": 7,
              "created_utc": "2026-02-06 09:08:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o42ok2b",
              "author": "_ManWithNoMemories_",
              "text": "The link does not work",
              "score": 0,
              "created_utc": "2026-02-07 13:09:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ro30m",
          "author": "eth0izzle",
          "text": "The Content ID of the email attachment is ends with cpusers.carillon.local, which suggests it originated from a local AD + Exchange environment. Could Carillion be the British multinational that went bust in 2018? [https://en.wikipedia.org/wiki/Carillion](https://en.wikipedia.org/wiki/Carillion)",
          "score": 6,
          "created_utc": "2026-02-05 19:14:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mwnpa",
          "author": "badteeth3000",
          "text": "naive idea : would photorec be of use vs qpdf? lol, it helped me when I had a cd with sun damage full of jpg files and it definitely works on pdfs..",
          "score": 8,
          "created_utc": "2026-02-05 01:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vwel4",
          "author": "Dracozirion",
          "text": "[https://github.com/KoKuToru/extract\\_attachment\\_EFTA00400459](https://github.com/KoKuToru/extract_attachment_EFTA00400459)",
          "score": 5,
          "created_utc": "2026-02-06 11:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3odjxi",
          "author": "Headz0r",
          "text": "The first question should be: What are we decoding?\nIf its a PDF with text this will mostly be Postscript commands.\n\nMost information would be between parenthesis: https://www.researchgate.net/publication/2416848/figure/fig1/AS:669440576348168@1536618479267/Conversion-from-PostScript-a-PostScript-file-the-text-extracted-from-it-and-a.png\n\nThis also gives you some hints of what are possible valid commands outside of parenthesis.",
          "score": 4,
          "created_utc": "2026-02-05 06:52:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qikg5",
              "author": "mqudsi",
              "text": "It is a PDF (that much is for sure). But, as with most PDF files, the actual PostScript is flate-compressed so the \"apparent\" contents of the PDF are binary, not text (except for some headers and stuff, such as the XML in the screenshot towards the end of the article).",
              "score": 5,
              "created_utc": "2026-02-05 16:02:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3osnti",
          "author": "perplexes_",
          "text": "If it‚Äôs just 1 vs l, you could brute force - try all possible combinations and see which ones come out as good PDFs",
          "score": 4,
          "created_utc": "2026-02-05 09:13:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40jiy2",
              "author": "Ok-Present1566",
              "text": "2^x grows very fast.  That is almost certainly totally practically infeasible if x is 24 or higher",
              "score": 2,
              "created_utc": "2026-02-07 02:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uwa93",
          "author": "euclidity",
          "text": "Was able to get very similar looking lossy character strings by:\n\n- Generating a known base64 dataset\n- Pasting it into a document with 0.5 margins, 0.5 line spacing, courier new in size 10, and printing it to pdf\n- pdftoppm test.pdf output -jpeg -jpegopt quality=100 -r 80\n- print to pdf again on the images\n- compare the final pdf to the reference epstein pdf\n- repeat with different jpeg options on pdftoppm until the glyphs look as close to the epstein reference as possible\n\nCould be used to train a custom OCR/tesseract on equivalent looking data but with known matching real text.",
          "score": 3,
          "created_utc": "2026-02-06 06:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3nbsfx",
          "author": "walkention",
          "text": "If you have a fairly decent GPU at home or feel like paying for cloud resources, what about an LLM OCR like this?\n https://huggingface.co/deepseek-ai/DeepSeek-OCR-2\n\nI was going to try and load this into my homelab LLM and see how it does.\n\nAlso, there are several companies doing AI OCR that could potentially https://www.docupipe.ai/ seems promising.",
          "score": 9,
          "created_utc": "2026-02-05 02:32:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nh1b1",
              "author": "duckne55",
              "text": "paddleOCR is also ML based and very easy to use as theres a python package [https://github.com/PaddlePaddle/PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)  \nBut the same issues with distinguishing lowercase \\`L\\` and \\`1\\` applies I think",
              "score": 7,
              "created_utc": "2026-02-05 03:01:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ns592",
                  "author": "walkention",
                  "text": "I saw PaddleOCR as well and will likely give it a try. I quickly tried running the image OP has at the top of the article (which is pretty low quality to be honest) through deepseek-ocr-2. It did pretty well, but I did notice it added unnecessary spaces and randomly changed character case in places, had some trouble with zero and capital O, and definitely can't handle lowercase L and 1 at that resolution. I'll have to try on the pages extracted from the original PDF.",
                  "score": 3,
                  "created_utc": "2026-02-05 04:10:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o413v0z",
          "author": "buttfuckingchrist",
          "text": "Not sure if it saw these or not but could be useful for understanding how the docs were instructed to be redacted using adobe: https://www.bloomberg.com/news/newsletters/2026-02-06/epstein-files-review-was-chaotic",
          "score": 2,
          "created_utc": "2026-02-07 04:47:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41xwvh",
          "author": "Kokuten",
          "text": "There are even more similar files. There are base64 encoded iphone pictures from 2018. Look at this thread: [https://www.reddit.com/r/Epstein/comments/1qu9az2/theres\\_unredacted\\_attachments\\_as\\_base64\\_in\\_some/](https://www.reddit.com/r/Epstein/comments/1qu9az2/theres_unredacted_attachments_as_base64_in_some/)  \nAre you able to decode them aswell? ",
          "score": 2,
          "created_utc": "2026-02-07 09:12:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49lgm8",
              "author": "mqudsi",
              "text": "That's an audio recording. *Theoretically* decodable, but MP4 containers are *incredibly* brittle (they're very shitty for long-term storage guarantees and resilience). You'd have to get all the bytes right.\n\nUnfortunately, this document is using a proportional (non-monospaced or \"regular\") font, which makes extraction harder. But it's still technically doable!",
              "score": 1,
              "created_utc": "2026-02-08 15:36:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o479mor",
          "author": "Less_Grapefruit_302",
          "text": "I created a custom OCR model specifically trained on the epstein files and was able to successfully decode EFTA00400459. Know of any more base64 blobs in the epstein files?\n\n[https://github.com/vExcess/epstein-ocr](https://github.com/vExcess/epstein-ocr)",
          "score": 2,
          "created_utc": "2026-02-08 04:37:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49l656",
              "author": "mqudsi",
              "text": "Nice work, I did the same with a CNN: https://github.com/mqudsi/monospace-ocr\n\nUnfortunately the training doesn't carry over to other base64 documents perfectly, even those using the same font family and size, in the same layout. Some of the other documents have \"smearing\" around the 1 vs l that makes it even harder üò≠",
              "score": 1,
              "created_utc": "2026-02-08 15:35:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4dqq9e",
                  "author": "Routine_Drummer1543",
                  "text": "Nice work, to both of you. This & the blog post throughly nerd-snipped me. Heh.\n\nI had made some headway cropping the images to only contain the b64 chars, then using tesseract and Apple's \"live text\", then comparing the two. I also cropped the b64 to single lines at a time, and used tesseract with `--psm 13, which did slightly better. I was then diffing the 3 outputs & selecting chars they disagreed on to manually correct. Unsurprisingly, it was a lot.\n\nI had also thought to train tesseract directly on Courier New, but hadn't gotten that far yet. Another thought was to train something like eigenfaces (eigenvalue decomposition) on the first couple of pages, cropped per character. I'm almost surprised tesseract doesn't have a way to specify both the allowed character set and a specific pattern of just those characters.",
                  "score": 1,
                  "created_utc": "2026-02-09 04:38:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o49lmtp",
              "author": "munogabba",
              "text": "look how causual this post is \n\namazing work",
              "score": 1,
              "created_utc": "2026-02-08 15:37:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o497gfi",
          "author": "tilrman",
          "text": "It's like Bletchley Park all over again.¬†",
          "score": 2,
          "created_utc": "2026-02-08 14:20:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wprwr",
          "author": "Yamisheiki",
          "text": "Does knowing Trump is the most hidden word help ? ",
          "score": 2,
          "created_utc": "2026-02-06 14:39:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qd0nj",
          "author": "pinxi",
          "text": "Here is a different way. Think of these like images going into a machine learning algorithm. So like matching different kinds of dogs, specific eye color, etc, the model treats the text like a image. Models are very good at this and continually get better with more data to train on. \n\nWe did this with regalory checks on legacy transactions that were basically massive strings with no headers or meta data.  It works very well.",
          "score": 1,
          "created_utc": "2026-02-05 15:37:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qhfr5",
              "author": "pinxi",
              "text": "Something like:\n\n1.\tImages ‚Üí Object store ‚Äì Raw images + unique ID  \n  ‚Ä¢\tMetadata ‚Üí Graph ‚Äì Image details.  \n  ‚Ä¢\tImages ‚Üí Patterns ‚Äì Image patterns.  \n2.\tPatterns ‚Üí Matches ‚Äì Similar images.  \n  ‚Ä¢\tDetails ‚Üí Documents ‚Äì Reference and analysis.  \n3.\tLinks ‚Üí Graph ‚Äì Context and relationships.  \n  ‚Ä¢\tHuman check ‚Äì Verify matches, reduce errors.  \n4.\tGraph ‚Üí LLM ‚Äì Uncover the bastards!",
              "score": 3,
              "created_utc": "2026-02-05 15:57:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qie5d",
                  "author": "pinxi",
                  "text": "With a graph db you could also add things like tweets and other feeds to provide more context of who is who and how they relate. Check out arangodb (doc, vector, and graph) or some of the cloud services.",
                  "score": 2,
                  "created_utc": "2026-02-05 16:01:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qo5a0",
                  "author": "zoopysreign",
                  "text": "I need you to teach me your ways please",
                  "score": 1,
                  "created_utc": "2026-02-05 16:28:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3vtb6e",
          "author": "ArgonWilde",
          "text": "I wonder if ell is a generally darker character than one? If you were to box in each character and average out the darkness of that box... Which is darker?\n\nOr, if you average the darkness of each row of pixels, ell would have more darkness at the top vs one which would be more consistent along the height of the serif.\n\nSo, we need a solution that exports out each character, in serial, as an X, Y box, which then averages out the darkness of the box, either in total, or graphed out along the Y axis, then classify which is which into a dataset, and then use that dataset for the remaining files. ü§î",
          "score": 1,
          "created_utc": "2026-02-06 11:17:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4336ov",
          "author": "Low_Lifeguard_7110",
          "text": "Can someone please make a archieve of the pics and share the link please or can u send any that u have done",
          "score": 1,
          "created_utc": "2026-02-07 14:36:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ogibe",
          "author": "404llm",
          "text": "You use a OCR api to process all files [https://jigsawstack.com/vocr](https://jigsawstack.com/vocr)",
          "score": 0,
          "created_utc": "2026-02-05 07:18:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qiqgo",
              "author": "mqudsi",
              "text": "As mentioned in the article, I used multiple OCR solutions, including open source OCR software, commercial OCR applications, and the hosted Amazon Textract OCR API. None did a good enough job.",
              "score": 4,
              "created_utc": "2026-02-05 16:03:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3un35k",
                  "author": "survivalist_guy",
                  "text": "Would OCR by committee be feasible? Most votes wins or something like that?  \nI'm giving Azure Document Intelligence a shot right now, but I don't have the highest hopes.",
                  "score": 1,
                  "created_utc": "2026-02-06 05:04:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxp66x",
      "title": "AI Agents‚Äô Most Downloaded Skill Is Discovered to Be an Infostealer",
      "subreddit": "netsec",
      "url": "https://www.infostealers.com/article/ai-agents-most-downloaded-skill-is-discovered-to-be-an-infostealer/",
      "author": "Malwarebeasts",
      "created_utc": "2026-02-06 18:10:48",
      "score": 107,
      "num_comments": 12,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxp66x/ai_agents_most_downloaded_skill_is_discovered_to/",
      "domain": "infostealers.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3ye81a",
          "author": "ruibranco",
          "text": "This is basically npm supply chain attacks all over again but worse because AI agents often run with elevated permissions and access to credentials by design. At least with npm packages there's some expectation that you audit what you install. These \"skill\" marketplaces are actively encouraging people to plug in third party code that gets executed with whatever access the agent has. We learned nothing from the dependency confusion era apparently.",
          "score": 53,
          "created_utc": "2026-02-06 19:29:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yvg89",
              "author": "whomthefuckisthat",
              "text": "That‚Äôs it. Back to downloading executable mp4s from limewire.",
              "score": 20,
              "created_utc": "2026-02-06 20:55:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4094x9",
                  "author": "TheG0AT0fAllTime",
                  "text": "Better days :(",
                  "score": 5,
                  "created_utc": "2026-02-07 01:26:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3z443k",
              "author": "RockinOneThreeTwo",
              "text": "> We learned nothing from the dependency confusion era apparently.¬†\n\n\nI imagine because the people who are doing this \"Agentic AI skills\" shit voluntarily and the people who were part of that era -- and understood what the problem was back then -- can be represented on a Venn diagram as two completely separate circles.",
              "score": 15,
              "created_utc": "2026-02-06 21:38:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3zy5bq",
              "author": "1esproc",
              "text": "> At least with npm packages there's some expectation that you audit what you install\n\nHahaha....ah. Good one.",
              "score": 7,
              "created_utc": "2026-02-07 00:21:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3zf66f",
              "author": "roastbits",
              "text": "Npm supply chain attacks still going strong",
              "score": 2,
              "created_utc": "2026-02-06 22:34:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xzr5e",
          "author": "Marshall_Lawson",
          "text": "site is not loading for me but archive loaded it\n\n\nhttps://archive.ph/Sa4bJ",
          "score": 5,
          "created_utc": "2026-02-06 18:20:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3z2zmo",
              "author": "thenickdude",
              "text": "It's just blogspam anyway, this is the original research:\n\nhttps://1password.com/blog/from-magic-to-malware-how-openclaws-agent-skills-become-an-attack-surface",
              "score": 30,
              "created_utc": "2026-02-06 21:32:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3z39qa",
                  "author": "Marshall_Lawson",
                  "text": "thanks",
                  "score": 5,
                  "created_utc": "2026-02-06 21:34:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o413uz8",
          "author": "AiChatPrime",
          "text": "Not surprising! \n\nAs soon as agents can browse, download, and execute tools, they become just another malware delivery layer.\n\nThe risk isn't \"AI going rogue\", it is automation making old attack faster and harder to attribute.",
          "score": 2,
          "created_utc": "2026-02-07 04:47:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40qtf7",
          "author": "tombob51",
          "text": "What an atrociously bad article. I really do not care about any completely unrelated attacks from years ago. This entire article is literally scarebait to sell that company's \"protection\" services.\n\nWhich is so stupid because this IS an actually interesting piece of news, and there are other sites covering it with 1000x better writing skills.",
          "score": 5,
          "created_utc": "2026-02-07 03:17:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxdzcu",
      "title": "The RCE that AMD won't fix!",
      "subreddit": "netsec",
      "url": "https://mrbruh.com/amd/",
      "author": "moviuro",
      "created_utc": "2026-02-06 10:22:22",
      "score": 97,
      "num_comments": 38,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxdzcu/the_rce_that_amd_wont_fix/",
      "domain": "mrbruh.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3vvm9n",
          "author": "NamedBird",
          "text": "Nothing wrong with HTTP downloads of large files, *as long as you check the hash afterwards!!!*\n\nThat this didn't happen is just plain negligence, if exploited, they'd be liable in my eyes.",
          "score": 38,
          "created_utc": "2026-02-06 11:36:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3waha2",
              "author": "FlamboyantKoala",
              "text": "If you mitm the download could you not also mitm the hash? ¬†I assume valid file hashes have to be stored somewhere",
              "score": 21,
              "created_utc": "2026-02-06 13:17:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3woqw9",
                  "author": "kopkaas2000",
                  "text": "In this specific case the metadata for the update was served over https, so a checksum could have worked.",
                  "score": 23,
                  "created_utc": "2026-02-06 14:34:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3wbpha",
                  "author": "Haniasita",
                  "text": "you're right, and the true solution is to implement TLS + certificates",
                  "score": 5,
                  "created_utc": "2026-02-06 13:24:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3x0jyl",
              "author": "ApertureNext",
              "text": "Not true and it's been proven by the apt package manager. They also believed HTTP was fine until they got a MITM redirect vulnerability against their connections. \n\nThere's no reason not to use HTTPS by default. I have nothing against HTTP as a fallback that can be enabled manually, but it should not be default.",
              "score": 9,
              "created_utc": "2026-02-06 15:33:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x2zqr",
                  "author": "NMCMXIII",
                  "text": "http is fine if you do everything right.¬†\n\n\nthe advantage of https is two fold:\n1 - most people dont mess with its defaults or implementation, so they dont f' it up too often, and the folks working on the servers/clients are scared of f' up because its a bit of their \"you have one job'\n\n\n2 - you still add signatures, etc in addition, so now you've two layers of verification instead of one",
                  "score": 5,
                  "created_utc": "2026-02-06 15:45:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3x26gy",
                  "author": "NamedBird",
                  "text": "Can i have a source for that?\n\nYou want to cache large files, especially in big computer fleets. And HTTP makes this easy.  \n(Of course, you *do* need to use a secure channel for version checking and metadata retrieval.)",
                  "score": 6,
                  "created_utc": "2026-02-06 15:41:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3winku",
              "author": "Jeoh",
              "text": "There's zero reason whatsoever to use HTTP. ",
              "score": -2,
              "created_utc": "2026-02-06 14:02:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ws1fp",
                  "author": "3MU6quo0pC7du5YPBGBI",
                  "text": "> There's zero reason whatsoever to use HTTP.\n\nIt allows transparent caching for large file distribution (e.g. see LANCache for Steam and other games). For something like AMD drivers that probably isn't a very big benefit though, and doing that without validating the downloaded binary is stupid.",
                  "score": 11,
                  "created_utc": "2026-02-06 14:51:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3vntnp",
          "author": "Jeoh",
          "text": "tl;dr AMD uses HTTP to download updates, doesn't perform any kind of validation they're downloading what they hope they're downloading. Why is it an issue? See [Notepad++ MitM attack](https://notepad-plus-plus.org/news/hijacked-incident-info-update/).",
          "score": 65,
          "created_utc": "2026-02-06 10:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wiruk",
              "author": "Arszilla",
              "text": "Notepad++‚Äôs is not ‚Äúas MitM‚Äù as AMD‚Äôs. In case of Notepad++:\n1. The connection is HTTPS\n2. The Chinese TA has compromised the server the downloads were available on\n3. The Chinese TA selectively redirected connections to the malicious version\n\nIt‚Äôs not a fair comparison.",
              "score": 37,
              "created_utc": "2026-02-06 14:03:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3w3ihd",
              "author": "JAD2017",
              "text": "I was going to say that I thankfully never update anything using the programs, but I do. Antivirus, for instance, firmware update for SSD. I just realised we put a lot of trust in our daily use programs because they are from reputable companies. This is just so messed up lol",
              "score": 4,
              "created_utc": "2026-02-06 12:34:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3w8n95",
          "author": "woolharbor",
          "text": "This after the Notepad++ attack, ugh.\n\nI'm so mad at updaters not checking signatures.\n\nAll software downloads should have signatures, even manual ones.",
          "score": 8,
          "created_utc": "2026-02-06 13:06:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vpr0u",
          "author": "ruibranco",
          "text": "Using plain HTTP for software updates in 2026 is genuinely indefensible, especially for a driver updater that runs with elevated privileges. The attack surface here is massive since anyone on the same network can MitM the update check and serve a malicious payload. This is the exact same class of vulnerability that hit Notepad++ and eScan antivirus before, and the fix is always the same: TLS plus code signing verification. The fact that AMD apparently considers this not worth fixing is wild given that their updater runs as SYSTEM on Windows. Any corporate network with ARP spoofing capability or a compromised gateway becomes an instant RCE vector against every machine running AMD's software.",
          "score": 36,
          "created_utc": "2026-02-06 10:47:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3w0eox",
              "author": "angellus",
              "text": "Many Linux distros still use http for downloads. It is literally what package signing is used for. Packages are signed with a key that the package manger knows about and it verifies ever package to make sure it is not tampered with.",
              "score": 20,
              "created_utc": "2026-02-06 12:12:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3w89eb",
                  "author": "JAD2017",
                  "text": "The issue here is that AMD isn't using any kind of verification mechanism, not the protocol itself.\n\nThen again, why use unencripted protocols when you can be safe instead? I don't get it.",
                  "score": 10,
                  "created_utc": "2026-02-06 13:04:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3x2am0",
                  "author": "ApertureNext",
                  "text": "I don't see how that's excusable? So you're exposing what packages you're installing to your ISP. \n\nAlso apt has had an MITM vulnerability which wouldn't have happened if they just used HTTPS back then.",
                  "score": 4,
                  "created_utc": "2026-02-06 15:42:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vqogs",
              "author": "moviuro",
              "text": "Windows' (and macOS for that matter too) lack of decent package management is a blight on modern infrastructure.\n\nAnd if/when they ever deliver anything remotely decent, app providers will need to deliver, which is another insurmontable hurdle.\n\nNothing to do, except block HTTP at the networking level?..",
              "score": 3,
              "created_utc": "2026-02-06 10:55:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wk7nl",
          "author": "dookie1481",
          "text": "This is why bug bounty scopes should not be unnecessarily restrictive. This is a legitimate problem closed by a triager who is just going off of a checklist. Hopefully someone in AMD security will reassess when they see this.",
          "score": 6,
          "created_utc": "2026-02-06 14:10:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yrm2j",
              "author": "AxonsAndDendrites",
              "text": "It's unfortunate that some companies consider \"not worth paying a bounty for\" equivalent to \"not worth fixing\".",
              "score": 1,
              "created_utc": "2026-02-06 20:35:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3z77jh",
                  "author": "bobalob_wtf",
                  "text": "Closed out of scope does not necessarily mean \"won't fix\"",
                  "score": 2,
                  "created_utc": "2026-02-06 21:53:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3w4klr",
          "author": "ukindom",
          "text": "I don't like how graphic drivers (both NVidia and AMD) handle updates themselves, so I get a notification, download full package and install offline.\n\nIn the light of this article, I see how my method is more secure, but it's more tedious",
          "score": 3,
          "created_utc": "2026-02-06 12:41:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3w8ug7",
              "author": "JAD2017",
              "text": "I've always updated GPU drivers manually, never from the program. Same goes for chipset updates or bios updates. But there are things in our computers that we actually trust the programs, such as the antivirus, games, professional suites for content creation or other kind of corporate programs.\n\nWe put a lot of faith in companies just because they are reputable, only to find out they don't really care about our security like AMD just did with this.",
              "score": 1,
              "created_utc": "2026-02-06 13:08:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xf1or",
          "author": "BurnoutEyes",
          "text": "And there's already a semi-ancient framework to exploit this style of bugs, [ISR EvilGrade](https://github.com/infobyte/evilgrade)",
          "score": 1,
          "created_utc": "2026-02-06 16:41:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d54el",
          "author": "enceladus7",
          "text": "Disclosure got some traction? Post now says:\n\n> Temporarily taken down due to a request, will be back at a later date :)",
          "score": 1,
          "created_utc": "2026-02-09 02:31:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qu3bgd",
      "title": "WhatsApp Encryption, a Lawsuit, and a Lot of Noise",
      "subreddit": "netsec",
      "url": "https://blog.cryptographyengineering.com/2026/02/02/whatsapp-encryption-a-lawsuit-and-a-lot-of-noise/",
      "author": "feross",
      "created_utc": "2026-02-02 18:32:07",
      "score": 94,
      "num_comments": 13,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qu3bgd/whatsapp_encryption_a_lawsuit_and_a_lot_of_noise/",
      "domain": "blog.cryptographyengineering.com",
      "is_self": false,
      "comments": [
        {
          "id": "o397aeu",
          "author": "russellvt",
          "text": "Having had a high-tech friend and prior colleague in the top levels of WhatsApp tell me that their code was fully e2e encrypted and they were unable to break it or MitM the messages, I believe(d) him.\n\nThat was prior to Meta taking it over, however.",
          "score": 28,
          "created_utc": "2026-02-03 00:23:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hmcxb",
              "author": "VarCoolName",
              "text": "So, that was like 12 years ago?\n\nYeah, I believe it was back then, sure. But man, it's been 12 years; lots of things change in 12 days, let alone 12 years.",
              "score": 8,
              "created_utc": "2026-02-04 06:50:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fxqri",
          "author": "tombob51",
          "text": "TL;DR some idiots filed a lawsuit claiming Meta has access to all WhatsApp messages. Meta maintains that all messages have been end-to-end encrypted, for the past nearly 10 years. The plaintiffs literally do not have a shred of evidence other than unnamed \"whistleblowers\".\n\nWhile people are rightly distrustful of Meta in general, in this case, there is *zero* concrete evidence they are actually able to read private WhatsApp messages.",
          "score": 6,
          "created_utc": "2026-02-04 00:25:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gcukl",
              "author": "jakiki624",
              "text": "the filers are the NSO Group's lawyers btw",
              "score": 3,
              "created_utc": "2026-02-04 01:49:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3gob8i",
                  "author": "tombob51",
                  "text": "Then maybe they should have asked their buddies at NSO group to give it a once over before filing headline-grabbing bull crap like this",
                  "score": 3,
                  "created_utc": "2026-02-04 02:54:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o382v5z",
          "author": "cbowns",
          "text": "I‚Äôm a simple person: I see Matthew Green, I upvote. This should be fun",
          "score": 8,
          "created_utc": "2026-02-02 20:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ocn96",
          "author": "AiChatPrime",
          "text": "Guys, the real story here isn't just encryption or backdoor, it's how users and systems place trust in software they can't fully verify. End to End encryption works only if the implementation, backups, and devices are all trustworthy. The real gaps in security come from unchallenged trust assumptions, not just weak crypto.",
          "score": 3,
          "created_utc": "2026-02-05 06:44:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o397iq9",
          "author": "EmperorOfCanada",
          "text": "A friend of mine says \"Anyone who says they have end to end encryption should pronounce it End to End to End\" as there is most certainly a third party able to listen in with 100% of US popular encryption.\n\nThe other reality of encryption is that it is very hard. It is the whole red team, blue team problem. People trying to hack these apps can fail and fail and fail by the millions. It only takes one brainiac with an inspiration to crack any flaws.\n\nSuch a brainiac can then potentially make untold fortunes far in excess of any rewards offered to the programmers building the encryption.",
          "score": -18,
          "created_utc": "2026-02-03 00:25:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o39x09g",
              "author": "LimBomber",
              "text": "Your friend clearly doesn't understand cryptography then. Because only the 2 clients have access to the keys to decrypt messages and no third party would be able to read the contents lol.",
              "score": 18,
              "created_utc": "2026-02-03 02:49:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3abr0o",
                  "author": "WorBlux",
                  "text": "Metadata is still often left in the open or is otherwise accessible. \n\nThe most recent example was abusing read recipts to monitor when a user was online, and whether they were actively using the app.",
                  "score": -8,
                  "created_utc": "2026-02-03 04:19:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3c1fid",
              "author": "upofadown",
              "text": "WhatsApp has their \"security code\" number to help a user detect \"End to End to End\" (AKA man in the middle) situations. It would change if Meta performed such an attack. I just went and looked and it turns out that the detection of such changes is an option that you have to turn on. It seems to be off by default:\n\n* https://faq.whatsapp.com/1524220618005378/\n\nSo your friend might have a point for the WhatsApp case. I don't know if it would be possible for Meta to set up a man in the middle attack as simply as described in the lawsuit, but due to a dumb option default it seems fairly sure that they could get away with it if they could.\n\nAdded: As pointed out at the end of the article (well implied at least) if Meta was doing this in a way that would allow  them to get everyone's past messages then that would mean that they would have to be doing \"End to End to End\" all the time for everyone. They would quickly get caught. Such an attack would have to be targeted and would only get messages after the time of the attack.",
              "score": 3,
              "created_utc": "2026-02-03 12:57:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qyl3yf",
      "title": "New OSS secret scanner: Kingfisher (Rust) validates exposed creds + maps permissions",
      "subreddit": "netsec",
      "url": "https://www.mongodb.com/company/blog/product-release-announcements/introducing-kingfisher-real-time-secret-detection-validation",
      "author": "micksmix",
      "created_utc": "2026-02-07 18:18:41",
      "score": 38,
      "num_comments": 13,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qyl3yf/new_oss_secret_scanner_kingfisher_rust_validates/",
      "domain": "mongodb.com",
      "is_self": false,
      "comments": [
        {
          "id": "o44ljgw",
          "author": "ruibranco",
          "text": "The blast radius mapping is what sets this apart for me. Most scanners just find the secret and call it a day, but knowing what a leaked key can actually access changes how you prioritize remediation completely. Smart call using tree-sitter for context too, regex-only approaches are false positive machines.\n\n  \nHow's CI integration look? Any plans for a pre-commit hook mode?",
          "score": 5,
          "created_utc": "2026-02-07 19:08:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45ntmi",
              "author": "micksmix",
              "text": "It supports pre-commit hooks natively, via the precommit framework, or via husky:  \n[https://github.com/mongodb/kingfisher/blob/main/docs/INSTALLATION.md#pre-commit-hooks](https://github.com/mongodb/kingfisher/blob/main/docs/INSTALLATION.md#pre-commit-hooks)\n\n",
              "score": 2,
              "created_utc": "2026-02-07 22:33:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o47n0at",
          "author": "cryotic",
          "text": "Name collision, that‚Äôs confusing",
          "score": 2,
          "created_utc": "2026-02-08 06:25:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dwixd",
              "author": "micksmix",
              "text": "As we all know, the two hardest problems in computer science are cache invalidation, naming things, and off-by-one errors. üòÑ\n\nTotally fair callout... Kingfisher definitely collides with a bunch of unrelated stuff (the bird, the beer, the airline, the Swift library, etc.). I'm hoping when used in a security context, it will be clear ü§û",
              "score": 1,
              "created_utc": "2026-02-09 05:20:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4e0ve6",
                  "author": "cryotic",
                  "text": "Strong collision in the security context to consider: [https://github.com/rsmusllp/king-phisher](https://github.com/rsmusllp/king-phisher)  \n",
                  "score": 1,
                  "created_utc": "2026-02-09 05:54:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o47xtvu",
          "author": "AiChatPrime",
          "text": "The validation + access mapping is powerful, but I think the real value is exposing how bad most orgs' IAM actually is.\n\nIn a lot of environments, \"blasts radius\" just means \"everything\" because service accounts are over privileged and reused across pipelines. Tools like this end up acting more as an audit mirror than just a scanner.\n\nAlso worth noting that real-time validation itself needs tight controls, if the scanner is hitting provider APIs at scale, that's another system that now needs secrets, rate limits, logging, and abuse monitoring.",
          "score": 1,
          "created_utc": "2026-02-08 08:04:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4alo2s",
              "author": "micksmix",
              "text": "Agreed on both points. In a lot of orgs the \"blast radius\" being \"everything\" is just the uncomfortable truth about over-privileged, reused service accounts, and access mapping makes that visible fast.\n\nAlso agreed that validation needs controls, which is why it is optional and can be disabled with `--no-validate`.   \n  \nEach finding report also provides a one-off validate command (`kingfisher validate --rule github \"ghp_...\"`) so you can re-check just that credential on demand, which makes it easy to script validation in a surgical, least-noisy way.\n\nWhen you do enable it, Kingfisher already de-duplicates findings (by default) so it issues far fewer network requests than most scanners, largely because Kingfisher focuses on detection accuracy and, by design, avoids re-validating the same thing over and over.\n\n[https://github.com/mongodb/kingfisher/blob/main/docs/COMPARISON.md#network-requests-comparison](https://github.com/mongodb/kingfisher/blob/main/docs/COMPARISON.md#network-requests-comparison)",
              "score": 2,
              "created_utc": "2026-02-08 18:31:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eh27x",
          "author": "gunni",
          "text": "I wish all these credentials would have an api call to revoke themselves just like you can use a certificates private key to revoke the certificate, that way these scanners could just send the revoke command for the keys.\n\nMaybe put a delay on the revocation so that the owner could react to the event but don't let them ever get away with ignoring it.",
          "score": 1,
          "created_utc": "2026-02-09 08:21:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o466ooj",
          "author": "37b",
          "text": "We are looking at switching to this from Nosey Parker. How are false positives managed?",
          "score": 1,
          "created_utc": "2026-02-08 00:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47w314",
              "author": "micksmix",
              "text": "Kingfisher reduces false positives a couple of ways:\n\n* **Service/API validation**: Kingfisher‚Äôs rules include HTTP/service‚Äëspecific validation checks (AWS, Azure, GCP, etc.) so it can confirm whether a detected string is actually a live credential, which helps filter noise beyond regex‚Äëonly matches.\n* **Confidence thresholds**: You can set `--confidence` to high/medium/low to exclude lower‚Äëconfidence hits (often the noisiest). Be default Kingfisher runs with \\`--confidence medium\\` which excludes low confidence rules.\n* **Skip known false positives**: Use `--skip-regex` and/or `--skip-word` to suppress known benign patterns, including inline ignores in code; both match against the secret value and surrounding context so you can be precise.\n* **Inline ignore directives**: Add `kingfisher:ignore` anywhere on the same line as a finding to silence it. (see https://github.com/mongodb/kingfisher/blob/main/docs/ADVANCED.md#inline-ignore-directives)\n* **Baseline management**: Create a baseline of existing findings so future scans only report *new* issues; great for large repos with legacy noise. (see https://github.com/mongodb/kingfisher/blob/main/docs/BASELINE.md)",
              "score": 1,
              "created_utc": "2026-02-08 07:48:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44v985",
          "author": "timmy166",
          "text": "Nice! All you lurkers pay attention, the tool reads to be the real deal and can be the defacto OSS secrets scanner:\n\n- Active Validation (like trufflehog) \n- Tree-sitter with hyperspace: Rust/C++ is faster than Golang‚Äôs regex engine\n- Apache 2 beats GPL3",
          "score": -3,
          "created_utc": "2026-02-07 19:58:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qz67d1",
      "title": "macOS Touch ID/Bio-metric kill switch like iPhone has - PanicLock",
      "subreddit": "netsec",
      "url": "https://paniclock.github.io/",
      "author": "seanieb",
      "created_utc": "2026-02-08 11:04:25",
      "score": 34,
      "num_comments": 8,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qz67d1/macos_touch_idbiometric_kill_switch_like_iphone/",
      "domain": "paniclock.github.io",
      "is_self": false,
      "comments": [
        {
          "id": "o48h685",
          "author": "seanieb",
          "text": "In the US police can force you to unlock your Apple laptop by putting your finger on Touch-ID. \n\nOn iOS you can squeeze the side buttons and Face ID's gone. Two seconds, works in your pocket. macOS has nothing like it.\n\nPanicLock sits in your menu bar. One click (or keyboard shortcut)locks the screen but asks for a password. When you log back in Touch ID will still be active. Free, opensource, notarized and no data collection.\n\nThere's good reasons to keep Touch ID on day-to-day. It stops people watching you type your password, cameras catching it, that sort of thing. This is just for when you need to turn it off quickly and easily. ",
          "score": 16,
          "created_utc": "2026-02-08 11:07:19",
          "is_submitter": true,
          "replies": [
            {
              "id": "o48se06",
              "author": "csonka",
              "text": "Would be good to link to an article to explain how to do the thing in iOS.",
              "score": 0,
              "created_utc": "2026-02-08 12:43:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48re4b",
          "author": "cloudzhq",
          "text": "Nice initiative. Going to add it to a certain list of bookmarks.",
          "score": 2,
          "created_utc": "2026-02-08 12:35:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48rnrt",
              "author": "seanieb",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-08 12:37:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48rxtd",
          "author": "csonka",
          "text": "This looks like something Patrick Wardle would make.\nVery nice.\n\nWas the website made using AI? It has that feel.",
          "score": 1,
          "created_utc": "2026-02-08 12:39:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48u74x",
              "author": "seanieb",
              "text": "Thank you. That's a very nice complement. I'm a big Patrick Wardle fan. I saw him at DefCon this year, and it was the talk that convinced me I could actually start making Mac Apps. I use their BlockBlock, Whats Your Sign and Lulu apps. It would be great if Patrick/Objective-See cloned my app and maintained as their own. I'd love that.   \n  \nAnd yes, nice catch, the webpage was made using AI, Claude Code Opus 4.5 and I made edits using Githubs Co-Pilot  Agent (it generates screenshots of the changes in the PR).  I dunno if I could spot an AI generated site without looking at the git commit history/comments. The first version of the webpage was made by hand, and it looked like trash. You can see it in the git repo.",
              "score": 3,
              "created_utc": "2026-02-08 12:56:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49y6mo",
                  "author": "the91fwy",
                  "text": "I think if you replaced the emoji with font awesome you would lose most of that ‚ÄúAI vibe‚Äù",
                  "score": 1,
                  "created_utc": "2026-02-08 16:39:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o49u7aq",
          "author": "ruibranco",
          "text": "Same threat model applies at border crossings ‚Äî CBP can compel biometrics without a warrant but not a memorized password. This plus FileVault is a solid baseline for anyone traveling with sensitive client data.",
          "score": 1,
          "created_utc": "2026-02-08 16:20:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qumhwe",
      "title": "Exploiting CVE-2025-49825 (authentication bypass vulnerability in Teleport)",
      "subreddit": "netsec",
      "url": "https://blog.offensive.af/posts/exploiting-cve-2025-49825/",
      "author": "gid0rah",
      "created_utc": "2026-02-03 08:24:22",
      "score": 32,
      "num_comments": 3,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qumhwe/exploiting_cve202549825_authentication_bypass/",
      "domain": "blog.offensive.af",
      "is_self": false,
      "comments": [
        {
          "id": "o3o9xi7",
          "author": "AiChatPrime",
          "text": "This isn't really a crypto issue, it's a logic issue. One \"this should never happen\" path and the whole Auth model collapses. That's becoming the pattern with a lot of modern Auth bypasses.",
          "score": 1,
          "created_utc": "2026-02-05 06:20:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxawcm",
      "title": "Hacking a cheap Wi-Fi toy drone",
      "subreddit": "netsec",
      "url": "https://journal.farhaan.me/hacking-chinese-toy-dronea17",
      "author": "fhackdroid",
      "created_utc": "2026-02-06 07:10:15",
      "score": 24,
      "num_comments": 3,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxawcm/hacking_a_cheap_wifi_toy_drone/",
      "domain": "journal.farhaan.me",
      "is_self": false,
      "comments": [
        {
          "id": "o3we8j4",
          "author": "ruibranco",
          "text": "Raw UDP with zero auth or encryption is wild but honestly expected for this price point. The scary part is that anyone on the same Wi-Fi range could just send control packets and hijack the thing mid-flight. Good writeup though, these cheap IoT teardowns are always a goldmine for understanding how little thought goes into security at the consumer hardware level.",
          "score": 3,
          "created_utc": "2026-02-06 13:38:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x9h5q",
              "author": "sdrawkcabineter",
              "text": ">Raw UDP with zero auth or encryption is wild\n\n\"No no, you're being ignorant. It's a really long OTP used as a continuous port knock...\"",
              "score": 2,
              "created_utc": "2026-02-06 16:16:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47z7e4",
          "author": "AiChatPrime",
          "text": "That shows up all over cheap IoT. No auth, no update story.\n\nIt's fine when it's a toy on a bench. It's a problem once it's sitting on a real network for 2 years and nobody remembers it exists.",
          "score": 1,
          "created_utc": "2026-02-08 08:17:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qw2mw8",
      "title": "2026: New N8N RCE Deep Dive into CVE-2026-25049",
      "subreddit": "netsec",
      "url": "https://blog.securelayer7.net/cve-2026-25049/",
      "author": "appsec1337",
      "created_utc": "2026-02-04 22:07:46",
      "score": 22,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qw2mw8/2026_new_n8n_rce_deep_dive_into_cve202625049/",
      "domain": "blog.securelayer7.net",
      "is_self": false,
      "comments": [
        {
          "id": "o3m2lzx",
          "author": "ruibranco",
          "text": "The public webhook attack surface is the part that should concern anyone self-hosting n8n. A lot of people expose n8n directly or behind a simple reverse proxy without any additional auth layer on the webhook paths, assuming the workflow-level authentication is sufficient. Getting RCE through JavaScript destructuring abuse in the expression evaluator is a nasty primitive because n8n's whole value proposition is running arbitrary integrations ‚Äî meaning the blast radius post-exploitation is enormous (API keys, database credentials, cloud tokens for every connected service).\n\n  \nThis is also a good reminder that sandboxing JavaScript execution in Node.js is fundamentally hard. n8n uses vm2 (or did, before it was abandoned) and later moved to isolated-vm, but expression evaluation paths sometimes bypass the sandbox entirely. The Code node vs expression evaluation have different trust boundaries that aren't always obvious.\n\n  \nFor anyone running n8n in production: put it behind a VPN or zero-trust proxy (Cloudflare Access, Tailscale, etc.), never expose webhook endpoints to the raw internet without rate limiting and input validation at the edge, and treat the n8n process as fully privileged in your threat model.",
          "score": 8,
          "created_utc": "2026-02-04 22:22:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o416kvp",
          "author": "AiChatPrime",
          "text": "Low-code tools like n8n are turning into real infrastructure, but most orgs still treat them like toys. RCE here is a big deal especially since these systems usually have broad internal access.",
          "score": 1,
          "created_utc": "2026-02-07 05:07:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwtzyn",
      "title": "Django SQL Injection in RasterField lookup (CVE-2026-1207)",
      "subreddit": "netsec",
      "url": "https://vulnerabletarget.com/VT-2026-1207",
      "author": "c0daman",
      "created_utc": "2026-02-05 18:54:56",
      "score": 22,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qwtzyn/django_sql_injection_in_rasterfield_lookup/",
      "domain": "vulnerabletarget.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3sfmmd",
          "author": "ruibranco",
          "text": "Worth noting that RasterField is part of django.contrib.gis, so this only affects projects using GeoDjango with PostGIS raster support. The attack surface is narrower than a typical Django SQLi since you'd need to pass user-controlled input into raster-specific lookups. That said, if you're running a mapping or GIS application that takes user input for spatial queries, this is a critical one to patch. Always good to see Django's security team catching these in the ORM's less-traveled corners.",
          "score": 5,
          "created_utc": "2026-02-05 21:25:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyfxlw",
      "title": "trappsec: open source framework for API deception",
      "subreddit": "netsec",
      "url": "https://trappsec.dev",
      "author": "nikhil-salgaonkar",
      "created_utc": "2026-02-07 14:59:42",
      "score": 21,
      "num_comments": 6,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qyfxlw/trappsec_open_source_framework_for_api_deception/",
      "domain": "trappsec.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o43eiq2",
          "author": "webrnaster",
          "text": "Clever idea, it made me smile.\n\nI've considered putting \"is_admin\" in a server header and if someone actually took the time to flip it from false to true, they'd get redirected to a fake login page . Time is the one of the best defenses. \n\nReminds me of nmap scans that just respond with yes for every port. \n\nWhat is the action someone would take on an IP address that was probing these endpoints? Would a security spend be better focused on securing the real endpoints that exist versus creating a maze? Then again getting any insight into a potential attacker is useful. \n\nSeems like false positives and alert overload could be an issue due to scanners and bots.",
          "score": 3,
          "created_utc": "2026-02-07 15:36:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43gr21",
              "author": "nikhil-salgaonkar",
              "text": "Thanks!\n\nSo, alerts are only raised if the attacker uses an authenticated session (valid credentials or API keys)\n\nThe framework has something called auth-aware responses. Just like real APIs would respond with some needs authn/authzn error, so would the decoy routes defined here leading the attacker to believe that it's just another API endpoint that needs authentication. The key is in making the deception boring.\n\nunauthenticated hits are logged as signals leaving their usage to the discretion of the monitoring team. Personally, my thought process was more around catching people poking for business logic flaws and not scanners.",
              "score": 3,
              "created_utc": "2026-02-07 15:47:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4418pf",
              "author": "peiggs",
              "text": "I think from an AppSec perspective, this isn‚Äôt the greatest idea. Sure, you have a high fidelity alert. But, the fake login page is only going to keep the bad actor interested longer. They will probably try elsewhere on your site instead of moving onto the next one.",
              "score": 1,
              "created_utc": "2026-02-07 17:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o443hjl",
                  "author": "nikhil-salgaonkar",
                  "text": "I wouldn't recommend fake login pages as a decoy to anyone. The framework offers better avenues for deception. That aside, my perspective is that if someone is actively mapping your API surface, they're going to try adjacent routes regardless. The framework helps you instrument your application to detect reconnaissance that's happening and make it visible.",
                  "score": 2,
                  "created_utc": "2026-02-07 17:39:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qvvin8",
      "title": "Kernel-Level Stealthy Observation of TTY Streams",
      "subreddit": "netsec",
      "url": "https://blog.cybervelia.com/p/kernel-level-stealthy-observation-of-tty-streams",
      "author": "thnew_mammoth",
      "created_utc": "2026-02-04 17:52:13",
      "score": 20,
      "num_comments": 2,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qvvin8/kernellevel_stealthy_observation_of_tty_streams/",
      "domain": "blog.cybervelia.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3n5fm7",
          "author": "ruibranco",
          "text": "Neat starting point. The kprobes approach being visible in /sys/kernel/debug/kprobes/list is the obvious weakness though ‚Äî trivially detectable with a periodic check. The eBPF evolution of this is where it gets more interesting for red teams: bpf\\_probe\\_read\\_user attached to tty\\_write achieves the same interception without a loadable module, and detection shifts to bpftool prog list which far fewer defenders are monitoring.",
          "score": 4,
          "created_utc": "2026-02-05 01:56:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sjgbz",
          "author": "AYamHah",
          "text": "Great work on this research and write up. Interested in what blue teamers think of this.",
          "score": 1,
          "created_utc": "2026-02-05 21:43:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy0mjx",
      "title": "crypto-scanner: Open-source CLI tool to find quantum-vulnerable cryptography in your codebase",
      "subreddit": "netsec",
      "url": "https://pypi.org/project/crypto-scanner/",
      "author": "MindlessConclusion42",
      "created_utc": "2026-02-07 01:41:45",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qy0mjx/cryptoscanner_opensource_cli_tool_to_find/",
      "domain": "pypi.org",
      "is_self": false,
      "comments": [
        {
          "id": "o42jvhk",
          "author": "ukindom",
          "text": "\nI like to ask what is the _severity_ of this problem? Many algorithms included modifications to mitigate post-quantum calculations, and upgrade burden to at least support (I don't mention to migrate users) is enormous.\n\nAdditionally, I'd like new algorithms to be added to platforms such as GitHub to auth.\n\nAnd what's about GPG? I believe it also susceptive as well.",
          "score": 2,
          "created_utc": "2026-02-07 12:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o490yzk",
              "author": "MindlessConclusion42",
              "text": "Great questions, let me take them one at a time.\n\nSeverity ‚Äî right now the 4-tier system is based on NIST's post-quantum vulnerability classifications. You're right that the migration burden is a huge factor that isn't captured in a simple \"critical/high/medium/low\" label. I'm considering adding a `migration_complexity` field to the JSON output so teams can prioritize by effort, not just risk.\n\nNew algorithms on platforms like GitHub auth ‚Äî agreed, detection for newer PQC-compatible algorithms is on the roadmap. Right now it catches what's vulnerable, but flagging what's *already migrated* would be just as useful.\n\nGPG ‚Äî yes, most GPG keys in the wild are RSA or classical ECC, both quantum-vulnerable. Adding GPG keyring scanning is a solid idea. I'll open an issue for it.\n\nThanks ‚Äî this is exactly the kind of feedback that makes the tool better.",
              "score": 1,
              "created_utc": "2026-02-08 13:41:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49ic43",
                  "author": "ukindom",
                  "text": "Additional questions are about non-technical cost and general availability. \n\nLet‚Äôs say I hijacked a database with such keys and want to crack them open\n\n1. What is the cost to have such computer without pinging back to a mother company? \n2. How to buy such computer to weaponise it without much attention? \n3. What are electricity and infrastructure (including occupied space and weight) costs to hide myself in a landscape and move myself from time to time?\n4. What is the time (average) to find pairs to reveal primes?\n‚Ä¶",
                  "score": 1,
                  "created_utc": "2026-02-08 15:20:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o42ixat",
          "author": "ukindom",
          "text": "Please modify exclusions to make them global and per-language. E.g. `target` should be excluded from Rust project, but shouldn't from Java or Python project.",
          "score": 1,
          "created_utc": "2026-02-07 12:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o490oxy",
              "author": "MindlessConclusion42",
              "text": "Good catch ‚Äî you're right that `target/` is noise in Rust but could be meaningful elsewhere. Exclusions are global right now which is lazy on my part.\n\nI'm adding per-language exclusion profiles with sensible defaults. \n\nAppreciate the feedback.\n\nTracking it here: [https://github.com/mbennett-labs/crypto-scanner/issues/1](https://github.com/mbennett-labs/crypto-scanner/issues/1)",
              "score": 1,
              "created_utc": "2026-02-08 13:39:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qza4lh",
      "title": "Defense Evasion: The Service Run Failed Successfully",
      "subreddit": "netsec",
      "url": "https://www.zerosalarium.com/2026/02/Defense-Evasion-The-service-run-failed-successfully.html",
      "author": "Cold-Dinosaur",
      "created_utc": "2026-02-08 14:21:01",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qza4lh/defense_evasion_the_service_run_failed/",
      "domain": "zerosalarium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4e0y27",
          "author": "AiChatPrime",
          "text": "\"Service Failure\" abuse is one of those things that sits in plain sites for years and still gets missed in most hardening guides. Everyone watching \"ImagePath\" and \"Registry\", almost nobody reviews failure action.\n\nGreat reminder that \"crash\" is often the hardest part of these chains, not execution itself.",
          "score": 1,
          "created_utc": "2026-02-09 05:55:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qux2hg",
      "title": "Auditing Outline. Firsthand lessons from comparing manual testing and AI security platforms",
      "subreddit": "netsec",
      "url": "https://blog.doyensec.com/2026/02/03/outline-audit-q32025.html",
      "author": "nibblesec",
      "created_utc": "2026-02-03 16:46:45",
      "score": 12,
      "num_comments": 6,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qux2hg/auditing_outline_firsthand_lessons_from_comparing/",
      "domain": "blog.doyensec.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3iu9v8",
          "author": "roadtoCISO",
          "text": "This is exactly the comparison the industry needs more of.\n\nThe AI security tool market is full of claims about coverage and speed but almost nobody publishes methodology comparisons like this. Most security teams are flying blind on what AI tools actually catch versus what they miss.\n\nWhat I keep seeing in practice: AI tools are fantastic at high volume, pattern-based findings. The stuff that scales. But the creative exploitation chains that combine three low-severity issues into one critical path? That's still where manual testing wins.\n\nThe interesting question is whether AI augmented manual testing beats either approach alone. Using AI to handle the coverage grind while humans focus on the weird edge cases and business logic. That's where I'd bet the future lands.",
          "score": 3,
          "created_utc": "2026-02-04 13:02:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g1tid",
          "author": "GreatWight",
          "text": "Thanks for the writeup! I've been looking into an OSS wiki solution and Outline wasn't on my list. Will be checking it out in the future.\n\nRegarding your closing statement, cleaning up and validating LLM findings took an estimated 40 hours. I agree that this is untenable during paid audits. How is your team positioning to be able to more effectively parse AI output while we wait for advancements in the field?",
          "score": 0,
          "created_utc": "2026-02-04 00:47:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hz4j9",
              "author": "nibblesec",
              "text": "Great questions, with a work-in-progress answer.   \n  \nAI is already very useful for many tasks, including understanding the business logic / reverse engineering and looking for specific functionalities within a large codebase. For vulnerability discovery, I believe we need to wait for this technology to evolve and introduce real \"validation\". Several of these platforms do provide exploit code but when it doesn't work, it's not clear whether it's a false positive or an issue with the exploit given the missing context (e.g. app requires identifiers, which are not available from the app src code).",
              "score": 2,
              "created_utc": "2026-02-04 08:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ol3kf",
                  "author": "Erik_BKQNMNBXSI",
                  "text": "Very cool research Doyseccrew!!\n\nI'd love to see details on the three AI platforms you used.\n\nLocal models, cloud FMs, or GenAI pentesting platforms?\n\nWere they given any \"additional\" info or training, or just pointed at the testing domain and given the src?",
                  "score": 1,
                  "created_utc": "2026-02-05 08:01:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qweadr",
      "title": "CVE-2025-11730: Remote Code Execution via DDNS configuration in ZYXEL ATP/USG Series (V5.41)",
      "subreddit": "netsec",
      "url": "https://rainpwn.blog/blog/cve-2025-11730/",
      "author": "Advanced_Rough8330",
      "created_utc": "2026-02-05 06:53:41",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qweadr/cve202511730_remote_code_execution_via_ddns/",
      "domain": "rainpwn.blog",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1quu7dk",
      "title": "How LLMs Feed Your RE Habit: Following the Use-After-Free Trail in CLFS",
      "subreddit": "netsec",
      "url": "https://clearbluejar.github.io/posts/how-llms-feed-your-re-habit-following-the-uaf-trail-in-clfs/",
      "author": "onlinereadme",
      "created_utc": "2026-02-03 15:01:21",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.68,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1quu7dk/how_llms_feed_your_re_habit_following_the/",
      "domain": "clearbluejar.github.io",
      "is_self": false,
      "comments": [
        {
          "id": "o3flx6n",
          "author": "thetinguy",
          "text": "Too bad the author couldn't be bothered to write the article himself. Guess the LLM feeds his article writing habit too.",
          "score": 15,
          "created_utc": "2026-02-03 23:20:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxdxjy",
      "title": "Experiment demonstrates Al-generated identities bypassing KYC-based verification systems",
      "subreddit": "netsec",
      "url": "https://mpost.io/humanity-protocol-experiment-reveals-how-ai-can-bypass-kyc-and-exploit-digital-trust/",
      "author": "Gullible_Bet_7899",
      "created_utc": "2026-02-06 10:19:25",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qxdxjy/experiment_demonstrates_algenerated_identities/",
      "domain": "mpost.io",
      "is_self": false,
      "comments": [
        {
          "id": "o3vyb49",
          "author": "AiChatPrime",
          "text": "The problem isn't that AI can fake identities, it's that most KY is still designed as a one-time check. Trust is treated as a static state, when it should be something continuously evaluated over time. AI just makes that gap obvious.",
          "score": 7,
          "created_utc": "2026-02-06 11:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z7nnc",
          "author": "ruibranco",
          "text": "KYC was already fragile before generative AI entered the picture. Sophisticated fraudsters have been beating document checks and liveness detection for years, AI just made it cheap and scalable enough that anyone can do it now. The fundamental issue is that the entire verification model is built on \"present a document and show your face,\" which becomes meaningless when both can be synthesized on demand. Until identity verification moves beyond static document checks to something cryptographically anchored, this is just going to keep getting worse.",
          "score": 4,
          "created_utc": "2026-02-06 21:55:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46dfze",
          "author": "Wonder_Weenis",
          "text": "Every tech CEO on the planet claiming most human jobs are going to be replaced by ai\n\nand you're telling me the ai can't identify stop signs?\n\nPick one.¬†",
          "score": 1,
          "created_utc": "2026-02-08 01:07:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtvonw",
      "title": "GatewayToHeaven: Finding a Cross-Tenant Vulnerability in Google Cloud's Apigee",
      "subreddit": "netsec",
      "url": "https://omeramiad.com/posts/gatewaytoheaven-gcp-cross-tenant-vulnerability/",
      "author": "omerhacking",
      "created_utc": "2026-02-02 13:55:38",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qtvonw/gatewaytoheaven_finding_a_crosstenant/",
      "domain": "omeramiad.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qzwqa7",
      "title": "klint - Linux Kernel Security Scanner",
      "subreddit": "netsec",
      "url": "http://saturnine.cc/klint",
      "author": "Short_Radio_1450",
      "created_utc": "2026-02-09 06:20:43",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1qzwqa7/klint_linux_kernel_security_scanner/",
      "domain": "saturnine.cc",
      "is_self": false,
      "comments": [
        {
          "id": "o4efdf4",
          "author": "AiChatPrime",
          "text": "Linux kernel scanners like this really show how much hidden attack surface exists in drivers and modules. \n\nMissing these issues isn't just a bug, it can compromise the whole system. In fact, tools that map and validate kernel threats are going to be critical as systems get more complex in 2026",
          "score": 0,
          "created_utc": "2026-02-09 08:04:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4elfsj",
              "author": "ptweezy",
              "text": "AI slop",
              "score": 1,
              "created_utc": "2026-02-09 09:04:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}