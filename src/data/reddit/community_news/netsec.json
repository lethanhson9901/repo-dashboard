{
  "metadata": {
    "last_updated": "2026-02-18 17:29:58",
    "time_filter": "week",
    "subreddit": "netsec",
    "total_items": 20,
    "total_comments": 38,
    "file_size_bytes": 56322
  },
  "items": [
    {
      "id": "1r4kmv7",
      "title": "Hacking a pharmacy to get free prescription drugs and more",
      "subreddit": "netsec",
      "url": "https://eaton-works.com/2026/02/13/dava-india-hack/",
      "author": "EatonZ",
      "created_utc": "2026-02-14 13:28:43",
      "score": 125,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r4kmv7/hacking_a_pharmacy_to_get_free_prescription_drugs/",
      "domain": "eaton-works.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5chw9k",
          "author": "webrnaster",
          "text": "How did you get the role id (674b187663b07...) when creating an admin?",
          "score": 17,
          "created_utc": "2026-02-14 14:50:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ci7pq",
              "author": "EatonZ",
              "text": "When you retrieved the list of existing users, it included their role ID.",
              "score": 20,
              "created_utc": "2026-02-14 14:52:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5cjvva",
                  "author": "webrnaster",
                  "text": "I see. All the \\_id parameter values are blurred. I assumed it was one of those. Thanks for confirming.",
                  "score": 6,
                  "created_utc": "2026-02-14 15:01:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5crycl",
          "author": "mpg111",
          "text": "how do you know that this is true?\n\nQ: Was my data leaked?\n\nA: No, the security vulnerabilities were fixed before this could happen.",
          "score": 11,
          "created_utc": "2026-02-14 15:44:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cuw59",
              "author": "EatonZ",
              "text": "In this case no other \"malicious\" admin accounts were found that would have allowed access.",
              "score": 11,
              "created_utc": "2026-02-14 15:59:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5eqxe9",
                  "author": "Rene_Z",
                  "text": "Someone could have done this and deleted their admin account after. And with such an obvious security vulnerability (unauthenticated endpoint to query and create admin users!?), no doubt that site has more. I would not trust that my data is safe with them.",
                  "score": 10,
                  "created_utc": "2026-02-14 21:51:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5cz63x",
                  "author": "mpg111",
                  "text": "thx",
                  "score": 1,
                  "created_utc": "2026-02-14 16:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r7j1zm",
      "title": "Leaking secrets from the claud: AI coding tools are leaking secrets via configuration directories",
      "subreddit": "netsec",
      "url": "https://ironpeak.be/blog/leaking-secrets-from-the-claud/",
      "author": "nindustries",
      "created_utc": "2026-02-17 21:16:50",
      "score": 116,
      "num_comments": 14,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r7j1zm/leaking_secrets_from_the_claud_ai_coding_tools/",
      "domain": "ironpeak.be",
      "is_self": false,
      "comments": [
        {
          "id": "o5ysl81",
          "author": "ruibranco",
          "text": "This is a real blind spot in most dev workflows right now. Tools like Cursor, Copilot, and Claude Code all create local config files (.cursor/, .github/copilot, [CLAUDE.md](http://CLAUDE.md), etc.) that can contain project context, API keys referenced in prompts, or even full conversation logs. Most .gitignore templates haven't caught up to include these directories yet, so they end up committed and pushed without anyone noticing.The fix is straightforward but tedious: audit your .gitignore for every AI tool your team uses, run git log searches for accidentally committed config dirs, and treat these directories the same way you'd treat .env files. Some teams are also adding pre-commit hooks that specifically scan for AI tool artifacts.",
          "score": 36,
          "created_utc": "2026-02-18 00:39:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zpzw6",
              "author": "xortingen",
              "text": "People do blind â€œgit add .â€ then blame others/tools.",
              "score": 23,
              "created_utc": "2026-02-18 03:42:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60j0g6",
              "author": "Danielo944",
              "text": "People don't do git status before doing a git add . ?",
              "score": 5,
              "created_utc": "2026-02-18 07:19:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62jgi1",
              "author": "ClassicPart",
              "text": ">Â The fix is straightforward but tedious\n\nOh, I know this one: itâ€™s people actually fucking checking what they commit to repositories instead of blindly adding shit.\n\n>Â audit your .gitignore for every AI tool your team uses\n\nAh, I guess personal responsibility is off the table then.",
              "score": 3,
              "created_utc": "2026-02-18 15:43:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5zq2o1",
              "author": "ko_oktide",
              "text": "I definitely understand the concern here. However, I havenâ€™t run into this at all. Every time I hard code even an ARN or something in some code Claude yells at me to throw it in an env file. Much less API keys. Alsoâ€¦ this was an issue before AI, but I do agree people will get more complacent with review etc. when they donâ€™t even have to write the code to begin with.",
              "score": 1,
              "created_utc": "2026-02-18 03:42:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60h59f",
                  "author": "nindustries",
                  "text": "It's not about hardcoding secrets in your code, it's e.g. Claude proposing to run your app with secrets on the CLI, which you whitelist. This whitelist then ends up in .claude/ and could leak those secrets to public repos.",
                  "score": 7,
                  "created_utc": "2026-02-18 07:03:05",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o62tk8f",
                  "author": "Patriark",
                  "text": "The git-commit-push slash command used by Claude team also have some helpful tools to prevent publishing secrets.",
                  "score": 1,
                  "created_utc": "2026-02-18 16:29:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60gdc1",
          "author": "platformuser",
          "text": "The real issue isnâ€™t just accidental commits. AI tools are creating new classes of sensitive artifacts (prompt logs, project summaries, context caches) that donâ€™t fit traditional secret-scanning models. \n\nMost orgs updated their .gitignore for .env years ago. Very few have updated their threat models for AI-generated config/state directories.",
          "score": 6,
          "created_utc": "2026-02-18 06:56:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o626w7s",
              "author": "TikiTDO",
              "text": "Since when are logs and intermediate generated files a new class of sensitive artifact? If you're a dev committing sensitive things, that's on you. This whole thing of, \"Oh, my AI did it\" is an absurd cop-out.\n\nThe AI wouldn't have done a thing without your involvement, so no, **you** did it. Your AI was just the vehicle through which you did. If you left secrets in your repo, that's just you being bad at security. \n\nAlso, most secret scanners are doing heuristic based matching. Does this look like a name? Does this look like SSN number? Does this look like a token? The entire point of those is to find secrets in arbitrary places. AI generated files also qualify. These people just aren't running secret scanners, and likely don't even know what those are.\n\nI essentially see this whole thing as another copy of the late 90s and early 2000s. A lot of people are suddenly getting into the field because it's become way easier than it used to be, and are suddenly finding out that real software is fuckin hard, even if an AI handles all the nasty coding for you.",
              "score": 3,
              "created_utc": "2026-02-18 14:43:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o629ada",
                  "author": "platformuser",
                  "text": "Iâ€™m not saying â€œAI did itâ€ and responsibility disappears. Devs are still accountable for what they commit.\n\nMy point is just that the shape of sensitive artifacts has changed. Secret scanners are good at catching structured secrets like keys and tokens. What theyâ€™re not always great at is large prompt transcripts, architecture summaries, or context caches that mix proprietary logic and pasted data in natural language.\n\nThose arenâ€™t secrets in the regex sense, but they can still expose internal systems or client information.\n\nSo yes, itâ€™s on the developer. I just think the threat model needs to expand as the tooling changes.",
                  "score": 2,
                  "created_utc": "2026-02-18 14:55:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6199fo",
          "author": "thedudeonblockchain",
          "text": "the whitelisted commands angle is the sneakiest part. if you allow claude to run something like STRIPE\\_KEY=sk\\_live\\_xxx in a bash command, that allowlist can live in .claude/settings.local.json in plaintext. trufflehog and gitleaks both need explicit rules for these dirs since most default configs skip dot-paths",
          "score": 3,
          "created_utc": "2026-02-18 11:18:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r66u2r",
      "title": "[Analysis] Massive Active GitHub Malware Campaign | Hundreds of Malicious Repositories Identified",
      "subreddit": "netsec",
      "url": "https://brennan.day/the-curious-case-of-the-triton-malware-fork/",
      "author": "WanderBetter",
      "created_utc": "2026-02-16 11:08:41",
      "score": 89,
      "num_comments": 9,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r66u2r/analysis_massive_active_github_malware_campaign/",
      "domain": "brennan.day",
      "is_self": false,
      "comments": [
        {
          "id": "o5o2f05",
          "author": "formatme",
          "text": "I have reported this a while back to the github subreddit, hoping a dev at github would take action\n\n[https://www.reddit.com/r/github/comments/1qbndfx/massive\\_ai\\_malware\\_campaign\\_happening\\_on\\_github/](https://www.reddit.com/r/github/comments/1qbndfx/massive_ai_malware_campaign_happening_on_github/)",
          "score": 19,
          "created_utc": "2026-02-16 11:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oc5wh",
          "author": "thedudeonblockchain",
          "text": "the automated deployment pattern is concerning because traditional rate limiting won't stop this since each repo looks independent. the emoji headers and manipulated commit history are clever social engineering since they make forks look more legitimate and established to casual users. from a detection standpoint, the low virustotal coverage means security teams relying on hash based detection are going to miss this entirely until it's already widespread. the real fix needs to be at the github platform level, maybe reputation scoring for forks plus automated analysis of sudden readme changes that introduce direct download links, but that's a hard moderation problem at github's scale.",
          "score": 11,
          "created_utc": "2026-02-16 12:59:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pmnkc",
          "author": "kingqk",
          "text": "Picked three random repos from your list, gave a 404, so chances are that all those repos are wiped.",
          "score": 9,
          "created_utc": "2026-02-16 16:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qruv5",
              "author": "WanderBetter",
              "text": "You're right. I just did another cursory search (https://github.com/search?q=malware&type=repositories&s=updated&o=desc&p=1) and found dozens more that I added.",
              "score": 2,
              "created_utc": "2026-02-16 20:11:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ogqix",
          "author": "Comfortable-Survey83",
          "text": "Could you please share which vendors had a detection at the time of first scan?",
          "score": 2,
          "created_utc": "2026-02-16 13:28:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ukja6",
          "author": "d3vk47",
          "text": "Looks like DGA with dicts to auto generate the accounts and projects. This looks like they are planned as short lived and campaign specific. I wonder how long is the TTL of the account before take down.",
          "score": 1,
          "created_utc": "2026-02-17 11:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rv3d5",
          "author": "V2UgYXJlIG5vdCBJ",
          "text": "I wonder if the security issues have anything to do with Microsoft taking over. I used to think GitHub was solid.",
          "score": 1,
          "created_utc": "2026-02-16 23:29:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6r7no",
      "title": "Almost Impossible: Java Deserialization Through Broken Crypto in OpenText Directory Services",
      "subreddit": "netsec",
      "url": "https://slcyber.io/research-center/almost-impossible-java-deserialization-through-broken-crypto-in-opentext-directory-services/",
      "author": "Mempodipper",
      "created_utc": "2026-02-17 00:34:23",
      "score": 65,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6r7no/almost_impossible_java_deserialization_through/",
      "domain": "slcyber.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5sqytq",
          "author": "SuperDrewb",
          "text": "Extremely impressiveÂ ",
          "score": 7,
          "created_utc": "2026-02-17 02:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u4dog",
          "author": "Few-Gap-5421",
          "text": "Nice research man",
          "score": 4,
          "created_utc": "2026-02-17 09:00:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2puq1",
      "title": "TURN Security Threats: A Hacker's View",
      "subreddit": "netsec",
      "url": "https://www.enablesecurity.com/blog/turn-server-security-threats/",
      "author": "EnableSecurity",
      "created_utc": "2026-02-12 10:20:38",
      "score": 39,
      "num_comments": 2,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r2puq1/turn_security_threats_a_hackers_view/",
      "domain": "enablesecurity.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4yihh3",
          "author": "EnableSecurity",
          "text": "Been poking at TURN server security since 2017 and finally wrote this up.\n\nIf you're not familiar with TURN: it's the fallback relay for WebRTC when direct peer-to-peer fails. It can relay both TCP and UDP to arbitrary peer addresses, so if not properly restricted, you've got an open proxy that can reach internal networks, localhost, cloud metadata services, etc.\n\nSome highlights:\n\n- During pentests we regularly find TURN servers that can reach internal networks, localhost, cloud metadata (169.254.169.254). If peer addresses aren't restricted, it's game over.\n- At DEF CON 2025, Adam Crosser demoed C2 operations running through Zoom and Teams TURN servers. Security monitoring sees legitimate video call traffic.\n- coturn (most common TURN implementation) has had 30+ memory safety fixes, a CVSS 9.8 SQL injection, and we found an IPv6 loopback bypass where the protection code just didn't work (CVE-2020-26262).\n- TURN servers are also abused for DDoS reflection/amplification. Only ~4x factor but they're everywhere and often misconfigured.\n\nPost goes into the technical details of each relay method (Send Indication, ChannelData, TCP Connect), real attack scenarios, and what defense actually looks like.\n\nHappy to answer questions.",
          "score": 19,
          "created_utc": "2026-02-12 10:21:50",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5jhcng",
          "author": "jews4beer",
          "text": "The protocol itself is ripe for abuse. At its core Its just an address sharing system that can be abused from all angles. But that's kind of the point behind it.",
          "score": 1,
          "created_utc": "2026-02-15 17:38:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r35ydb",
      "title": "Critical RCE Vulnerability in Unstructured.io (CVE-2025â€“64712) - CVSS 9.8",
      "subreddit": "netsec",
      "url": "https://www.cyera.com/research-labs/inside-destructured---critical-vulnerability-in-unstructured-io-cve-2025-64712",
      "author": "Shimiasm",
      "created_utc": "2026-02-12 21:24:37",
      "score": 39,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r35ydb/critical_rce_vulnerability_in_unstructuredio/",
      "domain": "cyera.com",
      "is_self": false,
      "comments": [
        {
          "id": "o55y5d4",
          "author": "thedudeonblockchain",
          "text": "nasty one since [unstructured.io](http://unstructured.io) processes untrusted documents by default - most deployments probably vulnerable out of the box without explicit input sanitization.",
          "score": 2,
          "created_utc": "2026-02-13 14:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56sz21",
          "author": "ruibranco",
          "text": "scary one for rag pipelines - unstructured is basically the default document ingestion layer and its entire purpose is processing untrusted content.",
          "score": 1,
          "created_utc": "2026-02-13 16:32:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52u28t",
          "author": "sunrise_zc",
          "text": "Once found a tarball uncompressed,they fixed it maybe",
          "score": 0,
          "created_utc": "2026-02-13 00:17:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5482er",
              "author": "tcpjack",
              "text": "My whole system is a tarball uncompressed!",
              "score": 1,
              "created_utc": "2026-02-13 05:40:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r74ifj",
      "title": "Log Poisoning in OpenClaw",
      "subreddit": "netsec",
      "url": "https://research.eye.security/log-poisoning-in-openclaw/",
      "author": "vaizor",
      "created_utc": "2026-02-17 12:19:40",
      "score": 36,
      "num_comments": 16,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r74ifj/log_poisoning_in_openclaw/",
      "domain": "research.eye.security",
      "is_self": false,
      "comments": [
        {
          "id": "o5wns2l",
          "author": "si9int",
          "text": "Another viby nail into the coffin of OpenClaw. I don't get the hype; srsly .. The idea might be interesting, but the implementation is a disaster.",
          "score": 27,
          "created_utc": "2026-02-17 18:19:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xdnrf",
              "author": "deneuralizer",
              "text": "There are quite a few forks coming out made in Rust, Go, which are supposed to be more secure. I am going to give ZeroClaw a shot",
              "score": -16,
              "created_utc": "2026-02-17 20:20:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xthow",
                  "author": "ziirex",
                  "text": "Rust and Go would mainly help if the issues were memory safety related, but the whole concept is quite risky by design. Fixes would need a major rearchitecture at which point it's a stretch to call them forks in my opinion.",
                  "score": 17,
                  "created_utc": "2026-02-17 21:35:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60gmvi",
          "author": "platformuser",
          "text": "This is a broader class of issue than just OpenClaw.\n\nAny agent that ingests its own logs, tool output, or environment artifacts is effectively expanding its prompt surface to include untrusted data.\n\nTraditional logging assumes â€œhumans read logs.â€ Agentic systems blur that boundary. Once logs become model input, theyâ€™re no longer passive telemetry  theyâ€™re an attack vector.\n\nTreat anything an agent can read as part of the prompt boundary.",
          "score": 6,
          "created_utc": "2026-02-18 06:58:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vyluv",
          "author": "thedudeonblockchain",
          "text": "the read/write access argument cuts both ways - yes it's a personal project, but once users deploy it in any networked or automated context (which full rw implicitly encourages), the log poisoning surface becomes a real downstream risk. logs that feed into SIEMs, dashboards, or monitoring pipelines are classic lateral movement paths once you control the content. the takeaway is probably less about enterprise hardening and more about surfacing default-safe configs even in experimental tools - write access in particular should require explicit opt-in.",
          "score": 13,
          "created_utc": "2026-02-17 16:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wflt9",
              "author": "[deleted]",
              "text": "[removed]",
              "score": -2,
              "created_utc": "2026-02-17 17:42:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5wi9xx",
                  "author": "rejuicekeve",
                  "text": "You'll say that without actually reporting the post for us to review like a big jabroni",
                  "score": 15,
                  "created_utc": "2026-02-17 17:54:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5wfrm8",
                  "author": "thedudeonblockchain",
                  "text": "What are you talking about man",
                  "score": 1,
                  "created_utc": "2026-02-17 17:42:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xljl3",
          "author": "InterSlayer",
          "text": "Theres a fridman interview with steinberger where he talks about having to rename repos, then the old names got sniped and started spreading malware. Then feeling distraught and wanting to just drop the whole project. ðŸ˜±",
          "score": 0,
          "created_utc": "2026-02-17 20:58:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v9jmv",
          "author": "hankyone",
          "text": "The cybersecurity industry treating a one man open source experiment created 80 days ago for shits and giggles like it should have enterprise grade security",
          "score": -26,
          "created_utc": "2026-02-17 14:10:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vpi9o",
              "author": "sarcasmguy1",
              "text": "When the tool has full read/write access, and encourages you to configure it as such, then yes it should have a level of security thats close to enterprise",
              "score": 29,
              "created_utc": "2026-02-17 15:32:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w10c3",
                  "author": "Hizonner",
                  "text": "Difficulty: there is no way to make that tool even vaguely close safe for anything, period, and leaking random stuff into logs is not in the top 1000 exposures.",
                  "score": 15,
                  "created_utc": "2026-02-17 16:29:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5zwje4",
              "author": "imsoindustrial",
              "text": "Idk why youâ€™re getting downvoted and I am a cynical fuck with decades of cybersecurity experience.",
              "score": 2,
              "created_utc": "2026-02-18 04:24:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o604jze",
                  "author": "hankyone",
                  "text": "The AI relationship perhaps?\n\nI thought Reddit was weird with AI but seems itâ€™s also the whole infosec industry",
                  "score": 1,
                  "created_utc": "2026-02-18 05:20:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r745t9",
      "title": "Prompt Injection Standardization: Text Techniques vs Intent",
      "subreddit": "netsec",
      "url": "https://www.lasso.security/blog/prompt-injection-taxonomy-techniques",
      "author": "Equivalent_Cover4542",
      "created_utc": "2026-02-17 12:02:09",
      "score": 32,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r745t9/prompt_injection_standardization_text_techniques/",
      "domain": "lasso.security",
      "is_self": false,
      "comments": [
        {
          "id": "o5w2sg4",
          "author": "thedudeonblockchain",
          "text": "the technique vs intent split hits on a core problem in prompt injection defense: the same text sequence can be benign or malicious depending on context, which makes purely syntactic detection brittle. what makes this particularly hard is multi-step indirect injections where neither the technique nor the intent is legible from a single interaction - the payload arrives in one turn, gets stored (retrieval, memory, tool output), and executes in a later turn in a completely different context. at that point you need to track provenance of content through the entire execution graph to reason about intent, which most current defenses don't do. the taxonomy is still useful for threat modeling and red-teaming even if it doesn't directly map to detection primitives - knowing whether you're dealing with a role-play jailbreak vs translation obfuscation vs indirect injection tells you which system components to harden first.",
          "score": 3,
          "created_utc": "2026-02-17 16:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61nan3",
              "author": "redyellowblue5031",
              "text": "Where have we seen that beforeâ€¦.",
              "score": 1,
              "created_utc": "2026-02-18 12:57:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uvncu",
          "author": "anyore909",
          "text": "The technique vs intent distinction makes sense. translation-based attacks and role-play jailbreaks may aim for the same outcome, but they work very differently. Structuring it this way makes the problem easier to reason about.",
          "score": 2,
          "created_utc": "2026-02-17 12:50:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wlc4p",
          "author": "ozgurozkan",
          "text": "The provenance tracking point is critical and often overlooked. Most organizations are focused on input sanitization, but the real danger is in persistence mechanisms where injected content gets written to context stores, vector databases, or agent memory.\n\n\n\nFrom a practical red team perspective, the highest success rate attacks I've seen combine two or three techniques in sequence. Start with translation obfuscation to bypass basic filters, use role play to establish a trusted context, then inject the actual payload through indirect means so it appears to come from a legitimate data source rather than user input.\n\n\n\nThe hardest part about defending against this is that effective mitigation requires architectural changes, not just better prompts. You need content signing, strict output encoding based on destination context, and proper separation between instruction channels and data channels. But most production systems treat everything as a string and hope prompt engineering will save them.\n\n\n\nThe taxonomy helps because it forces you to think about attack chains rather than individual techniques. Defense in depth means breaking the chain at multiple points, which means you need to map your architecture to the attack surface this framework describes.",
          "score": 2,
          "created_utc": "2026-02-17 18:08:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4u08r",
      "title": "Cloudflare Pages â€œContinue Readâ€ Redirect Kit Abused for Phishing, Adware, and Malware Delivery",
      "subreddit": "netsec",
      "url": "https://malwr-analysis.com/2026/02/15/cloudflare-pages-continue-read-redirect-kit-abused-for-phishing-adware-and-malware-delivery/",
      "author": "anuraggawande",
      "created_utc": "2026-02-14 19:47:30",
      "score": 31,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r4u08r/cloudflare_pages_continue_read_redirect_kit/",
      "domain": "malwr-analysis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5eti5a",
          "author": "Secure_Cyber",
          "text": "I see tons of these every week in my role. All sorts of versions with two to three redirects. Most of them check to see if you're looking at them in sandbox tools and they won't arrive at the final locations if you are. I get more data from running them from local. A lot of them are PaaS based phishing kits that are bought off the dark web or backchannel communication platforms. Also, most of the time they use existing public infrastructure to execute in one of the stages post-click; second or third redirect is what I've been finding for that one. That's probably to avoid detection on the surface.",
          "score": 6,
          "created_utc": "2026-02-14 22:06:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5evhvt",
              "author": "anuraggawande",
              "text": "Absolutely agree.\nSeeing multiple redirects and PaaS hosted phishing kits has become pretty normal now, especially with attackers trying to dodge sandbox.\nRunning them locally really does give a clearer picture of whatâ€™s actually happening behind the scenes.",
              "score": 2,
              "created_utc": "2026-02-14 22:17:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hu9zt",
          "author": "TerrorBite",
          "text": "The irony of getting a pop-up in the middle of this article with a â€œContinue Readingâ€ link.",
          "score": 5,
          "created_utc": "2026-02-15 12:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k5gte",
              "author": "DrorDv",
              "text": "Lol",
              "score": 1,
              "created_utc": "2026-02-15 19:36:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6k4z9",
      "title": "nono - kernel-enforced capability sandbox for AI agents",
      "subreddit": "netsec",
      "url": "https://nono.sh",
      "author": "DecodeBytes",
      "created_utc": "2026-02-16 19:59:20",
      "score": 27,
      "num_comments": 8,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6k4z9/nono_kernelenforced_capability_sandbox_for_ai/",
      "domain": "nono.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o5qqi2n",
          "author": "Otherwise_Wave9374",
          "text": "This is super timely. The whole \"agent has my full shell\" thing is the part that makes me nervous about coding agents in real workflows, prompt injection or not. Kernel-level deny-by-default (Landlock/Seatbelt) seems like the right layer to enforce it. Curious if youve tested weird edge cases like build tools that spawn helpers, symlink-heavy repos, or language servers that want to read dotfiles.\n\nAlso if you end up writing up the threat model tradeoffs, Id read it, Ive been collecting agent security notes and patterns here: https://www.agentixlabs.com/blog/",
          "score": 5,
          "created_utc": "2026-02-16 20:04:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qunn6",
              "author": "DecodeBytes",
              "text": "\\> Curious if youve tested weird edge cases like build tools that spawn helpers, symlink-heavy repos, or language servers that want to read dotfiles.\n\nAhh yeah, symlinks are the biggest ache\n\nWhen granted access to a path that's actually a symlink, we always resolve it to the real location immediately. We do this atomically rather than checking existence separately, which would create a window where an attacker could swap the symlink between our check and resolution.\n\nOn macOS, the sandbox enforces against literal path strings rather than resolved paths. So we store both the original path and the resolved real path, then emit sandbox rules for both. Without this, granting access via the real path would still block programs trying to use the symlink.\n\nWe also use proper path component comparison rather than string comparison when checking path relationships.  String prefix matching would incorrectly match paths that just happen to share the same starting characters but aren't actually descendants of the directory in question.\n\nWe also handle parent directory traversal. To access a deeply nested path, programs need to stat each parent directory along the way. We automatically allow metadata-only access to parent directories of granted paths, walking both the original and resolved path hierarchies when they differ.\n\nTaking a look at the blog thanks!   ",
              "score": 2,
              "created_utc": "2026-02-16 20:24:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5rngbq",
          "author": "bagbogbo",
          "text": "Been looking for something like this!",
          "score": 1,
          "created_utc": "2026-02-16 22:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5rtyug",
              "author": "DecodeBytes",
              "text": "cool! let me know if you need any more info or help. ",
              "score": 2,
              "created_utc": "2026-02-16 23:23:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uuiqu",
          "author": "One_Strike_1322",
          "text": "how does this compare to, say using the cursor docker container? To me, a container is easier and more portal to set up but I'd be keen to hear where this is better (obviously containers aren't a sandbox mechanism but they do help).",
          "score": 1,
          "created_utc": "2026-02-17 12:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v67rm",
              "author": "DecodeBytes",
              "text": "Containers and nono solve overlapping but distinct problems, and each has real trade-offs worth considering. There is a section in the docs on this: https://docs.nono.sh/security/containers \n\nContainers give you isolation through namespacing - the process sees a different filesystem root, network stack, and process tree. This is powerful for reproducibility and portability. You can ship a known-good environment, and anything the AI does stays inside that container's view of the world. The downside is that containers are coarse-grained. You either mount a volume into the container or you don't. There's no easy way to say \"read the whole project but only write to the src directory\" or \"access ~/.vscode , but not ~/.ssh/.\" You end up either over-permissioning (mounting your whole home directory) or dealing with friction every time the AI needs something outside the container.\n\nnono takes the opposite approach - it runs natively on your host but uses OS-level mandatory access control (Landlock on Linux, Seatbelt on macOS) to enforce fine-grained capabilities. You can grant read access to your entire codebase while restricting writes to specific directories, block access to credentials and browser data regardless of what commands run, and allow network access while still protecting sensitive local paths. The sandbox is applied to the process itself, not to a virtualized environment, so there's no filesystem copying, no Docker daemon, and near-zero startup overhead. \n\nWhere nono is stronger: granularity. You can express policies like \"read everywhere, write only here, never touch my SSH keys\" that would be awkward or impossible with container volume mounts. It also integrates more naturally with local tooling - your shell, your editor, your existing workflows all just work. \n\nWhere containers are stronger: they provide a complete environment boundary. If the AI installs a malicious package or corrupts system files, it's contained to that throwaway environment. With nono, you're still running on your real system - the sandbox prevents unauthorized access, but if you grant write access to a directory, the AI can still make a mess there (having said that we have an atomic undo system incoming).\n\nThe honest answer is they're complimentary. You can run nono inside a container for defense in depth, or use nono alone when you want lightweight, precise control without the overhead of containerization. It depends on which you value portability and environment isolation (containers) or fine-grained capability control with minimal friction (nono). \n\nThe other factor is nono has a load of other features thrown in, key protection, blocking of dangerous commands, and quite a bit more inbound. \n\nBut honestly, if containers are working, great! I am a fan and its never x vs y here, each have their own strengths.",
              "score": 2,
              "created_utc": "2026-02-17 13:52:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v4ewn",
          "author": "sexy_lady_at_aol_com",
          "text": "Do you know how we might prevent a rogue agent from leaking secrets that have been made available to it? \n\nFor example, say claude has been granted the ability to web search, encounters a prompt injection on the web, and then proceeds to POST any credentials we've shared with the bot (in a .env, or similar), to some strange site, or to Github (like the shai-hulud worm).\n\nCould we host an HTTP proxy and allow only certain domains or paths? Can an agent be instructed to persevere and workaround our limitations? \n\nCould we host a HTTP proxy that injects credentials into outgoing HTTP traffic?\n\nCould we upgrade our third party systems to issue the agent some delegated short lived keys and accept the risk?\n\nNone of these sound like great approaches to me, but I'm keen to hear if you or others have any thoughts.",
          "score": 1,
          "created_utc": "2026-02-17 13:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v70r2",
              "author": "DecodeBytes",
              "text": "Proxy is the way to go. Have a key that only the proxy knows of and it map to the real key in a data store on the proxy. \n\nYou would then have the agent populate the Auth Header with the proxy key, and the proxy swap out the proxy specific key for the real external services key. \n\nSomeone did share this with me, it uses nono - but I have not played around with it. I expect we may well do something native to nono as well - I can share a proof-of-concept with you if useful and you can kick the tyres and see if its something usable?\n\nhttps://github.com/dedene/claw-wrap",
              "score": 1,
              "created_utc": "2026-02-17 13:56:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r640ry",
      "title": "sandboxec: A lightweight command sandbox for Linux, secure-by-default, built on Landlock.",
      "subreddit": "netsec",
      "url": "https://gh.dw1.io/sandboxec",
      "author": "dwisiswant0",
      "created_utc": "2026-02-16 08:17:28",
      "score": 17,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r640ry/sandboxec_a_lightweight_command_sandbox_for_linux/",
      "domain": "gh.dw1.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5zt457",
          "author": "atxweirdo",
          "text": "I think these kind of projects are needed in the OS space however locking it down to the point where it can't access any files or communicate with other processes kinda takes the functionality out of the agent flow on desktops. \nHowever I'm sure there is a happy medium to be found",
          "score": 1,
          "created_utc": "2026-02-18 04:01:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60i1yc",
              "author": "dwisiswant0",
              "text": "agree. the whole move of this is explicit access.\n\n\\> I'm sure there is a happy medium to be found\n\nyes, there actually seems to be a path for this already (I probably forgot to mention it in the README), my best tip is to run it with \\`strace\\` to identify the minimal allowlist and then make it persistent in the config, something like this: https://github.com/dwisiswant0/sandboxec/blob/master/profiles/claude.yaml.",
              "score": 1,
              "created_utc": "2026-02-18 07:11:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5fa5e",
      "title": "Product engineering teams must own supply chain risk",
      "subreddit": "netsec",
      "url": "https://www.hyperact.co.uk/blog/product-engineering-teams-must-own-supply-chain-risk",
      "author": "ArtisticProgrammer11",
      "created_utc": "2026-02-15 13:58:37",
      "score": 15,
      "num_comments": 0,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r5fa5e/product_engineering_teams_must_own_supply_chain/",
      "domain": "hyperact.co.uk",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r3kavf",
      "title": "Pwning Supercomputers - A 20yo vulnerability in Munge",
      "subreddit": "netsec",
      "url": "https://blog.lexfo.fr/munge-heap-buffer-overflow.html",
      "author": "qwerty0x41",
      "created_utc": "2026-02-13 08:56:53",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 0.74,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r3kavf/pwning_supercomputers_a_20yo_vulnerability_in/",
      "domain": "blog.lexfo.fr",
      "is_self": false,
      "comments": [
        {
          "id": "o55q2tn",
          "author": "thedudeonblockchain",
          "text": "20 years is wild for a vuln that's been sitting in prod authentication code. the credential forwarding attack is the nasty part - compromising one node in the cluster lets you pivot to any other node that trusts the same munge instance.",
          "score": 4,
          "created_utc": "2026-02-13 13:15:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r38ylq",
      "title": "Capture the Flag (CTF) AWS/SANS",
      "subreddit": "netsec",
      "url": "https://app.brazenconnect.com/events/bJK18",
      "author": "Successful_Clock2878",
      "created_utc": "2026-02-12 23:23:37",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r38ylq/capture_the_flag_ctf_awssans/",
      "domain": "app.brazenconnect.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r7jdac",
      "title": "Kraken Darknet Access via Clearnet Gateways â€“ some observations",
      "subreddit": "netsec",
      "url": "https://malwr-analysis.com/2026/02/18/kraken-darknet-access-via-clearnet-gateways/",
      "author": "anuraggawande",
      "created_utc": "2026-02-17 21:28:29",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r7jdac/kraken_darknet_access_via_clearnet_gateways_some/",
      "domain": "malwr-analysis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5yqd00",
          "author": "dirkthedank",
          "text": "that smells like a pile of feds",
          "score": 1,
          "created_utc": "2026-02-18 00:27:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6l5e3",
      "title": "When Audits Fail Part 2: From Pre-Auth SSRF to RCE in TRUfusion Enterprise",
      "subreddit": "netsec",
      "url": "https://www.rcesecurity.com/2026/02/when-audits-fail-from-pre-auth-ssrf-to-rce-in-trufusion-enterprise/",
      "author": "MrTuxracer",
      "created_utc": "2026-02-16 20:36:35",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6l5e3/when_audits_fail_part_2_from_preauth_ssrf_to_rce/",
      "domain": "rcesecurity.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r27okq",
      "title": "Securing Digital Assets in an Evolving Threat Landscape â€” analysis of DPRK/Lazarus operations, DaaS proliferation, and defense-in-depth architecture [PDF]",
      "subreddit": "netsec",
      "url": "https://www.fireblocks.com/wp-content/uploads/2026/02/Fireblocks_Security_Whitepaper_Feb2026.pdf",
      "author": "FireblocksHQ",
      "created_utc": "2026-02-11 19:53:30",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.64,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "PDF",
      "permalink": "https://reddit.com/r/netsec/comments/1r27okq/securing_digital_assets_in_an_evolving_threat/",
      "domain": "fireblocks.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r63te8",
      "title": "Architectural Isolation Tradeoffs in the OpenClaw Ecosystem After CVE-2026-25253",
      "subreddit": "netsec",
      "url": "https://nvd.nist.gov/vuln/detail/CVE-2026-25253",
      "author": "rsrini7",
      "created_utc": "2026-02-16 08:04:58",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r63te8/architectural_isolation_tradeoffs_in_the_openclaw/",
      "domain": "nvd.nist.gov",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r64yhj",
      "title": "New Joomla! Novarain/Tassos Framework Vulnerabilities Advisory",
      "subreddit": "netsec",
      "url": "https://ssd-disclosure.com/joomla-novarain-tassos-framework-vulnerabilities/",
      "author": "SSDisclosure",
      "created_utc": "2026-02-16 09:15:33",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.72,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r64yhj/new_joomla_novaraintassos_framework/",
      "domain": "ssd-disclosure.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r2q683",
      "title": "YAML Merge Tags and More Parser Differentials",
      "subreddit": "netsec",
      "url": "https://blog.darkforge.io/yaml/merge/parser/differential/research/2026/02/11/YAML-Merge-Tags-and-Parser-Differentials.html",
      "author": "Moopanger",
      "created_utc": "2026-02-12 10:40:01",
      "score": 3,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r2q683/yaml_merge_tags_and_more_parser_differentials/",
      "domain": "blog.darkforge.io",
      "is_self": false,
      "comments": [
        {
          "id": "o4zxqb2",
          "author": "yawkat",
          "text": "We have to fix parser differentials in HTTP/1.1 often, I can only imagine how difficult it must be with a format as complicated as yaml. People should really design their systems in such a way that parser differentials become irrelevant.",
          "score": 2,
          "created_utc": "2026-02-12 15:47:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h72gw",
              "author": "Moopanger",
              "text": "100%. I want to say the the safest option feels like not supporting merging at all, but I doubt that's feasible in many systems. And then you still gotta worry about other tags like '!!binary' for key confusion. Definitely not an easy solution here.",
              "score": 1,
              "created_utc": "2026-02-15 08:24:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o55i180",
          "author": "Dependent_Web_1654",
          "text": "It's wild how often these parser differentials fly under the radar until something actually breaks. Using YAML for security-sensitive configurations always feels like playing with fire because of these weird edge cases with tags and merging. I've been following Orbon Cloud that's looking at more consistent ways to handle these kinds of data layer complexities. They aren't fully launched yet, but they have an Alpha program for early access if you're interested in checking out how they're tackling it.",
          "score": 2,
          "created_utc": "2026-02-13 12:23:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bopzp",
          "author": "thedudeonblockchain",
          "text": "the merge tag behavior is particularly nasty in ci/cd pipelines where different parsers in dev vs prod can silently change your configuration. most teams don't test for parser differentials because they assume 'valid yaml is valid yaml' until something breaks in production.",
          "score": 2,
          "created_utc": "2026-02-14 11:25:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h6vkp",
              "author": "Moopanger",
              "text": "I hadn't thought about that, definitely interested to dig into it more, thanks.",
              "score": 2,
              "created_utc": "2026-02-15 08:22:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5oc2x9",
                  "author": "thedudeonblockchain",
                  "text": "Np!",
                  "score": 2,
                  "created_utc": "2026-02-16 12:59:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}