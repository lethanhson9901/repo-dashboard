{
  "metadata": {
    "last_updated": "2026-02-21 08:57:51",
    "time_filter": "week",
    "subreddit": "netsec",
    "total_items": 20,
    "total_comments": 53,
    "file_size_bytes": 75502
  },
  "items": [
    {
      "id": "1r7j1zm",
      "title": "Leaking secrets from the claud: AI coding tools are leaking secrets via configuration directories",
      "subreddit": "netsec",
      "url": "https://ironpeak.be/blog/leaking-secrets-from-the-claud/",
      "author": "nindustries",
      "created_utc": "2026-02-17 21:16:50",
      "score": 163,
      "num_comments": 17,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r7j1zm/leaking_secrets_from_the_claud_ai_coding_tools/",
      "domain": "ironpeak.be",
      "is_self": false,
      "comments": [
        {
          "id": "o5ysl81",
          "author": "ruibranco",
          "text": "This is a real blind spot in most dev workflows right now. Tools like Cursor, Copilot, and Claude Code all create local config files (.cursor/, .github/copilot, [CLAUDE.md](http://CLAUDE.md), etc.) that can contain project context, API keys referenced in prompts, or even full conversation logs. Most .gitignore templates haven't caught up to include these directories yet, so they end up committed and pushed without anyone noticing.The fix is straightforward but tedious: audit your .gitignore for every AI tool your team uses, run git log searches for accidentally committed config dirs, and treat these directories the same way you'd treat .env files. Some teams are also adding pre-commit hooks that specifically scan for AI tool artifacts.",
          "score": 45,
          "created_utc": "2026-02-18 00:39:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zpzw6",
              "author": "xortingen",
              "text": "People do blind ‚Äúgit add .‚Äù then blame others/tools.",
              "score": 29,
              "created_utc": "2026-02-18 03:42:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60j0g6",
              "author": "Danielo944",
              "text": "People don't do git status before doing a git add . ?",
              "score": 9,
              "created_utc": "2026-02-18 07:19:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64112s",
                  "author": "psaux_grep",
                  "text": "Or after?\n\nBut also - the amount of people I see who do \n\n    git add .\n    git commit -m ‚Ä¶\n\nInstead of just doing `gc -am` is way too high. And yes, I‚Äôve aliased git commit. Save time where you can ;)",
                  "score": 4,
                  "created_utc": "2026-02-18 19:43:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62jgi1",
              "author": "ClassicPart",
              "text": ">¬†The fix is straightforward but tedious\n\nOh, I know this one: it‚Äôs people actually fucking checking what they commit to repositories instead of blindly adding shit.\n\n>¬†audit your .gitignore for every AI tool your team uses\n\nAh, I guess personal responsibility is off the table then.",
              "score": 6,
              "created_utc": "2026-02-18 15:43:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5zq2o1",
              "author": "ko_oktide",
              "text": "I definitely understand the concern here. However, I haven‚Äôt run into this at all. Every time I hard code even an ARN or something in some code Claude yells at me to throw it in an env file. Much less API keys. Also‚Ä¶ this was an issue before AI, but I do agree people will get more complacent with review etc. when they don‚Äôt even have to write the code to begin with.",
              "score": 1,
              "created_utc": "2026-02-18 03:42:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60h59f",
                  "author": "nindustries",
                  "text": "It's not about hardcoding secrets in your code, it's e.g. Claude proposing to run your app with secrets on the CLI, which you whitelist. This whitelist then ends up in .claude/ and could leak those secrets to public repos.",
                  "score": 7,
                  "created_utc": "2026-02-18 07:03:05",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o62tk8f",
                  "author": "Patriark",
                  "text": "The git-commit-push slash command used by Claude team also have some helpful tools to prevent publishing secrets.",
                  "score": 1,
                  "created_utc": "2026-02-18 16:29:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6199fo",
          "author": "thedudeonblockchain",
          "text": "the whitelisted commands angle is the sneakiest part. if you allow claude to run something like STRIPE\\_KEY=sk\\_live\\_xxx in a bash command, that allowlist can live in .claude/settings.local.json in plaintext. trufflehog and gitleaks both need explicit rules for these dirs since most default configs skip dot-paths",
          "score": 3,
          "created_utc": "2026-02-18 11:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60gdc1",
          "author": "platformuser",
          "text": "The real issue isn‚Äôt just accidental commits. AI tools are creating new classes of sensitive artifacts (prompt logs, project summaries, context caches) that don‚Äôt fit traditional secret-scanning models. \n\nMost orgs updated their .gitignore for .env years ago. Very few have updated their threat models for AI-generated config/state directories.",
          "score": 8,
          "created_utc": "2026-02-18 06:56:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o626w7s",
              "author": "TikiTDO",
              "text": "Since when are logs and intermediate generated files a new class of sensitive artifact? If you're a dev committing sensitive things, that's on you. This whole thing of, \"Oh, my AI did it\" is an absurd cop-out.\n\nThe AI wouldn't have done a thing without your involvement, so no, **you** did it. Your AI was just the vehicle through which you did. If you left secrets in your repo, that's just you being bad at security. \n\nAlso, most secret scanners are doing heuristic based matching. Does this look like a name? Does this look like SSN number? Does this look like a token? The entire point of those is to find secrets in arbitrary places. AI generated files also qualify. These people just aren't running secret scanners, and likely don't even know what those are.\n\nI essentially see this whole thing as another copy of the late 90s and early 2000s. A lot of people are suddenly getting into the field because it's become way easier than it used to be, and are suddenly finding out that real software is fuckin hard, even if an AI handles all the nasty coding for you.",
              "score": 6,
              "created_utc": "2026-02-18 14:43:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o629ada",
                  "author": "platformuser",
                  "text": "I‚Äôm not saying ‚ÄúAI did it‚Äù and responsibility disappears. Devs are still accountable for what they commit.\n\nMy point is just that the shape of sensitive artifacts has changed. Secret scanners are good at catching structured secrets like keys and tokens. What they‚Äôre not always great at is large prompt transcripts, architecture summaries, or context caches that mix proprietary logic and pasted data in natural language.\n\nThose aren‚Äôt secrets in the regex sense, but they can still expose internal systems or client information.\n\nSo yes, it‚Äôs on the developer. I just think the threat model needs to expand as the tooling changes.",
                  "score": 3,
                  "created_utc": "2026-02-18 14:55:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66fo08",
          "author": "dexgh0st",
          "text": "The interesting thing about the AI tool case is that secrets aren't always in obvious key=value format. They end up embedded in conversation context, prompt histories, and command allowlists in ways that regex-based scanners (gitleaks, trufflehog) don't pattern-match well. A Stripe key inside a JSON blob inside a conversation log is several layers of indirection past what most scanning rules expect.\n\nThe .gitignore fix is necessary but insufficient -- only protects future commits, not historical ones. Worth running `git log --all --diff-filter=A -- \"*.json\" \"*.md\"` piped through your scanner periodically. And for compiled artifacts (mobile apps, Docker images), secrets baked into the build are an entirely separate exposure surface that repo-level scanning never touches.",
          "score": 2,
          "created_utc": "2026-02-19 03:14:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6468yg",
          "author": "schwar2ss",
          "text": "Check out embracethered, Johann was conducting a few tests in August 2025 and found these issues (yolo mode, data leak, execution of downloaded binaries) in all coding tools. For a talk in September, I showcased a similar attack exfiltrating the entire .ssh folder for a staged lateral attack. \n\nIt's a whack-a-mole game and will give us plenty of work for the next decade or so.",
          "score": 1,
          "created_utc": "2026-02-18 20:07:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4kmv7",
      "title": "Hacking a pharmacy to get free prescription drugs and more",
      "subreddit": "netsec",
      "url": "https://eaton-works.com/2026/02/13/dava-india-hack/",
      "author": "EatonZ",
      "created_utc": "2026-02-14 13:28:43",
      "score": 127,
      "num_comments": 8,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r4kmv7/hacking_a_pharmacy_to_get_free_prescription_drugs/",
      "domain": "eaton-works.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5chw9k",
          "author": "webrnaster",
          "text": "How did you get the role id (674b187663b07...) when creating an admin?",
          "score": 17,
          "created_utc": "2026-02-14 14:50:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ci7pq",
              "author": "EatonZ",
              "text": "When you retrieved the list of existing users, it included their role ID.",
              "score": 23,
              "created_utc": "2026-02-14 14:52:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5cjvva",
                  "author": "webrnaster",
                  "text": "I see. All the \\_id parameter values are blurred. I assumed it was one of those. Thanks for confirming.",
                  "score": 6,
                  "created_utc": "2026-02-14 15:01:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5crycl",
          "author": "mpg111",
          "text": "how do you know that this is true?\n\nQ: Was my data leaked?\n\nA: No, the security vulnerabilities were fixed before this could happen.",
          "score": 11,
          "created_utc": "2026-02-14 15:44:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cuw59",
              "author": "EatonZ",
              "text": "In this case no other \"malicious\" admin accounts were found that would have allowed access.",
              "score": 9,
              "created_utc": "2026-02-14 15:59:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5eqxe9",
                  "author": "Rene_Z",
                  "text": "Someone could have done this and deleted their admin account after. And with such an obvious security vulnerability (unauthenticated endpoint to query and create admin users!?), no doubt that site has more. I would not trust that my data is safe with them.",
                  "score": 9,
                  "created_utc": "2026-02-14 21:51:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5cz63x",
                  "author": "mpg111",
                  "text": "thx",
                  "score": 1,
                  "created_utc": "2026-02-14 16:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r66u2r",
      "title": "[Analysis] Massive Active GitHub Malware Campaign | Hundreds of Malicious Repositories Identified",
      "subreddit": "netsec",
      "url": "https://brennan.day/the-curious-case-of-the-triton-malware-fork/",
      "author": "WanderBetter",
      "created_utc": "2026-02-16 11:08:41",
      "score": 91,
      "num_comments": 9,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r66u2r/analysis_massive_active_github_malware_campaign/",
      "domain": "brennan.day",
      "is_self": false,
      "comments": [
        {
          "id": "o5o2f05",
          "author": "formatme",
          "text": "I have reported this a while back to the github subreddit, hoping a dev at github would take action\n\n[https://www.reddit.com/r/github/comments/1qbndfx/massive\\_ai\\_malware\\_campaign\\_happening\\_on\\_github/](https://www.reddit.com/r/github/comments/1qbndfx/massive_ai_malware_campaign_happening_on_github/)",
          "score": 18,
          "created_utc": "2026-02-16 11:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oc5wh",
          "author": "thedudeonblockchain",
          "text": "the automated deployment pattern is concerning because traditional rate limiting won't stop this since each repo looks independent. the emoji headers and manipulated commit history are clever social engineering since they make forks look more legitimate and established to casual users. from a detection standpoint, the low virustotal coverage means security teams relying on hash based detection are going to miss this entirely until it's already widespread. the real fix needs to be at the github platform level, maybe reputation scoring for forks plus automated analysis of sudden readme changes that introduce direct download links, but that's a hard moderation problem at github's scale.",
          "score": 11,
          "created_utc": "2026-02-16 12:59:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pmnkc",
          "author": "kingqk",
          "text": "Picked three random repos from your list, gave a 404, so chances are that all those repos are wiped.",
          "score": 10,
          "created_utc": "2026-02-16 16:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qruv5",
              "author": "WanderBetter",
              "text": "You're right. I just did another cursory search (https://github.com/search?q=malware&type=repositories&s=updated&o=desc&p=1) and found dozens more that I added.",
              "score": 3,
              "created_utc": "2026-02-16 20:11:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ogqix",
          "author": "Comfortable-Survey83",
          "text": "Could you please share which vendors had a detection at the time of first scan?",
          "score": 2,
          "created_utc": "2026-02-16 13:28:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ukja6",
          "author": "d3vk47",
          "text": "Looks like DGA with dicts to auto generate the accounts and projects. This looks like they are planned as short lived and campaign specific. I wonder how long is the TTL of the account before take down.",
          "score": 2,
          "created_utc": "2026-02-17 11:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rv3d5",
          "author": "V2UgYXJlIG5vdCBJ",
          "text": "I wonder if the security issues have anything to do with Microsoft taking over. I used to think GitHub was solid.",
          "score": 1,
          "created_utc": "2026-02-16 23:29:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6r7no",
      "title": "Almost Impossible: Java Deserialization Through Broken Crypto in OpenText Directory Services",
      "subreddit": "netsec",
      "url": "https://slcyber.io/research-center/almost-impossible-java-deserialization-through-broken-crypto-in-opentext-directory-services/",
      "author": "Mempodipper",
      "created_utc": "2026-02-17 00:34:23",
      "score": 71,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6r7no/almost_impossible_java_deserialization_through/",
      "domain": "slcyber.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5sqytq",
          "author": "SuperDrewb",
          "text": "Extremely impressive¬†",
          "score": 8,
          "created_utc": "2026-02-17 02:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u4dog",
          "author": "Few-Gap-5421",
          "text": "Nice research man",
          "score": 3,
          "created_utc": "2026-02-17 09:00:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra5k54",
      "title": "Why AI agent containers need a syscall-level observer: the prompt injection blind spot",
      "subreddit": "netsec",
      "url": "https://itnext.io/runtime-tracing-for-ai-agents-what-your-openclaw-agent-actually-does-inside-the-container-aebabb8977f2",
      "author": "M4r10_h4ck",
      "created_utc": "2026-02-20 19:51:18",
      "score": 71,
      "num_comments": 10,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1ra5k54/why_ai_agent_containers_need_a_syscalllevel/",
      "domain": "itnext.io",
      "is_self": false,
      "comments": [
        {
          "id": "o6ho47u",
          "author": "jdefr",
          "text": "Alright but I am somewhat averse to security products that seem mostly ‚ÄúVibe Coded‚Äù which this seems to have been by looking at git history and such‚Ä¶ Don‚Äôt get me wrong it‚Äôs a great idea and stuff . Now, if you used agentic coding mostly as a check and you genuinely understand every line in the codebase. That‚Äôs different.",
          "score": 18,
          "created_utc": "2026-02-20 20:55:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hy9n8",
              "author": "M4r10_h4ck",
              "text": "Fair point, and it‚Äôs a legitimate concern for security tooling. Let me be transparent about it.\nYes, agentic coding was part of the workflow. But the git history also shows the test suite: 80% unit test coverage, integration tests that spin up a real container, run a malware behavior simulator, and assert that every expected event type was actually captured. Linter and security scan on every PR. All in CI, you can check it yourself.\nThe eBPF programs and the cgroup filtering logic were the parts I reviewed most carefully line by line, because that‚Äôs where a subtle bug would actually matter from a security perspective. That‚Äôs not something you can ship on vibes and hope for the best.\nThe idea that agentic coding and actually understanding your codebase are mutually exclusive is worth pushing back on. The question is whether the author can reason about what the code does and why. Happy to go deep on any specific part if you want to probe that.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
              "score": -10,
              "created_utc": "2026-02-20 21:45:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6idsiu",
                  "author": "Dangle76",
                  "text": "Unit test coverage is meaningless if it‚Äôs mostly agentic code. Agents will write tests so that they pass a lot of the time, even if the test itself doesn‚Äôt actually test your code properly. It ‚Äúfixes‚Äù the test not the thing it‚Äôs testing a lot",
                  "score": 17,
                  "created_utc": "2026-02-20 23:06:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6jdv1s",
                  "author": "kent_stor",
                  "text": "The response here I feel is very likely written by a bot, based on the wording I'd guess a GPT model. So the whole \"I reviewed most carefully line by line\" is a load of crap.",
                  "score": 3,
                  "created_utc": "2026-02-21 02:43:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6innp5",
          "author": "viziroth",
          "text": "better idea is to just stop giving AI agents access to anything production facing or able to make any infrastructure changes\n\neven better, just stop using something that doesn't actually understand code to code",
          "score": 12,
          "created_utc": "2026-02-21 00:03:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jk80h",
          "author": "KingOfKingOfKings",
          "text": "get out of here with your slop post of slop code to validate slop",
          "score": 7,
          "created_utc": "2026-02-21 03:24:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kkdds",
              "author": "M4r10_h4ck",
              "text": "You are the king of king of stupid! Show me your code!",
              "score": 1,
              "created_utc": "2026-02-21 08:22:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9wmyj",
      "title": "In Memoriam: Jason Snitker, a.k.a. Parmaster. RIP Legend",
      "subreddit": "netsec",
      "url": "https://professorsigmund.com/field-notes/in-memoriam-parmaster.html",
      "author": "Professor_Sigmund",
      "created_utc": "2026-02-20 14:21:47",
      "score": 63,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r9wmyj/in_memoriam_jason_snitker_aka_parmaster_rip_legend/",
      "domain": "professorsigmund.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6h66zb",
          "author": "fecalreceptacle",
          "text": "RIP to a legend",
          "score": 2,
          "created_utc": "2026-02-20 19:27:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hbpsj",
          "author": "catwiesel",
          "text": "legend indeed. RIP",
          "score": 2,
          "created_utc": "2026-02-20 19:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6illoe",
          "author": "intelw1zard",
          "text": "RIP and have fun in hacker heaven",
          "score": 0,
          "created_utc": "2026-02-20 23:51:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9qkpl",
      "title": "Your AD password complexity policies are security theater ‚Äî one RPC call bypasses all of them (PoC scripts + defense included)",
      "subreddit": "netsec",
      "url": "https://simpity.eu/blog/ad-password-policies-security-theater",
      "author": "Suitable-Baker7584",
      "created_utc": "2026-02-20 09:12:02",
      "score": 48,
      "num_comments": 13,
      "upvote_ratio": 0.68,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r9qkpl/your_ad_password_complexity_policies_are_security/",
      "domain": "simpity.eu",
      "is_self": false,
      "comments": [
        {
          "id": "o6e9fy9",
          "author": "cym13",
          "text": "Ok so someone with the rights to change a given account's password can push a raw hash for that account.\n\nWhile I appreciate the distinction between NTLM protocol and NTLM hash, I'm having trouble understanding the threat presented here. If I can push a hash of my choosing, I can just push a hash that I know the password so this isn't about account takeover. And it has to be an account I can change the password for, so there's no permission bypass here.\n\nYou can, indeed, voluntarily weaken your own password through an unorthodox procedure. That has no bearing on most users and doesn't make existing hashes that follow policy easier to crack. That's also not discreet as the user who's password you change will notice that their password has changed (and probably change it in return).\n\nMaybe there's a scenario where you use malware to change someone's password to something easier to crack, but again why change it to something you have to crack at all?\n\nSorry, but I really don't see the problem. If the only way to escape policy is through a non-standard procedure that requires proper authorization, then there's no security theater at play. You can voluntarily downgrade your own password. It would probably be better if it wasn't the case, but it doesn't invalidate the impact of the policy at scale, and if your goal is to facilitate someone breaking into your account, just give them the password. It'll leave less traces than changing your own password to something easier to crack.",
          "score": 49,
          "created_utc": "2026-02-20 09:46:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft8h6",
              "author": "just_for_saving61",
              "text": "if there were some monitoring or policy layer that caught normal password resets but not SamrSetInformationUser calls. That's a detection evasion argument, not a policy bypass argument, and the blog post doesn't frame it that way.",
              "score": 4,
              "created_utc": "2026-02-20 15:43:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fwzto",
                  "author": "cym13",
                  "text": "Ok, that I can get behind. But it has nothing to do with the type of hash used or the complexity of the password.",
                  "score": 1,
                  "created_utc": "2026-02-20 16:00:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ed4r7",
              "author": "Potato-9",
              "text": "Indeed. It would be nice if it was easy enough to know what was calling https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-samr/538222f7-1b89-4811-949a-0eac62e38dce or what programs have that call in them so I don't run them as domain admin.\n\nCustom password filter DLLs checking against breached dictionaries? Never invoked. Is kind of a big deal out that api is easy to expose accidentally.",
              "score": 5,
              "created_utc": "2026-02-20 10:19:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gmgg6",
          "author": "AYamHah",
          "text": "So you can intentionally set a weak password by entering a hash for it. But you already have access to update this accounts password. Why do you care to go around setting weak passwords for yourself or accounts you control? On an engagement, creating a service account with a weak password on the client's network would result in your firm losing the client and you losing your job. You wanted persistance with \"password123\"? - get outta here.",
          "score": 15,
          "created_utc": "2026-02-20 17:57:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f5vh8",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 16,
          "created_utc": "2026-02-20 13:45:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gpspc",
              "author": "intelw1zard",
              "text": "This is an AI account that posts comments. It's not a real person.",
              "score": 4,
              "created_utc": "2026-02-20 18:12:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6gcqgr",
              "author": "I_Will_Eat_Your_Ears",
              "text": "Sorry, but I think I'm missing something. If you're post-DA, why is complexity enforcement a concern?\n\nWhy do you want to crack a kerberos ticket if you already know the password? \n\nI may be mistaken, but it sounds like this flow is for demonstration purposes, and setting the credential isn't something an actual attacker would do",
              "score": 3,
              "created_utc": "2026-02-20 17:12:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hnj8d",
          "author": "Pink_Zepellica",
          "text": "I find the concept interesting especially from a defense evasion standpoint. I wanted to take a look at the password change script but the links don't work. OP, are you the original author, do you have the script?",
          "score": 1,
          "created_utc": "2026-02-20 20:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kfg0m",
          "author": "meutrei",
          "text": "[Suitable-Baker7584](https://www.reddit.com/user/Suitable-Baker7584/): Could you provide us with the .zip files (or source code) directly / GitHub etc? The download links on the website are blank.  \nFor research purposes & test EDR etc?",
          "score": 1,
          "created_utc": "2026-02-21 07:34:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fbdp6",
          "author": "dydhaw",
          "text": "All password policies are security theater.",
          "score": -4,
          "created_utc": "2026-02-20 14:14:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6flhll",
              "author": "bosconet",
              "text": "note: only when humans are involved in a system are they security theater.... :-) ",
              "score": 1,
              "created_utc": "2026-02-20 15:06:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6g3jm3",
          "author": "Oriumpor",
          "text": "Password complexity isn't useful¬†",
          "score": -4,
          "created_utc": "2026-02-20 16:30:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r74ifj",
      "title": "Log Poisoning in OpenClaw",
      "subreddit": "netsec",
      "url": "https://research.eye.security/log-poisoning-in-openclaw/",
      "author": "vaizor",
      "created_utc": "2026-02-17 12:19:40",
      "score": 44,
      "num_comments": 19,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r74ifj/log_poisoning_in_openclaw/",
      "domain": "research.eye.security",
      "is_self": false,
      "comments": [
        {
          "id": "o60gmvi",
          "author": "platformuser",
          "text": "This is a broader class of issue than just OpenClaw.\n\nAny agent that ingests its own logs, tool output, or environment artifacts is effectively expanding its prompt surface to include untrusted data.\n\nTraditional logging assumes ‚Äúhumans read logs.‚Äù Agentic systems blur that boundary. Once logs become model input, they‚Äôre no longer passive telemetry  they‚Äôre an attack vector.\n\nTreat anything an agent can read as part of the prompt boundary.",
          "score": 12,
          "created_utc": "2026-02-18 06:58:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wns2l",
          "author": "si9int",
          "text": "Another viby nail into the coffin of OpenClaw. I don't get the hype; srsly .. The idea might be interesting, but the implementation is a disaster.",
          "score": 29,
          "created_utc": "2026-02-17 18:19:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o633rvp",
              "author": "VoidVer",
              "text": "Idiots are excited to have the computer think for them, not understanding that will make them disposable and even stupider than they already are.",
              "score": 5,
              "created_utc": "2026-02-18 17:15:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xdnrf",
              "author": "deneuralizer",
              "text": "There are quite a few forks coming out made in Rust, Go, which are supposed to be more secure. I am going to give ZeroClaw a shot",
              "score": -17,
              "created_utc": "2026-02-17 20:20:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xthow",
                  "author": "ziirex",
                  "text": "Rust and Go would mainly help if the issues were memory safety related, but the whole concept is quite risky by design. Fixes would need a major rearchitecture at which point it's a stretch to call them forks in my opinion.",
                  "score": 19,
                  "created_utc": "2026-02-17 21:35:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vyluv",
          "author": "thedudeonblockchain",
          "text": "the read/write access argument cuts both ways - yes it's a personal project, but once users deploy it in any networked or automated context (which full rw implicitly encourages), the log poisoning surface becomes a real downstream risk. logs that feed into SIEMs, dashboards, or monitoring pipelines are classic lateral movement paths once you control the content. the takeaway is probably less about enterprise hardening and more about surfacing default-safe configs even in experimental tools - write access in particular should require explicit opt-in.",
          "score": 15,
          "created_utc": "2026-02-17 16:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wflt9",
              "author": "[deleted]",
              "text": "[removed]",
              "score": -2,
              "created_utc": "2026-02-17 17:42:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5wi9xx",
                  "author": "rejuicekeve",
                  "text": "You'll say that without actually reporting the post for us to review like a big jabroni",
                  "score": 15,
                  "created_utc": "2026-02-17 17:54:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5wfrm8",
                  "author": "thedudeonblockchain",
                  "text": "What are you talking about man",
                  "score": 1,
                  "created_utc": "2026-02-17 17:42:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xljl3",
          "author": "InterSlayer",
          "text": "Theres a fridman interview with steinberger where he talks about having to rename repos, then the old names got sniped and started spreading malware. Then feeling distraught and wanting to just drop the whole project. üò±",
          "score": 1,
          "created_utc": "2026-02-17 20:58:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v9jmv",
          "author": "hankyone",
          "text": "The cybersecurity industry treating a one man open source experiment created 80 days ago for shits and giggles like it should have enterprise grade security",
          "score": -24,
          "created_utc": "2026-02-17 14:10:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vpi9o",
              "author": "sarcasmguy1",
              "text": "When the tool has full read/write access, and encourages you to configure it as such, then yes it should have a level of security thats close to enterprise",
              "score": 32,
              "created_utc": "2026-02-17 15:32:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w10c3",
                  "author": "Hizonner",
                  "text": "Difficulty: there is no way to make that tool even vaguely close safe for anything, period, and leaking random stuff into logs is not in the top 1000 exposures.",
                  "score": 13,
                  "created_utc": "2026-02-17 16:29:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5zwje4",
              "author": "imsoindustrial",
              "text": "Idk why you‚Äôre getting downvoted and I am a cynical fuck with decades of cybersecurity experience.",
              "score": 4,
              "created_utc": "2026-02-18 04:24:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o604jze",
                  "author": "hankyone",
                  "text": "The AI relationship perhaps?\n\nI thought Reddit was weird with AI but seems it‚Äôs also the whole infosec industry",
                  "score": 2,
                  "created_utc": "2026-02-18 05:20:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o647ymf",
              "author": "ZestyTurtle",
              "text": "Yeah, I agree. This is a one man open source toy that‚Äôs barely a few months old, not an enterprise product.\n\nIf someone deploy it, wire it into real systems, feed it untrusted input and don‚Äôt think about a threat model (and secure it accordingly), that‚Äôs on him. \n\nActing shocked that an experimental AI agent doesn‚Äôt magically have enterprise grade security is missing the point. The responsibility is on the operator, not the hobby project.",
              "score": 2,
              "created_utc": "2026-02-18 20:15:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r92evr",
      "title": "[CVE-2026-0714] TPM-sniffing LUKS Keys on an Embedded Device",
      "subreddit": "netsec",
      "url": "https://www.cyloq.se/en/research/cve-2026-0714-tpm-sniffing-luks-keys-on-an-embedded-device",
      "author": "AlmondOffSec",
      "created_utc": "2026-02-19 15:38:01",
      "score": 37,
      "num_comments": 1,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r92evr/cve20260714_tpmsniffing_luks_keys_on_an_embedded/",
      "domain": "cyloq.se",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r745t9",
      "title": "Prompt Injection Standardization: Text Techniques vs Intent",
      "subreddit": "netsec",
      "url": "https://www.lasso.security/blog/prompt-injection-taxonomy-techniques",
      "author": "Equivalent_Cover4542",
      "created_utc": "2026-02-17 12:02:09",
      "score": 36,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r745t9/prompt_injection_standardization_text_techniques/",
      "domain": "lasso.security",
      "is_self": false,
      "comments": [
        {
          "id": "o5w2sg4",
          "author": "thedudeonblockchain",
          "text": "the technique vs intent split hits on a core problem in prompt injection defense: the same text sequence can be benign or malicious depending on context, which makes purely syntactic detection brittle. what makes this particularly hard is multi-step indirect injections where neither the technique nor the intent is legible from a single interaction - the payload arrives in one turn, gets stored (retrieval, memory, tool output), and executes in a later turn in a completely different context. at that point you need to track provenance of content through the entire execution graph to reason about intent, which most current defenses don't do. the taxonomy is still useful for threat modeling and red-teaming even if it doesn't directly map to detection primitives - knowing whether you're dealing with a role-play jailbreak vs translation obfuscation vs indirect injection tells you which system components to harden first.",
          "score": 3,
          "created_utc": "2026-02-17 16:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61nan3",
              "author": "redyellowblue5031",
              "text": "Where have we seen that before‚Ä¶.",
              "score": 1,
              "created_utc": "2026-02-18 12:57:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uvncu",
          "author": "anyore909",
          "text": "The technique vs intent distinction makes sense. translation-based attacks and role-play jailbreaks may aim for the same outcome, but they work very differently. Structuring it this way makes the problem easier to reason about.",
          "score": 2,
          "created_utc": "2026-02-17 12:50:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wlc4p",
          "author": "ozgurozkan",
          "text": "The provenance tracking point is critical and often overlooked. Most organizations are focused on input sanitization, but the real danger is in persistence mechanisms where injected content gets written to context stores, vector databases, or agent memory.\n\n\n\nFrom a practical red team perspective, the highest success rate attacks I've seen combine two or three techniques in sequence. Start with translation obfuscation to bypass basic filters, use role play to establish a trusted context, then inject the actual payload through indirect means so it appears to come from a legitimate data source rather than user input.\n\n\n\nThe hardest part about defending against this is that effective mitigation requires architectural changes, not just better prompts. You need content signing, strict output encoding based on destination context, and proper separation between instruction channels and data channels. But most production systems treat everything as a string and hope prompt engineering will save them.\n\n\n\nThe taxonomy helps because it forces you to think about attack chains rather than individual techniques. Defense in depth means breaking the chain at multiple points, which means you need to map your architecture to the attack surface this framework describes.",
          "score": 2,
          "created_utc": "2026-02-17 18:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f65wm",
          "author": "ozgurozkan",
          "text": "The technique vs intent taxonomy is useful but the real challenge in operationalizing this for detection is that the classification boundary is context-dependent and shifts with each model update.\n\n\n\nWhat I find more actionable is thinking about prompt injection in terms of trust boundary violations rather than textual features. The core issue is that LLM systems conflate data and instruction planes, and there's no enforced separation the way there is in, say, SQL parameterized queries. When a retrieval step can modify the instruction context without going through a separate validation layer, you have a structural vulnerability regardless of how the injected text looks.\n\n\n\nFor agentic systems specifically, the attack surface expands significantly because injected content can persist across tool calls and context windows. A payload that lands in a memory store during one session can execute in a completely different security context later. This is where purely text-technique-based defenses fail: the payload is dormant and innocuous at storage time.\n\n\n\nThe intent classification approach makes more sense for training-time or fine-tuning mitigations, but for runtime detection you really want to be monitoring for behavioral anomalies: unusual tool call sequences, unexpected data exfiltration patterns, privilege escalation in capability use. The taxonomy in this post is a solid framework for building red team test cases though.",
          "score": 0,
          "created_utc": "2026-02-20 13:46:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r89vac",
      "title": "CRESCENTHARVEST: Iranian protestors and dissidents targeted in cyberespionage campaign",
      "subreddit": "netsec",
      "url": "https://www.acronis.com/en/tru/posts/crescentharvest-iranian-protestors-and-dissidents-targeted-in-cyberespionage-campaign/",
      "author": "bagaudin",
      "created_utc": "2026-02-18 17:46:52",
      "score": 33,
      "num_comments": 4,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r89vac/crescentharvest_iranian_protestors_and_dissidents/",
      "domain": "acronis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o64iro8",
          "author": "ruibranco",
          "text": "the persistence mechanism here is pretty clever - using NetworkProfile event triggers (EventID 10000) instead of the usual run keys or startup folders means it only fires when connectivity is available, which makes sense for a campaign targeting people in a country with frequent internet shutdowns. no point phoning home if there's no internet.the DLL sideloading through google's own software\\_reporter\\_tool.exe is also notable. using a legitimately signed binary as the loader makes it way harder for endpoint protection to flag the execution chain. similar technique to what check point documented in earlier iranian campaigns but the chrome encryption bypass module is a newer addition.",
          "score": 5,
          "created_utc": "2026-02-18 21:06:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67eoo5",
          "author": "throwaway_88331",
          "text": "Im in Iran and I cant access the site without a VPN:\n\nError: Forbidden\nYour client does not have permission to get URL /en/tru/posts/crescentharvest-iranian-protestors-and-dissidents-targeted-in-cyberespionage-campaign/ from this server.\n\nThe funny thing is that the standard explanation of \"the IRGC will hack them\" falls flat on the fact that IRGC has access to better VPNs than I do and botnets across all of the west.",
          "score": 3,
          "created_utc": "2026-02-19 07:33:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o678pwn",
          "author": "panix187",
          "text": "Did Acronis get bought buy somebody?  Seems weird for a backup company to be putting out security bulletins.",
          "score": 1,
          "created_utc": "2026-02-19 06:41:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67vy3w",
              "author": "474Dennis",
              "text": "Acronis currently offers a complete cyber security stack. The company began integrating such features in 2017.  \nDisclosure: I work at Acronis and I am a mod of r/Acronis",
              "score": 2,
              "created_utc": "2026-02-19 10:20:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6k4z9",
      "title": "nono - kernel-enforced capability sandbox for AI agents",
      "subreddit": "netsec",
      "url": "https://nono.sh",
      "author": "DecodeBytes",
      "created_utc": "2026-02-16 19:59:20",
      "score": 32,
      "num_comments": 10,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6k4z9/nono_kernelenforced_capability_sandbox_for_ai/",
      "domain": "nono.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o5qqi2n",
          "author": "Otherwise_Wave9374",
          "text": "This is super timely. The whole \"agent has my full shell\" thing is the part that makes me nervous about coding agents in real workflows, prompt injection or not. Kernel-level deny-by-default (Landlock/Seatbelt) seems like the right layer to enforce it. Curious if youve tested weird edge cases like build tools that spawn helpers, symlink-heavy repos, or language servers that want to read dotfiles.\n\nAlso if you end up writing up the threat model tradeoffs, Id read it, Ive been collecting agent security notes and patterns here: https://www.agentixlabs.com/blog/",
          "score": 4,
          "created_utc": "2026-02-16 20:04:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qunn6",
              "author": "DecodeBytes",
              "text": "\\> Curious if youve tested weird edge cases like build tools that spawn helpers, symlink-heavy repos, or language servers that want to read dotfiles.\n\nAhh yeah, symlinks are the biggest ache\n\nWhen granted access to a path that's actually a symlink, we always resolve it to the real location immediately. We do this atomically rather than checking existence separately, which would create a window where an attacker could swap the symlink between our check and resolution.\n\nOn macOS, the sandbox enforces against literal path strings rather than resolved paths. So we store both the original path and the resolved real path, then emit sandbox rules for both. Without this, granting access via the real path would still block programs trying to use the symlink.\n\nWe also use proper path component comparison rather than string comparison when checking path relationships.  String prefix matching would incorrectly match paths that just happen to share the same starting characters but aren't actually descendants of the directory in question.\n\nWe also handle parent directory traversal. To access a deeply nested path, programs need to stat each parent directory along the way. We automatically allow metadata-only access to parent directories of granted paths, walking both the original and resolved path hierarchies when they differ.\n\nTaking a look at the blog thanks!   ",
              "score": 2,
              "created_utc": "2026-02-16 20:24:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5rngbq",
          "author": "bagbogbo",
          "text": "Been looking for something like this!",
          "score": 1,
          "created_utc": "2026-02-16 22:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5rtyug",
              "author": "DecodeBytes",
              "text": "cool! let me know if you need any more info or help. ",
              "score": 2,
              "created_utc": "2026-02-16 23:23:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uuiqu",
          "author": "One_Strike_1322",
          "text": "how does this compare to, say using the cursor docker container? To me, a container is easier and more portal to set up but I'd be keen to hear where this is better (obviously containers aren't a sandbox mechanism but they do help).",
          "score": 1,
          "created_utc": "2026-02-17 12:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v67rm",
              "author": "DecodeBytes",
              "text": "Containers and nono solve overlapping but distinct problems, and each has real trade-offs worth considering. There is a section in the docs on this: https://docs.nono.sh/security/containers \n\nContainers give you isolation through namespacing - the process sees a different filesystem root, network stack, and process tree. This is powerful for reproducibility and portability. You can ship a known-good environment, and anything the AI does stays inside that container's view of the world. The downside is that containers are coarse-grained. You either mount a volume into the container or you don't. There's no easy way to say \"read the whole project but only write to the src directory\" or \"access ~/.vscode , but not ~/.ssh/.\" You end up either over-permissioning (mounting your whole home directory) or dealing with friction every time the AI needs something outside the container.\n\nnono takes the opposite approach - it runs natively on your host but uses OS-level mandatory access control (Landlock on Linux, Seatbelt on macOS) to enforce fine-grained capabilities. You can grant read access to your entire codebase while restricting writes to specific directories, block access to credentials and browser data regardless of what commands run, and allow network access while still protecting sensitive local paths. The sandbox is applied to the process itself, not to a virtualized environment, so there's no filesystem copying, no Docker daemon, and near-zero startup overhead. \n\nWhere nono is stronger: granularity. You can express policies like \"read everywhere, write only here, never touch my SSH keys\" that would be awkward or impossible with container volume mounts. It also integrates more naturally with local tooling - your shell, your editor, your existing workflows all just work. \n\nWhere containers are stronger: they provide a complete environment boundary. If the AI installs a malicious package or corrupts system files, it's contained to that throwaway environment. With nono, you're still running on your real system - the sandbox prevents unauthorized access, but if you grant write access to a directory, the AI can still make a mess there (having said that we have an atomic undo system incoming).\n\nThe honest answer is they're complimentary. You can run nono inside a container for defense in depth, or use nono alone when you want lightweight, precise control without the overhead of containerization. It depends on which you value portability and environment isolation (containers) or fine-grained capability control with minimal friction (nono). \n\nThe other factor is nono has a load of other features thrown in, key protection, blocking of dangerous commands, and quite a bit more inbound. \n\nBut honestly, if containers are working, great! I am a fan and its never x vs y here, each have their own strengths.",
              "score": 2,
              "created_utc": "2026-02-17 13:52:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v4ewn",
          "author": "sexy_lady_at_aol_com",
          "text": "Do you know how we might prevent a rogue agent from leaking secrets that have been made available to it? \n\nFor example, say claude has been granted the ability to web search, encounters a prompt injection on the web, and then proceeds to POST any credentials we've shared with the bot (in a .env, or similar), to some strange site, or to Github (like the shai-hulud worm).\n\nCould we host an HTTP proxy and allow only certain domains or paths? Can an agent be instructed to persevere and workaround our limitations? \n\nCould we host a HTTP proxy that injects credentials into outgoing HTTP traffic?\n\nCould we upgrade our third party systems to issue the agent some delegated short lived keys and accept the risk?\n\nNone of these sound like great approaches to me, but I'm keen to hear if you or others have any thoughts.",
          "score": 1,
          "created_utc": "2026-02-17 13:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v70r2",
              "author": "DecodeBytes",
              "text": "Proxy is the way to go. Have a key that only the proxy knows of and it map to the real key in a data store on the proxy. \n\nYou would then have the agent populate the Auth Header with the proxy key, and the proxy swap out the proxy specific key for the real external services key. \n\nSomeone did share this with me, it uses nono - but I have not played around with it. I expect we may well do something native to nono as well - I can share a proof-of-concept with you if useful and you can kick the tyres and see if its something usable?\n\nhttps://github.com/dedene/claw-wrap",
              "score": 1,
              "created_utc": "2026-02-17 13:56:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f6cnm",
          "author": "ozgurozkan",
          "text": "The Landlock approach here is interesting because it addresses something that apparmor and seccomp profiles don't handle as cleanly: the problem that AI coding agents need some filesystem access to be useful, but you want that access to be scoped to the project directory and denied elsewhere by default.\n\n\n\nThe key architectural insight is putting enforcement at the kernel level rather than relying on the agent's own guardrails. Application-layer filtering is exactly what prompt injection is designed to bypass, so the security model collapses precisely when you need it most. Kernel-enforced Landlock LSM rules survive prompt injection because the agent process literally cannot make those syscalls regardless of what instructions it receives.\n\n\n\nA few edge cases worth thinking about for the threat model:\n\n\n\n1. Legitimate agent workflows that need broad access (e.g., reading environment configs across the home directory) will require allow-list configuration, which creates friction that might push users to over-permission the allow list.\n\n\n\n2. Network egress isn't mentioned. An agent that can make outbound connections could exfiltrate data or download additional payloads even with filesystem restrictions intact. Combining Landlock with network namespace restrictions or seccomp filtering on socket calls would be the complete picture.\n\n\n\n3. The credential exfiltration mitigation for \\~/.ssh and \\~/.aws is valuable, but intermediate credential storage (e.g., in-memory secrets passed via env vars) is still visible to the process.\n\n\n\nSolid project overall. The deny-by-default model is the right foundation.",
          "score": 0,
          "created_utc": "2026-02-20 13:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fzyzn",
              "author": "DecodeBytes",
              "text": "Thank you, the whole of the policy system is user configurable / composable:\n\n[https://docs.nono.sh/cli/features/profiles-groups](https://docs.nono.sh/cli/features/profiles-groups) ",
              "score": 1,
              "created_utc": "2026-02-20 16:14:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4u08r",
      "title": "Cloudflare Pages ‚ÄúContinue Read‚Äù Redirect Kit Abused for Phishing, Adware, and Malware Delivery",
      "subreddit": "netsec",
      "url": "https://malwr-analysis.com/2026/02/15/cloudflare-pages-continue-read-redirect-kit-abused-for-phishing-adware-and-malware-delivery/",
      "author": "anuraggawande",
      "created_utc": "2026-02-14 19:47:30",
      "score": 32,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r4u08r/cloudflare_pages_continue_read_redirect_kit/",
      "domain": "malwr-analysis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5eti5a",
          "author": "Secure_Cyber",
          "text": "I see tons of these every week in my role. All sorts of versions with two to three redirects. Most of them check to see if you're looking at them in sandbox tools and they won't arrive at the final locations if you are. I get more data from running them from local. A lot of them are PaaS based phishing kits that are bought off the dark web or backchannel communication platforms. Also, most of the time they use existing public infrastructure to execute in one of the stages post-click; second or third redirect is what I've been finding for that one. That's probably to avoid detection on the surface.",
          "score": 6,
          "created_utc": "2026-02-14 22:06:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5evhvt",
              "author": "anuraggawande",
              "text": "Absolutely agree.\nSeeing multiple redirects and PaaS hosted phishing kits has become pretty normal now, especially with attackers trying to dodge sandbox.\nRunning them locally really does give a clearer picture of what‚Äôs actually happening behind the scenes.",
              "score": 2,
              "created_utc": "2026-02-14 22:17:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hu9zt",
          "author": "TerrorBite",
          "text": "The irony of getting a pop-up in the middle of this article with a ‚ÄúContinue Reading‚Äù link.",
          "score": 4,
          "created_utc": "2026-02-15 12:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k5gte",
              "author": "DrorDv",
              "text": "Lol",
              "score": 1,
              "created_utc": "2026-02-15 19:36:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ra30yn",
      "title": "Your Samsung Weather App Is a Fingerprint: How saved locations create a persistent cross-session tracking identifier",
      "subreddit": "netsec",
      "url": "https://www.buchodi.com/your-samsung-weather-app-is-a-fingerprint/",
      "author": "AdTemporary2475",
      "created_utc": "2026-02-20 18:18:00",
      "score": 29,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1ra30yn/your_samsung_weather_app_is_a_fingerprint_how/",
      "domain": "buchodi.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6hmib3",
          "author": "Acct235095",
          "text": "[Welcome back.](https://www.reddit.com/r/netsec/comments/1r7ih5r/samsung_weather_widget_ships_hardcoded_shared_ibm/)\n\nSeems like a privacy problem rather than network security.",
          "score": 7,
          "created_utc": "2026-02-20 20:47:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hr29u",
              "author": "AdTemporary2475",
              "text": "Hey! The hardcoded API keys are what make this a security issue, not just a privacy one. The keys aren‚Äôt bound to any device or session they seem to be constant across user and devices. That means anyone can query the API directly, resolve any placeid to physical coordinates, and spam arbitrary location combinations into their data pipeline. If TWC is using these fingerprints for cross-session tracking or selling behavioral profiles downstream, an attacker can poison that entire dataset at scale. An unauthenticated, unrate-limited API endpoint serving location resolution for 50M+ US devices is a security problem.",
              "score": 6,
              "created_utc": "2026-02-20 21:09:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8vdkb",
      "title": "Compromising Cline's Production Releases just by Prompting an Issue Triager",
      "subreddit": "netsec",
      "url": "https://adnanthekhan.com/posts/clinejection/",
      "author": "albinowax",
      "created_utc": "2026-02-19 10:05:12",
      "score": 24,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r8vdkb/compromising_clines_production_releases_just_by/",
      "domain": "adnanthekhan.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6a8e9s",
          "author": "InsideStatistician68",
          "text": "Painful to read AI generated text.",
          "score": 3,
          "created_utc": "2026-02-19 18:27:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f3lld",
          "author": "ozgurozkan",
          "text": "This is a clean example of what makes AI-assisted CI/CD so dangerous from a supply chain perspective. The attack surface is no longer just the code or the developer workstation. Any AI agent that has write access to a repository, publish permissions, or the ability to trigger workflows is now a viable lateral movement path if it can be influenced through untrusted input channels.\n\n\n\nThe issue triager case is particularly interesting because the trust model for an issue tracker is fundamentally inverted from what you want in a privileged pipeline component. Issues are designed to be submitted by anyone, including external reporters who are not vetted contributors. Wiring a model with deployment permissions to that input channel without strict output constraints and intent verification is a significant architectural mistake.\n\n\n\nThe broader pattern is that many teams are integrating agents into workflows where they inherit permissions far beyond what their actual tasks require. An agent that labels and triages issues needs read access and label write access. It does not need release artifact permissions or the ability to approve PRs. The principle of least privilege applies to AI agents at least as much as it does to service accounts, but the tooling to scope agent permissions precisely is still immature.\n\n\n\nThe GHSA advisory albinowax linked about the self-propagation angle makes this worse. Once the agent can be turned against the repository it's supposed to protect, you're looking at a persistence mechanism that survives rotations and reviews that would catch traditional backdoors.",
          "score": 2,
          "created_utc": "2026-02-20 13:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67uj2s",
          "author": "albinowax",
          "text": "I love the implication that OpenClaw might be self-propagating https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7",
          "score": 4,
          "created_utc": "2026-02-19 10:07:26",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r640ry",
      "title": "sandboxec: A lightweight command sandbox for Linux, secure-by-default, built on Landlock.",
      "subreddit": "netsec",
      "url": "https://gh.dw1.io/sandboxec",
      "author": "dwisiswant0",
      "created_utc": "2026-02-16 08:17:28",
      "score": 18,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r640ry/sandboxec_a_lightweight_command_sandbox_for_linux/",
      "domain": "gh.dw1.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5zt457",
          "author": "atxweirdo",
          "text": "I think these kind of projects are needed in the OS space however locking it down to the point where it can't access any files or communicate with other processes kinda takes the functionality out of the agent flow on desktops. \nHowever I'm sure there is a happy medium to be found",
          "score": 1,
          "created_utc": "2026-02-18 04:01:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60i1yc",
              "author": "dwisiswant0",
              "text": "agree. the whole move of this is explicit access.\n\n\\> I'm sure there is a happy medium to be found\n\nyes, there actually seems to be a path for this already (I probably forgot to mention it in the README), my best tip is to run it with \\`strace\\` to identify the minimal allowlist and then make it persistent in the config, something like this: https://github.com/dwisiswant0/sandboxec/blob/master/profiles/claude.yaml.",
              "score": 2,
              "created_utc": "2026-02-18 07:11:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o66mh48",
                  "author": "atxweirdo",
                  "text": "O nice! I will be playing with it over the weekend, and will follow up on the GitHub if I come across anything",
                  "score": 1,
                  "created_utc": "2026-02-19 03:56:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r5fa5e",
      "title": "Product engineering teams must own supply chain risk",
      "subreddit": "netsec",
      "url": "https://www.hyperact.co.uk/blog/product-engineering-teams-must-own-supply-chain-risk",
      "author": "ArtisticProgrammer11",
      "created_utc": "2026-02-15 13:58:37",
      "score": 15,
      "num_comments": 0,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r5fa5e/product_engineering_teams_must_own_supply_chain/",
      "domain": "hyperact.co.uk",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r7jdac",
      "title": "Kraken Darknet Access via Clearnet Gateways ‚Äì some observations",
      "subreddit": "netsec",
      "url": "https://malwr-analysis.com/2026/02/18/kraken-darknet-access-via-clearnet-gateways/",
      "author": "anuraggawande",
      "created_utc": "2026-02-17 21:28:29",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.77,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r7jdac/kraken_darknet_access_via_clearnet_gateways_some/",
      "domain": "malwr-analysis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5yqd00",
          "author": "dirkthedank",
          "text": "that smells like a pile of feds",
          "score": 1,
          "created_utc": "2026-02-18 00:27:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6l5e3",
      "title": "When Audits Fail Part 2: From Pre-Auth SSRF to RCE in TRUfusion Enterprise",
      "subreddit": "netsec",
      "url": "https://www.rcesecurity.com/2026/02/when-audits-fail-from-pre-auth-ssrf-to-rce-in-trufusion-enterprise/",
      "author": "MrTuxracer",
      "created_utc": "2026-02-16 20:36:35",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6l5e3/when_audits_fail_part_2_from_preauth_ssrf_to_rce/",
      "domain": "rcesecurity.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r63te8",
      "title": "Architectural Isolation Tradeoffs in the OpenClaw Ecosystem After CVE-2026-25253",
      "subreddit": "netsec",
      "url": "https://nvd.nist.gov/vuln/detail/CVE-2026-25253",
      "author": "rsrini7",
      "created_utc": "2026-02-16 08:04:58",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r63te8/architectural_isolation_tradeoffs_in_the_openclaw/",
      "domain": "nvd.nist.gov",
      "is_self": false,
      "comments": []
    }
  ]
}