{
  "metadata": {
    "last_updated": "2026-02-23 17:19:57",
    "time_filter": "week",
    "subreddit": "netsec",
    "total_items": 18,
    "total_comments": 60,
    "file_size_bytes": 79754
  },
  "items": [
    {
      "id": "1r7j1zm",
      "title": "Leaking secrets from the claud: AI coding tools are leaking secrets via configuration directories",
      "subreddit": "netsec",
      "url": "https://ironpeak.be/blog/leaking-secrets-from-the-claud/",
      "author": "nindustries",
      "created_utc": "2026-02-17 21:16:50",
      "score": 177,
      "num_comments": 21,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r7j1zm/leaking_secrets_from_the_claud_ai_coding_tools/",
      "domain": "ironpeak.be",
      "is_self": false,
      "comments": [
        {
          "id": "o5ysl81",
          "author": "ruibranco",
          "text": "This is a real blind spot in most dev workflows right now. Tools like Cursor, Copilot, and Claude Code all create local config files (.cursor/, .github/copilot, [CLAUDE.md](http://CLAUDE.md), etc.) that can contain project context, API keys referenced in prompts, or even full conversation logs. Most .gitignore templates haven't caught up to include these directories yet, so they end up committed and pushed without anyone noticing.The fix is straightforward but tedious: audit your .gitignore for every AI tool your team uses, run git log searches for accidentally committed config dirs, and treat these directories the same way you'd treat .env files. Some teams are also adding pre-commit hooks that specifically scan for AI tool artifacts.",
          "score": 49,
          "created_utc": "2026-02-18 00:39:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zpzw6",
              "author": "xortingen",
              "text": "People do blind ‚Äúgit add .‚Äù then blame others/tools.",
              "score": 32,
              "created_utc": "2026-02-18 03:42:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60j0g6",
              "author": "Danielo944",
              "text": "People don't do git status before doing a git add . ?",
              "score": 12,
              "created_utc": "2026-02-18 07:19:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64112s",
                  "author": "psaux_grep",
                  "text": "Or after?\n\nBut also - the amount of people I see who do \n\n    git add .\n    git commit -m ‚Ä¶\n\nInstead of just doing `gc -am` is way too high. And yes, I‚Äôve aliased git commit. Save time where you can ;)",
                  "score": 4,
                  "created_utc": "2026-02-18 19:43:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62jgi1",
              "author": "ClassicPart",
              "text": ">¬†The fix is straightforward but tedious\n\nOh, I know this one: it‚Äôs people actually fucking checking what they commit to repositories instead of blindly adding shit.\n\n>¬†audit your .gitignore for every AI tool your team uses\n\nAh, I guess personal responsibility is off the table then.",
              "score": 5,
              "created_utc": "2026-02-18 15:43:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6u5lar",
              "author": "brophylicious",
              "text": "I've seen those files in my user-wide ~/.claude but never in a project dir. When would those ever go in the project dir?",
              "score": 1,
              "created_utc": "2026-02-22 20:47:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5zq2o1",
              "author": "ko_oktide",
              "text": "I definitely understand the concern here. However, I haven‚Äôt run into this at all. Every time I hard code even an ARN or something in some code Claude yells at me to throw it in an env file. Much less API keys. Also‚Ä¶ this was an issue before AI, but I do agree people will get more complacent with review etc. when they don‚Äôt even have to write the code to begin with.",
              "score": 1,
              "created_utc": "2026-02-18 03:42:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60h59f",
                  "author": "nindustries",
                  "text": "It's not about hardcoding secrets in your code, it's e.g. Claude proposing to run your app with secrets on the CLI, which you whitelist. This whitelist then ends up in .claude/ and could leak those secrets to public repos.",
                  "score": 8,
                  "created_utc": "2026-02-18 07:03:05",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o62tk8f",
                  "author": "Patriark",
                  "text": "The git-commit-push slash command used by Claude team also have some helpful tools to prevent publishing secrets.",
                  "score": 1,
                  "created_utc": "2026-02-18 16:29:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60gdc1",
          "author": "platformuser",
          "text": "The real issue isn‚Äôt just accidental commits. AI tools are creating new classes of sensitive artifacts (prompt logs, project summaries, context caches) that don‚Äôt fit traditional secret-scanning models. \n\nMost orgs updated their .gitignore for .env years ago. Very few have updated their threat models for AI-generated config/state directories.",
          "score": 7,
          "created_utc": "2026-02-18 06:56:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o626w7s",
              "author": "TikiTDO",
              "text": "Since when are logs and intermediate generated files a new class of sensitive artifact? If you're a dev committing sensitive things, that's on you. This whole thing of, \"Oh, my AI did it\" is an absurd cop-out.\n\nThe AI wouldn't have done a thing without your involvement, so no, **you** did it. Your AI was just the vehicle through which you did. If you left secrets in your repo, that's just you being bad at security. \n\nAlso, most secret scanners are doing heuristic based matching. Does this look like a name? Does this look like SSN number? Does this look like a token? The entire point of those is to find secrets in arbitrary places. AI generated files also qualify. These people just aren't running secret scanners, and likely don't even know what those are.\n\nI essentially see this whole thing as another copy of the late 90s and early 2000s. A lot of people are suddenly getting into the field because it's become way easier than it used to be, and are suddenly finding out that real software is fuckin hard, even if an AI handles all the nasty coding for you.",
              "score": 6,
              "created_utc": "2026-02-18 14:43:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o629ada",
                  "author": "platformuser",
                  "text": "I‚Äôm not saying ‚ÄúAI did it‚Äù and responsibility disappears. Devs are still accountable for what they commit.\n\nMy point is just that the shape of sensitive artifacts has changed. Secret scanners are good at catching structured secrets like keys and tokens. What they‚Äôre not always great at is large prompt transcripts, architecture summaries, or context caches that mix proprietary logic and pasted data in natural language.\n\nThose aren‚Äôt secrets in the regex sense, but they can still expose internal systems or client information.\n\nSo yes, it‚Äôs on the developer. I just think the threat model needs to expand as the tooling changes.",
                  "score": 3,
                  "created_utc": "2026-02-18 14:55:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6199fo",
          "author": "thedudeonblockchain",
          "text": "the whitelisted commands angle is the sneakiest part. if you allow claude to run something like STRIPE\\_KEY=sk\\_live\\_xxx in a bash command, that allowlist can live in .claude/settings.local.json in plaintext. trufflehog and gitleaks both need explicit rules for these dirs since most default configs skip dot-paths",
          "score": 3,
          "created_utc": "2026-02-18 11:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66fo08",
          "author": "dexgh0st",
          "text": "The interesting thing about the AI tool case is that secrets aren't always in obvious key=value format. They end up embedded in conversation context, prompt histories, and command allowlists in ways that regex-based scanners (gitleaks, trufflehog) don't pattern-match well. A Stripe key inside a JSON blob inside a conversation log is several layers of indirection past what most scanning rules expect.\n\nThe .gitignore fix is necessary but insufficient -- only protects future commits, not historical ones. Worth running `git log --all --diff-filter=A -- \"*.json\" \"*.md\"` piped through your scanner periodically. And for compiled artifacts (mobile apps, Docker images), secrets baked into the build are an entirely separate exposure surface that repo-level scanning never touches.",
          "score": 2,
          "created_utc": "2026-02-19 03:14:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6468yg",
          "author": "schwar2ss",
          "text": "Check out embracethered, Johann was conducting a few tests in August 2025 and found these issues (yolo mode, data leak, execution of downloaded binaries) in all coding tools. For a talk in September, I showcased a similar attack exfiltrating the entire .ssh folder for a staged lateral attack. \n\nIt's a whack-a-mole game and will give us plenty of work for the next decade or so.",
          "score": 1,
          "created_utc": "2026-02-18 20:07:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s5n55",
          "author": "peregrinefalco9",
          "text": "The .claude and .cursor directories are the new .env files. Developers commit them without thinking because they look like config, not secrets. Every AI coding tool needs a .gitignore template that ships by default.",
          "score": 1,
          "created_utc": "2026-02-22 15:09:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbjdso",
      "title": "How a single typo led to RCE in Firefox",
      "subreddit": "netsec",
      "url": "https://kqx.io/post/firefox0day/",
      "author": "campuscodi",
      "created_utc": "2026-02-22 11:19:49",
      "score": 135,
      "num_comments": 12,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1rbjdso/how_a_single_typo_led_to_rce_in_firefox/",
      "domain": "kqx.io",
      "is_self": false,
      "comments": [
        {
          "id": "o6skguw",
          "author": "winky9827",
          "text": "To be fair, it may only be a single character, but that character is an *operator*. Mixing up operators in any code will lead to bad juju. The depth and lack of instant visibility here is the masking factor.",
          "score": 59,
          "created_utc": "2026-02-22 16:17:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6twa9r",
              "author": "brophylicious",
              "text": "I wonder if the missing semi colon in that major openssl bug would be considered a typo.",
              "score": 3,
              "created_utc": "2026-02-22 20:00:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6v126g",
              "author": "[deleted]",
              "text": "[removed]",
              "score": -8,
              "created_utc": "2026-02-22 23:32:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rjr0h",
          "author": "peregrinefalco9",
          "text": "One character off and you go from a working check to a full RCE chain. This is why code review alone will never catch everything - the human eye skips single-character diffs. Static analysis tooling should flag any mutation in bounds checks as high priority by default.",
          "score": 26,
          "created_utc": "2026-02-22 13:03:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ts5g0",
          "author": "0xcrypto",
          "text": "Once I found a bug in laravel where a single dot missing led to validation bypass. https://github.com/laravel/framework/pull/37675.\n\nUnfortunately huntr.dev lost my report so its a 404 now.",
          "score": 8,
          "created_utc": "2026-02-22 19:39:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sgnp3",
          "author": "ruibranco",
          "text": "The diff between a safe bounds check and an off-by-one that turns exploitable is often literally one character ‚Äî which is the strongest practical argument for memory-safe languages by default rather than relying on review to catch what the eye naturally glosses over.",
          "score": 11,
          "created_utc": "2026-02-22 16:00:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v1058",
              "author": "[deleted]",
              "text": "[removed]",
              "score": -4,
              "created_utc": "2026-02-22 23:32:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v13pu",
                  "author": "ruibranco",
                  "text": "Go ahead and explain‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-02-22 23:32:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vs8m3",
          "author": "TheG0AT0fAllTime",
          "text": "That's good that it was only in a nightly build and not a major release. I can only imagine the stress if it was in a normal version.",
          "score": 1,
          "created_utc": "2026-02-23 02:11:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra30yn",
      "title": "Your Samsung Weather App Is a Fingerprint: How saved locations create a persistent cross-session tracking identifier",
      "subreddit": "netsec",
      "url": "https://www.buchodi.com/your-samsung-weather-app-is-a-fingerprint/",
      "author": "AdTemporary2475",
      "created_utc": "2026-02-20 18:18:00",
      "score": 122,
      "num_comments": 18,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1ra30yn/your_samsung_weather_app_is_a_fingerprint_how/",
      "domain": "buchodi.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6hmib3",
          "author": "Acct235095",
          "text": "[Welcome back.](https://www.reddit.com/r/netsec/comments/1r7ih5r/samsung_weather_widget_ships_hardcoded_shared_ibm/)\n\nSeems like a privacy problem rather than network security.",
          "score": 29,
          "created_utc": "2026-02-20 20:47:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hr29u",
              "author": "AdTemporary2475",
              "text": "Hey! The hardcoded API keys are what make this a security issue, not just a privacy one. The keys aren‚Äôt bound to any device or session they seem to be constant across user and devices. That means anyone can query the API directly, resolve any placeid to physical coordinates, and spam arbitrary location combinations into their data pipeline. If TWC is using these fingerprints for cross-session tracking or selling behavioral profiles downstream, an attacker can poison that entire dataset at scale. An unauthenticated, unrate-limited API endpoint serving location resolution for 50M+ US devices is a security problem.",
              "score": 19,
              "created_utc": "2026-02-20 21:09:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6mum1h",
                  "author": "MSgtGunny",
                  "text": "Maybe I‚Äôm not reading you‚Äôre write up correctly, but I‚Äôm not seeing the 3rd party (outside of the weather app data gathering) attack/privacy mechanism here for the end user. \n\nEach location point is a random 128bit value, equivalent to a guid as placeid. The placeid is not user specific, it‚Äôs generated from just the lat/long of the saved location right?\n\nSo even though the endpoint is unauthenticated and non-rate-limited, requiring to iterate over the full 128bit guid space, usually makes it not much of an issue, but then on top of that, the response data from each placeid request is anonymous and not tied to any particular user. \n\nIs that a correct understanding of it?",
                  "score": 4,
                  "created_utc": "2026-02-21 17:46:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6mzp3e",
                  "author": "phormix",
                  "text": "Kinda feels like the privacy issue could actually be somewhat solved by the security issue by modifying one's own dataset",
                  "score": 2,
                  "created_utc": "2026-02-21 18:12:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6nhsml",
          "author": "peregrinefalco9",
          "text": "This is wild but not surprising. The combination of saved locations is basically a unique tuple for most users. Curious if this persists after a factory reset or if it's tied to Samsung account sync. Either way, this is the kind of side-channel fingerprinting that GDPR regulators should be looking at way more seriously.",
          "score": 3,
          "created_utc": "2026-02-21 19:41:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6nz7ng",
              "author": "AdTemporary2475",
              "text": "Exactly!",
              "score": 2,
              "created_utc": "2026-02-21 21:13:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6qp4lj",
              "author": "Glathull",
              "text": "GDPR really shouldn‚Äôt engage with any specific mechanism at all. The law will never keep up with the implementation. The law should target the behavior and make that illegal. ‚ÄúDon‚Äôt fingerprint users.‚Äù",
              "score": 2,
              "created_utc": "2026-02-22 08:26:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qtale",
                  "author": "peregrinefalco9",
                  "text": "That's a good distinction. Targeting the behavior instead of the mechanism makes enforcement way more durable. The ePrivacy Directive technically already covers this under 'storing or accessing information on a user's device' but enforcement has been almost entirely focused on cookies. Side-channel stuff like this flies under the radar because regulators don't have the technical capacity to detect it.",
                  "score": 1,
                  "created_utc": "2026-02-22 09:06:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pdsho",
          "author": "code_investigator",
          "text": "What isn't these days",
          "score": 3,
          "created_utc": "2026-02-22 02:13:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mdmar",
          "author": "eagle33322",
          "text": "everything is a fingerprint",
          "score": 3,
          "created_utc": "2026-02-21 16:21:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qz9si",
          "author": "SkinnyDany",
          "text": "Isn't this privacy issue common to any weather app, or any app that allows a user to have information regarding a set of places? I mean, any app that sends a specific set of values to a server (be it geocoordinates, places names, hashes, or anything else...) can be used to track users, right? If I understand correctly, the main issue is that the more you have specific saved places, the more you can be identified.\n\n\nIs what makes it especially concerning in this case are the facts that it comes preinstalled in a lot of devices, and that the company behind it has been accused regularily under the spotlight for selling user data?\n\n\nWhat could someone do to protect themselves from being tracked in such a way, except uninstall this specific app? Research the weather app they install and the company behind it? So for instance, using a weather app that uses a weather API which company behind it is not famous for selling user data (like OpenWeatherMap or Open-Meteo) should be sufficient?",
          "score": 2,
          "created_utc": "2026-02-22 10:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rouef",
          "author": "Proper_Shopping_6183",
          "text": "How is this any different than your Google account that is tied to your Samsung Android phone. Your Google account maps every inch of location tracking. Google can tell me exactly where I wa sat what time on any given day. Its turned on by default, Its buried in the user settings and on all the time. ",
          "score": 2,
          "created_utc": "2026-02-22 13:36:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qmapo",
          "author": "dexgh0st",
          "text": "Solid research. This is a textbook OWASP MASVS violation across multiple categories - the hardcoded API keys alone are a storage issue (MSTG-STORAGE-1), but the real problem is the confluence of weak entropy in the fingerprint generation and lack of request signing. I'd be curious if you pulled the APK and ran it through jadx to check whether the placeids are generated client-side or just consumed from the API response - that distinction matters for whether this is an API design flaw or an app-level tracking vector Samsung introduced intentionally. The coordinate redundancy you mention is especially damning; that's not defensive programming, that's just logging location data twice. For anyone replicating this, frida hooks on the HTTP client would let you intercept and log the full request/response cycle in real-time without needing to parse network traffic. Did you check whether the placeid scheme is deterministic per location, or does it vary across devices querying the same place? If it's deterministic, that's a separate information disclosure issue - attackers could precompute a placeid database and correlate users.",
          "score": 1,
          "created_utc": "2026-02-22 08:00:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9wmyj",
      "title": "In Memoriam: Jason Snitker, a.k.a. Parmaster. RIP Legend",
      "subreddit": "netsec",
      "url": "https://professorsigmund.com/field-notes/in-memoriam-parmaster.html",
      "author": "Professor_Sigmund",
      "created_utc": "2026-02-20 14:21:47",
      "score": 88,
      "num_comments": 4,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r9wmyj/in_memoriam_jason_snitker_aka_parmaster_rip_legend/",
      "domain": "professorsigmund.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6h66zb",
          "author": "fecalreceptacle",
          "text": "RIP to a legend",
          "score": 2,
          "created_utc": "2026-02-20 19:27:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hbpsj",
          "author": "catwiesel",
          "text": "legend indeed. RIP",
          "score": 2,
          "created_utc": "2026-02-20 19:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mfv3j",
          "author": "AnyConsideration2235",
          "text": "RIP legend üôáüèΩ‚Äç‚ôÇÔ∏è",
          "score": 1,
          "created_utc": "2026-02-21 16:32:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6illoe",
          "author": "intelw1zard",
          "text": "RIP and have fun in hacker heaven",
          "score": 0,
          "created_utc": "2026-02-20 23:51:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra5k54",
      "title": "Why AI agent containers need a syscall-level observer: the prompt injection blind spot",
      "subreddit": "netsec",
      "url": "https://itnext.io/runtime-tracing-for-ai-agents-what-your-openclaw-agent-actually-does-inside-the-container-aebabb8977f2",
      "author": "M4r10_h4ck",
      "created_utc": "2026-02-20 19:51:18",
      "score": 71,
      "num_comments": 10,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1ra5k54/why_ai_agent_containers_need_a_syscalllevel/",
      "domain": "itnext.io",
      "is_self": false,
      "comments": [
        {
          "id": "o6ho47u",
          "author": "jdefr",
          "text": "Alright but I am somewhat averse to security products that seem mostly ‚ÄúVibe Coded‚Äù which this seems to have been by looking at git history and such‚Ä¶ Don‚Äôt get me wrong it‚Äôs a great idea and stuff . Now, if you used agentic coding mostly as a check and you genuinely understand every line in the codebase. That‚Äôs different.",
          "score": 18,
          "created_utc": "2026-02-20 20:55:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hy9n8",
              "author": "M4r10_h4ck",
              "text": "Fair point, and it‚Äôs a legitimate concern for security tooling. Let me be transparent about it.\nYes, agentic coding was part of the workflow. But the git history also shows the test suite: 80% unit test coverage, integration tests that spin up a real container, run a malware behavior simulator, and assert that every expected event type was actually captured. Linter and security scan on every PR. All in CI, you can check it yourself.\nThe eBPF programs and the cgroup filtering logic were the parts I reviewed most carefully line by line, because that‚Äôs where a subtle bug would actually matter from a security perspective. That‚Äôs not something you can ship on vibes and hope for the best.\nThe idea that agentic coding and actually understanding your codebase are mutually exclusive is worth pushing back on. The question is whether the author can reason about what the code does and why. Happy to go deep on any specific part if you want to probe that.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
              "score": -10,
              "created_utc": "2026-02-20 21:45:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6idsiu",
                  "author": "Dangle76",
                  "text": "Unit test coverage is meaningless if it‚Äôs mostly agentic code. Agents will write tests so that they pass a lot of the time, even if the test itself doesn‚Äôt actually test your code properly. It ‚Äúfixes‚Äù the test not the thing it‚Äôs testing a lot",
                  "score": 17,
                  "created_utc": "2026-02-20 23:06:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6jdv1s",
                  "author": "kent_stor",
                  "text": "The response here I feel is very likely written by a bot, based on the wording I'd guess a GPT model. So the whole \"I reviewed most carefully line by line\" is a load of crap.",
                  "score": 3,
                  "created_utc": "2026-02-21 02:43:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6innp5",
          "author": "viziroth",
          "text": "better idea is to just stop giving AI agents access to anything production facing or able to make any infrastructure changes\n\neven better, just stop using something that doesn't actually understand code to code",
          "score": 12,
          "created_utc": "2026-02-21 00:03:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jk80h",
          "author": "KingOfKingOfKings",
          "text": "get out of here with your slop post of slop code to validate slop",
          "score": 7,
          "created_utc": "2026-02-21 03:24:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kkdds",
              "author": "M4r10_h4ck",
              "text": "You are the king of king of stupid! Show me your code!",
              "score": 1,
              "created_utc": "2026-02-21 08:22:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6r7no",
      "title": "Almost Impossible: Java Deserialization Through Broken Crypto in OpenText Directory Services",
      "subreddit": "netsec",
      "url": "https://slcyber.io/research-center/almost-impossible-java-deserialization-through-broken-crypto-in-opentext-directory-services/",
      "author": "Mempodipper",
      "created_utc": "2026-02-17 00:34:23",
      "score": 69,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6r7no/almost_impossible_java_deserialization_through/",
      "domain": "slcyber.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5sqytq",
          "author": "SuperDrewb",
          "text": "Extremely impressive¬†",
          "score": 6,
          "created_utc": "2026-02-17 02:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u4dog",
          "author": "Few-Gap-5421",
          "text": "Nice research man",
          "score": 4,
          "created_utc": "2026-02-17 09:00:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r74ifj",
      "title": "Log Poisoning in OpenClaw",
      "subreddit": "netsec",
      "url": "https://research.eye.security/log-poisoning-in-openclaw/",
      "author": "vaizor",
      "created_utc": "2026-02-17 12:19:40",
      "score": 49,
      "num_comments": 19,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r74ifj/log_poisoning_in_openclaw/",
      "domain": "research.eye.security",
      "is_self": false,
      "comments": [
        {
          "id": "o60gmvi",
          "author": "platformuser",
          "text": "This is a broader class of issue than just OpenClaw.\n\nAny agent that ingests its own logs, tool output, or environment artifacts is effectively expanding its prompt surface to include untrusted data.\n\nTraditional logging assumes ‚Äúhumans read logs.‚Äù Agentic systems blur that boundary. Once logs become model input, they‚Äôre no longer passive telemetry  they‚Äôre an attack vector.\n\nTreat anything an agent can read as part of the prompt boundary.",
          "score": 11,
          "created_utc": "2026-02-18 06:58:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wns2l",
          "author": "si9int",
          "text": "Another viby nail into the coffin of OpenClaw. I don't get the hype; srsly .. The idea might be interesting, but the implementation is a disaster.",
          "score": 29,
          "created_utc": "2026-02-17 18:19:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o633rvp",
              "author": "VoidVer",
              "text": "Idiots are excited to have the computer think for them, not understanding that will make them disposable and even stupider than they already are.",
              "score": 4,
              "created_utc": "2026-02-18 17:15:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xdnrf",
              "author": "deneuralizer",
              "text": "There are quite a few forks coming out made in Rust, Go, which are supposed to be more secure. I am going to give ZeroClaw a shot",
              "score": -18,
              "created_utc": "2026-02-17 20:20:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xthow",
                  "author": "ziirex",
                  "text": "Rust and Go would mainly help if the issues were memory safety related, but the whole concept is quite risky by design. Fixes would need a major rearchitecture at which point it's a stretch to call them forks in my opinion.",
                  "score": 22,
                  "created_utc": "2026-02-17 21:35:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vyluv",
          "author": "thedudeonblockchain",
          "text": "the read/write access argument cuts both ways - yes it's a personal project, but once users deploy it in any networked or automated context (which full rw implicitly encourages), the log poisoning surface becomes a real downstream risk. logs that feed into SIEMs, dashboards, or monitoring pipelines are classic lateral movement paths once you control the content. the takeaway is probably less about enterprise hardening and more about surfacing default-safe configs even in experimental tools - write access in particular should require explicit opt-in.",
          "score": 15,
          "created_utc": "2026-02-17 16:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wflt9",
              "author": "[deleted]",
              "text": "[removed]",
              "score": -1,
              "created_utc": "2026-02-17 17:42:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5wi9xx",
                  "author": "rejuicekeve",
                  "text": "You'll say that without actually reporting the post for us to review like a big jabroni",
                  "score": 17,
                  "created_utc": "2026-02-17 17:54:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5wfrm8",
                  "author": "thedudeonblockchain",
                  "text": "What are you talking about man",
                  "score": 1,
                  "created_utc": "2026-02-17 17:42:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xljl3",
          "author": "InterSlayer",
          "text": "Theres a fridman interview with steinberger where he talks about having to rename repos, then the old names got sniped and started spreading malware. Then feeling distraught and wanting to just drop the whole project. üò±",
          "score": 1,
          "created_utc": "2026-02-17 20:58:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v9jmv",
          "author": "hankyone",
          "text": "The cybersecurity industry treating a one man open source experiment created 80 days ago for shits and giggles like it should have enterprise grade security",
          "score": -23,
          "created_utc": "2026-02-17 14:10:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vpi9o",
              "author": "sarcasmguy1",
              "text": "When the tool has full read/write access, and encourages you to configure it as such, then yes it should have a level of security thats close to enterprise",
              "score": 34,
              "created_utc": "2026-02-17 15:32:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w10c3",
                  "author": "Hizonner",
                  "text": "Difficulty: there is no way to make that tool even vaguely close safe for anything, period, and leaking random stuff into logs is not in the top 1000 exposures.",
                  "score": 15,
                  "created_utc": "2026-02-17 16:29:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5zwje4",
              "author": "imsoindustrial",
              "text": "Idk why you‚Äôre getting downvoted and I am a cynical fuck with decades of cybersecurity experience.",
              "score": 4,
              "created_utc": "2026-02-18 04:24:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o604jze",
                  "author": "hankyone",
                  "text": "The AI relationship perhaps?\n\nI thought Reddit was weird with AI but seems it‚Äôs also the whole infosec industry",
                  "score": 2,
                  "created_utc": "2026-02-18 05:20:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o647ymf",
              "author": "ZestyTurtle",
              "text": "Yeah, I agree. This is a one man open source toy that‚Äôs barely a few months old, not an enterprise product.\n\nIf someone deploy it, wire it into real systems, feed it untrusted input and don‚Äôt think about a threat model (and secure it accordingly), that‚Äôs on him. \n\nActing shocked that an experimental AI agent doesn‚Äôt magically have enterprise grade security is missing the point. The responsibility is on the operator, not the hobby project.",
              "score": 2,
              "created_utc": "2026-02-18 20:15:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9qkpl",
      "title": "Your AD password complexity policies are security theater ‚Äî one RPC call bypasses all of them (PoC scripts + defense included)",
      "subreddit": "netsec",
      "url": "https://simpity.eu/blog/ad-password-policies-security-theater",
      "author": "Suitable-Baker7584",
      "created_utc": "2026-02-20 09:12:02",
      "score": 45,
      "num_comments": 14,
      "upvote_ratio": 0.66,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r9qkpl/your_ad_password_complexity_policies_are_security/",
      "domain": "simpity.eu",
      "is_self": false,
      "comments": [
        {
          "id": "o6e9fy9",
          "author": "cym13",
          "text": "Ok so someone with the rights to change a given account's password can push a raw hash for that account.\n\nWhile I appreciate the distinction between NTLM protocol and NTLM hash, I'm having trouble understanding the threat presented here. If I can push a hash of my choosing, I can just push a hash that I know the password so this isn't about account takeover. And it has to be an account I can change the password for, so there's no permission bypass here.\n\nYou can, indeed, voluntarily weaken your own password through an unorthodox procedure. That has no bearing on most users and doesn't make existing hashes that follow policy easier to crack. That's also not discreet as the user who's password you change will notice that their password has changed (and probably change it in return).\n\nMaybe there's a scenario where you use malware to change someone's password to something easier to crack, but again why change it to something you have to crack at all?\n\nSorry, but I really don't see the problem. If the only way to escape policy is through a non-standard procedure that requires proper authorization, then there's no security theater at play. You can voluntarily downgrade your own password. It would probably be better if it wasn't the case, but it doesn't invalidate the impact of the policy at scale, and if your goal is to facilitate someone breaking into your account, just give them the password. It'll leave less traces than changing your own password to something easier to crack.",
          "score": 57,
          "created_utc": "2026-02-20 09:46:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft8h6",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 6,
              "created_utc": "2026-02-20 15:43:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fwzto",
                  "author": "cym13",
                  "text": "Ok, that I can get behind. But it has nothing to do with the type of hash used or the complexity of the password.",
                  "score": 1,
                  "created_utc": "2026-02-20 16:00:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ed4r7",
              "author": "Potato-9",
              "text": "Indeed. It would be nice if it was easy enough to know what was calling https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-samr/538222f7-1b89-4811-949a-0eac62e38dce or what programs have that call in them so I don't run them as domain admin.\n\nCustom password filter DLLs checking against breached dictionaries? Never invoked. Is kind of a big deal out that api is easy to expose accidentally.",
              "score": 4,
              "created_utc": "2026-02-20 10:19:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gmgg6",
          "author": "AYamHah",
          "text": "So you can intentionally set a weak password by entering a hash for it. But you already have access to update this accounts password. Why do you care to go around setting weak passwords for yourself or accounts you control? On an engagement, creating a service account with a weak password on the client's network would result in your firm losing the client and you losing your job. You wanted persistance with \"password123\"? - get outta here.",
          "score": 19,
          "created_utc": "2026-02-20 17:57:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f5vh8",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 13,
          "created_utc": "2026-02-20 13:45:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gpspc",
              "author": "intelw1zard",
              "text": "This is an AI account that posts comments. It's not a real person.",
              "score": 5,
              "created_utc": "2026-02-20 18:12:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6gcqgr",
              "author": "I_Will_Eat_Your_Ears",
              "text": "Sorry, but I think I'm missing something. If you're post-DA, why is complexity enforcement a concern?\n\nWhy do you want to crack a kerberos ticket if you already know the password? \n\nI may be mistaken, but it sounds like this flow is for demonstration purposes, and setting the credential isn't something an actual attacker would do",
              "score": 3,
              "created_utc": "2026-02-20 17:12:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kfg0m",
          "author": "meutrei",
          "text": "[Suitable-Baker7584](https://www.reddit.com/user/Suitable-Baker7584/): Could you provide us with the .zip files (or source code) directly / GitHub etc? The download links on the website are blank.  \nFor research purposes & test EDR etc?",
          "score": 2,
          "created_utc": "2026-02-21 07:34:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6l59sw",
          "author": "CeleryMan20",
          "text": "I don‚Äôt get it. \n\nNormal operation: user sets new password on PC, PC sends new hash to DC via SMB. \n\n‚ÄúEnhanced‚Äù operation: hash update blocked by hooking LSASS on the DC? How do users set new passwords?",
          "score": 2,
          "created_utc": "2026-02-21 11:45:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ly4m1",
          "author": "alnarra_1",
          "text": "> The only requirement is Password Reset permissions on the target account\n\n\n‚Ä¶ \n\n\n‚Ä¶.\n\n\nOk so this isn‚Äôt an attack, this is and administrative action. If I can reset the password to whatever I want, it doesn‚Äôt matter what the password complexity is because I know the password. \n\nThis is that sort of ‚ÄúAnd if you have domain admin suddenly the dc is vulnerable‚Äù type nonsense",
          "score": 2,
          "created_utc": "2026-02-21 15:01:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hnj8d",
          "author": "Pink_Zepellica",
          "text": "I find the concept interesting especially from a defense evasion standpoint. I wanted to take a look at the password change script but the links don't work. OP, are you the original author, do you have the script?",
          "score": 1,
          "created_utc": "2026-02-20 20:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fbdp6",
          "author": "dydhaw",
          "text": "All password policies are security theater.",
          "score": -5,
          "created_utc": "2026-02-20 14:14:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6flhll",
              "author": "bosconet",
              "text": "note: only when humans are involved in a system are they security theater.... :-) ",
              "score": 1,
              "created_utc": "2026-02-20 15:06:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6g3jm3",
          "author": "Oriumpor",
          "text": "Password complexity isn't useful¬†",
          "score": -5,
          "created_utc": "2026-02-20 16:30:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r92evr",
      "title": "[CVE-2026-0714] TPM-sniffing LUKS Keys on an Embedded Device",
      "subreddit": "netsec",
      "url": "https://www.cyloq.se/en/research/cve-2026-0714-tpm-sniffing-luks-keys-on-an-embedded-device",
      "author": "AlmondOffSec",
      "created_utc": "2026-02-19 15:38:01",
      "score": 44,
      "num_comments": 1,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r92evr/cve20260714_tpmsniffing_luks_keys_on_an_embedded/",
      "domain": "cyloq.se",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r745t9",
      "title": "Prompt Injection Standardization: Text Techniques vs Intent",
      "subreddit": "netsec",
      "url": "https://www.lasso.security/blog/prompt-injection-taxonomy-techniques",
      "author": "Equivalent_Cover4542",
      "created_utc": "2026-02-17 12:02:09",
      "score": 38,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r745t9/prompt_injection_standardization_text_techniques/",
      "domain": "lasso.security",
      "is_self": false,
      "comments": [
        {
          "id": "o5w2sg4",
          "author": "thedudeonblockchain",
          "text": "the technique vs intent split hits on a core problem in prompt injection defense: the same text sequence can be benign or malicious depending on context, which makes purely syntactic detection brittle. what makes this particularly hard is multi-step indirect injections where neither the technique nor the intent is legible from a single interaction - the payload arrives in one turn, gets stored (retrieval, memory, tool output), and executes in a later turn in a completely different context. at that point you need to track provenance of content through the entire execution graph to reason about intent, which most current defenses don't do. the taxonomy is still useful for threat modeling and red-teaming even if it doesn't directly map to detection primitives - knowing whether you're dealing with a role-play jailbreak vs translation obfuscation vs indirect injection tells you which system components to harden first.",
          "score": 3,
          "created_utc": "2026-02-17 16:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61nan3",
              "author": "redyellowblue5031",
              "text": "Where have we seen that before‚Ä¶.",
              "score": 1,
              "created_utc": "2026-02-18 12:57:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uvncu",
          "author": "anyore909",
          "text": "The technique vs intent distinction makes sense. translation-based attacks and role-play jailbreaks may aim for the same outcome, but they work very differently. Structuring it this way makes the problem easier to reason about.",
          "score": 2,
          "created_utc": "2026-02-17 12:50:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wlc4p",
          "author": "ozgurozkan",
          "text": "The provenance tracking point is critical and often overlooked. Most organizations are focused on input sanitization, but the real danger is in persistence mechanisms where injected content gets written to context stores, vector databases, or agent memory.\n\n\n\nFrom a practical red team perspective, the highest success rate attacks I've seen combine two or three techniques in sequence. Start with translation obfuscation to bypass basic filters, use role play to establish a trusted context, then inject the actual payload through indirect means so it appears to come from a legitimate data source rather than user input.\n\n\n\nThe hardest part about defending against this is that effective mitigation requires architectural changes, not just better prompts. You need content signing, strict output encoding based on destination context, and proper separation between instruction channels and data channels. But most production systems treat everything as a string and hope prompt engineering will save them.\n\n\n\nThe taxonomy helps because it forces you to think about attack chains rather than individual techniques. Defense in depth means breaking the chain at multiple points, which means you need to map your architecture to the attack surface this framework describes.",
          "score": 2,
          "created_utc": "2026-02-17 18:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f65wm",
          "author": "ozgurozkan",
          "text": "The technique vs intent taxonomy is useful but the real challenge in operationalizing this for detection is that the classification boundary is context-dependent and shifts with each model update.\n\n\n\nWhat I find more actionable is thinking about prompt injection in terms of trust boundary violations rather than textual features. The core issue is that LLM systems conflate data and instruction planes, and there's no enforced separation the way there is in, say, SQL parameterized queries. When a retrieval step can modify the instruction context without going through a separate validation layer, you have a structural vulnerability regardless of how the injected text looks.\n\n\n\nFor agentic systems specifically, the attack surface expands significantly because injected content can persist across tool calls and context windows. A payload that lands in a memory store during one session can execute in a completely different security context later. This is where purely text-technique-based defenses fail: the payload is dormant and innocuous at storage time.\n\n\n\nThe intent classification approach makes more sense for training-time or fine-tuning mitigations, but for runtime detection you really want to be monitoring for behavioral anomalies: unusual tool call sequences, unexpected data exfiltration patterns, privilege escalation in capability use. The taxonomy in this post is a solid framework for building red team test cases though.",
          "score": 0,
          "created_utc": "2026-02-20 13:46:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r89vac",
      "title": "CRESCENTHARVEST: Iranian protestors and dissidents targeted in cyberespionage campaign",
      "subreddit": "netsec",
      "url": "https://www.acronis.com/en/tru/posts/crescentharvest-iranian-protestors-and-dissidents-targeted-in-cyberespionage-campaign/",
      "author": "bagaudin",
      "created_utc": "2026-02-18 17:46:52",
      "score": 36,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r89vac/crescentharvest_iranian_protestors_and_dissidents/",
      "domain": "acronis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o64iro8",
          "author": "ruibranco",
          "text": "the persistence mechanism here is pretty clever - using NetworkProfile event triggers (EventID 10000) instead of the usual run keys or startup folders means it only fires when connectivity is available, which makes sense for a campaign targeting people in a country with frequent internet shutdowns. no point phoning home if there's no internet.the DLL sideloading through google's own software\\_reporter\\_tool.exe is also notable. using a legitimately signed binary as the loader makes it way harder for endpoint protection to flag the execution chain. similar technique to what check point documented in earlier iranian campaigns but the chrome encryption bypass module is a newer addition.",
          "score": 5,
          "created_utc": "2026-02-18 21:06:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67eoo5",
          "author": "throwaway_88331",
          "text": "Im in Iran and I cant access the site without a VPN:\n\nError: Forbidden\nYour client does not have permission to get URL /en/tru/posts/crescentharvest-iranian-protestors-and-dissidents-targeted-in-cyberespionage-campaign/ from this server.\n\nThe funny thing is that the standard explanation of \"the IRGC will hack them\" falls flat on the fact that IRGC has access to better VPNs than I do and botnets across all of the west.",
          "score": 3,
          "created_utc": "2026-02-19 07:33:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o678pwn",
          "author": "panix187",
          "text": "Did Acronis get bought buy somebody?  Seems weird for a backup company to be putting out security bulletins.",
          "score": 1,
          "created_utc": "2026-02-19 06:41:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67vy3w",
              "author": "474Dennis",
              "text": "Acronis currently offers a complete cyber security stack. The company began integrating such features in 2017.  \nDisclosure: I work at Acronis and I am a mod of r/Acronis",
              "score": 3,
              "created_utc": "2026-02-19 10:20:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6k4z9",
      "title": "nono - kernel-enforced capability sandbox for AI agents",
      "subreddit": "netsec",
      "url": "https://nono.sh",
      "author": "DecodeBytes",
      "created_utc": "2026-02-16 19:59:20",
      "score": 28,
      "num_comments": 10,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6k4z9/nono_kernelenforced_capability_sandbox_for_ai/",
      "domain": "nono.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o5qqi2n",
          "author": "Otherwise_Wave9374",
          "text": "This is super timely. The whole \"agent has my full shell\" thing is the part that makes me nervous about coding agents in real workflows, prompt injection or not. Kernel-level deny-by-default (Landlock/Seatbelt) seems like the right layer to enforce it. Curious if youve tested weird edge cases like build tools that spawn helpers, symlink-heavy repos, or language servers that want to read dotfiles.\n\nAlso if you end up writing up the threat model tradeoffs, Id read it, Ive been collecting agent security notes and patterns here: https://www.agentixlabs.com/blog/",
          "score": 6,
          "created_utc": "2026-02-16 20:04:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qunn6",
              "author": "DecodeBytes",
              "text": "\\> Curious if youve tested weird edge cases like build tools that spawn helpers, symlink-heavy repos, or language servers that want to read dotfiles.\n\nAhh yeah, symlinks are the biggest ache\n\nWhen granted access to a path that's actually a symlink, we always resolve it to the real location immediately. We do this atomically rather than checking existence separately, which would create a window where an attacker could swap the symlink between our check and resolution.\n\nOn macOS, the sandbox enforces against literal path strings rather than resolved paths. So we store both the original path and the resolved real path, then emit sandbox rules for both. Without this, granting access via the real path would still block programs trying to use the symlink.\n\nWe also use proper path component comparison rather than string comparison when checking path relationships.  String prefix matching would incorrectly match paths that just happen to share the same starting characters but aren't actually descendants of the directory in question.\n\nWe also handle parent directory traversal. To access a deeply nested path, programs need to stat each parent directory along the way. We automatically allow metadata-only access to parent directories of granted paths, walking both the original and resolved path hierarchies when they differ.\n\nTaking a look at the blog thanks!   ",
              "score": 2,
              "created_utc": "2026-02-16 20:24:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5rngbq",
          "author": "bagbogbo",
          "text": "Been looking for something like this!",
          "score": 1,
          "created_utc": "2026-02-16 22:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5rtyug",
              "author": "DecodeBytes",
              "text": "cool! let me know if you need any more info or help. ",
              "score": 2,
              "created_utc": "2026-02-16 23:23:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uuiqu",
          "author": "One_Strike_1322",
          "text": "how does this compare to, say using the cursor docker container? To me, a container is easier and more portal to set up but I'd be keen to hear where this is better (obviously containers aren't a sandbox mechanism but they do help).",
          "score": 1,
          "created_utc": "2026-02-17 12:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v67rm",
              "author": "DecodeBytes",
              "text": "Containers and nono solve overlapping but distinct problems, and each has real trade-offs worth considering. There is a section in the docs on this: https://docs.nono.sh/security/containers \n\nContainers give you isolation through namespacing - the process sees a different filesystem root, network stack, and process tree. This is powerful for reproducibility and portability. You can ship a known-good environment, and anything the AI does stays inside that container's view of the world. The downside is that containers are coarse-grained. You either mount a volume into the container or you don't. There's no easy way to say \"read the whole project but only write to the src directory\" or \"access ~/.vscode , but not ~/.ssh/.\" You end up either over-permissioning (mounting your whole home directory) or dealing with friction every time the AI needs something outside the container.\n\nnono takes the opposite approach - it runs natively on your host but uses OS-level mandatory access control (Landlock on Linux, Seatbelt on macOS) to enforce fine-grained capabilities. You can grant read access to your entire codebase while restricting writes to specific directories, block access to credentials and browser data regardless of what commands run, and allow network access while still protecting sensitive local paths. The sandbox is applied to the process itself, not to a virtualized environment, so there's no filesystem copying, no Docker daemon, and near-zero startup overhead. \n\nWhere nono is stronger: granularity. You can express policies like \"read everywhere, write only here, never touch my SSH keys\" that would be awkward or impossible with container volume mounts. It also integrates more naturally with local tooling - your shell, your editor, your existing workflows all just work. \n\nWhere containers are stronger: they provide a complete environment boundary. If the AI installs a malicious package or corrupts system files, it's contained to that throwaway environment. With nono, you're still running on your real system - the sandbox prevents unauthorized access, but if you grant write access to a directory, the AI can still make a mess there (having said that we have an atomic undo system incoming).\n\nThe honest answer is they're complimentary. You can run nono inside a container for defense in depth, or use nono alone when you want lightweight, precise control without the overhead of containerization. It depends on which you value portability and environment isolation (containers) or fine-grained capability control with minimal friction (nono). \n\nThe other factor is nono has a load of other features thrown in, key protection, blocking of dangerous commands, and quite a bit more inbound. \n\nBut honestly, if containers are working, great! I am a fan and its never x vs y here, each have their own strengths.",
              "score": 2,
              "created_utc": "2026-02-17 13:52:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v4ewn",
          "author": "sexy_lady_at_aol_com",
          "text": "Do you know how we might prevent a rogue agent from leaking secrets that have been made available to it? \n\nFor example, say claude has been granted the ability to web search, encounters a prompt injection on the web, and then proceeds to POST any credentials we've shared with the bot (in a .env, or similar), to some strange site, or to Github (like the shai-hulud worm).\n\nCould we host an HTTP proxy and allow only certain domains or paths? Can an agent be instructed to persevere and workaround our limitations? \n\nCould we host a HTTP proxy that injects credentials into outgoing HTTP traffic?\n\nCould we upgrade our third party systems to issue the agent some delegated short lived keys and accept the risk?\n\nNone of these sound like great approaches to me, but I'm keen to hear if you or others have any thoughts.",
          "score": 1,
          "created_utc": "2026-02-17 13:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v70r2",
              "author": "DecodeBytes",
              "text": "Proxy is the way to go. Have a key that only the proxy knows of and it map to the real key in a data store on the proxy. \n\nYou would then have the agent populate the Auth Header with the proxy key, and the proxy swap out the proxy specific key for the real external services key. \n\nSomeone did share this with me, it uses nono - but I have not played around with it. I expect we may well do something native to nono as well - I can share a proof-of-concept with you if useful and you can kick the tyres and see if its something usable?\n\nhttps://github.com/dedene/claw-wrap",
              "score": 1,
              "created_utc": "2026-02-17 13:56:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f6cnm",
          "author": "ozgurozkan",
          "text": "The Landlock approach here is interesting because it addresses something that apparmor and seccomp profiles don't handle as cleanly: the problem that AI coding agents need some filesystem access to be useful, but you want that access to be scoped to the project directory and denied elsewhere by default.\n\n\n\nThe key architectural insight is putting enforcement at the kernel level rather than relying on the agent's own guardrails. Application-layer filtering is exactly what prompt injection is designed to bypass, so the security model collapses precisely when you need it most. Kernel-enforced Landlock LSM rules survive prompt injection because the agent process literally cannot make those syscalls regardless of what instructions it receives.\n\n\n\nA few edge cases worth thinking about for the threat model:\n\n\n\n1. Legitimate agent workflows that need broad access (e.g., reading environment configs across the home directory) will require allow-list configuration, which creates friction that might push users to over-permission the allow list.\n\n\n\n2. Network egress isn't mentioned. An agent that can make outbound connections could exfiltrate data or download additional payloads even with filesystem restrictions intact. Combining Landlock with network namespace restrictions or seccomp filtering on socket calls would be the complete picture.\n\n\n\n3. The credential exfiltration mitigation for \\~/.ssh and \\~/.aws is valuable, but intermediate credential storage (e.g., in-memory secrets passed via env vars) is still visible to the process.\n\n\n\nSolid project overall. The deny-by-default model is the right foundation.",
          "score": 0,
          "created_utc": "2026-02-20 13:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fzyzn",
              "author": "DecodeBytes",
              "text": "Thank you, the whole of the policy system is user configurable / composable:\n\n[https://docs.nono.sh/cli/features/profiles-groups](https://docs.nono.sh/cli/features/profiles-groups) ",
              "score": 1,
              "created_utc": "2026-02-20 16:14:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8vdkb",
      "title": "Compromising Cline's Production Releases just by Prompting an Issue Triager",
      "subreddit": "netsec",
      "url": "https://adnanthekhan.com/posts/clinejection/",
      "author": "albinowax",
      "created_utc": "2026-02-19 10:05:12",
      "score": 27,
      "num_comments": 3,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r8vdkb/compromising_clines_production_releases_just_by/",
      "domain": "adnanthekhan.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6a8e9s",
          "author": "InsideStatistician68",
          "text": "Painful to read AI generated text.",
          "score": 5,
          "created_utc": "2026-02-19 18:27:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67uj2s",
          "author": "albinowax",
          "text": "I love the implication that OpenClaw might be self-propagating https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7",
          "score": 4,
          "created_utc": "2026-02-19 10:07:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6f3lld",
          "author": "ozgurozkan",
          "text": "This is a clean example of what makes AI-assisted CI/CD so dangerous from a supply chain perspective. The attack surface is no longer just the code or the developer workstation. Any AI agent that has write access to a repository, publish permissions, or the ability to trigger workflows is now a viable lateral movement path if it can be influenced through untrusted input channels.\n\n\n\nThe issue triager case is particularly interesting because the trust model for an issue tracker is fundamentally inverted from what you want in a privileged pipeline component. Issues are designed to be submitted by anyone, including external reporters who are not vetted contributors. Wiring a model with deployment permissions to that input channel without strict output constraints and intent verification is a significant architectural mistake.\n\n\n\nThe broader pattern is that many teams are integrating agents into workflows where they inherit permissions far beyond what their actual tasks require. An agent that labels and triages issues needs read access and label write access. It does not need release artifact permissions or the ability to approve PRs. The principle of least privilege applies to AI agents at least as much as it does to service accounts, but the tooling to scope agent permissions precisely is still immature.\n\n\n\nThe GHSA advisory albinowax linked about the self-propagation angle makes this worse. Once the agent can be turned against the repository it's supposed to protect, you're looking at a persistence mechanism that survives rotations and reviews that would catch traditional backdoors.",
          "score": 1,
          "created_utc": "2026-02-20 13:32:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbzbyv",
      "title": "Malicious Chrome extension targeting Apple App Store Connect developers through fake ASO service - full analysis",
      "subreddit": "netsec",
      "url": "https://blog.toborrm.com/findings/boostkey.html",
      "author": "Huge-Skirt-6990",
      "created_utc": "2026-02-22 22:11:15",
      "score": 13,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1rbzbyv/malicious_chrome_extension_targeting_apple_app/",
      "domain": "blog.toborrm.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6xa4fw",
          "author": "dexgh0st",
          "text": "Solid catch on the IP proxy requirement ‚Äî that's a sophisticated understanding of Apple's velocity and anomaly scoring. Since this bridges web and mobile, worth noting that similar session hijacking patterns show up in mobile apps when developers hardcode credentials or store sensitive tokens in plaintext SharedPreferences/Keychain. The OWASP MASTG covers this under insecure storage, but the social engineering angle here is the real weapon. I'd be curious if you pulled the extension's permissions manifest ‚Äî Chrome extensions with webRequest or declarativeNetRequest can passively intercept and exfiltrate cookies before the replay even happens. If you're building detection tooling, correlating extension install timestamps with sudden App Store Connect login anomalies from unfamiliar geolocations (even through proxies) might catch earlier iterations. Have you considered flagging extensions that request broad host permissions combined with credential-handling APIs?",
          "score": 1,
          "created_utc": "2026-02-23 09:14:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xc6i7",
              "author": "Huge-Skirt-6990",
              "text": "Cheers, so far what I managed to achieve is pulling daily newly added abd removed extensions from the store.\nFor newly added extensions I analyse the whole crx file for permission in the manifest file and external domain communication and check them in parallel with VT then i analyse critical combination of perm with external domains",
              "score": 1,
              "created_utc": "2026-02-23 09:35:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rcexc6",
      "title": "Have you tried turning it off and on again?¬†On bricking OT devices (part 2)",
      "subreddit": "netsec",
      "url": "https://www.midnightblue.nl/blog/have-you-tried-turning-it-off-and-on-again-on-bricking-ot-devices-part-2",
      "author": "2ROT13",
      "created_utc": "2026-02-23 11:25:12",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1rcexc6/have_you_tried_turning_it_off_and_on_again_on/",
      "domain": "midnightblue.nl",
      "is_self": false,
      "comments": [
        {
          "id": "o6ydzaj",
          "author": "peregrinefalco9",
          "text": "Bricking OT devices as a persistence technique is underresearched. Most ICS security focuses on data exfil and process manipulation, but firmware-level attacks that survive a power cycle are the ones plant operators actually can't recover from without physical replacement.",
          "score": 2,
          "created_utc": "2026-02-23 14:20:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7jdac",
      "title": "Kraken Darknet Access via Clearnet Gateways ‚Äì some observations",
      "subreddit": "netsec",
      "url": "https://malwr-analysis.com/2026/02/18/kraken-darknet-access-via-clearnet-gateways/",
      "author": "anuraggawande",
      "created_utc": "2026-02-17 21:28:29",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.77,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r7jdac/kraken_darknet_access_via_clearnet_gateways_some/",
      "domain": "malwr-analysis.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5yqd00",
          "author": "dirkthedank",
          "text": "that smells like a pile of feds",
          "score": 1,
          "created_utc": "2026-02-18 00:27:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6l5e3",
      "title": "When Audits Fail Part 2: From Pre-Auth SSRF to RCE in TRUfusion Enterprise",
      "subreddit": "netsec",
      "url": "https://www.rcesecurity.com/2026/02/when-audits-fail-from-pre-auth-ssrf-to-rce-in-trufusion-enterprise/",
      "author": "MrTuxracer",
      "created_utc": "2026-02-16 20:36:35",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r6l5e3/when_audits_fail_part_2_from_preauth_ssrf_to_rce/",
      "domain": "rcesecurity.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r9th6w",
      "title": "Discovery & Analysis of CVE-2025-29969",
      "subreddit": "netsec",
      "url": "https://www.safebreach.com/blog/safebreach_labs_discovers_cve-2025-29969/",
      "author": "AlmondOffSec",
      "created_utc": "2026-02-20 11:59:22",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/netsec/comments/1r9th6w/discovery_analysis_of_cve202529969/",
      "domain": "safebreach.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6rjvsn",
          "author": "peregrinefalco9",
          "text": "Clean root cause analysis. The interesting part is how long this sat in the codebase before anyone looked at it. Would be worth tracking how many similar patterns exist in adjacent code paths.",
          "score": 1,
          "created_utc": "2026-02-22 13:04:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}