{
  "metadata": {
    "last_updated": "2026-02-12 09:09:57",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 330,
    "file_size_bytes": 412298
  },
  "items": [
    {
      "id": "1qwrxe8",
      "title": "Notebooks, Spark Jobs, and the Hidden Cost of Convenience",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/g2mm7qq5lphg1.jpeg",
      "author": "mwc360",
      "created_utc": "2026-02-05 17:41:38",
      "score": 400,
      "num_comments": 93,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwrxe8/notebooks_spark_jobs_and_the_hidden_cost_of/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3rw2pa",
          "author": "Rycross",
          "text": "Whether its a notebook or not isn't really the issue.  The issue is whether there is a proper version control, change control, and rollback process.  Notebooks *usually* don't have that in practice.  But you can do VC, CI/CD, and testing with notebooks.  If you do then there's nothing wrong with using them in prod.\n\n\nSome more thoughts: The issue that I usually see in practice is that once you start introducing these things then notebooks' convenience is reduced, so there's a lot of resistance against controls that prevent people from just yeeting something into production.  And once you let people yeet their non-important work, its only a matter of time before people start yeeting important work.",
          "score": 77,
          "created_utc": "2026-02-05 19:51:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x4565",
              "author": "LandlockedPirate",
              "text": "Except that notebooks also frequently rely on side effects, %run, magic commands, comments that are actually code in a different language (sql),  typically don't have a dependency manifest, typically don't have tests etc.  The code can't really be processed correctly by commodity static code analyses tools, is painful to merge (jupyter), sometimes also contains results (jupyter) etc.\n\nYes I know you \\_can\\_ do some of these things, you \\_can\\_ avoid %run and magic commands, you \\_can\\_ avoid relying on side effects, but the tooling doesn't help.  On a large project or team the tooling is what makes it actually happen.",
              "score": 7,
              "created_utc": "2026-02-06 15:50:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4279g5",
                  "author": "No_Mongoose6172",
                  "text": "I think this shows that there's room for new tools that have the advantages of notebooks (like being able to use markdown, math expressions and photos in your comments to better document its behaviour) while avoiding those problems\n\nA production oriented notebook based ide would be great. In that sense, I like Matlab approach for notebooks, as it uses normal text files for storing them with special comments for identifying cells, equations, photos, bullet points and so on (so notebooks can also be executed like a normal script)\n\nEdit: I would love to be able to generate pdf files from my C/C++ tests with plots. It would be great for documenting scientific code (like an advanced version of something like doxygen with notebook like features)",
                  "score": 3,
                  "created_utc": "2026-02-07 10:45:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3r8uat",
          "author": "GrumDum",
          "text": "If people who used notebooks in prod could read, they would be very angry right now.",
          "score": 295,
          "created_utc": "2026-02-05 18:04:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rl8y3",
          "author": "scataco",
          "text": "Quality is subjective.\n\nIf \"most prod jobs\" are for dashboards that nobody uses, who cares if the data is consistent, interpretable and accurate!",
          "score": 91,
          "created_utc": "2026-02-05 19:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rxfvj",
              "author": "jimtoberfest",
              "text": "Someone fast track this guy to senior management",
              "score": 77,
              "created_utc": "2026-02-05 19:57:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s2exm",
                  "author": "scataco",
                  "text": "Nooooo!",
                  "score": 8,
                  "created_utc": "2026-02-05 20:21:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3svei7",
                  "author": "jun00b",
                  "text": "I'm working on a spot bonus right now.",
                  "score": 4,
                  "created_utc": "2026-02-05 22:42:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xgkld",
                  "author": "LandlockedPirate",
                  "text": "Get him an agentic coding workflow and he'll be a 1 man army",
                  "score": 1,
                  "created_utc": "2026-02-06 16:49:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vjpfw",
              "author": "CAPSLOCKAFFILIATE",
              "text": "> for dashboards that nobody uses\n\nI feel my neck veins bulging as I read this part.",
              "score": 7,
              "created_utc": "2026-02-06 09:51:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3y3k89",
              "author": "st4reater",
              "text": "Why have the dashboard then",
              "score": 1,
              "created_utc": "2026-02-06 18:38:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rapf9",
          "author": "CrowdGoesWildWoooo",
          "text": "Well databricks ‚Äúnotebook‚Äù aren‚Äôt literal notebook.",
          "score": 82,
          "created_utc": "2026-02-05 18:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3riyps",
              "author": "TripleBogeyBandit",
              "text": "This, you can have python files with a comment at the top ‚ÄúDatabricks notebook source‚Äù and it render as notebook in the ui but allow for test suites.",
              "score": 52,
              "created_utc": "2026-02-05 18:50:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xfpus",
                  "author": "LandlockedPirate",
                  "text": "Ok, i'll bite.  \n\nHow do you write tests around your non python cells?",
                  "score": 3,
                  "created_utc": "2026-02-06 16:45:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3tm7e6",
              "author": "TheRealStepBot",
              "text": "They were and once they realized how bad it was to build a platform on notebooks they have spent a better part of a decade trying to tack standard software development tooling onto them. They aren‚Äôt notebooks in only the most technical of ways. They still are square pegs trying to fit into the round hole that is the rest of software development.",
              "score": 10,
              "created_utc": "2026-02-06 01:13:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3uxlsp",
                  "author": "CrowdGoesWildWoooo",
                  "text": "The change to .ipynb default was recent, but it‚Äôs not like the ecosystem around the .py file was lacking or non-functional. \n\nAs in the issue with notebooks are inconsistency when it comes to commit because you are bringing the whole notebook state, and poor integration with testing suite. \n\nIf it behaves like a normal python file which you can do easily do testing, and it doesn‚Äôt carry the bad traits of a notebook, there‚Äôs no point to be pedantic.\n\nIt‚Äôs ironically like one of the common ‚Äúprinciple‚Äù in python. If it walks like a duck, quack like a duck‚Ä¶",
                  "score": 4,
                  "created_utc": "2026-02-06 06:27:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3sasrr",
              "author": "Atticus_Taintwater",
              "text": "Are they not? With dbr 15+ aren't they stored by default as ipynb and you have to change it to py, and I wonder how long that backward support will stick around",
              "score": 5,
              "created_utc": "2026-02-05 21:01:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3s10a4",
              "author": "Clean-Health-6830",
              "text": "Abstractions? In my software? Bah!",
              "score": 2,
              "created_utc": "2026-02-05 20:14:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ve5ml",
              "author": "SnowyBiped",
              "text": "to be fair, a few years back, in Databricks a notebook based job had better logging that a standard jobs.\n\nYou could see where there was a failure and just get that notebook and run it in the UI to replicate the problem.\n\nBut for what we were doing (copy some tables and run some SQL) Databricks was an overkill",
              "score": 1,
              "created_utc": "2026-02-06 08:57:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3s19dp",
              "author": "mwc360",
              "text": "I disagree. This works the same in Fabric, Synapse, and likely other platforms as well. A PySpark Notebook put into GIT has a bunch of comment lines that are used to parse where a cell begins/ends, magics, different cell languages, etc. ~~BUT, the actual thing in the platform backend is almost surely not a simple \\`.py\\` file, it is something more complex (i.e. \\`.ipynb\\` which is just JSON underneath) as it stores cell outputs, metadata, and other things which are not parsed into a \\`.py\\` file when the object is sync'd to GIT.~~ *Edited for those that can't see the forest through the trees:* this might have changed in DBX but this ultimately doesn't matter to my point that what is deployed to prod at the end of the day is a Notebook experience that comes with Notebook risks. Sure you can mitigate most of the risk with tests (and maybe CI validation to block usage of MAGICS that are untestable) and tight governance on your prod env, but it's still awkward.\n\nSo why does this matter? From a development perspective (and almost surely from a backend storage perspective) it is a Notebook by all measures. This matters as you can arbitrarily decide to use Scala or SparkSQL cells in your Notebook where PySpark is the default language, and when parsed into a \\`.py\\` file, none of those non-default language cells can be tested, type checked, linted, etc.. they show as commented out lines of code with a header that tells the platform's parser to interpret it as a specific language.\n\nSure, you could require your devs to not use multiple languages in a single Notebook and use an awkward process to ensure test coverage (awkward because you can't really start with local development, you'd have to do cloud>local>write tests and repeat, but even then you are still shipping into production something that comes with a built in IDE. At that point, only proper governance and access control can save you from a \"well it's super easy so I just directly applied the change in production\" scenario.",
              "score": -9,
              "created_utc": "2026-02-05 20:16:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3sb00z",
                  "author": "CrowdGoesWildWoooo",
                  "text": "Stop yapping bs, if you never used one.",
                  "score": 23,
                  "created_utc": "2026-02-05 21:02:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3sabye",
                  "author": "ADGEfficiency",
                  "text": "You are uneducated about this topic.",
                  "score": 17,
                  "created_utc": "2026-02-05 20:59:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rirkl",
          "author": "raskinimiugovor",
          "text": "I'll give you an example of how we use synapse notebooks (had no say in technology used, but generally it's enough for our needs) which are orchestrated via pipelines and triggers:\n\n* all processing logic is maintained in a custom python library covered with unit tests and a few integration tests, separate from transform logic\n* this custom library has very minor dependencies on Azure (only a few generic functions) and could be migrated to databricks or something similar if necessary\n* all notebooks import the library and use same flow, so everything is familiar from notebook to notebook\n* simple transformations are mapping based\n* more complex transformations are implemented in the notebooks but they can only output a dataframe (later handled by processing module), they can't write to the env directly or depend on some global variables (in some cases wrapper functions can be used to circumvent that)\n* changes are committed and deployed using CI/CD\n* development and debugging is generally done directly in the notebook but has no effect until it ends up on the main branch and becomes a part of the project\n* in most cases when something fails, it's related to env or env specific data and most convenient way is to debug it via notebook which is already part of the isolated workspace and connected storage accounts\n\nDo you think there's anything wrong with this workflow and how would spark jobs improve it?",
          "score": 20,
          "created_utc": "2026-02-05 18:49:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rnkeg",
              "author": "instamarq",
              "text": "If it reliably delivers the goods in a maintainable, secure, easily audited and cost effective way, the job has been done well.",
              "score": 12,
              "created_utc": "2026-02-05 19:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s2pgd",
                  "author": "mwc360",
                  "text": "100%. If your process is working well, this blog shouldn't make you question everything about your existing process. If you find that your process makes it hard to deliver reliability outcomes, that's when I'd question what parts can be improved. What you've described seems quite clean.",
                  "score": 2,
                  "created_utc": "2026-02-05 20:23:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ry9lw",
              "author": "fuhgettaboutitt",
              "text": "Without the notebooks, this is the approach my old team came up with a few years ago but we exposed the library as YAML and as the direct library. Its HARD to implement, but you know exactly how to get something reliably in prod, the uplift of data science toolkit into prod came down to days. More complex transformations were required to implement unit tests and be stored in code and reviewed as regular software. You knew the training pipe and the prediction pipe were exactly the same for transformations, so any modifications at a lower level were tested by the tests for that lower level function, as well as all of the pipes utilizing that funciton. DS only lived in notebooks as long as the project was exploratory, notebooks were sourced from a default notebook that could be checked out and had all of our pip installs and configurations loaded.",
              "score": 2,
              "created_utc": "2026-02-05 20:01:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3t72p3",
          "author": "Sufficient_Example30",
          "text": "Honestly,i don't agree with this sentiment.\nI've found notebooks in production extremely useful, especially when things have gone wrong .\nIt makes things easier for me to explain to business at what step the pipeline failed via visuals.\nIn ML workload environments ,it allows data science a chance to know from where things have gone awry easily and provides them with like a base code to fix their model.\nEverything is a trade off ,\nThere's also a cost of ci/cd  a script and a hidden cost of going the pipeline route.,maintaining multiple environments etc\nThe only difference is you build more stuff to show things for more stake holder confidence.\nI think you should decide your approach on a pipeline to pipeline basis.\nNot everyone is gonna agree with my sentiment but i heavily disagree with the post\n\n====\nI also disagree with the notion that the code being harder to test.\nIn my opinion data pipelines should be tested end to end with data and while testing see how each transformation affects stuff and using dequeue log stuff correctly.\nWriting testable code has nothing to do with using  a notebook and all common stuff can be written as a .python file of a pip package.",
          "score": 11,
          "created_utc": "2026-02-05 23:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s4ngi",
          "author": "mttpgn",
          "text": "I will refuse to share my demo notebooks for exactly this reason. \"Obviously it'll need to be productionalized first.\"",
          "score": 5,
          "created_utc": "2026-02-05 20:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s8akh",
          "author": "tjger",
          "text": "I like using notebooks for the entry points. Notebooks help explain the pipeline / job better than just plain code.",
          "score": 3,
          "created_utc": "2026-02-05 20:49:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3t4e6c",
              "author": "Teddy_Raptor",
              "text": "This is why marimo is cool. Notebook interface book backed by . Py fines",
              "score": 2,
              "created_utc": "2026-02-05 23:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3u60h4",
          "author": "Ted_desolation",
          "text": "Im in fabric. I have no choice in the matter so don't blame me.",
          "score": 3,
          "created_utc": "2026-02-06 03:11:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uxqgk",
              "author": "mwc360",
              "text": "Would love to learn more. Have you tried Spark Job Definitions or is this more of a team culture thing?",
              "score": 1,
              "created_utc": "2026-02-06 06:28:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3udhzu",
          "author": "focused_entrepreneur",
          "text": "But why? I love Databricks notebooks.",
          "score": 3,
          "created_utc": "2026-02-06 03:58:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42evcw",
              "author": "EntertainmentOne7897",
              "text": "People say you cant do this and that with notebooks which is not true. You can do all that but it seems that people writing notebook might be lazy and not do all the production ready things. Which is just an idea living in their head.",
              "score": 1,
              "created_utc": "2026-02-07 11:55:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3v9if7",
          "author": "skippy_nk",
          "text": "I agree with the post but I'll comment on another thing that I see people use to counter argue this idea.\n\nThere's this argument that notebooks make the code more explainable to stakeholders.\n\nBut really, code is not for the non-coders and they shouldn't bother with it. I prefer not to show the code to them, especially if it's in notebooks, and especially now with all this GenAI stuff. It's because notebooks make the code look simple to non technical folks. It's due to the cell layout, I believe, that they get the feeling it's basically not much more than excel formulas, while in reality, there's a huge clusterfuck of moving parts underneath. \n\nAnd there's always this one manager that half assed a Python for DE course on Udemy and \"wants to help\". Of course, we end up losing our precious time by going over their slop because we can't just tell them to fuck off and do their job and we'll do ours. \n\nCode explainability (to stakeholders) should not be a thing, ideally. Basically, development experience beats the explainability argument all day long.",
          "score": 3,
          "created_utc": "2026-02-06 08:13:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x2w5c",
          "author": "miker5555",
          "text": "Honestly this matches my experience too. Notebooks are great for exploration, but once something is ‚Äúreal,‚Äù they tend to turn into a dumping ground of half-run cells and mystery state.\n\nEvery prod issue I‚Äôve debugged that started with ‚Äúbut it worked in the notebook‚Äù ended up costing way more time than just writing the job cleanly from the start.\n\nStill‚Ä¶ I‚Äôll admit I keep one notebook around to poke at data before doing it the right way üòÑ",
          "score": 3,
          "created_utc": "2026-02-06 15:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s10ot",
          "author": "Throwaway999222111",
          "text": "I export as a .py and the script does the same thing, I just rename it as prod. That isn't what others do? Notebooks are for dev I thought",
          "score": 5,
          "created_utc": "2026-02-05 20:14:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3y450j",
              "author": "st4reater",
              "text": "A notebook is - a notebook. You need to ensure parity between what you develop and what you push to prod. Otherwise, how can you say you know what you're pushing, and what you tested represents what users will meet?",
              "score": 1,
              "created_utc": "2026-02-06 18:41:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rbdzx",
          "author": "Tushar4fun",
          "text": "You said notebooks - I heard HTML/CSS",
          "score": 4,
          "created_utc": "2026-02-05 18:16:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s7bpa",
          "author": "Arnechos",
          "text": "Using notebooks in databricks when you only write pysprark code is laziness given the option to run python script/wheel task",
          "score": 2,
          "created_utc": "2026-02-05 20:45:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v8bgn",
              "author": "ephemeralentity",
              "text": "But what if you want to make it easy to debug? If you are using PySpark you are likely doing data transformation. What is the benefit of converting that to a py file? You lose the ability to step through it next time you want to make changes. Worse, if you package in a whl you have to constantly recompile it.\n\nThere are circumstances where notebooks become inefficient, e.g. software engineering (not data engineering applications), where you have a large number of imports / component class modules and you don't want to have to instantiate them all in your notebook environment or have a large number of notebook dependencies but for simpler data transforming logic, they work well.",
              "score": 2,
              "created_utc": "2026-02-06 08:02:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3v9y83",
                  "author": "Arnechos",
                  "text": "\\> e.g. software engineering (not data engineering applications)\n\nThis is weird distinction for me, data engineering is software engineering with data product at the end.\n\n>But what if you want to make it easy to debug? If you are using PySpark you are likely doing data transformation. What is the benefit of converting that to a py file? You lose the ability to step through it next time you want to make changes. Worse, if you package in a whl you have to constantly recompile it.\n\nProper logging and stack traces already give you the debugging what is happening in production. I'm not saying don't use notebooks during development. The package argument is kinda silly, like with uv, CI/CD and IaC it's trivial - even so today when you can have claude/codex to whip up yamls\n\n\\>¬†simpler data transforming logic, they work well.\n\nFor this you could even use a GUI tool. ",
                  "score": 2,
                  "created_utc": "2026-02-06 08:17:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3uxtt7",
          "author": "DoubleAway6573",
          "text": "I'll take the bait.\n\n\nAny prod at all should be notebooks.\n\n\nAre you convinced?",
          "score": 2,
          "created_utc": "2026-02-06 06:28:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vy99r",
          "author": "ActionConnect5973",
          "text": "Notebooks when done \"right\" are basically offloading a bit of the engineering to DS/Analytics. You can still version it, deploy it and run it. Is it optimal? No. Does it make sense? Sometimes. \n\nHowever, that is predicated on pull requests and actual engineering maintenance from a dedicated engineer if the thing hits production. \n\nIt is useful as a first step, or in CI testing while you are prototyping. This is from databricks experience. ",
          "score": 2,
          "created_utc": "2026-02-11 23:07:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xdfim",
              "author": "mwc360",
              "text": "Totally agree.",
              "score": 1,
              "created_utc": "2026-02-12 04:15:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sa0um",
          "author": "SBolo",
          "text": "Most?? No prod job should be a notebook",
          "score": 3,
          "created_utc": "2026-02-05 20:58:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ske81",
              "author": "Sagarret",
              "text": "I would say something like around 95% or more.\n\nFor really simple tasks they are okay.\n\nBut yes, I totally agree and that was one of the main reasons why I left DE",
              "score": 3,
              "created_utc": "2026-02-05 21:48:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wipi8",
          "author": "Nekobul",
          "text": "Finally Miles, you are starting to see the light. But your journey will not be complete until you start to reject Spark as Anathema and not needed for the vast majority of the solutions.",
          "score": 1,
          "created_utc": "2026-02-06 14:02:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4k4ksw",
              "author": "mwc360",
              "text": "ü§£",
              "score": 1,
              "created_utc": "2026-02-10 04:10:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wq9at",
          "author": "geeeffwhy",
          "text": "i mean, i tend to agree‚Ä¶ but at the same time, a notebook is just a python file. nothing stops you from structuring your program reasonably with a notebook. it feels like a resurgence of one of my favorite old ideas, Literate Programming. \n\nSometimes the convenient interface is useful, even in prod. you can still have tests and types and clearly defined interface, modules, abstraction, etc.",
          "score": 1,
          "created_utc": "2026-02-06 14:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x7973",
          "author": "dillanthumous",
          "text": "Blanket statements are rarely true and often clickbait. Change my mind.",
          "score": 1,
          "created_utc": "2026-02-06 16:05:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xjnj5",
              "author": "mwc360",
              "text": "Ok. **Most** is not a blanket statement. Change my mind.",
              "score": 2,
              "created_utc": "2026-02-06 17:03:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xdqi7",
          "author": "sleeper_must_awaken",
          "text": "\n\n",
          "score": 1,
          "created_utc": "2026-02-06 16:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41n5ya",
          "author": "ds1841",
          "text": "Honestly they're much better than the fucking mess we've got with talend over time, but without using git it's a big risk.",
          "score": 1,
          "created_utc": "2026-02-07 07:29:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41vskr",
          "author": "Wonderful-Fold1364",
          "text": "What is a notebook ?",
          "score": 1,
          "created_utc": "2026-02-07 08:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ihcd",
          "author": "goldi8",
          "text": "You are right... But tell that Netflix they developed Papermill ü§£",
          "score": 1,
          "created_utc": "2026-02-08 11:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wo5ft",
          "author": "Mario4272",
          "text": "The fk you saying?",
          "score": 0,
          "created_utc": "2026-02-06 14:31:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3usm9e",
          "author": "shennan-lane",
          "text": "What about a well written Marimo",
          "score": -1,
          "created_utc": "2026-02-06 05:46:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy6ca4",
      "title": "AI engineering is data engineering and it's easier than you may think",
      "subreddit": "dataengineering",
      "url": "https://www.datagibberish.com/p/ai-powered-apps-dictionary-for-data-engineers",
      "author": "ivanovyordan",
      "created_utc": "2026-02-07 06:20:37",
      "score": 191,
      "num_comments": 31,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qy6ca4/ai_engineering_is_data_engineering_and_its_easier/",
      "domain": "datagibberish.com",
      "is_self": false,
      "comments": [
        {
          "id": "o42kx1t",
          "author": "DisjointedHuntsville",
          "text": "‚ÄúData engineering is just software engineering and it‚Äôs easier than you think‚Äù\n\n‚ÄúSoftware engineering is just an abstraction of mathematics and it‚Äôs easier than you think‚Äù\n\n‚ÄúMathematics is an abstraction of formally provable empirical observations and its easier than you think‚Äù\n\nFor fucks sake. . . The worst part of the data engineering world is the overkill on needless categorization of work to justify a role.",
          "score": 90,
          "created_utc": "2026-02-07 12:44:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43x5tu",
              "author": "decrementsf",
              "text": "The simplest possible form is trim out the incantations and have direct access to the upstream money printer sinecure. It's a silly game. Dilbert provided a good summary.",
              "score": 4,
              "created_utc": "2026-02-07 17:07:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48gfa9",
                  "author": "dillanthumous",
                  "text": "Don't forget to sing the appropriate psalms while communing with the Omnisiah.",
                  "score": 3,
                  "created_utc": "2026-02-08 11:00:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o448tzh",
              "author": "[deleted]",
              "text": "It‚Äôs not that serious. I thought it was a decent write up.",
              "score": 4,
              "created_utc": "2026-02-07 18:05:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o463pkf",
              "author": "TechnicallyCreative1",
              "text": "Title was click bait, the content wasn't terrible. The sentiment was that data organization is important. That is all",
              "score": 2,
              "created_utc": "2026-02-08 00:09:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42fd55",
          "author": "mint_warios",
          "text": "AI engineering existed way before LLMs. Agree there's a lot of overlap with \"classical\" data engineering, but there's so much more to AIE/MLE than LLM pipelines and RAG mechanisms",
          "score": 68,
          "created_utc": "2026-02-07 11:59:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42fyoy",
              "author": "MonochromeDinosaur",
              "text": "MLE and AI Engineering are completely separate job descriptions. \n\nAI Engineering roles are essentially just web development using LLMs with a side of data engineering.\n\nMLE is Data Engineering+MLOps+actual understanding of ML.",
              "score": 36,
              "created_utc": "2026-02-07 12:04:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o488mih",
                  "author": "xorgeek",
                  "text": "What is MLops",
                  "score": 2,
                  "created_utc": "2026-02-08 09:46:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o445ctx",
                  "author": "Blaze344",
                  "text": "Proper AI engineering should have at least some basic ML knowledge behind the things being built. Knowing the best way to represent information from retrieval, running experiments to get the F1 score of the current solution, knowing how to debug all the moving pieces to find which one is bottle necking...\n\nThere's a lot of web dev, tho, that's true, and MLE is the one that really grits into true ML territory. It's just that current AI is \"powerful enough\" (quotes required) that you can make do without having the core skills and deliver something, just in spite of how powerful things are. Sort of how we have so much compute no one cares about delivering something memory aware nowadays, too...",
                  "score": 3,
                  "created_utc": "2026-02-07 17:48:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o42fp1f",
              "author": "ivanovyordan",
              "text": "I 100% agree with you here. But you will also agree that in 2026 AI means LLM for most people.",
              "score": 8,
              "created_utc": "2026-02-07 12:02:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o42yszk",
          "author": "genobobeno_va",
          "text": "I concur. It‚Äôs all pipelines.",
          "score": 14,
          "created_utc": "2026-02-07 14:12:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xo4e",
              "author": "decrementsf",
              "text": "There is a non zero chance this is the same as medical students experiencing every medical condition they study in sequence. Humans are a pattern recognition machine interpreting stimulus through the bounds of the information already known. What do I know? Predict what happens next. Surprise or affirms the machine is working. Output -> It's all pipelines.",
              "score": 2,
              "created_utc": "2026-02-07 17:10:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44glc8",
          "author": "gnomehearted",
          "text": "AI engineering's existence makes me want to leave the industry wholesale",
          "score": 8,
          "created_utc": "2026-02-07 18:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44juk7",
              "author": "ivanovyordan",
              "text": "A friend of mine left his job on Friday because he felt unappreciated contary to folks who build LLM solutions.\n\nWhat exactly is the thing that you dislike?",
              "score": 0,
              "created_utc": "2026-02-07 18:59:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o45fm0k",
                  "author": "Aggravating-One3876",
                  "text": "For me it‚Äôs what you can tour AI all day long but management only hears that you can do your job faster. If you can do your job faster then let‚Äôs move up deadlines and if you can get push back it‚Äôs pretty much ‚Äúwell AI should make it faster‚Äù.\n\nThe other issue is that AI makes senior devs spend more time cleaning up the AI code that gets put into production and it robs junior devs of experience in debugging. \n\nFor me the only reason to use AI is that deadlines become unreasonable and that is in part of people overselling what AI can do. Then when you do use AI it can give you wrong answers so hopefully you look at the code that you are putting in. \n\nSo for me AI does not benefit DE and is only to shorten deadlines and put pressure to preform, thus forcing you to use it just to keep up.",
                  "score": 2,
                  "created_utc": "2026-02-07 21:48:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ba5ct",
                  "author": "lolsillymortals",
                  "text": "Your friend sounds like a spoiled worker bee.\n\n‚ÄúI‚Äôm not getting the glory I used to, I‚Äôm going to throw a fit and go get another job where they think what I‚Äôm doing is amazing again! One more pat on the back is all I‚Äôm asking for!‚Äù",
                  "score": 1,
                  "created_utc": "2026-02-08 20:29:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o459gtj",
          "author": "constantly-pooping",
          "text": "probiabtistic?",
          "score": 3,
          "created_utc": "2026-02-07 21:15:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45atns",
              "author": "ivanovyordan",
              "text": "Ha-ha. That's how you know I don't use AI to write. :D\n\nThanks for that. Won't fix it though. It's funny",
              "score": 1,
              "created_utc": "2026-02-07 21:22:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46dqwq",
          "author": "Procrastinator9Mil",
          "text": "A post from someone who doesn‚Äôt understand neither.",
          "score": 2,
          "created_utc": "2026-02-08 01:09:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47labx",
              "author": "ivanovyordan",
              "text": "Interessting. What made you think so?",
              "score": 1,
              "created_utc": "2026-02-08 06:10:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fvakj",
          "author": "Thinker_Assignment",
          "text": "Thanks for this one, the community needs to hear this more, the AI layer is definitely more easily served by DEs than new SEs as AIEs",
          "score": 2,
          "created_utc": "2026-02-09 14:50:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4h51cf",
              "author": "ivanovyordan",
              "text": "I appreciate it!",
              "score": 1,
              "created_utc": "2026-02-09 18:30:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o47tdev",
          "author": "PracticalBumblebee70",
          "text": "Written by data engineer¬†",
          "score": 1,
          "created_utc": "2026-02-08 07:23:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47w72t",
              "author": "ivanovyordan",
              "text": "True",
              "score": 2,
              "created_utc": "2026-02-08 07:49:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4drc9f",
          "author": "EviliestBuckle",
          "text": "What is ideal tech stack these days? Also can you suggest some beginners courses?",
          "score": 1,
          "created_utc": "2026-02-09 04:43:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42pdpb",
          "author": "Illustrious_Role_304",
          "text": "is AI engineering is mandatory for data engineering  now ? Any recent interview experience ?",
          "score": 1,
          "created_utc": "2026-02-07 13:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42s4f1",
              "author": "ivanovyordan",
              "text": "From a hiring manager point of view, I'd say no.\nBut the tuth is that it's very easy and some \"broader\" knowledge can only help in interviews.",
              "score": 2,
              "created_utc": "2026-02-07 13:32:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o452rwa",
          "author": "dudeaciously",
          "text": "This is a beautiful, concise and meaningful article.",
          "score": 1,
          "created_utc": "2026-02-07 20:39:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45avt5",
              "author": "ivanovyordan",
              "text": "Thank you so much. I really appreciate this.",
              "score": 2,
              "created_utc": "2026-02-07 21:23:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0ff3b",
      "title": "[AMA] We‚Äôre dbt Labs, ask us anything!",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/",
      "author": "andersdellosnubes",
      "created_utc": "2026-02-09 20:24:08",
      "score": 131,
      "num_comments": 115,
      "upvote_ratio": 0.91,
      "text": "Hi r/dataengineering ‚Äî though some might say analytics and data engineering are not the same thing, there‚Äôs still a great deal of dbt discussion happening here. So much so that the superb mods here have graciously offered to let us host an AMA happening this **Wednesday, February 11 at 12pm ET.**\n\nWe‚Äôll be here to answer your questions about anything (though preferably about dbt things)\n\n**As an introduction, we are:**\n\n* Anders u/andersdellosnubes (DX Advocate) ([obligatory proof](https://i.imgur.com/4WzEcKM.jpeg))\n* Jason u/dbt-Jason (Director: DX, Community & AI)\n* Jeremy Cohen u/jtcohen6 (PM) ([proof](https://imgur.com/rGUclDq))\n* Grace Goheen u/dbt-grace (PM) ([extra extra proof](https://i.imgur.com/pGMhBlk.gif))\n* Sara u/schemas_sgski (Product Marketing)\n* Quigley u/dbt-quigley (dbt Core engineer) ([proof](https://imgur.com/a7e89c8b-ee7d-42d3-a249-0fa68fe8d928))\n* Zeeshan u/dbt-zeeshan (Core engineering manager) ([proof](https://i.imgur.com/EkgG2dC.jpeg))\n* Tristan Handy u/jthandy (founder/CEO)\n\n**Here‚Äôs some questions that you might have for us:**\n\n* [what‚Äôs new](https://github.com/dbt-labs/dbt-core/releases/tag/v1.11.0) in dbt Core 1.11? what‚Äôs [coming next](https://github.com/dbt-labs/dbt-core/blob/main/docs/roadmap/2025-12-magic-to-do.md)?\n* what‚Äôs the latest in AI and agentic analytics ([MCP server](https://docs.getdbt.com/blog/introducing-dbt-mcp-server), [ADE bench](https://www.getdbt.com/blog/ade-bench-dbt-data-benchmarking), [dbt agent skills](https://docs.getdbt.com/blog/dbt-agent-skills))\n* what‚Äôs [the latest](https://github.com/dbt-labs/dbt-fusion/blob/main/CHANGELOG.md) with Fusion? is general availability coming anytime soon?\n* who is to blame to `nodes_to_a_grecian_urn` corny classical reference in our [docs site](https://docs.getdbt.com/reference/node-selection/yaml-selectors)?\n* is it true that we all get goosebumps anytime anytime someone types dbt with a capital d?\n\nDrop questions in the thread now or join us live on Wednesday!\n\nP.S. there‚Äôs a dbt Core 1.11 live virtual event next Thursday February 19. It will have live demos, cover roadmap, and prizes! [Save your seat here](https://www.getdbt.com/resources/webinars/dbt-core-1-11-live-release-updates-roadmap/?utm_medium=social&utm_source=reddit&utm_campaign=q1-2027_dbt-core-live_aw&utm_content=themed-webinar____&utm_term=all_all__).\n\nedit: Hey we're live now and jumping in!\n\n>thanks everyone for your questions! we all had a great time. we'll check back in on the thread throughout the day for any follow ups!\n>\n>If you want to know more about dbt Core 1.11, next week there's a live event next week!\n>\n>[reserve your spot here](https://www.getdbt.com/resources/webinars/dbt-core-1-11-live-release-updates-roadmap/?utm_medium=social&utm_source=reddit&utm_campaign=q1-2027_dbt-core-live_aw&utm_content=themed-webinar____&utm_term=all_all__)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4irts2",
          "author": "Interesting_Tank_118",
          "text": "I love your product! Since merging with Fivetran: Whats the long term strategy of dbtlabs? i.e. will dbt cloud have even more advanced features than dbt core to get more paying customers?",
          "score": 80,
          "created_utc": "2026-02-09 23:23:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u1abx",
              "author": "dbt-jason",
              "text": "First of all - thank you for being a dbt user!! Before I worked at dbt Labs I spent a lot of time on this subreddit so it's great to be here chatting with you all.\n\nRe: merger / Core / Cloud\n\nThe process of merging the two companies is still underway, so there‚Äôs really not much we can say besides ‚Äústay tuned.‚Äù The details we shared back in October at Coalesce in Las Vegas ([blog](https://www.getdbt.com/blog/dbt-labs-and-fivetran-merge-announcement), [keynote](https://youtu.be/KhBsI2LQQ90?si=YWWxfJnK5J6vRxOg)) haven't changed.\n\nOne thing I'll add is that we're committed to keeping dbt Core the open source standard for data transformation. Are we going to ship great new dbt features to our paying customers? Of course. But not by keeping important functionality out of dbt Core. The way to do it is to make sure dbt Core (and Fusion) have more powerful and better functionality and then build even better features on top.\n\nGrace and the rest of the Core team can talk about some of the things we've been cooking up there. And most importantly - we \\_always\\_ want to hear from you. What would you like to see in Core?",
              "score": 7,
              "created_utc": "2026-02-11 17:35:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u80vu",
              "author": "andersdellosnubes",
              "text": "what u/dbt-jason said! time will tell; stay tuned",
              "score": 0,
              "created_utc": "2026-02-11 18:06:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4tet8g",
              "author": "finally_i_found_one",
              "text": "Looks like the most voted (and most important) question went unanswered.",
              "score": -6,
              "created_utc": "2026-02-11 15:50:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4utnx1",
                  "author": "andersdellosnubes",
                  "text": "I think you were early to the party!",
                  "score": 1,
                  "created_utc": "2026-02-11 19:47:59",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jcvg9",
          "author": "FIapdoodle",
          "text": "Some questions pertaining to Fivetran merger:\n\nSince they also acquired Tobiko Data, will we see any consolidation/standardization efforts between DBT and SQLMesh? \n\nWith Fivetran providing many data connectors, will we see a more end-to-end flow established where the ingestion and transformations will be managed together?",
          "score": 21,
          "created_utc": "2026-02-10 01:23:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u45gh",
              "author": "andersdellosnubes",
              "text": "u/dbt-jason already touched on this in [this reply](https://www.reddit.com/r/dataengineering/comments/1r0ff3b/comment/o4u1abx/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 2,
              "created_utc": "2026-02-11 17:48:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4vknbx",
                  "author": "m1hawkgsm",
                  "text": "That's not an answer, though. It makes an explicit reference to only Fivetran / dbt as \"two companies merging\".",
                  "score": 2,
                  "created_utc": "2026-02-11 21:57:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4j8enu",
          "author": "flatulent1",
          "text": "The gap between dbt explorer/catalog and a full scale catalog like Atlan or Datahub or Alation or Secoda etc is still huge. In 2026, data is a context game. Are yall just playing it safe as a metadata provider for more expensive, external catalogs?",
          "score": 16,
          "created_utc": "2026-02-10 00:57:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u2ypt",
              "author": "jthandy",
              "text": "Awesome question.\n\nWe have a ton of respect for what pure-play catalog providers do and how hard that is. A lot of this functionality is purely an integration game, and that‚Äôs a TON of work both in terms of the initial build and the maintenance of the integrations.\n\nWe do think that dbt metadata is really central to all analytical metadata and think that we‚Äôre the best place to get that, whether that‚Äôs via artifacts or our API. And with Fusion this dbt-related metadata is getting *significantly* more advanced.\n\nWe do have a few integrations where we pull in metadata of downstream artifacts--tableau and powerbi--but certainly we are *nowhere near as comprehensive* as most pure-play catalogs. And that is ok.\n\nOur goal with Catalog is:\n\n* to provide a really amazing catalog experience that can be the ONLY catalog for small-to-medium companies.\n* to provide a really useful development tool for dbt authors at companies of all sizes\n* to provide a high-quality source of dbt metadata for companies of all sizes\n\nOver time, I fully imagine that we will continue to expand our capabilities here (as we have been!). But we‚Äôre not trying to head-to-head compete against pure-play catalog companies.",
              "score": 6,
              "created_utc": "2026-02-11 17:43:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4io7a9",
          "author": "Sex4Vespene",
          "text": "Thanks for reaching out for questions, I love DBT and it‚Äôs been so useful for our org. I have one question that‚Äôs somewhat of a feature request. Have you considered having an ‚Äúintermediate‚Äù type table materialization? We have several large models that have to be broken up into intermediate steps because they would either overload memory, or perform poorly due to CTE‚Äôs that are called multiple times, which we can instead just process them once in a separate model. What gets annoying with this, is we don‚Äôt want any of these intermediate models taking up space in our warehouse, so we have to use a custom post-hook on any end-state models to clean up the upstream intermediate models. It would be really awesome if you integrated this automatically. Let us use intermediate as a materialization strategy, and have them be autodropped once an end-state model finishes. I know you have ephemeral and view materializations, but none of those solve the problem of having too much stuff happening in the final query that uses them. Thanks again!",
          "score": 24,
          "created_utc": "2026-02-09 23:04:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y6frm",
              "author": "Global_Bar1754",
              "text": ">¬†Let us use intermediate as a materialization strategy, and have them be autodropped once an end-state model finishes.\n\nCorrect me if I‚Äôm wrong, but it would be even better if the intermediate model was dropped after the last model that directly references it is materialized, right? No need to wait for the end state model to finish?",
              "score": 1,
              "created_utc": "2026-02-12 08:23:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iw32u",
              "author": "Chilangosta",
              "text": "Something about this feels off... You have such massive tables that they overload memory, and are forced to break apart queries into intermediate steps. But you then delete said intermediate products presumably because they take up so much space that this saves you money.... And somehow the savings are worth rebuilding it from scratch every time?\n\nI have so many questions; this isn't making sense to me. Feels like either you're overoptimizing for cost when it's really not worth it or else doing something wrong when it comes to query optimization for the intermediate products to truly not be worth keeping around. Are your joins exploding? Is storage really so expensive that rebuilding these intermediates makes sense? Are you doing too much in your final query? Without more info it's hard to say for certain, but intermediate products aside I suspect something isn't as optimal about this scenario as you think.",
              "score": 1,
              "created_utc": "2026-02-09 23:47:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4iyv6s",
                  "author": "Sex4Vespene",
                  "text": "You‚Äôre making some incorrect assumptions here. We are on prem, this isn‚Äôt about saving cloud costs, it‚Äôs about us being somewhat low on storage and trying to minimize how much useless data is just sitting around. We are working on getting budget to expand, but that doesn‚Äôt happen immediately. I don‚Äôt understand what you mean about doing something wrong with optimization for them to not be worth keeping around. These are models that are run on a daily/weekly/monthly cadence. The previous versions of the intermediate models are useless for the next run. They either cover a completely different date range, and even if there is overlap, we have a decent amount of updates/deletes against old records so we‚Äôd want to rerun with the newest versions of the records anyways. And no, our joins aren‚Äôt exploding, I‚Äôve actually done a huge amount of work creating optimization guidelines for our models, and will go in to fine tune when needed. Since we are on prem, we aren‚Äôt paying for aggregate compute usage. We have a set amount of compute and memory that is always available at any moment. If we just ran one model at a time, we would be massively underutilizing our compute. To make the most out of our compute, we run multiple models at once. But since we aren‚Äôt just running one model, we have to set memory limits on all models, by dividing our available memory by the number of concurrent models we run, to ensure we don‚Äôt have memory related failures. Also as I mentioned, there are cases where breaking things out into an intermediate model can have massive performance improvements. Our query engine materializes CTE‚Äôs every time it is called. If you use the same CTE in a query 5 times, it quintuples the memory and compute usage, versus just running it once into a table and then just referencing the table a few times. It all makes plenty of sense, you are just evaluating it from an invalid context.",
                  "score": 12,
                  "created_utc": "2026-02-10 00:02:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4iwknd",
          "author": "RobG760",
          "text": "How will dbt core adapt to a world where streaming pipelines are starting to become more common?  How do you see dbt helping build a clean data lineage across all enterprise data regardless of whether batch or streaming tools are being leveraged?",
          "score": 25,
          "created_utc": "2026-02-09 23:50:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u7z63",
              "author": "jtcohen6",
              "text": "candidly - streaming pipelines have been \"starting to become more common\" for as long as I can remember (since \\~2018)  \n  \nok in seriousness - what i can say is:\n\n* the big innovation over the past \\~decade has been the development of streaming pipelines *written in SQL*. (you don't need to know java/scala! power to the data team!)\n* there are dbt adapters for streaming-first/native DWHs that support an all-SQL interface - Materialize has had an adapter for years, and we see that the Clickhouse adapter has been quite popular of late\n* batch DWHs Snowflake + Databricks have both rolled out support for their own streaming solutions - Dynamic Tables and Materialized Views / Streaming Tables, respectively - with full SQL support. those features are supported as materialization types in dbt, a pretty decent number of folks are using them, but for <5% of all the models in their project.\n\nso - while we see folks adopting streaming pipelines for specific use cases, when there is a specific business need that justifies the added cost/complexity - we still see batch (with hourly/daily refresh) as \"good enough\" for >90% of data transformations.  \n  \nI think dbt's role is continuing to serve as an abstraction across *both* batch and streaming pipelines - both kinds of data products still need version control, testing, documentation, CI/CD, ... - and they should be written in SQL, as dbt models :)",
              "score": 7,
              "created_utc": "2026-02-11 18:06:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ua3zq",
              "author": "muneriver",
              "text": "this may be interesting to you: https://docs.getdbt.com/best-practices/how-we-handle-real-time-data/1-intro",
              "score": 1,
              "created_utc": "2026-02-11 18:16:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4j35rw",
          "author": "midnighttyph00n",
          "text": "when will fusion support python  models",
          "score": 11,
          "created_utc": "2026-02-10 00:26:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lgyag",
              "author": "pseudo-logical",
              "text": "It already does for the big three (snow dbx and bq) which says something about their marketing and comms",
              "score": 3,
              "created_utc": "2026-02-10 11:11:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tyoik",
                  "author": "jtcohen6",
                  "text": "u/pseudo-logical is right - Fusion added supported for Python models way back in \\[v2.0.0-preview.81\\]([https://github.com/dbt-labs/dbt-fusion/blob/main/CHANGELOG.md#200-preview81---december-09-2025](https://github.com/dbt-labs/dbt-fusion/blob/main/CHANGELOG.md#200-preview81---december-09-2025)) - across Snowflake + Databricks + BigQuery  \n  \nto the point about marketing/comms (fair!) - we haven't made a big announcement (yet), since we're still testing out this functionality in real-world projects with help from folks in the community. we know we've shipped *a lot* of stuff in Fusion over the past \\~6 months, and we're trying to do a better job of distinguishing between \"this is new and could use your help testing\" vs. \"this is ready for production *right now*.\" you can expect to hear more from us in the next \"Fusion diary\" (long awaited & soon to drop!). the big remaining piece before GA is figuring out how \"static analysis\" can/should work with Python models (which, for obvious reasons, can't be analyzed as SQL) - [https://github.com/dbt-labs/dbt-fusion/discussions/1042](https://github.com/dbt-labs/dbt-fusion/discussions/1042)\n\nfyi - you can always check here to see the latest table of dbt feature support / what's still missing in Fusion - [https://docs.getdbt.com/docs/fusion/supported-features](https://docs.getdbt.com/docs/fusion/supported-features)\n\nu/midnighttyph00n \\- how are you using Python models in dbt today? on which data warehouse? are you down to give them a try on Fusion? :)  \n  \n**tl;dr - Python models are in Preview (like the rest of Fusion), and will be GA when Fusion goes GA**",
                  "score": 6,
                  "created_utc": "2026-02-11 17:23:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4j4wea",
          "author": "HC-Klown",
          "text": "Please, when will you support write audit publish pattern as a materialization option? I want to build the model in some temp environment then test it and then ‚Äúdeploy‚Äù it without having to rely on data branching features from for example Nessie or LakeFs. \n\nI know this can get more involved with views etc but do you guys have anything related to this in your roadmap? Or would recommend building a custom materialization?",
          "score": 8,
          "created_utc": "2026-02-10 00:36:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tyerj",
              "author": "andersdellosnubes",
              "text": "So, SDF had WAP built into how it was working, and we plan to bring it to dbt in the future! But for now the key priority for us is to make dbt projects run on Fusion without adding too many changes yet to the overall dbt framework.\n\nThere's other tools out there that do more exactly what you're saying.\n\nWe haven't spent too much time in this space. I share your view that DVC or Pachyderm or LakeFS, while great, feel like overkill. My brain has been somewhat sniped by the fact that Apache Iceberg tables have a concept of branching. For me this is very compelling in it's simplicity. In this world you don't need to make a \"view\" rather a \"branch\" of a prod table for local dev.\n\nOrthogonally, we're rather bullish on sampling prod data locally, which is a different pattern than a direct WAP pattern",
              "score": 2,
              "created_utc": "2026-02-11 17:21:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4tz94t",
              "author": "oliverlrj",
              "text": "Hi, may I know how you are implementing write audit publish currently? I am currently in the midst of playing with iceberg, dbt and nessie. Do you use dbt macros to create a new branch for writing of data to the audit branch, or a dbt pre-run hook etc? \n\nWould love to see how people currently do it, thank you!",
              "score": 2,
              "created_utc": "2026-02-11 17:25:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4u1uii",
                  "author": "jtcohen6",
                  "text": "I think there are two different patterns that get lumped into \"WAP\" or \"blue/green\":  \n\\-  (1) for each individual model, first build an intermediate model with the new data, run tests against it (unique, not\\_null, etc) if (and only if) all the tests pass, complete the materialization (swap, merge, ...). if the tests fail - don't; or put the failing rows into \"quarantine\", then keep going...  \n\\- (2) for a group of models, or an entire environment (dev/CI/CD) - create a separate DWH schema (or Iceberg \"branch\"), run all tests, then only if all the tests pass, swap the entire schema/branch into production. this has the advantage of supporting tests that span across multiple models, or allowing sanity-checking / human-in-the-loop verification for final models/metrics at the end of the DAG before re-deploying. this obviously *doesn't* work if the dev/CI/CD environment has a subset of data, or different data from production (scrubbed/anonymized).\n\nI think u/HC-Klown's original question is asking after (1), as a per-model materialization strategy - but just to say, there are pros/cons to either approach, and I don't think we've landed cleanly on which one to pursue (or some combination of both)",
                  "score": 1,
                  "created_utc": "2026-02-11 17:38:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4l0vwi",
          "author": "paujas",
          "text": "What are the priority developments dbt-Labs are concentrating on ?\n\nWhat is the long term vision for dbt-core and dbt-cloud?",
          "score": 6,
          "created_utc": "2026-02-10 08:39:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u0au5",
              "author": "dbt-jason",
              "text": "There's a *ton* going on right now! In terms of priorities, here's how I'm thinking about it.  \n\n\n* First and always - ensure that dbt is a great way to do data work for organizations all across the world. You'd be surprised by how much nuance there is in keeping that up. Addressing bugs and community issues, adapters changes from the underlying databases and new releases for things like dbt-utils. I came to dbt from running a data team and more than anything else the question is how can we continue to be a trusted piece of the analytics stack for data teams across the world.\n* Beyond that, I think of the next set of priorities across three primary buckets - the dbt Fusion engine, AI and emerging standard.\n   1. The dbt Fusion engine is a big area of investment for us and we've seen that for projects that are able to successfully adopt, the rust based, strongly typed version of dbt brings a ton of improvements. Things like speed, improved developer experience and the sql comprehension features that power the VS code extension work great. And also - we've seen some challenges in complex projects getting migrated over to Fusion\n   2. AI - I've been obsessed with AI since way before I worked at dbt Labs (fun fact I was an r/futurology mod when it had less than 1000 users). I really believe that AI is going to radically reshape how we do data work - and giving dbt users the tools to do that *right* is very top of mind.\n   3. Emerging standards - Iceberg, arrow and more. We've been watching Iceberg for a few years and now we're starting to see real customers using Iceberg in production for cheaper / more flexible data ingestion, and to use dbt across multiple data platforms",
              "score": 3,
              "created_utc": "2026-02-11 17:30:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ky1in",
          "author": "pseudo-logical",
          "text": "Ok, I'll bite, _is_ Fusion going to be GA anytime soon? I feel bad for the devs who have had to keep their foot on the gas for nearly a full year since someone on the e-team decided to launch prematurely.",
          "score": 6,
          "created_utc": "2026-02-10 08:11:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u2m80",
              "author": "schemas_sgski",
              "text": "Hey! Really appreciate the interest in Fusion. The team has def been busy building a new engine for dbt that is fast, stable, has parity with the features in dbt Core, and builds on it in important ways. This takes time and we want to make sure we nail it for y'all. More news on Fusion GA coming soon. Stay tuned!",
              "score": 1,
              "created_utc": "2026-02-11 17:41:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rnmxg",
          "author": "OrneryBlood2153",
          "text": "Honestly .. What is going on .. ? \ncore is till getting big fix as releases,\nFusion still in beta,\nCloud was said to go under a single umbrella with five tran,\nOpen engine,\nOpen catalog,\nNow that sqlmesh is also under the same umbrella what happens to the ideas in that tool.\n\nFeels like too much is said but not sure what's the direction of this product for ,\nEnd users - open source and cloud users,\nOpen source contributors - adapter and core ,\ncore vs fusion - what to use going forward.. I don't think both products are going to get equal attention.",
          "score": 5,
          "created_utc": "2026-02-11 08:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iwxwj",
          "author": "Proudly_Funky_Monkey",
          "text": "Is there a better way to manage the lifecycle of parallel pipelines?¬†\n\n\nContext: we use DBT core to build features for ml models. New data is ingested weekly, and from it new model features are built through a tree of 30+ very complicated tables. Models are then fed these latest features. We're pretty happy with this.¬†\n\n\nBut when we want/need to develope new/different model features, we really struggle with versioning. we only have one database: production. So end up duplicating the entire tree of tables with _version[] appended. The development is then done in the version suffixed tables until eventually it eventually becomes prod and the old tables/definitions are deleted.¬†\n\n\nWhy is this bad? Massive PRs, drift between trees during dev, significant risk of manual mistakes, entire tree must be duplicated even for small changes (complexity and cost).\n\n\nCan DBT help with our architecture problems?",
          "score": 3,
          "created_utc": "2026-02-09 23:52:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l1ez7",
              "author": "SpookyScaryFrouze",
              "text": "You could change the generate_schema_name macro in order for the target name to be appended to the schema name.\n\nThat way you would have 2 schemas : ml_models_prod and ml_models_dev, in the same database.",
              "score": 7,
              "created_utc": "2026-02-10 08:44:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4r2ls2",
                  "author": "ianitic",
                  "text": "Yup that's what we do at work. There's all contracts and model versioning in dbt as well though we haven't needed the latter yet.",
                  "score": 1,
                  "created_utc": "2026-02-11 05:32:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4j2h0o",
              "author": "fsm_follower",
              "text": "I don‚Äôt have a solution for you but have felt this.  Would the ability for dev pipelines to pull almost all the tables from prod then only generate those in your diff be a solution?",
              "score": 3,
              "created_utc": "2026-02-10 00:23:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tytwy",
                  "author": "andersdellosnubes",
                  "text": "interesting. can you say more?",
                  "score": 1,
                  "created_utc": "2026-02-11 17:23:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4orc2h",
              "author": "infomocrat",
              "text": "Are you familiar with model versions?   \n[https://docs.getdbt.com/docs/mesh/govern/model-versions](https://docs.getdbt.com/docs/mesh/govern/model-versions)  \nbest practice guide: [https://docs.getdbt.com/best-practices/how-we-mesh/mesh-6-coordinate-versions](https://docs.getdbt.com/best-practices/how-we-mesh/mesh-6-coordinate-versions)",
              "score": 1,
              "created_utc": "2026-02-10 21:21:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4tyqqa",
              "author": "andersdellosnubes",
              "text": "Yes, dbt should be able to help with that. It is a pretty detailed use case you have so we won‚Äôt be able to go into a lot of details but I feel like a combination of using [dbt clone](https://docs.getdbt.com/reference/commands/clone) and/or [deferral](https://docs.getdbt.com/reference/node-selection/defer) to build only the minimum set of models for a given ML feature branch.  \n  \nThen, my first instinct would also be to try to use different schemas or database to separate the output of the different LM pipelines..\n\n  \nAlso lots of others have contributed ideas that you might find helpful as well",
              "score": 1,
              "created_utc": "2026-02-11 17:23:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ngrbx",
          "author": "uglylookingguy",
          "text": "What‚Äôs the biggest mistake teams make when adopting dbt that doesn‚Äôt show up until months later in production?",
          "score": 4,
          "created_utc": "2026-02-10 17:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u3iam",
              "author": "schemas_sgski",
              "text": "I have seen two extremes.  \n  \nI have seen teams trying to come up with the end to end data pipeline design on paper, without writing any model, and then trying to implement it.  \n  \ndbt is made for agility, so, my experience is that people should write models, iterate, refactor, deprecate, improve etc‚Ä¶ With CI/CD in place there is not a lot of risk in modifying existing models, not like with platforms not backed by git and version control.  \n  \nThe other extreme is people going a bit wild on the models they build and not focusing on PR reviews and overall coherence. After a few months a dbt project can become complex if not managed enough. What I recommend here is to set some tools like [dbt-projet-evaluator](https://github.com/dbt-labs/dbt-project-evaluator) as soon as possible so that best practices are baked into the project from its inception.",
              "score": 2,
              "created_utc": "2026-02-11 17:45:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u972o",
              "author": "andersdellosnubes",
              "text": "sometimes, as the case in all engineering, just because you can do something that feels smart, doesn't mean that you should.\n\nI'm not so extreme as folks who say\n\n>the best code is the code you don't write\n\nhowever, with great jinja powers comes great responsibility. now with Fusion, some users have had to rethink their pure jinja automation solutions, especially when they mess with the DAG or ask the DWH for these things\n\n",
              "score": 2,
              "created_utc": "2026-02-11 18:12:12",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ud52q",
              "author": "andersdellosnubes",
              "text": "some others from colleauges:\n\n>too many jobs and not understanding that a dbt DAG creates dependencies for you. stop doing steps like `dbt build -s model_a`. use selectors and tags instead!\n\nalso\n\n>ensure you've set up your CI/CD environments correctly at the outset and don't do a staging environment unless you really really need to\n\none more\n\n>never have multiple dbt projects that are copies of the same repo called like `project-a-staging` and `project-a-prod` \\-- it's a mess. thank me later\n\n  \nlast. lol\n\n>do not override `ref()` unless you have some batshit crazy insane reason and know what you're doing\n\nhard agree. overriding critical dbt jinja macros connotes great power, but comes with great responsiblitly! \"KISS\" rules the day",
              "score": 2,
              "created_utc": "2026-02-11 18:30:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4oj2su",
          "author": "uncertainschrodinger",
          "text": "What are some new trends, ideas, competitors, and schools of thought that you find to be the biggest threat to the principles and roadmap of dbt?",
          "score": 4,
          "created_utc": "2026-02-10 20:43:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u8n48",
              "author": "dbt-jason",
              "text": "So dbt arose in popularity because of a very specific set of technological circumstances. Cloud data warehouses allowed you to load more data into yuor warehouse, but there wasn't a great way to manage this. Compute was cheap, storage was cheap, but getting useful, structured answers was challenging and difficult.  \n  \nThat technological paradigm isn't going anywhere, but it is going to be changed *a lot* by AI. Something that I'm thinking a lot about is how to make \"the dbt lifestyle\" remains relevant in the AI era.  \n  \nFor example, we saw an interesting article published [this week](https://substack.com/@groupby1/p-187428984) claiming that the \"Modern Data Stack\" worked great for humans, but there are other tools that will perform better for agents. I think it's important to take an honest look here - the experiment run in this wasn't very rigorous from what I can tell, but it might be pointing at something real.  \n  \nBut I really do believe we have an interesting role to play in the AI world. For example - last year we shipped the [dbt MCP server](https://github.com/dbt-labs/dbt-mcp) and we just released [dbt agent skills](https://github.com/dbt-labs/dbt-agent-skills) but the thing that's really exciting to me here is some testing we've been doing around how Fusion (because it's faster, has more metadata awareness and is more strongly typed) can be the best of both worlds- a great experience for human developers and powering agentic workloads.",
              "score": 1,
              "created_utc": "2026-02-11 18:09:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4k3rdf",
          "author": "ActEfficient5022",
          "text": "What would you say you do here?",
          "score": 6,
          "created_utc": "2026-02-10 04:05:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tkp7y",
              "author": "turboDividend",
              "text": "i mean, it can build depencys which would be useful in some use cases. ive alway been kind of skeptical of this tool though",
              "score": 3,
              "created_utc": "2026-02-11 16:17:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4r2udj",
              "author": "ianitic",
              "text": "I have people skills and I'm good at dealing with people so the engineers don't have to.",
              "score": 2,
              "created_utc": "2026-02-11 05:34:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u5sa4",
              "author": "andersdellosnubes",
              "text": "~~Well, I generally come in at least fifteen minutes late, ah, I use the side door - that way Lumbergh can't see me, heh heh - and, uh, after that I just sorta space out for about an hour~~.\n\nWell, I generally I ship Fusion Diaries a few days late, I work with Slack notifications off - that way u/dbt-jason can't ping me, heh heh - and, uh, after that I just sorta refresh Hacker News until links about data show up\n\nalternatively phrased: Developer Experience Advocacy!",
              "score": 2,
              "created_utc": "2026-02-11 17:56:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kkib8",
          "author": "Ramshizzle",
          "text": "Do you have any plans for improving how dbt deployment pipelines are configured, build and run?\n\nAt my company we are brand new to dbt-cloud. So far I really love dbt and all its capabilities. There is one issue I'm having, which is the only way it seems we can create an ETL pipelines from dbt-cloud is to manually click together a 'deployment job'.\n\nI am already experimenting with dbt-jobs-as-code, but while that is a great tool, it seems like that is still in early development.\n\nAt this moment we are considering getting an outside scheduler/orchestration tool. Which would be a shame in my opinion.",
          "score": 3,
          "created_utc": "2026-02-10 06:09:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oruyl",
              "author": "infomocrat",
              "text": "terraform? [https://registry.terraform.io/providers/dbt-labs/dbtcloud/latest/docs](https://registry.terraform.io/providers/dbt-labs/dbtcloud/latest/docs)\n\nTalk: [https://www.getdbt.com/resources/coalesce-on-demand/coalesce-2024-why-analytics-engineering-and-devops-go-hand-in-hand](https://www.getdbt.com/resources/coalesce-on-demand/coalesce-2024-why-analytics-engineering-and-devops-go-hand-in-hand)",
              "score": 1,
              "created_utc": "2026-02-10 21:23:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u8jbq",
              "author": "schemas_sgski",
              "text": "as an orchestration nerd, I love this question - and welcome to dbt cloud! This is an area of dbt that we spend a lot of time thinking about, and one exciting feature we have recently shipped is [state-aware orchestration](https://docs.getdbt.com/docs/deploy/state-aware-about). It lets you build and run based on what‚Äôs actually changed (using state comparison and deferral), which can make pipelines a lot more efficient, especially as your project grows. There are also some [advanced configs](https://docs.getdbt.com/docs/deploy/state-aware-setup#advanced-configurations) that you can set up to customize at a more granular level and specify what actually gets run. This does require fusion. If you can share what you are looking for when scheduling jobs I'm happy to share some other functionality of the dbt orchestrator.",
              "score": 1,
              "created_utc": "2026-02-11 18:09:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m6uf5",
          "author": "Existing_Wealth6142",
          "text": "What is your perspective on open table formats like Iceberg,  Delta Lake, and Hudi? If you are positive on the technology, what do you think are the most important features still lacking from either the formats or dbt in order to maximize their value?",
          "score": 3,
          "created_utc": "2026-02-10 14:04:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u7ktd",
              "author": "andersdellosnubes",
              "text": "omg what a nerd snipe of a question!\n\nfor me what i'm most looking forward too are features that make it so that it just works for us analytics engineers! also my white whale forever has been a \"multi-engine stack\" with one iceberg catalog but heterogenous query engines.\n\nwhat's missing? support for the Iceberg Rest Catalog is still spotty amongst vendors, and the IRC itself needs some improvement (performance & federated, user-level authentication).\n\nif Iceberg and other formats are working as they should, we as analytics engineers should hardly ever have to thing of them!\n\nI also answered more in [this answer](https://www.reddit.com/r/dataengineering/comments/1r0ff3b/comment/o4u3x71/) to u/Longjumping-Pin-3235",
              "score": 2,
              "created_utc": "2026-02-11 18:04:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ucvfm",
                  "author": "Existing_Wealth6142",
                  "text": "thanks for the response! A multi engine stack is also on my wishlist. Do you have a thought on which catalog best facilitates that? I've been wondering about either R2 or Lakekeeper as they seem like they might be credibly neutral",
                  "score": 1,
                  "created_utc": "2026-02-11 18:29:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ng6a3",
          "author": "domscatterbrain",
          "text": "What's the big roadmap for DBT?\n\nYou must know that, while the acquisition shenanigans are good for your team (hopefully) it made many people who's been a long fan of DBT furious.",
          "score": 3,
          "created_utc": "2026-02-10 17:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ua1g1",
              "author": "dbt-jason",
              "text": "Shared some thoughts on [this here](https://www.reddit.com/r/dataengineering/comments/1r0ff3b/comment/o4u1abx/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)!",
              "score": 3,
              "created_utc": "2026-02-11 18:16:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4o5oy4",
          "author": "Adrien0623",
          "text": "When will the fix for dbt-redshift connector will come so that materialized view refresh stops failing randomly?",
          "score": 3,
          "created_utc": "2026-02-10 19:40:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tzzko",
              "author": "Longjumping-Pin-3235",
              "text": "dbt just issues the DDL, right?",
              "score": 2,
              "created_utc": "2026-02-11 17:29:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u03gj",
              "author": "dbt-zeeshan",
              "text": "Hey I see a couple that seem related [\\#1256](https://github.com/dbt-labs/dbt-adapters/issues/1256) and [\\#1499](https://github.com/dbt-labs/dbt-adapters/issues/1499). If you share the link we'll definitely take a look!",
              "score": 2,
              "created_utc": "2026-02-11 17:29:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lsn8q",
          "author": "GarpA13",
          "text": "Are you planning to abandon dbt core? What is your vision for on-premise software?",
          "score": 5,
          "created_utc": "2026-02-10 12:40:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u6yk6",
              "author": "dbt-grace",
              "text": "**TLDR;** No, we are actively shipping new features to dbt Core! \n\nWrote up a longer response [here](https://www.reddit.com/r/dataengineering/comments/1r0ff3b/comment/o4u5986/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) :)",
              "score": 2,
              "created_utc": "2026-02-11 18:01:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ju1xp",
          "author": "superconductiveKyle",
          "text": "Hey dbt Crew, I'm Kyle Eaton, Head of Growth at Agno (https://github.com/agno-agi/agno). I've been a big fan of your product for a long time now and specifically the community you all created. I'm the Former Head of Growth at Great Expectations, so I've been following for a long time.\n\nWe recently asked some of our users who we should partner with, and dbt came up. Seeing your AMA reminded me about this. Would love the chat with you all about what a partnership with Agno and dbt could look like! \n\nHope you have fun with your AMA! ",
          "score": 2,
          "created_utc": "2026-02-10 03:03:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u609j",
              "author": "andersdellosnubes",
              "text": "hey u/superconductiveKyle IIRC our paths have crossed before, at least i've been in GE slack for many years. feel free to reach out on LinkedIn would love to say hi and talk shop",
              "score": 2,
              "created_utc": "2026-02-11 17:57:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ubj2z",
                  "author": "superconductiveKyle",
                  "text": "Hello! That's awesome. Just sent a connect via LinkedIn. ",
                  "score": 1,
                  "created_utc": "2026-02-11 18:23:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4lhwd6",
          "author": "finally_i_found_one",
          "text": "RemindMe! 4 days",
          "score": 2,
          "created_utc": "2026-02-10 11:19:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4li1k1",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 4 days on [**2026-02-14 11:19:40 UTC**](http://www.wolframalpha.com/input/?i=2026-02-14%2011:19:40%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/o4lhwd6/?context=3)\n\n[**2 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1r0ff3b%2Fama_were_dbt_labs_ask_us_anything%2Fo4lhwd6%2F%5D%0A%0ARemindMe%21%202026-02-14%2011%3A19%3A40%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r0ff3b)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-10 11:20:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lim0t",
          "author": "set92",
          "text": "I'm deciding in moving my code from Airflow to Dbt using Cosmos. The idea is that instead of having custom sql code with jinja, I can move everything to dbt and let it run everything. \n\nI do this to improve in logging/debugging, and easiness. I suppose the speed/easiness is going to be there. But not sure about the logging part. Does dbt returns the output of queries, or is something that we can modify or specify in our own?",
          "score": 2,
          "created_utc": "2026-02-10 11:25:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ofuk2",
              "author": "Comfortable-Power175",
              "text": "Have you looked into dbt elementary? This is how we monitor model runs. FWIW we have an airflow + dbt + cosmos with elementary setup and are extremely happy",
              "score": 2,
              "created_utc": "2026-02-10 20:27:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4oqz3a",
                  "author": "set92",
                  "text": "Thanks, I'll check it. Although in general I was thinking more in the outputs itself. Like we have Snowflake, and the Operator of Airflow doesn't show you the results of the query by default, and in Snowflake itself only the owner of the query can check the results for 24h only. So, I thought maybe with dbt I could log this, like for example when I do COPY INTOs be able to see if a file has failed, and other information that comes on that results table, but I suppose the best will be to find some free moment and test it myself.",
                  "score": 2,
                  "created_utc": "2026-02-10 21:19:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4u8xq8",
              "author": "dbt-grace",
              "text": "Hey! I would point you to a few different places: \n\n* [log jinja function](https://docs.getdbt.com/reference/dbt-jinja-functions/log) for logging custom messages\n* [exceptions](https://docs.getdbt.com/reference/dbt-jinja-functions/exceptions#warn) for raising warnings/errors\n* [dbt show](https://docs.getdbt.com/reference/commands/show) command for displaying a preview of results from a query\n* [documentation on events and logs](https://docs.getdbt.com/reference/events-logging)",
              "score": 1,
              "created_utc": "2026-02-11 18:11:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ualfm",
              "author": "andersdellosnubes",
              "text": "interesting! what are you looking for w.r.t. logging? Are you saying you to log the result of queries? Most folks don't, preferring to keep the data where it is.\n\n  \nI'm not sure if you've looked much into dbt Fusion, but it's [telemetry](https://docs.getdbt.com/docs/fusion/telemetry) is based on OTel, quite robust and just as extensible as dbt Core.\n\nlike u/Comfortable-Power175 said, there's also great dbt packages that help with logging and monitoring",
              "score": 1,
              "created_utc": "2026-02-11 18:18:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4uwxqi",
                  "author": "set92",
                  "text": "Anything that could help me debug ETLs when something fail. When something fails I like to see what it ran, and what was the output of everything in case I can detect where it failed. I would not be able to understand everything, but seeing that a file of X customer didn't get ingested, or that X parameter was not set as I thought could help me debug the problems faster. \n\nBut yep, in Snowflake they told me that the results of queries were only visible for 24h by the owner of the query, no one else, not even an accountadmin could see the results. Which for me seems madness, and completely different than, if I'm not wrong, BQ, where anyone can see all the queries run, and that let you see/analyze any query and see what was processed, or didn't run as intended.\n\nFor copy into maybe the list of files, or be able to filter and only get the ones that failed to ingest, and trigger an alarm with it.\n\nAnother example could be when I run a MERGE on Snowsight (UI of Snowflake) it returns me the inserted and merged cols I think it is. I built some custom code to retrieve those values to sql variable and store them in a logging table. But it would be good if the tool has the functionality on its own. \n\nOr there is a query where I retrieve the max date of the ingested data, store it in a sql variable, and use it later. From what @dbt-grace said, I would be able to use [log jinja functions](https://docs.getdbt.com/reference/dbt-jinja-functions/log) to print those to the log, that way if we have a problem in the future I will be able to see which data we processed.",
                  "score": 1,
                  "created_utc": "2026-02-11 20:03:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4q9uw0",
          "author": "infomocrat",
          "text": "What have been your favorite Coalesce talks of all time?\n\nIf you could wish any talk into existence for a future Coalesce (ok, dbt Summit) what would it be?",
          "score": 2,
          "created_utc": "2026-02-11 02:19:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ubgz8",
              "author": "dbt-grace",
              "text": "I love it when community members give talks sharing their custom solutions! It's very inspiring to see what people are doing in the wild, and (selfishly) helpful when building out our roadmap for dbt Core. [Mariah Rodger's talk on testing](https://www.youtube.com/watch?v=hxvVhmhWRJA) is one of the many community projects that motivated us to build out-of-the-box support for unit testing into dbt :)",
              "score": 2,
              "created_utc": "2026-02-11 18:22:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u1kaf",
              "author": "dbt-zeeshan",
              "text": "Definitely u/dbt-grace [live-coding UDFs](https://youtu.be/aMUAQjqTKtc?si=vN4H-TEBf4EHpntw&t=1130) while roller blading!",
              "score": 1,
              "created_utc": "2026-02-11 17:36:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ub9ov",
              "author": "andersdellosnubes",
              "text": "The Magic School Bus themed talk with u/dbt-grace about dbt Mesh  \n[https://www.youtube.com/watch?v=FAsY0Qx8EyU](https://www.youtube.com/watch?v=FAsY0Qx8EyU)",
              "score": 1,
              "created_utc": "2026-02-11 18:21:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tuemk",
          "author": "Longjumping-Pin-3235",
          "text": "Iceberg  \nShould it be the default for a new project or greenfield snowflake environment?\n\nIs the complexity worth it?\n\nWhat catalog would you reach for for the most compatible multi-engine read / write?",
          "score": 2,
          "created_utc": "2026-02-11 17:03:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u3x71",
              "author": "andersdellosnubes",
              "text": "This feels like the most important question re: Iceberg, huh?\n\nThere's lots of opinions here but my take: Iceberg isn't a free lunch.  \n  \nYou need a business case and the pros need to outweigh the drawbacks. This was actually discussed as well in [a recent episode ](https://www.getdbt.com/blog/apache-iceberg-and-the-catalog-layer)of the Analytics Engineering podcast. There's another episode due out soon where Tristan and I discuss the future of Iceberg.  \n  \nIceberg brings you the flexibility around where your data is stored and what compute you pick, but it adds complexity in having to manage an iceberg catalog. There are a few iceberg catalogs out there but many of them support ‚Äúpart‚Äù of the iceberg spec, and finding who supports what is not super easy.  \n  \nIf you are all-in on a data platform and won‚Äôt need cross data warehouse compute my take is that Iceberg would not be worth the effort today.\n\nHowever my prevailing opinion is that the Iceberg project is to data what standard-sized ship containers do for global trade. It's not necessarily \"exciting\" per se, but it has undeniable impacts on end users in that it's easier to get your ~~goods~~ data from point A to point B",
              "score": 1,
              "created_utc": "2026-02-11 17:47:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tujdn",
          "author": "infomocrat",
          "text": "With fusion and state aware orchestration, a lot of issues around multi-project orchestration can be solved. What problems do you see that \\*still exist\\* to be solved for more complex implementations of dbt involving multiple interconnected projects, and what are some strategies you see for addressing them?",
          "score": 2,
          "created_utc": "2026-02-11 17:03:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u5588",
              "author": "andersdellosnubes",
              "text": "short-answer: yes!\n\ncan you share what complex scenarios you've seen that you think can be addressed?",
              "score": 1,
              "created_utc": "2026-02-11 17:53:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4u97qc",
                  "author": "jtcohen6",
                  "text": "short-answer: seconded!\n\nthe challenges I keep hearing about are more \"socio-technical\" - improvements to dbt framework / platform / related tooling can help, but probably aren't sufficient in a vacuum:  \n\\- managing and discovering data products across multiple teams  \n\\- communicating data quality and freshness data contracts for public dbt models.  \n\\- sharing reusable macro code in (private) packages, with (semantic? calendar?) versioning for breaking changes to those macros (which are still untyped in dbt...)  \n\\- supporting multi-project deployments across \\*multiple data platforms\\* (think: upstream project on Databricks / downstream project on Snowflake, with a common Iceberg catalog across both)  \n\\- model-level access controls (more granular than project-level access)  \n\\- ... lots of other things I'm sure I'm not thinking/hearing about ...",
                  "score": 1,
                  "created_utc": "2026-02-11 18:12:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tyszp",
          "author": "Longjumping-Pin-3235",
          "text": "Did u/dbt-grace watch How To Trick People Into Thinking You can Juggle?  \n[https://youtube.com/shorts/trKLrl6y\\_Vc?si=Y9zMa2dQMt\\_ZCgU0](https://youtube.com/shorts/trKLrl6y_Vc?si=Y9zMa2dQMt_ZCgU0)",
          "score": 2,
          "created_utc": "2026-02-11 17:23:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u24fq",
              "author": "dbt-grace",
              "text": "LOL - you can actually thank my high school drama teacher for that one ([from deep in the archives](https://imgur.com/QakqCAT))",
              "score": 3,
              "created_utc": "2026-02-11 17:39:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kq035",
          "author": "Tall_Working_2146",
          "text": "Your certifications are interesting but the price is high, are there no initiative to make learning resources more accessible for students and people abroad?",
          "score": 4,
          "created_utc": "2026-02-10 06:56:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oqywm",
              "author": "infomocrat",
              "text": "The learning resources are all free: [https://learn.getdbt.com/catalog](https://learn.getdbt.com/catalog)   \nCertifications are half off if you take them at coalesce, also partners can get discounts. But certifications are really only important in certain situations (for partners, if employer requires it to prove your knowledge). I wouldn't worry about the certs unless you need it. If you want to prove your knowledge, put up a personal project on your github.",
              "score": 2,
              "created_utc": "2026-02-10 21:19:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4uo2rq",
              "author": "[deleted]",
              "text": "Truly agree with others: ignore certs and just take the learning resources cause as others have said, they're all free!!",
              "score": 1,
              "created_utc": "2026-02-11 19:21:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4n1bel",
          "author": "Ready-Marionberry-90",
          "text": "What problem do you exist to solve?",
          "score": 3,
          "created_utc": "2026-02-10 16:35:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u130q",
              "author": "andersdellosnubes",
              "text": "juicy! the thing that drew me to dbt originally was Tristan (founder/CEO) answering this question on the [Software Engineering Podcast: dbt](https://softwareengineeringdaily.com/2021/09/28/dbt-data-build-tool-with-tristan-handy-2/)\n\ndbt exists to solve the problem that data analysts don't have a career path beyond:  \n\"manage more dashboards\" or \"manage more people\".\n\nimho, dbt exists to solve that socio-technical problem and others common amongst data practitioners",
              "score": 2,
              "created_utc": "2026-02-11 17:34:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mrppy",
          "author": "sleeper_must_awaken",
          "text": "How will you prevent companies being charged $350 / seat / month for an enterprise DBT Cloud subscription of three years when they need more than 8 seats? ¬†This is a real story I‚Äôve seen at two of our clients. That amount is just inordinate and betrays the trust companies and consultancies have placed in your DBT Labs.\n\nFor me, DBT Labs needs to regain my trust. I‚Äôve recommended many companies to use DBT Core and DBT Cloud since 2019, but am hesitant to continue recommending it.\n\nCompare that pricing with GitHub, which also has runners, incident management, traceability, collaboration, auditing and IdP integration (among many other things).",
          "score": 4,
          "created_utc": "2026-02-10 15:50:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tqp2d",
          "author": "J0hnDutt00n",
          "text": "Will there ever be more dynamic ways of orchestrating jobs in Cloud?",
          "score": 1,
          "created_utc": "2026-02-11 16:45:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4twpgq",
              "author": "andersdellosnubes",
              "text": "my interest is piqued -- can you share more about what you mean by \"dynamic\"?",
              "score": 1,
              "created_utc": "2026-02-11 17:13:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4uh9cn",
                  "author": "J0hnDutt00n",
                  "text": "Sorry for the vague question, scenario: build fails on one model that succeeded yesterday and employ a WAP strategy. Will there ever be the ability to automatically re-execute a build but with that stale data model from yesterday to unblock those downstream models with an *asterisk of stale prod data model used? This already is essentially capable for child mesh projects but not others.",
                  "score": 2,
                  "created_utc": "2026-02-11 18:49:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tvna4",
          "author": "infomocrat",
          "text": "What do you think is the most under-appreciated feature of dbt core?",
          "score": 1,
          "created_utc": "2026-02-11 17:08:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tz803",
              "author": "andersdellosnubes",
              "text": "dbt seed! csv's (while ugly) aren't going away for anytime soon! when i started in data a decade ago. \"getting data in the database\" was like half the coding work to be done in my Jupyter notebook. \\`dbt seed\\` makes it so easy",
              "score": 1,
              "created_utc": "2026-02-11 17:25:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ucd7m",
              "author": "dbt-grace",
              "text": "I am a big fan of all of the ways you can customize your dbt project to meet your org's specialized needs - specifically, I've seen a lot of creative problem-solving using [custom materializations](https://docs.getdbt.com/guides/create-new-materializations?step=1)!",
              "score": 1,
              "created_utc": "2026-02-11 18:26:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4o8pge",
          "author": "Ok-Sentence-8542",
          "text": "Why did you abandon dbt core and the open source community?",
          "score": 1,
          "created_utc": "2026-02-10 19:54:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1tcjp",
      "title": "It's nine years since 'The Rise of the Data Engineer'‚Ä¶what's changed?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r1tcjp/its_nine_years_since_the_rise_of_the_data/",
      "author": "rmoff",
      "created_utc": "2026-02-11 09:58:52",
      "score": 130,
      "num_comments": 30,
      "upvote_ratio": 0.95,
      "text": "See title\n\nMax Beauchemin published [The Rise of the Data Engineer](https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603) in Jan 2017 (_and [The Downfall of the Data Engineer](https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b) seven months later_).\n\nWhat's the biggest change you've seen in the industry in that time? What's stayed the same?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r1tcjp/its_nine_years_since_the_rise_of_the_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4sncod",
          "author": "redditreader2020",
          "text": "COVID and AI. And I have more grey hair. Otherwise not much.",
          "score": 115,
          "created_utc": "2026-02-11 13:27:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tqr0r",
              "author": "updated_at",
              "text": "I'm balding",
              "score": 17,
              "created_utc": "2026-02-11 16:45:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ttb5t",
                  "author": "zerofatorial",
                  "text": "/r/tressless",
                  "score": 8,
                  "created_utc": "2026-02-11 16:57:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4swe8s",
          "author": "drag8800",
          "text": "Been in data since 2012. Few observations:\n\nWhat changed completely:\n- Infrastructure abstraction. In 2017 we were still debating Hadoop distributions. Now most teams never think about cluster management.\n- Analytics engineering emerged as a discipline. Beauchemin predicted DEs would need more SQL, but underestimated how much the transformation layer would specialize (dbt, semantic layers, etc.)\n- The 'modern data stack' hype cycle. Lots of point solutions that promised to solve specific problems, then consolidation as everyone realized 47 tools was too many.\n\nWhat stayed the same (unfortunately):\n- The gap between 'we have data' and 'we understand the business domain.' Still the hardest part.\n- Pipeline maintenance burden. Different failure modes now (API rate limits vs disk space), same percentage of time spent on it.\n- Stakeholder expectations vs data quality reality.\n\nWhat's genuinely better:\n- Getting started is 10x easier. A junior can have a working pipeline in a day instead of weeks.\n- The tooling for testing and observability actually exists now.\n- Version control for transformations is standard, not exotic.\n\nThe 'Downfall' article was prescient about platform engineering eating some DE work. But the semantic layer and data modeling parts got more complex, not less. Different work, roughly same headcount.",
          "score": 145,
          "created_utc": "2026-02-11 14:17:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tif2n",
              "author": "Kobosil",
              "text": ">The gap between 'we have data' and 'we understand the business domain.' Still the hardest part.\n\nas long thats the case i am not worried for my job",
              "score": 33,
              "created_utc": "2026-02-11 16:07:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vdrm1",
                  "author": "trixiethegoat",
                  "text": "same. It's a pain, but once you're the data SME for the business team and the domain SME for the data engineering team, you're golden.",
                  "score": 8,
                  "created_utc": "2026-02-11 21:25:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4tf7td",
              "author": "cokeapm",
              "text": "What tooling for testing and observability do you recommend?",
              "score": 3,
              "created_utc": "2026-02-11 15:52:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tqu6q",
                  "author": "updated_at",
                  "text": "Monte Carlo and soda",
                  "score": 6,
                  "created_utc": "2026-02-11 16:46:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4vkna7",
              "author": "umognog",
              "text": "I was just reflecting earlier today on the same point about having a working pipeline in a day rather than a week.\n\nToday, i not only put up a PPE & a prod machine and wrote \"the happy path code\" but I also had it all connected to observation, lineage and some basic tests.\n\nIn 5 hours.\n\nThat was really unheard of by a single person in my business in 2015/2016. Getting a VM alone was 4-6 weeks back then.",
              "score": 2,
              "created_utc": "2026-02-11 21:57:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4thiax",
          "author": "mach_kernel",
          "text": "As hardware is getting better some \"big data\" is no longer that big. I see more and more developers reaching for things like DuckDB. I see an increase of robust federation solutions for cross-engine queries and optimizations.\n\nI am happy to see that the enterprise data pipeline is becoming more \"a la carte\".",
          "score": 23,
          "created_utc": "2026-02-11 16:03:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vdgpt",
              "author": "Mclovine_aus",
              "text": "So many places where the data could easily fit in a single machine, but execs fell for the big data warehouse and have bought a managed spark service like synapse - the bane of my existence.",
              "score": 6,
              "created_utc": "2026-02-11 21:23:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4xxhxk",
                  "author": "One_Citron_4350",
                  "text": "Yes, they looked at it from a one-size-fits all point of view. Let's just put everything in Databricks with Spark.",
                  "score": 1,
                  "created_utc": "2026-02-12 06:58:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u7cyd",
          "author": "StewieGriffin26",
          "text": "Lots of consolidation to either Snowflake or Databricks. Either platform \"does it all\" now. \n\nAlso reinventing the wheel. What IBM and Oracle released back in the 80s is what Databricks and Snowflake are releasing now, just with a fancier name.",
          "score": 21,
          "created_utc": "2026-02-11 18:03:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4v3n1g",
              "author": "GarboMcStevens",
              "text": "software is cyclical. People old enough age out and then you can rebrand old things as new.",
              "score": 11,
              "created_utc": "2026-02-11 20:36:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4v7pgx",
              "author": "kbisland",
              "text": "I‚Äôm wondering what IBM or Oracle released?",
              "score": 9,
              "created_utc": "2026-02-11 20:56:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vldi2",
                  "author": "StewieGriffin26",
                  "text": "https://old.reddit.com/r/dataengineering/comments/1r1tcjp/its_nine_years_since_the_rise_of_the_data/o4vl9cp/",
                  "score": 1,
                  "created_utc": "2026-02-11 22:01:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4vdl2k",
              "author": "Mclovine_aus",
              "text": "Wha are some examples of re released features?",
              "score": 2,
              "created_utc": "2026-02-11 21:24:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vl9cp",
                  "author": "StewieGriffin26",
                  "text": "Databricks released temporary tables on Dec 9, 2025.  \nOracle released temporary tables in 1999.  \nIBM released temporary tables in 2001.  \nSnowflake released temporary tables in 2014.  \nSybase released temporary tables in ~1987.",
                  "score": 9,
                  "created_utc": "2026-02-11 22:00:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4xowb3",
              "author": "sib_n",
              "text": "I don't think making data warehousing work on a distributed cluster of commodity machines is just a \"fancier name\". There's a reason why Google, Yahoo and all web giants, invested in R&D to develop them from the 00', which gave birth to Hadoop. Snowflake and Databricks are abstracting this but it is still behind.  \nWhat's true is that they are still trying to reach the same level of reliability and features that those monolithic systems already had (like ACID), but some of them are not easy to reach with a distributed system. The latest big improvements towards this is the new table formats like Iceberg and Delta Lake to allow merge, time travel, column renaming and other metadata related features.",
              "score": 1,
              "created_utc": "2026-02-12 05:43:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4vetcr",
          "author": "Eleventhousand",
          "text": "Back before the term Data Engineer was a thing, I was still making design patterns and frameworks for my team.  Yes, I also spent half of my time on business problems, but I spent the other half on ensuring that we had a rock-solid and maintainable product, including tooling developed in 3GL languages as opposed to pure SQL.  There were other companies that had job duties split out - one team might handle the data modeling, another might handle the Informatica stuff, and another might handle dashboards, reports, and ad-hoc requests for insights.  I don't think much changed fundamentally, other than the job title, no different than going from being titled Programmer/Analyst one decade to Software Engineer during the next.  So, I'm not totally sold on the rise of Data Engineer.\n\nAs far as what has changed since 2017, really, just more cloud tools, more automation, etc.\n\n",
          "score": 7,
          "created_utc": "2026-02-11 21:30:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4whsre",
          "author": "_TheDataBoi_",
          "text": "I was hired as a data engineer, but my role demands more than just data engineering starting from devops, data analysis, front end (streamlit and nextjs), business translation, some legal aspects of data processing and sharing, infra maintainability lmao.\n\n\nSince being a data engineer already would've touched the above tangents, we are now expected to take the entire thing upon ourselves. Data engineering has become the bridge connecting business to tech. Data engineers are the ones who enable decisions. We are just not in the spotlight.",
          "score": 7,
          "created_utc": "2026-02-12 00:58:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tcck6",
          "author": "zjaffee",
          "text": "The truth is that data engineer is a fake role that can mean tons of different things to different people in the same way roles like DevOps engineer or SRE can, increasingly ML engineer has a similar vibe. This was something very popular in the world of software development in 2017 where people were very focused on defining what large software teams should look like, along with the desire to build all sorts of new frameworks, this has died down.\n\nThere are places where a data engineer is a software engineer who owns the full stack of the data platform whatever that means, including in my cases also building data products on top of said platform. There are other places where a data engineer is someone who writes SQL largely for ETL purposes and maybe just manages the schema and type definitions of a particular data set and optimizes the routine queries that are run against said database, but even then that can be a stretch. In other cases, it might just be closer to a db admin setting privacy rules so that development teams cannot misuse PII.",
          "score": 20,
          "created_utc": "2026-02-11 15:38:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tigtg",
              "author": "Swayfromleftoright",
              "text": "Couldn‚Äôt you say that about pretty much any tech role though? A data analyst at company A probably spends their time differently to one at company B",
              "score": 12,
              "created_utc": "2026-02-11 16:07:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4trbic",
                  "author": "updated_at",
                  "text": "A carpenter at company A builds tables and at the company B builds doors. Always been like that",
                  "score": 7,
                  "created_utc": "2026-02-11 16:48:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4v30sf",
          "author": "Accomplished-Row7524",
          "text": "dbt and analytics engineering",
          "score": 2,
          "created_utc": "2026-02-11 20:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xftus",
          "author": "Wizardij",
          "text": "The Rise of the Dead Engineers!\n\nNobody wants to work anymore. üòÅ",
          "score": 1,
          "created_utc": "2026-02-12 04:32:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxifq4",
      "title": "Is classic data modeling (SCDs, stable business meaning, dimensional rigor) becoming less and less relevant?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxifq4/is_classic_data_modeling_scds_stable_business/",
      "author": "Likewise231",
      "created_utc": "2026-02-06 14:02:24",
      "score": 123,
      "num_comments": 40,
      "upvote_ratio": 0.96,
      "text": "I‚Äôve been in FAANG for about 5 years now, across multiple teams and orgs (new data teams, SDE-heavy teams, BI-heavy teams, large and small setups), and one thing that‚Äôs consistently surprised me is how little classic data modeling I‚Äôve actually seen applied in practice.\n\nWhen I joined as a junior/intern, I expected things like proper dimensional modeling, careful handling of changing business meaning, SCD Type 2 being a common pattern, and shared dimensions that teams actually align on ‚Äî but in reality most teams seem extremely execution-focused, with the job dominated by pipelines, orchestration, data quality, alerts, lineage, governance, security, and infra, while modeling and design feel like maybe 5‚Äì10% of the work at most.\n\nEven at senior levels, I‚Äôve often found that concepts like ‚Äúensuring the business meaning of a column doesn‚Äôt silently change‚Äù or why SCD2 exists aren‚Äôt universally understood or consistently applied. In tech-driven organizations it is more structured, but in business-driven organizations it's less structued (Organization I mean ¬±100-300 people organization).\n\nMy logic is because compute and storage got so much cheapier over the years, the effort/benefit ratio is not there in as many situations. Curious what others think: have you seen the same pattern?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxifq4/is_classic_data_modeling_scds_stable_business/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3wqclv",
          "author": "JonPX",
          "text": "And then people wonder why data projects are so prone to failure.",
          "score": 132,
          "created_utc": "2026-02-06 14:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wlhq8",
          "author": "cream_pie_king",
          "text": "Yes.\n\nIt's because individual teams spin up their own analysts. Which then brute force their way into basically being shadow engineers. All in the name of \"faster time to insight\".\n\nProblem is, people leave, people shuffle around, people get promoted. No one aligns on what the metric really should be.\n\nIt eventually blows up in everyone's face when multiple versions of the same number hit the desks of execs and the board.\n\nThese embedded analyst fiefdoms resist change and take it as a personal insult when you tell them their 5000 line query that feeds one report is garbage, not scalable, and you can't run a business like this. \n\nYou're then targeted as slowing things down for trying to put real rigor into the data platform.\n\nI'm leaving an environment like this in a week. For a greenfield opportunity to build the stack from scratch precisely because I'm tired of this bullshit.\n\nI don't care about the minor and bootcamp you took in SQL and Python. That shit can't run a multi billion dollar business long term.\n\nHell I'm seeing intern built \"data science\" workloads being deployed. They're \"version controlled\" in SharePoint and run locally to push to reporting. When we push back it's our fault.",
          "score": 120,
          "created_utc": "2026-02-06 14:17:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wphxu",
              "author": "hectorgarabit",
              "text": ">¬†take it as a personal insult when you tell them their 5000 line query that feeds one report is garbage\n\nSome head of Analytics / BI told me, when I proposed some dimensional modeling that they were not interested in \"philosophy\". Their model is chaos and they spin countless hours untangling their spaghetti data model. They feel smart because they wrote a 1000 lines SQL query or Python notebook. They don't understand that they would be a lot smarter if their model was clean enough, so the same query only took 10 lines...\n\nThe main issue IMO is that many people come from a non-technical background, and they don't understand how data model, architecture solve the vast majority of development problems.",
              "score": 55,
              "created_utc": "2026-02-06 14:38:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xeot8",
              "author": "calaelenb907",
              "text": "Well, when you started with a green field to build an analytical system eventually you'll face the same problems you mentioned previously. People will like how your reports are accurate, faster and easier to navigate then previous ones but eventually they will target you as a person that slow things for put real rigor into the data platform yadada. Business people will act as business people even if the project is new.",
              "score": 3,
              "created_utc": "2026-02-06 16:40:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3wytyj",
              "author": "domscatterbrain",
              "text": "I always warn my manager to not to give users the freedom of running their own statements. Just drag and drop filters and pivot in their own custom dashboard is more than enough.\n\nToday by the power of chatgpt, they start creating more spaghetti. Their submitted statements looks very structured at a glance. But since, they don't give enough contexts to prompt and just copying their costly statements as is and  simply said \"this query is slow, optimize it\", the result is just anInstagramable spaghetti.",
              "score": 5,
              "created_utc": "2026-02-06 15:25:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wx36m",
          "author": "tophmcmasterson",
          "text": "No. \n\nThere are lots of people who don‚Äôt understand it and brute force implement sloppy bad practices for ad-hoc reporting. \n\nAnd then inevitably end users end up upset that the data is inflexible, report builders in tools like Power BI are seeing unexpected results, they need to make a new table or view every time they want to cross analyze things across tables, etc. \n\nAnd then the org calls on the person or consultant that actually understands data modeling to figure out where things went wrong. Or they just continue the cycle. \n\nIt‚Äôs not that it‚Äôs less relevant, it‚Äôs that there‚Äôs a huge number of developers who never understood it in the first place and think it‚Äôs not relevant because compute is faster and storage is cheap when those were never the main reasons to create a dimensional model in the first place.",
          "score": 15,
          "created_utc": "2026-02-06 15:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x5xrf",
          "author": "El_Guapo_Supreme",
          "text": "I agree with a lot of this, except the last bit about the effort to benefit not being there because of cost. You are right that compute got so cheap and efficient that people can be sloppy about architecture. \n\nBut the benefit still far exceeds the costs. The problem is leadership has a bias for action and expediency. It's hard to explain the proper modeling and architecture will make everything faster and easier down the road. \n\nBut will you get a reward for taking longer to do it correctly or fix what's broken? No. And if you have a great model, you'll never be able to point to problems that never manifested and how much time you saved. To the business it looks like you just took a long time.",
          "score": 10,
          "created_utc": "2026-02-06 15:59:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wwr5r",
          "author": "123456234",
          "text": "A few forces are pushing modeling out of the center:\n\n* Storage and compute keep getting cheaper, so the pressure to model everything 'correctly' up front is lower.\n* Dimensional modeling isn‚Äôt valuable by itself. Its real value is allowing systems to adapt as business meaning changes over time, and that benefit is easy to defer.\n* Tech debt is real, and under delivery pressure the cleanup backlog rarely wins. Even when modeling could be part of the design, timelines usually cut it first.\n* Storing source data indefinitely is becoming common, which makes replaying historical transformations feel like an acceptable substitute for managing change semantics.\n* Data teams are increasingly embedded in business units. Without a central steward, consistency across domains erodes even when the same underlying data is reused.\n* AI increases speed and lowers the cost of repetitive work, which further shifts effort toward shipping and iteration rather than integration rigor.\n* The idea of a single source of truth still matters philosophically, but if leadership doesn‚Äôt care when numbers don‚Äôt line up exactly, it‚Äôs hard to justify enforcing it.\n\nThe common thread is that modern data systems are optimized for reversibility rather than correctness. Cheap compute, infinite retention, replayability, and AI assisted iteration all increase tolerance for semantic drift. Dimensional modeling still addresses that problem, but its value only materializes when the organization is forced to care about consistency over time. \n\nModeling is rejected in favor of these other mechanisms which isn't a better approach but it does align with the systems that are readily available.",
          "score": 35,
          "created_utc": "2026-02-06 15:15:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44y0k4",
              "author": "raginjason",
              "text": "I would add to point 2 (and have done so in my organization): having a vocabulary  that every one can learn instead of being some home-grow data slop is tremendous value. If you don‚Äôt do dimensional modeling (which in reality is the only kind of modeling we use as DE), then people are calling the same concepts different words. Or mashing concepts together in a haphazard way.\n\nIf it were ‚Äúdimensional modeling vs some other modeling‚Äù I would be interested in discussion. It‚Äôs pretty much ‚Äúdimensional modeling or no modeling‚Äù, which I don‚Äôt have the patience for. This was solved over 20 years ago. The hubris of teams and organizations to think they know better than established practice is amazing to me, although extremely common.",
              "score": 3,
              "created_utc": "2026-02-07 20:13:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wxnos",
          "author": "RoomyRoots",
          "text": "LOL, no. The problem is that many companies think they are or they must be like FAANG sized ones with data projects to be successful with data products.\n\nIn the past 20 years most of the companies I worked wouldnt even be considerable to Big Data solution but still they would sink lots of money to try to mimic it.",
          "score": 9,
          "created_utc": "2026-02-06 15:19:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xg6cl",
          "author": "ding_dong_dasher",
          "text": "No they're just as relevant as before, it's just that enough platform engineers are clueless enough to not realize that this same failure-state has existed in our domain forever.\n\nIt's just in 2003 analysts were circumventing Oracle-based DW's in Excel instead of DS's marring your precious DBX deployment with AI slop.\n\nIt points to the same root cause of there having been a business need for something that the existing environment couldn't serve quickly enough. Nobody is going to tell some SVP who needs an answer yesterday that your first step is to attend the DE team's next backlog grooming session lol.\n\nThat's always going to happen and is just a reality of operating platforms used for decision support, if it feels like an adversarial thing you're probably looking at org dysfunction, not an architectural problem. Digesting analytical output and turning it into a mature reporting product is a pretty normal responsibility for data teams, imo.",
          "score": 7,
          "created_utc": "2026-02-06 16:47:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xhpi2",
          "author": "Rovaani",
          "text": "Infinite storage and compute won't help solve the problem if sales, manufacturing and logistics can't agree on what a  \"product\" or \"customer\" is or isn't and when their respective operational systems reflect that dichotomy and use different terms for same things ans same or similar terms for different things.\n\nTo solve that you need data modelling. Introduce your own terms or concepts if need be and map the source models to that. Then you can escape the trap of trying to understand several incompatible data models simultaneously just to feed the next dashboard.",
          "score": 3,
          "created_utc": "2026-02-06 16:54:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xwsp1",
          "author": "konwiddak",
          "text": "So I work for a company which several years ago purchased a drag and drop ETL tool, and handed out licenses to anyone who asked. It's an absolute mess. The tool is very expensive, and people have built these business critical monstrosities. There are workflows with over 70 inputs and outputs. IT wasn't really keeping tabs on the tool and are shitting a brick now they've realised what's out there propping up the business.\n\nFortunately there was a leader who let a few of us in the background do things properly. We've been unpicking one segment of the business for about 3 years now - and we're just finally getting to the point where people are going \"oh wow we get it now\". However, it's a constant battle to keep things under control and lots of people see us as the enemy.\n\nIf you can start well, do start well.",
          "score": 3,
          "created_utc": "2026-02-06 18:06:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ydgc5",
          "author": "kxlx_rxvi",
          "text": "I'm an entry level data engineer who started working a few months back, took courses on data warehousing and data modeling during college learnt the basics of SCDs, designing schemas and everything and loved doing it as hard as it was but haven't used any of these concepts even once so far at work.\nMakes me wonder why I spent sleepless nights learning all of these.",
          "score": 3,
          "created_utc": "2026-02-06 19:25:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42asqt",
              "author": "Data_cruncher",
              "text": "I‚Äôve said it before and I‚Äôll say it again: the value of Kimball only shines AFTER you‚Äôve tried deploying your first data warehouse.",
              "score": 2,
              "created_utc": "2026-02-07 11:18:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o44y45g",
                  "author": "raginjason",
                  "text": "That‚Äôs pretty good. I may have to steal this one.",
                  "score": 2,
                  "created_utc": "2026-02-07 20:13:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3x8tbv",
          "author": "Ploasd",
          "text": "Modelling is still important, if anything more important.",
          "score": 2,
          "created_utc": "2026-02-06 16:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40eqtj",
          "author": "drag8800",
          "text": "Honestly I think the answer depends a lot on the maturity of the org and the type of questions being asked. At places where speed to insight matters more than long term consistency, yeah people skip the modeling rigor because storage is cheap and nobody wants to wait 2 weeks for a proper star schema.\n\nBut I've seen it bite teams hard when they try to do anything cross-functional or longitudinal. Without SCDs or at least some versioning strategy you end up with a bunch of snapshots that don't stitch together and analysts reinventing the wheel every quarter.\n\nThe real issue is most teams don't feel the pain until they're 2-3 years in and by then the cost of retrofitting proper models is enormous. Classic modeling isn't dead, it's just expensive upfront and most orgs optimize for short term velocity.",
          "score": 2,
          "created_utc": "2026-02-07 02:01:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44ylkm",
              "author": "raginjason",
              "text": "Reflecting on what I have done with modeling, I admit that nobody wants to wait 2 weeks for a proper star schema. However, often you can take an engineering-first approach to star schema design and just get it done in short order. Technically you should engage business analysts and stakeholders and the like, but I‚Äôve seldom had engagement from those roles. So, do your best as an engineer, make something star-ish, and you‚Äôll be 90% of the way there.",
              "score": 2,
              "created_utc": "2026-02-07 20:16:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xd539",
          "author": "zx440",
          "text": "I'd say that \"traditional\" data modelling was becoming too rigorous, to heavy, and not agile. People were applying rules and methodologies blindly, without any real driver or value proposition. \n\nSo people went around it and went back to a tactical way of doing things. \n\nThere needs to be a middle ground. I think Data Contracts and Data Mesh are two of the very promising ways of implementing order in a chaotic data world within big (and small) enterprises. \n\nNot every data set needs SCD modelling. Not every team is ready to create a semantic layer, and you need to let people play around with the \"raw\" data before seeing a model emerge. A more decentralized data modelling approach is much more adapted for a modern world. ",
          "score": 2,
          "created_utc": "2026-02-06 16:33:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xy29b",
              "author": "cream_pie_king",
              "text": "Except that's not the reality of how everyone operates. They look at the raw data, hack together endless shadow pipelines and reports, management pushes for the next shiny thing and this tech debt becomes embedded in the org and the resulting data is shared broadly.",
              "score": 3,
              "created_utc": "2026-02-06 18:12:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3yb2ji",
                  "author": "zx440",
                  "text": "Yes, of course. I've been working to implement decentralized data approach for years. We has some success, but there's huge resistance from both sides.\n\n\"Traditionnal\" BI teams want to control everything and be in charge of all modeling, but are unable to deliver. Data consumers view any attempt at structuring their work as impeding their progress...\n\nBut eventually, they start to see the benefit of a more decentralized approach. BI team get a bit of air and can focus on platforming and infrastructure. Data consumers get the benefit of collaboration between teams that often run into the same issues.\n\nBut then management comes in, views decentralization as a menace to society, and just puts an end to this and force everyone to use the BI team... and we're back to square one...",
                  "score": 2,
                  "created_utc": "2026-02-06 19:14:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xqlmo",
          "author": "turboDividend",
          "text": "time is money. if the product works...what diff does it make?\n\nthats how mgmt look at things",
          "score": 1,
          "created_utc": "2026-02-06 17:36:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xrrda",
          "author": "OGMiniMalist",
          "text": "I‚Äôve had 3 interviews within as many months. All 3 wanted me to demonstrate my knowledge of data modeling in the interviews, IE what is a fact / dimension table? Have I ever made or used them in practice? What‚Äôs the difference between star and snowflake schema? Etc.",
          "score": 1,
          "created_utc": "2026-02-06 17:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44z2cp",
              "author": "raginjason",
              "text": "These are all very surface and any DE should be able to answer them honestly. That lack of depth suggests to me that if you worked for any of those places you would absolutely not be doing anything dimensional at all.",
              "score": 1,
              "created_utc": "2026-02-07 20:19:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xwaa9",
          "author": "aMare83",
          "text": "I don't think so. Even if your data platform is Databricks which is the ultimate choice these days, it does matter how you design the database schema and queries. It manifests in cloud compute costs, so I think it still matters.",
          "score": 1,
          "created_utc": "2026-02-06 18:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zbnbi",
          "author": "jaymopow",
          "text": "Data modeling is still very important, but the classical data modeling approaches don‚Äôt really support today‚Äôs use cases.",
          "score": 1,
          "created_utc": "2026-02-06 22:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zyf3o",
          "author": "onomichii",
          "text": "Modelling the business logically is critical.\nModelling this in physical terms that is performant, scalable and maintainable is critical.\nEngineering this well is critical.\n\n\nAll three are distinct skills. You might think you're skipping some because of the features of your target platform, but what you're really doing is just short sighted half assed modelling which you will pay for one way or another later¬†",
          "score": 1,
          "created_utc": "2026-02-07 00:23:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43o4jr",
          "author": "Relative_Wear2650",
          "text": "No",
          "score": 1,
          "created_utc": "2026-02-07 16:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43p7l2",
          "author": "Typhon_Vex",
          "text": "I have noticed the same thing. It really began with the empowering of the non-IT personall.\n\nThe self-called dahsboard developers havig no clue what a dimension is - no joke.\n\nNow the data transformations have been moved from IT-based ETL developers to the bussiness and the analysts there.\n\nMost managers or architects also don¬¥t anymore know what it is. No one is even pushing it. It has gotten so bad that I was told to stop asking job applicants to our data team about Dimensions. To keep it practicall only. Well guess what, they can¬¥t write the SQL neither, as it would require a basic Star Schema model understanding.\n\n  \nWell in the end, it will just be more work for us the data engineers. Quality - reusable models would actually mean less work. So why push it from my side.",
          "score": 1,
          "created_utc": "2026-02-07 16:28:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46v1vy",
          "author": "Impossible-End4881",
          "text": "No",
          "score": 1,
          "created_utc": "2026-02-08 02:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o475dd9",
          "author": "GreyHairedDWGuy",
          "text": "I think many of your observations are in correct but that doesn't make it the right way to go.  FAANG tend to have very aggressive deadlines and have the 'just get it done' mentality.  They see modelling as an impediment to delivery time.  \n\nI'm not with a FAANG company but the 'get it done quickly' mentality impacts the quality of our deliveries.  Someone ends up having to clean the mess at some point. ",
          "score": 1,
          "created_utc": "2026-02-08 04:07:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m9o61",
          "author": "dbjan",
          "text": "Yes, but my experience is that many junior people like to feel like experts these days and if you try to explain why to model staff properly, they feel insulted. Lack of arguments makes it just worse, on one project they took what I designed and made it a monster, I regretted I didn't leave them alone.. : D\n\nOverall you design to keep it fast long term. If not, you end up fire-fighting, the best people leaving the team and so on...",
          "score": 1,
          "created_utc": "2026-02-10 14:19:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wvnwv",
          "author": "Atticus_Taintwater",
          "text": "Yes and no\n\n\nThe ideology of a data model \"modeling the business\" and the more theoretical techniques are definitely falling out of favor for good reason.¬†\n\n\nEvery time I've seen that it's just ego stroking from a modeler and a lot of time contorting the way the systems actually behave to his Disneyland idea of \"the business\". It ends up just making everything either harder or weirder¬†\n\n\nData modeling is important up to the point where people can write sensible queries and get sensible results. Greatly diminishing returns after that.",
          "score": -1,
          "created_utc": "2026-02-06 15:09:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x4yjx",
              "author": "DungKhuc",
              "text": "What you said is true if data modeling is used for forgotten BI dashboards.\n\nIf data is at the core of the business, data modeling is critical as it's typically crucial part of the products. The value of data models in such cases only grows over time, never the other way around.",
              "score": 3,
              "created_utc": "2026-02-06 15:54:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xe34g",
                  "author": "Atticus_Taintwater",
                  "text": "I think what I said is true for most data products that aren't for operations\n\n\nWouldn't lump in scd with this. That's barely modeling.¬†I'm more talking about bloated er modeling.\n\n\nThere should be a generally sensible structure. My addresses should be collated with some kind of locations concept, etc\n\n\nBut every time I see a subrogations process modeled in 15 tables because that's how it theoretically works it becomes a counterproductive rats nest because the real world is far gnarlier.",
                  "score": 1,
                  "created_utc": "2026-02-06 16:37:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wwzhh",
              "author": "MissingSnail",
              "text": "And in practice, tech teams are understaffed and doing the best they can with the time they have.",
              "score": 1,
              "created_utc": "2026-02-06 15:16:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wx1s3",
          "author": "kjmerf",
          "text": "Yes",
          "score": 0,
          "created_utc": "2026-02-06 15:16:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0fky1",
      "title": "Visualizing full warehouse schemas is useless, so I built an ERD tool that only renders the tables you're working on",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/706ayxj8yiig1.gif",
      "author": "Spiritual_Ganache453",
      "created_utc": "2026-02-09 20:29:55",
      "score": 114,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0fky1/visualizing_full_warehouse_schemas_is_useless_so/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4lr57a",
          "author": "ThroughTheWire",
          "text": "Pretty cool! think it could be useful for presentations for sure. maybe decent as a documentation tool as well.. I definitely do not want to ever manually draw or create UML tables ever again lol",
          "score": 7,
          "created_utc": "2026-02-10 12:30:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4odebs",
          "author": "DungKhuc",
          "text": "This looks very neat!\n\nOne thing though, besides showing relationship when pointing to a foreign key, what else does this do?",
          "score": 3,
          "created_utc": "2026-02-10 20:16:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ozeep",
              "author": "Spiritual_Ganache453",
              "text": "Yeah, here's the list.\n\n**Primary:**\n\n* Real-time SQL Canvas synchronization\n* MySQL parser with full syntax support\n* Drag-to-connect foreign key creation\n* Inline column editing on canvas\n* Drag-and-drop column reordering (swap/insert modes)\n* Customizable auto-formatting (indentation, casing)\n* Toggleable Brainstorm mode\n* Instant bulk rendering\n* Project & snapshots creation\n* Version history timeline\n\n**Upcoming:**\n\n* Cardinality support\n* Auto-generated SQL queries on connection hover\n* Diagram-wide search with auto-framing\n* Visual diff mode for team collaboration\n\nMore info: [sqlestev.com](http://sqlestev.com)",
              "score": 2,
              "created_utc": "2026-02-10 21:58:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r15015",
      "title": "2026 State of Data Engineering Report - 1000+ responses from data engineers",
      "subreddit": "dataengineering",
      "url": "https://www.linkedin.com/posts/josephreis_recently-i-surveyed-1101-of-you-about-the-share-7426990778536583168-fqMr/?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAajovEBZaTvKT0qIqHq9ItYb5C1EMVsVSY",
      "author": "DungKhuc",
      "created_utc": "2026-02-10 16:12:59",
      "score": 114,
      "num_comments": 8,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r15015/2026_state_of_data_engineering_report_1000/",
      "domain": "linkedin.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4qlhfo",
          "author": "dreyybaba",
          "text": "This is a lovely insight. Thanks for putting this together",
          "score": 7,
          "created_utc": "2026-02-11 03:31:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r3ata",
              "author": "DungKhuc",
              "text": "All credits go to Joe Reis, so I'm not putting anything together except cross posting the links from his discord channel :)",
              "score": 10,
              "created_utc": "2026-02-11 05:38:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rvfui",
          "author": "rmoff",
          "text": "super useful. love the fully-functioning enterprise version too ü§£ https://joereis.github.io/super_corporate_pdm_survey/\n\n(Crystal reports, anyone?)",
          "score": 8,
          "created_utc": "2026-02-11 09:54:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4s7av0",
              "author": "flashpoints80",
              "text": "He really went the extra mile!",
              "score": 3,
              "created_utc": "2026-02-11 11:38:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4x3kq9",
              "author": "shoppedpixels",
              "text": "I like the duplicate or erroneous data like Data Analyst listed twice or misspellings persisting, gives a feel of authenticity.",
              "score": 1,
              "created_utc": "2026-02-12 03:10:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sxjor",
          "author": "ironmagnesiumzinc",
          "text": "AI helping only 29% of respondents with debugging was extremely surprising. I think this is maybe the best part about LLMs",
          "score": 2,
          "created_utc": "2026-02-11 14:24:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xmn4r",
              "author": "Oxford89",
              "text": "It is THE most common use I have for AI. I don't even bother reading logs anymore. I just feed them to AI and get an answer faster than I would be able to scroll to the error.",
              "score": 2,
              "created_utc": "2026-02-12 05:24:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4scz0g",
          "author": "observability_geek",
          "text": "I'm so surprised only to see that only 6.8% are using EDA and the big gap between enterprise usage and SMBs. \n\n# \n\n",
          "score": 1,
          "created_utc": "2026-02-11 12:21:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxzr61",
      "title": "My boss asked about the value I bring to the company.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxzr61/my_boss_asked_about_the_value_i_bring_to_the/",
      "author": "Consistent-Appeal922",
      "created_utc": "2026-02-07 01:02:39",
      "score": 94,
      "num_comments": 93,
      "upvote_ratio": 0.91,
      "text": "Basically send me that through a message, and what exactly I generated for the company in the last quarter.. that the future of the team I work in (3 people) depends on that answer. The problem? I am not sure.. joined a year ago and they made me jump from project to project as a business analyst, ended up configuring a data quality tool and configuring some data quality checks on pipelines, help people use the tool, log in, etc. Basically I work 2 hours a day .. sometimes I don‚Äôt have any task to do.\n\nAt the same time I got a job offer from a company, is less money ( I am very well paid right now). Should I switch job and start fresh or stay and defend my position?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxzr61/my_boss_asked_about_the_value_i_bring_to_the/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4069xi",
          "author": "Think-Trouble623",
          "text": "you‚Äôre next on the layoff list, jump ship if you have an offer",
          "score": 269,
          "created_utc": "2026-02-07 01:09:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o407rap",
              "author": "Consistent-Appeal922",
              "text": "Maybe, but they are not laying off people and the quality of their data is a disaster, pipelines failing everywhere, and definitely under staffed. \n\nWhat I don‚Äôt understand is why they even hired me.. I did everything I was asked to do, but they were just not dedicating time to myself. Had a lot of initiative multiple times to participate in projects/proposals to do stuff and most of the time they said (this is handled by other team, stay in your lane). For the last 4 months being in a more ‚Äúsupport‚Äù role for this data quality tool, people reaching out to me for access, for explanations on how to use the tool, for onboarding sessions, but not much else. I many times asked my supervisor for a roadmap for the upcoming year and he said he needed to discuss that with more people, now he come back with that question.. very strange",
              "score": 20,
              "created_utc": "2026-02-07 01:18:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o409lof",
                  "author": "Think-Trouble623",
                  "text": "sorry brother, this question only works if it‚Äôs day one for your new boss. I can rattle off every single achievement, struggle, and goal of my employees without having to ask them. This question is not good and you should leave.",
                  "score": 116,
                  "created_utc": "2026-02-07 01:29:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40iees",
                  "author": "kayakdawg",
                  "text": "> but they are not laying off people\n\n\nnobody is ever laying off people\n\n\nuntil they are",
                  "score": 44,
                  "created_utc": "2026-02-07 02:24:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40u40r",
                  "author": "RoomyRoots",
                  "text": "The sad reality is that most companies are filled with useless positions and there are loads of evidence on that. Don't hang around on why you were hired, focus always on what you can learn and apply. \n\nIt is your employer that needs to understand what you can contribute to the company, not the reverse. People are delegating the very basics of management because most managers are incompetent. ",
                  "score": 20,
                  "created_utc": "2026-02-07 03:38:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o423d1u",
                  "author": "paco1305",
                  "text": "> Maybe, but they are not laying off people \n\nMy dude, some times you need to read between the lines when you are in danger of being laid off\n\n> that the future of the team I work in (3 people) depends on that answer\n\nThis is not one of those times though, they've flat out told you",
                  "score": 13,
                  "created_utc": "2026-02-07 10:07:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o426qh1",
                  "author": "Environmental_Pop686",
                  "text": "Understaffed but you work 2 hours a day? You saying their data is a disaster and pipelines are failing but are working 2 hours a day.",
                  "score": 9,
                  "created_utc": "2026-02-07 10:40:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o42j9y3",
                  "author": "Expensive_Culture_46",
                  "text": "It‚Äôs not strange. You are marked and you should bail. \n\nAnd if you‚Äôre only working like 2 hours a day then you really aren‚Äôt bringing any value because leadership doesn‚Äôt know how to effectively utilize you. However, it being a leadership problem won‚Äôt save you here.",
                  "score": 7,
                  "created_utc": "2026-02-07 12:31:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o430pgo",
                  "author": "HolyGeneralK",
                  "text": "Preface here - this got waaaayyy longer than I thought. Don‚Äôt take the ‚Äúyou‚Äù defensively below. \n\nI would encourage a little thought experiment here. Initially, take yourself out of the picture. Look at your job description (what you were hired to do). Look for value statements in there (find insights, reduce costs, improve productivity, etc.). This helps quantify ‚Äúvalue.‚Äù Then look a little broader (Reddit is a good start) - where do data engineers add value. Look at other job descriptions. Once you have a good understanding of where data engineers add value to an organization, that‚Äôs your sales pitch to you boss. ‚ÄúI am here to enable our sales and marketing teams to increase revenue by improving the breadth, depth, and quality of data available for our business analysts to use.‚Äù Don‚Äôt bring that yet. \n\nNext - if someone is questioning the value you bring,  they either don‚Äôt have a good understanding of the first part of the exercise, which can happen. That can be solved with a bit of education and managing upward. It may also be your lead is asking on behalf of another person in the organization.\n\nThe other part is that they know what your value should be but does not observe the company getting it (expectations not being met). That could be interpreted as ‚Äúyou don‚Äôt know why you‚Äôre here and look lost,‚Äù ‚Äúyou‚Äôre lazy,‚Äù ‚Äúyou‚Äôre working hard but on the wrong things,‚Äù or ‚Äúyou used to engage hard with other people but now you don‚Äôt, what‚Äôs wrong?‚Äù Or, I have seen this occasionally- ‚ÄúCan we replace you with an LLM toolset?‚Äù\n\nKeep peeling back the onion here - do a ‚Äú5 Whys‚Äù down various paths. If you do this honestly I think you will find some observations about your role and the organization that are things you can learn from (or put into consideration for your next role). \n\nFor example: ‚ÄúI believe that the value a data engineer, and my role/job description, brings to an organization is X, Y, and Z. I cannot achieve the value that I believe my role as a data engineer should bring because the organization does not have a policy or incentive to put more diverse and higher quality data sets to the Business Intelligence Suite. I don‚Äôt have the political acumen or appropriate authorities to drive a change at this level. I could use my 4-6 hours of downtime per day integrating with specific teams for a few weeks at a time. I would need support from leadership to do this because historically, teams are highly siloed and resist me working with them. Here is a plan, a timeline, and here is a specific outcome I hope to achieve.‚Äù \n\nThat is a level of maturity that I, as a leader, would respect. Be careful of assigning any blame - you need to talk about impediments to your ability to deliver value. \n\nAs a manager, if one of my employees only ‚Äúworked two hours a day‚Äù and was getting salary, that‚Äôs a red flag worth looking into. I like my developers and engineers to have a backlog of work - we currently have several months work per person - and I like to see them showing 6 hours of real good ‚Äúproductivity‚Äù each day. I assume that the other two hours are emails, conversations, helping others out - still value add, but it‚Äôs the grease in the cogs of the machine.\n\nI would be looking at that 4 hour gap. You said their data and pipelines are garbage despite having a tool. Is the tool hard to use? Do they know how to use it effectively? Are they required to use it? Are they required but don‚Äôt see a value/return on investment so they half-ass it?\n\nIf they all use the tool, and the data is great, does that translate into more work for you? Less? Think of an ideal end state. Everyone uses it. The data is fantastic. Sales go up 200%. There is a parade in your honor. What does the job look like then? \n\nAlternatively, you may have already checked out mentally from this job and are just cruising to collect a pay check. Personally I would do the introspection and 5 Whys exercise and see if there‚Äôs a path to being engaged again at this job because you want to avoid the same conditions in the future. Some places hired a bunch of ‚ÄúNEW ROLES‚Äù for fear of missing out on industry trends with no idea what to actually do with them long term. Or they do know and you‚Äôre not delivering (for any number of reasons).\n\nAlso, be aware that, in my observations, the job market is starting to tighten. If you do plan to move companies, can you use your 4-6 hours of downtime per day training on new tools?",
                  "score": 3,
                  "created_utc": "2026-02-07 14:22:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41sxrk",
                  "author": "I_Blame_DevOps",
                  "text": "Sounds a lot like my situation. Was hired 8 months ago to fix their ETL issues. Spent the first 5-6 working on building out CDC infrastructure for a high volume database. Had it mostly working but they were becoming increasingly impatient and decided to just keep using physical database replication. Outside of that my boss seems to believe that I should fix all their DB performance issues. My dude, you‚Äôre running analytical queries against an OLTP Postgres database and are surprised this is slow? He‚Äôs made it increasingly clear that he doesn‚Äôt see the value in a data engineer so at this point I‚Äôm just doing support functions until I can find somewhere that actually values a data engineer.",
                  "score": 6,
                  "created_utc": "2026-02-07 08:24:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41zqk8",
                  "author": "davf135",
                  "text": "I think, part of the problem is \"doing everything [you were] asked to do\". In some level, they should be asking YOU what to do, or else you are totally replaceable.",
                  "score": 4,
                  "created_utc": "2026-02-07 09:31:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41yc9t",
                  "author": "Ojy",
                  "text": "Don't think just about what you have done but what you can bring to the company. You have already identified the problems you can see in the company. Don't give him a list of things that you have done, highlight these problems and give him the solution, and what you think YOU need to do to fix them, give him a timeframe and cost etc. \n\nDon't think of this as an end of the world event, but as an opportunity to shine. It'll put you head and shoulders above the other workers, if they just provide a list of, I did this, I did this, I did that... Blah blah blah.",
                  "score": 2,
                  "created_utc": "2026-02-07 09:16:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41sm8u",
                  "author": "TurboMuffin12",
                  "text": "Either you don‚Äôt get it and ur at a big company where your boss can‚Äôt figure out what to do with you or your boss is an idiot",
                  "score": 1,
                  "created_utc": "2026-02-07 08:21:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4f94xh",
                  "author": "slayerzerg",
                  "text": "You deserve better. I‚Äôve experienced that ‚Äúyou don‚Äôt own this, stay in your lane‚Äù just a bunch of groups who want the more interesting or value-providing projects. And they may not be capable of actually executing a plan for it, bogs down the company, and your growth as well. Go somewhere where some role where they need you and they want you to build things for them without all those constraints",
                  "score": 1,
                  "created_utc": "2026-02-09 12:37:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o412y36",
              "author": "redditreader2020",
              "text": "Final answer.",
              "score": 2,
              "created_utc": "2026-02-07 04:40:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4082d9",
          "author": "bugtank",
          "text": "Why have you only been working 2 hours a day? Have you asked for more work? What about any of these so called improvements that the data needs? Have you pushed or taken initiative on those actions? \n\nYou always need to have the answer to this question at the tip of your tongue. If not now, then make sure you have to ready for your next job.",
          "score": 57,
          "created_utc": "2026-02-07 01:20:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o408qpx",
              "author": "Consistent-Appeal922",
              "text": "A lot of initiative. But the problem is they never put our project under any leadership since they hired us.. weeks without meetings or calls, asking for how I can help people. Then they put a supervisor that manages multiple projects to assign us work, but not enough, I asked many times what else we can do, what‚Äôs the roadmap for our team and this supervisor said (I am waiting on the manager to define that).. now that manager came to me with that question, I am like dude I been asking for the last 4 months what‚Äôs the roadmap for this team",
              "score": 18,
              "created_utc": "2026-02-07 01:24:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40bpa3",
                  "author": "Altruistic_Stage3893",
                  "text": "Sounds like you're screwed. Jump ship and focus on owning your projects and taking leadership. If you'll keep hiding behind \"the other guy did not move it\" you'll never get to management. might not be your goal. that's fine ofc just own the decision",
                  "score": 44,
                  "created_utc": "2026-02-07 01:42:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40j557",
                  "author": "kayakdawg",
                  "text": "sound like your manager is incompetent - given this and the fact they had to ask you what value you deliver¬†\n\n\ngood lesson for future, in that situation you can either take initiative and ownership, find your own roadmap or leave - otherwise the decision will eventually be made for you¬†",
                  "score": 5,
                  "created_utc": "2026-02-07 02:28:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40cjxl",
          "author": "Treemosher",
          "text": "You said multiple times in this post and replies to other comments that you ask them what the road map is.  Are you sure they're not expecting you to draft that up?\n\nAsking for a roadmap multiple times gives me the impression that they could see you as that guy who constantly needs direction.\n\nMaybe they were hoping you'd come up with your own roadmap.\n\n>Maybe, but they are not laying off people and the quality of their data is a disaster, pipelines failing everywhere, and definitely under staffed.\n\nIf you recognize this, have you come up with a road map to address these things you're seeing?  Is it possible they were expecting you to address them and communicate your plan?\n\nThe way you explain how you ask about a road map just feels like \"hey, got any work for me?  what do you want me to do today?\".\n\nI only have your words to go by here, so my impression is likely misinformed.  Just throwing it out there that if you really are asking about a roadmap and inserting yourself into other teams' projects and getting shut down, that seems to me that they're expecting you to manage and direct yourself more than you are.\n\nAnd now they're asking you what value you bring.  Without actually being there to see for myself, this is the best take I can come up with.\n\nIf I were you, I'd take the other job offer and consider the lessons to be learned here with the luxury of a fresh start.  I've been in a similar spot and it is very frustrating to navigate.  \"Do they want me to be my own manager?  Or do they want to manage me?\"  If you don't get that right, it can be really dicey I think.",
          "score": 22,
          "created_utc": "2026-02-07 01:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40f9oy",
              "author": "Consistent-Appeal922",
              "text": "You are right in many things. But I presented a roadmap , I said I will onboard teams to the data quality tool , make sure data products upstream assets have the right data quality checks, that there is an incident management response process , follow with tech that the necessary integrations are happening, etc\n\nI started with a team that owned a pipeline working on defining and enabling data quality metrics, sending alerts to them, etc.. was going well, until my manager said that‚Äôs not my role. Teams need to define their own metrics, not me, since they understand the data. And data engineers will decide the incident management process not me.. that I should help them enabling the data quality controls in the tool. So basically he reduced my scope when I offered myself as leading the data quality initiative. Few months after that? Very few people enabled alerts, critical pipelines that were used for very important business purposes failed and no one realized. My manager got pressure from his superiors, he came back yelling it us like it why we don‚Äôt have a dashboard showing all the critical alerts failing and I was like, the alerts are not even in place. Teams are not using the tool even that you asked them to use it and reach out to us for help.. we need ownership and someone telling them constantly to do it, I tried.",
              "score": 7,
              "created_utc": "2026-02-07 02:04:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40hzos",
                  "author": "Treemosher",
                  "text": "Yeah it's way too much in the for me to wrap my brain around at the moment, honestly.  \n\nYour manager and you seem to have a huge disconnect.  Sounds like you and them need to sit down and go over expectations and figure out where the drop-off was.  \n\nEven if you decide to leave, I would try to have this conversation just so you start your next job with a big lesson learned, regardless of who is at fault.  Maybe before turning in your resignation.\n\nI am not saying you should leave, that's your decision.  But if you do, I would try to learn how to avoid this situation again.  Bad experiences are ok as long as we find a way to grow and improve afterword.  \n\nThis is really hard because I don't know you and I sure as hell don't know your boss.  So toss everything I'm saying out the window if you think it'll make things worse.  \n\nThe point is to learn & grow above all else (aside from paying the bills obviously).",
                  "score": 7,
                  "created_utc": "2026-02-07 02:21:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o40ez41",
              "author": "ScottFujitaDiarrhea",
              "text": "At the same time how is something like this a surprise? Does their company not have reviews or 1:1s?",
              "score": 2,
              "created_utc": "2026-02-07 02:03:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40g18w",
                  "author": "Treemosher",
                  "text": "Without being there, who the hell knows.  It's possible the manager can also suck.\n\nThe employer's responsible for communicating expectations of the employee they're paying.  It's the employee's responsibility to understand what they're being paid to do.\n\nThis scenario, if OPs explanation is accurate, reeks of both parties failing in these responsibilities.\n\nCommunication is everything.  This kind of stuff is what lack of communication looks like to me.\n\nWe only have one side of the story though, so it's impossible to take this beyond an armchair analysis lol",
                  "score": 3,
                  "created_utc": "2026-02-07 02:09:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40zhj1",
                  "author": "minato3421",
                  "text": "There are some managers who don't conduct 1:1s. They take advantage of freshers in situations like OPs and screw them over",
                  "score": 4,
                  "created_utc": "2026-02-07 04:15:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o42tn8x",
              "author": "TA_poly_sci",
              "text": "Yeah, I have never been in or observed a data-focused position where it was not a central expectation and requirement for people to be self-driven. Chances are leadership are not data people themselves. And even if they are, they do not have the time to be.\n\nAnd as a general rule, people should not be surprised to be asked what value they bring to a company when they are getting paid (presumably) a quite nice salary.",
              "score": 2,
              "created_utc": "2026-02-07 13:41:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o40gphg",
          "author": "healthcare-analyst-1",
          "text": "Your boss needs to have something to kick up to their boss to justify the team's existence. Write up a short bullet point memo detailing actions you've done & the resulting accomplishments from them. Feel free to put *everything* on there regardless of what the actual lift ended up being, just try to avoid the appearance that you're filibustering.\n\n* Configured and implemented X Data Quality Tool\n* Implemented automated data quality checks on Y pipeline, ensuring a Y% data accuracy rate after deployment\n* Implemented data quality checks on Z pipeline, which successfully identified problem A in data quality for resolution\n* Onboarded stakeholders from business groups C, D, and E onto Data Quality Product\n* Provided training & ongoing support for users from business groups C, D, and E to allow for self-service\n\nIn the meantime, it sounds like your management is aloof & afraid of stepping on other teams' toes. To keep yourself busy maybe send a few follow ups to some of the teams that you've onboarded onto the tool to make sure everything is working properly & see if they have any issues you could resolve that fall within or overlap with your purview. Ideally initially small tasks that you can resolve with your free time & then mention to your boss afterwards, this might lead to you being able to develop a pipeline of additional work if necessary.",
          "score": 6,
          "created_utc": "2026-02-07 02:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41afec",
          "author": "Homonkoli",
          "text": "Sorry, but if you don‚Äôt have an answer then you‚Äôre really not valuable for the company from management perspective. However, don‚Äôt let that define you, poor resource management is not your responsibility, but at the same time its your responsibility to actively ask/seek proper valuable work that is impactful for your department or workplace in general.",
          "score": 7,
          "created_utc": "2026-02-07 05:37:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4knbzg",
              "author": "Sensitive-Sugar-3894",
              "text": "Most people don't know how to sell themselves. We see deliveries as \"easy stuff, no need to mention\".",
              "score": 1,
              "created_utc": "2026-02-10 06:33:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o41ge6h",
          "author": "Chowder1054",
          "text": "I would switch. I don‚Äôt get the talk here blaming you for not taking the initiative. Ambiguity has limits, you need some sort of goal/overarching project and then you can find things to do. When you have zero idea where and you need to practically scavenge for work and ideas, then it‚Äôs a leadership problem.\n\nYour manager should be the one passing down projects and ideas down to their team. And from what you said, it just sounds like a disconnected mess. I would strongly suggest you jump ship elsewhere.\n\nDealt with places like this before, and the lack of work and leadership caused teams to fall apart fast.",
          "score": 6,
          "created_utc": "2026-02-07 06:27:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40c0c0",
          "author": "Old_Tourist_3774",
          "text": "95% you are in the chopping block already and they are just checking to make sure nothing important slipped by so they can fire you without it backfiring.\n\nAnd from you comments it seems not even your fault, I had the same experience with companies that did even know what they want and need and 1 man team seldom can do something if he doesn't even have contact with the users pains and needs",
          "score": 9,
          "created_utc": "2026-02-07 01:44:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40ggi7",
              "author": "amejin",
              "text": "Little oversight and lots of problems and you think it's not on them to fix things? I fully disagree. \n\nThis is the mindset difference between a junior engineer and a senior+\n\nTake ownership. If things are a mess and you can objectively prove a better solution, that better solution should be paraded around until someone listens to it or explicitly kills it ( hopefully with a reasonably explanation as to why).",
              "score": 3,
              "created_utc": "2026-02-07 02:12:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o42c2hd",
                  "author": "Old_Tourist_3774",
                  "text": "I think you did not get it.\n\nFix what? Give a solution to what? Legit people will tell things don't work but can't even point to why, or what the tool is doing or how they interact with each other. Everything is blurry and you become isolated.\nAnd these companies tend to be massive, with decades of patchwork, incredible amounts of segregation of systems, acceses and things that does not work together.\n\nAnd honestly, i could not care less for \"having ownership\".",
                  "score": -1,
                  "created_utc": "2026-02-07 11:30:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40g5nz",
          "author": "T3quilaSuns3t",
          "text": "I just had this happen to me today. Got a talking to.\n\nLol I didn't really care üòÇ",
          "score": 4,
          "created_utc": "2026-02-07 02:10:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4knht0",
              "author": "Sensitive-Sugar-3894",
              "text": "Not caring is the best position to be at. But it's a luxury for the majority.",
              "score": 2,
              "created_utc": "2026-02-10 06:34:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o40wogo",
          "author": "bugthelady02",
          "text": "Do not jump ship. Wait until they fire you, hopefully, with severance.\n\n1- Highlight your contribution to different projects.\n\n2- Reiterate that you would have loved the chance to work on X project but we're denied.\n\n3 - Tell them what value add you can bring to future initiatives.\n\n4 - keep applying and interviewing\n\nIt sounds like they were not organized with projects lined up for you to jump in. Either that or you have not been proactive enough to create work for yourself.",
          "score": 10,
          "created_utc": "2026-02-07 03:56:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40lbh2",
          "author": "refrigerador82",
          "text": "You should ask for more work. Dedicating 2 hours per day is lowkey a dick move.\n\nThey probably noticed it and want to fire you.",
          "score": 6,
          "created_utc": "2026-02-07 02:42:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40cqbf",
          "author": "Patient_Professor_90",
          "text": "Switch immediately",
          "score": 3,
          "created_utc": "2026-02-07 01:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40jz4p",
          "author": "SRMPDX",
          "text": "What did your job description say when you interviewed? Are you doing any of that?  You've mentioned in this thread that you don't know why they hired you if they don't have the work, seems like your boss is catching up to that. He's likely pretty sure you don't do anything useful but wants to check so he can get others trained to pick it up before you're let go.",
          "score": 3,
          "created_utc": "2026-02-07 02:34:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40xuq7",
          "author": "Cruxwright",
          "text": "Reading your replies....\n\n\"I'm here so middle management can tell someone, no.\"\n\nI started doing my job as described when hired and was told, \"no, stop.\"\n\nI started initiatives to clean data and manage pipelines so things like incident X wouldn't happen. I was told, \"no, stop,\"\n\nI offered to help other teams and was told, \"no, stop.\"\n\nI asked what the roadmap for the department is and where I can help and was told, \"no, stop.\"",
          "score": 3,
          "created_utc": "2026-02-07 04:04:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o410dpi",
              "author": "Consistent-Appeal922",
              "text": "Yes. Sometimes straight ‚ÄúThat‚Äôs not our scope/your scope‚Äù and sometimes simply not getting any engagement",
              "score": 1,
              "created_utc": "2026-02-07 04:21:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f2xqg",
          "author": "llamacoded",
          "text": "That's a direct question from your boss, but also an opportunity to be specific. \"Configuring a data quality tool\" is fine, but what did it \\*do\\*? Did your checks prevent X bad records from hitting production pipelines? Did they stop Y broken feature values from affecting a critical report or even a model downstream? Did you free up Z hours for someone who used to manually clean that data every week? You need to tie it to measurable outcomes like prevented errors or saved time.  \n  \nHonestly, working 2 hours a day isn't sustainable for your career. You're not learning or building much. If the new job offers real problems to solve and actual projects, even for less money, I'd consider it. Sticking around just for the higher paycheck when you're stagnating will make you less competitive for future roles.  \n",
          "score": 2,
          "created_utc": "2026-02-09 11:49:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40chjf",
          "author": "tophmcmasterson",
          "text": "Sounds like your boss is asking the right questions honestly. \n\nI can‚Äôt imagine working someplace as a data engineer and only having two hours of work a day and expecting to remain hired. \n\nWith any job if you want to do well it‚Äôs about finding ways to make yourself valuable/indispensable. If you‚Äôre sitting around waiting to move on projects, or blaming leadership for not managing things etc. when you‚Äôre working two hours a day I don‚Äôt know what to tell you. \n\nI‚Äôd start prepping for a new job as it honestly just doesn‚Äôt sound like you‚Äôre bringing much value where you are now.",
          "score": 4,
          "created_utc": "2026-02-07 01:47:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40ct3t",
              "author": "Consistent-Appeal922",
              "text": "Definitely not adding much value currently, and I am not a data engineer anyway, I am a business analyst. My problem is they didn‚Äôt hire me and said, make yourself valuable , they really sold me the job during interviews and since I joined I didn‚Äôt have any leadership, directions, etc.\n\nI can‚Äôt just guess what I need to do",
              "score": 3,
              "created_utc": "2026-02-07 01:49:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40dm4l",
                  "author": "ATL_we_ready",
                  "text": "Honestly, nobody wants a hire that has to be told everything to do.  Learn to thrive in ambiguity and reach out to people and figure out how to make things better with skills you have.  You have to want it‚Ä¶",
                  "score": -3,
                  "created_utc": "2026-02-07 01:54:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o408you",
          "author": "Specific-Mechanic273",
          "text": "Have you tried being proactive? Not asking for tasks but just pushing improvements for the data product?\n\nsome companies just expect that from you. Not everyone will feed you with tasks if they expect you to be the subject matter expert. ",
          "score": 1,
          "created_utc": "2026-02-07 01:25:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40fm79",
          "author": "Wadix9000f",
          "text": "Does this boss exactly know what you do? \n\nIs he the one who made you jump through all those roles? \n\nWhat is your visibility to him? \n\nIs this an  engineering/tech manager or a People manager? \n\nStill asking such a question I would not be surprised if he's the one who is on the chopping block",
          "score": 1,
          "created_utc": "2026-02-07 02:06:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40g2us",
              "author": "Consistent-Appeal922",
              "text": "He is a tech manager, he hired me and bunch of people. He basically is very busy with AI stuff, and he never gave me much attention until now.. First was under a team , the team got disolved, supervisor left. Then assigned me another supervisor who wasn‚Äôt joining any call. Then another supervisor who was supposed to be aligned with my manager , they sit next to each other , I thought he was aware of our existence now. But it looks like he is not",
              "score": 2,
              "created_utc": "2026-02-07 02:09:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40wtav",
                  "author": "Wadix9000f",
                  "text": "yeah... i'll have to agree with what most people are saying here, as cliche as it sounds but most people quit their jobs because of bad managers. Perhaps you should look into some sort of applying for other teams or roles within the company if you like it there and he or she would not be your boss.",
                  "score": 2,
                  "created_utc": "2026-02-07 03:56:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40z6sr",
          "author": "mindwrapper13",
          "text": "YOE? I would say find a new job to challenge yourself regardless of what your boss says.",
          "score": 1,
          "created_utc": "2026-02-07 04:13:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41n7ym",
          "author": "Longjumping_Lab4627",
          "text": "I would ask for a call with the manager and tell him what you are saying that you did x and y for data quality. Tell him you want to work on a more interesting project and be strict. Tell him how you feel and the worst case if it didn‚Äôt change under 3-7 days leave and go to the next job.\n\nIf you have an offer from another company what are you afraid of? It‚Äôs time to be honest with yourself and the manager",
          "score": 1,
          "created_utc": "2026-02-07 07:30:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41tqjx",
          "author": "PrestigiousAnt3766",
          "text": "Try to be more proactive next time.\n\nWork is more enjoyable, you learn more and are not fired as easily.",
          "score": 1,
          "created_utc": "2026-02-07 08:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41y278",
          "author": "fistular",
          "text": "I work in an R+D role and I am \\*constantly\\* creating proposals for work with solid business cases behind them.  Some sputter and die, some I work on for months.  You need to be more proactive about identifying where you can be useful and pitching that use to stakeholders.",
          "score": 1,
          "created_utc": "2026-02-07 09:14:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o425nwq",
          "author": "TheTackleZone",
          "text": "Never answer that question with what you did generate. Answer it with what you could generate. Talk about all the opportunities missed due to the bad management of the team and what you would do if you were in charge.",
          "score": 1,
          "created_utc": "2026-02-07 10:29:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42ku7b",
          "author": "Typhon_Vex",
          "text": "ah the data quality death trap.\n\nno one cares, not the bussines, not the developers, it¬¥s fake employment. stay away",
          "score": 1,
          "created_utc": "2026-02-07 12:43:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42zcv3",
          "author": "Barbacula",
          "text": "Ask your boss what he/she brings to the company, if they don't know what their own reports are doing or why they have them. \n\n(probably don't do this unless you *really* want to be on the layoff list)",
          "score": 1,
          "created_utc": "2026-02-07 14:15:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43cqpl",
          "author": "McNoxey",
          "text": "Honestly I feel rude saying this, but if you don‚Äôt know how to answer, you‚Äôre probably not adding value.",
          "score": 1,
          "created_utc": "2026-02-07 15:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44d5yo",
          "author": "MrSquigglesWiggle",
          "text": "You mentioned that you only work 2 hrs but the company's data quality is bad. You could've used your free hours to improve those. Even planning out and creating a proposal that they would reject is better than being seen doing nothing. There are really times where you have to create your own pet projects on the side. Your team's main goal should be improving the quality of the data even without being asked.",
          "score": 1,
          "created_utc": "2026-02-07 18:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o451ei8",
          "author": "Buffalo_Burner",
          "text": "Take every little thing you worked on and send it in a list to chatgpt. Tell chatgpt to bake you up a nice bullshit answer.",
          "score": 1,
          "created_utc": "2026-02-07 20:31:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47gsn6",
              "author": "Corn-Fed-Mule",
              "text": "I think OP‚Äôs boss is indirectly telling him that you don‚Äôt provide value and would rather push you to quit instead of paying for unemployment. You would likely be let go in the new round of layoffs. I‚Äôd polish that resume and start looking for a higher paying job.. if it‚Äôs a good fit and +/-5% of your current salary, take it, else let them fire you. You don‚Äôt want to be around after round 2 anyway..",
              "score": 1,
              "created_utc": "2026-02-08 05:32:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48bfmy",
          "author": "NoleMercy05",
          "text": "Why are you working 2 hrs a day.  Really?",
          "score": 1,
          "created_utc": "2026-02-08 10:13:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48n3v0",
              "author": "Consistent-Appeal922",
              "text": "Not enough tasks assigned?",
              "score": 1,
              "created_utc": "2026-02-08 12:00:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ciahw",
          "author": "jonahnr",
          "text": "It honestly sounds like the problem is you do tasks you are assigned instead of taking initiative to find the biggest pain points for the business to solve. It sucks since your manager should be helping find those pain points, but if you want to grow, then doing what youre doing is of course going to get you laid off..you're not really providing any real value.",
          "score": 1,
          "created_utc": "2026-02-09 00:27:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dgau1",
              "author": "Consistent-Appeal922",
              "text": "Honestly? If they hired me they need to give me a job to do. If they want me to discover how to make the company work better, they need to hire me as a consultant and I will charge them 10 times what I make.. if they don‚Äôt like it I can go somewhere else",
              "score": 1,
              "created_utc": "2026-02-09 03:31:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4htrq5",
          "author": "ntdoyfanboy",
          "text": "You work two hours a day? Yeah, you're on the chopping block. Get the new gig and start to shine",
          "score": 1,
          "created_utc": "2026-02-09 20:31:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lzfn2",
          "author": "GAZ082",
          "text": "You are already cooked. You needed to show initiative asking for stuff to do (if junior) or pinpointing issues/blockers and managing with your boss a plan to fix to have visibility.",
          "score": 1,
          "created_utc": "2026-02-10 13:23:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lzqny",
              "author": "Consistent-Appeal922",
              "text": "Interestingly after I said I have another job offer they started giving me a lot of work and asked me to stay ü§î",
              "score": 1,
              "created_utc": "2026-02-10 13:25:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4m8fzx",
                  "author": "GAZ082",
                  "text": "There you go! Be vocal, don't be afraid. And if you are low on work, show initiative. Best of luck!",
                  "score": 2,
                  "created_utc": "2026-02-10 14:13:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u57ho",
          "author": "FireFighter1015",
          "text": "Your boss is next on the layoff list and you‚Äôre about to get a promotion or you‚Äôre part of that layoff.\nLayoffs aren‚Äôt announced.  Especially if your superiors are fired too.",
          "score": 1,
          "created_utc": "2026-02-11 17:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40d51q",
          "author": "ATL_we_ready",
          "text": "You work 2 hours a day and it probably shows!  Hence the question perhaps?",
          "score": 1,
          "created_utc": "2026-02-07 01:51:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40h518",
          "author": "chrisgarzon19",
          "text": "If ur not sure\nYou‚Äôre the problem \nStart looking for a job\nHere‚Äôs the thing though\nFIND OUT\nCause the way you nail the interview is by explaining that exact question to interviewers\n\nNot trying to be mean. Trying to help.\n\nBut it‚Äôs something I‚Äôm so passionate about cause I think 80% of engineers deal w exactly this isssue\n\nThey don‚Äôt know their business impact",
          "score": 0,
          "created_utc": "2026-02-07 02:16:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40rpyf",
          "author": "Tougher-Guy",
          "text": "First understand things like you are learning something or the other everyday , if not just leave and make your soul happy \nDon't just get money minded for your self happiness",
          "score": 0,
          "created_utc": "2026-02-07 03:22:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qym03a",
      "title": "Coinbase Data Tech Stack",
      "subreddit": "dataengineering",
      "url": "https://www.junaideffendi.com/p/coinbase-data-tech-stack",
      "author": "mjfnd",
      "created_utc": "2026-02-07 18:52:11",
      "score": 90,
      "num_comments": 17,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qym03a/coinbase_data_tech_stack/",
      "domain": "junaideffendi.com",
      "is_self": false,
      "comments": [
        {
          "id": "o45yw4e",
          "author": "Relative-Cucumber770",
          "text": "Might be a rookie question, but: What's the point of using Snowflake for warehousing if they're already using Databricks (Unity Catalog)? ",
          "score": 31,
          "created_utc": "2026-02-07 23:40:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45zmr3",
              "author": "mjfnd",
              "text": "Multiple teams owning different stacks or in the middle of migration which could take years.\n\n\nI can resonate with their stack as we also used DBX for processing core pipelines and BI related workflows on Snowflake linked to Tableau.",
              "score": 14,
              "created_utc": "2026-02-07 23:44:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o48ybve",
              "author": "a_lic96",
              "text": "Diversificaci√≥n, Risk hedging, avoiding full vendor lock-in, as well as to have more contractual power during negotiations",
              "score": 2,
              "created_utc": "2026-02-08 13:24:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47xgiy",
          "author": "PeitersSloppyBallz",
          "text": "Technology bingo much?",
          "score": 5,
          "created_utc": "2026-02-08 08:01:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45oflq",
          "author": "joeblk73",
          "text": "If you are on AWS why use Looker a GCP product ?",
          "score": 4,
          "created_utc": "2026-02-07 22:36:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45r700",
              "author": "halfrightface",
              "text": "looker core vs studio. studio is what google data studio used to be and probably what you're thinking of. they're using core as a semantic layer on top of snowflake to leverage lookml to build their views/explores.",
              "score": 11,
              "created_utc": "2026-02-07 22:52:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46d75u",
              "author": "Vautlo",
              "text": "Depending on the needs of the organization, Looker can beat Quicksight in a lot of ways. I think the value is in the modelling/semantic layer, governance, and being git native/BI as code. \n\nI've been through a migration from Tableau to Looker, as well as standing up and maintaining a self hosted Looker instance, both at AWS shops. Quicksight wasn't really considered as an option for either project - one was in the public sector and they put a lot of value on the governance baked into Looker, and the other was scared off of anything primarily UI driven and really valued the idea of BI as code.\n\nThe public sector project was pre-acquisition. I don't recall the costs from back then, but I'd bet that it was less of a factor than today.\n\nQuicksight is way less expensive, though I still doubt I'd choose it if I was the first data hire at a standup today. There are just too many no contract/free options to create decent reports that would satisfy a startup for quite a while.",
              "score": 3,
              "created_utc": "2026-02-08 01:06:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46ftwb",
                  "author": "joeblk73",
                  "text": "What does modelling and semantic layer mean here ?",
                  "score": 1,
                  "created_utc": "2026-02-08 01:22:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o45u6te",
              "author": "mjfnd",
              "text": "I think this is very common, the main reason is Looker is great and popular and it used to be a standalone product, not sure if that's true now, can we just buy looker instead of onboarding to GCP?\n\nWe also had Looker with AWS Stack.",
              "score": 2,
              "created_utc": "2026-02-07 23:09:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o45ou0v",
              "author": "data4u",
              "text": "I was wondering the same",
              "score": 1,
              "created_utc": "2026-02-07 22:38:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4576qi",
          "author": "theath5",
          "text": "Do you know if they use dbt for transformations?",
          "score": 3,
          "created_utc": "2026-02-07 21:03:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o458ejf",
              "author": "mjfnd",
              "text": "I couldn't find any mention of DBT publicly, let me know if you have any insights.",
              "score": 3,
              "created_utc": "2026-02-07 21:09:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o467bki",
                  "author": "ActEfficient5022",
                  "text": "I would have to assume databricks provides transformations I don't see what dbt would add to that given the diagram",
                  "score": 6,
                  "created_utc": "2026-02-08 00:30:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48006f",
          "author": "No_Airline_8073",
          "text": "Databricks and Snowflake and Starrocks and Looker and Airflow as well. Lot of redundancy.\nWhy not just use Databricks scheduler and warehouse and get rid of snowflake and airflow. I can understand why looker over Databricks-redash and maybe starrocks for few things",
          "score": 2,
          "created_utc": "2026-02-08 08:24:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4phuig",
              "author": "alittletooraph3000",
              "text": "Maybe someone who works for CB can chime in here but if they're using multiple compute platforms, seems pretty unlikely that they'd migrate off an orchestrator that's neutral to everything. ",
              "score": 1,
              "created_utc": "2026-02-10 23:35:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxl981",
      "title": "Are you a Data Engineer or Analytics Engineer?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxl981/are_you_a_data_engineer_or_analytics_engineer/",
      "author": "Free-Bear-454",
      "created_utc": "2026-02-06 15:50:53",
      "score": 79,
      "num_comments": 105,
      "upvote_ratio": 0.86,
      "text": "Hi everyone,\n\nMost of us entered the Data World knowing this roles BI Analyst, Data Analyst, Data Scientist and the one only geeks were enough crazy to pick Data Engineer.\n\nLately, Data Engineer is not only Data Engineer anymore. There is this new profile that is Analytics Engineer. \n\nNot everyone seems to have the same definition of it, so my question is:\n\nAre you Data Engineer or Analytics Engineer?\n\nWhatever your answer, why are defining yourself like this?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxl981/are_you_a_data_engineer_or_analytics_engineer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3x74o9",
          "author": "CommonUserAccount",
          "text": "I appreciate the title of this sub is data engineering, but after 20+ years in the industry the obsession with job titles amazes me, and historically there have been way more roles than those you've listed.\n\nWhatever a role is called at company X, I can guarantee it would look completely different in company Y especially when the company size and tooling can vary so dramatically.\n\nBetween the two roles you present, in the current company I work for I would suggest I'm now an analytics engineer as we have a centralised team that does the heavy lifting but without domain knowledge, leaving downstream curation to people like myself. Is my title either of these things? No!",
          "score": 122,
          "created_utc": "2026-02-06 16:04:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xv97o",
              "author": "sahelu",
              "text": "Its all Marketing people in the middle. Creating new titles to sell a better image. ",
              "score": 20,
              "created_utc": "2026-02-06 17:58:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ydnfn",
                  "author": "muneriver",
                  "text": "I think there‚Äôs definitely a marketing side. But I also think it represents a type of data person that does code-first data transformations, knows the software development lifecycle, and in general, has more technical skills than an alteryx/informatica developer who creates pipelines in a GUI. \n\nIf someone is an AE, I generally know what plane of work and skill they operate in. I‚Äôd argue it‚Äôs the most defined out of DA, DS, and DE. \n\nI also think AEs are a subset of DE",
                  "score": 6,
                  "created_utc": "2026-02-06 19:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3y9ibl",
              "author": "Odd-Government8896",
              "text": "Yep. Its just a title someone tossed in workday with a pay grade associated with it.\n\nI stopped looking at titles years ago.",
              "score": 4,
              "created_utc": "2026-02-06 19:06:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47iox4",
              "author": "Python_Darchives",
              "text": "Agreed on the x vs y titlings. Was deemed a Principal Data Science Engineer in telecom when in reality it was a BI and Data Engineer merger, but on the translational level, not ingestion. In my opinion from an earlier position and patterns I‚Äôve seen recently, DE is related to the Data Architecture and ingestion to a level of making the bulk data work. The AE is tasked with an overlap of the translation of ingested data but in a BI level foresight of what the data will be used for in its final destination. They are often a main resource of denormalizing the data into special groups for the analytics and dashboards. One of the best and most haunting quotes I remember from an article was ‚Äúthe best AE is able to get the questions answered before they are even asked.‚Äù",
              "score": 2,
              "created_utc": "2026-02-08 05:48:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xatpk",
              "author": "SirGreybush",
              "text": "I find the US & Canada especially bad at this. I've seen people put engineer or ing√©nieur in their email signatures, yet when I ask them about their degree, they only have a few college-level courses.\n\nI actively encourage real engineers to add their acronym degree in their email signatures, or the analyst to put \", mba\" if they have it, as it helps people craft a proper response in a technical email.",
              "score": -17,
              "created_utc": "2026-02-06 16:22:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xuw7l",
                  "author": "glymeme",
                  "text": "You‚Äôre 51 years old with probably 20+ YOE  and talking about having people add their college degrees to their email signatures so you know how to talk to them. That‚Äôs not a them problem. That‚Äôs a you problem.",
                  "score": 13,
                  "created_utc": "2026-02-06 17:57:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xtcqx",
                  "author": "Firm-Requirement1085",
                  "text": "Is the title engineer limited to mechanical and structural engineers, or if somebody has a degree in software engineering, could they be classed as an engineer?\n\nIf the latter is true , then it's irrelevant if they have a degree or not, they are as much a data/software engineer as somebody with a PhD if they are in that role.",
                  "score": 4,
                  "created_utc": "2026-02-06 17:49:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xhine",
          "author": "PantsMicGee",
          "text": "Mate, I don't know. I'm whatever bullshit the company decided it wasn't going to ask their Devs to do after having fired their B.I., Testers and BA teams.",
          "score": 52,
          "created_utc": "2026-02-06 16:53:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40429w",
              "author": "Even_Serve7918",
              "text": "Man this is so accurate",
              "score": 3,
              "created_utc": "2026-02-07 00:56:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y1gg2",
          "author": "Remarkable-Win-8556",
          "text": "I am a data dude.",
          "score": 51,
          "created_utc": "2026-02-06 18:28:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ysm8l",
              "author": "burningburnerbern",
              "text": "I‚Äôm someone‚Äôs data bitch üò≠",
              "score": 40,
              "created_utc": "2026-02-06 20:40:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40ewgh",
                  "author": "peppaz",
                  "text": "We are all someone's data bitch at the end of the day lol",
                  "score": 6,
                  "created_utc": "2026-02-07 02:02:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3yezjr",
              "author": "sudotrd",
              "text": "‚ÄúData Guy‚Äù checking in lol",
              "score": 13,
              "created_utc": "2026-02-06 19:33:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4035ap",
              "author": "SaintTimothy",
              "text": "I 'member Data Dude (flavor of visual studio around 2007-10ish intended to package up ssis, ssas, ssrs, and dbproj solution types)",
              "score": 3,
              "created_utc": "2026-02-07 00:50:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o44g3k2",
              "author": "dark_dagger99",
              "text": "I‚Äôm the Data guy too (I head the data team)",
              "score": 2,
              "created_utc": "2026-02-07 18:41:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y4giw",
          "author": "SasheCZ",
          "text": "I'm a Data Developer. Check mate.\n\nDon't fuss around the titles, they don't mean much.",
          "score": 34,
          "created_utc": "2026-02-06 18:42:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3zrfcl",
              "author": "Bolt986",
              "text": "I've told people I'm a \"database developer\" for at least a decade.",
              "score": 5,
              "created_utc": "2026-02-06 23:42:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3zyymd",
              "author": "Rodeo9",
              "text": "My company literally lets us choose titles. I just change it depending on applications.",
              "score": 3,
              "created_utc": "2026-02-07 00:26:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o40govp",
              "author": "Guilty_Ask_9445",
              "text": "My company gave me Data Developer/Analyst. I have to put that in my signature with a slash ‚Äò/‚Äò üòÅ",
              "score": 3,
              "created_utc": "2026-02-07 02:13:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3yreah",
          "author": "[deleted]",
          "text": "I'm a Data Plumber",
          "score": 20,
          "created_utc": "2026-02-06 20:34:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o403obq",
              "author": "SaintTimothy",
              "text": "'The internet is a series of tubes' - Sen. Ted Stevens, June 2006, when arguing opposing a net neutrality bill.",
              "score": 3,
              "created_utc": "2026-02-07 00:53:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o405ghn",
                  "author": "Even_Serve7918",
                  "text": "I mean technically everything is a series of tubes, including humans, so he‚Äôs right.",
                  "score": 0,
                  "created_utc": "2026-02-07 01:04:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o409h2l",
              "author": "krurran",
              "text": "Data Sanitation Engineer\n\n\nAka data janitor",
              "score": 3,
              "created_utc": "2026-02-07 01:29:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4326om",
              "author": "JBalloonist",
              "text": "The answer I always give to people not in the know. ",
              "score": 1,
              "created_utc": "2026-02-07 14:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xv004",
          "author": "soggyarsonist",
          "text": "I'm probably an analytics engineer.\n\nI have colleagues who sort out integrations into our datalake but my team does all the SQL and BI stuff.\n\nI've also set up some scheduled notebooks on the datalake running python scripts and appending data to tables used in reports.\n\nIn all honesty I'd hate being purely BI and entirely dependent on someone else transforming the data into the required format.\n\nI quite enjoy problem solving, and if I need a new skill then I just teach myself what I need to know.",
          "score": 16,
          "created_utc": "2026-02-06 17:57:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o434rm5",
              "author": "0sergio-hash",
              "text": "In the same boat. Trying to get more towards data engineering. Honestly want to do a tour through DE , and then some BI, Data Gov, MDM work, maybe a little Data Science \n\nJust out here sampling all the roles lol. Eventually would love to be \"full stack\" as much as one can be\n\nI feel like the distinctions are a bit arbitrary because to be a good analyst you need to understand master data management, the pipelines that brought you the data, the way things were modeled, the quirks of the BI tool, the quirks of the business and the random assortment of software they use etc",
              "score": 3,
              "created_utc": "2026-02-07 14:45:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4i89o3",
              "author": "HOMO_FOMO_69",
              "text": "BI is more than just reporting.... Transforming data into the required format is still under the BI umbrella",
              "score": 1,
              "created_utc": "2026-02-09 21:42:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4i8qkl",
                  "author": "soggyarsonist",
                  "text": "I see comments from quite a few people who seem to work almost entirely from prepared datasets.",
                  "score": 2,
                  "created_utc": "2026-02-09 21:44:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xdjek",
          "author": "PrestigiousAnt3766",
          "text": "Platform engineer üòÇ, but data discounting that.",
          "score": 16,
          "created_utc": "2026-02-06 16:34:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y29r3",
          "author": "Distinct-deel",
          "text": "BI Analyst (~2.5 YOE) at healthcare (a small organization\naround 700-employe) . What I do: building SQL-based ETL pipelines, managing the data warehouse, and developing stored procedures for staging, dimension, and fact table loads. I also build and automate Power BI semantic models and dashboards, and develop KPI frameworks and basic predictive models for pricing and productivity. \nBasically analytics + data engineering + ‚Äúwhatever breaks.‚Äù Still not sure what my actual title is.",
          "score": 12,
          "created_utc": "2026-02-06 18:32:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41q6k5",
              "author": "sweet_dandelions",
              "text": "Data Architect/All",
              "score": 5,
              "created_utc": "2026-02-07 07:58:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o40f6lv",
              "author": "peppaz",
              "text": "I'm doing all exactly that and I'm a chief lmao so yea, titles don't mean shit- I've been doing it for 20 years now",
              "score": 3,
              "created_utc": "2026-02-07 02:04:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o423y1r",
              "author": "hereforthistoo",
              "text": "I want to be/do this.. essentially a data/bi solution architect, mind if I dm you?",
              "score": 1,
              "created_utc": "2026-02-07 10:12:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o43kngg",
                  "author": "Distinct-deel",
                  "text": "Hey sure",
                  "score": 1,
                  "created_utc": "2026-02-07 16:06:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4r1htr",
              "author": "OkDirection3438",
              "text": "Nice! Can I also dm you some questions?",
              "score": 1,
              "created_utc": "2026-02-11 05:24:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o408rcx",
          "author": "tvdang7",
          "text": "Data imposter here....",
          "score": 5,
          "created_utc": "2026-02-07 01:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zhuor",
          "author": "Pandapoopums",
          "text": "I prefer to call myself a Data Dumbass because I think any of the other titles inflate the head to be too large - let's not forget we're fallible people at the end of the day with strengths and weaknesses, despite our expertise and experience. Out of the two options, I think my strength is definitely more in the Analytics Engineer direction, though my official title is Senior Data Engineer.\n\nI would say I'm more in the Analytics Engineer direction because I work directly with the business defining models and answering their questions, something most people who involve themselves only in ingestion and processing I've found tend to shy away from. I've handled ingestion, I've also had past lives in reporting, ETL/ELT and web dev, so I'm confident in my skills on any side they want to put me on. I don't really concern myself with title all that much, what I do care about is that the problem in front of me and ownership of responsibilities gets handed out cleanly. If you want me to do all of it end to end, I can do it, if you want me to handle just one piece just tell me where to stop and interface with another group.",
          "score": 5,
          "created_utc": "2026-02-06 22:48:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ybnpz",
          "author": "brrrreow",
          "text": "Neither, technically. Closer to AE but I find keeping up in DE communities to be helpful for my role and interests. \n\nOur Engineering team has dedicated data (platform) engineers that get software and external source data into a central datalake. I‚Äôm on the analytics team, and own the warehouse, including ingesting from the datalake and transforming/orchestrating it for use by data scientists and business analysts. \n\nI also pick up lightweight DE tasks that are too small for eng teams to pick up, like scheduled file processing/drops to external vendors.",
          "score": 3,
          "created_utc": "2026-02-06 19:16:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ys6yy",
          "author": "MPL206",
          "text": "I feel like everything is getting bundled, as I fresh grad who‚Äôs role is a BI analyst slowly my role is transitioning to more analytics engineer.  Most my role now is power automate for automations or data capture in excels/sharepoint list in a SharePoint type non-relational setup. This obviously isn‚Äôt the same for every company, but as a analytics team with an IT team that just got cut by 95%, strict cyber and IT red tape. Just trying to do my best with little resources I have.",
          "score": 3,
          "created_utc": "2026-02-06 20:38:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zd9sd",
          "author": "dev81808",
          "text": "25% DE, 75% AE\n\nOfficially: DE\n\nThis past week: 10% DE, 40% AE, 50% PM fml",
          "score": 3,
          "created_utc": "2026-02-06 22:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zyem5",
          "author": "iwantthisnowdammit",
          "text": "Nah, I‚Äôm data governance engineer üòÇ",
          "score": 3,
          "created_utc": "2026-02-07 00:23:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o411bo8",
              "author": "mpaes98",
              "text": "Ah yes, a fellow paperwork scientist",
              "score": 2,
              "created_utc": "2026-02-07 04:28:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42tdqc",
          "author": "HC-Klown",
          "text": "I am a what people are calling right now a Full Stack Data Engineer. \n\nIs there where the market is going? \n\nI take care of platform design & implementation, ingestion, curation, modeling, orchestration and sometimes i even create simple exposures (simple dashboards, reports etc.). On top of that i create processes and frameworks that enable DQ Assurance for data stewards. \n\nMy official title is Senior Data Engineer. We have another Non Sr. Data Engineer in our team and he mostly does platform and ingestion. Now we are trying to push him to also do more modeling and curation so he geta to know the domains better. But i guess as a Data Engineer you are expected to kind of be able to do it all.",
          "score": 3,
          "created_utc": "2026-02-07 13:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xpeor",
          "author": "MonochromeDinosaur",
          "text": "I write A LOT of code, A LOT of SQL, and a lot of user facing application code (unfortunately) but my main responsibility is DE.\n\nI came from a hybrid of data science and web development into DE best of both worlds few of the downsides IMO.",
          "score": 5,
          "created_utc": "2026-02-06 17:31:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xxfrg",
              "author": "SOLUNAR",
              "text": "Do you build datasets or foundations for others to do their analysis? Or are the one using sql for the analysis ?",
              "score": 1,
              "created_utc": "2026-02-06 18:09:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xzds9",
                  "author": "MonochromeDinosaur",
                  "text": "All of the above. Depends on the product I‚Äôm working on. \n\nMy current company has a full suite of SaaS, Data APIs, and DWaaS products. \n\nI‚Äôve implemented frontend features for the SaaS, dashboards to embed in products, backend code for serving data via the APIs, and  data modeling for the DW services we provide. \n\nWe give our customers the options to use our interface for their analytics, APIs to self serve, or set them up with OLAP warehousing, we also offer export services to DB/data dump/FTP.\n\nIt‚Äôs a little of everything. I joined when the company was small <100 people we‚Äôre at around ~1500 now.",
                  "score": 2,
                  "created_utc": "2026-02-06 18:18:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3yobbj",
          "author": "a-vibe-coder",
          "text": "Yes",
          "score": 6,
          "created_utc": "2026-02-06 20:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y448x",
          "author": "Outside-Storage-1523",
          "text": "Analytic, and I fucking hate it. I don‚Äôt consider myself as an engineer either. It‚Äôs just a glorified analyst position.",
          "score": 5,
          "created_utc": "2026-02-06 18:40:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47bg2k",
              "author": "HC-Klown",
              "text": "Why do you hate it? What stage of the data lifecycle would you rather be working in? Or any at all?",
              "score": 2,
              "created_utc": "2026-02-08 04:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48togc",
                  "author": "Outside-Storage-1523",
                  "text": "I guess I don't really like this business-facing position. I'd rather go upstream to do streaming/ingestion than data modelling, which bores the majority headache from the human side. Streaming is technically more challenging but a bit further from stakeholders.",
                  "score": 1,
                  "created_utc": "2026-02-08 12:52:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3yqt0x",
          "author": "rampagenguyen",
          "text": "Yes",
          "score": 5,
          "created_utc": "2026-02-06 20:31:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xtvwn",
          "author": "nightslikethese29",
          "text": "At my company we have them separated. I'm a data engineer so for us our responsibility is to get data into and out of the data warehouse as well as transfer data between our other systems. The modeling and most data validation goes to the analytics engineers that we work closely with.",
          "score": 3,
          "created_utc": "2026-02-06 17:52:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42v4sn",
              "author": "HC-Klown",
              "text": "How much work does just doing ingestion, RETL and platform dev generate for you? In our team we have a lot of business data validation and modeling work to do. We do not have the need to keep upgrading our Platform, so data engineers end up also doing more data modeling (as I think they should by default) and business understanding.\n\nIngestion for us is fairly simple, we have a declarative way to setup ingestion and ingesting new data takes 10 minutes. After it‚Äôs in the platform it‚Äôs all about modeling and understanding the business process. \n\nWe don‚Äôt mindlessly update the platform capabilities if there is no need for it.\n\nAnd mind you we are a telecom company with over 75 different systems to ingest data from and we built our own on-prem data platform.",
              "score": 1,
              "created_utc": "2026-02-07 13:50:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4450qd",
                  "author": "nightslikethese29",
                  "text": "A lot of work. We're in a high growth phase and essentially a startup. Leadership is constantly changing systems. The infrastructure maturity isn't there and I'm helping to build it. \n\nWe also handle some non data engineering tasks that I think backend software engineers would normally do. That involves a lot of data and business validation, but I didn't include it because it's not typical DE work.",
                  "score": 2,
                  "created_utc": "2026-02-07 17:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3y6fbn",
              "author": "apache_tomcat40",
              "text": "lol, what kind of data engineering do you do if you don‚Äôt do data modeling and data validation?",
              "score": -1,
              "created_utc": "2026-02-06 18:51:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3y8m8p",
                  "author": "nightslikethese29",
                  "text": "Extracting data from source systems and loading to raw layer. Extracting data from warehouse to send externally. So essentially the EL part of ELT. \n\nThe data validation we do is much more about data types, missing data, etc. Business data validation happens downstream of us.",
                  "score": 7,
                  "created_utc": "2026-02-06 19:02:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3y9fxz",
                  "author": "paxmlank",
                  "text": "platform/infra/devops",
                  "score": 4,
                  "created_utc": "2026-02-06 19:06:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3x93ag",
          "author": "Sensitive-Sugar-3894",
          "text": "I'm one of the geek ones. üòÅ",
          "score": 2,
          "created_utc": "2026-02-06 16:14:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yidbx",
          "author": "m915",
          "text": "Analytics engineer was created by dbt, and most of them use it",
          "score": 1,
          "created_utc": "2026-02-06 19:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ymtl7",
          "author": "Thatgreenvw",
          "text": "The UK Government Digital and Data Profession Capability Framework has distinct definitions for analytics engineers alongside a myriad of other data roles. This is used as the basis for job profiles across the uk civil service\n\nhttps://ddat-capability-framework.service.gov.uk/#data-roles",
          "score": 1,
          "created_utc": "2026-02-06 20:11:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yxkx2",
          "author": "stayfroggy-6",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-06 21:05:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z6e2p",
          "author": "Lucade2210",
          "text": "Role names are just HR bs. \n\nIf your team adheres to specific tasks for these specific roles, you're completely missing the point and failing at your job.",
          "score": 1,
          "created_utc": "2026-02-06 21:49:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40ehq6",
          "author": "peppaz",
          "text": "Yes but not a good one. I would for a big non profit federal health system and self host everything. So I hacked together an enterprise system lol but we don't get to use too much cool stuff",
          "score": 1,
          "created_utc": "2026-02-07 02:00:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40glbd",
          "author": "daszelos008",
          "text": "I started with DE title but I built API in java, wrote scala spark jobs, doing shit with open source technology. I interviewed another company for a DE role and they said I should be in DataOps position...\n\nNow I'm calling myself a Software Engineer specialized in data tech",
          "score": 1,
          "created_utc": "2026-02-07 02:12:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40mnhw",
          "author": "RadioactiveTwix",
          "text": "I'm the guy you call when you need to migrate the on prem Hadoop pipeline to the cloud.... Title irrelevant.",
          "score": 1,
          "created_utc": "2026-02-07 02:50:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o417aj1",
          "author": "Ace__Trainer",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-07 05:12:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o417d9r",
          "author": "Lurch1400",
          "text": "Current title: Data Integration Engineer\n\nActual title based on what I do: Business Intelligence Developer\n\n\nLearned by being a fly on the wall that the title doesn‚Äôt really matter, it‚Äôs what you‚Äôre actually doing that does",
          "score": 1,
          "created_utc": "2026-02-07 05:13:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41jx9o",
          "author": "killer_sheltie",
          "text": "I just move data around. I think people are often surprised at how little I look at the data beyond confirming it‚Äôs where it needs to be.",
          "score": 1,
          "created_utc": "2026-02-07 06:59:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41kwt0",
          "author": "nerevisigoth",
          "text": "No idea. I just do what seems useful and they keep giving me lots of money for it.",
          "score": 1,
          "created_utc": "2026-02-07 07:08:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41pzxf",
          "author": "sweet_dandelions",
          "text": "Senior DevOps and Data Engineer. So yeah, basically you are expected to know IaC, CICD, Kubernetes and whatnot besides being the true Data Engineer with building data pipelines, analyzing the business side and also developing reports in BI tools. \n\nIt's fucking crazy, but hey, how else would companies get more money for themselves if they hire 5 people for all of the above? Just sell the dream that you can and should become the one man show to rule it all üôÇ And no, I'm not the senior here, just venting",
          "score": 1,
          "created_utc": "2026-02-07 07:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41rqnh",
          "author": "davf35",
          "text": "I am glad I am not alone. I often feel like an overpaid analyst. \n\nNo warehouse. No constant new pipelines.\n\nJust solving whatever data needs a specific application has.\n\nIdk how I will ever be able to find a real DE job with only experience like this, yet DE is in my title and DE was what I was trained on.",
          "score": 1,
          "created_utc": "2026-02-07 08:12:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41wlt8",
          "author": "freedumz",
          "text": "Non tech people callee me data wizard",
          "score": 1,
          "created_utc": "2026-02-07 08:59:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42ujhj",
          "author": "hardrock2474",
          "text": "i think i am more of an analytics engg rather than data engg.\n\n\ni do mostly etl work, but i really don't delve into systems architecture anymore, compared to when i was a software engineer in my previous job. then i do dashboarding in power bi as well.",
          "score": 1,
          "created_utc": "2026-02-07 13:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44o904",
          "author": "dev_lvl80",
          "text": "Both. If there are third differential in title, still same answer.\nMean, does not matter how many titles are in data.¬†\nIf you work long enough in this field, you should know end to end stack and be able to adapt quickly.",
          "score": 1,
          "created_utc": "2026-02-07 19:22:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o469c0m",
          "author": "Amar_K1",
          "text": "Call it data analyst end of story\n\nBusiness intelligence, data science, data engineer, analytics engineer its all the same thing. Use excel, sql and python.",
          "score": 1,
          "created_utc": "2026-02-08 00:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47gzo3",
          "author": "ninja_age",
          "text": "part time plumber over here, just left my tool bag in the car",
          "score": 1,
          "created_utc": "2026-02-08 05:34:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4857gw",
          "author": "grungedimi",
          "text": "So what would be the most correct title for someone who doesn't develop the ETL pipelines and such, but makes data models (conceptual, logical, physical) based on what business needs, to then check the as is physical data structures to see what is missing and needs to be built, and communicates all of that to the developers?\n\nSome places call them data analyst, but in other places that title is for the power users who come to business insights based on what their BI tool shows. Some would call them data architects.\n\nI agree with most people here who say there really isn't any consistency in terminology across organisations. But i'm still curious what you would call the role described above.",
          "score": 1,
          "created_utc": "2026-02-08 09:14:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4blzpj",
              "author": "Free-Bear-454",
              "text": "Great question. Indeed the role definition depend a lot on the company, the teams and the timing¬†",
              "score": 1,
              "created_utc": "2026-02-08 21:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49uwk4",
          "author": "stavroblofeldd",
          "text": "I can understand why Analytics Engineering term popped up. Since demands are getting higher and higher every day on shifting business dynamics and people expect you to know everything, you cannot exist as pure data analyst/engineer or BI developer. \n\nI am currently working on an engineering company‚Äôs R&D department as data analyst but actively doing data engineering, BI development, data analytics and also minor business analyst tasks. Due to recent layoffs, I am forced to do all those tasks as a single person! \n\nIn conclusion, analytics engineering is polite way to say ‚Äúdo all related data tasks‚Äù",
          "score": 1,
          "created_utc": "2026-02-08 16:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ec9sx",
          "author": "mattiasthalen",
          "text": "I‚Äôm an Analytics Data Engineer üòÖ j/k\nI‚Äôm an Analytics Consultant and I do both DE & AE.\nClients doesn‚Äôt want DEs or AEs, they want full-stack.",
          "score": 1,
          "created_utc": "2026-02-09 07:35:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fig05",
          "author": "gabyzochloride888",
          "text": "There is only one Engineering",
          "score": 1,
          "created_utc": "2026-02-09 13:37:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y8zes",
          "author": "Treemosher",
          "text": "I have no idea.  I am the first DE person at my employer, they're working on my new title right now, but their titles are all over the place anyway.  Network engineers are called system administrators here, for example.\n\nI am building a CDW basically from scratch along with learning all the major platforms our data is sourced from.\n\nSince it is all supporting analytics, I would assume \"analytics engineer\" is that?  \n\nI'm just having a blast though.  I don't care about the title or even the money as long as I can pay my mortgage and work on cool projects",
          "score": 1,
          "created_utc": "2026-02-06 19:03:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ythka",
              "author": "Unlikely-Loss5616",
              "text": "What is your education and credentials?",
              "score": 1,
              "created_utc": "2026-02-06 20:45:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3zj1zc",
                  "author": "Treemosher",
                  "text": "I'll try to keep it brief - I started as a paper pusher who got really mad at a terrible data migration with our billing system.  Very long story that still irks me to this day.  Left that company after the dust settled and got started in IT at another company.\n\nDid very well in IT for a few years, then was an awful data analyst for a couple years.  But while being terrible at analytics, I did convince IT to spin me up a couple VM servers and I built my own end-to-end orchestration in Python because I hated spending 2 days a week updating dashboards.\n\nThe system I built ended up running all the analyst's updates so they could focus on customers more.\n\n(To anyone thinking of all the things wrong with that, yes I know.  We all knew, which is why it was temporary.  Sometimes you have to pick up a machete and force a path forward.  It worked and I'm retiring those VM shitballs as soon as I can.  I wrote the systems myself and will be the first to say let's burn it all in fire.)\n\nTwo years later we got a director who agreed with me that we need a proper data warehouse.  Surprise surprise, it's amazing and everyone else now realizes it's not as scary as they thought.\n\nEducation - I've got a BS in IT and always strive to follow best practices with coding, governance etc.  I'm not just saying that.  Following best practices goes a very long way.",
                  "score": 3,
                  "created_utc": "2026-02-06 22:55:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3y4mhv",
          "author": "Typhon_Vex",
          "text": "Analytics engineer is a joke position and outcome of the ideology that the bussiness should handle as much of the data wranglig as possible themsleves.\n\nSee it goes like this. Supposedly the IT profesionsals handling data in the past were too expensive, slow and asking many annoying questions.\n\nThe bussines needed shipping their crappy dahsboards and reports in high frequency. So they gained more and more permissions to achieve just that and do their own crappy tranformations regardless of any modelling aor achitecture.\n\nSurprisingly eventually they are swamped in spaghetti code and tech debt. Eventually the called data analysts has to maintain that crucial report by himself 24/7 and becomes a single dashboard person.\n\nAlso the bussines needs more talking and show off people. And they can¬¥t waste their time with SQL.\n\nAnd so the analytics engineer is born. It¬¥s a developer outside of IT, to do the slave work, but not cool enough to run around with piecharts.\n\nHe does it for the bussines salary , and not the IT professional salary - thats your main identifier, how you will know if you are an IT professional, or a data analytics bozo.\n\n  \nAs for me, since the company started to move to the cloud, I¬¥m fully on data engineering - meaning moving data reliably between systems, in this case from legacy to the cloud. I¬¥m damn gonna make sure to go nowhere near a metric or piechart. Anyway we used to do that too, but freedom was given to the data analysts, to do that.\n\n",
          "score": 0,
          "created_utc": "2026-02-06 18:43:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40avzy",
              "author": "murphire",
              "text": "I‚Äôm sure it varies from company to company, but this description is not reflective of my position as an analytics engineer. Well, except the parts where they find me expensive and slow, and not cool enough to run around with pie charts very often.",
              "score": 2,
              "created_utc": "2026-02-07 01:37:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o402jsl",
              "author": "glymeme",
              "text": "Wow. Moving data from A to B is so much better than building data products. üôÑ",
              "score": 2,
              "created_utc": "2026-02-07 00:47:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x9omp",
          "author": "SirGreybush",
          "text": "Oxymoron - analytics engineer\n\nAn engineer supposes advanced math, chemistry & physics with a Uni degree in any engineering field. They have advanced problem solving skills. Thus engineers can also be decent with actual coding and applying best practices.\n\nA data analyst usually know basic + statistics math, maybe basic calculus, and would have an MBA. Some excellent schools have within their MBAs dimensional modeling + advanced SQL courses. Or a good student will do a minor in SWE.\n\nAlso - hotels in the US call janitors \"maintenance engineers\" - I mean WTF???",
          "score": -15,
          "created_utc": "2026-02-06 16:17:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xq1rd",
              "author": "MiserableLadder5336",
              "text": "\nen¬∑gi¬∑neer\n/Àåenj…ôÀànir/\nnoun\n1. A person who designs, builds, or maintains machines, structures, or systems.\n\n\nGet over yourself.",
              "score": 4,
              "created_utc": "2026-02-06 17:34:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xjqtt",
              "author": "EricMichaelHarris99",
              "text": "Chemistry?",
              "score": 2,
              "created_utc": "2026-02-06 17:03:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xmz2b",
                  "author": "SirGreybush",
                  "text": "Chemistry - it's a required STEM subject to obtain your engineering Bachelor's degree.\n\nIt's a jab at all the non-engineers that give themselves the title just because they occupy a job role.",
                  "score": 2,
                  "created_utc": "2026-02-06 17:19:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3xiq3s",
              "author": "SirGreybush",
              "text": "LMAO the downvotes, seems I'm rubbing some analysts the wrong way",
              "score": 0,
              "created_utc": "2026-02-06 16:59:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xtmlt",
                  "author": "glymeme",
                  "text": "No, you just come off as combative. Analytics engineering is literally applying software engineering best practices to analytics work. I‚Äôve seen just as many CS majors do worse system designs than non-CS majors. Problem solving skills aren‚Äôt limited to people with STEM degrees.",
                  "score": 5,
                  "created_utc": "2026-02-06 17:51:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qwvy5y",
      "title": "Data Modeling expectations at Senior level",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/",
      "author": "Outside_Reason6707",
      "created_utc": "2026-02-05 20:04:50",
      "score": 67,
      "num_comments": 29,
      "upvote_ratio": 0.98,
      "text": "I‚Äôm currently studying data modeling. Can someone suggest good resources?\n\nI‚Äôve read Kimballs book but really from experience questions were quite difficult.\n\nIs there any video where person is explaining a Data Modeling round and is covering most of the things that Sr engineer should talk. \n\nEnglish is not my first language so communication has been barrier, watching videos will help me understand what and how to talk.\n\nWhat has helped you all?\n\nThank you in advance!",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3ryvy2",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-05 20:04:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s0lgf",
          "author": "Ok_Tough3104",
          "text": "Joe Reis is dropping a book on data modelling in 1 month, if you're patient enough...\n\nAlso he has a whole substack about that book if you can read from a PC screen without having your eyes bleeding\n\nhttps://practicaldatamodeling.substack.com/",
          "score": 48,
          "created_utc": "2026-02-05 20:12:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xixpa",
              "author": "mightregret",
              "text": "RemindMe! 1 month",
              "score": 5,
              "created_utc": "2026-02-06 17:00:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ti6tn",
              "author": "studentofarkad",
              "text": "Thank you, thats the book I'm waiting for to drop!",
              "score": 1,
              "created_utc": "2026-02-06 00:49:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3v5b83",
              "author": "AccomplishedTax2306",
              "text": "Is it possible to pre-order?",
              "score": 1,
              "created_utc": "2026-02-06 07:34:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vbidi",
                  "author": "Ok_Tough3104",
                  "text": "The whole book is on the substack. (If you can read from a screen)\n\nIts a pay sub. I havent heard Joe mentioning anything about pre ordering, im also in europe, so compared to the US market the book will be delayed by a couple of weeks\n\nApologies for not being able to provide better insights üòÖ",
                  "score": 2,
                  "created_utc": "2026-02-06 08:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3xing2",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-06 16:58:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xitrv",
                  "author": "RemindMeBot",
                  "text": "I will be messaging you in 1 month on [**2026-03-06 16:58:46 UTC**](http://www.wolframalpha.com/input/?i=2026-03-06%2016:58:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/o3xing2/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1qwvy5y%2Fdata_modeling_expectations_at_senior_level%2Fo3xing2%2F%5D%0A%0ARemindMe%21%202026-03-06%2016%3A58%3A46%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qwvy5y)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                  "score": 1,
                  "created_utc": "2026-02-06 16:59:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ekjpk",
              "author": "HODLING_APE",
              "text": "RemindMe! 1 month",
              "score": 1,
              "created_utc": "2026-02-09 08:56:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sn0h5",
          "author": "Gullible_Buy427",
          "text": "Another great read is data modeling made simple by Steve Hoberman.",
          "score": 7,
          "created_utc": "2026-02-05 22:00:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uvyiq",
              "author": "dehaema",
              "text": "Anything by steve hoberman really. His \"data modeling masterclass\" is the best course i ever took",
              "score": 3,
              "created_utc": "2026-02-06 06:13:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x2oy1",
          "author": "miker5555",
          "text": "At senior level, interviews usually aren‚Äôt about memorizing modeling patterns as much as **talking through real tradeoffs**.\n\nWhat helped me most was experience explaining *why* I modeled something a certain way, not just what pattern I used. In interviews they often care more about:\n\n* how you handle messy data\n* how models evolve over time\n* what breaks when requirements change\n* and how you explain things to non-engineers",
          "score": 7,
          "created_utc": "2026-02-06 15:44:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xhx91",
              "author": "Outside_Reason6707",
              "text": "Thank you for explaining! I think I miss the point of explaining why I model something a certain way. I focused on patterns and writing sql. Would you be open for a continued discussion, can I dm you?",
              "score": 2,
              "created_utc": "2026-02-06 16:55:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uuivo",
          "author": "tophmcmasterson",
          "text": "It depends on the role. I know tons of data engineers, maybe even most of them are pretty terrible at data modeling. \n\nThere‚Äôs a large group of engineers that have gotten by just basically moving data into the warehouse and then brute forcing OBT/flat tables ad-hoc and never really learned best practices in dimensional modeling. \n\nMy recommendation is actually play around with a front end tool like Power BI and understand how data is used and what is recommended for best practices for how data should be structured. If you understand that and refer to the Kimball modeling techniques and can actually internalize it that will get you most of the way there. \n\nIt‚Äôs not really something that is easy to explain in a video I don‚Äôt think. You need to be able to really mentally visualize how data ties together and what shape will make it easiest and most flexible to work with.",
          "score": 11,
          "created_utc": "2026-02-06 06:01:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v0cb8",
              "author": "Hear7y",
              "text": "We just got forced by business to make this absolutely awful flat table (think here both business keys and foreign keys BOTH present) in an increasingly wise table, because they didn't want to have to build any sort of relation when doing stuff in Excel.\n\nFeels like a massive App that was made to solve multiple issues and serve a variety of internal customers is exclusively used to serve a crappy table for Excel. :D",
              "score": 2,
              "created_utc": "2026-02-06 06:50:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vd3dp",
                  "author": "BrownBearPDX",
                  "text": "That‚Äôs when you keep your data models as you should for all the goody goods that will stick to them forever and ever and ever because of that good thinking. \n\nWhat you do then is you build them a freaking view as wide as their stupid little brains can handle. Don‚Äôt change the actual schemas that the business actually relies on and more intelligent people will rely on in the future. Don‚Äôt destructure good thinking into bad and actually implement it. Lie to them if you have to.  Retain your ability to sleep at night.",
                  "score": 7,
                  "created_utc": "2026-02-06 08:47:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3x07z3",
              "author": "Outside_Reason6707",
              "text": "Okay understood. I'm struggling with performance in data modeling interviews, and I'm unsure what's expected of me. In the past, I've asked clarifying questions, proposed entities, and developed dimensional models with fact tables and dimension tables. I've also written SQL code for my proposed solutions and modified my schema based on follow-up questions. However, I haven't received positive feedback, and I'm starting to wonder if I'm missing something fundamental or if it's just a communication issue. I'd love to find a recommended video that demonstrates how to excel in a data modeling interview. Something like demo interviews",
              "score": 2,
              "created_utc": "2026-02-06 15:32:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3x2rlo",
                  "author": "tophmcmasterson",
                  "text": "I‚Äôd again just recommend reviewing some of the well established documentation on Kimball techniques or even going through the Microsoft guidance documentation on star schema (it‚Äôs aimed at designing for Power BI but broadly applicable I think).\n\nIf you internalize the concepts and thought process through working on actual projects you‚Äôll be able to speak to it more naturally.",
                  "score": 3,
                  "created_utc": "2026-02-06 15:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vp67i",
              "author": "Ploasd",
              "text": "Kimball is one of many methods of modelling and is only really good if your building OLAP style infrastructure but people really should understand alternative methodology - 3NF and all that.",
              "score": 0,
              "created_utc": "2026-02-06 10:41:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3vpbs8",
          "author": "Ploasd",
          "text": "I do think Database Design for Mere Mortals by Michael Hernandez is a good easy to read reference around database design that can also help with understanding how to model data.",
          "score": 2,
          "created_utc": "2026-02-06 10:43:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hig0x",
          "author": "BitterAcanthisitta67",
          "text": "two words: DATA VAULT",
          "score": 1,
          "created_utc": "2026-02-09 19:34:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vwkyd",
          "author": "IrquiM",
          "text": "You only get to senior level in data modeling after having spent 10 years at a lower level. No books kan teach it to you, and anyone who says otherwise, are not at a senior level.",
          "score": 0,
          "created_utc": "2026-02-06 11:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x0l1p",
              "author": "Outside_Reason6707",
              "text": "I‚Äôve 7-8 years of experience. And what you said is very much valid. I'm struggling with performance in data modeling interviews, and I'm unsure what's expected of me. I haven't received positive feedback, and I'm starting to wonder if I'm missing something fundamental or if it's just a communication issue.",
              "score": 3,
              "created_utc": "2026-02-06 15:33:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3xvn5e",
                  "author": "IrquiM",
                  "text": "Modeling is just a part of it. To get a senior position, you need to show that you do not require supervision, you can take decision yourself, you can plan ahead and decide what to prioritize, etc.",
                  "score": 2,
                  "created_utc": "2026-02-06 18:00:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxhzhs",
      "title": "In what world is Fivetran+dbt the \"Open\" data infrastructure?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxhzhs/in_what_world_is_fivetrandbt_the_open_data/",
      "author": "finally_i_found_one",
      "created_utc": "2026-02-06 13:43:47",
      "score": 64,
      "num_comments": 31,
      "upvote_ratio": 0.97,
      "text": "I like dbt. But I recently saw these weird posts from them:\n\n* [https://www.getdbt.com/blog/what-is-open-data-infrastructure](https://www.getdbt.com/blog/what-is-open-data-infrastructure)\n* [https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future](https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future)\n\nWhat is really \"Open\" about this architecture that dbt is trying to paint?\n\nThey are basically saying they would create something similar to databricks/snowflake, stamp the word \"Open\" on it, and we are expected to clap?\n\nIn one of the posts, they say \"I hate neologisms for the sake of neologisms. No one needs a tech company to introduce new terms of art purely for marketing.\" - its feels they are guilty of the same thing with this new term \"Open Data Infrastructure\". One more narrative that they are trying to sell.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxhzhs/in_what_world_is_fivetrandbt_the_open_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3wlke3",
          "author": "codykonior",
          "text": "Open (your wallet for) data infrastructure.\n\nCompanies who use FiveTran must be the billion dollar types with money burning holes in their pockets.\n\nI had a look at migrating a small ELT process to it last year, which I can run almost free inside Azure SQL DB with scripts and elastic job agent, for a few minutes each night.\n\nFiveTran was going to cost $50kpa, before the recent price increases üòí And you'd be locked in to more. And you'd still have to spend tons of time scripting up stuff.",
          "score": 70,
          "created_utc": "2026-02-06 14:18:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wzt0i",
              "author": "CulturalKing5623",
              "text": "A recent client had maybe 10 sources, none of them larger than 10K records per day. I told them all they needed was to throw some python scripts in an EC2 to handle it, had it built and ready to go. Total cost was probably somewhere around $50/month and it just chugged along, rarely had any issues ever. \n\nFast forward to them hiring a chief \"go to market strategist\" or something like that, the person responsible for getting them acquired, and they decide they need a \"mature data stack\" to be more attractive to outside investors. So we hooked everything up to Fivetran and data bricks and built a medallion architecture and the whole shebang. All great stuff.\n\nThe last time I checked their Fivetran is running at $15k/year and is _constantly_ throwing errors for this reason or that.",
              "score": 16,
              "created_utc": "2026-02-06 15:30:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x0j49",
                  "author": "contrivedgiraffe",
                  "text": "That‚Äôs a great example of the difference between trying to run a business and trying to get acquired.",
                  "score": 20,
                  "created_utc": "2026-02-06 15:33:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3yh2p2",
              "author": "baronfebdasch",
              "text": "To be fair, the value proposition of FiveTran is always competing against a ‚Äúroll your own‚Äù extracting method. It‚Äôs not rocket science. \n\nIf your data environment is relatively fixed I would agree there is almost no point. \n\nBut if you‚Äôre in the business of having to extract data from dozens of systems, then it‚Äôs a matter of ‚Äúdo I pay my engineers to keep the lights on at making sure our data extraction jobs are always running, up to date, and can manage various versions of source systems, or do I simply outsource that part of the value chain and focus on actually making the data usable? \n\nIf you are a company that needs to focus on integrating data from say dozens of ERPs‚Ä¶ maybe it‚Äôs worth it to let FiveTran expedite when a new ERP hits the market (or one you haven‚Äôt seen before). \n\nOr you‚Äôre setting up a brand new data infrastructure and your sponsors are breathing down your neck to integrate your new HR system. You can spend days/weeks working through building jobs to extract said data, or have it with FiveTran in minutes. \n\nBecause they typically price on monthly deltas volumes there‚Äôs kind of a middle tier where it makes sense as part of your tech stack. Too low and it‚Äôs too expensive, and if your data volumes are massive, again, too expensive. But if you‚Äôre in that sweet spot, it may be worth paying a vendor than paying an engineer to perform those tasks.",
              "score": 8,
              "created_utc": "2026-02-06 19:43:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o42iuqw",
                  "author": "dillanthumous",
                  "text": "100% we use Fivetran tactically to keep up with fast changing APIs (Amazon etc.) and in house we handle all the stable data sources the old fashioned way.",
                  "score": 2,
                  "created_utc": "2026-02-07 12:28:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wp6l2",
              "author": "finally_i_found_one",
              "text": "No doubt they are going to raise prices. They now own the first and the middle layer of the data architecture. Also, they are now a monopoly in the data transformation space.",
              "score": 3,
              "created_utc": "2026-02-06 14:36:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4d4zrk",
              "author": "pro-taco",
              "text": "They openly scoff at people who use open stacks. If you're not snowflake or databricks, you're not important to them. \n\nVery unimpressed by their vision: it's Fusion.\n\nSqlmesh is probably dead but unclear",
              "score": 2,
              "created_utc": "2026-02-09 02:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3woj7w",
          "author": "Known-Huckleberry-55",
          "text": "The world they are pitching is one where data is stored in Iceberg tables in storage owned by companies (S3, ADLS2) and that the compute layer becomes a commodity that can become easily swapped out. One of the big features of Fusion is that it can cross-compile across different SQL dialects. Instead of getting locked into Snowflake, you can easily switch to duckdb, Databricks, whatever for different use cases.\n\nAll that said, my Fivetran and dbt Cloud bill is much higher than my Snowflake bill so I'm not worried about the compute layer like they seem to think companies are.",
          "score": 21,
          "created_utc": "2026-02-06 14:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wkcg5",
          "author": "drew-saddledata",
          "text": "dbt core is pretty good.  It's funny, I have build the same thing they envision in that blog post, ETL pipeline tool and dbt working together as a SaaS.",
          "score": 15,
          "created_utc": "2026-02-06 14:11:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4d56ue",
              "author": "pro-taco",
              "text": "Love dbt core or sqlmesh but seems like it'll die a slow death. Hoping not",
              "score": 1,
              "created_utc": "2026-02-09 02:32:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wka75",
          "author": "Illustrious_Web_2774",
          "text": "No surprise. They fucked up the word \"model\" pretty badly.",
          "score": 11,
          "created_utc": "2026-02-06 14:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wxg1y",
          "author": "Nekobul",
          "text": "The \"modern\" keyword is now toxic. The new psyop is called \"open\". ",
          "score": 7,
          "created_utc": "2026-02-06 15:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wj1ut",
          "author": "omonrise",
          "text": "well there's OpenAI ü§£",
          "score": 5,
          "created_utc": "2026-02-06 14:04:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wq3zx",
              "author": "Any_Tap_6666",
              "text": "Like the 'Democractic Republic of Congo'",
              "score": 10,
              "created_utc": "2026-02-06 14:41:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x3swm",
                  "author": "blueadept_11",
                  "text": "And Democratic People's Republic of Korea",
                  "score": 6,
                  "created_utc": "2026-02-06 15:49:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wosm6",
              "author": "finally_i_found_one",
              "text": "haha",
              "score": 2,
              "created_utc": "2026-02-06 14:34:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zggge",
          "author": "muneriver",
          "text": "My POV is someone who is closely following the work happening in iceberg, arrow, ADBC, data fusion, etc. These are technologies that are making data tools more interoperable and standardized which is what open here refers to.\n\n‚Äî-\n\nSo back to my point: The majority of the disagreement here comes from how people are defining ‚Äúopen.‚Äù This doesn‚Äôt mean open source. If you pay attention to the current developments, it‚Äôs about open standards and moving away from ‚Äúproprietary interfaces‚Äù to tools and formats that can talk to one another and in general, enable much more efficient data transfer. These two alone unlock many downstream applications!\n\nAs a small example: warehouses bundled storage, compute, and proprietary file formats together. That‚Äôs where the lock-in came from. If your data lived inside a proprietary format  (like in Snowflake), you were effectively tied to that engine.\n\nThe thing that‚Äôs really exciting and evolving is the maturation of standardized components of technological primitives that many modern tools use today. Open table formats like iveberg and delta, arrow (as a shared in-memory format), ABDC for super fast data transfer ,and newer engines like duckdb and data fusion all are working towards the same future. They‚Äôre all open source, want to converge to open standards, and if used together, enable an ‚Äúopen data infrastructure‚Äù. Which means the engine you use for AI/ML, real-time applications, and BI can all be based on data that lives in one storage layer and yet, can be run in any compute engine. Developers can live in a world where you can work towards running local dev in DuckDB and prod workloads in Snowflake. Minimizing vendor lock-in to me is just the a small side-benefit.\n\nVendors are still vendors. Nothing about this means tools like Fivetran+dbt are suddenly open source. The idea is that they operate on top of this new infrastructure that is less restrictive than the old warehouse model for the technological benefits, but also allows them to compete with Snowflake/Databricks/etc at a completely different angle. If engines are swappable, these big platforms lose a lot of their architectural leverage. Now the power and thing to control is the stuff outside of that (I will let you think through that part as an exercise haha).  \n\nAll of this to say, I try not to take anything with face value. There‚Äôs always nuance. Yes ‚Äúopen data infra‚Äù is a buzz word and is marketing for sure, but if you follow the current state of technology, there‚Äôs real nuance here!",
          "score": 9,
          "created_utc": "2026-02-06 22:41:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ce6ks",
              "author": "georgewfraser",
              "text": "This üëÜ\n\nThe data stack of the future is based open standards: Iceberg, dbt, sql. ",
              "score": 3,
              "created_utc": "2026-02-09 00:04:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wip08",
          "author": "West_Good_5961",
          "text": "dbt core is pretty open",
          "score": 9,
          "created_utc": "2026-02-06 14:02:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wo81g",
              "author": "finally_i_found_one",
              "text": "Doesn't really answer what I am asking. I hope you don't believe that Fivetran (who just ate dbt and SQLMesh) is going to create something \"Open\".",
              "score": 10,
              "created_utc": "2026-02-06 14:31:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3yvzhf",
          "author": "thisFishSmellsAboutD",
          "text": "Remember a year ago when SQLMesh didn't the same, but for free and much faster?\n\nThey were super responsive and moved fast towards a pretty decent maturity level.\n\nThen, acquisition.\n\nWho else is dreading the inevitable license rug pull from Fivetran?",
          "score": 6,
          "created_utc": "2026-02-06 20:57:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xtwwk",
          "author": "Possible_Ground_9686",
          "text": "Apache NiFi still going strong üí™üí™üí™",
          "score": 3,
          "created_utc": "2026-02-06 17:52:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40pgqo",
              "author": "Nekobul",
              "text": "Keep dreaming.",
              "score": 1,
              "created_utc": "2026-02-07 03:08:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y25qn",
          "author": "GreyHairedDWGuy",
          "text": "I tend to filter out all the nonsense terms vendors use to promote their offerings.  At the end of the day, using Fivetran (for example) is an economic decision....is it lower cost/reliable/faster to use FT versus paying a developer to build it and maintain it.  For some things yes, other no.  We use Fivetran and it works well for us but it's not economic to use is all situations and so we have rolled our own replication processes as needed.",
          "score": 1,
          "created_utc": "2026-02-06 18:31:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y62r2",
          "author": "Typhon_Vex",
          "text": "open source mostly often only means a demo or shareware that will eventually be sold and monetized.\n\nthe word open source is way overused.\n\nit shouldn¬¥t be used for pieces of software maintained by typically a lone company, typically of the same name, and which only work well when you buy the fully supported version",
          "score": 1,
          "created_utc": "2026-02-06 18:50:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41q66a",
              "author": "Thinker_Assignment",
              "text": "Have you heard of Linux, python, Kafka? Postgres? You're mistaking open source for open washing.\n\nIt's overused because sales people are using it.\n\nThere's open source and open core that aim to produce open standards\n\nThen there's open saas which is partly working software designed to upsell you to saas.\n\nThen there's open washing which is not open at all.",
              "score": 1,
              "created_utc": "2026-02-07 07:57:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o449c19",
          "author": "GoodLyfe42",
          "text": "There is always a new tool that a leader wants to use that keeps the data engineers employed. Then you have the data engineering team led by an actual data engineer who builds it in python for a fraction of the cost, fetches 5x faster, is truly portable and has far fewer incidents.\n\nIt‚Äôs hard to go to the fancy tool when you know that tool will eventually die or increase 5x in price forcing you to have a huge project to migrate off to another tool. Then you look over at all your python ingestion flows (you never moved over) and see them reliably chugging along.",
          "score": 1,
          "created_utc": "2026-02-07 18:08:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a7wom",
          "author": "Hot_Map_7868",
          "text": "While things like Iceberg and duck lake make the compute/storage more interoperable. I think that there are other things that need to be considered. Case in point, security. It's one thing to be able to run compute in Snowflake or DBX. It is another to have the same RBAC model on both platforms. \n\nSometimes I see technical teams advocate for openness, lower costs, etc without considering the additional cost of integration, maintenance, and administration. \n\n",
          "score": 1,
          "created_utc": "2026-02-08 17:26:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41nrhp",
          "author": "Thinker_Assignment",
          "text": "It's called Gaslighting, same energy as Truth social. Open bigly.",
          "score": 1,
          "created_utc": "2026-02-07 07:35:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzswfm",
      "title": "are we a dime a dozen?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qzswfm/are_we_a_dime_a_dozen/",
      "author": "turboDividend",
      "created_utc": "2026-02-09 03:08:12",
      "score": 61,
      "num_comments": 39,
      "upvote_ratio": 0.94,
      "text": "hearing alot of complaining on the cscareers subreddit and one comment that stuck out was that the OP was a front end guy and one of the responders said being a react/node.js guy isnt special. sometimes i feel the same way about being an  etl guy who does alot of sql.....",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qzswfm/are_we_a_dime_a_dozen/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4exg5o",
          "author": "Tender_Figs",
          "text": "I left corporate finance for analytics and then data engineering across a 15-year time frame. I feel more of a commodity now than I did when I was a staff accountant unless I really focus on using my domain experience. It is also why I am trying to formally get out of data engineering. \n\nI'm in a group that is constantly obsessed about tooling while paying no attention to technical debt or scale, nor the purpose of what we do in the first place. It feels very far removed from any \"so what?\" in my opinion, and yes, I do understand what the \"so what?\" is.",
          "score": 69,
          "created_utc": "2026-02-09 11:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fabxw",
              "author": "A_Poor_Economist",
              "text": "I read an article once that said there are 2 types of IT. IT that's just tech nerds and IT that is tied to Finance.\n\nTech nerds tend to get obsessed with shiny new objects. Finance tied ones tended to weigh tradeoffs and more \"so what?\"\n\nA gross overgeneralization but there seems to be tech people obsessed with just the tech and people who can do more strategic thinking about what to use when and why. \n\nOf course if you're on an island that sucks. Been there.\n\nWhat are you trying to transition to?",
              "score": 29,
              "created_utc": "2026-02-09 12:45:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4fni7x",
                  "author": "Gedrecsechet",
                  "text": "The 2 types are in the name. Information and Technology. In my 25years plus working from the trenches up have noticed some people care about the tech and don't care about info it holds and others are visa versa.  Both are necessary but one exists for the purposes of the other. Like plumbing, the pipes exist to carry water and have no purpose without it.",
                  "score": 13,
                  "created_utc": "2026-02-09 14:06:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4gvdug",
                  "author": "scarredMontana",
                  "text": "I used to work as software eng. at a famous investment bank in NYC (now I'm at a fintech in Times Sq.), but you quickly learn that engineering is 2nd and business is first. Everything is done with the attitude of 1) how can we make money and stay in business and then 2) how do we make this resilient and scalable. It pains me now to work with engineers who are just to up their own ass to realize why we're building things.",
                  "score": 6,
                  "created_utc": "2026-02-09 17:45:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4fgd3h",
              "author": "Tender_Figs",
              "text": "To answer where I want to go - I would love to get back into analytics with a very heavy finance bend that may also mix data science into it. It‚Äôs where I was headed in 2022 before detouring into data engineering.",
              "score": 8,
              "created_utc": "2026-02-09 13:24:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4fr4ur",
                  "author": "RandomAccount0799",
                  "text": "What made you detour into data engineering? Do you prefer analytics to corporate finance?",
                  "score": 2,
                  "created_utc": "2026-02-09 14:27:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4fewnn",
              "author": "lozinge",
              "text": "Its a good point - also raises the question of how far can domain experience get you / how much of a moat is it?\n\nDo you know what you're going to try breaking into?",
              "score": 3,
              "created_utc": "2026-02-09 13:15:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4gfoy5",
          "author": "THBLD",
          "text": "Yes and no. I don't know where your skill level is but:\nthe ability of people to actually do quality in-depth SQL, writing functions and procedures, while understanding how it works under the hood is very far and few ppl. \n\nAs someone who's done a lot of ETL and works very heavily with SQL procedures - I do ALSO unfortunately feel that's it's nowadays not a very appreciated skill set, given the complexity to do it well.\n\nEveryone is way too focused on tool sets, AI and relying on Python for way too much. Proper SQL is still very powerful in the right hands and NEEDED.",
          "score": 14,
          "created_utc": "2026-02-09 16:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4gq18t",
              "author": "turboDividend",
              "text": "yeah dude, like...I can understand using python to parse unstructured data or something, like scrapring a website or pulling information out of a word doc/flat file/etc but i dont see the purpose of using it for doing regular ETL type stuff when a proper database can do alot of the heavy lifting, granted you know what you're doing.\n\nI've made functions in sql, stored procs, know window functions , cte, temp tables very well and have even used cursors ( lol ) . I understand how pivots work and have done outer joins/cross joins (this seems to be a bit outdated though) ive come across it in older dbs",
              "score": 3,
              "created_utc": "2026-02-09 17:19:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f9l9n",
          "author": "ThroughTheWire",
          "text": "If you're working in a cost center rather than a profit center then it can really feel that way. I do recognize that my job is almost completely subject to automation within the next few years and so I need to make sure I'm in a position to be an influential decision maker from a business / technical point of view rather than just following the directions of management/stakeholders.",
          "score": 32,
          "created_utc": "2026-02-09 12:40:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fnbol",
              "author": "turboDividend",
              "text": "most of these jobs are cost centers unfortunately. what data engineering jobs are profit centers? working in trading, Adtech, or supporting some sort of high volume sales business?",
              "score": 10,
              "created_utc": "2026-02-09 14:05:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4fowi1",
                  "author": "snarleyWhisper",
                  "text": "I‚Äôm an embedded data engineer within a sales org. All my projects have a very specific roi and are low cost. They are happy to keep expanding the scope and investing in it because they are cost sensitive but are getting business value.",
                  "score": 7,
                  "created_utc": "2026-02-09 14:14:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4fqgsp",
                  "author": "BoringGuy0108",
                  "text": "If you're driving sales or cost reductions, you could be considered a profit center. It depends on your KPIs. Is your goal to accomplish a minimum expectation at the lowest possible cost? You're a cost center. Is your goal to drive the most overall business value and cost is just one factor? You're a profit center. Or at least more of one. \n\nAlso, if your company's product is technology that requires data movement, you're a profit center by default. At my company, IT is broadly a cost center, but my team is often treated more like a profit center because we actively drive sales.",
                  "score": 6,
                  "created_utc": "2026-02-09 14:23:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4fqve8",
                  "author": "thisfunnieguy",
                  "text": "there are companies that sell data or data products\n\nadtech is one example but not the only example.\n\n",
                  "score": 3,
                  "created_utc": "2026-02-09 14:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4fg4mc",
          "author": "CorpusculantCortex",
          "text": "Idk i work as a 700 person global saas company that provides an industry specific data product that has a dedicated data science team. And I get roped into so many random etl and automation jobs because I'm the one who knows python and does etl stuff. So im not feeling very dime a dozen.",
          "score": 15,
          "created_utc": "2026-02-09 13:23:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fn25q",
              "author": "turboDividend",
              "text": "if you know python/sql and are good at it, it seems like you can write your ticket.",
              "score": 2,
              "created_utc": "2026-02-09 14:04:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4gxvz8",
                  "author": "outlier_fallen",
                  "text": "Huh? Every data engineer should know python and SQL. This kind of contradicts the point of this thread.. now I'm questioning it",
                  "score": 5,
                  "created_utc": "2026-02-09 17:57:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4fqmz4",
          "author": "thisfunnieguy",
          "text": "how \"special\" do you need to be? theres like 400 million ppl in this country. Something like 200-300million of that are adults.\n\n  \n",
          "score": 8,
          "created_utc": "2026-02-09 14:24:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4golu2",
          "author": "cokeapm",
          "text": "Branch out deeper into infra. Learn cloud, bigger tools like spark, Kafka, etc. Just go bigger. As you grow less and less people compete with you. Also git gud at being a value provided. Learn how to talk to different people, how to drive initiatives, etc",
          "score": 3,
          "created_utc": "2026-02-09 17:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hv1vd",
          "author": "RoleAffectionate4371",
          "text": "As a staff engineer, in a 100+ person data org, I very much do not feel a dime a dozen. \n\nIt‚Äôs still exceptionally hard to hire skilled engineers with agency, work ethic, and an ounce of business instinct. \n\nThe key is to not just be someone who writes etl. But someone who influences the bottom line through data engineering",
          "score": 3,
          "created_utc": "2026-02-09 20:37:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h5llq",
          "author": "TA_poly_sci",
          "text": "If you are good at DE, very much no",
          "score": 1,
          "created_utc": "2026-02-09 18:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jk7v6",
          "author": "molodyets",
          "text": "If you don‚Äôt understand the business and how other departments think and just want to be an order taker - yes",
          "score": 1,
          "created_utc": "2026-02-10 02:06:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mxehf",
              "author": "Accomplished_Cloud80",
              "text": "I think just take orders is priority. Understand business and share ideas always good and being part of the team.",
              "score": 0,
              "created_utc": "2026-02-10 16:17:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nohss",
                  "author": "molodyets",
                  "text": "being able to take orders is table stakes. if you can't do more than that, you are going to have a very hard time in a down job market.",
                  "score": 1,
                  "created_utc": "2026-02-10 18:21:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4k9uh5",
          "author": "JuggernautSad10",
          "text": "Yes",
          "score": 1,
          "created_utc": "2026-02-10 04:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ki7mo",
          "author": "szrotowyprogramista",
          "text": "Surfing cscareers to get a read on the market is kind of like reading feedback about parcel delivery services online (in absolute terms). People who are doing fine are not posting there. People who are anxious, venting or desperate are. So you're dealing with some serious sampling bias. If you value your mental health I see no point visiting that subreddit.\n\nWith that said - yeah. We are a dime a dozen. So are most people working in the more-or-less modern and commercially relevant branches of software engineering. We are not special, neither are react/node devs, neither are ios/android mobile devs, neither are infra/devops, neither are (run-of-the-mill) data scientists, etc. The non-dime-a-dozen people are those that work in more niche technologies, like dedicated graph DB engineers, or SAP stack devs or maybe these few guys that some US state government urgently hired in 2020 because they knew FORTRAN. \n\nIt's not obvious to me that one is better than the other. If you're niche, you probably have one or two employers that really need your services, but once they finally retire the legacy application they had that required you - you're in a bad position, because you're probably not finding another job. If you're a dime a dozen - you face a lot of competition, but it would be relatively easier to find something new if you lose your job. (This is of course ignoring how good you are - of course there's always many beginners and few extremely knowledgeable people, but that is true with any technology.)\n\nAlso, just a small remark, I'm not sure it is informative to say \"does a lot of SQL\". SQL is a language that has broad support across different databases and data processing engines, it's one thing to be doing a lot of SQL on a huge on-prem Postgres cluster, another to be doing a lot of SQL on a managed platform like Snowflake.",
          "score": 1,
          "created_utc": "2026-02-10 05:50:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ltqm3",
          "author": "Commercial-Ask971",
          "text": "Back in the day I was power bi developer who would establish metrics and discuss how to calculate things or why, however I felt bad because I was chased for silly things like metric doesnt fit to one MD expectations.. or ‚Äûlets make this report more aesthetic‚Äù etc so I switched to data engineering and while I rarely make anything related to metrics anymore (just deliver semantic model and finish), now I feel like nobody cares and just expect me to move and shape the data then get into next. ‚Äû if it works it works‚Äù so no time for technical debt or scabalility unless something fair miserably, then an asap fix is required.. I feel that I do more ‚Äûvaluable‚Äù things but I guess only mine imagination. In both positions I feel like third wheel. When would it end?",
          "score": 1,
          "created_utc": "2026-02-10 12:47:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r741h",
          "author": "Hear7y",
          "text": "I work in a pretty big company, and if we were a dime a dozen, they wouldn't call me and members of the team I'm part of to develop and lead everything, that has to do with that, if that were true. We have people in Asia, LATAM and so on.\n\nIf it weren't illegal, I'd probably be booked 400%.\n\nIt's the same with software engineers - there are many, most are however just not good, the difference is that DE actually requires a significant amount of non-technical knowledge, on top of a constantly shifting tech stack (why most people say DE is not entry-level).\n\nIt is absurdly difficult to find skilled and knowledgeable people whose hand you don't have to constantly hold, but they somehow demand massive payment.\n\nSo, no, I don't think we're a dime a dozen and AI use is actually making the inadequate people painfully obvious. Just because it is a force multiplier and 0 multiplied by anything is still 0. :D",
          "score": 1,
          "created_utc": "2026-02-11 06:09:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ixyal",
          "author": "LCuevad",
          "text": "switch to data platform ",
          "score": 1,
          "created_utc": "2026-02-09 23:57:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0rt35",
      "title": "Are people actually use AI in data ingestions? Looking for practical ideas",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r0rt35/are_people_actually_use_ai_in_data_ingestions/",
      "author": "[deleted]",
      "created_utc": "2026-02-10 05:03:57",
      "score": 57,
      "num_comments": 26,
      "upvote_ratio": 0.9,
      "text": "Hi All,  \n\n\nI have a degree in Data Science and am working as a Data Engineer (Azure Databricks)  \n\n\nI was wondering if there are any practical use cases for me to implement AI in my day to day tasks. My degree taught us mostly ML, since it was a few years ago. I am new to AI and was wondering how I should go about this? Happy to answer any questions that'll help you guys guide me better. \n\nThank you redditors :)",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0rt35/are_people_actually_use_ai_in_data_ingestions/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4kv87x",
          "author": "SharpRule4025",
          "text": "The biggest practical win right now is using LLMs to extract structured data from unstructured web sources. Scrape a product page, get back clean JSON with price, description, specs fields instead of maintaining brittle CSS selector pipelines that break every time the source site changes a div class.\n\nAlso useful for classifying and routing incoming data during ingestion - deciding which pipeline a document goes through based on content type rather than hardcoded rules.\n\nFor Databricks specifically, you could experiment with running smaller models to do schema inference on messy source data before it hits your bronze layer. Saves a lot of manual mapping work.",
          "score": 79,
          "created_utc": "2026-02-10 07:44:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l6x25",
              "author": "pceimpulsive",
              "text": "I would use the AI to generate the CSS selector pipeline.\n\nOnce you get an error reading you can re-run the CSS selector generator.\n\nThis way you don't burn tokens like crazy, and you get higher performance too!",
              "score": 31,
              "created_utc": "2026-02-10 09:38:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4lfyi5",
              "author": "Ultimate_Foreigner",
              "text": "For data ingestion with AI, getting back clean JSON from a web page can be tricky and easily break but using [Pydantic AI](https://ai.pydantic.dev/) would likely help here - basically data validation for LLM responses with auto retries etc.\n\nFor any use case other than web scraping, I don‚Äôt really think it is worth trying to wedge in any LLM steps here. Data integration is really a solved problem that would only be hindered by adding in superfluous AI tooling.",
              "score": 6,
              "created_utc": "2026-02-10 11:02:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4lpq9e",
              "author": "tadtoad",
              "text": "This is brilliant! I need to crawl a page where the html changes frequently enough to make traversing the page a nightmare because of the daily monitoring. I think this LLM JSON output would work for me. Thanks for sharing!",
              "score": 3,
              "created_utc": "2026-02-10 12:20:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kyet9",
          "author": "drag8800",
          "text": "honestly the biggest win for us has been using LLMs during validation. not type checking, but catching semantic weirdness that rules miss. like when a field is technically valid but contains \"N/A\" or \"TBD\" or \"pending\" and those all mean different things downstream. having an LLM tag those during ingestion saves so much debugging later.\n\nother thing that's been useful is throwing sample records at an LLM when you inherit a data source with garbage documentation. \"what do these fields probably mean and what types should they be\" gets you 80% there way faster than playing detective.\n\nfor actual pipeline dev i've been using claude code to scaffold ingestion jobs. not shipping the code directly but it's good at recognizing patterns for common sources like REST APIs or SFTP drops. still review everything but cuts initial dev time.\n\nwhat hasn't worked: trying to be clever with dynamic schema evolution. sometimes you want the pipeline to fail loudly when something breaks, not silently adapt and cause problems downstream.\n\nif you're on databricks, check out unity catalog's AI stuff for metadata enrichment. more governance side but still useful.",
          "score": 15,
          "created_utc": "2026-02-10 08:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lefc5",
          "author": "Which_Roof5176",
          "text": "Yep, people use ‚ÄúAI‚Äù in ingestion, but mostly around the pipeline, not inside it: schema mapping, data quality checks, log/alert summarization, and writing connector/ETL code faster.",
          "score": 4,
          "created_utc": "2026-02-10 10:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qjm4c",
              "author": "GAZ082",
              "text": "mmmh, how you would use it for data quality without sharing the actual data?",
              "score": 1,
              "created_utc": "2026-02-11 03:19:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lqe14",
          "author": "tadtoad",
          "text": "I use LLMs for classification/tagging. A stage in my pipeline requires classification of the ingested data into one of 100 categories. I send the category list and the content and get by the right category. It barely costs anything.",
          "score": 3,
          "created_utc": "2026-02-10 12:25:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r4ayg",
              "author": "Desperate_Pumpkin168",
              "text": "Could you please elaborate on how you have set up llm to do this",
              "score": 1,
              "created_utc": "2026-02-11 05:46:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tl98i",
                  "author": "tadtoad",
                  "text": "It‚Äôs pretty straightforward. I have a huge list of product names in my database that are not categorized. I pull each product name, add it to my prompt (along with a list of categories), then send it to OpenAI‚Äôs api. It then returns the right category from my list, which I then store in my database.",
                  "score": 2,
                  "created_utc": "2026-02-11 16:20:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4l72ii",
          "author": "pceimpulsive",
          "text": "Just hell naww to me.\n\nI want my data ingestions to be very fast and have as little dependencies as possible, I also don't want to them to change when openAI changes their guardrails or guts their model a little more to save costs ....",
          "score": 6,
          "created_utc": "2026-02-10 09:40:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lzgx5",
              "author": "Skullclownlol",
              "text": "> I want my data ingestions to be very fast and have as little dependencies as possible, I also don't want to them to change when openAI changes their guardrails or guts their model a little more to save costs ....\n\nExactly the same here. Ingestion = source copy, no transformations.",
              "score": 1,
              "created_utc": "2026-02-10 13:23:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4odhna",
                  "author": "pceimpulsive",
                  "text": "I do ELT,\n\nSmall transforms via uoserts.\n\nE.g. my source system stores timestamps as epoch and a few fields are ints that I want as enumerated strings. I achieve this via a view in a staging layer in the destination DB.\n\nOutside that though... It's copy copy",
                  "score": 1,
                  "created_utc": "2026-02-10 20:16:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4n1hn0",
          "author": "mckey86",
          "text": "I guess U can use automation",
          "score": 2,
          "created_utc": "2026-02-10 16:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l984h",
          "author": "DungKhuc",
          "text": "I'm using AI to ingest news that's relevant to the user profile from different news feeds. LLM is used to transform the news into signals (in JSON format) for UI to consume.",
          "score": 1,
          "created_utc": "2026-02-10 10:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lijg7",
          "author": "Nearby_Fix_8613",
          "text": "Heading our data science and ml dept\n\nIts a blessing and a curse for us",
          "score": 1,
          "created_utc": "2026-02-10 11:25:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lsw2m",
          "author": "reditandfirgetit",
          "text": "Data analysis. Using AI to find fast answers or confirm your theories. For example, a properly trained model could help catch fraud",
          "score": 1,
          "created_utc": "2026-02-10 12:42:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m96v8",
          "author": "ppsaoda",
          "text": "I'm working on medical datasets. And it's messy with clinical notes, so we have developed in-house LLM model to classify diagnosis. Other than that, not much except helping to write code based on my ideas.",
          "score": 1,
          "created_utc": "2026-02-10 14:17:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rtwi9",
              "author": "dillanthumous",
              "text": "How do you deal with data loss and hallucinations. Sounds extremely high risk.",
              "score": 1,
              "created_utc": "2026-02-11 09:40:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4satzc",
                  "author": "ppsaoda",
                  "text": "We have dedicated staffs to validate.",
                  "score": 1,
                  "created_utc": "2026-02-11 12:05:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mcjuk",
          "author": "share_insights",
          "text": "Great conversation. For those training models (even toy models) and looking for ways to make money off of their hard work, we'd love to chat. We believe (read: know) there is a market for the intelligence encapsulated in the code.",
          "score": 1,
          "created_utc": "2026-02-10 14:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kn3yl",
          "author": "Prestigious-Bath8022",
          "text": "Depends what you call AI.\n\n",
          "score": 1,
          "created_utc": "2026-02-10 06:31:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ldkj9",
          "author": "Reach_Reclaimer",
          "text": "Unless it's for actually scraping data, there's no reason to use it over a traditional source as far as I'm aware. Would be more expensive for little gain and no ability to troubleshoot",
          "score": 1,
          "created_utc": "2026-02-10 10:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ki7ze",
          "author": "Thinker_Assignment",
          "text": "I'm co-founder of an oss ingestion library so I can give you some community observations \n\nFirst, everyone uses LLMs for coding at this time, some do it completely by chat interface. We support them with tools to do so with less bad consequences, and faster.\n\nSecond, there's a small group of people that does a lot of ingestion from unstructured sources like multimodal and social media, or in document heavy industries. Those folks do an order of magnitude more ingestion than the rest of the community combined - so the LLM data processing use cases far outweigh normal data engineering in data engineering work at this time.\n\nOn the other hand we're moving towards complete agentic coding, Wes recently said python is going to no longer be coded by humans but agents. So maybe learn in that direction. Check out skills, they are the latest thing that works well.",
          "score": -7,
          "created_utc": "2026-02-10 05:50:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r12ckn",
      "title": "How do you justify confluent cloud costs to leadership when the bill keeps climbing?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r12ckn/how_do_you_justify_confluent_cloud_costs_to/",
      "author": "Funny-Affect-8718",
      "created_utc": "2026-02-10 14:34:12",
      "score": 49,
      "num_comments": 68,
      "upvote_ratio": 0.88,
      "text": "Our confluent bill just hit $18k this month and my manager is freaking out. We're processing around 2 million events daily, but between cluster costs, connector fees, and moving data around we're burning through money.\n\n\n\nI tried explaining that kafka needs this setup, showed him what competitors charge, but he keeps asking why we can't use something cheaper, and honestly starting to wonder the same thing. We're paying top dollar and I still spend half my time fixing cluster issues.\n\n\n\nHow do you prove it's worth it when your boss sees the bill and goes pale, we're a series b startup so every dollar counts, what are teams using these days that won't drain your budget but also won't wake you up with alerts?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r12ckn/how_do_you_justify_confluent_cloud_costs_to/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4mqup0",
          "author": "DungKhuc",
          "text": "Without knowing your requirements, that sounds like a very small amount of data to move for 18k / month",
          "score": 88,
          "created_utc": "2026-02-10 15:46:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oem9n",
              "author": "TA_poly_sci",
              "text": "<30 events per second, <60 if we say most are concentrated during the day. Not nothing, but sure as hell not something that requires spending 18k a month.",
              "score": 19,
              "created_utc": "2026-02-10 20:22:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ofl0j",
              "author": "shoppedpixels",
              "text": "It is likely the connectors, I do t believe you can sleep them for lower environments or cost savings. Maybe over those to a self managed connect cluster or just a container environment?",
              "score": 4,
              "created_utc": "2026-02-10 20:26:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mxg9w",
          "author": "Skullclownlol",
          "text": "> How do you prove it's worth it when your boss sees the bill and goes pale, we're a series b startup so every dollar counts, what are teams using these days that won't drain your budget but also won't wake you up with alerts?\n\nEverything non-realtime/non-streaming. Literally almost everything else will be cheaper.",
          "score": 32,
          "created_utc": "2026-02-10 16:17:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mykmx",
          "author": "Prinzka",
          "text": "In fact I do the opposite.  \nI use what would be high cloud cost to justify keeping our Kafka on-prem.  \nWe stream trillions of events per day for basically the same cost as your confluent cloud setup by just running Kafka on-prem.",
          "score": 31,
          "created_utc": "2026-02-10 16:22:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ol59v",
              "author": "yesoknowhymayb",
              "text": "Just curious, are you including extra labour cost? If there is any.",
              "score": 5,
              "created_utc": "2026-02-10 20:52:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4oqrql",
                  "author": "Prinzka",
                  "text": "In my internal calculations yes, labour and on prem compute cost. \nI meant our licensing is the same cost as OP's confluent cloud cost.  \nIncluding all costs and comparing to confluent cloud for our volume it was more than an order of magnitude more expensive to stay on-prem.   \n\nAlso keep in mind that to run 24/7 without outages you still need at least 2 people (realistically 3) to maintain things even if you're using confluent cloud.  \nWe're expected to provide real time security feeds without downtime, so we can't just switch off after hours.",
                  "score": 5,
                  "created_utc": "2026-02-10 21:18:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4nhcqa",
          "author": "vish4life",
          "text": "2 million events for $18k on Kafka? We process 1 billion+ events on AWS MSK Kafka < 15k. A single Kafka node on basic cloud machines can easily handle 100-500 mil events per day. You are struggling to handle 2 mil events. \n\nSomething has gone terribly wrong with your setup.",
          "score": 32,
          "created_utc": "2026-02-10 17:49:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mpqgv",
          "author": "sazed33",
          "text": "Your manager is right, you don't need Kafka",
          "score": 39,
          "created_utc": "2026-02-10 15:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nmvti",
          "author": "sleeper_must_awaken",
          "text": "Talk to Confluent sales rep: either consult to bring the cost down by 50% or we‚Äôre out.\n\nBut 2M events per day is literally only 23 events per second. That‚Äôs nothing. An old Raspberry Pi could process at least 2000 events per second with two fingers in its nose. You‚Äôre being screwed, either by Confluent or by incompetence in configuration, probably both.",
          "score": 17,
          "created_utc": "2026-02-10 18:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mr22r",
          "author": "tedward27",
          "text": "You should be embarrassed at spending so much for so little¬†",
          "score": 48,
          "created_utc": "2026-02-10 15:47:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mzd0s",
          "author": "ReporterNervous6822",
          "text": "2 million daily and using Kafka üò≠üò≠",
          "score": 14,
          "created_utc": "2026-02-10 16:26:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n36oc",
              "author": "Sex4Vespene",
              "text": "I mean if they need streaming, it‚Äôs a decent enough reason to go with Kafka is it not? Although I have to wonder if they really need streaming",
              "score": 6,
              "created_utc": "2026-02-10 16:43:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mot9n",
          "author": "No_Lifeguard_64",
          "text": "If you can't afford streaming data then don't do streaming. That's just the reality of it. Whats the business difference between streaming and microbatch? If you aren't actually actioning on that real-time data then just move to airflow or something.",
          "score": 41,
          "created_utc": "2026-02-10 15:37:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mjaol",
          "author": "TheOverzealousEngie",
          "text": "why do you need streaming? Why not data replication?",
          "score": 22,
          "created_utc": "2026-02-10 15:10:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ngr6f",
          "author": "dfwtjms",
          "text": "That's cloud. In reality a smartwatch and sqlite could handle that workload.  \n  \nThe truth is that nothing justifies those bills. Don't fall for the sunk cost fallacy and build something better.",
          "score": 10,
          "created_utc": "2026-02-10 17:46:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mv223",
          "author": "wqrahd",
          "text": "If you are on aws, why not kinesis?",
          "score": 7,
          "created_utc": "2026-02-10 16:06:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n39mj",
          "author": "Truth-and-Power",
          "text": "What about microbatch instead of streaming?",
          "score": 3,
          "created_utc": "2026-02-10 16:44:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pmq6n",
          "author": "DarthCalumnious",
          "text": "Get a VM with fast nvme and just throw your junk into clickhouse.",
          "score": 3,
          "created_utc": "2026-02-11 00:03:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mrh6o",
          "author": "Training_Refuse7745",
          "text": "You can try serverless approach if cluster keeps on going down. That is more reliable. I have 1.5yoe but recently in my current project we replaced things with serverless and it is not failing and also the costs are low. We have batch ingestion so I am not 100% sure about streaming.",
          "score": 2,
          "created_utc": "2026-02-10 15:49:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qll3n",
              "author": "kingglocks",
              "text": "Lambda + step functions?",
              "score": 1,
              "created_utc": "2026-02-11 03:31:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4myi9v",
          "author": "ThroughTheWire",
          "text": "Would need to know/understand why you need Kafka in the first place to give you a real answer tbh",
          "score": 2,
          "created_utc": "2026-02-10 16:22:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p5ugs",
          "author": "zikawtf",
          "text": "OP could you bring us more context, I am really curious about the stack and business context to justify using Kafka (not just as tool, but as a business requirement)",
          "score": 2,
          "created_utc": "2026-02-10 22:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4morxd",
          "author": "Nekobul",
          "text": "That's ridiculous. You can process that amount of data easily on a single machine using SSIS and it will be dirt cheap.",
          "score": 7,
          "created_utc": "2026-02-10 15:36:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nh8sa",
              "author": "dfwtjms",
              "text": "Or even better, open source stack without Microslop.",
              "score": 7,
              "created_utc": "2026-02-10 17:48:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pxemt",
                  "author": "wubalubadubdub55",
                  "text": "What‚Äôs up with Microsoft hate for everything? \n\nLike what have the engineers who develop SSIS done to you that‚Äôs so bad that you have to ridicule it? \n\nMan you people are pathetic and full of hate.",
                  "score": -1,
                  "created_utc": "2026-02-11 01:04:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4nrqru",
                  "author": "Nekobul",
                  "text": "How is that better if you have to pay consultants top dollars to create and maintain that solution?",
                  "score": -3,
                  "created_utc": "2026-02-10 18:36:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4negya",
              "author": "IndependentTrouble62",
              "text": "Truth...",
              "score": 1,
              "created_utc": "2026-02-10 17:35:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nnb1u",
          "author": "Flacracker_173",
          "text": "You need to self host a Kafka connect cluster and probably lower your data retention period and topic replicas.",
          "score": 1,
          "created_utc": "2026-02-10 18:16:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nncn0",
          "author": "baby-wall-e",
          "text": "2 millions per day is to tiny. You should consider refactoring your system, moving away from confluent.",
          "score": 1,
          "created_utc": "2026-02-10 18:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nt44o",
          "author": "Sad_Monk_",
          "text": "for 2 million events what is stopping you from micro batching?",
          "score": 1,
          "created_utc": "2026-02-10 18:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nvfjm",
          "author": "Brave_Affect_298",
          "text": "We will soon have to choose between Google Pub/Sub and Confluent Kafka. Is Pub/Sub cheaper?",
          "score": 1,
          "created_utc": "2026-02-10 18:53:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ocfl9",
          "author": "dan_the_lion",
          "text": "Why do you feel like you need to justify the bill instead of exploring alternatives which might be better fit for your use case? \n\nWhat are you using Kafka for exactly? Is it just data replication from databases to warehouses or is it actually a queue/streaming backbone of your application? \n\nIf it‚Äôs just to enable analytics there are many options you can consider. Do you need log-based CDC?",
          "score": 1,
          "created_utc": "2026-02-10 20:12:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p45u0",
          "author": "Hackerjurassicpark",
          "text": "You don‚Äôt. We‚Äôre moving to pub sub",
          "score": 1,
          "created_utc": "2026-02-10 22:22:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pwavn",
          "author": "wubalubadubdub55",
          "text": "You‚Äôre wasting so much money for so little. \n\nA .NET worker service + Postgres db can do that in a small VM without breaking a sweat for a tiny fraction of that cost.",
          "score": 1,
          "created_utc": "2026-02-11 00:58:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q6iol",
          "author": "thisfunnieguy",
          "text": ">kafka needs this setup\n\nThere are things like MSK via AWS\n\n  \nim not saying thats right for you, but there are a number of other options.",
          "score": 1,
          "created_utc": "2026-02-11 01:59:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qpr8j",
          "author": "codykonior",
          "text": "Replace it with a bash script on a VM.\n\nPro: $18k cheaper\n\nCon: Does not look fancy on the resume and HA DR are extra work.\n\n/s but ... üòÄ",
          "score": 1,
          "created_utc": "2026-02-11 03:59:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r817v",
          "author": "Front-Ambition1110",
          "text": "I think you are overprovisioning. 2 million events is not that huge.¬†",
          "score": 1,
          "created_utc": "2026-02-11 06:17:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rs3km",
          "author": "calimovetips",
          "text": "at 2m events a day that bill sounds more like overprovisioning or connector sprawl than pure volume, i‚Äôd break down cost per million events and map it to actual business use cases so leadership sees value per stream, not just a lump sum.\n\nhave you modeled what self managed or a lighter managed kafka setup would cost once you factor in ops time and on call?",
          "score": 1,
          "created_utc": "2026-02-11 09:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sbdnm",
          "author": "observability_geek",
          "text": "You don't because you can run enterprise kafka without confluent.. I really don't understand why orgs pay for kafka if they can use Strimzi. [https://github.com/strimzi/strimzi-kafka-operator](https://github.com/strimzi/strimzi-kafka-operator) if you are in the EU you can use [axual.com](http://axual.com) for the governance.",
          "score": 1,
          "created_utc": "2026-02-11 12:09:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sdjz9",
          "author": "Los_Cairos",
          "text": "As others in this thread have said, your costs are crazy given the volume.\n\nI work at a data streaming company (not Confluent) and we have customers doing 25x your daily events for 1-1.5x the cost.\n\nSo either something is really off in your setup (e.g. something about your connector setup, or you've got some super high custom data retention duration), or you're paying wayyyy too much and you need to talk to your rep.\n\nEdit: better cost estimate",
          "score": 1,
          "created_utc": "2026-02-11 12:25:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sixbi",
          "author": "trentsiggy",
          "text": "Are you processing them realtime?  If so, do you *have* to process them realtime?",
          "score": 1,
          "created_utc": "2026-02-11 13:00:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1yl3v",
      "title": "Hired as a data engineer in a startup but being used only for building analytics dashboards, how do i pivot",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r1yl3v/hired_as_a_data_engineer_in_a_startup_but_being/",
      "author": "aks-786",
      "created_utc": "2026-02-11 14:18:44",
      "score": 48,
      "num_comments": 27,
      "upvote_ratio": 0.9,
      "text": "Am a solo Data Engineer at a startup. I was hired to build infrastructure and pipelines, but leadership doesn't value anything they can't \"see.\"\n\nI spend 100% of my time churning out ad-hoc dashboards that get used once and forgotten. Meanwhile, the AI team is getting all the praise and attention, even though my work supports them. Also, i think they can now build rdbms in such a way that DE work would not be required in sometime\n\nRight now, I feel like a glorified Excel support desk. How do I convince leadership to let me actually do Engineering work, or is this a lost cause and look for switch?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r1yl3v/hired_as_a_data_engineer_in_a_startup_but_being/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4symz4",
          "author": "codykonior",
          "text": "> Also, i think they can now build rdbms in such a way that DE work would not be required in sometime. \n\nUhhh. Yeah. Sure. Any day now for the past 3 decades.",
          "score": 52,
          "created_utc": "2026-02-11 14:29:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t9ipo",
              "author": "aks-786",
              "text": "But what if data size is low ü•≤. Do they need columnar database for this?",
              "score": -7,
              "created_utc": "2026-02-11 15:25:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4u97sy",
                  "author": "Subject_Fix2471",
                  "text": "data size and data complexity are separate, can have a \"low\" amount of data that's complex enough to greatly benefit from a relational db. ",
                  "score": 16,
                  "created_utc": "2026-02-11 18:12:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4x2k24",
                  "author": "IndependentTrouble62",
                  "text": "A well modeled database is like a tailored tux. Its never out of style.",
                  "score": 4,
                  "created_utc": "2026-02-12 03:04:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4xxmaj",
                  "author": "sib_n",
                  "text": "The explanation is that this AI team is doing the data engineering for their need, not that there is no DE. It's possible that they would be thankful for someone to do it for them, maybe you can try asking them. If this doesn't work and you can't find DE work, go somewhere else. But don't neglect the fact that building analytics dashboard is great experience for a DE. It is usually the main downstream usage of a DE's work and it is common to ask DEs to do dashboarding, especially in small structures.",
                  "score": 1,
                  "created_utc": "2026-02-12 06:59:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4sxzha",
          "author": "Key_Post9255",
          "text": "Look somewhere else",
          "score": 68,
          "created_utc": "2026-02-11 14:26:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tkpu0",
              "author": "mrbartuss",
              "text": "Easier said than done in the current job market",
              "score": 26,
              "created_utc": "2026-02-11 16:17:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4w7lov",
                  "author": "Key_Post9255",
                  "text": "He's tagged as the plumber. \n\nUnluckily for him there is no one above him to give him value or \"defend\" him in front of the leadership.\n\nHe would have to find someone to sponsor him or put him in a different situation, but it seems no one is going to do that. It doesn't matter how beautiful the data will be, what tools he uses, whatever else..he is just the nerd in the back doing the PC stuff. No one understands what he's doing. Other people get the merit. Get out if you can because you'll get nothing from this company üòÄ",
                  "score": 7,
                  "created_utc": "2026-02-11 23:59:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ucr3l",
                  "author": "M4A1SD__",
                  "text": "Looking is easy",
                  "score": 3,
                  "created_utc": "2026-02-11 18:28:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tlske",
          "author": "ianitic",
          "text": "Doing more of the infrastructure and pipelines would likely make the praise and attention situation worse. That was how it was when I was at a small company.\n\nReport builder got the largest raises due to visibility. I built the pipelines, infrastructure, and ml models. I could build reports too but just didn't have the time. The discrepancy got so bad that by the time I left the report builder had double my salary.\n\nThe only way to fix it is to leave.",
          "score": 31,
          "created_utc": "2026-02-11 16:22:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tuano",
              "author": "aks-786",
              "text": "Okay I see. Thanks for the feedback",
              "score": 4,
              "created_utc": "2026-02-11 17:02:37",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4wsnbn",
              "author": "OkMaize9773",
              "text": "Stop giving quality data to the report builder and enjoy the show",
              "score": 3,
              "created_utc": "2026-02-12 02:05:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4x00ou",
                  "author": "ianitic",
                  "text": "I'm not there anymore, left for greener pastures lol",
                  "score": 1,
                  "created_utc": "2026-02-12 02:48:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4to7na",
          "author": "Yuki100Percent",
          "text": "I'm also a solo data person at a startup. First off, if you're at a decent company/team, when your work is related to somebody's that got attention, they would or should mention your work too. What you just said kinda indicates a not-so-good-culture.   \n  \nAnyway, I don't know how much tasks or tickets you get a day/week, you should start asking project priorities or start building one yourself and propose it to the exec team. And how they impact the business for the better. This also helps you become more visible if you've been just working with other folks in the company, but not with exec team. Not sure who you report to, but asking these kinds of questions to your direct report also helps. If not, I might start looking for a new place to work for.   \n  \nAlso, realistically what you can do is to start building infra and pipelines along with what you're doing. You satisfy the current needs and start working on things you think are important or necessary to do what they ask you to do (reporting, dashboarding). \n\nOverall, I'd try to communicate a lot more and see what they say. And depending on that, you either start looking for a new job or decide to do things differently going forward. \n\nDM me if you have any other questions! ",
          "score": 11,
          "created_utc": "2026-02-11 16:34:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vosuz",
              "author": "blue_leader27",
              "text": "hey I‚Äôm also in your position can I dm you",
              "score": 2,
              "created_utc": "2026-02-11 22:18:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4w3m7n",
                  "author": "Yuki100Percent",
                  "text": "Yup feel free",
                  "score": 1,
                  "created_utc": "2026-02-11 23:36:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4tui8g",
              "author": "aks-786",
              "text": "Thanks for the feedback. I will reach out to you in DM once I think about this",
              "score": 1,
              "created_utc": "2026-02-11 17:03:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ue5s9",
          "author": "randomuser1231234",
          "text": "If you‚Äôre writing dashboards that aren‚Äôt being used, that means you‚Äôre working on someone‚Äôs ‚Äúoh I‚Äôm curious‚Äù questions and not addressing the actual business needs.\n\nLearn how your company works, how it actually makes money, what the market differentiators are. Get cozy with the engineering managers and the finance manager and learn what they give a shit about. Make data artifacts and dashboards that answer THOSE questions.",
          "score": 9,
          "created_utc": "2026-02-11 18:35:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uz1fb",
          "author": "cky_stew",
          "text": "When you say the AI team is piggybacking on your work, that would sound like you‚Äôre doing some data engineering in order to feed their models/LLMs, but if that‚Äôs not the case- then how does that situation look?\n\nHow do these ad-hoc dashboards look? Are you just writing one off queries on raw data to populate them? In my experience ad hoc reports are a symptom of a lack of good models (and pipelines that build those models) going into your BI tools. If that‚Äôs the case it‚Äôs a pretty easy sell to your line manager that building a proper pipeline would mean dashboards get built faster and have way more reusability.\n\nIf you‚Äôre the solo data engineer, then you‚Äôre the sole authority and the only one who can explain why it is a problem. Have you raised this with them? If you‚Äôre just complying with the requests of things they think they want to see, then they‚Äôre gunna be stuck in a loop of forcing through ad hoc things - because it‚Äôs all they know.\n\nYou mention being an excel support desk too - this definitely shouldn‚Äôt be happening - spreadsheets can be avoided in almost all cases these days (with some exceptions). I LOVE it when someone requests a spreadsheet because it‚Äôs an opportunity for me to ask them ‚Äúout of curiosity‚Äù what are they doing with the spreadsheet - then you almost always get given an opportunity to solve a problem that they didn‚Äôt even know existed, this can make people very happy and that‚Äôs the most satisfying part of this job, I find.\n\nMaybe I‚Äôve got the completely wrong take here but it sounds like the company hasn‚Äôt been exposed to a modern data stack before and are doing things the old way, if you‚Äôve already shown them how it could be better (time optimisation, data reliability, and undiscovered insights being the selling points that execs hear) - then fair enough leave - if you haven‚Äôt you‚Äôre sitting on a golden opportunity, cause it sounds like you‚Äôre the only authority. Best wishes going forward - but this sounds like you‚Äôre not doing data engineering at all and would be a red flag to me if I were to interview you for an engineering role and you spoke about this sort of setup.",
          "score": 3,
          "created_utc": "2026-02-11 20:13:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4up0n4",
          "author": "sciencewarrior",
          "text": "One possible opportunity is tooling. See where the AI team is spending time with manual tasks and propose ways to simplify their workflow.",
          "score": 2,
          "created_utc": "2026-02-11 19:25:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w1f65",
          "author": "SaintTimothy",
          "text": "My job since forever has been to try and automate myself out of a job. I keep creating automation, pr enhancing old ones, and they keep bringing up more and more stuff that needs it.\n\n\nYou making the donuts every day manually is the opposite of automation. Taking what, of that, can be automated is your job. Either they recognize you did a good job, or you still do a good job and only work one hour a day and surf reddit the other 7. OR you keep manually making the donuts every day because that's fun.",
          "score": 2,
          "created_utc": "2026-02-11 23:24:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4u3x8p",
          "author": "Firm_Communication99",
          "text": "Do data science stuff‚Äî r2 , basic stats",
          "score": 1,
          "created_utc": "2026-02-11 17:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vsm0s",
          "author": "Eleventhousand",
          "text": "Talk to your boss in the one in one and ask to be given more DE work .\n\n\nBe nice about it though, don't go in there trashing other data related work like you did in here.",
          "score": 1,
          "created_utc": "2026-02-11 22:37:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vxfsc",
          "author": "HeyNiceOneGuy",
          "text": "How are ad-hoc dashboards that only get used once supporting your AI team?",
          "score": 1,
          "created_utc": "2026-02-11 23:02:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4won63",
          "author": "rdmcoloring",
          "text": "Transition to AI engineer, just do whatever you were doing and just add a chatgpt API call in between",
          "score": 1,
          "created_utc": "2026-02-12 01:40:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xdtj7",
          "author": "MindlessTime",
          "text": "Find a way to be necessary. By necessary I mean without your knowledge something important would fail in a costly way. Maybe you simplify data pulls for the accounting team and without you they can‚Äôt create financial statements. Maybe you create and maintain the data that goes into the CRM, without which all the marketing campaigns would fail. Even if leadership doesn‚Äôt ‚Äúsee‚Äù the work, someone will say ‚ÄúI‚Äôm screwed without this person‚Äù and you‚Äôll be fine.",
          "score": 1,
          "created_utc": "2026-02-12 04:18:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v3iia",
          "author": "Accomplished-Row7524",
          "text": "SELECT ...\nFROM ...\n   PIVOT ( <aggregate_function> ( <pivot_column> ) [ [ AS ] <alias> ]\n            FOR <value_column> IN (\n              <pivot_value_1> [ [ AS ] <alias> ] [ , <pivot_value_2> [ [ AS ] <alias> ] ... ]\n              | ANY [ ORDER BY ... ]\n              | <subquery>\n            )\n            [ DEFAULT ON NULL (<value>) ]\n         )\n\n[ ... ]",
          "score": 0,
          "created_utc": "2026-02-11 20:35:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0wwrn",
      "title": "Our company successfully built an on-prem \"Lakehouse\" with Spark on K8s, Hive, Minio. What are Day 2 data engineering challenges that we will inevitably face?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r0wwrn/our_company_successfully_built_an_onprem/",
      "author": "seaborn_as_sns",
      "created_utc": "2026-02-10 10:08:31",
      "score": 43,
      "num_comments": 47,
      "upvote_ratio": 0.91,
      "text": "I'm thinking \n\n\\- schema evolution for iceberg/delta lake  \n\\- small file performance issues, compaction\n\nWhat else? \n\nAny resources and best practices for on-prem Lakehouse management?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0wwrn/our_company_successfully_built_an_onprem/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4la04a",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-10 10:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lccan",
          "author": "liprais",
          "text": "minio will be your biggest pain of ass",
          "score": 52,
          "created_utc": "2026-02-10 10:30:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lde2s",
              "author": "jupacaluba",
              "text": "I second that. Just reading gave me the itch",
              "score": 5,
              "created_utc": "2026-02-10 10:39:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ldpak",
              "author": "seaborn_as_sns",
              "text": "is it because they abandoned foss? what else is there for on-prem? ceph?",
              "score": 5,
              "created_utc": "2026-02-10 10:42:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lkli5",
                  "author": "rmoff",
                  "text": "garage, seaweedfs, apache ozone, and several others. depends what you need. I wrote about it here (although from a PoC/demo perspective, not production usage): https://rmoff.net/2026/01/14/alternatives-to-minio-for-single-node-local-s3/",
                  "score": 5,
                  "created_utc": "2026-02-10 11:42:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ljukg",
                  "author": "liprais",
                  "text": "i am running hdfs ,works smooth",
                  "score": 2,
                  "created_utc": "2026-02-10 11:36:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4nln7l",
                  "author": "Colafusion",
                  "text": "It‚Äôs also AGPL, which depending on what you‚Äôre doing can be a massive issue.",
                  "score": 1,
                  "created_utc": "2026-02-10 18:08:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4m127x",
              "author": "543254447",
              "text": "Can't agree with you more. Literally cannot delete some files for no reason.......\n\nAlways run into weird error with spark due to it.....",
              "score": 2,
              "created_utc": "2026-02-10 13:32:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4met9m",
                  "author": "seaborn_as_sns",
                  "text": "how big is your dataeng/dataops team?",
                  "score": 1,
                  "created_utc": "2026-02-10 14:47:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4p6daw",
              "author": "zikawtf",
              "text": "What justify the MinIO as a storage tool in production environment? I mean, store data is cheap, so why not S3?",
              "score": 1,
              "created_utc": "2026-02-10 22:33:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4sx6sn",
                  "author": "seaborn_as_sns",
                  "text": "airgapped environment, data residency regulations, etc",
                  "score": 1,
                  "created_utc": "2026-02-11 14:22:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4t1sjq",
              "author": "ludflu",
              "text": "wait, people use minio in production?!",
              "score": 1,
              "created_utc": "2026-02-11 14:46:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lh0gn",
          "author": "Gold_Ad_2201",
          "text": "it sounds like you buit now a 20 year old architecture.\n1. is spark the only access to data? what about lower latency? trino, duckdb?\n2. hive partitioning will only delay your problems. you def need to look into table formats (iceberg, delta). and more importantly - they are also designed badly. you need to look into having catalog with them to have the good speed\n3. I assume minio and k8s are because you have some requirement to have air gapped env? if not, do consider S3/blob to save your maintenance team",
          "score": 17,
          "created_utc": "2026-02-10 11:12:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mf2uk",
              "author": "seaborn_as_sns",
              "text": "1. experimenting on trino too  \n2. we have iceberg and delta too, unified hive catalog. should we adopt polaris or something else do you think?  \n3. yes we need airgapped. i think ceph is better option but no experience to advocate for it.  ",
              "score": 4,
              "created_utc": "2026-02-10 14:48:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4mwg0o",
              "author": "Doto_bird",
              "text": "Do you have any experience with MotherDuck (from DuckDB)? They critized iceberg and delta quite harshly in their announcement video and they addressed those issues (in their opinion), but I've never talked with anyone who's actually used it for big data workloads yet.",
              "score": 2,
              "created_utc": "2026-02-10 16:12:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mxgfv",
                  "author": "Gold_Ad_2201",
                  "text": "didn't use it in production, no. their comments are fair. but let's see if this tech becomes adopted and supported. their idea of DuckLake sounds pretty logical but other than MotherDuck I didn't hear of any commercial implementation.\nbut duckDB itself is awesome engine!",
                  "score": 2,
                  "created_utc": "2026-02-10 16:17:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4le43p",
          "author": "dragonnfr",
          "text": "Run aggressive compaction (bin-packing, 128MB targets). For schema evolution, only add fields. Check Delta docs for OPTIMIZE + ZORDER BY on small files.",
          "score": 6,
          "created_utc": "2026-02-10 10:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4leirv",
              "author": "seaborn_as_sns",
              "text": "any tool to monitor general health of delta tables or do teams build inhouse monitoring scripts?",
              "score": 1,
              "created_utc": "2026-02-10 10:50:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ltl6j",
          "author": "Hackerjurassicpark",
          "text": "Upgrading your K8S, Hive and Minio when your current versions go EOL",
          "score": 6,
          "created_utc": "2026-02-10 12:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfa2j",
              "author": "seaborn_as_sns",
              "text": "you think thats near-term (2yrs) or bit later? ",
              "score": 2,
              "created_utc": "2026-02-10 14:49:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4p5ima",
                  "author": "Hackerjurassicpark",
                  "text": "Depends on the version you‚Äôre using. Go check the EOL dates for the exact version you‚Äôre using",
                  "score": 1,
                  "created_utc": "2026-02-10 22:28:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ldmck",
          "author": "FunAd6672",
          "text": "Data quality checks become your real Day 2 job not pipelines.",
          "score": 3,
          "created_utc": "2026-02-10 10:41:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4le9qw",
              "author": "seaborn_as_sns",
              "text": "how do you manage them? via dbt or inhouse tools via great expectations or something? ",
              "score": 2,
              "created_utc": "2026-02-10 10:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lsdb6",
          "author": "Eitamr",
          "text": "Minio is for testing, avoid on prod if you can",
          "score": 3,
          "created_utc": "2026-02-10 12:38:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfh1k",
              "author": "seaborn_as_sns",
              "text": "even enterprise minio? the \"aistor: Exabyte-Scale Storage Engineered for the AI Era\"",
              "score": 1,
              "created_utc": "2026-02-10 14:50:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ltxgx",
          "author": "6nop_",
          "text": "Q: How are you supporting multiple writers using Delta Lake ? See [DeltaLake S3 Docs](https://docs.delta.io/delta-storage/#amazon-s3)\n\nWe have been running an on prem data warehouse for over 1.5 years. Our setup looks like.\n\n* [S3 Compatible Objectstore](https://vastdata.com/)\n* K8S compute.\n* Iceberg and Kafka Connect\n* Hive Metastore (don't use 4.0.1 ) see [issue](https://github.com/apache/iceberg-python/issues/1222)\n* Trino - Runs great!\n* Kafka - Strimzi - Also Great!\n* OPA for permissions\n* Okta for Auth\n\nOur biggest issue is doing table maintenance, removing snapshots without getting corrupted tables. [see issue](https://github.com/trinodb/trino/issues/19638)\n\nOur S3 Compatible objectstore has been a problem lately. When it gets stressed, it introduces latency and not all S3 clients deal with that properly, ie default 3 sec request timeouts.",
          "score": 3,
          "created_utc": "2026-02-10 12:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfyxl",
              "author": "seaborn_as_sns",
              "text": "thanks so much! what was the decision-making process that you guys arrived to that stack? followed some tried-and-tested blueprint from some similar company's experience or arrived purely based on internal discussions and evaluations?",
              "score": 1,
              "created_utc": "2026-02-10 14:53:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mtd7n",
          "author": "ShanghaiBebop",
          "text": "Governance and access management will be a PITA.¬†",
          "score": 3,
          "created_utc": "2026-02-10 15:58:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4syj5q",
              "author": "seaborn_as_sns",
              "text": "any limitations to apache ranger?",
              "score": 1,
              "created_utc": "2026-02-11 14:29:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4n92oq",
          "author": "SuperTangelo1898",
          "text": "Ghost objects that exist in the backend but don't exist in Minio's front end UI object manager",
          "score": 2,
          "created_utc": "2026-02-10 17:11:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nbpub",
          "author": "swapripper",
          "text": "Tenancy/Cost attribution \nGovernance/PII masking / RLS\nLogs/Lineage/Observability/Performance monitoring\nSemantic layer possibly\nCDC if you need it\nEasy abstractions for backfills/backups/compaction/cleanup",
          "score": 2,
          "created_utc": "2026-02-10 17:23:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nw2e9",
          "author": "efxhoy",
          "text": "Just curious, how much data do you have? 1TB? 100TB?¬†",
          "score": 2,
          "created_utc": "2026-02-10 18:56:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sxtzp",
              "author": "seaborn_as_sns",
              "text": "around 10TB in now legacy data warehouse in total",
              "score": 1,
              "created_utc": "2026-02-11 14:25:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pn6dc",
          "author": "Due_Carrot_3544",
          "text": "Whats your total data volume stored right now?",
          "score": 2,
          "created_utc": "2026-02-11 00:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sxv14",
              "author": "seaborn_as_sns",
              "text": "around 10TB in now legacy data warehouse in total",
              "score": 1,
              "created_utc": "2026-02-11 14:25:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lg82w",
          "author": "reallyserious",
          "text": "How can one handle access control like row level security and table level security?",
          "score": 1,
          "created_utc": "2026-02-10 11:05:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfc28",
              "author": "seaborn_as_sns",
              "text": "experimenting with ranger now",
              "score": 3,
              "created_utc": "2026-02-10 14:49:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4psyls",
          "author": "Rich-Ad5460",
          "text": "May I ask how long does it take to build this? And with how many people?",
          "score": 1,
          "created_utc": "2026-02-11 00:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sy3ft",
              "author": "seaborn_as_sns",
              "text": "total 10\\~ people built this as poc, ops + engineering",
              "score": 1,
              "created_utc": "2026-02-11 14:26:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4n14a3",
          "author": "ChinoGitano",
          "text": "Why use Hive when Unity Catalog is now open-source?  Governance and performance may be your biggest headache ‚Ä¶ assuming you actually have the component integration licked. üòÖ",
          "score": 1,
          "created_utc": "2026-02-10 16:34:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzb76a",
      "title": "Tech stack in my area has changed?How do I cope",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qzb76a/tech_stack_in_my_area_has_changedhow_do_i_cope/",
      "author": "Sufficient_Example30",
      "created_utc": "2026-02-08 15:05:00",
      "score": 42,
      "num_comments": 16,
      "upvote_ratio": 0.86,
      "text": "So basically my workplace of 6 years has become very toxic so I wanted to switch.\nOver there i mainly did spark (dataproc),pub sub consumers to postgres,BQ and Hive tables ,Scala and a bit of pyspark and SQL\nBut I see that the job market has shifted.\nNowadays \nThey are asking me for knowledge of\nKubernetes\nDocker\nAnd alot of questions regarding networking along with Airflow \nHonestly I don't know any of these.\nHow do I learn them in a quick manner.\nLike realistically how much time do I need for airflow,docker and kubernetes ",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qzb76a/tech_stack_in_my_area_has_changedhow_do_i_cope/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o49jswk",
          "author": "Darkendfearz",
          "text": "Honestly you can learn the basics of kubernetes and enough information to pass most interviews in a day. I also have used airflow a ton and would consider myself pretty comfortable with the tool but I have never been asked an interview question about it. Docker is also super simple to learn. Just take a step back, breath, and reading about it before freaking out. What kind of networking questions are you getting?",
          "score": 45,
          "created_utc": "2026-02-08 15:28:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49l6nb",
              "author": "Sufficient_Example30",
              "text": "Very wierd ones.\nHow do you setup Ray clusters.\nWhat are the firewalls rules you would need to enable\nIf the company services are behind a NAT gateway how do you ensure that you can hit them.\nIt's very wierd nowadays \nWhy use spark serverless over a spark cluster\nHow does networking work there .\nHow do you ensure IP resource management so they don't exhaust more IPs than needed.\nI expected these to be either platform engineer interview questions but I have never done any of this.\nI would just build the image,use the subnetwork provided to me and would usually be done",
              "score": 9,
              "created_utc": "2026-02-08 15:35:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4cxu6p",
                  "author": "West_Good_5961",
                  "text": "These aren‚Äôt DE questions. That‚Äôs cloud engineer territory. They‚Äôre probably looking for a unicorn who can do 3 jobs at once and still not pay them enough.",
                  "score": 11,
                  "created_utc": "2026-02-09 01:54:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4cnju7",
                  "author": "sib_n",
                  "text": "Yeah, they need a platform/devops/cloud/network engineer to set up their data platform, before the data engineering starts and they are trying to take the shortcut to find someone who can do both. If you're not experienced in setting such as thing, I would move one. I feel like you will be studying for weeks to match the requirements, it's not just learning the Kubernetes basics, only for them to take a guy who has years of experience in cloud platform set up. They will eventually focus on data engineer hiring.",
                  "score": 4,
                  "created_utc": "2026-02-09 00:55:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o49lz26",
                  "author": "Darkendfearz",
                  "text": "That's actually wild. What kind of companies are you interviewing for?",
                  "score": 5,
                  "created_utc": "2026-02-08 15:39:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4a9c6t",
          "author": "tiredITguy42",
          "text": "Wait, there was a time when tech-stack did not change each few months?\n\nBut seriously. Fake it till you make it. All these technologies are easy to use when you are forced to work with them. Just watch some videos, so you have some idea what it is about.\n\nThere are differences in details for each company as the DevOps team is different in each place.",
          "score": 5,
          "created_utc": "2026-02-08 17:33:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bo7c8",
          "author": "turboDividend",
          "text": "data engineering is becoming dev/data ops it seems. you need to be a networking gguy and a pipeline guy. \n\nmost of the devops ppl i met were not developers, not knocking them but it wasnt what they were about.",
          "score": 5,
          "created_utc": "2026-02-08 21:39:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d0ilb",
          "author": "calimovetips",
          "text": "you don‚Äôt need deep kubernetes, just enough to run and debug jobs. airflow plus docker can be picked up in a few weeks, kubernetes basics in about a month if you practice consistently.",
          "score": 2,
          "created_utc": "2026-02-09 02:08:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dq9j8",
          "author": "EviliestBuckle",
          "text": "What is data stack these days?",
          "score": 1,
          "created_utc": "2026-02-09 04:35:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eavf3",
          "author": "al_tanwir",
          "text": "Binge watch a few Kubernetes tutorial on YouTube, and you're good to go. :)",
          "score": 1,
          "created_utc": "2026-02-09 07:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4onjgv",
          "author": "LilParkButt",
          "text": "The way I see things, data engineering is getting split into DataOps, Analytics Engineering, and MLOps.",
          "score": 1,
          "created_utc": "2026-02-10 21:03:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r08mq6",
      "title": "Explain ontology to a five year old",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r08mq6/explain_ontology_to_a_five_year_old/",
      "author": "ephemeral404",
      "created_utc": "2026-02-09 16:22:56",
      "score": 37,
      "num_comments": 23,
      "upvote_ratio": 0.89,
      "text": "Not absolutely to 5 yo but need your help explaining ontology in simpler words, to a non-native English speaker, a new engineering grad",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r08mq6/explain_ontology_to_a_five_year_old/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4h52d7",
          "author": "_OMGTheyKilledKenny_",
          "text": "You start with a controlled vocabulary for a set of values something can be.  Like Houston, Dallas, Austin are cities in Texas.  \n\nYou add a taxonomy on top of this to say Texas is a state and the aforementioned cities are located in the geographical and legal boundaries of the state ofTexas and another taxonomy that says Texas, California, Florida are states and are located is country named USA and follow/benefit from its federal laws. \n\nThen you can add an ontology that defines relationships between taxonomies, such as cities follow the laws of states and countries can enter free trade agreements, defensive cooperation with one another etc.  \n\nThen you can draw logical statements from these, like if John is a farmer in midlands, Texas he can sell beef to a company in Brazil free for tariffs. \n\nYou can build knowledge graphs on top of these ontologies that can ground LLMs into context specific answers.",
          "score": 42,
          "created_utc": "2026-02-09 18:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jtcbs",
              "author": "Leading-Inspector544",
              "text": "Is that not just a knowledge graph?",
              "score": 2,
              "created_utc": "2026-02-10 02:59:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4k46jg",
                  "author": "Idiot_LevMyskin",
                  "text": "Ontology is the data model for Knowledge graph.",
                  "score": 12,
                  "created_utc": "2026-02-10 04:08:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4gg3qz",
          "author": "ResidentTicket1273",
          "text": "In simple terms, an ontology is a map of \"types of things that exist\" and the kinds of relationships those things can be expected to have with one another.\n\nIn data engineering terms, it's a bit like a formalised conceptual data model where the concepts have defined expected relationships with one another.\n\nMore advanced ontologies can be constructed to accept fragmented or incomplete information and define rules to help infer other facts about the things referenced that aren't explicitly provided in the inputs.\n\nFor example, we might have a data stream that imports records about a person and their parents. We might define a relationship that says \"A sibling is defined as someone who shares the same parents.\" The ontology can then (given enough input data) infer these additional relationships logically, even though they've not been expressly provided by the data.",
          "score": 16,
          "created_utc": "2026-02-09 16:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4h0jxg",
              "author": "dyogenys",
              "text": "Piggybacking on the correct description to say, it's kind of like types in programming languages, except it's for diverse facts represented in machine readable syntax instead of just data types.",
              "score": 1,
              "created_utc": "2026-02-09 18:09:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4iccvb",
          "author": "Mclovine_aus",
          "text": "To piggyback, who is using ontologies in their work. I only ever hear ontology brought up by data execs as a buzzword or golden future state.  But obviously that‚Äôs just my area of the world.",
          "score": 7,
          "created_utc": "2026-02-09 22:03:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4if2ts",
              "author": "pceimpulsive",
              "text": "Not my area but we are starting to work towards it \n\nTelco sector.\n\nWe are starting with knowledge graphs, ontology is next I think.",
              "score": 1,
              "created_utc": "2026-02-09 22:17:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4snjo8",
              "author": "Level-School-2022",
              "text": "It's becoming more popular because it's a key pillar of Palantir (Foundry and Other Platforms) which are hot right now.",
              "score": 1,
              "created_utc": "2026-02-11 13:28:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ig8oz",
          "author": "dudeaciously",
          "text": "Taxonomy is a system of naming things.  So we know how to name fighter jets as they are created.  And we will never call a fruit F-117.\n\nOntology says that given a lot of things in a system that have a reasonable set of names, we want to know what things are very similar, what are slightly similar, and what is very different.  They might be similar in some property like taste of fruits vs. crunchiness.\n\nSo, in the end, we can add new things with good system of names, and we will know what they are related to.  \n\nWe end up with groups of things that are of one category.  Then groups of groups, etc.",
          "score": 3,
          "created_utc": "2026-02-09 22:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4htn0x",
          "author": "iwantthisnowdammit",
          "text": "Types of things which exist and a verb to describe their relationship.",
          "score": 2,
          "created_utc": "2026-02-09 20:30:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lx8yi",
          "author": "tatum106",
          "text": "A structured, digital representation of your business",
          "score": 2,
          "created_utc": "2026-02-10 13:10:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i0n0b",
          "author": "ChinoGitano",
          "text": "What Lecun is pushing about ‚Ä¶ *world model*, but domain-specific?",
          "score": 1,
          "created_utc": "2026-02-09 21:04:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k5p9w",
          "author": "one-step-back-04",
          "text": "When you say ontology, do you mean how things are categorized, like in knowledge graphs?",
          "score": 1,
          "created_utc": "2026-02-10 04:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m65k6",
          "author": "NotSure2505",
          "text": "[https://www.reddit.com/r/agiledatamodeling/comments/1r11hl2/what\\_is\\_ontology\\_eli5\\_please/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/agiledatamodeling/comments/1r11hl2/what_is_ontology_eli5_please/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
          "score": 1,
          "created_utc": "2026-02-10 14:00:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4gf4jc",
          "author": "frombsc2msc",
          "text": "What do you mean with ontology? I‚Äôve never heard it be used in my domain at least?",
          "score": -3,
          "created_utc": "2026-02-09 16:28:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kme2m",
              "author": "DJ_Laaal",
              "text": "Very common in healthcare and other regulated industries like finance and asset management.",
              "score": 2,
              "created_utc": "2026-02-10 06:25:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ksu29",
                  "author": "frombsc2msc",
                  "text": "Ah oke! Thanks.",
                  "score": 1,
                  "created_utc": "2026-02-10 07:22:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qzxr0f",
      "title": "How are you debugging and optimizing slow Apache Spark jobs without hours of manual triage in 2026?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qzxr0f/how_are_you_debugging_and_optimizing_slow_apache/",
      "author": "AdOrdinary5426",
      "created_utc": "2026-02-09 07:19:23",
      "score": 37,
      "num_comments": 10,
      "upvote_ratio": 0.94,
      "text": "We've seen Spark jobs dragging on forever lately: stages with skew, small files, memory spills, or bad shuffles that take hours to pinpoint, even with the default Web UI. We stare at operator trees and executor logs, guess at bottlenecks, then trial-and-error code changes that sometimes make it worse.\n\nOnce the job is running in production, the standard Spark UI is verbose and overwhelming, leaving us blind to real-time issues until it's too late.\n\nKey gaps frustrating us right now\n\n*  Default Spark UI hard to read with complex plans and no clear heat maps for slow stages.\n*  No automatic alerts on common perf killers like small files IO, data skew, or partition imbalances during runs.\n*  Debugging relies on manual log parsing and guesswork instead of actionable insights or code suggestions.\n*  No easy way to rank issues by impact (e.g., cost or runtime delta) across jobs or clusters. Team spends too much time firefighting instead of preventing repeats in future pipelines.\n\nSpark is our core engine but we're still debugging it like it's 2014. Anyone running large-scale Spark (Databricks, EMR, on-prem) solved this at scale without dedicated perf engineers?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qzxr0f/how_are_you_debugging_and_optimizing_slow_apache/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4eedot",
          "author": "noobcoder17",
          "text": "I'll give it to you straight, YOU DON'T.\n\n\nThere's all these talk, all this theory about spark optimizations and debugging, yada yada.¬†\n\n\nIn reality you have to spend those hours in triage.¬†\n\n\nBut usually once you get a hang of it, you shouldn't be spending too many hours next time.¬†",
          "score": 33,
          "created_utc": "2026-02-09 07:55:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jmx7c",
              "author": "ubelmann",
              "text": "Some of it is taking time to adhere to best practices in the first place.  You could argue it's overkill in some cases, but being proactive about things like too many small files, being thoughtful about partitions and such can go a really long way.\n\nBut I agree that once you've seen a few bad jobs, you get better at finding the root causes more quickly, or maybe I should say less slowly.",
              "score": 1,
              "created_utc": "2026-02-10 02:21:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4jolho",
                  "author": "noobcoder17",
                  "text": "Yep! it's always \"BEST\" to follow best practices. On the contrary, what i've noticed in my experience working for many years in this field, engineers are rushed to deliver and the people who are taking these arch decisions are also in a rush and juggling around multiple projects and they give us the best practice that they know of which may not always work in production. \n\nI've found, no matter how much we do, things will break at one point and that's the real opportunity to learn and optimize.   \n  \nHeck i used to think big tech is immune to this, remember times when google, chatgpt went down? or the Korian guy making this \"gangnam style\" video and breaking youtubes views pipeline?- all were learning opportunities and DE is same as such. ",
                  "score": 1,
                  "created_utc": "2026-02-10 02:31:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4enuhm",
          "author": "not-an-AI-bot",
          "text": "Follow good practices, avoid functions that are already documented for slow performance, avoid too much custom code, use modularity, specially the ones you know perform very well. And keep logs for steps/substeps so you can monitor and adjust where necessary.",
          "score": 7,
          "created_utc": "2026-02-09 09:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ji1vi",
          "author": "MonochromeDinosaur",
          "text": "You don‚Äôt this is unfortunately the reality of self managed spark.\n\nLooking at the SQL execution DAG in the spark UI for long steps and finding the longest duration ones or bottle necks is what I would do for performance. It was the only useful view\n\nThankfully I moved on to Snowflake and hoping to never look back.",
          "score": 3,
          "created_utc": "2026-02-10 01:53:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eazm1",
          "author": "Efficient_Agent_2048",
          "text": "Well, I would say the key is moving from reactive debugging to proactive instrumentation. Integrate structured logging and metrics, for example SparkListener events, Ganglia, Prometheus, so you get live alerts for small files, skew, or memory spills. Use automated stage analysis to highlight the top N bottlenecks by runtime or cost impact. Combine that with CI tests for job profiles, so regressions get flagged before hitting prod. It is not magic, but layering metrics, alerts, and profiling drastically reduces the manual triage.",
          "score": 6,
          "created_utc": "2026-02-09 07:23:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f75os",
              "author": "One_Citron_4350",
              "text": "What do you mean by automated stage analysis? How do you do it?I'm curious, is it something you implemented internally because I don't know of such a tool.",
              "score": 3,
              "created_utc": "2026-02-09 12:22:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4em6fu",
              "author": "DeepFryEverything",
              "text": "Suggestions for tooling? Our platform team has set up Grafana, but I am not sure how to plug that into Databricks-clusters.",
              "score": 1,
              "created_utc": "2026-02-09 09:12:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}