{
  "metadata": {
    "last_updated": "2026-02-07 02:58:04",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 269,
    "file_size_bytes": 312721
  },
  "items": [
    {
      "id": "1qvizak",
      "title": "Data Engineering as an After Thought",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/pdqlix94tfhg1.png",
      "author": "uncertainschrodinger",
      "created_utc": "2026-02-04 08:20:10",
      "score": 487,
      "num_comments": 21,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qvizak/data_engineering_as_an_after_thought/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3igd75",
          "author": "meatmick",
          "text": "Yeah... Their tools are also sometimes python scripts, written with AI (nothing againstAI for code but not like this) and are unmaintainable pieces of garbage...\nAll that for the small price of hundreds of thousands of dollars if not millions. Ask me how I know lol",
          "score": 193,
          "created_utc": "2026-02-04 11:23:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3imfy3",
              "author": "TheFach",
              "text": "I probably know the same way as you but tell the story man",
              "score": 38,
              "created_utc": "2026-02-04 12:10:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3jach2",
                  "author": "meatmick",
                  "text": "One of those 3 companies was hired to find things to optimize in our processes. They clearly sold us the dream of saving millions, which so far doesn't look like it'll ever be the case. To do their dream stuff, we needed to provide a shit-load of data from all manners of business units in the company. Then this data gets normalized by them and fed in their \"tool\". The tool uses AI to find the \"things to optimize\". Now the department that paid for this crap is trying to pawn the maintenance off on us in IT. The company also doesn't provide help on how to normalize data to fit their tool, and guess who will probably also be in charge of doing it? So far, they have not found any significant savings and the ROI vs how much their cost (1+ million so far) will take years, if it ever pays back.\n\n  \nAs others have said, it's ok because our VPs can say we're AI enabled.",
                  "score": 50,
                  "created_utc": "2026-02-04 14:31:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ip8di",
              "author": "uncertainschrodinger",
              "text": "As long as the VP can tell execs \"we are AI enabled now\" in the next quarterly report, then it's worth every penny.",
              "score": 40,
              "created_utc": "2026-02-04 12:30:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3l4xoc",
                  "author": "TheFach",
                  "text": "I guess this is sadly the reality of the moment",
                  "score": 5,
                  "created_utc": "2026-02-04 19:40:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3k1zfs",
              "author": "mertertrern",
              "text": "This has been the game with these companies for a long time. Before AI, the term used was \"Machine Learning\", but the pitch was the same. Before that, it was \"Semantic Model\" or \"OLAP Cube\". It's always the same: \"give us your data and $1M, and we'll give you back a miracle\". It's always too good to be true though.",
              "score": 12,
              "created_utc": "2026-02-04 16:42:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3lc506",
                  "author": "South_Candle_5871",
                  "text": "Agreed with the sentiment, but semantic models are real and useful abstractions to non tech data consumers",
                  "score": 2,
                  "created_utc": "2026-02-04 20:15:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qdo86",
                  "author": "JJ3qnkpK",
                  "text": "Working with the resultant product of a major tech consultancy now. I've noticed that they absolutely *fixate* on using a particular suite of products even if they're horrendous solutions to the actual problem. It's like they're trying to farm case studies for how good said suite of products is rather than use the best tool for the job.\n\nIn this case: Microsoft stuff. I've got a Synapse instance with a freakish set of pipelines and notebooks to make it function even somewhat like Databricks. This was a clean slate start from only a few years, so they could have chosen any product, but instead they chose to go all-in on Microsoft.\n\nInstead, this client company paid that consultancy tons of money to custom build janky code on an old platform when they could have saved so much time and money by just using tools made for the job. Now they're digging deeper trying to make this weird stuff work. But hey, at least you got a cool PowerPoint with a bunch of tech product logos with arrows pointing between them (and no description about how said diagram represents an actual solution to the problems at hand).\n\nRabble rabble rabble..",
                  "score": 2,
                  "created_utc": "2026-02-05 15:40:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iuwg7",
          "author": "Rift-enjoyer",
          "text": "Well It was a 3 week project, and the IT said it will take 2 weeks to just get access to data. Also the exec only paid for a POC + a roadmap slides that can score him the next year's bonus.",
          "score": 47,
          "created_utc": "2026-02-04 13:06:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jciy0",
          "author": "decrementsf",
          "text": "Professional maturity is recognizing when to laugh when the consultant leaves the room. Does your boss need political cover for a decision that must be made? That is the only time to use the consultant. Nobody got fired when the consultants advice didn't work out. They're an insurance product.",
          "score": 45,
          "created_utc": "2026-02-04 14:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jgt7o",
              "author": "passing_marks",
              "text": "Yeah a consultant that worked with us said it openly! Blame it on us üòÇ I don't know if that makes me believe in them or not lol",
              "score": 19,
              "created_utc": "2026-02-04 15:04:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ujbws",
              "author": "zazzersmel",
              "text": "pretty sure I was the consultant in this scenario, and the consultancy fired me.",
              "score": 2,
              "created_utc": "2026-02-06 04:38:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jgy7f",
          "author": "glubglublub",
          "text": "As a side question, does any of these companies do any good projects? I feel like they're a fraud at this point lol",
          "score": 17,
          "created_utc": "2026-02-04 15:04:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lbgu9",
          "author": "klubmo",
          "text": "I work for a medium size consulting firm that often gets contracts to come and fix the ‚Äúwork‚Äù that these big companies sold. Often that means completely needing to redo everything from scratch. C-suite loves these big companies, but the directors have to convince the VPs to use us constantly to fix the big firms screw ups.\n\nIt‚Äôs a very expensive way to run a business.",
          "score": 12,
          "created_utc": "2026-02-04 20:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lassb",
          "author": "engineer_of-sorts",
          "text": "Massive fuck you to all the consultants out there getting paid to literally churn out tech debt",
          "score": 12,
          "created_utc": "2026-02-04 20:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ip4tx",
          "author": "Morpheyz",
          "text": "Are you me?",
          "score": 3,
          "created_utc": "2026-02-04 12:29:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oecxn",
          "author": "redeyedbiker",
          "text": "Ugh, all my homies hate BCG",
          "score": 1,
          "created_utc": "2026-02-05 06:59:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwrxe8",
      "title": "Notebooks, Spark Jobs, and the Hidden Cost of Convenience",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/g2mm7qq5lphg1.jpeg",
      "author": "mwc360",
      "created_utc": "2026-02-05 17:41:38",
      "score": 365,
      "num_comments": 85,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwrxe8/notebooks_spark_jobs_and_the_hidden_cost_of/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3rw2pa",
          "author": "Rycross",
          "text": "Whether its a notebook or not isn't really the issue.  The issue is whether there is a proper version control, change control, and rollback process.  Notebooks *usually* don't have that in practice.  But you can do VC, CI/CD, and testing with notebooks.  If you do then there's nothing wrong with using them in prod.\n\n\nSome more thoughts: The issue that I usually see in practice is that once you start introducing these things then notebooks' convenience is reduced, so there's a lot of resistance against controls that prevent people from just yeeting something into production.  And once you let people yeet their non-important work, its only a matter of time before people start yeeting important work.",
          "score": 65,
          "created_utc": "2026-02-05 19:51:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x4565",
              "author": "LandlockedPirate",
              "text": "Except that notebooks also frequently rely on side effects, %run, magic commands, comments that are actually code in a different language (sql),  typically don't have a dependency manifest, typically don't have tests etc.  The code can't really be processed correctly by commodity static code analyses tools, is painful to merge (jupyter), sometimes also contains results (jupyter) etc.\n\nYes I know you \\_can\\_ do some of these things, you \\_can\\_ avoid %run and magic commands, you \\_can\\_ avoid relying on side effects, but the tooling doesn't help.  On a large project or team the tooling is what makes it actually happen.",
              "score": 6,
              "created_utc": "2026-02-06 15:50:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3r8uat",
          "author": "GrumDum",
          "text": "If people who used notebooks in prod could read, they would be very angry right now.",
          "score": 291,
          "created_utc": "2026-02-05 18:04:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ypgyw",
              "author": "Brymanen",
              "text": "I use notebooks in prod and I am proud of it. I use notebooks in prod and I am proud of it. I use notebooks in prod and I am proud of it. I use notebooks in prod and I am proud of it. I use notebooks in prod and I am proud of it. ",
              "score": -2,
              "created_utc": "2026-02-06 20:25:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rl8y3",
          "author": "scataco",
          "text": "Quality is subjective.\n\nIf \"most prod jobs\" are for dashboards that nobody uses, who cares if the data is consistent, interpretable and accurate!",
          "score": 87,
          "created_utc": "2026-02-05 19:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rxfvj",
              "author": "jimtoberfest",
              "text": "Someone fast track this guy to senior management",
              "score": 72,
              "created_utc": "2026-02-05 19:57:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s2exm",
                  "author": "scataco",
                  "text": "Nooooo!",
                  "score": 8,
                  "created_utc": "2026-02-05 20:21:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3svei7",
                  "author": "jun00b",
                  "text": "I'm working on a spot bonus right now.",
                  "score": 6,
                  "created_utc": "2026-02-05 22:42:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xgkld",
                  "author": "LandlockedPirate",
                  "text": "Get him an agentic coding workflow and he'll be a 1 man army",
                  "score": 1,
                  "created_utc": "2026-02-06 16:49:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vjpfw",
              "author": "CAPSLOCKAFFILIATE",
              "text": "> for dashboards that nobody uses\n\nI feel my neck veins bulging as I read this part.",
              "score": 5,
              "created_utc": "2026-02-06 09:51:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3y3k89",
              "author": "st4reater",
              "text": "Why have the dashboard then",
              "score": 1,
              "created_utc": "2026-02-06 18:38:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rapf9",
          "author": "CrowdGoesWildWoooo",
          "text": "Well databricks ‚Äúnotebook‚Äù aren‚Äôt literal notebook.",
          "score": 78,
          "created_utc": "2026-02-05 18:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3riyps",
              "author": "TripleBogeyBandit",
              "text": "This, you can have python files with a comment at the top ‚ÄúDatabricks notebook source‚Äù and it render as notebook in the ui but allow for test suites.",
              "score": 50,
              "created_utc": "2026-02-05 18:50:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xfpus",
                  "author": "LandlockedPirate",
                  "text": "Ok, i'll bite.  \n\nHow do you write tests around your non python cells?",
                  "score": 1,
                  "created_utc": "2026-02-06 16:45:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3tm7e6",
              "author": "TheRealStepBot",
              "text": "They were and once they realized how bad it was to build a platform on notebooks they have spent a better part of a decade trying to tack standard software development tooling onto them. They aren‚Äôt notebooks in only the most technical of ways. They still are square pegs trying to fit into the round hole that is the rest of software development.",
              "score": 8,
              "created_utc": "2026-02-06 01:13:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3uxlsp",
                  "author": "CrowdGoesWildWoooo",
                  "text": "The change to .ipynb default was recent, but it‚Äôs not like the ecosystem around the .py file was lacking or non-functional. \n\nAs in the issue with notebooks are inconsistency when it comes to commit because you are bringing the whole notebook state, and poor integration with testing suite. \n\nIf it behaves like a normal python file which you can do easily do testing, and it doesn‚Äôt carry the bad traits of a notebook, there‚Äôs no point to be pedantic.\n\nIt‚Äôs ironically like one of the common ‚Äúprinciple‚Äù in python. If it walks like a duck, quack like a duck‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-02-06 06:27:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3sasrr",
              "author": "Atticus_Taintwater",
              "text": "Are they not? With dbr 15+ aren't they stored by default as ipynb and you have to change it to py, and I wonder how long that backward support will stick around",
              "score": 6,
              "created_utc": "2026-02-05 21:01:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3s10a4",
              "author": "Clean-Health-6830",
              "text": "Abstractions? In my software? Bah!",
              "score": 2,
              "created_utc": "2026-02-05 20:14:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ve5ml",
              "author": "SnowyBiped",
              "text": "to be fair, a few years back, in Databricks a notebook based job had better logging that a standard jobs.\n\nYou could see where there was a failure and just get that notebook and run it in the UI to replicate the problem.\n\nBut for what we were doing (copy some tables and run some SQL) Databricks was an overkill",
              "score": 1,
              "created_utc": "2026-02-06 08:57:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3s19dp",
              "author": "mwc360",
              "text": "I disagree. This works the same in Fabric, Synapse, and likely other platforms as well. A PySpark Notebook put into GIT has a bunch of comment lines that are used to parse where a cell begins/ends, magics, different cell languages, etc. ~~BUT, the actual thing in the platform backend is almost surely not a simple \\`.py\\` file, it is something more complex (i.e. \\`.ipynb\\` which is just JSON underneath) as it stores cell outputs, metadata, and other things which are not parsed into a \\`.py\\` file when the object is sync'd to GIT.~~ *Edited for those that can't see the forest through the trees:* this might have changed in DBX but this ultimately doesn't matter to my point that what is deployed to prod at the end of the day is a Notebook experience that comes with Notebook risks. Sure you can mitigate most of the risk with tests (and maybe CI validation to block usage of MAGICS that are untestable) and tight governance on your prod env, but it's still awkward.\n\nSo why does this matter? From a development perspective (and almost surely from a backend storage perspective) it is a Notebook by all measures. This matters as you can arbitrarily decide to use Scala or SparkSQL cells in your Notebook where PySpark is the default language, and when parsed into a \\`.py\\` file, none of those non-default language cells can be tested, type checked, linted, etc.. they show as commented out lines of code with a header that tells the platform's parser to interpret it as a specific language.\n\nSure, you could require your devs to not use multiple languages in a single Notebook and use an awkward process to ensure test coverage (awkward because you can't really start with local development, you'd have to do cloud>local>write tests and repeat, but even then you are still shipping into production something that comes with a built in IDE. At that point, only proper governance and access control can save you from a \"well it's super easy so I just directly applied the change in production\" scenario.",
              "score": -10,
              "created_utc": "2026-02-05 20:16:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3sb00z",
                  "author": "CrowdGoesWildWoooo",
                  "text": "Stop yapping bs, if you never used one.",
                  "score": 23,
                  "created_utc": "2026-02-05 21:02:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3sabye",
                  "author": "ADGEfficiency",
                  "text": "You are uneducated about this topic.",
                  "score": 17,
                  "created_utc": "2026-02-05 20:59:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rirkl",
          "author": "raskinimiugovor",
          "text": "I'll give you an example of how we use synapse notebooks (had no say in technology used, but generally it's enough for our needs) which are orchestrated via pipelines and triggers:\n\n* all processing logic is maintained in a custom python library covered with unit tests and a few integration tests, separate from transform logic\n* this custom library has very minor dependencies on Azure (only a few generic functions) and could be migrated to databricks or something similar if necessary\n* all notebooks import the library and use same flow, so everything is familiar from notebook to notebook\n* simple transformations are mapping based\n* more complex transformations are implemented in the notebooks but they can only output a dataframe (later handled by processing module), they can't write to the env directly or depend on some global variables (in some cases wrapper functions can be used to circumvent that)\n* changes are committed and deployed using CI/CD\n* development and debugging is generally done directly in the notebook but has no effect until it ends up on the main branch and becomes a part of the project\n* in most cases when something fails, it's related to env or env specific data and most convenient way is to debug it via notebook which is already part of the isolated workspace and connected storage accounts\n\nDo you think there's anything wrong with this workflow and how would spark jobs improve it?",
          "score": 19,
          "created_utc": "2026-02-05 18:49:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rnkeg",
              "author": "instamarq",
              "text": "If it reliably delivers the goods in a maintainable, secure, easily audited and cost effective way, the job has been done well.",
              "score": 11,
              "created_utc": "2026-02-05 19:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s2pgd",
                  "author": "mwc360",
                  "text": "100%. If your process is working well, this blog shouldn't make you question everything about your existing process. If you find that your process makes it hard to deliver reliability outcomes, that's when I'd question what parts can be improved. What you've described seems quite clean.",
                  "score": 2,
                  "created_utc": "2026-02-05 20:23:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ry9lw",
              "author": "fuhgettaboutitt",
              "text": "Without the notebooks, this is the approach my old team came up with a few years ago but we exposed the library as YAML and as the direct library. Its HARD to implement, but you know exactly how to get something reliably in prod, the uplift of data science toolkit into prod came down to days. More complex transformations were required to implement unit tests and be stored in code and reviewed as regular software. You knew the training pipe and the prediction pipe were exactly the same for transformations, so any modifications at a lower level were tested by the tests for that lower level function, as well as all of the pipes utilizing that funciton. DS only lived in notebooks as long as the project was exploratory, notebooks were sourced from a default notebook that could be checked out and had all of our pip installs and configurations loaded.",
              "score": 2,
              "created_utc": "2026-02-05 20:01:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3t72p3",
          "author": "Sufficient_Example30",
          "text": "Honestly,i don't agree with this sentiment.\nI've found notebooks in production extremely useful, especially when things have gone wrong .\nIt makes things easier for me to explain to business at what step the pipeline failed via visuals.\nIn ML workload environments ,it allows data science a chance to know from where things have gone awry easily and provides them with like a base code to fix their model.\nEverything is a trade off ,\nThere's also a cost of ci/cd  a script and a hidden cost of going the pipeline route.,maintaining multiple environments etc\nThe only difference is you build more stuff to show things for more stake holder confidence.\nI think you should decide your approach on a pipeline to pipeline basis.\nNot everyone is gonna agree with my sentiment but i heavily disagree with the post\n\n====\nI also disagree with the notion that the code being harder to test.\nIn my opinion data pipelines should be tested end to end with data and while testing see how each transformation affects stuff and using dequeue log stuff correctly.\nWriting testable code has nothing to do with using  a notebook and all common stuff can be written as a .python file of a pip package.",
          "score": 12,
          "created_utc": "2026-02-05 23:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s4ngi",
          "author": "mttpgn",
          "text": "I will refuse to share my demo notebooks for exactly this reason. \"Obviously it'll need to be productionalized first.\"",
          "score": 3,
          "created_utc": "2026-02-05 20:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3u60h4",
          "author": "Ted_desolation",
          "text": "Im in fabric. I have no choice in the matter so don't blame me.",
          "score": 3,
          "created_utc": "2026-02-06 03:11:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uxqgk",
              "author": "mwc360",
              "text": "Would love to learn more. Have you tried Spark Job Definitions or is this more of a team culture thing?",
              "score": 1,
              "created_utc": "2026-02-06 06:28:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3s10ot",
          "author": "Throwaway999222111",
          "text": "I export as a .py and the script does the same thing, I just rename it as prod. That isn't what others do? Notebooks are for dev I thought",
          "score": 5,
          "created_utc": "2026-02-05 20:14:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3y450j",
              "author": "st4reater",
              "text": "A notebook is - a notebook. You need to ensure parity between what you develop and what you push to prod. Otherwise, how can you say you know what you're pushing, and what you tested represents what users will meet?",
              "score": 1,
              "created_utc": "2026-02-06 18:41:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rbdzx",
          "author": "Tushar4fun",
          "text": "You said notebooks - I heard HTML/CSS",
          "score": 4,
          "created_utc": "2026-02-05 18:16:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s7bpa",
          "author": "Arnechos",
          "text": "Using notebooks in databricks when you only write pysprark code is laziness given the option to run python script/wheel task",
          "score": 2,
          "created_utc": "2026-02-05 20:45:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v8bgn",
              "author": "ephemeralentity",
              "text": "But what if you want to make it easy to debug? If you are using PySpark you are likely doing data transformation. What is the benefit of converting that to a py file? You lose the ability to step through it next time you want to make changes. Worse, if you package in a whl you have to constantly recompile it.\n\nThere are circumstances where notebooks become inefficient, e.g. software engineering (not data engineering applications), where you have a large number of imports / component class modules and you don't want to have to instantiate them all in your notebook environment or have a large number of notebook dependencies but for simpler data transforming logic, they work well.",
              "score": 2,
              "created_utc": "2026-02-06 08:02:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3v9y83",
                  "author": "Arnechos",
                  "text": "\\> e.g. software engineering (not data engineering applications)\n\nThis is weird distinction for me, data engineering is software engineering with data product at the end.\n\n>But what if you want to make it easy to debug? If you are using PySpark you are likely doing data transformation. What is the benefit of converting that to a py file? You lose the ability to step through it next time you want to make changes. Worse, if you package in a whl you have to constantly recompile it.\n\nProper logging and stack traces already give you the debugging what is happening in production. I'm not saying don't use notebooks during development. The package argument is kinda silly, like with uv, CI/CD and IaC it's trivial - even so today when you can have claude/codex to whip up yamls\n\n\\>¬†simpler data transforming logic, they work well.\n\nFor this you could even use a GUI tool. ",
                  "score": 2,
                  "created_utc": "2026-02-06 08:17:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3s8akh",
          "author": "tjger",
          "text": "I like using notebooks for the entry points. Notebooks help explain the pipeline / job better than just plain code.",
          "score": 2,
          "created_utc": "2026-02-05 20:49:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3t4e6c",
              "author": "Teddy_Raptor",
              "text": "This is why marimo is cool. Notebook interface book backed by . Py fines",
              "score": 2,
              "created_utc": "2026-02-05 23:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uxtt7",
          "author": "DoubleAway6573",
          "text": "I'll take the bait.\n\n\nAny prod at all should be notebooks.\n\n\nAre you convinced?",
          "score": 2,
          "created_utc": "2026-02-06 06:28:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v9if7",
          "author": "skippy_nk",
          "text": "I agree with the post but I'll comment on another thing that I see people use to counter argue this idea.\n\nThere's this argument that notebooks make the code more explainable to stakeholders.\n\nBut really, code is not for the non-coders and they shouldn't bother with it. I prefer not to show the code to them, especially if it's in notebooks, and especially now with all this GenAI stuff. It's because notebooks make the code look simple to non technical folks. It's due to the cell layout, I believe, that they get the feeling it's basically not much more than excel formulas, while in reality, there's a huge clusterfuck of moving parts underneath. \n\nAnd there's always this one manager that half assed a Python for DE course on Udemy and \"wants to help\". Of course, we end up losing our precious time by going over their slop because we can't just tell them to fuck off and do their job and we'll do ours. \n\nCode explainability (to stakeholders) should not be a thing, ideally. Basically, development experience beats the explainability argument all day long.",
          "score": 2,
          "created_utc": "2026-02-06 08:13:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x2w5c",
          "author": "miker5555",
          "text": "Honestly this matches my experience too. Notebooks are great for exploration, but once something is ‚Äúreal,‚Äù they tend to turn into a dumping ground of half-run cells and mystery state.\n\nEvery prod issue I‚Äôve debugged that started with ‚Äúbut it worked in the notebook‚Äù ended up costing way more time than just writing the job cleanly from the start.\n\nStill‚Ä¶ I‚Äôll admit I keep one notebook around to poke at data before doing it the right way üòÑ",
          "score": 2,
          "created_utc": "2026-02-06 15:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sa0um",
          "author": "SBolo",
          "text": "Most?? No prod job should be a notebook",
          "score": 4,
          "created_utc": "2026-02-05 20:58:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ske81",
              "author": "Sagarret",
              "text": "I would say something like around 95% or more.\n\nFor really simple tasks they are okay.\n\nBut yes, I totally agree and that was one of the main reasons why I left DE",
              "score": 2,
              "created_utc": "2026-02-05 21:48:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3udhzu",
          "author": "focused_entrepreneur",
          "text": "But why? I love Databricks notebooks.",
          "score": 1,
          "created_utc": "2026-02-06 03:58:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wipi8",
          "author": "Nekobul",
          "text": "Finally Miles, you are starting to see the light. But your journey will not be complete until you start to reject Spark as Anathema and not needed for the vast majority of the solutions.",
          "score": 1,
          "created_utc": "2026-02-06 14:02:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wq9at",
          "author": "geeeffwhy",
          "text": "i mean, i tend to agree‚Ä¶ but at the same time, a notebook is just a python file. nothing stops you from structuring your program reasonably with a notebook. it feels like a resurgence of one of my favorite old ideas, Literate Programming. \n\nSometimes the convenient interface is useful, even in prod. you can still have tests and types and clearly defined interface, modules, abstraction, etc.",
          "score": 1,
          "created_utc": "2026-02-06 14:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x7973",
          "author": "dillanthumous",
          "text": "Blanket statements are rarely true and often clickbait. Change my mind.",
          "score": 1,
          "created_utc": "2026-02-06 16:05:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xjnj5",
              "author": "mwc360",
              "text": "Ok. **Most** is not a blanket statement. Change my mind.",
              "score": 2,
              "created_utc": "2026-02-06 17:03:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xdqi7",
          "author": "sleeper_must_awaken",
          "text": "\n\n",
          "score": 1,
          "created_utc": "2026-02-06 16:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3usm9e",
          "author": "shennan-lane",
          "text": "What about a well written Marimo",
          "score": 0,
          "created_utc": "2026-02-06 05:46:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wo5ft",
          "author": "Mario4272",
          "text": "The fk you saying?",
          "score": 0,
          "created_utc": "2026-02-06 14:31:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv0iyl",
      "title": "DoorDash Sr Data Engineer",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qv0iyl/doordash_sr_data_engineer/",
      "author": "Outside_Reason6707",
      "created_utc": "2026-02-03 18:49:14",
      "score": 192,
      "num_comments": 54,
      "upvote_ratio": 0.95,
      "text": "Recently interviewed at DoorDash. \n\nOnsite had 4 rounds System Design, Data Modeling, Business Partner and Leadership \n\nThe recruiter who had reached out regarding the role had transferred my profile to other recruiter at onsite process. \n\nThis new recruiter , not friendly. In a cold email said that I should book time on her calendar for a prep call. Well there was not a single slot available for next 3 weeks. I kept checking for couple of days and finally found one. On the day of call she rescheduled for different time. On the call read the same pdf that she had shared with me over the email on what to expect. Not a great conversation. I‚Äôve  met really good recruiters who are friendly enough. \n\nSystem Design question - question was quite big 6-7 lines. I‚Äôll put it in simple words - Design DataBricks! Yes, you read it right! Interviewer was interested in knowing how will I write exact YAML code for this. I was able to answer all his questions.\n\nData Modeling - Design fitness app. But the interviewer wanted me to draw visualizations. Well never in my past 8 years of work experience I had to do any visualizations but looks like DE in DoorDash work on visualizations as well. It wasn‚Äôt a basic graph , some advanced trend graph. \n\nBusiness Partner - DoorDash expanding business how will you go about it etc. basic questions interviewer also seem to be onboarded on the approaches\n\nLeadership - Hiring Manager joined 2-3 minutes late. Didn‚Äôt bother to apologize. I ignored that and continued to talk with my positive energy. He said he will leave 10 minutes at the end for me to ask any questions. \n\nQuestions were normal tell me about the time kind. Situation based. I answered all. He had multiple follow up questions. Kept asking something from the list. It was almost 5 minutes to end the meeting and then he stopped and started sharing about the team. Even here he didn‚Äôt ask if I have any questions. I had to ask him when we were at time if I can ask couple of questions. I felt like I performed well.\n\nNext day morning Recruiter‚Äôs cold email came in that team has not decided to move forward. \n\nHappy to answer any questions anyone has. ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qv0iyl/doordash_sr_data_engineer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3e4xpf",
          "author": "DenselyRanked",
          "text": "Sorry that it didn't work out for you and thanks for sharing your experience. Some of these companies do not have a team selection process for DE and given how competitive the market is, you may have been second best to someone that they have already interviewed.\n\nFor the sys design, were they expecting a YAML or was that the agreed upon method to explain the design? How in-depth did you need to get into involving things that are not normally in the JD for data engineering like networking, security, shared resources, etc?",
          "score": 59,
          "created_utc": "2026-02-03 19:07:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3edp3i",
              "author": "Calm_Bodybuilder_335",
              "text": "Yes , can you elaborate on the system design round? What was the expectation?",
              "score": 9,
              "created_utc": "2026-02-03 19:48:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ejycx",
              "author": "Outside_Reason6707",
              "text": "I totally agree, but sharing a feedback would really help candidates to understand their weaknesses when candidates actually answered everything they asked! \n\nFor system design- question was design declarative and interactive system that can connect multiple sources like OLTP to event stream and destination could also be multiple like dw, dashboard, etc. again it was a very long question so I don‚Äôt remember exact wording but this was the idea. \nWhen I tried to explain high level design using Medallion architecture interviewer redirected conversation to asking how will I declare it. Then I suggested YAML. Then he wanted to know how in YAML will I explicitly write for each source . Which IDID! Wrote a pseudo script. Then I moved to design again. He asked multiple questions about each component. Semantic layer was something I couldn‚Äôt answer well. I have no idea where thing went wrong , which interview",
              "score": 10,
              "created_utc": "2026-02-03 20:17:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3rpzmz",
                  "author": "drunkenboy_",
                  "text": "sometimes whoever is interviewing is giving a list of requirements but does not really know what they are asking for.\nor their delusion levels are sky high and expect us to answer like AI does.\n\nwhatever it happened, it was not for you. make retrospection, improve, practice and something better will come up.",
                  "score": 2,
                  "created_utc": "2026-02-05 19:22:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3f1z7z",
          "author": "Informal_Pace9237",
          "text": "They are looking for Unicorns.\nNot normal folks",
          "score": 22,
          "created_utc": "2026-02-03 21:41:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g0wqo",
              "author": "Outside_Reason6707",
              "text": "None of interviewer was anywhere close to unicorn! Not here to rant but just frustrated with so called policy to not share feedback",
              "score": 10,
              "created_utc": "2026-02-04 00:42:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fjyby",
          "author": "Commercial-Ask971",
          "text": "Design databricks in YAML was meant to be databricks asset bundle for running pipelines?",
          "score": 12,
          "created_utc": "2026-02-03 23:10:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gm50u",
              "author": "Outside_Reason6707",
              "text": "Yess",
              "score": 2,
              "created_utc": "2026-02-04 02:42:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eqrtd",
          "author": "epic-growth_",
          "text": "Design data bricks???? Bro I gotta switch out",
          "score": 7,
          "created_utc": "2026-02-03 20:49:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3erfaw",
              "author": "Outside_Reason6707",
              "text": "What do you mean ? Sorry didn‚Äôt understand",
              "score": 2,
              "created_utc": "2026-02-03 20:52:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3etx5w",
                  "author": "epic-growth_",
                  "text": "I‚Äôm a data engineer with much less experience. So doing something like writing YAML code for designing data bricks just seems like a lot to know in the future. And I‚Äôve been thinking of pivoting out of data engineering eventually.",
                  "score": 8,
                  "created_utc": "2026-02-03 21:04:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3e2q71",
          "author": "wiseyetbakchod",
          "text": "Even I had Doordash interview and I felt like I do good. At the end, I received a call saying I didn‚Äôt explain two points in data modelling round correctly.\n\nIn my few, designing exactly the same data model that interviewer have in his mind in one hour is not possible. \n\n\nAfter some permutations and combinations, i realised that they aren‚Äôt looking for someone who can perform. They are looking for perfect 10/10 candidate which seems fair given they are paying top buck.",
          "score": 14,
          "created_utc": "2026-02-03 18:56:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eibq0",
              "author": "Outside_Reason6707",
              "text": "Recruiter said she can‚Äôt share feedback due to company policy.",
              "score": 8,
              "created_utc": "2026-02-03 20:10:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3epbkd",
          "author": "Foreign_Yam3729",
          "text": "How was the technical screen went? I am about to have a call with recruiter ?",
          "score": 3,
          "created_utc": "2026-02-03 20:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3errbz",
              "author": "Outside_Reason6707",
              "text": "It was easy! I luckily got chill interviewer. He wasn‚Äôt concerned about the syntax errors. 4 SQL and one DSA",
              "score": 4,
              "created_utc": "2026-02-03 20:54:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3f17pq",
          "author": "BeeLive9842",
          "text": "Can you share the resources you follow for preparing system design and data modelling interviews?",
          "score": 3,
          "created_utc": "2026-02-03 21:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gbuj0",
          "author": "calimovetips",
          "text": "that sounds frustrating, especially the mismatch between what was tested and what the role likely does day to day. honestly feels like either the loop wasn‚Äôt well calibrated or they were already unsure what they wanted, which is rough but not a reflection of your performance.",
          "score": 3,
          "created_utc": "2026-02-04 01:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gjyld",
              "author": "Outside_Reason6707",
              "text": "I hope that was the case since I started questioning where am I lagging",
              "score": 1,
              "created_utc": "2026-02-04 02:29:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e9za5",
          "author": "Boy675te",
          "text": "India or us ?",
          "score": 10,
          "created_utc": "2026-02-03 19:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ekvfy",
              "author": "Outside_Reason6707",
              "text": "USA",
              "score": 8,
              "created_utc": "2026-02-03 20:22:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e7dqz",
          "author": "SaintTimothy",
          "text": "Run, dont walk. Did you see the whistle blower letter this past week? Who do you think designed the system that determines whether a contractor is \"desperate\"? Do you want to maintain that system, that helps the company further exploit its own staff?\n\nEdit - the story got debunked as fake, my bad",
          "score": 7,
          "created_utc": "2026-02-03 19:18:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e8vph",
              "author": "Intelligent_Series_4",
              "text": "Share link?",
              "score": 3,
              "created_utc": "2026-02-03 19:25:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ear67",
                  "author": "SaintTimothy",
                  "text": "Apparently it was made up :-(\n\nhttps://www.reddit.com/r/doordash_drivers/s/vuOwLwPlpX",
                  "score": 3,
                  "created_utc": "2026-02-03 19:34:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ekxuk",
              "author": "Outside_Reason6707",
              "text": "Sorry I didn‚Äôt get what you said",
              "score": 1,
              "created_utc": "2026-02-03 20:22:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e72xg",
          "author": "armoman92",
          "text": "Thank you for sharing.",
          "score": 2,
          "created_utc": "2026-02-03 19:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fxf48",
          "author": "goeb04",
          "text": "I would be miserable if I put in the effort and quality responses you gave‚Ä¶.and got nothing in the end. Best of luck moving forward OP.",
          "score": 2,
          "created_utc": "2026-02-04 00:23:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g0l13",
              "author": "Outside_Reason6707",
              "text": "Thank you!!",
              "score": 1,
              "created_utc": "2026-02-04 00:40:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eehn5",
          "author": "PplAreStooopid",
          "text": "Could you pls elaborate on the system design \"Design Databricks\" question? What exactly did he want? Did they want a control plane vs compute/data plane architecture details? Also isnt YAML config for all of the resources would be too much right?",
          "score": 2,
          "created_utc": "2026-02-03 19:52:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3elgux",
              "author": "Outside_Reason6707",
              "text": "I answered above in the thread",
              "score": -2,
              "created_utc": "2026-02-03 20:24:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3edr32",
          "author": "Calm_Bodybuilder_335",
          "text": "Is this US based experience?",
          "score": 1,
          "created_utc": "2026-02-03 19:48:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eld3h",
              "author": "Outside_Reason6707",
              "text": "Yes USA",
              "score": 1,
              "created_utc": "2026-02-03 20:24:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3gw3wa",
          "author": "busybeeatwork",
          "text": "Thanks for sharing your experience!",
          "score": 1,
          "created_utc": "2026-02-04 03:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h3sm1",
          "author": "Original_Fox_6278",
          "text": "Sorry to hear that. By any chance can you give like a good resource from where I can practice case studies for data modelling and system design",
          "score": 1,
          "created_utc": "2026-02-04 04:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hnces",
              "author": "Outside_Reason6707",
              "text": "Honestly even I‚Äôm looking for a good resource. So far all I‚Äôm doing is random YouTube videos especially from Exponent",
              "score": 4,
              "created_utc": "2026-02-04 06:58:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3hh7wt",
          "author": "NefariousnessSea5101",
          "text": "What‚Äôs your profile like if I may ask?",
          "score": 1,
          "created_utc": "2026-02-04 06:07:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hnh9d",
              "author": "Outside_Reason6707",
              "text": "Grad School - Top 10 Private Schools in USA 6 years of experience in big tech 2 years in start up",
              "score": 1,
              "created_utc": "2026-02-04 06:59:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ivzmb",
          "author": "Confident-Advice-390",
          "text": "Thanks for sharing your experience.",
          "score": 1,
          "created_utc": "2026-02-04 13:13:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j27i2",
          "author": "rudderstackdev",
          "text": "It is time to document your answers (for imp questions like databricks design) and put it out there on your personal blog. So that you get something out of the time you invested.",
          "score": 1,
          "created_utc": "2026-02-04 13:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l4m7x",
          "author": "agent_kowalski",
          "text": "For system design, were they evaluating tradeoffs (cost, scaling, failure) or more like tool specific expertise (Databricks internals, YAML, clusters, etc.)?",
          "score": 1,
          "created_utc": "2026-02-04 19:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lhn6w",
              "author": "Outside_Reason6707",
              "text": "It was none of that. Interviewer was pretty old school (25+ years of experience) He seemed to be interested in theoretical knowledge- what will you write in YAML, How spark works internally to give you few examples. \nEnlist functional and non functional requirements and when I try to do so he will interrupt and suggest more which I was anyway supposed to talk etc\nProbably not a helpful answer but he just seemed to be not satisfied with whatever I was talking.",
              "score": 1,
              "created_utc": "2026-02-04 20:41:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uhqnq",
          "author": "zazzersmel",
          "text": "the content on this sub lately combined with the experience i've had working over the last couple years has me pretty damn discouraged. it's not even the AI shit (although perhaps it could be related somehow), just feels like people are straight up assholes.",
          "score": 1,
          "created_utc": "2026-02-06 04:27:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gyrjf",
          "author": "No-Carob4234",
          "text": "Interested to hear your profile. Seems like outside of Meta's push a few months ago most FAANG or adjacent only looking for tier 1 schools or previous FAANG.",
          "score": 1,
          "created_utc": "2026-02-04 03:56:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hn7ry",
              "author": "Outside_Reason6707",
              "text": "Grad School - Top 10 Private Schools in USA\n6 years of experience in big tech\n2 years in start up",
              "score": 7,
              "created_utc": "2026-02-04 06:57:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e5xuu",
          "author": "Razzl",
          "text": "No DSA?",
          "score": 0,
          "created_utc": "2026-02-03 19:11:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3el3rn",
              "author": "Outside_Reason6707",
              "text": "That was during technical screen. Interviewer was great and very chill!",
              "score": 3,
              "created_utc": "2026-02-03 20:23:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eae2m",
          "author": "Boy675te",
          "text": "Op when exactly you interviewed ,?",
          "score": 0,
          "created_utc": "2026-02-03 19:32:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv5w7i",
      "title": "Fivetran cut off service without warning over a billing error",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qv5w7i/fivetran_cut_off_service_without_warning_over_a/",
      "author": "DigitalDelusion",
      "created_utc": "2026-02-03 22:07:31",
      "score": 149,
      "num_comments": 30,
      "upvote_ratio": 0.92,
      "text": "I need to vent and have a shoulder to cry on (ib4 \"I told you so\"). \n\nWe've been a Fivetran customer since the early days. Renewed in August and provided a new email address for billing. Our account rep confirmed IN WRITING that they would do that. They didn't. Sent the invoice to old contacts intead, we never saw it. \n\nNo past due notice.   \nNo grace period. \n\nThis morning 10;30 am services turned off. \n\nWe're a reverse-ELT shop: data warehouse feed *everything.* Salesforce to ERP. ERP to Salesforce, EAM to ERP, P2P to ERP, holy crap there's so much stuff I've built over the last few years. All down. I mean that's not even calling out the reporting! \n\nWired the payment, proof from the bank send. Know what they said? \n\n\"Reinstatement takes 24-48 hours\"\n\nBro. 31k to 45k in our renewal cycle and we moved connectors off. \n\nI know it's so hot right now to shit on Fivetran. I'm here now. I was a fan (was featured on a dev post too). \n\nI can't get anyone on the phone, big delays in emails. Horror. ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qv5w7i/fivetran_cut_off_service_without_warning_over_a/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3g39f7",
          "author": "data4u",
          "text": "This is why customer support and customer success are crucial. Time to roll your own ELT.",
          "score": 42,
          "created_utc": "2026-02-04 00:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fecpu",
          "author": "No_Lifeguard_64",
          "text": "I empathize with you OP and while I think Fivetran sucks, all these tools in the \"connector\" space are varying degrees of bad so while I would recommend getting off of Fivetran because the amount you're paying is actually crazy, you will run into SOME issue with all of the tools.",
          "score": 42,
          "created_utc": "2026-02-03 22:41:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ff00c",
              "author": "DigitalDelusion",
              "text": "My leadership team is going to make me break contract. This is terrible. We've been down all day and I can't get anyone on the phone, just an email every few hours. \n\nThe value prop is I don't need as many devs here to maintain these pipelines and that I'd have someone to call when things went south. \n\nThat trust is being broken.",
              "score": 31,
              "created_utc": "2026-02-03 22:44:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3gc4wq",
                  "author": "Nottabird_Nottaplane",
                  "text": "This is a disaster on both sides. I‚Äôm shocked FiveTran would allow something like this; that your AEs/CSMs are MIA; that this is all happening. I can also only imagine you‚Äôre panicking a bit since you probably have customers to serve of your own and this is impacting that.\n\nHuman error + rules-lawyering & rigid policy + lazy response = apocalyptic scenarios, every time",
                  "score": 16,
                  "created_utc": "2026-02-04 01:45:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3hfzg0",
                  "author": "C2mind",
                  "text": "I chose airbyte after using fivetran at my last company. Very glad I did. It took a bit to get the infra in place for self hosting but has been smooth sailing ever since. I know you‚Äôre not asking for these kind of recs but just wanted to point out that there are alternatives that you can still manage with a lean team.",
                  "score": 2,
                  "created_utc": "2026-02-04 05:57:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3i31sf",
                  "author": "Thinker_Assignment",
                  "text": "you don't need many devs in this day and age to maintain pipelines if you use stuff with schema evolution, resllience and a little LLMs for maintenance. You can ask a LLM for fixes faster than you can get that out of Saas support.",
                  "score": 2,
                  "created_utc": "2026-02-04 09:22:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3juqgh",
                  "author": "No_Lifeguard_64",
                  "text": "I'm not affiliated with either of these tools but I would recommend looking at [integrate.io](http://integrate.io) or dlthub+. Both of these tools do integration and are based around the idea of very small teams. [Integrate.io](http://Integrate.io) is more tailored to your use-case from what I understand and would cut your Fivetran bill in half. We demoed both of these tools and found that while we liked them, they had shortcomings that made it no go for us but the teams were great.",
                  "score": 2,
                  "created_utc": "2026-02-04 16:09:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3g58w3",
          "author": "Choperello",
          "text": "Fivetran is predatory. The fact DBT sold to them made beyond sad.",
          "score": 29,
          "created_utc": "2026-02-04 01:06:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g7smz",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 16,
              "created_utc": "2026-02-04 01:21:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ikg7h",
                  "author": "StarWars_and_SNL",
                  "text": "Fivetran acquired SQLmesh in September then dbt in October. No months in between. It happened crazy fast.",
                  "score": 8,
                  "created_utc": "2026-02-04 11:55:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3fcygm",
          "author": "Murky_Extension2089",
          "text": "u/DigitalDelusion \\- I'm a PM at Fivetran. I'll DM you to get more details.",
          "score": 30,
          "created_utc": "2026-02-03 22:34:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gc18h",
          "author": "calimovetips",
          "text": "that‚Äôs brutal, especially with reverse-elt where everything is chained together. cutting service with no past due notice or grace period is an ops failure, not a billing one, and 24 to 48 hours is a long time when prod depends on it.",
          "score": 5,
          "created_utc": "2026-02-04 01:44:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gthpc",
          "author": "GreyHairedDWGuy",
          "text": "definitely sounds like some CSM somewhere messed up big time.  There should have been ways to reach someone at your company.  Shutting you off is bush league.\n\nPersonally I like Fivetran.  It allows us to focus on other DE tasks (and let them deal with changing API's...etc).   \n\nHowever, if this happen to us, I'd insist that they provide us at least 3 months free usage and if not.  Look at alternatives or roll your own.",
          "score": 6,
          "created_utc": "2026-02-04 03:24:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gae7t",
          "author": "mertertrern",
          "text": "No customer service? How about no customers then.",
          "score": 3,
          "created_utc": "2026-02-04 01:35:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g84rf",
          "author": "MandrillTech",
          "text": "the 24-48 hour reinstatement after they screwed up the billing is wild. that's basically saying 'we broke it but you get to eat the downtime.' at minimum i'd be documenting everything for contract renegotiation leverage, especially since they confirmed the billing change in writing.",
          "score": 3,
          "created_utc": "2026-02-04 01:22:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ht1pt",
          "author": "Kukaac",
          "text": "This is crazy, as customer support used the be a huge thing for Fivetran. If that's gone all will they have is high prices.",
          "score": 3,
          "created_utc": "2026-02-04 07:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3il50k",
          "author": "Therican85",
          "text": "Just got up tools like Matia. Screw fivetran, I'm sorry, thief-tran",
          "score": 1,
          "created_utc": "2026-02-04 12:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iw261",
          "author": "Used-Comfortable-726",
          "text": "If you‚Äôre considering switching to a more enterprise IPaaS, I recommend **MuleSoft**, especially for Salesforce<>ERP<>EAM<>P2P.  Real-time transactional bidirectional sync across all endpoints is way more efficient than multiple ETL/RETL jobs.  And if you‚Äôre company already has a Salesforce contract, the billing for MuleSoft will just rollup (and optionally co-terminate if you want) into your existing contract, so one less vendor to pay",
          "score": 1,
          "created_utc": "2026-02-04 13:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3j07gp",
              "author": "Nekobul",
              "text": "MuleSoft is dead at this point after the Informatica acquisition.",
              "score": 1,
              "created_utc": "2026-02-04 13:37:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3jnabk",
              "author": "rico_andrade",
              "text": "Celigo is a good option too.",
              "score": 1,
              "created_utc": "2026-02-04 15:35:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3julfd",
          "author": "ClavLos",
          "text": "This is exactly where trust breaks. When your warehouse feeds everything, ‚Äú24‚Äì48 hour reinstatement‚Äù is unacceptable.\n\nI‚Äôm one of the founders at SupaFlow. We‚Äôre an alternative to Fivetran focused on pipeline reliability, sane pricing, and real humans when things go sideways.\n\nNot here to pile on ‚Äî just saying teams shouldn‚Äôt have to accept this as normal.",
          "score": 1,
          "created_utc": "2026-02-04 16:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i2qaz",
          "author": "Thinker_Assignment",
          "text": "# it's trival to replace them in this day and age\n\nNowadays you can replace them in about 1h per pipeline to get the code, and of course a little more to do the actual migration ops and any stitching or backfilling.\n\nI recently ran an experiment where I give an LLM the target model of a saas pipeline and ask it to fill the gap between my current OSS pipeline and the target state.\n\nIt works extremely well in cursor, getting your work done within the hour per pipeline - in my experience not only did claude make the SQL to do the migration, but it also extended the python ingestion side to call more endpoints",
          "score": -4,
          "created_utc": "2026-02-04 09:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ikl23",
              "author": "StarWars_and_SNL",
              "text": "Ok now do that work under the pressure of prod being down",
              "score": 6,
              "created_utc": "2026-02-04 11:56:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3j03v9",
                  "author": "Thinker_Assignment",
                  "text": "I'm not victim blaming and neither should you  \n  \nNothing you can do can bring your pipelines back, or within your control, except migrating away.\n\nPressure can only be released by vendor or by migration. The business is under pressure, why should you accept it, did you choose to give control to a 3rd party? nah it was your manager",
                  "score": -1,
                  "created_utc": "2026-02-04 13:36:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3j01yl",
              "author": "Nekobul",
              "text": "That is a bold-faced lie.",
              "score": 1,
              "created_utc": "2026-02-04 13:36:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3j3hcu",
                  "author": "Thinker_Assignment",
                  "text": "We are seeing 55-60% success rates per session (n=800) with python ingestion pipelines.\n\nAt the event we did at Motherduck's Amsterdam office last week, multiple users presented how they reach first pipelines in 1h.\n\nFor T our current eval shows 70% success rate with 1-shot to bridge the T from raw to a target model like a Saas,\n\nIn work session in cursor that 70% becomes a 95%+ match within 1h\n\nMy guess is by the end of the year multiple players will offers complete end to end automation as a \"starting point\" for AI driven customisation\n\nhere's openAI describing how they take over a stack and replace customisation with a LLM memory layer. [https://openai.com/index/inside-our-in-house-data-agent/](https://openai.com/index/inside-our-in-house-data-agent/)\n\nHere's snowflake describing generating canonical views.  \n[https://x.com/Snowflake/status/2018660572980707741](https://x.com/Snowflake/status/2018660572980707741)\n\nbut you do you man, i see your contributions here and as far as I can tell your opinions are very old school and rigid and lack acceptance of current practices and reealities\n\nEdit: and you can see on our sub how someone migrated their entire stack in 5 days with claude code.",
                  "score": 1,
                  "created_utc": "2026-02-04 13:55:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3fjbzt",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -10,
          "created_utc": "2026-02-03 23:06:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g08j9",
              "author": "AskMeAboutMyHermoids",
              "text": "Your website is so slow.",
              "score": 4,
              "created_utc": "2026-02-04 00:38:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwd5of",
      "title": "Is someone using DuckDB in PROD?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwd5of/is_someone_using_duckdb_in_prod/",
      "author": "Free-Bear-454",
      "created_utc": "2026-02-05 05:51:13",
      "score": 100,
      "num_comments": 53,
      "upvote_ratio": 0.95,
      "text": "As many of you, I heard a lot about DuckDB then tried it and liked it for it's simplicity.\n\nBy the way, I don't see how it can be added in my current company production stack.\n\nDoes anyone use it on production? If yes, what are the use cases please?\n\nI would be very happy to have some feedbacks",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwd5of/is_someone_using_duckdb_in_prod/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3oeowa",
          "author": "ambidextrousalpaca",
          "text": "We've been using DuckDB in production for a year now, running and generating the queries we need with Python code.  \n\nSo far it's gone great. No major problems.\n\nWe switched from developing new pipelines in PySpark to doing so with DuckDB mainly on the basis that:\n\n1. We observed that the actual data loads we were processing were never big enough to necessitate a Spark cluster.\n2. Getting rid of Spark meant we could get rid of the whole complexity of running a JVM using the massive collection of libraries Spark requires (with all of their attendant security vulnerabilities) and replace it with a single, dependency-free DuckDB compiled binary.\n3. When we tested it against Spark on our real data it ran about 10 times faster and used half the resources (and _yes_, I'm sure the Spark code could have been optimised better, but that's what our testing for our specific use-case showed).\n\nPoint 3 was the major one that allowed us to convince ourselves this was a good idea and sell it to management.",
          "score": 128,
          "created_utc": "2026-02-05 07:02:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3or0x0",
              "author": "CAPSLOCKAFFILIATE",
              "text": "> actual data loads we were processing were never big enough to necessitate a Spark cluster.\n\nThe first step towards living an easy life is realizing we overcomplicate things without actual need. There is no \"big data\" in corporate, unless you work in MAG7, major banks or AI labs. 95% of companies can run just fine with DuckDB, and that's assuming they ever leave Excel as \"data management backend\".",
              "score": 53,
              "created_utc": "2026-02-05 08:57:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qtg7i",
                  "author": "reelznfeelz",
                  "text": "For sure.  People are quick to reach for these powerhouse tools but you really should consider if you need them.   Postgres, or apparently duckDB, can take you quite far.",
                  "score": 3,
                  "created_utc": "2026-02-05 16:52:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3uv1af",
                  "author": "turboDividend",
                  "text": "yes. i never got too interested in learning about 'real data engineering' because so few places actually really need it unfortunately. Most corporate enviroments are not dealing with big data. I have personal projects that actually generate/consume more data than some places ive worked at",
                  "score": 2,
                  "created_utc": "2026-02-06 06:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3oma84",
              "author": "CulturMultur",
              "text": "Yeah, Spark infrastructure completely sucks. But, Dataframe API vs templated SQLs are very different, and whenever trend is to start programming with templating (dbt macros, I‚Äôm looking at you) - I would not put any important business logic under templating. With Spark I can isolate logic into pure functions - dataframes in, Dataframe out -and test it. With templating - nope.",
              "score": 10,
              "created_utc": "2026-02-05 08:12:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3p11fb",
                  "author": "Difficult-Tree8523",
                  "text": "We use SQLFrame to get a pyspark compatibility API",
                  "score": 5,
                  "created_utc": "2026-02-05 10:34:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3r0g08",
                  "author": "New-Addendum-6209",
                  "text": "Could you provide an example of one of these pure functions and how you test it?",
                  "score": 2,
                  "created_utc": "2026-02-05 17:25:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ol9zk",
              "author": "Free-Bear-454",
              "text": "Very interesting feedback! Where do you run DuckDB though? What is the infra and architecture if you can talk about it?",
              "score": 5,
              "created_utc": "2026-02-05 08:02:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q8741",
                  "author": "ambidextrousalpaca",
                  "text": "There's very little. Just running it on Linux boxes in the cloud. That's the beauty of it. Simple.",
                  "score": 1,
                  "created_utc": "2026-02-05 15:13:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ovsug",
              "author": "singinggiraffe",
              "text": "Is spark and duckdb comparable? I don't know much but I thought spark was abiut distributed computing and duckdb is a tabular database optimized for longer tables or something, no?",
              "score": 3,
              "created_utc": "2026-02-05 09:44:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q2h8w",
                  "author": "Keizojeizo",
                  "text": "They are comparable in the sense that they write transformations in SQL - not exact same dialect but very close. They both can read and write csv, parquet, etc.\n\nOften those are the only features that people are really using from each engine.\n\nSpark is optimized for distributed compute, and duckdb is meant to execute within a single process. Spark has more overhead, always, than duckdb, and one could argue is only worth it if the data size is absolutely massive such that the data can‚Äôt fit on a single machine.",
                  "score": 4,
                  "created_utc": "2026-02-05 14:44:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3q8fco",
                  "author": "ambidextrousalpaca",
                  "text": "DuckDB actually does a better job of parallelizing queries across process cores than Spark does, based on our testing and monitoring of memory and CPU usage.",
                  "score": 2,
                  "created_utc": "2026-02-05 15:14:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ofru0",
              "author": "Difficult-Tree8523",
              "text": "+1 share same experience¬†",
              "score": 5,
              "created_utc": "2026-02-05 07:11:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o76xj",
          "author": "putokaos",
          "text": "It all depends on the size, complexity, and purpose of your stack. In my case, we use DuckDB to detach some queries from Snowflake that even with the smallest compute engine size, would be an overkill, so it's very useful with our processing pipelines. Aside from that, DuckDB is fantastic for Data Analysts, as they can make use of their computers instead of draining resources from the DWH. We also use it in its WASM version as part of the Evidence.dev stack, which nurtures a lot of our dashboards.",
          "score": 25,
          "created_utc": "2026-02-05 05:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3olg3x",
              "author": "Free-Bear-454",
              "text": "Can you tell us about how it works please? Are you using DBT or something else to handle transformations?",
              "score": 2,
              "created_utc": "2026-02-05 08:04:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3p446f",
                  "author": "putokaos",
                  "text": "We mainly use dbt for transformations, so, for some of them we use DuckDB, and for some others, we use Snowflake. That said, to make this possible you must work with external tables in Snowflake, as our architecture is based on a Data Lakehouse. You'd also need an orchestrator, such as Dagster, as dbt has some limitations in this regard, especially if you want to maintain lineage. Regarding the execution engine, it's fair to say that there are alternatives that allow you to route your queries dynamically, such as Greybeam. But they are still in a very early stage.",
                  "score": 7,
                  "created_utc": "2026-02-05 11:01:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3onyal",
          "author": "ppyil",
          "text": "Yes, heavily using DuckDB. We work with less data than most companies here I suspect, enough that tables used for analytics can be loaded into instances of our webserver in-memory for extremely quick data analytics on the front end.\n\nSo each instance is a Docker image running Django and periodically redownloading the latest DuckDB file (which is an output of our data pipeline elsewhere) and then allowing for views to be constructed via direct access to DuckDB.\n\nI've been thinking about building a proper database driver between Django and DuckDB but for now, a combination of generating direct SQL and using polars have given us everything we need.",
          "score": 12,
          "created_utc": "2026-02-05 08:28:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3otnuj",
              "author": "ILoveBNTC",
              "text": "Very interested in this. We currently run a django backend that has some slow queries consumed by our frontend and have already been optimized.\n\nWould you be able to share how this integration works?",
              "score": 3,
              "created_utc": "2026-02-05 09:23:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pbgu5",
                  "author": "ppyil",
                  "text": "We've got a cron job that downloads the latest duckdb file from S3 periodically, every 15 mins or so. Luckily our final DuckDB file is pretty small, about 30MB and so we can easily just download and use",
                  "score": 1,
                  "created_utc": "2026-02-05 12:02:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3okark",
          "author": "PrinceN71",
          "text": "I do. It's very useful although currently only a very small part. Traditionally my company uses sql in database but seeing the performance benefits of duckdb, my company is planning on using a data lake like delta lake and duck DB to do the processing\n\nCurrently my biggest issue I'm trying to figure out is how I want to update the data in delta tables because I'm mainly using polars to insert the data. I don't really have much experience in this but if anyone has any tips on how I can update delta tables using polars instead of pyspark I am all ears",
          "score": 3,
          "created_utc": "2026-02-05 07:53:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p9fuj",
              "author": "commandlineluser",
              "text": "What trouble are you having exactly?\n\nThere's many examples in the delta tests:\n\n- https://github.com/pola-rs/polars/blob/0c179b5c3edcbfd9db8745507931781327950a9d/py-polars/tests/unit/io/test_delta.py#L576-L601\n\n(`LazyFrame.sink_delta()` was also added in 1.37.0)",
              "score": 1,
              "created_utc": "2026-02-05 11:46:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3uh0b8",
              "author": "losh-purler",
              "text": "Since you're in the process of figuring out your data lake, I'd suggest you check out DuckLake from DuckDB themselves. I haven't used it personally yet.\nhttps://www.youtube.com/watch?v=zeonmOO9jm4",
              "score": 1,
              "created_utc": "2026-02-06 04:22:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3oliod",
              "author": "Typical_Priority3319",
              "text": "I‚Äôm not going to tell you to not do it in Polars but what I will say is that you‚Äôre going to have a MUCH easier time just doing it in spark imo. That is if you can figure out how to get a spark instance up and running in demand (I just use glue typically)",
              "score": 0,
              "created_utc": "2026-02-05 08:05:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3om2tj",
                  "author": "PrinceN71",
                  "text": "Then I think I will just stick with spark for now. I can sacrifice abit of performance and resource if it's easier to work with",
                  "score": 2,
                  "created_utc": "2026-02-05 08:10:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3q6flx",
              "author": "shockjaw",
              "text": "Ibis supports spark if you need it to. You can switch to other coding backends if you need to without code changes.",
              "score": 0,
              "created_utc": "2026-02-05 15:04:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o6rea",
          "author": "nonamenomonet",
          "text": "If you‚Äôre using a severless function for some lighter weight ETL it can be used.",
          "score": 4,
          "created_utc": "2026-02-05 05:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3olryi",
          "author": "CulturMultur",
          "text": "We use DuckDB in production. Our dwh is Snowflake and I built a tool that runs worksheets (series of SQL statements) in Snowflake with little templating (Go text/template library). Some workloads started using Snowflake as an engine - in worssheet query from s3 and copy back to s3 immediately.\n\nThen we added support to DuckDB instead, now all processing happens inside the tool, so paying AWS instead of Snowflake.\n\nHowever, working with big parquets is still better in Snowflake - maybe it‚Äôs me, but ‚Äúselect from s3://prefix-with-parquets limit 100‚Äù hangs in DuckDB while taking 100ms in Snowflake.",
          "score": 2,
          "created_utc": "2026-02-05 08:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ooa98",
              "author": "linos100",
              "text": "At what sizes are you having issues with parquets in duckdb? Where is duckdb running? (I assume the mentioned tool in \"...inside the tool...\" is duckdb)",
              "score": 2,
              "created_utc": "2026-02-05 08:31:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3omyja",
              "author": "Free-Bear-454",
              "text": "Please let me understand, you migrated all of Snowflake workloads to DuckDB?",
              "score": 1,
              "created_utc": "2026-02-05 08:18:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3vdagd",
                  "author": "CulturMultur",
                  "text": "No, only those that used Snowflake as engine (without storage - so read from s3, write to s3) - those we migrated to either DuckDB (simple workloads) or Spark (workflows with complex business-logic).",
                  "score": 0,
                  "created_utc": "2026-02-06 08:49:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3osziz",
          "author": "pra__bhu",
          "text": "we use it for ad-hoc analytics and local development but not as a primary production db\nthe sweet spot ive found is:\n\t‚àô\trunning queries against parquet/csv exports without spinning up a full warehouse\n\t‚àô\tprototyping analytics pipelines before pushing to snowflake\n\t‚àô\tinternal tools where you need fast aggregations but dont need concurrent writes\nthe limitation is it‚Äôs single-process - no concurrent write access, so anything with multiple users writing data simultaneously is a no-go. reads scale fine though\nseen some teams embed it in data apps where users query pre-built datasets, works great for that. but if you need a traditional multi-user transactional system it‚Äôs not the right tool\nwhat‚Äôs your use case? might be able to give a more specific take‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 2,
          "created_utc": "2026-02-05 09:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pil1h",
          "author": "Thinker_Assignment",
          "text": "using it for (ELT)->L\n\ncanonical on duckdb then load",
          "score": 2,
          "created_utc": "2026-02-05 12:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pt6l5",
          "author": "ghost-in-the-toaster",
          "text": "I use it for a small internal web app. I chose it because 1) I needed complex data structures and 2) as a tool that would get infrequent use, I wanted to limit it‚Äôs resource consumption (disk-only data store and no separate service running). Otherwise, Postgres is what our company uses.",
          "score": 2,
          "created_utc": "2026-02-05 13:54:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q650k",
          "author": "shockjaw",
          "text": "Yup! Using it as a sink for data when I have to pull user information from Active Directory, a website, and another user directory. Have to reconcile all three to make sure they match or certain exceptions are met. It‚Äôs real nice to front load the LDAP query and not have to deal with latency unless I need to reach back out to Active Directory.",
          "score": 2,
          "created_utc": "2026-02-05 15:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3svjf2",
          "author": "JBalloonist",
          "text": "Yes. I‚Äôm running it in MS Fabric Python notebooks because Spark is overkill (spare me the hate‚Ä¶I know it‚Äôs not as good as other platforms but it works for our SMB). \n\nQuery raw parquet in my data lake and load to Bronze tables. Query Bronze and load to silver. Most of the logic is in the SQL. \n\nThere are a few exceptions where I have to use Pandas to add some additional business logic.",
          "score": 2,
          "created_utc": "2026-02-05 22:43:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oqyx0",
          "author": "blockchan",
          "text": "Hex.tech is using it in analytics layer as in memory db. Works v ery nice",
          "score": 1,
          "created_utc": "2026-02-05 08:57:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3or1ux",
          "author": "hoselorryspanner",
          "text": "I use it in a severless Vue app to speak to a parquet datalake. Works a treat for smallish (<10k records) tables.\n\nWhether or not you‚Äôd call this prod is a different story: it‚Äôs a web viewer for an intake catalog, just aiming to make life easier for our users.",
          "score": 1,
          "created_utc": "2026-02-05 08:57:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p1dx3",
          "author": "undergrinder_dareal",
          "text": "We use duckdb as processing engine mostly, very statisfied. Our use case is like duckdb as a pandas replacement, but in fact we never used pandas, but spark with low utilization or some kind of SQL Server.",
          "score": 1,
          "created_utc": "2026-02-05 10:37:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q1nhq",
          "author": "calimovetips",
          "text": "yes, but usually in narrow roles, not as a central warehouse. i see it used for embedded analytics, batch feature generation, or ad hoc transforms inside pipelines where spinning up infra is overkill. it works well when data fits on disk and concurrency is low, it falls apart once you expect shared state or lots of writers. what part of your stack are you thinking of replacing or augmenting with it?",
          "score": 1,
          "created_utc": "2026-02-05 14:40:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q5b06",
          "author": "phonyfakeorreal",
          "text": "We load user uploads into SQLite for intermediate processing, and I desperately want to replace it with DuckDB for its excellent column type detection",
          "score": 1,
          "created_utc": "2026-02-05 14:59:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q9crw",
          "author": "Lucky_Badger_",
          "text": "We also use it as a pandas replacement in our data pipelines . Files -> DuckDb ->  Postgres, Postgres tables -> DuckDb -> Postgres. In our event driven architecture its fantastic using it with Python. We break up the transformations into methods and we have a nice little library we have created to help us create datasets we can use in our unit tests. Loving it so far. \n\nIt does use floating point division, but we created a python udf that allows use to Pythons Decimal type which has solved that issue for us",
          "score": 1,
          "created_utc": "2026-02-05 15:19:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qoyqu",
          "author": "licyeus",
          "text": "We use it in a prod data pipeline to regularly ingest+process 10s of billions of rows of time series data. We load CSV, run a bunch of transforms + checks, and write parquet into blob storage. We wrote our own orchestration framework (though if starting over, we'd likely use dbt or sqlmesh).\n\nIt's been pretty solid, minus one problem with k8s killing the pod when it thinks it's OOM (we work around this by processing in batches).\n\nInfrastructural simplicity is the biggest benefit, IMO.",
          "score": 1,
          "created_utc": "2026-02-05 16:32:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qs1ur",
          "author": "full_arc",
          "text": "We use it very heavily at Fabi.ai\n\nAwesome for caching and quick processing for our users. Basically when you retrieve data that‚Äôs what we use to store it and reduce the load on the DB and avoid running up compute for our customers as the business vibes their way through an analysis. It also makes report loading super quick.",
          "score": 1,
          "created_utc": "2026-02-05 16:46:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3quful",
          "author": "hornyforsavings",
          "text": "We (Greybeam) help companies use DuckDB with their Snowflake workloads in production. We likely have the second or third largest DuckDB production clusters next to Motherduck and Coginiti",
          "score": 1,
          "created_utc": "2026-02-05 16:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qxg2a",
          "author": "PinkFrosty1",
          "text": "I use DuckDB for real-time and in-memory data transformations within my machine learning inference data pipeline.",
          "score": 1,
          "created_utc": "2026-02-05 17:11:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r0jf2",
          "author": "theManag3R",
          "text": "I set up a dataplatform for my friend who's a founder of a startup. I wanted to try how Ducklake fits prod and while there are some caveats, it's performing quite well.\n\nI have a dockerized app running Superset, which is. connected to Ducklake. Metadata for both Superset and Ducklake is running in Postgres (on another container) and data is on S3.\n\nPython scripts are transforming some raw data and inserting it to Ducklake.\n\nIt has been a very pleasant experience so far",
          "score": 1,
          "created_utc": "2026-02-05 17:26:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vngfl",
          "author": "BusOk1791",
          "text": "Question:  \nWhat about sync to Power-BI, does anyone use DuckDB & PowerBI combined?  \nIf so, how do you handle Power-BI synchronizing the data from Duck?",
          "score": 1,
          "created_utc": "2026-02-06 10:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vtkw4",
          "author": "peterv50",
          "text": "We use it in production mainly for analytics/log storage because it‚Äôs fast, multi-threaded, and compresses insanely well (for us it beats MySQL even with InnoDB compression).\n\nWe write logs as Parquet and use DuckDB to query/aggregate directly on those files. That gives us cheap storage + quick ad-hoc queries without running a heavy warehouse for this workload.",
          "score": 1,
          "created_utc": "2026-02-06 11:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o7zj8",
          "author": "Acceptable-Sense4601",
          "text": "As a data analyst, i use it in report automation to store intermediate data. So the report starts with CSV files that need to be cleaned and manipulated. The result of that stage is stored in DuckDB, then the rest of the automation pulls data from that DuckDB file.",
          "score": 1,
          "created_utc": "2026-02-05 06:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3okz5j",
              "author": "Free-Bear-454",
              "text": "Is it some kind of adhoc/local work or production one? I mean something with orchestrated pipelines, CICD, deployments, whatever...",
              "score": 1,
              "created_utc": "2026-02-05 08:00:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3p9sw3",
                  "author": "Acceptable-Sense4601",
                  "text": "It‚Äôs either me downloading CSV‚Äôs with the raw data or me extracting the data from the production database (the CSVs come from the same place but i only have the back end access to some of it at the moment). But the data goes into reports that are used by senior leadership.",
                  "score": 1,
                  "created_utc": "2026-02-05 11:49:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1quvm92",
      "title": "Are we all becoming \"Full Stack-something\" nowadays?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1quvm92/are_we_all_becoming_full_stacksomething_nowadays/",
      "author": "HungryRefrigerator24",
      "created_utc": "2026-02-03 15:54:07",
      "score": 83,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "Whats up?\n\nWithout further ado... I've found myself in the position where I went from a standard data engineer where I took care of a couple of data services, some ETLs, moving a client infrastructure from one architecture to another...\n\nNowadays I'm already designing the 6th architecture of a project which includes Data Engineering + AI + ML. Besides doing that I did at the start, I also develop and design LLM applications, deploy ML algorithms, create tasks and project plannins and do follow-up with my team. I'm still a \"Senior DE\" on paper but I feel like a weird mix of coordinator (or tech lead whatever u call) and a \"Full Stack Data\" since I'm working in every step of the process. Master of none but an improviser of all arts.\n\nI wonder if this is happening at other companies or in the market in general?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1quvm92/are_we_all_becoming_full_stacksomething_nowadays/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3d0cat",
          "author": "Former_Disk1083",
          "text": "It's a mixture right now, but yes a lot of the market is like that. It's just companies hear \"AI\" and think they just need someone to push a button but it still requires lots of knowledge and understanding how they need to cleanse the data and hyperparameter tuning and understanding what model works best for what and all that. There was a small period in time, and maybe it's still true, where it was just throw XGBOOST at it and go sip your coffee, and thats what a lot of folk were doing. But that does a disservice to a lot of the actual data scientists out there doing the maths and actually understanding inputs and outputs.\n\nI guess I ranted a bit there, the short story long is, yes, that is common, and I typically avoid it if I can. But you sometimes have to do what the market dictates even if it's not sustainable.",
          "score": 21,
          "created_utc": "2026-02-03 16:01:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gswvl",
              "author": "LilParkButt",
              "text": "XGBoost does perform well pretty often though üòÇ",
              "score": 6,
              "created_utc": "2026-02-04 03:20:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3gu6ub",
                  "author": "Former_Disk1083",
                  "text": "Yeah I had a feeling not much has changed with that hahaha. Hard to beat the thing that just works.",
                  "score": 1,
                  "created_utc": "2026-02-04 03:28:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3d0a1m",
          "author": "SoggyGrayDuck",
          "text": "Yeah, it's going to happen eventually. Now management doesn't have to get involved in those pesky details that used to justify their pay. Hell mine can't even escalate problems correctly. It's like they put a quarterly PowerPoint together and sit back until quarters end and see how things shook out. They've successfully separated their individual success or failure from the teams success/failure. It's the most absurd thing I've seen and they're only getting away with it due to the shortage. I wouldn't put it past some conspiracy plan enacted to knock devs down from their high perch they got to during COVID, working multiple jobs in just 40 hour weeks. \n\nIt's just the managers/leaders taking another step away from responsibilities",
          "score": 16,
          "created_utc": "2026-02-03 16:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d9win",
              "author": "Skullclownlol",
              "text": "> It's just the managers/leaders taking another step away from responsibilities\n\n100%, exact same pattern is happening in my experience. It doesn't always mean roles become full-stack, sometimes departments are being scrapped.",
              "score": 2,
              "created_utc": "2026-02-03 16:46:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3di7b3",
                  "author": "SoggyGrayDuck",
                  "text": ">sometimes departments are being scrapped.\n\nYep, cut and replaced with a 3rd party company that is based out of India. I think it's a loophole around the 100k fee. You're not technically bringing in foreign workers to replace US workers, you're just hiring another company to do the work for you.",
                  "score": 2,
                  "created_utc": "2026-02-03 17:24:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3fu2tn",
              "author": "x246ab",
              "text": "Most managers exist to buffer the incompetence above them",
              "score": 2,
              "created_utc": "2026-02-04 00:05:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3fv9yc",
              "author": "HungryRefrigerator24",
              "text": "Im really curious about what the PM and my manager really does because im the one doing the project architecture, creating the project planning, the tasks, giving the tasks, so on..",
              "score": 1,
              "created_utc": "2026-02-04 00:11:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3d0mr3",
          "author": "ManyMuchMoosenen",
          "text": "‚ÄúT-shaped‚Äù seems to be an increasingly popular buzzword. Deep knowledge in a one/few areas but broad enough knowledge to contribute and assist in other areas.",
          "score": 12,
          "created_utc": "2026-02-03 16:02:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3d0fsb",
          "author": "EmotionalSupportDoll",
          "text": "I feel like we're all being asked to do more with less these days. Good in terms of learning opportunities, but obviously burdensome at times.",
          "score": 8,
          "created_utc": "2026-02-03 16:01:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ibr05",
              "author": "HungryRefrigerator24",
              "text": "I agree with you in terms of learning opportunities, but where is the line that you dont cross? Or are we at the point we're data will be expected to be \"full stack\" without any payment adjustment?",
              "score": 1,
              "created_utc": "2026-02-04 10:43:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e6e9z",
          "author": "kaapapaa",
          "text": "instead AI/ML, I take care of Platform Engineering/CICD.",
          "score": 2,
          "created_utc": "2026-02-03 19:13:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nmpwn",
              "author": "FarFaithlessness8812",
              "text": "I genuinely suck at CI/CD, can you point me to some sort of path on how to learn about it?",
              "score": 1,
              "created_utc": "2026-02-05 03:36:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ob2bl",
                  "author": "kaapapaa",
                  "text": "You can start with git, docker, git actions, terraform.",
                  "score": 1,
                  "created_utc": "2026-02-05 06:30:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3i4vom",
          "author": "Thinker_Assignment",
          "text": "Did you see my post from last week? that's what i'm seeing across 15% of the industry, and i think it's going to be the end state by end of year. Also AE is getting replaced - see the recent openai, snowflake about semantic views and feedback memory layer - so it looks to me like it's 3 options for people: go fullstack, stay in (shrinking) legacy until it dies, or get unemployed.",
          "score": 1,
          "created_utc": "2026-02-04 09:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ic41t",
              "author": "HungryRefrigerator24",
              "text": "The post with the funny image and pathways? I did although I believe that ML Engineer is also part of the \"Builder\" stack since ML Engineering also depends heavily in pretty much software engineering and Data Engineering. Perhaps I might be wrong but that's my viewpoint since Im also asked to do pretty much everything Engineering-like at work. \n\nWhat comes to my mind often is that if I were in this position years ago I'd be making 10K but seems that being Full Stack in Data is becoming a norm. Companies asking for a lot and paying close to nothing",
              "score": 1,
              "created_utc": "2026-02-04 10:46:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3jy0wb",
                  "author": "Thinker_Assignment",
                  "text": "Yeah. The reason i left ML to the side is because I do not see the other data roles getting into ML - they get into ML engineering. I do also see ML people now going down the stack and owning ingestion to AI. So this makes the ML specialist a bit unique in my view.\n\nand you're right - I was freelancing as full stack DE before starting this company (9-4y ago), the rate for that kind of work was usually in the 90-150 euro/h range",
                  "score": 1,
                  "created_utc": "2026-02-04 16:24:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iiy6i",
          "author": "EviliestBuckle",
          "text": "Can you share ai application tutorials you followed?",
          "score": 1,
          "created_utc": "2026-02-04 11:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ofhif",
          "author": "Ancient_Ad_916",
          "text": "I got hired as Business Intelligence Engineer, it includes data engineering (ETL, data modeling), data analysis (provide BI automation), and some data science (optimization). So I suppose you‚Äôre correct",
          "score": 1,
          "created_utc": "2026-02-05 07:09:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxifq4",
      "title": "Is classic data modeling (SCDs, stable business meaning, dimensional rigor) becoming less and less relevant?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxifq4/is_classic_data_modeling_scds_stable_business/",
      "author": "Likewise231",
      "created_utc": "2026-02-06 14:02:24",
      "score": 80,
      "num_comments": 30,
      "upvote_ratio": 0.95,
      "text": "I‚Äôve been in FAANG for about 5 years now, across multiple teams and orgs (new data teams, SDE-heavy teams, BI-heavy teams, large and small setups), and one thing that‚Äôs consistently surprised me is how little classic data modeling I‚Äôve actually seen applied in practice.\n\nWhen I joined as a junior/intern, I expected things like proper dimensional modeling, careful handling of changing business meaning, SCD Type 2 being a common pattern, and shared dimensions that teams actually align on ‚Äî but in reality most teams seem extremely execution-focused, with the job dominated by pipelines, orchestration, data quality, alerts, lineage, governance, security, and infra, while modeling and design feel like maybe 5‚Äì10% of the work at most.\n\nEven at senior levels, I‚Äôve often found that concepts like ‚Äúensuring the business meaning of a column doesn‚Äôt silently change‚Äù or why SCD2 exists aren‚Äôt universally understood or consistently applied. In tech-driven organizations it is more structured, but in business-driven organizations it's less structued (Organization I mean ¬±100-300 people organization).\n\nMy logic is because compute and storage got so much cheapier over the years, the effort/benefit ratio is not there in as many situations. Curious what others think: have you seen the same pattern?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxifq4/is_classic_data_modeling_scds_stable_business/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3wqclv",
          "author": "JonPX",
          "text": "And then people wonder why data projects are so prone to failure.",
          "score": 96,
          "created_utc": "2026-02-06 14:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wlhq8",
          "author": "cream_pie_king",
          "text": "Yes.\n\nIt's because individual teams spin up their own analysts. Which then brute force their way into basically being shadow engineers. All in the name of \"faster time to insight\".\n\nProblem is, people leave, people shuffle around, people get promoted. No one aligns on what the metric really should be.\n\nIt eventually blows up in everyone's face when multiple versions of the same number hit the desks of execs and the board.\n\nThese embedded analyst fiefdoms resist change and take it as a personal insult when you tell them their 5000 line query that feeds one report is garbage, not scalable, and you can't run a business like this. \n\nYou're then targeted as slowing things down for trying to put real rigor into the data platform.\n\nI'm leaving an environment like this in a week. For a greenfield opportunity to build the stack from scratch precisely because I'm tired of this bullshit.\n\nI don't care about the minor and bootcamp you took in SQL and Python. That shit can't run a multi billion dollar business long term.\n\nHell I'm seeing intern built \"data science\" workloads being deployed. They're \"version controlled\" in SharePoint and run locally to push to reporting. When we push back it's our fault.",
          "score": 86,
          "created_utc": "2026-02-06 14:17:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wphxu",
              "author": "hectorgarabit",
              "text": ">¬†take it as a personal insult when you tell them their 5000 line query that feeds one report is garbage\n\nSome head of Analytics / BI told me, when I proposed some dimensional modeling that they were not interested in \"philosophy\". Their model is chaos and they spin countless hours untangling their spaghetti data model. They feel smart because they wrote a 1000 lines SQL query or Python notebook. They don't understand that they would be a lot smarter if their model was clean enough, so the same query only took 10 lines...\n\nThe main issue IMO is that many people come from a non-technical background, and they don't understand how data model, architecture solve the vast majority of development problems.",
              "score": 38,
              "created_utc": "2026-02-06 14:38:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3wytyj",
              "author": "domscatterbrain",
              "text": "I always warn my manager to not to give users the freedom of running their own statements. Just drag and drop filters and pivot in their own custom dashboard is more than enough.\n\nToday by the power of chatgpt, they start creating more spaghetti. Their submitted statements looks very structured at a glance. But since, they don't give enough contexts to prompt and just copying their costly statements as is and  simply said \"this query is slow, optimize it\", the result is just anInstagramable spaghetti.",
              "score": 2,
              "created_utc": "2026-02-06 15:25:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xeot8",
              "author": "calaelenb907",
              "text": "Well, when you started with a green field to build an analytical system eventually you'll face the same problems you mentioned previously. People will like how your reports are accurate, faster and easier to navigate then previous ones but eventually they will target you as a person that slow things for put real rigor into the data platform yadada. Business people will act as business people even if the project is new.",
              "score": 1,
              "created_utc": "2026-02-06 16:40:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wx36m",
          "author": "tophmcmasterson",
          "text": "No. \n\nThere are lots of people who don‚Äôt understand it and brute force implement sloppy bad practices for ad-hoc reporting. \n\nAnd then inevitably end users end up upset that the data is inflexible, report builders in tools like Power BI are seeing unexpected results, they need to make a new table or view every time they want to cross analyze things across tables, etc. \n\nAnd then the org calls on the person or consultant that actually understands data modeling to figure out where things went wrong. Or they just continue the cycle. \n\nIt‚Äôs not that it‚Äôs less relevant, it‚Äôs that there‚Äôs a huge number of developers who never understood it in the first place and think it‚Äôs not relevant because compute is faster and storage is cheap when those were never the main reasons to create a dimensional model in the first place.",
          "score": 11,
          "created_utc": "2026-02-06 15:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wwr5r",
          "author": "123456234",
          "text": "A few forces are pushing modeling out of the center:\n\n* Storage and compute keep getting cheaper, so the pressure to model everything 'correctly' up front is lower.\n* Dimensional modeling isn‚Äôt valuable by itself. Its real value is allowing systems to adapt as business meaning changes over time, and that benefit is easy to defer.\n* Tech debt is real, and under delivery pressure the cleanup backlog rarely wins. Even when modeling could be part of the design, timelines usually cut it first.\n* Storing source data indefinitely is becoming common, which makes replaying historical transformations feel like an acceptable substitute for managing change semantics.\n* Data teams are increasingly embedded in business units. Without a central steward, consistency across domains erodes even when the same underlying data is reused.\n* AI increases speed and lowers the cost of repetitive work, which further shifts effort toward shipping and iteration rather than integration rigor.\n* The idea of a single source of truth still matters philosophically, but if leadership doesn‚Äôt care when numbers don‚Äôt line up exactly, it‚Äôs hard to justify enforcing it.\n\nThe common thread is that modern data systems are optimized for reversibility rather than correctness. Cheap compute, infinite retention, replayability, and AI assisted iteration all increase tolerance for semantic drift. Dimensional modeling still addresses that problem, but its value only materializes when the organization is forced to care about consistency over time. \n\nModeling is rejected in favor of these other mechanisms which isn't a better approach but it does align with the systems that are readily available.",
          "score": 27,
          "created_utc": "2026-02-06 15:15:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wxnos",
          "author": "RoomyRoots",
          "text": "LOL, no. The problem is that many companies think they are or they must be like FAANG sized ones with data projects to be successful with data products.\n\nIn the past 20 years most of the companies I worked wouldnt even be considerable to Big Data solution but still they would sink lots of money to try to mimic it.",
          "score": 7,
          "created_utc": "2026-02-06 15:19:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x5xrf",
          "author": "El_Guapo_Supreme",
          "text": "I agree with a lot of this, except the last bit about the effort to benefit not being there because of cost. You are right that compute got so cheap and efficient that people can be sloppy about architecture. \n\nBut the benefit still far exceeds the costs. The problem is leadership has a bias for action and expediency. It's hard to explain the proper modeling and architecture will make everything faster and easier down the road. \n\nBut will you get a reward for taking longer to do it correctly or fix what's broken? No. And if you have a great model, you'll never be able to point to problems that never manifested and how much time you saved. To the business it looks like you just took a long time.",
          "score": 5,
          "created_utc": "2026-02-06 15:59:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xg6cl",
          "author": "ding_dong_dasher",
          "text": "No they're just as relevant as before, it's just that enough platform engineers are clueless enough to not realize that this same failure-state has existed in our domain forever.\n\nIt's just in 2003 analysts were circumventing Oracle-based DW's in Excel instead of DS's marring your precious DBX deployment with AI slop.\n\nIt points to the same root cause of there having been a business need for something that the existing environment couldn't serve quickly enough. Nobody is going to tell some SVP who needs an answer yesterday that your first step is to attend the DE team's next backlog grooming session lol.\n\nThat's always going to happen and is just a reality of operating platforms used for decision support, if it feels like an adversarial thing you're probably looking at org dysfunction, not an architectural problem. Digesting analytical output and turning it into a mature reporting product is a pretty normal responsibility for data teams, imo.",
          "score": 4,
          "created_utc": "2026-02-06 16:47:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xhpi2",
          "author": "Rovaani",
          "text": "Infinite storage and compute won't help solve the problem if sales, manufacturing and logistics can't agree on what a  \"product\" or \"customer\" is or isn't and when their respective operational systems reflect that dichotomy and use different terms for same things ans same or similar terms for different things.\n\nTo solve that you need data modelling. Introduce your own terms or concepts if need be and map the source models to that. Then you can escape the trap of trying to understand several incompatible data models simultaneously just to feed the next dashboard.",
          "score": 3,
          "created_utc": "2026-02-06 16:54:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ydgc5",
          "author": "kxlx_rxvi",
          "text": "I'm an entry level data engineer who started working a few months back, took courses on data warehousing and data modeling during college learnt the basics of SCDs, designing schemas and everything and loved doing it as hard as it was but haven't used any of these concepts even once so far at work.\nMakes me wonder why I spent sleepless nights learning all of these.",
          "score": 3,
          "created_utc": "2026-02-06 19:25:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x8tbv",
          "author": "Ploasd",
          "text": "Modelling is still important, if anything more important.",
          "score": 2,
          "created_utc": "2026-02-06 16:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xd539",
          "author": "zx440",
          "text": "I'd say that \"traditional\" data modelling was becoming too rigorous, to heavy, and not agile. People were applying rules and methodologies blindly, without any real driver or value proposition. \n\nSo people went around it and went back to a tactical way of doing things. \n\nThere needs to be a middle ground. I think Data Contracts and Data Mesh are two of the very promising ways of implementing order in a chaotic data world within big (and small) enterprises. \n\nNot every data set needs SCD modelling. Not every team is ready to create a semantic layer, and you need to let people play around with the \"raw\" data before seeing a model emerge. A more decentralized data modelling approach is much more adapted for a modern world. ",
          "score": 2,
          "created_utc": "2026-02-06 16:33:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xy29b",
              "author": "cream_pie_king",
              "text": "Except that's not the reality of how everyone operates. They look at the raw data, hack together endless shadow pipelines and reports, management pushes for the next shiny thing and this tech debt becomes embedded in the org and the resulting data is shared broadly.",
              "score": 2,
              "created_utc": "2026-02-06 18:12:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3yb2ji",
                  "author": "zx440",
                  "text": "Yes, of course. I've been working to implement decentralized data approach for years. We has some success, but there's huge resistance from both sides.\n\n\"Traditionnal\" BI teams want to control everything and be in charge of all modeling, but are unable to deliver. Data consumers view any attempt at structuring their work as impeding their progress...\n\nBut eventually, they start to see the benefit of a more decentralized approach. BI team get a bit of air and can focus on platforming and infrastructure. Data consumers get the benefit of collaboration between teams that often run into the same issues.\n\nBut then management comes in, views decentralization as a menace to society, and just puts an end to this and force everyone to use the BI team... and we're back to square one...",
                  "score": 2,
                  "created_utc": "2026-02-06 19:14:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xwsp1",
          "author": "konwiddak",
          "text": "So I work for a company which several years ago purchased a drag and drop ETL tool, and handed out licenses to anyone who asked. It's an absolute mess. The tool is very expensive, and people have built these business critical monstrosities. There are workflows with over 70 inputs and outputs. IT wasn't really keeping tabs on the tool and are shitting a brick now they've realised what's out there propping up the business.\n\nFortunately there was a leader who let a few of us in the background do things properly. We've been unpicking one segment of the business for about 3 years now - and we're just finally getting to the point where people are going \"oh wow we get it now\". However, it's a constant battle to keep things under control and lots of people see us as the enemy.\n\nIf you can start well, do start well.",
          "score": 2,
          "created_utc": "2026-02-06 18:06:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xqlmo",
          "author": "turboDividend",
          "text": "time is money. if the product works...what diff does it make?\n\nthats how mgmt look at things",
          "score": 1,
          "created_utc": "2026-02-06 17:36:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xrrda",
          "author": "OGMiniMalist",
          "text": "I‚Äôve had 3 interviews within as many months. All 3 wanted me to demonstrate my knowledge of data modeling in the interviews, IE what is a fact / dimension table? Have I ever made or used them in practice? What‚Äôs the difference between star and snowflake schema? Etc.",
          "score": 1,
          "created_utc": "2026-02-06 17:42:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xwaa9",
          "author": "aMare83",
          "text": "I don't think so. Even if your data platform is Databricks which is the ultimate choice these days, it does matter how you design the database schema and queries. It manifests in cloud compute costs, so I think it still matters.",
          "score": 1,
          "created_utc": "2026-02-06 18:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zbnbi",
          "author": "jaymopow",
          "text": "Data modeling is still very important, but the classical data modeling approaches don‚Äôt really support today‚Äôs use cases.",
          "score": 1,
          "created_utc": "2026-02-06 22:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zyf3o",
          "author": "onomichii",
          "text": "Modelling the business logically is critical.\nModelling this in physical terms that is performant, scalable and maintainable is critical.\nEngineering this well is critical.\n\n\nAll three are distinct skills. You might think you're skipping some because of the features of your target platform, but what you're really doing is just short sighted half assed modelling which you will pay for one way or another later¬†",
          "score": 1,
          "created_utc": "2026-02-07 00:23:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40eqtj",
          "author": "drag8800",
          "text": "Honestly I think the answer depends a lot on the maturity of the org and the type of questions being asked. At places where speed to insight matters more than long term consistency, yeah people skip the modeling rigor because storage is cheap and nobody wants to wait 2 weeks for a proper star schema.\n\nBut I've seen it bite teams hard when they try to do anything cross-functional or longitudinal. Without SCDs or at least some versioning strategy you end up with a bunch of snapshots that don't stitch together and analysts reinventing the wheel every quarter.\n\nThe real issue is most teams don't feel the pain until they're 2-3 years in and by then the cost of retrofitting proper models is enormous. Classic modeling isn't dead, it's just expensive upfront and most orgs optimize for short term velocity.",
          "score": 1,
          "created_utc": "2026-02-07 02:01:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wvnwv",
          "author": "Atticus_Taintwater",
          "text": "Yes and no\n\n\nThe ideology of a data model \"modeling the business\" and the more theoretical techniques are definitely falling out of favor for good reason.¬†\n\n\nEvery time I've seen that it's just ego stroking from a modeler and a lot of time contorting the way the systems actually behave to his Disneyland idea of \"the business\". It ends up just making everything either harder or weirder¬†\n\n\nData modeling is important up to the point where people can write sensible queries and get sensible results. Greatly diminishing returns after that.",
          "score": -1,
          "created_utc": "2026-02-06 15:09:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x4yjx",
              "author": "DungKhuc",
              "text": "What you said is true if data modeling is used for forgotten BI dashboards.\n\nIf data is at the core of the business, data modeling is critical as it's typically crucial part of the products. The value of data models in such cases only grows over time, never the other way around.",
              "score": 3,
              "created_utc": "2026-02-06 15:54:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xe34g",
                  "author": "Atticus_Taintwater",
                  "text": "I think what I said is true for most data products that aren't for operations\n\n\nWouldn't lump in scd with this. That's barely modeling.¬†I'm more talking about bloated er modeling.\n\n\nThere should be a generally sensible structure. My addresses should be collated with some kind of locations concept, etc\n\n\nBut every time I see a subrogations process modeled in 15 tables because that's how it theoretically works it becomes a counterproductive rats nest because the real world is far gnarlier.",
                  "score": 1,
                  "created_utc": "2026-02-06 16:37:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wwzhh",
              "author": "MissingSnail",
              "text": "And in practice, tech teams are understaffed and doing the best they can with the time they have.",
              "score": 1,
              "created_utc": "2026-02-06 15:16:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wx1s3",
          "author": "kjmerf",
          "text": "Yes",
          "score": 0,
          "created_utc": "2026-02-06 15:16:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtwdcf",
      "title": "Best companies to settle as a Senior DE",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qtwdcf/best_companies_to_settle_as_a_senior_de/",
      "author": "Dapper-Computer-7102",
      "created_utc": "2026-02-02 14:22:50",
      "score": 75,
      "num_comments": 49,
      "upvote_ratio": 0.93,
      "text": "So I have been with startups and consulting firms for last few years and really fed up with unreal expectations and highly stressful days. \n\n  \nI am planning to switch and this time I wanted to be really careful with my choice( I know the market is tough but I can wait) \n\n  \nSo what companies do you suggest that has good work life balance that I can finally go to gym and sleep well and spend time with my family and friends. I have gathered some feedback from ex colleagues that insurance industry is the best. IS it true? Do you have any suggestions?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qtwdcf/best_companies_to_settle_as_a_senior_de/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o35rms0",
          "author": "Kenny_Lush",
          "text": "The ones that pay way less than you‚Äôre used to.",
          "score": 110,
          "created_utc": "2026-02-02 14:27:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37mavr",
              "author": "sciencewarrior",
              "text": "Consulting doesn't pay all that well for the qualifications they require and performance expectations; after all, their profit is the difference between what the client is willing to pay and your salary. \n\nIME, chemical, healthcare, and other large companies in highly regulated sectors tend to avoid crunch. They do have tons of red tape and legacy, though.",
              "score": 19,
              "created_utc": "2026-02-02 19:39:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o360m4p",
              "author": "Dapper-Computer-7102",
              "text": "I‚Äôm okay to cut down my salary and joined my last organization with the same hope and end up as single person data team apparently they don‚Äôt have money to hire the remaining team still wanted migration, dashboards everything ready in 6 months. Pay doesn‚Äôt really translate to work environment.",
              "score": 18,
              "created_utc": "2026-02-02 15:14:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36108t",
                  "author": "Kenny_Lush",
                  "text": "True, you do have to get lucky.",
                  "score": 3,
                  "created_utc": "2026-02-02 15:16:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o36d5ck",
              "author": "zazzersmel",
              "text": "I‚Äôm not senior but I make less working for a tech startup now than I did at a large non-tech company a couple years ago. It‚Äôs also like twice as much work.",
              "score": 1,
              "created_utc": "2026-02-02 16:13:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36zq0o",
                  "author": "Dapper-Computer-7102",
                  "text": "Cost cutting I guess",
                  "score": 1,
                  "created_utc": "2026-02-02 17:57:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o363ogm",
          "author": "protonchase",
          "text": "I work as mid level DE at a F500 insurance company. My organization in particular has a lot of ambitious folks. There are definitely people who have ‚Äòsettled‚Äô but most of them are not seniors. The seniors have high expectations here. That being said, insurance in general is pretty ‚Äòchill‚Äô.",
          "score": 33,
          "created_utc": "2026-02-02 15:29:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36ecu0",
              "author": "JohnPaulDavyJones",
              "text": "Oh hey, I'm also a mid-level DE at a F500 insurer. We don't really have many ambitious folks, though; we've got a ton of lifers focused on slow, iterative build outs for a new policy system we're bringing online, as well as keeping the lights on for an extremely stable series of warehouses. This team has institutional knowledge out the wazoo, which rocks.\n\nI get the feeling that a lot of the insurance industry is like this. I spent a year at USAA prior to this, and they had a ton of lifers too before they handed out a ton of early retirement incentives to thin the workforce in 2023 and then still had to do their first-ever wave of layoffs in 2024.",
              "score": 9,
              "created_utc": "2026-02-02 16:19:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36gorf",
                  "author": "protonchase",
                  "text": "Nice. I work with underwriting data. Yeah we have a lot of lifers as well actually. But those are usually the folks who stay stagnant and don‚Äôt get promoted but instead just bounce from team to team when they get bored lol.",
                  "score": 5,
                  "created_utc": "2026-02-02 16:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35y5ri",
          "author": "0sergio-hash",
          "text": "I've only been to a few companies and I honestly think work life balance is like 50/50 between the company and yourself \n\nI work at a startup type environment now and I'm just ok with being one of only a couple people on the team that doesn't volunteer for everything and stick their nose in everything lol \n\nI don't rush to deliver every single project and fall for their manufactured urgency \n\nThen again, my role isn't some mission critical thing. I produce reports so it's a little different \n\nI worked at a huge fintech and they were pretty dang slow to do anything so work life balance was decent but you get bored not getting anything done",
          "score": 16,
          "created_utc": "2026-02-02 15:01:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35zfef",
              "author": "Dapper-Computer-7102",
              "text": "I‚Äôm your kind but everyone else in my organization runs on a treadmill and behaves like they‚Äôre operating on a patient who is ready to die. I don‚Äôt really care and end my day at 5. And guess what my manager calls me on my personal number to login at 11pm as everyone else is working and in a meeting. I voice my concerns a lot. And I am only one who does that and only one to say NO. Startups are way better at least the pay and benefits are decent. But consultancies are horrible.¬†",
              "score": 8,
              "created_utc": "2026-02-02 15:08:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3cutep",
                  "author": "0sergio-hash",
                  "text": "My phone would be on DND at 11 pm lol I am not an EMT ü§£ Sounds like a leadership/culture issue, I'd get a new job my friend \n\nI won't even install work apps on my phone lol",
                  "score": 2,
                  "created_utc": "2026-02-03 15:35:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36h1q9",
          "author": "JohnPaulDavyJones",
          "text": "Established insurance companies usually rock. They're incredibly risk-averse by nature, so there are tons of lifers here.\n\nI'm a mid-level/senior-ish DE at a F500 insurer these days, after I spent time in higher education, B4 consulting, and then built the data team at a PE-backed startup in the healthcare sector. I've done the stress of consulting and PE, and I can't imagine leaving insurance these days unless it was to go back to higher ed, but the pay there doesn't compete with the pay in insurance.\n\nInsurance in general tends to have a lot of lifers, my team these days has 14 folks, with an average age of 51. Five of us are younger than 40, seven folks are older than 50, and one gentleman still plugging away at 73. Only two of us have been here less than 8 years, and six have been here 15+ years.\n\nI was at USAA for about a year before this, and they also had a ton of long-timers. My team there was \\~8 folks and only two of us had been there less than a decade, lots of folks had started in other jobs at the company and then cross-trained over into DE as the company built their org. They want to keep folks who really get the insurance business, that domain knowledge is really helpful.\n\nNot sure if I'd recommend USAA right now, though. They're going through a whole lot of flux these last few years, and I think I'd steer clear until they figure things out, maybe 2028\\~2030 or so. The thing that hurt USAA was that they got out over their skis after their big hiring burst during Covid, so they tried to thin the workforce with a ton of early retirement incentives in 2023, and then still had to do their first-ever wave of layoffs in 2024. Morale went from sky-high to the absolute gutter after the layoffs, so a lot of us bounced in the aftermath of that.\n\nOnce you've seen how stressful consulting and other industries can be, then how unerringly *stable* insurance is, it's hard to want to leave.",
          "score": 9,
          "created_utc": "2026-02-02 16:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38ucth",
              "author": "Spunelli",
              "text": "Yea but they are incredibly outdated technology wise and the culture can be quite toxic. The lifers fear change and will go to great manipulative lengths to keep their seats warm.",
              "score": 3,
              "created_utc": "2026-02-02 23:13:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38x1l5",
                  "author": "JohnPaulDavyJones",
                  "text": "The toxic culture is news to me, I've been a huge fan of the culture at both my current employer and at USAA. I'd go so far as to say that USAA had the best corporate culture I've ever seen/heard of. Folks love it there for a reason. Granted, that may have taken a hit after the layoffs, but I presume it'll come back pretty well.\n\nYou're not wrong abou the archaic tech stacks, though. USAA was still using Hadoop broadly in 2023 and my current firm is entirely on SQL Server/SSIS. Our \"new technology\" that we're integrating in 2025-2026 is Python.\n\nThat just adds to the stability, though. It works a lot better for you if you've already gone and done the high speed jobs with the fun toys, and now you want stability.",
                  "score": 2,
                  "created_utc": "2026-02-02 23:27:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ah8yn",
                  "author": "SuperTangelo1898",
                  "text": "Are they still on prem??? (Ew)",
                  "score": 1,
                  "created_utc": "2026-02-03 04:57:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3w96hn",
                  "author": "Spare_Mango_6843",
                  "text": "Definitely not true depending on company. Some companies are invested heavily in AI and FAANG like movement towards Enterprise Architecture.",
                  "score": 1,
                  "created_utc": "2026-02-06 13:10:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38ui1g",
              "author": "number676766",
              "text": "Also in insurance. I'm not a true data engineer, but I do some and I interface between our data engineers and everyone else. Having worked at a very large EHR company, then a start up as the first engineer, and now this, I can safely say it's better. \n\nI grew up in a house where my parents were working on their business all day and into the night. Nothing weird about only stepping down to dinner and then returning to work until 11pm like my dad did my whole childhood. I took that behavior with me to my first couple of jobs and survived and thrived while others burnt out. \n\nBut at this job, I have the constant anxiety that I'm not doing enough because I'm not stressed all the time. I'm not on call, and I don't really work late except a couple nights a year. It's quite chill compared to what I'm used to. \n\nWhile the contractors cycle in and out, I haven't seen many of our IT FTEs leave. The pay is pretty good, only two days a week in office which I like, and good benefits. \n\nThere was a time when I was like \"I'll never do something boring like insurance\" and now I consider myself lucky to have a job with all of the aforementioned qualities. Especially in this economy.",
              "score": 3,
              "created_utc": "2026-02-02 23:13:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o370g9t",
              "author": "Dapper-Computer-7102",
              "text": "Last line is 100% true.¬†",
              "score": 1,
              "created_utc": "2026-02-02 18:00:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38tdts",
                  "author": "pmorrisonfl",
                  "text": "After years in the trenches of F500 dev orgs and consulting, I did a four-year stint at an insurance-adjacent organization. I called it the 'Country Club'. If I had more sense I'd probably still be there.",
                  "score": 1,
                  "created_utc": "2026-02-02 23:08:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36d14w",
          "author": "MikeDoesEverything",
          "text": "As per usual, location really helps people here as nobody knows where you are and it might differ from country to country.\n\nIn the UK, traditional industries are pretty good.  Legal, finance, banking etc.  Not the most interesting roles although you 100% get work-life balance.  Not sure if that translates to where you are, mind.",
          "score": 5,
          "created_utc": "2026-02-02 16:12:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36zih8",
              "author": "Dapper-Computer-7102",
              "text": "I‚Äôm in USA",
              "score": 2,
              "created_utc": "2026-02-02 17:56:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3834uk",
          "author": "Steelcowinc",
          "text": "Just about any large non-tech company has a high probability of being more chill than a startup. Retailers, manufacturers, insurers, financial, etc.\n\nBut as others have said, salaries tend to be lower.",
          "score": 4,
          "created_utc": "2026-02-02 20:59:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38j11h",
          "author": "Ketchup571",
          "text": "I‚Äôm a lead at large health insurance company. The pay is good, not FAANG level by any means, but I‚Äôm quite comfortable. The work-life balance though is out of this world. Days are low stress. I can count on one hand the amount of days I have to work late in a year and they have vary generous pto.",
          "score": 4,
          "created_utc": "2026-02-02 22:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37kvbm",
          "author": "fuloqulous",
          "text": "Can confirm insurance is pretty chill. I worked with a large health insurance company and worked about 3 hours a day. Two of my colleagues each work for different insurance companies and same story.",
          "score": 3,
          "created_utc": "2026-02-02 19:33:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o391buj",
          "author": "Patient_Professor_90",
          "text": "Banks!",
          "score": 3,
          "created_utc": "2026-02-02 23:51:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dvsdq",
          "author": "geek180",
          "text": "I've always worked in mid-sized, non-tech startups. I was originally in marketing and then moved to data engineering about 6-7 years ago. I'm now a staff data engineer at a mid-size biotech company. \n\nThere's a point around the $10-$30 million annual revenue mark where companies start to really need to step up their data and analytics practices and will start investing more in personnel and technology. These are great moments to get hired.\n\nIn my experience, these companies often pay above average and offer a lot of learning opportunities. Since there is always so much that needs to be done, I can often pick and choose what I want to work on. If you're in early enough, you get to do a lot of the foundational design of whatever system you need to build. \n\nI prefer this to jumping into a well-established team at a large company where the work is just delegated to you, you have to completely conform to the existing paradigm, and potential for skill or career progression is possibly a little more constrained.",
          "score": 2,
          "created_utc": "2026-02-03 18:25:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35xwik",
          "author": "West_Good_5961",
          "text": "Government",
          "score": 2,
          "created_utc": "2026-02-02 15:00:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3602i5",
              "author": "Dapper-Computer-7102",
              "text": "Right. But hardly see any openings there and not sure what criteria they have to choose a CV mine never gets picked up. I get pretty decent number of calls from other companies but from Fed, not really.",
              "score": 2,
              "created_utc": "2026-02-02 15:11:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3613t8",
                  "author": "West_Good_5961",
                  "text": "I assume you‚Äôre an American. In first world countries, public service jobs publish detailed selection criteria and transparency about how their merit system works.",
                  "score": 7,
                  "created_utc": "2026-02-02 15:16:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3928zb",
          "author": "theungod",
          "text": "Find a subsidiary of a large, well off company. Way less stress with similar pay.",
          "score": 1,
          "created_utc": "2026-02-02 23:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3awa58",
          "author": "Rand_alThor_",
          "text": "I work in a great company in Sweden. Company hit it‚Äôs goal so we all will get a 10% bonus. Yes everyone.\n\n30-35 days leave, go pick up my kid whenever; family comes first. I feel good working for the company.\n\nI will stay until the kids are grown for sure.\n\nI would make way more working for a US company, either directly or as a consultant (not even speaking of moving back to the US). But I earn good money and I‚Äôm spending time with my family. I love it.\n\n\nSo my advice is to look at overall company culture, but also a manager/team that shares your values: family, friends, taking care of yourself (gym etc.) should come first for the team/manager and you. Then it‚Äôs about finding a company culture that can support such a team stably, instead of grinding it down. Good luck!",
          "score": 1,
          "created_utc": "2026-02-03 06:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3m4o56",
          "author": "Loud-Librarian-8600",
          "text": "I see that apart from mid size to large enterprises none is recruiting for DEs and large companies expecting 5-10 yrs of expereince. Please anybody correct me if I'm wrong!",
          "score": 1,
          "created_utc": "2026-02-04 22:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37e16v",
          "author": "financialthrowaw2020",
          "text": "This isn't really the market to be choosy in. The best job is the one you can get that pays you what you want",
          "score": 0,
          "created_utc": "2026-02-02 19:01:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37qxg9",
              "author": "Dapper-Computer-7102",
              "text": "So you stay where your stress is in peak? You always have a choice.",
              "score": 2,
              "created_utc": "2026-02-02 20:01:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38fbs6",
                  "author": "financialthrowaw2020",
                  "text": "You always have the option to look for new jobs, it doesn't mean you'll get to be selective beyond your current job and your new job, and sometimes the risk is that you're now the newest guy in a rough economy. There are risks involved as with everything.",
                  "score": 1,
                  "created_utc": "2026-02-02 21:57:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35yzjm",
          "author": "rajekum512",
          "text": "Settle ?Lol. bro dreaming of retirement at a job",
          "score": -9,
          "created_utc": "2026-02-02 15:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o360svx",
              "author": "Dapper-Computer-7102",
              "text": "How is a decent WLB is retirement now?",
              "score": 10,
              "created_utc": "2026-02-02 15:15:00",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o371c5u",
              "author": "makesufeelgood",
              "text": "Not everyone lives to work lil bro.",
              "score": 2,
              "created_utc": "2026-02-02 18:04:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qsm2gq",
      "title": "How to learn OOP in DE?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qsm2gq/how_to_learn_oop_in_de/",
      "author": "EconMadeMeBald",
      "created_utc": "2026-02-01 02:32:50",
      "score": 69,
      "num_comments": 77,
      "upvote_ratio": 0.96,
      "text": "I‚Äôm trying to learn OOP in the context of DE, while I do a lot of work DE work, I haven‚Äôt found a reason why to use classes which is probably due lack of knowledge. So I was wondering are there sources that you recommend that could help fill in the gaps on OOP in DE?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qsm2gq/how_to_learn_oop_in_de/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2x38jg",
          "author": "dukeofgonzo",
          "text": "I start with functions to do what I need to do. One at a time. After a while I have a lot of functions that use the same parameters. That's when I think I have a good candidate for building a class. I just do it to keep my own work organized.",
          "score": 64,
          "created_utc": "2026-02-01 04:49:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xgvi4",
              "author": "JunkPup",
              "text": "Bingo. My only other recommendation is if you can think of a real world ‚Äúobject‚Äù that you‚Äôre constantly writing functions to handle, then writing a class should be something you work towards from the start. It makes adding new functions (methods) so much easier to bolt on when you already have the base class written.",
              "score": 12,
              "created_utc": "2026-02-01 06:33:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2yvt11",
              "author": "Headband6458",
              "text": "Great! That‚Äôs not OOP, though, unless when you put the functions together you‚Äôre changing them to modify object state, i.e. making them not be functions anymore. I would call what you describe ‚Äúnamespacing‚Äù, which is the only benefit you get from just putting a bunch of functions into a class.",
              "score": 6,
              "created_utc": "2026-02-01 13:44:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2z17fp",
                  "author": "dukeofgonzo",
                  "text": "These are not just collections of static methods. I'm building objects all the time that use object, class, and static methods. These objects get used in other classes. I make a few abstract classes and a lot of children for specific work topics. I have found a lot of use out of Python classes to do my data engineering work. However, most of my coworkers aren't comfortable with Python that deep.",
                  "score": 4,
                  "created_utc": "2026-02-01 14:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2x6jd1",
          "author": "psychuil",
          "text": "I feel functional fits DE much more, never really use classes.",
          "score": 64,
          "created_utc": "2026-02-01 05:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xavj1",
              "author": "Otherwise_Movie5142",
              "text": "Same, at least in the type of work I do.\n\nI'll use polymorphism for things like 'rules' or 'selectors',  maybe a few data classes and an orchestrator etc but pure OOP is usually overkill.",
              "score": 7,
              "created_utc": "2026-02-01 05:45:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2xgtly",
                  "author": "psychuil",
                  "text": "Why use dataclasses when arrow exists?",
                  "score": 6,
                  "created_utc": "2026-02-01 06:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wqqzs",
          "author": "zeolus123",
          "text": "I try not to get too carried away with it because it can be easy to over engineer things. \nWe use oop to write reusable source gateway and downloader classes.",
          "score": 24,
          "created_utc": "2026-02-01 03:26:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yzgpe",
              "author": "speedisntfree",
              "text": "This is good advice, bad OOP code is awful. These cases are pretty much the only times I've used it, most code in DE doesn't need state.",
              "score": 2,
              "created_utc": "2026-02-01 14:06:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xand4",
          "author": "IDoCodingStuffs",
          "text": "OOP directly maps to table schemas. You can try to represent tables you work with as classes and rows as objects. \n\nThen you can try to play around with inheritance, interfaces etc. if you have some relationships. Or try to apply language features depending on which one you are using.\n\nBut simply mapping data from tables to defined classes puts you ahead of the curve tbh.",
          "score": 15,
          "created_utc": "2026-02-01 05:43:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ywbo9",
              "author": "Headband6458",
              "text": "Be aware the difference between the logical and physical model. You probably want the logical model in your code, not the physical model. What‚Äôs the advantage of re-using the physical model like you describe? The logical model will only change when the business that the data relates to changes. The physical model can change at the whim of the data engineer.",
              "score": 2,
              "created_utc": "2026-02-01 13:47:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o30ypit",
                  "author": "IDoCodingStuffs",
                  "text": ">¬†What‚Äôs the advantage of re-using the physical model like you describe\n\nSo that you can wire it up with different APIs that require that data in different formats.\n\nFair point though. Domain Driven Design was invented to solve the problem you brought up essentially\n\n> The physical model can change at the whim of the data engineer\n\nIt can, in which case you update the code. Or have a sit-down and try to convince them to not make breaking changes so often",
                  "score": 2,
                  "created_utc": "2026-02-01 19:44:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xbncd",
              "author": "IshiharaSatomiLover",
              "text": "This is the way.",
              "score": 1,
              "created_utc": "2026-02-01 05:51:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2x9d9k",
          "author": "dataenfuego",
          "text": "We build a lot of python libraries that help automate certain DE tasks:\n- table metadata (DDLs, table management)\n- workflow orchestration (we use maestro) \n- data diff tooling\n\nSo all of the above are OOP, so not necessarily the data transformation itself",
          "score": 6,
          "created_utc": "2026-02-01 05:33:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xam25",
              "author": "EconMadeMeBald",
              "text": "Would you suggest a way to learn from your experience?",
              "score": 2,
              "created_utc": "2026-02-01 05:43:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xex3d",
          "author": "MonochromeDinosaur",
          "text": "You don‚Äôt need to learn it in DE context just pick up a book on Python OOP. \n\nI like https://www.cosmicpython.com because it‚Äôs practical and not dogmatic about OOP which is how most Python is written anyway.",
          "score": 4,
          "created_utc": "2026-02-01 06:17:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30y61v",
              "author": "campbell363",
              "text": "Great resource for learning Python. I love when the authors post the free versions of their books online.",
              "score": 1,
              "created_utc": "2026-02-01 19:41:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xuhzq",
          "author": "islandboi124",
          "text": "I‚Äôve lately been using classes a lot supported by protocols in Python to standardize the methods in the classes. This has been helpful when I have multiple sources with different source types, schemas and/or formats. \n\nThis allows me in a main function to simply do something like:\n\nfor source in sources:\n\n    source.extract()\n    source.transform()\n    source.load()\n\n\nSorry for the formatting, writing this from my phone!",
          "score": 3,
          "created_utc": "2026-02-01 08:36:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yg9k0",
              "author": "Usurper__",
              "text": "Do you have an example. Sounds cool",
              "score": 1,
              "created_utc": "2026-02-01 11:54:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2yi98x",
                  "author": "islandboi124",
                  "text": "https://realpython.com/python-protocol/\n\nHere under structural subtyping and protocols gives a clear general example, but would suggest reading the whole thing!",
                  "score": 1,
                  "created_utc": "2026-02-01 12:10:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ye1qx",
          "author": "Frosty-Practice-5416",
          "text": "OOP is anti pattern",
          "score": 6,
          "created_utc": "2026-02-01 11:35:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xuute",
          "author": "omonrise",
          "text": "You don't need to.\nOOP makes sense when you need to store state, for example if you have a bunch of functions that can do multiple things with tables, you might like to make them methods of a class so you don't have to configure them individually.",
          "score": 3,
          "created_utc": "2026-02-01 08:39:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wiz0s",
          "author": "Tushar4fun",
          "text": "Have a look at this https://github.com/tushar5353/sports_analysis\n\nI‚Äôve created this pipeline just to show how can we leverage classes in ETL.\n\nAlso, to show modularised approach.\n\nI know there things because I‚Äôve also worked as SE.",
          "score": 3,
          "created_utc": "2026-02-01 02:39:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zer9i",
              "author": "EconMadeMeBald",
              "text": "Thank you! This is really good.",
              "score": 1,
              "created_utc": "2026-02-01 15:27:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36ewpu",
                  "author": "Headband6458",
                  "text": "No, it's not! What do you think is good about it? It's actually horrible, please don't emulate this! Every class has so many responsibilities, as one example of what's bad. The transform classes also load data from files, for example. There are no abstractions, everything is a concrete implementation. It's like somebody who has never heard of the SOLID principles trying to do OOP.",
                  "score": 0,
                  "created_utc": "2026-02-02 16:21:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wkcon",
          "author": "New-Composer2359",
          "text": "If you use Pyspark, try creating a new dataframe class based on the standard one with new functionalities that you like!",
          "score": 4,
          "created_utc": "2026-02-01 02:47:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y9wy4",
          "author": "xmBQWugdxjaA",
          "text": "For large data processing you don't want it, since you want a struct-of-arrays approach (reading from columnar data), not array of structs.\n\nBut it can be handy in orchestrators or scrapers.",
          "score": 2,
          "created_utc": "2026-02-01 10:58:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ygco4",
          "author": "robberviet",
          "text": "Unless you are writing libraries, there is not much value in learning OOP. If you still do, then it's no different from traditional SWE. Just learn how OOP is used in Python.",
          "score": 2,
          "created_utc": "2026-02-01 11:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yw2z1",
          "author": "instamarq",
          "text": "In data engineering, it's usually best to operate like Bruce Lee; take what's valuable from different approaches and apply that in areas where it will most effectively solve the problem.\n\nIn general, OOP won't get you that far in most DE scenarios _unless_ you're writing a library for some niche problem that your business data has that OOP helps you properly model.\n\nIn my opinion, OOP is for building tools and modeling reality. Most of the time, in DE, our tools are already built and our realities are mapped using data. I think someone in this thread mentioned that functional patterns are more applicable in our field. I think they're right.",
          "score": 2,
          "created_utc": "2026-02-01 13:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o301ukd",
          "author": "_Batnaan_",
          "text": "I use OOP (python mostly) to organize some complex orchestration or transformation logic when there is a lot of context information that is used repeatedly.\n\nUsually I will create one or a few classes for each problem, but nothing like what you would find in a java server app with 100+ classes.\n\nBasically I have some kafka-like stateful joins I do in incremental batch transforms. The Stateful Transform will handle its memory and its logic differently depending on what happened on inputs or depending on whether it's a replay or not. So I have a dozen functions being called with different arguments depending on the context, so I created a class to contain all of these contextual variables.\n\nSome colleagues use classes to generate transformations with very repeatable logic with some adjustments based on the size of datasets. Classes are a nice way to make the repeatable logic clear while also making the configuration well constrained (with a builder pattern for example) instead of a yaml file being called in hundreds of if/else statements)",
          "score": 2,
          "created_utc": "2026-02-01 17:14:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o312zja",
          "author": "acana95",
          "text": "I used OOP to reuse object that refer to table schema",
          "score": 2,
          "created_utc": "2026-02-01 20:04:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ze64j",
          "author": "nightslikethese29",
          "text": "Going to go against the grain here. I use OOP all the time at work. For example, we have classes for database connectors, APIs, SFTP, and other automation jobs. \n\nIf I need to download data from multiple sources and run a few checks on it, I can abstract all that away and create a method called download_data() where all of the API calls are in the method. In my opinion, it looks cleaner and it's very obvious what's happening. It's also easier to modularize and test code. \n\nOf course, both functional and OOP have their place.",
          "score": 4,
          "created_utc": "2026-02-01 15:24:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zg0rf",
              "author": "EconMadeMeBald",
              "text": "1.When you say validate here, do you integrate pd/spark or whatever into your classes? \n\n2. Any repo you recommend me looking at?",
              "score": 2,
              "created_utc": "2026-02-01 15:33:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o307gts",
                  "author": "nightslikethese29",
                  "text": "Yeah it could be things like validating API response bodies using pydantic or validating data frame schema using pandera. Just things I abstract away from the top level code. \n\nI don't have a repo to recommend unfortunately.",
                  "score": 2,
                  "created_utc": "2026-02-01 17:40:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o36e2w8",
                  "author": "Headband6458",
                  "text": "Also understand that you can do exactly the same thing with a funcitonal approach and likely end up with somehting more maintainable.\n\nIt's telling that not one single person has been able to explain a single advantage they feel they get from taking an OOP approach to a problem space that is so well-suited to the functional paradigm.",
                  "score": 0,
                  "created_utc": "2026-02-02 16:17:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wxxjp",
          "author": "Resident-Loss8774",
          "text": "While not fully in the context of DE, what has helped me gain a better understanding of OOP is first by getting a grasp the fundamental concepts (Corey Schafer has great videos) and then trying to apply those concepts. Also just reading code that uses a lot of OOP (e.g., Polars, Airflow), can help as well. Imo, for DE, OOP has a place for API clients, database connectors, custom Airflow operators, and things of that manner.",
          "score": 2,
          "created_utc": "2026-02-01 04:13:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xbn4t",
          "author": "Specific-Mechanic273",
          "text": "The only use-cases where I needed classes was when I built an ingestion tool which normally worked with most API integrations that return a JSON. And once I've built a data validation tool that runs between two databases for a migration.\n\ntbh not worth the effort, just get better in relevant stuff or look into software engineering if you're interested in OOP.",
          "score": 1,
          "created_utc": "2026-02-01 05:51:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yea1a",
          "author": "PrestigiousAnt3766",
          "text": "Don't need classes. I have a data context object containing metadata, run context though and python logger",
          "score": 1,
          "created_utc": "2026-02-01 11:37:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yeh44",
          "author": "ZirePhiinix",
          "text": "Classes only make sense when the project is so large that you bring in OOP so that you can have better control over the objects.\n\nMost DE projects don't scale in a way that particularly benefits from OOP concepts though.",
          "score": 1,
          "created_utc": "2026-02-01 11:39:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ygohd",
          "author": "D1yzz",
          "text": "In my context, we have a class DataTypeImporters, that is responsible to validate and store data in the respective tables. This class has a lot of properties/method that need to be defined/implemented to force consistency and pre validations.   \nEach of the same DataTypeImporters, can have different sources, with specific implementations, like Rest API, SOAP, XML, SFTP, DB, and so on, where the specifics are implemented but they all use a sort of client, that serves has base class for the specific client. Then we might have specific classes for data cleaning, transformation, validation, data quality checks, reports and so on.   \nWe create a template, with optional or mandatory parts, than can be reused or overwriten",
          "score": 1,
          "created_utc": "2026-02-01 11:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2z06vc",
          "author": "speedisntfree",
          "text": "If you use Airflow, writing custom Operators and Hooks will give you can idea of how OOP can be useful. They give you a structured way to write the custom behviour you want that is compatible with Airflow.",
          "score": 1,
          "created_utc": "2026-02-01 14:10:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zc4cv",
          "author": "Bach4Ants",
          "text": "If it ain't broke don't fix it. I've seen \"OOP\" go horribly wrong in DE: Using classes with many-level inheritance to write procedures and mutating internal state to store results. Python makes it especially easy to abuse classes.",
          "score": 1,
          "created_utc": "2026-02-01 15:14:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34xzdi",
          "author": "CynicalShort",
          "text": "Like many others, advice caution with OOP in DE. Namespacing static methods is nice use of classes, but applying OOP to pipeline code is usually extra abstraction. I have witnessed cases that I count as griefing the company by incompetense. But if you need a small library or custom tool for a problem, OOP could be suitable.",
          "score": 1,
          "created_utc": "2026-02-02 11:11:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsg6tc",
      "title": "Puzzle game to learn Apache Spark & Distributed Computing concepts",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qsg6tc/puzzle_game_to_learn_apache_spark_distributed/",
      "author": "Elegant_Debate8547",
      "created_utc": "2026-01-31 22:21:37",
      "score": 66,
      "num_comments": 3,
      "upvote_ratio": 0.99,
      "text": "https://i.redd.it/fsa3dtvkfrgg1.gif\n\nHello all!\n\nI'm new in this subreddit! I'm a Data Engineer with +3 years of experience in the field.\n\nAs shown in the attached image, I'm making an ETL simulator in JavaScript, that simulates the data flow in a pipeline.\n\nRecently I came across a Linkedin post of a guy showcasing this project : [https://github.com/pshenok/server-survival](https://github.com/pshenok/server-survival)\n\nHe made a little tower defense game that interactively teaches Cloud Architecture basics.\n\nIt was interesting to see the engagement of the DevOps community with the project. Many have starred and contributed to the Github repo.\n\nI'm thinking about building something silimar for Data Engineers, given that I have some background in Game Dev and UI/UX too. I still need your opinion though, to see whether or not it is going to be that useful, especially that it will take some effort to come up with something polished, and AI can't help much with that (I'm coding all of the logic manually).\n\nThe idea is that I want to make it easy to learn Apache Spark internals and distributed computing principles. I noticed that many Data Engineers (at least here in France), including seniors/experts, say they know how to use Apache Spark, yet they don't deeply understand what's happening under the hood.\n\nThrough this game, I'll try to concretize the abstract concepts and show how they impact the execution performance, such as : transformations/actions, wide/narrow transformations, shuffles, repartition/coalesce, partitions skew, spills, node failures, predicate pushdown, ...etc\n\nYou'll be able to build pipelines by stacking transformer blocks. The challenge will be to produce a given dataframe using the provided data sources, while avoiding performance killers and node failures. In the animated image above, the sample pipeline is equivalent to the following Spark line : `new_df = source_df.filter($\"shape\" === \"star\").withColumn(\"color\", lit(\"orange\"))`\n\nI represented the rows with shapes. The dataframe schema will remain static (shape, color, label) and the rendering of each shape reflects the content of the row it represents. Dataframe here is a set of shapes.\n\nI'm still hesitant about this representation. Do you think it is intuitive and easy to understand ? I can always revert to the standard tabular visualisation of rows with dynamic schemas, but I guess it won't look user friendly when there are a lot of rows in action.\n\nThe next step will be to add logical multi-node clusters in order to simulate the distributed computing. The heaviest task that I estimated would be the implementation of the data shuffling.\n\nI'll share the source code within the next few days, the project needs some final cleanups.\n\nIn the meanwhile, feel free to comment or share anything helpful :)",
      "is_original_content": false,
      "link_flair_text": "Personal Project Showcase",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qsg6tc/puzzle_game_to_learn_apache_spark_distributed/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o306k8s",
          "author": "goeb04",
          "text": "Some distributed computing architecture does seem murky to me, so I would be happy to use it once you make the code available.\n\nWish I had more to offer, but as someone who is a severe Visual Learner, this sounds great üëç.",
          "score": 5,
          "created_utc": "2026-02-01 17:36:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31c134",
              "author": "Elegant_Debate8547",
              "text": "Thank you for your comment !\nWhat do you think about the shape representation of data rows ? Is it something you feel comfortable with ?",
              "score": 2,
              "created_utc": "2026-02-01 20:48:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o32chcf",
          "author": "lezwon",
          "text": "I'd love to try something like this out ü•≥",
          "score": 5,
          "created_utc": "2026-02-01 23:55:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsqhzm",
      "title": "How to become senior data engineer",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qsqhzm/how_to_become_senior_data_engineer/",
      "author": "Sudden-Inflation2686",
      "created_utc": "2026-02-01 06:08:16",
      "score": 63,
      "num_comments": 18,
      "upvote_ratio": 0.84,
      "text": "I am trying to develop my skills be become senior data engineer and I find myself under confident during interviews .How do you analyze a candidate who can be fit as senior position?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qsqhzm/how_to_become_senior_data_engineer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2xv7f2",
          "author": "cmcclu5",
          "text": "Seniors can:\n- Solve problems on their own\n- Mentor juniors\n- Understand not just a single piece but how it relates to the overall architecture\n- Be aware of the cost/benefit analysis of various solutions\n- Propose new VALID design patterns (not just ‚Äúwe should refactor to Snowflake‚Äù or ‚Äúlet‚Äôs migrate everything to Dagster‚Äù)\n- And, most importantly for most companies, communicate effectively with non-technical and differently-technical stakeholders and executives",
          "score": 69,
          "created_utc": "2026-02-01 08:43:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yn3co",
              "author": "decrementsf",
              "text": "I agree. Expanding more on job leveling processes from an employer perspective.\n\nCompanies look for comparison to other companies to determine what to price their roles at. This is done through compensation surveys with data generally collected each June-July, and results published around November. This is an imperfect process as every company calls roles slightly different so an analyst goes through and tries to match the roles reasonably to a generalized guide of what other companies call this role. Part of this process is it is helpful to level how senior the duties of that role is. Usually this is done with Pay Grades. Because the companies that collect analyze and prepare the compensation surveys are broadly known, their Pay Grades are most often what companies are internally calling their pay grades.\n\nWillis Towers Watson is one of the common surveys. They provide a leveling guide with description of what is generally differences between levels of seniority for professionals. Data engineer is generally going to fall under the Professional (P) classification in the WTW system. Most data engineers would be a P2, and senior a P3. Entry level may be P1. The P4 and P5 is much more rare, usually a professional individual contributor with 20 or 30 years experience, much less common. P3 tends to be the catch all for senior.\n\nA crude difference is that a data engineer can work through core business tasks but generally needs a more senior team member for guidance and some supervision. They can follow processes and best practices. At the senior level they can work more independently thinking through novel challenges that come up, they can create the processes and best practices and serve as a resource for more junior associates when novel challenges come up outside the usual experiences.\n\nA listing of descriptions of the different Professional pay grades can be read here.\n\nhttps://itv.career-navigator.willistowerswatson.com/career-bands/definition/professional?level=P2\n\nThere are other adjustments usually tech roles receive a compensation premium in compensation surveys. They'll denote things like a \"P3 - P\" the - P denoting a tech role premium that may be a flat 15% - 20% over compensation benchmarks depending on the companies policies. With rare skills as is common in tech roles often comp surveys are less useful and they'll perform specialized analysis for compensation plans for these.\n\nNot speaking exhaustively how work gets done but enough to get a sense for the flow of why pay grades exist and a primary source you can familiarize with that are used by companies. There also exist pay grades of other career levels, M is management, senior management are E's, business admin are B's.",
              "score": 8,
              "created_utc": "2026-02-01 12:47:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o31i9vv",
              "author": "LoaderD",
              "text": "Yeah, but they have to forget the ‚Äúdon‚Äôt blindly refactor‚Äù rule if they want to move to a manager+ role.",
              "score": 2,
              "created_utc": "2026-02-01 21:19:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zz1jc",
          "author": "A_Polly",
          "text": "People here are pulling a leg out to tell you what to do. The reality is: You are Junior DE. Only Senior leaves. You are Senior now. That's like 80% of cases.\nThat's how it fucking works and never let anyone tell you something else. But you need to be able to handle the shit show.\n\nThe other way is to tell your boss what you have to do to become senior. Define clear tangible Targets. If you meet those targets you should become Senior. If not hand in your resignation. Either you are valuable and they will reward you with the role or you were not valuable (just a cost center) in your role, which is just a time bomb anyway.\n\nNobody is waiting to award you with a senior title. They will try to keep you on a lower paycheck as long as possible.",
          "score": 10,
          "created_utc": "2026-02-01 17:01:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ynagm",
          "author": "chrisgarzon19",
          "text": "Business impact \n\nEveryone whose already a level 2 or 3 know the basics and tech stuff \n\nAre you a leader with a business mind is the question",
          "score": 4,
          "created_utc": "2026-02-01 12:48:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xh6ug",
          "author": "adastra1930",
          "text": "I really want to help you, but it‚Äôs the kind of question where if you are asking, it means you‚Äôre nowhere near ready. But as a general rule, the difference between any individual contributor (IC) role and a senior IC role is the demonstrable ability to basically manage yourself. Identify and execute projects that support company objectives, develop relationships within the business, that sort of thing. \n\nThis is why: the next step from senior is often a lead or manager, so to go from junior to senior, you need to demonstrate capability, then when you‚Äôre a senior you‚Äôll be refining your capability and starting to demonstrate that you can apply your skill to leading others, which gets you to the next place.\n\nAnd obviously that varies wildly from company to company üòÖ",
          "score": 21,
          "created_utc": "2026-02-01 06:36:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z97eh",
              "author": "shittyfuckdick",
              "text": "What a gatekeepy response. We should be encouraging people to grow in their career not scare them away from it.¬†",
              "score": 4,
              "created_utc": "2026-02-01 14:59:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31indr",
          "author": "LoaderD",
          "text": "Learn to explain things well.\n\nYou don‚Äôt even outline your background, so people are giving you blind advice.\n\n‚ÄúI want to be sr‚Äù can be totally different if you‚Äôre a 5yoe intermediate vs a new grad who has 6 months of experience.",
          "score": 3,
          "created_utc": "2026-02-01 21:21:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xgnch",
          "author": "amejin",
          "text": "You have a leg up - you've interviewed!\n\nFirst, some practical advice - you sitting in an interview means on paper you're already qualified. They're getting to know you. \n\nSecond, some actionable advice - you have experienced the questions and have a newfound understanding of what the industry is looking for. Be good at those things and be the expert so you can answer confidently. Lack of confidence is usually a lack of preparation. \n\nFinally - you will be hit with imposter syndrome your entire career. Embrace the suck.",
          "score": 7,
          "created_utc": "2026-02-01 06:31:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z9ili",
              "author": "shittyfuckdick",
              "text": "This is not true in my experience. I have been interviewing for senior roles and have had many rejections all of which either saying i didnt have enough experience or they had a more qualified person. Just cause they interview you does mean your senior level imo.¬†",
              "score": 2,
              "created_utc": "2026-02-01 15:01:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o305zye",
                  "author": "Childish_Redditor",
                  "text": "It means your resume meets the minimum requirements to be a senior level engineer at those companies giving you interviews",
                  "score": 3,
                  "created_utc": "2026-02-01 17:33:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o309nr9",
                  "author": "amejin",
                  "text": "I guess the \"on paper\" part was lost on you.. maybe you're over representing yourself?",
                  "score": 1,
                  "created_utc": "2026-02-01 17:50:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xmcdg",
              "author": "Adepate",
              "text": "That imposter syndrome feels real. Sometimes, the reason for underperforming during interviews is the fear of being an imposter",
              "score": 1,
              "created_utc": "2026-02-01 07:21:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xmshd",
          "author": "circumburner",
          "text": "When a technical problem gets escalated, and there is no one to escalate higher, whether you know the solution or not, you're senior. \n\nOr, whenever your bosses changes your title. Either way.",
          "score": 4,
          "created_utc": "2026-02-01 07:25:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xzpps",
          "author": "robberviet",
          "text": "Many people has answered, just want to add: Can architecture design, and explain why to do that; understand that there are more than just technical about this role.",
          "score": 2,
          "created_utc": "2026-02-01 09:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3465sr",
          "author": "empireofadhd",
          "text": "Once you see data engineering as the ‚Äùthree body problem‚Äù and can navigate that I‚Äôd say you are senior. \n\nJuniors fixate on a specific aspect of the solution as a whole while seniors know there is more to things then eg perfect code. \n\nAlso you have seen and probably contributed to a couple of failed/sucessful projects end to end and had to do some maintenance of it after you are ‚Äùdone‚Äù. The maintenance is very important because long term that is where most costs are generated. This is why lots of senior devs are a bit sceptical about ai and the maintenance costs it will generate.\n\nSo to answer your question: make sure you are exposed to all aspects of a project lifecycle, not just greenfield nice solutions where you have free hands. Also spend time with mid career seasoned guys and listen to them rant.",
          "score": 2,
          "created_utc": "2026-02-02 06:50:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y0m4i",
          "author": "revitev1122",
          "text": "Most of the real skills one learns in the job. Once you know the basics of SQL/Python/basic Data Engineering fundamentals (CDC/Data Governance/OOP/Security/Statistic/DevOps/BI/etc), the questions one can be asked in this industry is so vast that practicing for it may be in vain. Esp in the high pressure screen share environment of difficult questions one might be asked.¬†\n\nThe longer you work at that job the more senior one can become. Avoid working in/applying to industries/for companies that intentionally use older technologies. By that I mean if they list older technologies in their job positing or the company inherently keeps themselves ancient like Intel/IBM/some pharmaceutical companies/some government jobs/etc.¬†\n\nThis approach may not be for everyone but I applied to hundreds, if not thousands of jobs in a year. Which, like reading 20 pages of a book a day, can be the simple consistency of a few jobs a day. And when my current job stopped challenging me enough during the pandemic I joined a start-up to challenge myself further. They just wanted SQL which is an easy requisite and through that process I learned Snowflake, and through that start-up/Snowflake experience I later got another job in Snowflake/GBQ/GCP, and through that job I later got a job in AWS/Databricks.\n\nI never practiced code tests for any job. Many jobs didn‚Äôt want me for many reasons outside my control and it still hurt on a deep personal level. Many jobs I didn‚Äôt want because the interviewer was rude/the company didn‚Äôt seem fun. But for the few jobs that worked out I have seen a bunch of different problems in a bunch of different contexts in a bunch of different languages in a bunch of different industries. Those things, and factors about one‚Äôs personality, seem to govern good Senior/Staff level positions. It‚Äôs more about the patterns one has seen in real scenario's and one‚Äôs temperament - that‚Äôs hard to train for.",
          "score": 1,
          "created_utc": "2026-02-01 09:33:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y19it",
          "author": "PrestigiousAnt3766",
          "text": "Work.",
          "score": -3,
          "created_utc": "2026-02-01 09:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwvy5y",
      "title": "Data Modeling expectations at Senior level",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/",
      "author": "Outside_Reason6707",
      "created_utc": "2026-02-05 20:04:50",
      "score": 57,
      "num_comments": 23,
      "upvote_ratio": 0.98,
      "text": "I‚Äôm currently studying data modeling. Can someone suggest good resources?\n\nI‚Äôve read Kimballs book but really from experience questions were quite difficult.\n\nIs there any video where person is explaining a Data Modeling round and is covering most of the things that Sr engineer should talk. \n\nEnglish is not my first language so communication has been barrier, watching videos will help me understand what and how to talk.\n\nWhat has helped you all?\n\nThank you in advance!",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3ryvy2",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-05 20:04:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s0lgf",
          "author": "Ok_Tough3104",
          "text": "Joe Reis is dropping a book on data modelling in 1 month, if you're patient enough...\n\nAlso he has a whole substack about that book if you can read from a PC screen without having your eyes bleeding\n\nhttps://practicaldatamodeling.substack.com/",
          "score": 36,
          "created_utc": "2026-02-05 20:12:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xixpa",
              "author": "mightregret",
              "text": "RemindMe! 1 month",
              "score": 2,
              "created_utc": "2026-02-06 17:00:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ti6tn",
              "author": "studentofarkad",
              "text": "Thank you, thats the book I'm waiting for to drop!",
              "score": 1,
              "created_utc": "2026-02-06 00:49:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3v5b83",
              "author": "AccomplishedTax2306",
              "text": "Is it possible to pre-order?",
              "score": 1,
              "created_utc": "2026-02-06 07:34:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vbidi",
                  "author": "Ok_Tough3104",
                  "text": "The whole book is on the substack. (If you can read from a screen)\n\nIts a pay sub. I havent heard Joe mentioning anything about pre ordering, im also in europe, so compared to the US market the book will be delayed by a couple of weeks\n\nApologies for not being able to provide better insights üòÖ",
                  "score": 1,
                  "created_utc": "2026-02-06 08:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3xing2",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-06 16:58:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xitrv",
                  "author": "RemindMeBot",
                  "text": "I will be messaging you in 1 month on [**2026-03-06 16:58:46 UTC**](http://www.wolframalpha.com/input/?i=2026-03-06%2016:58:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/o3xing2/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1qwvy5y%2Fdata_modeling_expectations_at_senior_level%2Fo3xing2%2F%5D%0A%0ARemindMe%21%202026-03-06%2016%3A58%3A46%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qwvy5y)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                  "score": 1,
                  "created_utc": "2026-02-06 16:59:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3uuivo",
          "author": "tophmcmasterson",
          "text": "It depends on the role. I know tons of data engineers, maybe even most of them are pretty terrible at data modeling. \n\nThere‚Äôs a large group of engineers that have gotten by just basically moving data into the warehouse and then brute forcing OBT/flat tables ad-hoc and never really learned best practices in dimensional modeling. \n\nMy recommendation is actually play around with a front end tool like Power BI and understand how data is used and what is recommended for best practices for how data should be structured. If you understand that and refer to the Kimball modeling techniques and can actually internalize it that will get you most of the way there. \n\nIt‚Äôs not really something that is easy to explain in a video I don‚Äôt think. You need to be able to really mentally visualize how data ties together and what shape will make it easiest and most flexible to work with.",
          "score": 9,
          "created_utc": "2026-02-06 06:01:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v0cb8",
              "author": "Hear7y",
              "text": "We just got forced by business to make this absolutely awful flat table (think here both business keys and foreign keys BOTH present) in an increasingly wise table, because they didn't want to have to build any sort of relation when doing stuff in Excel.\n\nFeels like a massive App that was made to solve multiple issues and serve a variety of internal customers is exclusively used to serve a crappy table for Excel. :D",
              "score": 1,
              "created_utc": "2026-02-06 06:50:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vd3dp",
                  "author": "BrownBearPDX",
                  "text": "That‚Äôs when you keep your data models as you should for all the goody goods that will stick to them forever and ever and ever because of that good thinking. \n\nWhat you do then is you build them a freaking view as wide as their stupid little brains can handle. Don‚Äôt change the actual schemas that the business actually relies on and more intelligent people will rely on in the future. Don‚Äôt destructure good thinking into bad and actually implement it. Lie to them if you have to.  Retain your ability to sleep at night.",
                  "score": 5,
                  "created_utc": "2026-02-06 08:47:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3x07z3",
              "author": "Outside_Reason6707",
              "text": "Okay understood. I'm struggling with performance in data modeling interviews, and I'm unsure what's expected of me. In the past, I've asked clarifying questions, proposed entities, and developed dimensional models with fact tables and dimension tables. I've also written SQL code for my proposed solutions and modified my schema based on follow-up questions. However, I haven't received positive feedback, and I'm starting to wonder if I'm missing something fundamental or if it's just a communication issue. I'd love to find a recommended video that demonstrates how to excel in a data modeling interview. Something like demo interviews",
              "score": 1,
              "created_utc": "2026-02-06 15:32:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3x2rlo",
                  "author": "tophmcmasterson",
                  "text": "I‚Äôd again just recommend reviewing some of the well established documentation on Kimball techniques or even going through the Microsoft guidance documentation on star schema (it‚Äôs aimed at designing for Power BI but broadly applicable I think).\n\nIf you internalize the concepts and thought process through working on actual projects you‚Äôll be able to speak to it more naturally.",
                  "score": 2,
                  "created_utc": "2026-02-06 15:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vp67i",
              "author": "Ploasd",
              "text": "Kimball is one of many methods of modelling and is only really good if your building OLAP style infrastructure but people really should understand alternative methodology - 3NF and all that.",
              "score": 0,
              "created_utc": "2026-02-06 10:41:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sn0h5",
          "author": "Gullible_Buy427",
          "text": "Another great read is data modeling made simple by Steve Hoberman.",
          "score": 6,
          "created_utc": "2026-02-05 22:00:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uvyiq",
              "author": "dehaema",
              "text": "Anything by steve hoberman really. His \"data modeling masterclass\" is the best course i ever took",
              "score": 2,
              "created_utc": "2026-02-06 06:13:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x2oy1",
          "author": "miker5555",
          "text": "At senior level, interviews usually aren‚Äôt about memorizing modeling patterns as much as **talking through real tradeoffs**.\n\nWhat helped me most was experience explaining *why* I modeled something a certain way, not just what pattern I used. In interviews they often care more about:\n\n* how you handle messy data\n* how models evolve over time\n* what breaks when requirements change\n* and how you explain things to non-engineers",
          "score": 3,
          "created_utc": "2026-02-06 15:44:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xhx91",
              "author": "Outside_Reason6707",
              "text": "Thank you for explaining! I think I miss the point of explaining why I model something a certain way. I focused on patterns and writing sql. Would you be open for a continued discussion, can I dm you?",
              "score": 1,
              "created_utc": "2026-02-06 16:55:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3vpbs8",
          "author": "Ploasd",
          "text": "I do think Database Design for Mere Mortals by Michael Hernandez is a good easy to read reference around database design that can also help with understanding how to model data.",
          "score": 2,
          "created_utc": "2026-02-06 10:43:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vwkyd",
          "author": "IrquiM",
          "text": "You only get to senior level in data modeling after having spent 10 years at a lower level. No books kan teach it to you, and anyone who says otherwise, are not at a senior level.",
          "score": 0,
          "created_utc": "2026-02-06 11:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x0l1p",
              "author": "Outside_Reason6707",
              "text": "I‚Äôve 7-8 years of experience. And what you said is very much valid. I'm struggling with performance in data modeling interviews, and I'm unsure what's expected of me. I haven't received positive feedback, and I'm starting to wonder if I'm missing something fundamental or if it's just a communication issue.",
              "score": 3,
              "created_utc": "2026-02-06 15:33:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3xvn5e",
                  "author": "IrquiM",
                  "text": "Modeling is just a part of it. To get a senior position, you need to show that you do not require supervision, you can take decision yourself, you can plan ahead and decide what to prioritize, etc.",
                  "score": 2,
                  "created_utc": "2026-02-06 18:00:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qt95p7",
      "title": "First time data engineer contract- how do I successfully do a knowledge transfer quickly with a difficult client?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qt95p7/first_time_data_engineer_contract_how_do_i/",
      "author": "FiftyShadesOfBlack",
      "created_utc": "2026-02-01 20:06:16",
      "score": 45,
      "num_comments": 24,
      "upvote_ratio": 0.94,
      "text": "This is my first data engineering role after graduating and I'm expected to do a knowledge transfer starting on day one. The current engineer has only a week and a half left at the company and I observed some friction between him and his boss in our meeting.  For reference, he has no formal education in anything technical and was before this a police officer for a decade. He admitted himself that there isn't really any documentation for his pipelines and systems, \"it's easy to figure out when you look at the code.\" From what my boss has told me about this client their current pipeline is messy, not intuitive, and that there's no common gold layer that all teams are looking at (one of the company's teams makes their reports using the raw data). \n\nI'm concerned that he isn't going to make this very easy on me, and I've never had a professional industry role before, but jobs are hard to find right now and I need the experience. What steps should I take to make sure that I fully understand what's going on before this guy leaves the company? ",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qt95p7/first_time_data_engineer_contract_how_do_i/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3155wi",
          "author": "vikster1",
          "text": "record the session, have a lot of questions for him to answer before he leaves. document everything. do as much as you can while he is still there. it's a tough situation many of us have been in and there is no one right way to do it. try your best",
          "score": 40,
          "created_utc": "2026-02-01 20:15:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o315aod",
          "author": "Specific-Mechanic273",
          "text": "That's the reality in many companies.\n\nAs he said, look at the code, you'll figure it out. This is a great learning experience for you. It will be frustrating, but being able to tame messy code from other people without any help is a super valuable skill. \n\nHard times make you a great engineer, enjoy the struggle :)",
          "score": 15,
          "created_utc": "2026-02-01 20:15:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31632h",
          "author": "mr_thwibble",
          "text": "Ok, I'll go first.\n\nIf possible, take him for a coffee, establish a rapport before you get into the details.  Set him at ease away from any 'external influences'. \n\nGet the high-level starting points.  Servers.  Processes.  Credentials.  You can - yes, follow the code, but without knowing where the trail starts and what unlocks the gate you're a bit screwed.\n\nWelcome to the magical land of fuckery.  Hope you like reverse-engineering shit. üòÅ",
          "score": 20,
          "created_utc": "2026-02-01 20:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o317fxh",
              "author": "FiftyShadesOfBlack",
              "text": "Thanks for your reply! Unfortunately the role is remote and he's multiple states away, or else I definitely would establish a rapport to set him at ease. He was pretty abrasive in the meeting and defensive of his methods when I asked for clarification. When we meet (virtually) should I be leading the conversation with questions or is it typically on him to give me what he has? I don't want to break professional decorum or come across as trying to interrogate/belittle him.",
              "score": 4,
              "created_utc": "2026-02-01 20:26:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o31bnnr",
                  "author": "mr_thwibble",
                  "text": "Listen first.  Give space.  You need him a lot more than he needs you.  Spending a few mins up front to break down some barriers and show interest might just win you some social credit.\n\nUnless he clearly just can't be bothered and is irritated, in which case move right along and get to the point.\n\nEither way this is a baptism of fire in terns of 'reading the room'.  It won't be the last time you hVe to deal with something like this.  Trust me.",
                  "score": 7,
                  "created_utc": "2026-02-01 20:47:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o31cz7o",
                  "author": "mr_thwibble",
                  "text": "Sounds like he's tired of some shit.  Some of it might get flung at you initially, but keep your calm, polite, respectful.\n\nWho.  What.  Where.  When.  Why.  How.\n\nStart with that, maybe work in some questions about his background, get him to talk about himself.  Loosen him up a bit.  Difficult for sure.",
                  "score": 7,
                  "created_utc": "2026-02-01 20:53:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o31uexv",
                  "author": "VipeholmsCola",
                  "text": "He built the thing so let him explain it, its his baby. Give some compliments wherever, sound interested. With a little luck he will enjoy talking about his build.\n\nmost people like to talk about themselves and their acomplishments, abuse that in this situation...",
                  "score": 6,
                  "created_utc": "2026-02-01 22:18:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o351d60",
                  "author": "remainderrejoinder",
                  "text": ">defensive of his methods when I asked for clarification.\n\nIt may help to level set. Point out that he built these up from nothing with limited time and resources. Make sure he knows you're not going to sit there and bad-mouth him when he's gone because you'll be in the same situation someday.\n\nIgnore things that are part of his learning process--you're not there to teach him what you learned in school.",
                  "score": 2,
                  "created_utc": "2026-02-02 11:40:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33csoj",
          "author": "Mamertine",
          "text": "I'm going to go in a very different direction.¬†\n\n\nYour being set up to fail. They needed to hire an experienced engineer.\n\n\nThis is your first job out of college. You should be working at a shop where a senior person can explain things to you. Both how the code works and data engineer concepts.¬†\n\n\nGo ahead and do your best, but I'd really recommend you keep looking for a different job.",
          "score": 10,
          "created_utc": "2026-02-02 03:20:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dhsvt",
              "author": "taker223",
              "text": "I second that.\n\n\\> Already experienced engineer (with proven built and working solutions) leaves in a hurry, clearly he would NOT give a f\\*ck about newbie OP and even OP has spotted some \"friction\" between leaving engineer and his boss.\n\n\\> a fresh graduate is hired (for likely a fraction of leaving engineer's salary. Jackpot if he would be on probation/intern)  \n\\> the role is remote and he's multiple states away. Bzzzzt sorry can;t hear you Nelson. Make a jesture if you can hear me! (c) Gavin Belson\n\n\\> nothing really is documented. Means leaving engineer leaves with his institutional knowledge\n\nAs I wrote, \"The best is yet to come...\" (c) Scorpions",
              "score": 1,
              "created_utc": "2026-02-03 17:22:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31rhhb",
          "author": "MonochromeDinosaur",
          "text": "Start getting used to situations like this. Isn‚Äôt the first or last time it‚Äôll happen. \n\nDocument everything, if you have it available record sessions, AI transcripts, take copious notes. If allowed use AI and/or ripgrep to figure out the code.\n\nThe more information you have the better.",
          "score": 3,
          "created_utc": "2026-02-01 22:04:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31gred",
          "author": "chrisgarzon19",
          "text": "Loom record\nDocument \nSend\nIf they have questions questions \nHop on 15 minute call\nUpdate the doc while explaining anything AND record that session as well)",
          "score": 2,
          "created_utc": "2026-02-01 21:12:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o323bq9",
          "author": "adastra1930",
          "text": "Definitely record the meeting for reference later, there will always be stuff you won‚Äôt understand until you‚Äôre stuck into it. Also, in this case where the former person had some friction, please feel confident that if you deviate from their method and create your own approach, that might actually be good for you and your reputation with this new (to you) stakeholder ‚ò∫Ô∏è",
          "score": 2,
          "created_utc": "2026-02-01 23:04:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32mk69",
          "author": "BaddDog07",
          "text": "Focus on what to do if it breaks while he is still there and then figure out the rest later",
          "score": 1,
          "created_utc": "2026-02-02 00:50:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37wton",
          "author": "llamacoded",
          "text": "Honestly, this is a tough spot for your first role. 1.5 weeks with a guy like that is brutal. Don't even try to understand every line of code; you'll burn out.  \n  \nGet him to talk through the \\*critical data paths\\*. Which tables are consumed by the most important downstream systems? Ask:  \n1. What are the inputs for X pipeline? Where do they come from?  \n2. What are the expected outputs? Who uses them?  \n3. How do you know when it breaks? What's the runbook for common failures?  \n  \nDraw diagrams as he talks; even rough ones. Focus on the data contracts. Who relies on this data, and what format do they expect? Don't leave without clear answers on failure modes; that's what'll bite you in production. You'll figure out the \"how\" later.",
          "score": 1,
          "created_utc": "2026-02-02 20:29:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3diide",
              "author": "taker223",
              "text": "What if leaving engineer would simplify all your questions in a general GTFO graph, with arrows and nodes.",
              "score": 1,
              "created_utc": "2026-02-03 17:25:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bjzvm",
          "author": "TitanTheSpidermonkey",
          "text": "Feels like something you can ask Claude. Just audit this codebase and give me an entry point.",
          "score": 1,
          "created_utc": "2026-02-03 10:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dhxs1",
              "author": "taker223",
              "text": "Sure, do some vibes! Better directly on customer production. Real Hands-On approach",
              "score": 1,
              "created_utc": "2026-02-03 17:23:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3jeq89",
                  "author": "TitanTheSpidermonkey",
                  "text": "I meeaaannn!!! lololol\n\nBut I think auditing is ok no? seems inconsequential to me...",
                  "score": 1,
                  "created_utc": "2026-02-04 14:53:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dg0ez",
          "author": "taker223",
          "text": "\\> The current engineer has only a week and a half left at the company and \n\n\\> I observed some friction between him and his boss in our meeting.\n\n\\> This is my first data engineering role after graduating and I'm expected to do a knowledge transfer starting on day one\n\nMakes perfect alignment. \"The best is yet to come...\" (c) Scorpions",
          "score": 1,
          "created_utc": "2026-02-03 17:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ubd6c",
          "author": "PrestigiousAnt3766",
          "text": "You can't..¬†\n\n\nRecord him explaining the flow as much as you can.\n\n\nId focus mostly on design choices, what works, what doesn't. Pieces he's proud of vs what he's not. What he'd do if he'd start over.\n\n\nThat gives you a good idea of what the code should do, why it's built this way (business logic / source weirdness), and what will give you headaches down the line.",
          "score": 1,
          "created_utc": "2026-02-06 03:45:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxhzhs",
      "title": "In what world is Fivetran+dbt the \"Open\" data infrastructure?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxhzhs/in_what_world_is_fivetrandbt_the_open_data/",
      "author": "finally_i_found_one",
      "created_utc": "2026-02-06 13:43:47",
      "score": 45,
      "num_comments": 21,
      "upvote_ratio": 0.98,
      "text": "I like dbt. But I recently saw these weird posts from them:\n\n* [https://www.getdbt.com/blog/what-is-open-data-infrastructure](https://www.getdbt.com/blog/what-is-open-data-infrastructure)\n* [https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future](https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future)\n\nWhat is really \"Open\" about this architecture that dbt is trying to paint?\n\nThey are basically saying they would create something similar to databricks/snowflake, stamp the word \"Open\" on it, and we are expected to clap?\n\nIn one of the posts, they say \"I hate neologisms for the sake of neologisms. No one needs a tech company to introduce new terms of art purely for marketing.\" - its feels they are guilty of the same thing with this new term \"Open Data Infrastructure\". One more narrative that they are trying to sell.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxhzhs/in_what_world_is_fivetrandbt_the_open_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3wlke3",
          "author": "codykonior",
          "text": "Open (your wallet for) data infrastructure.\n\nCompanies who use FiveTran must be the billion dollar types with money burning holes in their pockets.\n\nI had a look at migrating a small ELT process to it last year, which I can run almost free inside Azure SQL DB with scripts and elastic job agent, for a few minutes each night.\n\nFiveTran was going to cost $50kpa, before the recent price increases üòí And you'd be locked in to more. And you'd still have to spend tons of time scripting up stuff.",
          "score": 48,
          "created_utc": "2026-02-06 14:18:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wzt0i",
              "author": "CulturalKing5623",
              "text": "A recent client had maybe 10 sources, none of them larger than 10K records per day. I told them all they needed was to throw some python scripts in an EC2 to handle it, had it built and ready to go. Total cost was probably somewhere around $50/month and it just chugged along, rarely had any issues ever. \n\nFast forward to them hiring a chief \"go to market strategist\" or something like that, the person responsible for getting them acquired, and they decide they need a \"mature data stack\" to be more attractive to outside investors. So we hooked everything up to Fivetran and data bricks and built a medallion architecture and the whole shebang. All great stuff.\n\nThe last time I checked their Fivetran is running at $15k/year and is _constantly_ throwing errors for this reason or that.",
              "score": 10,
              "created_utc": "2026-02-06 15:30:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x0j49",
                  "author": "contrivedgiraffe",
                  "text": "That‚Äôs a great example of the difference between trying to run a business and trying to get acquired.",
                  "score": 14,
                  "created_utc": "2026-02-06 15:33:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wp6l2",
              "author": "finally_i_found_one",
              "text": "No doubt they are going to raise prices. They now own the first and the middle layer of the data architecture. Also, they are now a monopoly in the data transformation space.",
              "score": 3,
              "created_utc": "2026-02-06 14:36:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3yh2p2",
              "author": "baronfebdasch",
              "text": "To be fair, the value proposition of FiveTran is always competing against a ‚Äúroll your own‚Äù extracting method. It‚Äôs not rocket science. \n\nIf your data environment is relatively fixed I would agree there is almost no point. \n\nBut if you‚Äôre in the business of having to extract data from dozens of systems, then it‚Äôs a matter of ‚Äúdo I pay my engineers to keep the lights on at making sure our data extraction jobs are always running, up to date, and can manage various versions of source systems, or do I simply outsource that part of the value chain and focus on actually making the data usable? \n\nIf you are a company that needs to focus on integrating data from say dozens of ERPs‚Ä¶ maybe it‚Äôs worth it to let FiveTran expedite when a new ERP hits the market (or one you haven‚Äôt seen before). \n\nOr you‚Äôre setting up a brand new data infrastructure and your sponsors are breathing down your neck to integrate your new HR system. You can spend days/weeks working through building jobs to extract said data, or have it with FiveTran in minutes. \n\nBecause they typically price on monthly deltas volumes there‚Äôs kind of a middle tier where it makes sense as part of your tech stack. Too low and it‚Äôs too expensive, and if your data volumes are massive, again, too expensive. But if you‚Äôre in that sweet spot, it may be worth paying a vendor than paying an engineer to perform those tasks.",
              "score": 3,
              "created_utc": "2026-02-06 19:43:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3woj7w",
          "author": "Known-Huckleberry-55",
          "text": "The world they are pitching is one where data is stored in Iceberg tables in storage owned by companies (S3, ADLS2) and that the compute layer becomes a commodity that can become easily swapped out. One of the big features of Fusion is that it can cross-compile across different SQL dialects. Instead of getting locked into Snowflake, you can easily switch to duckdb, Databricks, whatever for different use cases.\n\nAll that said, my Fivetran and dbt Cloud bill is much higher than my Snowflake bill so I'm not worried about the compute layer like they seem to think companies are.",
          "score": 13,
          "created_utc": "2026-02-06 14:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wkcg5",
          "author": "drew-saddledata",
          "text": "dbt core is pretty good.  It's funny, I have build the same thing they envision in that blog post, ETL pipeline tool and dbt working together as a SaaS.",
          "score": 10,
          "created_utc": "2026-02-06 14:11:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wka75",
          "author": "Illustrious_Web_2774",
          "text": "No surprise. They fucked up the word \"model\" pretty badly.",
          "score": 7,
          "created_utc": "2026-02-06 14:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wj1ut",
          "author": "omonrise",
          "text": "well there's OpenAI ü§£",
          "score": 3,
          "created_utc": "2026-02-06 14:04:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wq3zx",
              "author": "Any_Tap_6666",
              "text": "Like the 'Democractic Republic of Congo'",
              "score": 4,
              "created_utc": "2026-02-06 14:41:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x3swm",
                  "author": "blueadept_11",
                  "text": "And Democratic People's Republic of Korea",
                  "score": 4,
                  "created_utc": "2026-02-06 15:49:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wosm6",
              "author": "finally_i_found_one",
              "text": "haha",
              "score": 2,
              "created_utc": "2026-02-06 14:34:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wxg1y",
          "author": "Nekobul",
          "text": "The \"modern\" keyword is now toxic. The new psyop is called \"open\". ",
          "score": 4,
          "created_utc": "2026-02-06 15:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wip08",
          "author": "West_Good_5961",
          "text": "dbt core is pretty open",
          "score": 9,
          "created_utc": "2026-02-06 14:02:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wo81g",
              "author": "finally_i_found_one",
              "text": "Doesn't really answer what I am asking. I hope you don't believe that Fivetran (who just ate dbt and SQLMesh) is going to create something \"Open\".",
              "score": 6,
              "created_utc": "2026-02-06 14:31:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xtwwk",
          "author": "Possible_Ground_9686",
          "text": "Apache NiFi still going strong üí™üí™üí™",
          "score": 3,
          "created_utc": "2026-02-06 17:52:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yvzhf",
          "author": "thisFishSmellsAboutD",
          "text": "Remember a year ago when SQLMesh didn't the same, but for free and much faster?\n\nThey were super responsive and moved fast towards a pretty decent maturity level.\n\nThen, acquisition.\n\nWho else is dreading the inevitable license rug pull from Fivetran?",
          "score": 2,
          "created_utc": "2026-02-06 20:57:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zggge",
          "author": "muneriver",
          "text": "My POV is someone who is closely following the work happening in iceberg, arrow, ADBC, data fusion, etc. These are technologies that are making data tools more interoperable and standardized which is what open here refers to.\n\n‚Äî-\n\nSo back to my point: I think some of the disagreement here comes from how people are defining ‚Äúopen.‚Äù It doesnt necessarily mean open source. It‚Äôs quite literally about open standards and moving away from ‚Äúproprietary interfaces‚Äù since this unlocks so much (minimizing vendor lock-in is the first high level superficial answer).\n\nAs an example: warehouses bundled storage, compute, and file formats together. That‚Äôs where the real lock-in came from. If your data lived inside a proprietary format  (like in Snowflake), you were effectively tied to that engine.\n\nThe thing that‚Äôs really changing is the growth of standardized layers. Open table formats like iveberg and delta, arrow (as a shared in-memory format), and newer engines like duckdb and data fusion all point in the same direction. When data is stored in formats multiple engines __can__ read, compute becomes easier to swap and vendors have to compete more on performance than on lock-in.\n\nVendors are still vendors. Nothing about this means tools like Fivetran+dbt are suddenly open source. The idea is that they operate on top of infrastructure that is less restrictive than the old warehouse model - there‚Äôs so much to unpack tho in terms of current technological developments and what future data platform will look like. \n\nAll of this to say, I try not to take anything with face value. There‚Äôs always nuance. Yes it‚Äôs marketing for sure, but if you follow the current states of technology, there‚Äôs real nuance here.",
          "score": 2,
          "created_utc": "2026-02-06 22:41:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y25qn",
          "author": "GreyHairedDWGuy",
          "text": "I tend to filter out all the nonsense terms vendors use to promote their offerings.  At the end of the day, using Fivetran (for example) is an economic decision....is it lower cost/reliable/faster to use FT versus paying a developer to build it and maintain it.  For some things yes, other no.  We use Fivetran and it works well for us but it's not economic to use is all situations and so we have rolled our own replication processes as needed.",
          "score": 1,
          "created_utc": "2026-02-06 18:31:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y62r2",
          "author": "Typhon_Vex",
          "text": "open source mostly often only means a demo or shareware that will eventually be sold and monetized.\n\nthe word open source is way overused.\n\nit shouldn¬¥t be used for pieces of software maintained by typically a lone company, typically of the same name, and which only work well when you buy the fully supported version",
          "score": 1,
          "created_utc": "2026-02-06 18:50:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quddio",
      "title": "What are people transitioning to if they can't find a job?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1quddio/what_are_people_transitioning_to_if_they_cant/",
      "author": "SoggyGrayDuck",
      "created_utc": "2026-02-03 00:48:42",
      "score": 43,
      "num_comments": 52,
      "upvote_ratio": 0.84,
      "text": "I have some time but I'm preparing myself for what will probably be the inevitable in this market. Im using outdated technology and in this market I keep seeing that classes or certs won't help. I've heard some say they changed directions and I'm curious what people are finding? \n\nI know we can transition to ML but I'm assuming that needs a math background. AI is an option but then you're competing with new grads (do we even stand a chance? Does our background experience help?). I'm asking for more general answers but my background issue is essentially being a jr-mid level at 3-4 different positions, all at smaller companies and more of a startup environment. Platform/cloud (AWS) engineering, bi developer, data engineer and architect. I would be EXTREMELY valuable if this background was at larger companies. \n\nFrom what I can see this isn't valuable unless you're senior/staff or a cloud architect level. They don't bring in jr/mid level and train them, at least not right now. ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1quddio/what_are_people_transitioning_to_if_they_cant/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o39bubs",
          "author": "AutoModerator",
          "text": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-03 00:48:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39o739",
          "author": "chrisgarzon19",
          "text": "Become a senior BIE \nOr DE \nYou can still very much get data roles\n\nYou‚Äôre just gonna have to apply 10x more than what you thought you would",
          "score": 43,
          "created_utc": "2026-02-03 01:59:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b8oed",
              "author": "SoggyGrayDuck",
              "text": "With my outdated environment I need to learn Python as well. I'm not scared of it and have used it plenty but just not in production and definitely not senior de level.",
              "score": 6,
              "created_utc": "2026-02-03 08:53:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3e17px",
                  "author": "Thinker_Assignment",
                  "text": "If you get discouraged keep in mind the 20 hour rule (look it up for an inspiring video) - says you can get basic at anything if you just put in the time",
                  "score": 6,
                  "created_utc": "2026-02-03 18:50:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bmf85",
          "author": "Schwartz210",
          "text": "If DE is the career you want then you need to fight for it. Apply, apply, apply! Fix your resume if you can't get an interview. Fix your interview skills if you can't convert interviews to offers. Always upskill. Stay persistent and pound the pavement. I graduated during the Financial Crisis with a totally different background. Bad markets happen, but this is a high demand profession. If you can't land roles with decent experience then don't expect to walk into another profession and score jobs. If DE is what you want then you need to plant your flag.",
          "score": 16,
          "created_utc": "2026-02-03 11:04:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e1gbj",
              "author": "Outside_Reason6707",
              "text": "Can I dm you? I‚Äôm in interview process and unable to convert",
              "score": 2,
              "created_utc": "2026-02-03 18:51:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3e7qi3",
                  "author": "Schwartz210",
                  "text": "Sure",
                  "score": 1,
                  "created_utc": "2026-02-03 19:20:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3qle4p",
              "author": "shimell",
              "text": "Hi Can I dm you. I am too in interview process but unable to convert.",
              "score": 1,
              "created_utc": "2026-02-05 16:15:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ax470",
          "author": "susosexy",
          "text": "IMO if you were to transition to ML/AI engineering, you would be fighting another steeper and longer uphill battle. In your current situation you are already climbing a hill, but atleast you're on your way up. It would make more sense to build out your skills in DE and grow from there.",
          "score": 8,
          "created_utc": "2026-02-03 07:05:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c0wpg",
              "author": "SoggyGrayDuck",
              "text": "Thanks, the gatekeepers in these subs out there telling people it's pointless to upskill and you'll never get the skills you actually need doing so are just making the situation worse. I just don't want to dump months and thousands only to be pushed out anyway. I am in the rare situation I could go back to grad school but damn, that's something I haven't thought about in 7+ years and don't even know if that would help. It's such an uphill battle to get your brain back to education mode. I'm getting there but it's been a battle. I need more hands on",
              "score": 1,
              "created_utc": "2026-02-03 12:54:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3hfnuf",
                  "author": "susosexy",
                  "text": "If it was pointless to upskill then there would be no reason to learn and get better at anything. Truth be told, most engineers are probably in situations where their environment and tech stack hinders them from learning, so the best way is often to learn yourself. Whether you should pursue further studies is another question on its own, but if you have genuine interest and are certain it can help you, then go for it.",
                  "score": 2,
                  "created_utc": "2026-02-04 05:54:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c6hf9",
          "author": "Odd-Government8896",
          "text": "Dude what's your outdated tech your so worried about? Access?\n\nI use Databricks everyday, and its still just SQL, with Python for the complicated or production bits.\n\nIf you know how to use pandas, you're going to be fine.\n\nDon't let these guys fool you with their whacky stacks. Get yourself a spark docker image, maybe with dbt, or a free databricks account and just start messing with it.",
          "score": 9,
          "created_utc": "2026-02-03 13:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c9wlp",
              "author": "Spunelli",
              "text": "This is what I keep saying but employers are NOT entertaining anyone without the direct experience in databricks.",
              "score": 4,
              "created_utc": "2026-02-03 13:47:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3cnard",
                  "author": "SoggyGrayDuck",
                  "text": "This is what im finding as well. Why teach someone the interface if you don't need to. My recruiter advised learning snowflake first but I see databricks come up a LOT in requirements. This market happened at the absolute worst time for me. I kept reaching and getting positions in was slightly under qualified for (because you could and they'd let you learn) and now feel like I'm a jr-mid level in several areas. I literally had consultants trying to recruit me, telling me I think like a CIO and to continue the path of learning everything vs going deeper into a particular topic and now I'm looking at getting pushed out of the industry. I needed just one more job to tie everything together and we ended up getting offshored vs getting any kind of training.",
                  "score": 2,
                  "created_utc": "2026-02-03 14:58:31",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o3csqxa",
                  "author": "MakeoutPoint",
                  "text": "I did mine on company time as \"research into potential new system to solve issues\". Built my own little setup, got familiar using company data, and boom there's your direct experience and it's not even a lie.\n\n\nThey won't be calling your employer, and if they did it would just be to verify employment, not to ask about the tech stack.",
                  "score": 2,
                  "created_utc": "2026-02-03 15:25:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3dqssr",
                  "author": "Odd-Government8896",
                  "text": "Very unfortunate. The whole point to databricks is that anyone can build hyper scaled analytics platforms without worrying about something like pyarrow. Hell, serverless makes it even more brain dead.",
                  "score": 1,
                  "created_utc": "2026-02-03 18:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cxfcy",
          "author": "thethirdmancane",
          "text": "Unemployed senior data engineer here. Over 10 years of experience building data pipelines in Python SQL, and golang. I applied for over 200 jobs. Got plenty of interviews but no takers. I finally got a non-paying gig building data pipelines for non-profits as a volunteer. I love data engineering so much I just can't give it up. So now I just do it for free.",
          "score": 4,
          "created_utc": "2026-02-03 15:47:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3midu5",
              "author": "CaptainDawah",
              "text": "200 roles within what time frame? That seems a bit low",
              "score": 1,
              "created_utc": "2026-02-04 23:46:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o39m8n7",
          "author": "shittyfuckdick",
          "text": "Trying to figure this out as well. I have 8 years. experience with most the popular DE tools and still cant land a job anywhere.¬†",
          "score": 12,
          "created_utc": "2026-02-03 01:48:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3a2fgb",
              "author": "mistanervous",
              "text": "In what country are you located/looking? Just curious",
              "score": 5,
              "created_utc": "2026-02-03 03:20:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3a55c1",
                  "author": "thelewdfolderisvazio",
                  "text": "Yeah me too, seems quite odd...",
                  "score": 2,
                  "created_utc": "2026-02-03 03:37:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3c74j2",
                  "author": "shittyfuckdick",
                  "text": "In the US",
                  "score": 1,
                  "created_utc": "2026-02-03 13:31:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3blsxx",
          "author": "Raddzad",
          "text": "If you have experience, I would say even as a mid it's hard not to find a job in this market, even if you have to wait a little bit. DEs are literally the gold for the AI hype",
          "score": 3,
          "created_utc": "2026-02-03 10:59:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39mz7s",
          "author": "KBaggins900",
          "text": "I have been wanting a data engineering job but unfortunately I‚Äôm stuck in .net dev at the moment.",
          "score": 3,
          "created_utc": "2026-02-03 01:52:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b7ujl",
          "author": "techjobmentor",
          "text": "sometimes overlooked, but, given your data expertise, you have already learned a lot of insights into the business, so switching to a technical project manager role is an option I've seen some peers succeed at, better paid even",
          "score": 3,
          "created_utc": "2026-02-03 08:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3axjyl",
          "author": "Thinker_Assignment",
          "text": "As a senior DE with a pinch of AI, you're the GOAT in this market",
          "score": 4,
          "created_utc": "2026-02-03 07:09:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c2jrt",
              "author": "SoggyGrayDuck",
              "text": "Like the other person asked, what should I be looking at for upskilling? \n\nI agree that this best aligns with my background. I think about the big picture but my dev skills are weak. Id be the AI dev that knows what I want each piece to do and build them out independently. \n\nI also feel like I need a slightly better understanding of the new cloud architecture. I'm slowly coming to the realization that the answer is \"whatever agile demands\" but that CAN'T be right. It might be what happens but I want to know what's ideal so I can keep it as close to standard as possible. Any good links on modern data structures? Ideally it would use older architecture as an example/reference. Ie source data --> star schema --> data cube --> kpi",
              "score": 2,
              "created_utc": "2026-02-03 13:04:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ck7vs",
                  "author": "Thinker_Assignment",
                  "text": "Honestly from my experiments coding is going away - in the sense that machines will do it.  \nSo what I would do is learn the architecture and understand capabilities so you can design these systems and get a feel for what might work, how to do it.\n\n\\- understand architecture basics - fuck all the old stuff, it's not valid anymore, nobody has 5 years to debate a perfect canonical model or enteprise model nowadays. you want to understand:  Path a: Data vault, canonical data model, and denormalisation of it into snowflake->star->obt schemas. Path b: activity schema (radically different model). On canonical or its denorms, see semantic layers for chat-bi\n\n\\- understand AI basics  \n\\- rags, eval, agent skills, mcp, knoweldge graph (basically unstructured data modeling)  \n\\- multimodal data (audio video)\n\ni will write more about it on our blog as it's an interesting topic for me to push what can be done and see what's left.",
                  "score": 6,
                  "created_utc": "2026-02-03 14:42:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3b33s2",
              "author": "MightyFinch",
              "text": "What kind of AI stuff do you know in relation to DE that is helping you ?",
              "score": 1,
              "created_utc": "2026-02-03 08:00:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3c6vc3",
                  "author": "Odd-Government8896",
                  "text": "ai_query()\n\n... Seriously lol.. Google it",
                  "score": 2,
                  "created_utc": "2026-02-03 13:30:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3exfu2",
          "author": "ironmagnesiumzinc",
          "text": "Has it always been this hard to find a DE (or equivalent) job?",
          "score": 1,
          "created_utc": "2026-02-03 21:20:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eyqll",
              "author": "SoggyGrayDuck",
              "text": "Nope, people had 2-3 remote positions for a bit during/after COVID. It was back when the leaders/business side was responsible for requirements and etc. They've pushed all of that down onto the engineers. For several reasons it means they can't really use jr/mid level devs.",
              "score": 5,
              "created_utc": "2026-02-03 21:26:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvoj0i",
      "title": "Financial engineering at its finest",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qvoj0i/financial_engineering_at_its_finest/",
      "author": "SignalMine594",
      "created_utc": "2026-02-04 13:27:12",
      "score": 41,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "I‚Äôve been spending time lately looking into how big tech companies use specific phrasing to mask (or highlight) their updates, especially with all the chip investment deals going on. \n\nEarlier this week, I was going through the Microsoft earnings call transcript and (based on what seems like shared sentiment in the market), I was curious how Fabric was represented. From my armchair analyst position, its adoption just doesn‚Äôt seem to line up with what I assumed would exist by now...\n\nOn the recent FY26 Q2 call, Satya said:\n\n>Two years since it became broadly available, Fabric's annual revenue run rate is now over $2 billion with over 31,000 customers... revenue up 60% year over year.\n\nThe first thing that made me skeptical is the type of metrics used for Fabric. ‚ÄúAnnual revenue run rate‚Äù is NOT the same as ‚Äúwe actually generated $2B over the last 12 months.‚Äù This is super normal when startups report earnings, since if a product is growing, run rate can look great even when realized trailing revenue is still catching up. Microsoft chose run rate wording here.\n\nThen I looked at the previous earnings where Fabric was discussed. In FY25 Q3, they said Fabric had 21k paid customers and ‚Äú40% using Real-Time Intelligence‚Äù five months after GA, but ‚Äúusing‚Äù isn‚Äôt defined in a way that‚Äôs tangible, which usually is telling. In last week‚Äôs earnings, Satya immediately discusses specific metrics, customer references, etc. for other products.\n\nA huge part of why I‚Äôm also not convinced on adoption is because of the forced Power BI capacity migration. I know the world is all about financial engineering, and since Microsoft forced us all to migrate off of P-SKUs, it‚Äôs not hard to advertise those numbers as great. The conspiracist in me says the numbers line up a little too neatly with the SKU migration:\n\n* $2B in revenue run rate / 31,000 customers ‚âà $64.5k per customer per year.¬†\n* That‚Äôs conveniently right around the published price of an F64 reservation\n\nObviously an average is oversimplifying it, and I don‚Äôt think Microsoft is lying about the metrics whatsoever, but I do think the phrasing doesn‚Äôt line up with the marketing and what my account team says‚Ä¶\n\nThe other thing I saw was how Microsoft talks when they have deeper adoption. They normally use harder metrics like customers >$1M, big deployments, customer references, etc. In the same FY26 Q2 transcript, Fabric gets the run-rate/customer count and then the conversation moves on. And that‚Äôs it. After that, I was surprised that Fabric was never mentioned on its own again, nor expanded upon, and outside of that sentence, Fabric was always mentioned with Foundry.\n\nEarnings reports aren't everything, and 31,000 customers is a lot, so I went looking for proof in customer stories, and the majority of the stories are just implementation partners and consultancies whose practices depend on selling Fabric (Boutiques/Avanade types), not a flood of end-customer production migrations with scale numbers. (There are are a couple of enterprise stories like LSEG and Microsoft‚Äôs internal team, but it doesn‚Äôt feel like ‚Äúno shortage.‚Äù)\n\nPlease check me. Am I off base here? Or is the growth just because of the forced migration from Power BI?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qvoj0i/financial_engineering_at_its_finest/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3lbqv3",
          "author": "engineer_of-sorts",
          "text": "It's literally power bi\n\n  \nthe idea there are $2bn of data engineering workloads running on fabric cannot be true",
          "score": 13,
          "created_utc": "2026-02-04 20:13:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j8wly",
          "author": "Kobosil",
          "text": ">forced migration\n\nah the Microsoft way",
          "score": 15,
          "created_utc": "2026-02-04 14:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j30gf",
          "author": "Nofarcastplz",
          "text": "It would definitely validate what I read here on this subreddit",
          "score": 8,
          "created_utc": "2026-02-04 13:52:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nbkzp",
              "author": "EversonElias",
              "text": "People here just want to hate Fabric. I got downvoted hard because I said I like it.",
              "score": -4,
              "created_utc": "2026-02-05 02:31:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qu47hc",
      "title": "When Your Career Doesn‚Äôt Go as Planned",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qu47hc/when_your_career_doesnt_go_as_planned/",
      "author": "krmehul-tech-7564",
      "created_utc": "2026-02-02 19:02:33",
      "score": 39,
      "num_comments": 20,
      "upvote_ratio": 0.91,
      "text": "Sometimes in life, what you plan doesn‚Äôt work out.\n\nI prepared for a Data Engineer role since college. I got selected on campus at Capgemini, but after joining, I was placed into the SAP ecosystem. When I asked for a domain change, I was told it‚Äôs not possible.\n\nNow I‚Äôm studying on my own and applying daily for Data Engineer roles on LinkedIn and Naukri, but I‚Äôm not getting any responses.\n\nIt feels like no matter how much we try, our path is already written somewhere else. Still trying. Still learning.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qu47hc/when_your_career_doesnt_go_as_planned/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o37joqj",
          "author": "ironwaffle452",
          "text": "I never wanted to be data engineer but i give up LOL now almost 8yo, i never had the opportunity to choose the job",
          "score": 30,
          "created_utc": "2026-02-02 19:27:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37l7eq",
              "author": "krmehul-tech-7564",
              "text": "Everyone‚Äôs journey is different. I didn‚Äôt get many chances to choose early, so now I‚Äôm shaping my path step by step. Learning and adapting is my only option.I don't know what will happen in future....",
              "score": 6,
              "created_utc": "2026-02-02 19:34:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37ubm2",
                  "author": "SalamanderMan95",
                  "text": "If you‚Äôre not a data engineer by 7 you might as well give up, everyone knows that once you hit 12 you start getting aged out. But seriously, it‚Äôs a marathon not a sprint",
                  "score": 8,
                  "created_utc": "2026-02-02 20:17:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37keah",
          "author": "ratczar",
          "text": "Be the best prisoner you can be: [Learning to Measure Time in Love and Loss - The New York Times](https://www.nytimes.com/2024/10/18/style/modern-love-classic-learning-to-measure-time-in-love-and-loss.html)",
          "score": 9,
          "created_utc": "2026-02-02 19:31:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3all34",
          "author": "MPGaming9000",
          "text": "I feel the same way. I got lumped into Support Engineering roles due to my customer service background and I'm finding it hard to break out. People say 'just work on projects' as if it actually fucking makes a difference. Nobody actually gives a shit about your projects no matter how impressive they are because it doesn't count as 'real experience' to actual hiring managers in this job market. Just sucks man. Not sure what else to really do at this point.",
          "score": 12,
          "created_utc": "2026-02-03 05:29:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3aqal7",
              "author": "krmehul-tech-7564",
              "text": "Yeah man, what else can we do. Just keep trying skill up, apply as much as possible, and hope something works out. That‚Äôs what I‚Äôm doing too, along with a few certifications.",
              "score": 1,
              "created_utc": "2026-02-03 06:06:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3apmg0",
              "author": "Sensitive-Sugar-3894",
              "text": "In this case, automate all you can. Even minor validations. Then ask AI for a way to sell it in your LinkedIn.",
              "score": -2,
              "created_utc": "2026-02-03 06:01:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fnkt6",
          "author": "TheOverzealousEngie",
          "text": "to be clear, data engineering is one of the most turbulent careers you could choose. Except for the part about SAP. I do believe that sap will find a way to survive even when the world ends.",
          "score": 5,
          "created_utc": "2026-02-03 23:29:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gbro9",
              "author": "lmottads",
              "text": "I'm with you. It could be a lot worse. SAP is solid as hell. Of course, it is frustrating not being able to set your path. But you can actually run some local DE projects on your own and learn by yourself. You could hardly do that with SAP, and it is a good skill to have.",
              "score": 2,
              "created_utc": "2026-02-04 01:43:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jwo6n",
          "author": "Awkward_Tick0",
          "text": "Dude it sounds like you‚Äôre just starting. Why the sob story",
          "score": 2,
          "created_utc": "2026-02-04 16:18:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jywi3",
          "author": "dessmond",
          "text": "OP, I feel you. SAP is a horrible beast. It‚Äôs so complex and so huge nobody wants to touch that shit. Hence, a lot of money can be made, though.",
          "score": 2,
          "created_utc": "2026-02-04 16:28:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o8c99",
              "author": "Economy_Passenger_93",
              "text": "What is SAP",
              "score": 1,
              "created_utc": "2026-02-05 06:07:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3axqun",
          "author": "Thinker_Assignment",
          "text": "Get into any technical role closer to data and move from there",
          "score": 1,
          "created_utc": "2026-02-03 07:10:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ay17y",
              "author": "krmehul-tech-7564",
              "text": "Thanks üëç",
              "score": 1,
              "created_utc": "2026-02-03 07:13:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwdlph",
      "title": "Offered a client a choice of two options. I got a thumbs up in return.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwdlph/offered_a_client_a_choice_of_two_options_i_got_a/",
      "author": "Shadowlance23",
      "created_utc": "2026-02-05 06:15:00",
      "score": 38,
      "num_comments": 27,
      "upvote_ratio": 0.91,
      "text": "I'm building out a data source from a manually updated Excel file. The file will be ingested into a warehouse for reporting. I gave the client two options for formatting the file based on their existing setup. One option requires more work from the client upfront, but will save time when adding data in the future. The second one I can implement as-is without extra work on their end but will mean they have to do extra manual work when they want to update the source.\n\nI sent them a message explaining this and asking which one they preferred. As the title suggests, their response was a thumbs up.\n\nIt's late and I don't have bandwidth to deal with this... Looks like a problem for Tomorrow Man (my favourite superhero, incidentally).\n\nEDIT: I hate you all üòÇ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwdlph/offered_a_client_a_choice_of_two_options_i_got_a/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3o9kvc",
          "author": "LoaderD",
          "text": "üëç",
          "score": 35,
          "created_utc": "2026-02-05 06:17:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oajv2",
          "author": "MichelangeloJordan",
          "text": "üëç LGTM",
          "score": 14,
          "created_utc": "2026-02-05 06:26:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3obkec",
          "author": "Thisisinthebag",
          "text": "üëå",
          "score": 10,
          "created_utc": "2026-02-05 06:34:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oero4",
          "author": "every_other_freackle",
          "text": "üëç",
          "score": 9,
          "created_utc": "2026-02-05 07:02:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ohtpb",
          "author": "je_grootje",
          "text": "üëç",
          "score": 6,
          "created_utc": "2026-02-05 07:30:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oov8b",
          "author": "Putrid-Kale-1793",
          "text": "üëçüèª",
          "score": 6,
          "created_utc": "2026-02-05 08:37:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oqnfn",
          "author": "pndrng",
          "text": "üëç",
          "score": 6,
          "created_utc": "2026-02-05 08:54:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3omnof",
          "author": "Ok_Smell_453",
          "text": "Always choose the option with \n\nLittle to no maintenance once setup \nTime spent vs time saved\n\nFirst one is key.",
          "score": 10,
          "created_utc": "2026-02-05 08:15:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p5okr",
              "author": "MK_BombadJedi",
              "text": "üëç",
              "score": 8,
              "created_utc": "2026-02-05 11:15:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pdn20",
              "author": "Shadowlance23",
              "text": "In this case, the extra effort is on the part of the client. It's up to them to keep the source updated. On my end, it makes no difference. Basically, the choice was to either add a couple extra columns to the source table to capture data they aggregate manually now and the warehouse will handle the automation, or they can just do the aggregation themselves and the warehouse will read it directly. \n\nMaybe it's my fault for giving them the option in the first place.",
              "score": 8,
              "created_utc": "2026-02-05 12:18:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3zozka",
                  "author": "Ok_Smell_453",
                  "text": "It's a learning curve but if possible, you want code or a process to not involve any updating going forward. \n*With the exception of new fields, etc*\n\nüëçüëçüëçüëçüëçüëç",
                  "score": 1,
                  "created_utc": "2026-02-06 23:28:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ov3rp",
          "author": "Strange-Ninja3214",
          "text": "üëç indeed",
          "score": 3,
          "created_utc": "2026-02-05 09:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p1xvi",
          "author": "mushashi_san",
          "text": "üëç",
          "score": 3,
          "created_utc": "2026-02-05 10:42:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3par5n",
          "author": "SoggyGrayDuck",
          "text": "Isn't it getting insane, they no longer understand what they're even asking for. Are they not the ones who are actually asking for the metrics? Are executives telling directors they need these metrics without any direction? Is this more BS rolling downhill from some conference?",
          "score": 3,
          "created_utc": "2026-02-05 11:56:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v9da4",
          "author": "Cruxwright",
          "text": "Some things to keep in mind when sending e-mails and requesting feedback:\n\n1- Some people only read the first line and will write their entire reply based on that.\n\nB- Only ask Yes/No questions as many people are incapable of making a choice.\n\niii- Posit the solution that works for you while keeping points 1 and B in mind.",
          "score": 3,
          "created_utc": "2026-02-06 08:11:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p9z0c",
          "author": "poroloid1337",
          "text": "üëç",
          "score": 2,
          "created_utc": "2026-02-05 11:50:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3palxj",
          "author": "Maximum_Syrup998",
          "text": "üëç",
          "score": 2,
          "created_utc": "2026-02-05 11:55:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3te4db",
          "author": "reditandfirgetit",
          "text": "![gif](giphy|RJwdVNdPGxyYQwKu4K)",
          "score": 2,
          "created_utc": "2026-02-06 00:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rzdt7",
          "author": "hubert1224",
          "text": "üëç",
          "score": 1,
          "created_utc": "2026-02-05 20:07:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3u317g",
          "author": "Daddy_data_nerd",
          "text": "üëç",
          "score": 1,
          "created_utc": "2026-02-06 02:53:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uhre8",
          "author": "Childish_Redditor",
          "text": "They're letting you choose",
          "score": 1,
          "created_utc": "2026-02-06 04:27:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vf8rd",
          "author": "BrownBearPDX",
          "text": "Grow up and push for a real answer that will actually be documented and signed off on. Are you afraid of this person who gave you the thumbs up? Tell them ha ha I need a real answer. I can‚Äôt work with a thumbs up for two options. \n\nSign off Will save your skin when this idea of using actual Excel spreadsheet with manually input data blows up, and the whole thing comes tumbing down. If you don‚Äôt have strong data types and validation and schema and you have somebody who is this slack in their care of the project and the dev implementing it, it‚Äôs gonna slide into hellville about two seconds after you launch.",
          "score": 1,
          "created_utc": "2026-02-06 09:08:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3vlh7s",
              "author": "Shadowlance23",
              "text": "Whoa dude calm down. I was having a little joke at the end of the day, not an existential crisis.",
              "score": 2,
              "created_utc": "2026-02-06 10:08:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wejhv",
          "author": "Expensive_Culture_46",
          "text": "üññ",
          "score": 1,
          "created_utc": "2026-02-06 13:40:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xm0tw",
          "author": "jorbai",
          "text": "üëçüèª",
          "score": 1,
          "created_utc": "2026-02-06 17:14:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pf0bc",
          "author": "Ploasd",
          "text": "Just ring them up and ask them",
          "score": 1,
          "created_utc": "2026-02-05 12:27:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pkftq",
              "author": "Shadowlance23",
              "text": "That's great advice! I'll do that first thing in the morning!",
              "score": 2,
              "created_utc": "2026-02-05 13:03:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qv7786",
      "title": "People who moved from DE to Analytics Engineering",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qv7786/people_who_moved_from_de_to_analytics_engineering/",
      "author": "PremierLeague2O",
      "created_utc": "2026-02-03 22:58:09",
      "score": 32,
      "num_comments": 32,
      "upvote_ratio": 0.85,
      "text": "I want to learn about experiences of people who moved from DE to Analytics Engineering. Why did you make the change? What has been your learning so far and how do you see your career progress like how you would brand yourself? Is it a step up from previous role or a step down?\n\nP.s I‚Äôm a DE with 8 years of experience curious to know if it‚Äôs a good career move",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qv7786/people_who_moved_from_de_to_analytics_engineering/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3fhp73",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-03 22:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hzkxd",
          "author": "valentin-orlovs2c99",
          "text": "Did that move about 3 years ago, can share my 2 cents.\n\nWhy I switched: I realized the parts of DE I enjoyed most were modeling data for analysts, arguing about metrics definitions, and making dashboards actually useful. I cared less about perfect infra and more about ‚Äúare people making better decisions with this.‚Äù Analytics engineering was basically that full time.\n\nDay to day difference: as a DE I spent a lot of time on infra, pipelines, performance, random firefighting. As an AE I‚Äôm still writing SQL and some Python, but I‚Äôm way closer to the business. More time on dbt models, tests, documentation, semantic layers, and collaborating with PMs / analysts. Less Kafka / Spark / k8s, more ‚Äúwhat does ‚Äòactive user‚Äô actually mean and can we stop changing it every quarter.‚Äù\n\nStep up or step down: it‚Äôs more of a fork than a ladder. If you like infra and scale problems, AE will feel softer. If you like modeling, metrics, and being involved in product / strategy chats, it feels like a step up because your impact is easier to see. Comp for me stayed roughly the same, slightly higher later because I became the ‚Äúmetrics owner‚Äù and that‚Äôs valuable at product‚Äëled companies.\n\nBranding / career path: I brand myself as ‚Äúdata platform + analytics‚Äù now. Titles I see after AE: senior AE, analytics lead, data product manager, head of data, sometimes even PM for data products. You become a good candidate for roles where you‚Äôre the bridge between pure engineering and pure analytics.\n\nGotchas:\nYou will write a lot of SQL and stakeholder‚Äëfriendly docs.\nYou‚Äôll spend more time in meetings explaining data than tuning clusters.\nIf you hate ambiguity and politics around definitions, it can be frustrating.\n\nWith 8 years as DE you‚Äôre probably overqualified on the tech side. The real question is whether you want to move closer to the business and be judged more on clarity, communication and ‚Äúdoes this metric make sense‚Äù than on how elegant your pipeline is. If yes, AE is a pretty solid move.",
          "score": 66,
          "created_utc": "2026-02-04 08:49:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nyzxu",
              "author": "tamerlein3",
              "text": "An anecdote, not me but I‚Äôve seen someone become a metrics owner like this. After climbing the ladder, did nothing but build crappy shadow platforms for years that had a ton of ‚Äúinner platform‚Äù effect. Was not accountable to either side because he changes into the most convenient persona depending on the audience. (To business side he is advancing the tech stack, to techies he is the business expert). Had to get new senior leadership who understood both sides to put an end to this multi-year productivity and money sink. \n\nDon‚Äôt become this, keep your skills sharp.",
              "score": 6,
              "created_utc": "2026-02-05 04:56:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3h45vs",
          "author": "apache_tomcat40",
          "text": "I have done it all, SDE to BIA to BIE to DE to AE now. Consistent thing across all the roles is having good grasp on business context and basics.",
          "score": 16,
          "created_utc": "2026-02-04 04:31:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hqjv3",
              "author": "shanksfk",
              "text": "What about Data ops?",
              "score": 3,
              "created_utc": "2026-02-04 07:26:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3hwyvi",
                  "author": "apache_tomcat40",
                  "text": "I‚Äôll answer if you can define what DataOps means to you.",
                  "score": 7,
                  "created_utc": "2026-02-04 08:24:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3fyhcr",
          "author": "sahelu",
          "text": "I think for every 4 DEs there is one AE. I have seen many teams working like that. So less chances to land a job.",
          "score": 15,
          "created_utc": "2026-02-04 00:29:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hhhwg",
              "author": "SellGameRent",
              "text": "our company has almost entirely AEs because the ETL is done largely with fivetran",
              "score": 9,
              "created_utc": "2026-02-04 06:09:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3im9m4",
                  "author": "SoggyGrayDuck",
                  "text": "Yeah the way medallion architecture is approached today new data can be made available extremely quickly. DEs can crank out 'datamarts' and let the more advanced AEs handle putting it all together. I think I'm going to be pushed in this or BI direction too. Have to decide if I take the uphill battle of learning what I need to know about DE coming from a traditional data warehousing background or pivot to BI/AE. I feel like BI/DE would simply require a class or two on the reporting tools with my background. DE means improving my python, learning spark, creating GitHub projects to show I can do it & really learning code repos, cloud formation and doing everything from an SDK/cloud formation template. I have all those background skills but need an employer to simply show/let me learn the tools/interface",
                  "score": 9,
                  "created_utc": "2026-02-04 12:09:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3l8now",
          "author": "dev81808",
          "text": "I have maybe a different perspective.. I was a full stack dev (DE/AE) for 10+years and recently i was moved to AE specific role as part of a reorg. I still do many DE tasks, but not nearly as many as before. Because I can do both, when I need data from a new source, alot of the time ill write the process and send it to the DEs to deploy. \n\nI work with a DE only people and ive noticed a here a huge difference in design patterns. Their solutions tend to be one off purpose built imports. They almost never parameterize their solutions and any meta data used is typically a json file in the app and locked behind version control.\n\nWhen you are tasked with modeling an enterprise asset, you're forced to figure out ways of genericize your solution to support future initiatives. Alot of times this means data driven solutions for DE tasks... and I dont see many DE only peers that use data to drive their pipelines. \n\nThis is a great opportunity for you to *up-skill your DE game.",
          "score": 6,
          "created_utc": "2026-02-04 19:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fvu16",
          "author": "Danibrosi",
          "text": "What is analytics engineering?",
          "score": 8,
          "created_utc": "2026-02-04 00:14:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ges6i",
              "author": "Sex4Vespene",
              "text": "It‚Äôs basically a bridge position between data engineering and data analytics/science. You won‚Äôt be as responsible for the base pipeline work of getting data into the warehouse, but you are more technically proficient at things like optimization than the typical analyst.",
              "score": 16,
              "created_utc": "2026-02-04 02:00:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3km4n2",
                  "author": "Lastrevio",
                  "text": "How is this different from a BI developer?",
                  "score": 2,
                  "created_utc": "2026-02-04 18:15:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3g57ap",
              "author": "commiPANDA",
              "text": "Everybody is an engineer!",
              "score": 8,
              "created_utc": "2026-02-04 01:06:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3nopb7",
              "author": "Lopsided-Pen9097",
              "text": "I currently work as a BI Developer, receiving average compensation while often experiencing burnout from working 10+ hour days. Much of this stems from operating under leadership that lacks experience and demonstrates poor communication‚Äîleaders who believe they understand analytics and engineering but often do not.\n\nMy responsibilities span the entire data lifecycle: sourcing petabytes of data from diverse systems, automating workflows through both low-code and scripting solutions, transforming data across on-premise and cloud platforms, designing robust data models, and developing insightful visualizations, reports, and dashboards. Despite consistently delivering across these areas, feedback is frequently non-constructive, and efforts to communicate analytically rather than emotionally often go unappreciated.\n\nIn my experience, job titles and scopes vary significantly depending on the organization. Working in a well-structured environment with managers who possess strong technical and communication skills makes a tremendous difference. However, in less organized workplaces, titles hold little real value‚Äîleaders may insist that ‚Äútitles don‚Äôt matter‚Äù while maintaining elevated roles like Director or VP.\n\nUltimately, the impact and meaning of any role heavily depend on the culture and leadership of the organization.",
              "score": 2,
              "created_utc": "2026-02-05 03:48:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3j277g",
              "author": "Squirrel_Uprising_26",
              "text": "A dbt certified role",
              "score": 1,
              "created_utc": "2026-02-04 13:48:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3kj5ay",
              "author": "CaptainDawah",
              "text": "Basically a hybrid of DE and DA, depends on the company though obviously but I‚Äôm sure this job will become more common in next 5-10 years.",
              "score": 1,
              "created_utc": "2026-02-04 18:01:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3myooy",
          "author": "Brief-Employee-9246",
          "text": "I really enjoyed AE but just started DE so we will see how it goes",
          "score": 1,
          "created_utc": "2026-02-05 01:17:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o4w0e",
          "author": "UniversallyUniverse",
          "text": "It is innate on my last scenario/position.\n\nAll analyst resigned. Only me and my Manager was on survival mode in BI Dept.\n\nIt lasts about 3 years before the dept dissolved, and our team absorbed by Data Science Dept.\n\nThe experience being AE is superb. It's like I know how to get/transform data and read/analyze the data.\n\nThe experience of knowing what's the problem of the company, revenues, KPI Metrics or any business problem and having a solution and recos for it is one of the best exp I had.",
          "score": 1,
          "created_utc": "2026-02-05 05:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r1mnx",
          "author": "New-Addendum-6209",
          "text": "What are the DE roles doing in organisations with a DE/AE split? Just looking after ingestions?",
          "score": 1,
          "created_utc": "2026-02-05 17:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hex64",
          "author": "West_Good_5961",
          "text": "AE is mostly a click-n-drag engineer.",
          "score": -14,
          "created_utc": "2026-02-04 05:48:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quxzvb",
      "title": "Are Python UDFs in Spark still less efficient than UDFs written in Scala or Java?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1quxzvb/are_python_udfs_in_spark_still_less_efficient/",
      "author": "Lastrevio",
      "created_utc": "2026-02-03 17:20:05",
      "score": 31,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "I'm reading \"Spark: The Definitive\" guide and there's a part about how user defined functions in Python can be inefficient. This is the quote: \n\n\"When you use the function, there are essentially two different things that occur. If the function is written in Scala or Java, you can use it within the Java Virtual Machine (JVM). This means that there will be little performance penalty aside from the fact that you can‚Äôt take advantage of code generation capabilities that Spark has for builtin functions. There can be performance issues if you create or use a lot of objects; we cover that in the section on optimization in Chapter 19. \n\nIf the function is written in Python, something quite different happens. Spark starts a Python process on the worker, serializes all of the data to a format that Python can understand (remember, it was in the JVM earlier), executes the function row by row on that data in the Python process, and then finally returns the results of the row operations to the JVM and Spark.\n\nStarting this Python process is expensive, but the real cost is in serializing the data to Python. This is costly for two reasons: it is an expensive computation, but also, after the data enters Python, Spark cannot manage the memory of the worker. This means that you could potentially cause a worker to fail if it becomes resource constrained (because both the JVM and Python are competing for memory on the same machine). We recommend that you write your UDFs in Scala or Java‚Äîthe small amount of time it should take you to write the function in Scala will always yield significant speed ups, and on top of that, you can still use the function from Python!\" \n\nI heard from Reddit that this book was written a long time ago and some things may be outdated. Is this still relevant with the latest versions of Spark? Are Python UDFs still significantly slower than Scala/Java UDFs in Spark? If yes, have you ever encountered a situation at work where someone actually wrote a UDF in Scala or Java and avoided using Python for the sake of performance increases?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1quxzvb/are_python_udfs_in_spark_still_less_efficient/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3dh9e8",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-03 17:20:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3djxys",
          "author": "bacondota",
          "text": "The principle still applies. Spark will serialize the data and transfer to python process. If you run out of memory, you get no error, your task will hang indefinitely until you kill it. Had this problem on spark 3.5, but it should apply even to the newest version.\n\nYou can alter your session to have a bigger memory overhead. Look what each memory options on spark does. There is an option to increase the memory the JVM uses, and one that increases the memory outside the JVM (which the python process will consume)",
          "score": 32,
          "created_utc": "2026-02-03 17:32:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dy4hb",
          "author": "WinstonCaeser",
          "text": "You can write python arrow udfs which are much more efficient",
          "score": 24,
          "created_utc": "2026-02-03 18:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3h5vwi",
              "author": "iamnotapundit",
              "text": "I second this. I did a Scala UDF vs a Python UDTF. The Python actually won the speed test. But only UDTFs.",
              "score": 4,
              "created_utc": "2026-02-04 04:43:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3dktc2",
          "author": "Sufficient_Example30",
          "text": "In my experience this rarely is a problem you will encounter.\nBut if you do writing it in spark scala is a band aid to a problem that you are kicking down the road.",
          "score": 10,
          "created_utc": "2026-02-03 17:36:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gx2x6",
          "author": "robberviet",
          "text": "Always. Avoid UDF if you can. However, if you must, it's fine to a degree. Not many people actually need optimization.",
          "score": 6,
          "created_utc": "2026-02-04 03:46:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l8fq4",
          "author": "aes110",
          "text": "Yes, though less than they used to be.  \nNative functions (the built in spark sql) functions are the best because of their inner optimizations, vectorization, and being able to be optimized by the planner\n\nWhen it comes to python vs java\\scala udfs, python is still the slowest since well, python is just slower, but most of the overhead that used to be a thing like serialization is less of an issue now with the usage of Arrow udfs \n\nBasically try to keep to native functions, but python udfs arent that much of a taboo as older guides might suggest. And unless it's some special performance issue, i wouldn't introduce scala\\java udfs to a pyspark project",
          "score": 2,
          "created_utc": "2026-02-04 19:57:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mi5kl",
              "author": "Mclovine_aus",
              "text": "Are arrow udfs better because it solves serialisation problems or because it has more parallelisation through vectorisation?",
              "score": 1,
              "created_utc": "2026-02-04 23:45:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3mvhgb",
                  "author": "aes110",
                  "text": "Well there are two different definitions, regular python UDFs can now be optimized by arrow (useArrow=True), which solves the serialization issue.\n\nApart from that, you have two other types of UDFs that also help with \"parallelisation through vectorisation\". Either Pandas UDFs that get a pandas series and can use the built in pandas stuff, or \"Arrow UDFs\" that get an array and return an array, so they can use other vectorized stuff too\n\nusing these, most of the logic really is usually in C, so the perf diff from java/scala is much smaller\nhttps://spark.apache.org/docs/latest/api/python/user_guide/udfandudtf.html#Arrow-optimization",
                  "score": 1,
                  "created_utc": "2026-02-05 00:58:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3gv45f",
          "author": "Ok-Bee-5814",
          "text": "Shouldn‚Äôt have this problem",
          "score": 1,
          "created_utc": "2026-02-04 03:34:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kj2gl",
          "author": "22Maxx",
          "text": "Have you considered using Ray for expensive UDFs?",
          "score": 0,
          "created_utc": "2026-02-04 18:01:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}