{
  "metadata": {
    "last_updated": "2026-01-26 08:59:58",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 397,
    "file_size_bytes": 436832
  },
  "items": [
    {
      "id": "1qivk0x",
      "title": "This will work, yes??",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/ht0f89g2voeg1.png",
      "author": "Thinker_Assignment",
      "created_utc": "2026-01-21 11:34:40",
      "score": 222,
      "num_comments": 8,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qivk0x/this_will_work_yes/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0ucq1b",
          "author": "Ok-Improvement9172",
          "text": "Management wouldn't be wearing the hard hat and swinging the hammer. They'd be staring at their watch, tapping their foot, with a whip in their hand, grumbling to a consultant while a contingent worker on a 3 month contract is sweating bullets trying to make this happen.",
          "score": 39,
          "created_utc": "2026-01-21 12:20:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ughsi",
              "author": "Thinker_Assignment",
              "text": "nice one :) maybe it's a budget hammer that hits hard and leaves a dent",
              "score": 1,
              "created_utc": "2026-01-21 12:45:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uopdc",
          "author": "SupaWillis",
          "text": "It‚Äôs actually me with the hammer usually",
          "score": 31,
          "created_utc": "2026-01-21 13:35:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0upzy3",
              "author": "Thinker_Assignment",
              "text": "username checks out",
              "score": 7,
              "created_utc": "2026-01-21 13:42:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uj36e",
          "author": "lillogicdork",
          "text": "Ain't no way management touches code",
          "score": 10,
          "created_utc": "2026-01-21 13:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0uqeqr",
              "author": "Thinker_Assignment",
              "text": "i really wish that were true, but i once did a 6mo enterprise project where we re-wrote a manager's monolithic notebook to discover his genius 99% accuracy was infact, suprised pikachu, a bug. The people involved had salaries in the millions per year.",
              "score": 3,
              "created_utc": "2026-01-21 13:44:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0xmhx6",
                  "author": "Difficult-Vacation-5",
                  "text": "Which company is this thst pays people millions a year?",
                  "score": 2,
                  "created_utc": "2026-01-21 21:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0uua4p",
              "author": "Kaze_Senshi",
              "text": "They don't want to , because of that they love vibe coding.",
              "score": 2,
              "created_utc": "2026-01-21 14:05:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhcekr",
      "title": "Any data engineers here with ADHD? What do you struggle with the most?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qhcekr/any_data_engineers_here_with_adhd_what_do_you/",
      "author": "psgpyc",
      "created_utc": "2026-01-19 18:31:30",
      "score": 149,
      "num_comments": 85,
      "upvote_ratio": 0.94,
      "text": "I‚Äôm a data/analytics engineer with ADHD and I‚Äôm honestly trying to figure out if other people deal with the same stuff.\n\nMy biggest problems\n\n\\- I keep forgetting config details. YAML for Docker, dbt configs, random CI settings. I have done it before, but when I need it again my brain is blank.\n\n\\- I get overwhelmed by a small list of fixes. Even when it‚Äôs like 5 ‚Äúeasy‚Äù things, I freeze and can‚Äôt decide what to start with.\n\n\\- I ask for validation way too much. Like I‚Äôll finish something and still feel the urge to ask ‚Äúis this right?‚Äù even when nothing is on fire. Feels kinda toddler-ish. \n\n\\- If I stop using a tool for even a week, I forget it. Then I‚Äôm digging through old PRs and docs like I never learned it in the first place.\n\n\\- Switching context messes me up hard. One interruption and it takes forever to get my mental picture back.\n\nI‚Äôm not posting this to be dramatic, I just want to know if this is common and what people do about it.\n\nIf you‚Äôre a data engineer (or similar) with ADHD, what do you struggle with the most? \n\nAny coping systems that actually worked for you? Or do you also feel like you‚Äôre constantly re-learning the same tools?\n\nWould love to hear how other people handle it.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qhcekr/any_data_engineers_here_with_adhd_what_do_you/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0is2dt",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-19 18:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0it4nd",
          "author": "GachaJay",
          "text": "Meetings and constantly changing requirements",
          "score": 133,
          "created_utc": "2026-01-19 18:36:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ix2ke",
              "author": "SirGreybush",
              "text": "You need a data analyst that is part of your team, part of IT and not a business unit. \n\nSo that he/she go nuts not you.",
              "score": 31,
              "created_utc": "2026-01-19 18:53:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ixtlb",
                  "author": "GachaJay",
                  "text": "We need a lot of things. First and foremost we need to be relieved from the 126% tariff on our company as we only have a 9% profit margin prior to the tariff being enforced. The joys of ‚Äúwanting manufacturing to occur in America,‚Äù but taxing the manufacturing companies for raw materials it has to get overseas.",
                  "score": 16,
                  "created_utc": "2026-01-19 18:56:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0jpd9d",
                  "author": "thisfunnieguy",
                  "text": "ive worked with data analysts at 3 different companies; each one they were sorta mini-data scientists with better presentation skills.\n\nthey were doing dashboards and running analysis about new features and about user behavior on our site.\n\n  \nnever se them have anything to do with requirements.",
                  "score": 5,
                  "created_utc": "2026-01-19 21:04:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0iwbay",
          "author": "SoggyGrayDuck",
          "text": "Context switching and the absolute insane overuse of agile. Agile isn't supposed to mean \"throw everything at the engineer and then prioritize\" \n\nI'm at a company that wants to think and act like fin tech but because we don't have solid processes it creates so much tech debt. Bringing it up is like you dropped an f bomb in church",
          "score": 79,
          "created_utc": "2026-01-19 18:50:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j0y8j",
              "author": "ResidentTicket1273",
              "text": "Agile kills so many good teams, especially if it gets invaded by the business/product-manager who use it as a stick to beat engineers with. A good reply I've found is to make sure you raise high-value tickets/tasks to refactor/enable sustainable build/promote maintainability/maintain velocity - just to shoehorn actual real development work into what would otherwise be a wishlist with no idea as to the costs/consequences of balancing a bunch of unicorn-shit until it all falls over.",
              "score": 17,
              "created_utc": "2026-01-19 19:10:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0kgr0v",
                  "author": "StewieGriffin26",
                  "text": "I had an 8 point user story one time, like I created it, said it was 8 points, everyone agreed, but it was still tooth and nail to get that set as 8 because agile says you can break it down further.\n\nSure I can break it down to a 5 point and a 3 point user story but my god, sometimes it's just doing shit in jira for *metrics* which really just means paperwork.",
                  "score": 6,
                  "created_utc": "2026-01-19 23:21:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0lircp",
              "author": "Sea-Meringue4956",
              "text": "Are we in the same company? This is my life",
              "score": 1,
              "created_utc": "2026-01-20 02:47:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0nja0m",
                  "author": "SoggyGrayDuck",
                  "text": "Is there a consulting firm involved?",
                  "score": 0,
                  "created_utc": "2026-01-20 12:07:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0iuf6f",
          "author": "Distinct-deel",
          "text": "I struggle with long meetings \nI lose my focus half way through when they repeat same unnecessary things over and over that I miss important parts discussed then I have to figure them by my own",
          "score": 55,
          "created_utc": "2026-01-19 18:41:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kj1lv",
              "author": "Kukaac",
              "text": "Same. Just for context, \"long\" starts at around 17 seconds.",
              "score": 10,
              "created_utc": "2026-01-19 23:33:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0krr05",
                  "author": "Distinct-deel",
                  "text": "It depends on the topic for me.\nI can stay engaged for hours if I‚Äôm contributing, leading the discussion, or answering meaningful questions.\nBut it drops to about 10 seconds when directors are arguing about policies and internal management politics. I sometimes force myself to stay alert and listen just to understand the politics, but it‚Äôs very challenging and honestly frustrating. At times, it becomes difficult to even pretend that I‚Äôm still listening.",
                  "score": 6,
                  "created_utc": "2026-01-20 00:20:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0jnsvi",
              "author": "areyoua0neora0",
              "text": "I‚Äôm so happy that I‚Äôm not alone",
              "score": 3,
              "created_utc": "2026-01-19 20:56:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0mx3wz",
              "author": "VibraniumSpork",
              "text": "And video call training.\n\nBrother, you want me to focus on a 9-5 Teams presentation over 3 days? I ain‚Äôt learning shit.",
              "score": 3,
              "created_utc": "2026-01-20 08:52:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0kwaaf",
              "author": "katharsix",
              "text": "That's why I always ask for them to record meetings so I can just zone out and work while people are talking and then come back to the video and watch it in 2.5x or get an AI summary or smth to get to the important bits.",
              "score": 5,
              "created_utc": "2026-01-20 00:44:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vv11r",
                  "author": "psgpyc",
                  "text": "I do the same. If its a one-on-one, or few off us, I always ask beforehand If i can record it.",
                  "score": 1,
                  "created_utc": "2026-01-21 16:58:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0mqgw2",
              "author": "ooh-squirrel",
              "text": "Wait.. what kind sorcery is this? How do you make it all the way to half way? 20 minutes in I need an import statement before I am of any use. I can stay somewhat focused if I find the topic interesting enough but even then it's sometimes a struggle.",
              "score": 1,
              "created_utc": "2026-01-20 07:50:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0lppnc",
              "author": "PlantainStriking4423",
              "text": "Make it a habit to use an LLM recording/ summariser in every meeting, this is my plan too!",
              "score": 1,
              "created_utc": "2026-01-20 03:26:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vqko0",
                  "author": "psgpyc",
                  "text": "Yeah, I use the notion AI meeting tool. It helps.",
                  "score": 1,
                  "created_utc": "2026-01-21 16:39:01",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jn81w",
          "author": "kiquetzal",
          "text": "I think for us all it's context switching , which includes meeting transitioning. I have two tools I absolutely relish:\n1) Todo manager: I use Super Productivity. 100% local with ADHD and Focus/Flow management in mind\n2) Rituals: I plan my week and I plan my day. Every time as the first thing I'll do. When forced to switch context, I look into the day plan that I set up.",
          "score": 22,
          "created_utc": "2026-01-19 20:54:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0juf5n",
          "author": "ooh-squirrel",
          "text": "Yup. Lead engineer with primarily inattentive type adhd and a sprinkle of autism. Context switching and changing requirements are the worst. And meetings. Oh my god.. the meetings. \n\nI decided that I didn‚Äôt want to deal with it alone and I felt comfortable enough to disclose my adhd to my manger, my PM (that I have worked closely with for 5+ years) and a few more coworkers. Full acceptance and support all around. The PM was even like ‚Äúuhm.. yeah, I could have told you that‚Äù\n\nI still forget shit. And sometimes trail off. Or hyperfocus on the wrong task. Or deepdive into some weird deviation on the 8th decimal in an algorithm while listening to Finnish melodic death metal at a dangerously high volume. The difference is that now they know why.",
          "score": 17,
          "created_utc": "2026-01-19 21:28:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0l01jd",
              "author": "mikeballs",
              "text": "This genuinely gave me a second-hand rush of relief to read that you can be accepted and supported at work while being wired this way. Thanks for sharing",
              "score": 5,
              "created_utc": "2026-01-20 01:05:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mpgiq",
                  "author": "ooh-squirrel",
                  "text": "Happy to hear that. It's a story I like telling. \n\nI'm lucky to be in a company that support D&I by word and action. Fx. they are an active supporter of the hidden disabilities sunflower. It also helps to be in a country where D&I is literally part of the labor laws and ADHD is covered by disabilities laws. \n\nThat said, I would still encourage people to disclose if they feel safe to do so. You'd be surprised how many people are supportive or struggle with similar or other issues themselves. Diagnosed or otherwise.",
                  "score": 5,
                  "created_utc": "2026-01-20 07:41:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ke73z",
              "author": "PoochyPoochPooch",
              "text": "Username checks out",
              "score": 3,
              "created_utc": "2026-01-19 23:07:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jbhun",
          "author": "Treemosher",
          "text": "Yep, sole data engineer here and standing up a brand new CDW.  Diagnosed and medicated when i was a kid.  Re-diagnosed and medicated since about 5 years ago.\n\nBiggest help for me is cognitive therapy with psychologist who specializes in ADHD and stuff.\n\nThe validation thing, learning to trust myself, learning to stop self-shaming myself, etc has been a lifesaver.\n\nAnd to literally sit down and talk with someone about all the stupid junk that goes through my head.  Just being able to express frustrations with myself and occasionally with coworkers (data analysts).\n\nOn top of designing the ingestion and bringing in new data sources, I'm also the only account administrator for our CDW.\n\nLiterally nobody else on my team, even IT, understands the work I do.  They wouldn't even know I am doing it unless I straight up explain it to them.\n\nIt does force me to communicate and document like a mad dog.  Force my team to make decisions together with me so they stay involved and in the knowledge loop.\n\nBut going from access control, onboarding & training new users, coming up with a strategy for ongoing development, and also switching back to discussing whether to bring in <this other critical system's data>, peppering in these smaller data sources, it's a fucking lot.  I\n\nSometimes I think the ADHD helps lol  But my therapist is my fucking hero.\n\nBased on the text vomit I just dumped here, I would recommend you find a therapist you click with if you are struggling.  And ADHD people usually feel like they're struggling, don't we.",
          "score": 15,
          "created_utc": "2026-01-19 19:59:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ka6jb",
              "author": "TieAccomplished7039",
              "text": "That‚Äôs great!\nWhat kinda data you with? I‚Äôm looking for insights on data engineering.",
              "score": 1,
              "created_utc": "2026-01-19 22:46:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0j3vy0",
          "author": "hotlinesmith",
          "text": "the 7 seconds it may take spark to start evaluating a simple query",
          "score": 13,
          "created_utc": "2026-01-19 19:24:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m5z1q",
              "author": "solo_stooper",
              "text": "Switch to snowflake lol",
              "score": 1,
              "created_utc": "2026-01-20 05:05:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iwts6",
          "author": "SirGreybush",
          "text": "Reddit when someone says something that is wrong. \n\nOr that I am wrong. \n\nArgh! Distracted again FML",
          "score": 10,
          "created_utc": "2026-01-19 18:52:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j8azo",
              "author": "Treemosher",
              "text": "Defiance is one hell of a motivator",
              "score": 3,
              "created_utc": "2026-01-19 19:44:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ixoq9",
          "author": "Budget-Minimum6040",
          "text": "Meetings.\n\nEvery 2 weeks in person scrum retro + scrum planning for 4 hours with my team (2 people), web analysis team (4 people) + both team leads + head of department.\n\nMy tickets were like 5 minutes of the 4 hours and everything else so fucking boring and had nothing to do with my work at all so ... felt asleep 2 times while sitting next to the head of ...",
          "score": 7,
          "created_utc": "2026-01-19 18:56:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kobdc",
              "author": "MissingSnail",
              "text": "No meeting should ever last four hours. ADHD or not, that is torture.",
              "score": 6,
              "created_utc": "2026-01-20 00:02:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0n8ya1",
                  "author": "Budget-Minimum6040",
                  "text": "1:30 hours, 30min mandatory lunch break where we ordered pizza normally, 2:30 hours\n\nStill so sleepy.",
                  "score": 1,
                  "created_utc": "2026-01-20 10:42:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kkw8n",
          "author": "jubza",
          "text": "I struggle the most with paying attention in meetings, morning meetings in particular. And getting started. Once I'm into the swing of things, I can sit there for hours and plug away at it (if I enjoy it). \n\nSomething that helps me is that I have a file that has all my testing code in. YYYYMMDD_scratchpad.py/sql \n\nAll my little bits of code are in there on a weekly basis. If there was a funky function or something that I once did and want again, there it is. I recommend saving your configs somewhere :) \n\nAlso, few people mentioned AI here. Absolutely, I was very against it until recently, I thought it took away from me being a proper data engineer but honestly, AI is not something thats going to take your job away if you know how to leverage it in your favour. I ask my preferred AI provider some questions, sometimes it gets it wrong and I have to correct it or point it but even when it gives me something a bit wrong, it still gives me something to work with that I would have otherwise taken an hour or two to put together where to start.",
          "score": 5,
          "created_utc": "2026-01-19 23:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m6rn2",
              "author": "solo_stooper",
              "text": "I have this system too. In markdown in VS Code/ Cursor",
              "score": 1,
              "created_utc": "2026-01-20 05:10:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jhgog",
          "author": "wherzeat",
          "text": "Oh god... i am not alone",
          "score": 5,
          "created_utc": "2026-01-19 20:27:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j1mng",
          "author": "chock-a-block",
          "text": "You need a project manager that you trust to set your priorities.  Whoever you report to might be the way to get going.\n\nJust couch it like, ‚ÄúI want to make sure I have my priorities straight. I worry about that.‚Äù. Not ‚ÄúI need help because I have a thing you might get very judgmental about.‚Äù  And everyone knows priorities change.  It‚Äôs just knowing/acting on what they are right now.\n\nNever, ever discuss ADHD at work.  ADHD is one topic  that brings the crazy out.  Among medical professional, too!\n\nEDITS for clarity.",
          "score": 7,
          "created_utc": "2026-01-19 19:13:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mshr1",
              "author": "ooh-squirrel",
              "text": "Honestly discussing my ADHD at work has helped a lot. People were very understanding and supportive but it naturally depends a lot on the situation, the country you're in, and how safe you feel in your company and position. \n\nWe changed some things in the team including how we run meetings and ways-of-working. Incidentally the entire team are really happy about the changes.",
              "score": 1,
              "created_utc": "2026-01-20 08:08:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1npugq",
                  "author": "No_Investigator_5562",
                  "text": "This is the key thing I think. It‚Äôs really helpful to address with your manager when you know you have a good relationship with them and good standing in the company. I find that they accept that just fine when they appreciate your work.\n\nThen, when you inevitably miss some ‚Äúless important thing,‚Äù I feel like there‚Äôs understanding around that and it‚Äôs perceived less as carelessness and laziness. \n\nIt‚Äôs been helpful to think of my ADHD as not just a dysfunction but a series of strengths and weaknesses all bundled together.",
                  "score": 1,
                  "created_utc": "2026-01-25 17:59:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kcnls",
          "author": "cky_stew",
          "text": "Since I got medicated I turned into an absolute powerhouse, and my career skyrocketed to taking very well paid and competitive contracts. I gained the capability to focus on fulfilling tasks to absolute completion, it was life changing.",
          "score": 3,
          "created_utc": "2026-01-19 22:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lcbg1",
              "author": "superiorballsack",
              "text": "What medication did you take? Do you find the side effects to be worth it?",
              "score": 1,
              "created_utc": "2026-01-20 02:12:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0myt5b",
                  "author": "cky_stew",
                  "text": "I started with elvanse (vyvanse in US) - which worked OK but required strict regiment I struggled with. Then due to a shortage of it I had to switch to Amfexa which is like instant release dexamfetamine - this stuff works way better on me - I can dynamically adjust dose, it‚Äôs not the end of the world if I miss one etc - it kicks in faster and I know it‚Äôs not supposed to but I feel the effects last almost as long as the slow release stuff.\n\nThis was all on docs recommendation though, I never ‚Äúchose‚Äù what I wanted to be on.\n\nI have a higher heart rate, burn more calories, and if I take a dose too late then I might lose a bunch of sleep, which happens every now and again when my routine is all over the place.\n\nWell worth it for me, personally. Yes, it will probably shorten my lifespan - but I enjoy my work way more now (I sometimes work evenings, wtf), and I‚Äôm earning so much more to retire earlier with a nicer house etc; I genuinely prefer my life this way so I‚Äôm happy with the elevated risks.\n\nI don‚Äôt want to take this stuff forever, I feel I can eventually move away from being the code grunt and more of a manager and project director type role, which requires less pure concentration in order to overcome complex technical intricacies- because that‚Äôs where the meds really shine. But yeah I think I‚Äôd probably be OK without it in a fast moving role with constant requirement shifting.",
                  "score": 1,
                  "created_utc": "2026-01-20 09:08:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kk4fg",
          "author": "ForMyWork",
          "text": "For me, I love jumping between helping people in the team on different tasks or problem solving. I find I'm a very rapid problem solver. Whereas if I have one big thing that isn't particularly interesting I find it difficult to sit with just that. \n\nIf it's an interesting problem, or new piece of work for tackling, then that's different and I can often get a really good burst of work done. If it's a repetitive thing that isn't particularly fast, that's the work that causes me to just freeze up and I struggle with. \n\nI find that to get through those tasks where my brain just has no interest and freezes up, jumping onto other things that are more interesting and then coming back to it helps a lot, so doing it in chunks, whether that is my work or helping someone else. \n\nAlso a 10-minute walk to break up a day really helps me focus, and I do little longer lunch walk on my break and eat at my desk. Those two things help me focus a lot better throughout the day. Also when I started medication in October that really helped as well.\n\nOh one other one, I sometimes get a bit frustrated when people are so much slower at picking up the concept or the problem when they are the decision maker, or blocking something. If it is someone just working at their pace or understanding things as they do that's fine, but when it's a blocker or like I feel like I've explained myself three times, that can be frustrating. I don't often show that frustration but it puts a downer on the day.",
          "score": 3,
          "created_utc": "2026-01-19 23:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0knvil",
          "author": "MissingSnail",
          "text": "This is silly, but I keep losing notebooks and just grabbing a new one from the supply closet on the way to the next meeting. I have like five going now with various notes in them. I know I‚Äôve written it down somewhere, in one of the notebooks I on my work desk, or maybe one I left at home (I‚Äôm hybrid), or maybe one I left in a conference room‚Ä¶.",
          "score": 3,
          "created_utc": "2026-01-19 23:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pk6dl",
          "author": "ObjetoQuaseNulo",
          "text": ">Any coping systems that actually worked for you? Or do you also feel like you‚Äôre constantly re-learning the same tools?\n\nCheatsheets.  \n\n\nYes they work, find ones that are pertinent for the tools you use. For example, I know Python, Java, and Rust. Sometimes I might not use a language for a week or a few weeks, and end up forgetting the syntax structure of a language or some functions, I just check the cheatsheet, and check the standard library/api.\n\n  \nThere's a lot of cheatsheets out there for the tools you need, if there isn't, make ones that are useful for you.",
          "score": 3,
          "created_utc": "2026-01-20 18:22:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jzqfw",
          "author": "Deadible",
          "text": "I've found that my team generally has a good validation culture for asking quick clarifying questions of each other. This does slightly clash with not wanting context switching, but a bit of disruption there has been a good sacrifice to stopping things getting sluggish.\n\nI'm generally much better with lists of tiny tasks - it's the big ones where I just accumulate distractions. At some point I had to train myself to split it out into more tickets. ALWAYS overestimate how long something will take to do and you will still be underestimating it.\n\nMe and my small team are generally fine asking each other for validation - we take reviewing as an opportunity to knowledge share, so that's baked into how we spend our time/how productive we are.\n\nI hate meetings where I'm not needed, or I'm witnessing a project manager give an inaccurate representation of something. I hate when people give too much detail about things in standup when they're not looking for input. It's physically painful. \n\nI find unreasonable requirements difficult, because my instinct is always to begin to work around how we would do something, even if the system doesn't support it, and not ask whether we should do something. So I tend to hold my cards close to my chest and talk with my team/manager before I solutionise in the moment.\n\nI have been at the same place for around five years so I have built trust that I do good work, ask the right questions for peoples requirements, and am proactive about our data stack, so that gives me some leeway.",
          "score": 2,
          "created_utc": "2026-01-19 21:55:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lvjk1",
          "author": "Inevitable_Bunch_248",
          "text": "Taking notes helps me a ton, then I turn them into jota epics/stories/spikes for my team.\n\n\nMaking people write what they want after talking to them helps too.",
          "score": 2,
          "created_utc": "2026-01-20 03:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m6ju5",
          "author": "Digitaldarkness14",
          "text": "Technical writer turned Data Engineer here. Systems work for me. I have habit of using lists and trackers for my work. I always had to work with changing requirements so that was the only way",
          "score": 2,
          "created_utc": "2026-01-20 05:09:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mgq4z",
          "author": "Great-Tart-5750",
          "text": "I also struggle with the same things as you listed along with continuous meetings and changing PRD's. \n\nWhat I do to deal with this is, I have created extensive documentation for all login credentials, common bug fixes, dbt scripts, jenkins steps, etc. \nI also shared it with my seniors so that he can also provide inputs if anything had to be changed. \n\nIt has been more than a year since I created that doc and now it is used by everyone in our team.\n\nFor the changing requirements and meetings, I start my day with creating a note of things that need to be closed today. If there are anything left from the previous day, those are inserted according to priority. The list keeps me in check what I am currently working with even if someone interrupts and the mental map is lost. \n\nIt took me 2 years to learn all this, but in the end this works well for me.",
          "score": 2,
          "created_utc": "2026-01-20 06:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ojccb",
          "author": "soundboyselecta",
          "text": "Honestly with the amount of information being thrown at any human who uses any tech in the last few years of high speed access, even more so now with llm(s) and socials especially the short video epidemic, I find it hard to believe not everyone has ADHD. One of the most important things I find is limit distractions this includes \n1) shutoff all social related apps\n2) dont have 400 windows open (mainly browsers) constantly close anything unrelated to main task, you can get it back with grouping  browser tabs/ windows and history.\n3) if you have multiple screens like me, use it only when u need it otherwise limit it to one\n4) try to read a book before you sleep versus anything on a screen \n5) invest in a proper time management tool\n6) invest in an advanced to do list is important\n7) catch bad habits before then happen",
          "score": 2,
          "created_utc": "2026-01-20 15:31:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0to0io",
          "author": "arachnarus96",
          "text": "I have ADHD and my problems include impulsivity and forgetting why I did stuff. I may have found a good solution to a problem and months later when someone asks me about it I have no clue what they're talking about. I don't struggle with forgetting how to do stuff though but refreshing skills is always nice. And also naming stuff in data factory or in a database like views or tables can get messy.",
          "score": 2,
          "created_utc": "2026-01-21 08:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u1ak1",
          "author": "BorisKuntimov",
          "text": "Scope creep from stakeholders, remembering certain pyspark libraries that I've used countless times for integrations and or transformations, whimsical meetings that I'm not actually in required in because requirements haven't even been gathered.....\nThere's loads ,,ü§£",
          "score": 2,
          "created_utc": "2026-01-21 10:49:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jaogh",
          "author": "nonamenomonet",
          "text": "Yes. That‚Äôs me.  \n\n\nWhat helps me is my tickets have acceptance criteria that I can point back to to make sure I‚Äôm done. I also am a big believer in using AI when my brain is stuck. And though my current setup doesn‚Äôt work for this (cloud based with no local environment‚Ä¶ which is dumb) I was a big believer in TDD.",
          "score": 2,
          "created_utc": "2026-01-19 19:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k5qzy",
          "author": "heisoneofus",
          "text": "Oh shit I might have ADHD. Thanks OP.",
          "score": 2,
          "created_utc": "2026-01-19 22:24:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j7pai",
          "author": "Mysterious_Rub_224",
          "text": "AI is your friend here. Make a Claude style that will help you triage and breakdown projects or deployments. And then use whichever LLM in your IDE and give it your repo + docs as context on how your project is structured. Then you can turn around and get the LLM to \"make a game plan\" instead of you combing thru old PRs.\n\nLLM is also good at helping separate out all the disparate tasks/issues, so it takes on a good bit the cognitive load of \"wait which context am I in and do I need to switch over to another mode of thinking  for this other deliverable?\". Like just word vomit everything thats on your plate or in your head and get it to structure and breakdown what matters (critical path, bruh) and what does not.\n\nThink of it this way: Wouldn't it be nice to have additional roles supporting you as a DE? Like...\n\n- a PM to help prioritize all the chaos of requests\n- An intern to go do the \"look up how we did this last time\" work\n\nThen make appropriate personas for AI to fill those roles.",
          "score": 4,
          "created_utc": "2026-01-19 19:41:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vqyd8",
              "author": "psgpyc",
              "text": "I have been using AI. I am asking it to be my PM and list out requirements and acceptance criteria. Thank you.",
              "score": 1,
              "created_utc": "2026-01-21 16:40:42",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0jguxh",
              "author": "wherzeat",
              "text": "Thanks!",
              "score": 0,
              "created_utc": "2026-01-19 20:24:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0jazuc",
              "author": "nonamenomonet",
              "text": "This assumes they are allowed to use AI/Claude at work. At my last three jobs I wasn‚Äôt allowed to have Ubuntu on my machine.",
              "score": -2,
              "created_utc": "2026-01-19 19:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jcypu",
                  "author": "ActEfficient5022",
                  "text": "Using Claude for assistance with task management is way less difficult than getting Linux on your work machine. I'm not sure what the connection is.",
                  "score": 1,
                  "created_utc": "2026-01-19 20:05:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jp2t1",
          "author": "thisfunnieguy",
          "text": "there's plenty of neurodivergent in the SWE/DE space.\n\nand importantly there HAVE been neurodivergents in the eng space for many many many years.\n\nSo you CAN be successful, you just have to figure out a mix of meds and processes to keep you on the track.\n\nchecklists are great.\n\nI really like a \"deploy checklist\" md file added with any PR: \"this is a quick list of what needs to happen to make this change go live\".\n\nThat might be a \"merge to main\" and profit or stuff like \"merge to main, delete the OLD s3 bucket manually, run the TF apply... run the DB migration, wait for this jenkins pipeline to finish....\"\n\n  \n\\--\n\n  \nEDIT:\n\nanother reason i like this is it gives me something i can point someone else to. \"hey is this the right steps to deploy this\"",
          "score": 2,
          "created_utc": "2026-01-19 21:02:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k2qbo",
          "author": "Adorable-Emotion4320",
          "text": "Wait, so you guys are saying the DE's that 1) are not insanely overcompensating their insecurity by being a d##k¬†\n2) those that not like meetings, agile, ridiculous requirements, getting new tasks every day and basically everything else that is wrong in every other data project\n\n\nBut the ones that are just struggling and have imposter syndrome like the rest of us are all neurodivergent?\n\n\nPlease show me the list of symptoms that fill this criteria (genuinely would like to know)",
          "score": 1,
          "created_utc": "2026-01-19 22:09:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0l5x9p",
          "author": "zazzersmel",
          "text": "Had a manager who would send back all my work with lists of minor formatting issues, refusing to answer any big picture questions I had about the project until everything met his exact standards, often over and over again. Then he‚Äôd criticize for taking too long.",
          "score": 1,
          "created_utc": "2026-01-20 01:37:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ldf94",
          "author": "Tupiekit",
          "text": "I will say‚Ä¶.as a data analyst who has ADHD and wants to pivot into data engineer but who is scared/self selecting myself out of the field because of my fear of my ADHD making it hard‚Ä¶,this thread is kinda helping.",
          "score": 1,
          "created_utc": "2026-01-20 02:18:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lif69",
          "author": "skatastic57",
          "text": "Everything you said plus Adderall hasn't been available for 3 months. \n\nOn the validation thing, I'll often get a somewhat vague ask so I'll do a minimum viable thing, give them that and ask where they want to go, and they'll say this is great, no notes. It seems like that would be good but getting no notes sucks. It just makes me think they didn't want anything to begin with and they were just asking me to check the box that they asked me. \n\nIf I have a bunch of low priority things I also often end up doing none of them and instead invent a project that's tangentially related or is a pet project.",
          "score": 1,
          "created_utc": "2026-01-20 02:45:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lrjqe",
          "author": "hairymelon90",
          "text": "You summed it up well. I've got perfectionism too which is so difficult because it irks me to have incorrect data and not do anything about it RIGHT NOW. But if I try to fix it, I hyper-fixate and go down rabbit holes trying to find the root of an issue... 20-30 dbt models deep and I've found 17 more issues and can't figure out which to tackle first. It's overwhelming and I feel so defeated.\n\nHowever, I feel like I'm a good counter to others on my team though because they're so quick to just push out \"good enough\" (ughhh I wish my brain could be okay with that) and I catch things they miss with my annoyingly fine-tooth comb.",
          "score": 1,
          "created_utc": "2026-01-20 03:37:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mk5l9",
          "author": "One_Citron_4350",
          "text": "It depends on how your team or working environment is like? Do you have a team leader or a manager or are you alone in this situation? How many stakeholders are you working with?\n\nChanges, especially on short notice are unfortunately common.",
          "score": 1,
          "created_utc": "2026-01-20 06:55:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ndkzx",
          "author": "angry_oil_spill",
          "text": "Yyyyep. Down to a T. Described my experience perfectly as a data analyst and learning data engineer.",
          "score": 1,
          "created_utc": "2026-01-20 11:22:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nfe0u",
          "author": "GehDichWaschen",
          "text": "I dont have adhd and struggle with the same things. Mostly I have accepted that things take time, in particular what you mentioned: \n\nProper docs, \nAnnoying context switching, \nTedious result validation with users\n\nI cannot use a magic wand to do all this, it just takes time.\n\nbut when you have clear procedures to do each step properly and stick to it, at least you yourself keep the sanity",
          "score": 1,
          "created_utc": "2026-01-20 11:37:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nh8fk",
          "author": "Murky-Sun9552",
          "text": "I use notepad ++ to copy and paste config templates with heavily commented lines, and jupyter notebooks to scratch in, all saved on my desktop, has helped me no end",
          "score": 1,
          "created_utc": "2026-01-20 11:51:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o3cf4",
          "author": "Longjumping_Lab4627",
          "text": "Are these related any to ADHD? Don‚Äôt everyone just struggle with these challenges? \nI can extend the list with challenges where I can‚Äôt force myself to pay attention to‚Ä¶ but tbh I think that‚Äôs a common struggle among normal people as well",
          "score": 1,
          "created_utc": "2026-01-20 14:10:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vurr7",
          "author": "psgpyc",
          "text": "Thank you everyone for the replies. It genuinely makes me feel safer knowing so many of us go through similar things.\n\nI realised I have ADHD a bit late, and I‚Äôm still learning how to cope with it. I‚Äôm more on the hyperactive side, and for years I‚Äôve lived in a cycle of hyperfocus and burnout. Nothing felt ‚Äúenough‚Äù or ‚Äúperfect‚Äù, so I kept polishing, then I‚Äôd burn out and abandon it. In the end, I had lots of half-finished work and very little truly completed.\n\nLately I‚Äôm learning to prioritise, and like many of you said, a consistent routine has helped the most. To manage the hyperactive side, the vocal stimming, and my mind wandering, I started going live on Facebook (I just have my famliy members on facebook). Weirdly, that‚Äôs helped me stay present and keep the hyperactivity in check.\n\nI also used to take loads of notes, but they were scattered everywhere (notebooks, random apps, GitHub). Now I‚Äôve moved everything into Notion with a proper structure, and it‚Äôs made a huge difference\n\nOne thing I still struggle with is the need for validation. I‚Äôm starting to accept that this might be something I need to work through properly, and I think therapy is the direction that will actually help long-term.\n\nReally appreciate all of you taking the time to share advice and experiences.",
          "score": 1,
          "created_utc": "2026-01-21 16:57:49",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o109z4q",
          "author": "Glittering_Light_334",
          "text": "Yes, I do. I have been clinically diagnosed with ADHD but not on any medication currently. The biggest struggles have been with: \n\n1. Paying attention especially on long drawn business meetings.\n\n2. Sticking to learning something and being consistent once the novelty wears off. \n\n3. Being able to estimate and track time in general. \n\n4. Hyper focusing on perfecting trivial aspects of routine tasks like documentation.",
          "score": 1,
          "created_utc": "2026-01-22 07:14:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10rzpa",
          "author": "ineedasolution",
          "text": "You just helped me self diagnosis myself with ADHD.",
          "score": 1,
          "created_utc": "2026-01-22 10:01:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14bqqy",
          "author": "junacik99",
          "text": "Hello, for some time now I work in Data Engineering and Data Science. I was not diagnosed with adhd, but I have always felt that I cannot focus on one thing for a long time. I have trouble even doing online courses for more than 5 minutes. Especially boring HR stuff, but also technical courses.\n\nI recently discovered Planner on MS teams. Which is like really simplified version of Jira. I add there really small implementation steps I want to take . Usually one day before. Those tasks are usually small and simple so I don't feel overwhelmed. And if I do I take a breath and just choose one that can be done right away. This start is the most important.\n\nTo focus on a task, when my hands are not occupied by the keyboard, I use small objects to hold in my hand like d20 dice or even a pen. \n\nAlso very good thing is a rubber duck debugging. You can have a small rubber duck to which you explain your task or your code and it just listens and won't interrupt you. This helps you focus more on your task and immerse in it.",
          "score": 1,
          "created_utc": "2026-01-22 21:14:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kisie",
          "author": "SaintTimothy",
          "text": "What do I struggle most with?\n\n\nhumans\n\n\nOr, more specifically, psychology... maybe IOPsych.\n\n\nIf a person is an idiot, I can't just call them an idiot, replace them with someone competent, and move on with my life (as one might a failed laptop). I have to instead provide them enough opportunities to either grow, or prove to their boss that they are, indeed, an idiot. Bonus points of their boss is also an idiot.\n\n\nRunner up, for things I struggle with. Weltschmerz.",
          "score": 1,
          "created_utc": "2026-01-19 23:32:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kj8p9",
              "author": "SaintTimothy",
              "text": "I've heard weltschmerz described as the pain felt when someone doesn't do what you expected of them.",
              "score": 1,
              "created_utc": "2026-01-19 23:34:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0l32ab",
          "author": "decrementsf",
          "text": "ADHD does not exist. On average it is lifestyle factors posing as a label. Stay up late with poor sleep binge watching shows, eat terrible, no exercise for aerobic development, no restful practices to build parasympathetic support and counter stress, focus is going to go to hell. We teach therapy terms without teaching language and habits for health.",
          "score": -2,
          "created_utc": "2026-01-20 01:22:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lqpvo",
              "author": "PlantainStriking4423",
              "text": "not sure this is true but even if it were you still needs way to cope with the 'symptoms' of bad health while you find better health",
              "score": 1,
              "created_utc": "2026-01-20 03:32:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0o4cf3",
                  "author": "decrementsf",
                  "text": "There used to be the boring advice of grandma. She would chastise you for staying up all night. Cut to the point that well of course you feel terrible, you're not doing any of the things all people who feel good have to do.\n\nI have in mind the parents of the boomers generation. They're not around anymore and this role is being forgotten.\n\nChanneling that energy to play it forward. With mind toward college and high school aged as audience. A large portion of them are naturally unaware, yet, what habits support feeling good. More than is accurate take on an identity of a neurotic. I think they'd be happier with the cut to the point advice from grandma. Playing it forward, I loved that grandma. She was full of boring advice from grandma you roll your eyes at. Then fifteen years later after trying every nootropic and other option finally tried going to bed earlier and your life falls together and recognize damnit, the boring advice was from grandma was wisdom.",
                  "score": 1,
                  "created_utc": "2026-01-20 14:16:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qi7quj",
      "title": "Spending >70% of my time not coding/building - is this the norm at big corps?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qi7quj/spending_70_of_my_time_not_codingbuilding_is_this/",
      "author": "HiddenStanLeeCameo",
      "created_utc": "2026-01-20 17:40:10",
      "score": 136,
      "num_comments": 35,
      "upvote_ratio": 0.97,
      "text": "I'm currently a \"Senior\" data engineer at a large insurance company (Fortune 100, US).\n\nPrior to this role, I worked for a healthcare start up and a medium size retailer, and before that, another huge US company, but in manufacturing (relatively fast paced). Various data engineer, analytics engineer, senior analyst, BI, etc roles.\n\nThis is my first time working on a team of just data engineers, in a department which is just data engineering teams.\n\nIn all my other roles, even ones which had a ton of meetings or stakeholder management or project management responsibilities, I still feel like the majority of what I did was technical work. \n\nIn my current role, we follow Devops and Agile practices to a T, and it's translating to a **single pipeline being about 5-10 hours of data analysis and coding and about 30 hours of submitting tickets to IT requesting 1000 little changes to configurations, permissions, etc and managing Jenkins and GitHub** deployments from unit>integration>acceptance>QA>production>reporting\n\nIs this the norm at big companies? if you're at a large corp, I'm curious what ratio you have between technical and administrative work.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qi7quj/spending_70_of_my_time_not_codingbuilding_is_this/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0pefea",
          "author": "Reverie_of_an_INTP",
          "text": "Yeah that was my exact experience in a similar job.",
          "score": 98,
          "created_utc": "2026-01-20 17:56:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sgnho",
              "author": "Fun-Estimate4561",
              "text": "We moved over to databricks last year and no one else wanted it so my team took hold \n\nNot having any red tape and autonomy to build has been amazing \n\n(Being the manger of the group still force everyone to follow best practices but not having to deal with other groups red tape is awesome)",
              "score": 14,
              "created_utc": "2026-01-21 03:11:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pmouj",
          "author": "toadling",
          "text": "Is that normal? I am not sure. All I know from experience is that the bigger the org the more red tape and the more pointless meetings you get stuck with",
          "score": 62,
          "created_utc": "2026-01-20 18:33:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tftf5",
              "author": "ask-the-six",
              "text": "If you lack skills and talent in a large org you can make a career out of scheduling meetings/creating meaningless policies to roadblock skilled and talented people.",
              "score": 22,
              "created_utc": "2026-01-21 07:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yvmb1",
                  "author": "NDHoosier",
                  "text": "Stop giving me flashbacks, dammit.",
                  "score": 1,
                  "created_utc": "2026-01-22 01:39:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1e0aqb",
                  "author": "Afedzi",
                  "text": "üòÇüòÇüòÇüòÇ",
                  "score": 1,
                  "created_utc": "2026-01-24 07:20:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pk5pr",
          "author": "zipzapzippydyzoom",
          "text": "I've found that no matter what you're doing, working in big corporations means less responsibility and more redtape. That's why I prefer consultancy rather than working inhouse. Because you have a higher probability of working on big projects and are less likely to do day to day stuff. (logging every hour of your day is a bitch, though)",
          "score": 44,
          "created_utc": "2026-01-20 18:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sdfmm",
              "author": "NDHoosier",
              "text": "\\> *I've found that no matter what you're doing, working in big corporations means less responsibility and more redtape.*¬†\n\nTry working in government....",
              "score": 5,
              "created_utc": "2026-01-21 02:52:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yq3s6",
                  "author": "Empty_Experience_950",
                  "text": "That's not red tape that's red carpet bureaucracy, where literally \"nothing\" gets done",
                  "score": 5,
                  "created_utc": "2026-01-22 01:08:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qsn68",
          "author": "BestNarcissist",
          "text": "you are an engineer, not a coder.\n\nLawyers don't spend much time in court.\n\nSurgeons don't spend much time in the OR.\n\nArchitects dont spend much time drawing.\n\nThis is completely normal.",
          "score": 99,
          "created_utc": "2026-01-20 21:45:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0shgir",
              "author": "Maple_Mathlete",
              "text": "damn this was a great way of putting it",
              "score": 16,
              "created_utc": "2026-01-21 03:16:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o169w4c",
              "author": "jduran9987",
              "text": "Damn dude‚Ä¶ look at the perspective on you.",
              "score": 1,
              "created_utc": "2026-01-23 03:28:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0xa3j8",
              "author": "SELECT_ALL_FROM",
              "text": "I like this idea, but also glad you didn't capitalise Engineer. Some of those other professions, and Engineers, are highly governed and accredited titles. That said, much like software engineering, data engineering feels right",
              "score": 0,
              "created_utc": "2026-01-21 20:46:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o115ose",
                  "author": "Quick_Assignment8861",
                  "text": "Does it matter? They could call me a pipeline artist idgaf. Sounds like a culture thing",
                  "score": 1,
                  "created_utc": "2026-01-22 11:56:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pd092",
          "author": "joins_and_coffee",
          "text": "Yeah, this is pretty normal at large, regulated companies. Once you hit a certain scale, a lot of the ‚Äúwork‚Äù becomes coordination, approvals, and moving changes safely through environments rather than writing code. The irony is that the more senior and mature the org, the less time you actually spend coding. devops + strict governance + multiple environments usually means pipelines are easy to build but slow to *land*. Insurance is especially heavy on this. Some teams do manage to streamline it with better self-service, platform teams, or looser controls in non-prod, but 60 to 70% overhead isn‚Äôt unusual. Whether that‚Äôs acceptable or soul draining is kind of the real question",
          "score": 21,
          "created_utc": "2026-01-20 17:49:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pt8dx",
          "author": "Astherol",
          "text": "Most senior DE in major manufacturing company in Europe here. It's normal, the further I go into high impact projects the more calls and business engineering I do. Currently I do mailing, meetings and monitoring the control dashboards and it's already 4 hours in work and I'm about to finally open Databricks to throw in some code. Don't fear of going Data Engineer -> Solution engineer, there is good $$ there",
          "score": 9,
          "created_utc": "2026-01-20 19:02:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pe9l7",
          "author": "mcgrst",
          "text": "Depends on the project. Last one got so crunchy my boss was doing all the meetings and admin while I done all the work. Other projects it's been near 50/50.¬†\n\n\nPart of me prefers the pressure of a very hard deadline and someone else dealing with the rest of the chaos.¬†",
          "score": 7,
          "created_utc": "2026-01-20 17:55:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0quyqq",
          "author": "Kenny_Lush",
          "text": "Ah, ‚Äúagile.‚Äù Somewhere there are happy people that never heard of that miasma of dystopian micromanagement. I really need to be more grateful for what I have.",
          "score": 6,
          "created_utc": "2026-01-20 21:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pyfgo",
          "author": "Im_probably_naked",
          "text": "Sounds like you're in a large company. My company was bought a year ago by a large company and I'm experiencing this too. I'm actively looking.",
          "score": 5,
          "created_utc": "2026-01-20 19:26:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rfw11",
          "author": "StewieGriffin26",
          "text": "That's normal.",
          "score": 5,
          "created_utc": "2026-01-20 23:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rfxp8",
          "author": "jfrazierjr",
          "text": "Unfortunately yes.   The bigger the company, the bigger the work getting done tax",
          "score": 4,
          "created_utc": "2026-01-20 23:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q6why",
          "author": "peterxsyd",
          "text": "Literally just get out of there. Those companies will be dead. Setup an auto Claude bot to do your tickets for you, ask to work from home lots and build your own apps and startup whilst studying to learn lots of stuff that will help scale your impact meaningfully.",
          "score": 7,
          "created_utc": "2026-01-20 20:05:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rdrji",
          "author": "secretazianman8",
          "text": "I am at a large corporation in a similar role and situation. I saw the same problem with these types of friction here and elsewhere. And we both know this friction could be reduced by moving a lot of these responsibilities into the cicd pipelines.  \n\nThis type of friction is something unfortunately only certain people can change because it's organizational and requires different c suite and vp's to understand which can be a difficult task. If those people aren't open to it, then switch jobs. Optimizing for machines is easy. Optimizing our companies decisions unfortunately is complicated. \n\nAs my role has increased, my time is being spent more on \"selling\" our devops practices to the right leadership and how these best practices reduce the friction from organizational processes.  There're two paths to adoption in my opinion.\n\nThe first is convincing the leadership in charge of both organizations to see the friction. So a lot of my time is spent on making architectural diagrams, reading the latest research publications to use in presentations and design, generating pretty graphs, etc. I want to showcase where we are spending our time and the value coming out of the different usages of time.\n\nThe second is to convince the leadership and engineers from the team causing friction that there's a better way. For this, I spend time helping my team excel in ways that we always get recognition in organizational announcements. We want to convince leadership and engineers in other organizations to see how efficient we are and come to us to adopt our practices.  \n\nEncouraging education seems to be difficult in this industry. The people in the highest roles often get there over time and often get stuck in their ways. It's not always the case but it happens enough and the research agrees. The DORA research publications have shown that a disconnect between developers and researchers is all too common",
          "score": 3,
          "created_utc": "2026-01-20 23:33:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pd9z8",
          "author": "PrestigiousAnt3766",
          "text": "No, it sounds like a hellhole..\n\nId get out fast.",
          "score": 10,
          "created_utc": "2026-01-20 17:50:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q2oy8",
          "author": "Firm-Yogurtcloset528",
          "text": "Recognizable. Advice, get out if you can before you become brain death,",
          "score": 5,
          "created_utc": "2026-01-20 19:46:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tb6wc",
          "author": "i_hate_budget_tyres",
          "text": "Seniors in my firm are also mainly managers.  My firm followed the big tech trend of laying off the proper manager roles PM, BA, Scrum master etc and flattening out the structure.  This meant the seniors had to start filling in.",
          "score": 2,
          "created_utc": "2026-01-21 06:47:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xtp7s",
          "author": "DoubleAway6573",
          "text": "I'm in a small start up reverted to seed phase. we are less than 25 heads in total and my last two days I had no less than 9 meetings. this is hell",
          "score": 2,
          "created_utc": "2026-01-21 22:17:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qxz6o",
          "author": "GachaJay",
          "text": "The higher your designation the more meetings and less IC work. As a manager, graduated from Lead,85% of my day is meetings.",
          "score": 2,
          "created_utc": "2026-01-20 22:10:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sgre7",
          "author": "Sizzlingbrowny",
          "text": "That‚Äôs completely normal",
          "score": 1,
          "created_utc": "2026-01-21 03:12:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tf1gd",
          "author": "One_Citron_4350",
          "text": "My understanding is that the more you go up the rank, you tend to focus less on the coding/building. The nature of your work changes, it remains technical but you become more of an enabler, focus on designing, meetings, connecting, doing glue work, following through the entire data engineering lifecycle and beyond.",
          "score": 1,
          "created_utc": "2026-01-21 07:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0thlnj",
          "author": "m1nkeh",
          "text": "Yep, pretty much mate",
          "score": 1,
          "created_utc": "2026-01-21 07:44:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tm1s7",
          "author": "GrandOldFarty",
          "text": "This is exactly how it is.",
          "score": 1,
          "created_utc": "2026-01-21 08:25:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tsm3y",
          "author": "gaussmage",
          "text": "Depends on the company. I had a previous job where everything had to be signed off by multiple people to approve a deployment or change. Current job more leeway and direct cloud access to do stuff vs having to rely on another team",
          "score": 1,
          "created_utc": "2026-01-21 09:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xm5i9",
          "author": "ID_Pillage",
          "text": "Wait until your company trials implementing AI DLC",
          "score": 1,
          "created_utc": "2026-01-21 21:41:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjbawr",
      "title": "Fivetran pricing spike",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qjbawr/fivetran_pricing_spike/",
      "author": "onksssss",
      "created_utc": "2026-01-21 21:44:44",
      "score": 101,
      "num_comments": 54,
      "upvote_ratio": 0.98,
      "text": "Hi DEs,\n\nAnd the people using Fivetran..\n\nWe are experiencing a huge spike (more than double) in monthly costs following the March 2025 changes, and now with the January 2026 pricing updates.\n\nPreviously, Fivetran calculated the cost per million Monthly Active Rows (MAR) at the account level. Now, it has shifted to the connector (or connection) level. This means costs increase significantly ‚Äî often exponentially ‚Äî for any connector handling no more than one million MAR per month. If a customer has multiple connectors below that threshold, the overall pricing shoots up dramatically.\n\nWhat is Fivetran trying to achieve with this change?\nFivetran's official explanation (from their 2025 Pricing FAQ and documentation) is that moving tiered discounts (lower per-MAR rates for higher volumes) from account-wide to per-connector aligns pricing more closely with their actual infrastructure and operational costs. Low-volume connectors still require setup, ongoing maintenance, monitoring, support, and compute resources ‚Äî the old model let them \"benefit\" from bulk discounts driven by larger connectors, effectively subsidizing them.\n\nWill Fivetran survive this one? My customer is already thinking about alternatives.. what is your opinion?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qjbawr/fivetran_pricing_spike/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0xmt52",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 21:44:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xpx9x",
          "author": "trash_snackin_panda",
          "text": "Many businesses who are stuck on Fivetran don't have another option, whether it's because there is a technical skill gap, staffing, etc. There are alternatives, but high switching costs. \n\nFivetran is trying to make more money, to properly expand their product offering, and make good on their merger with dbtLabs, sqlmesh, etc. They need staffing hours dedicated to people making good on the synergies between their products. Essentially flying the plane while building it. \n\nSo yeah. They now own probably 50% of the teams that manage the software products many DE's rely on. Probably more. Are we surprised prices went up? No. Will they keep going up? Almost definitely.",
          "score": 43,
          "created_utc": "2026-01-21 21:59:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10j2ex",
              "author": "Odd-String29",
              "text": "‚Ç¨10K is our yearly Fivetran bill. We are keeping our eyes open for other solutions, but if we need to hire someobdy to built a replacement the ROI is going to be several years. Looking at the current spend for this month I don't see a very large increase in our situation.",
              "score": 3,
              "created_utc": "2026-01-22 08:36:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o123ytb",
                  "author": "asevans48",
                  "text": "Airflow to the rescue i guess.",
                  "score": 3,
                  "created_utc": "2026-01-22 15:11:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0z2k8s",
          "author": "pungaaisme",
          "text": "Isn't this expected? I am not sure why FT customers are surprised by the increase in their FT invoices. Any VC-backed company needs to show 50% YoY growth, or it faces a down round. FT raises prices for its customers at every renewal to keep its VC satisfied. There are plenty of alternatives available that are much cheaper. It's time to stop paying per-row for data.",
          "score": 23,
          "created_utc": "2026-01-22 02:19:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10s8la",
              "author": "uncertainschrodinger",
              "text": "It also seems like a never ending spiral - they increase prices, lose customers, need to increase prices to make up for lost customers, rinse and repeat.\n\nFrom what I've seen around me, people are more and more opting for tools that are not so vendor-locked just so they can jump ship when this type of shit happens.",
              "score": 6,
              "created_utc": "2026-01-22 10:03:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o11c2c1",
                  "author": "anti_humor",
                  "text": "I'm still in my first data engineering job. I remember being a bit disappointed when I was hired that we aren't using many if any of the tools that are popular in this sub and on DE blogs and everywhere else. \n\nI've been here a couple of years now, and although there's definitely some extra work involved with doing almost everything in house, it totally makes sense to me now. Every company is going to have some amount of exposure to vendor lock in, but it seems clear that limiting this exposure as much as is practical has been a good move.",
                  "score": 6,
                  "created_utc": "2026-01-22 12:41:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0zfdi9",
          "author": "blueadept_11",
          "text": "We pay around $10k a month for fivetran and are paying somebody to migrate to an in-house built solution. I think the ROI is positive in like 3 months. In 2021-2023, I paid $10k/yr to stitch for unlimited rows. Fivetran is out of its damn mind.",
          "score": 13,
          "created_utc": "2026-01-22 03:32:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10be3v",
              "author": "ZirePhiinix",
              "text": "Nah, they know not everyone can switch and they need to get the returns going.",
              "score": 4,
              "created_utc": "2026-01-22 07:26:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17gtwz",
              "author": "TiredDataDad",
              "text": "Not sure what are the data sources you are ingesting with Fivetran, but I think you are probably not very far off with your ROI calculation.\n\nWe did it for a few clients and they were quite happy, not just for the cost savings, but also because they got full visibility on their loading pipelines",
              "score": 1,
              "created_utc": "2026-01-23 08:51:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0xqiys",
          "author": "GreyHairedDWGuy",
          "text": "I know nothing about you or your customers situation but for us, there was a small increase but not significant.  Most of our connectors attract more than 1M MAR per month with some around 10million so perhaps that's why we didn't see a large increase.  Our small MAR connectors are generally less than 500,000 paid MAR each with a few < 100,000MAR (we're talking $40USD for the month).\n\nWhat plan are you using?",
          "score": 9,
          "created_utc": "2026-01-21 22:01:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zx01i",
              "author": "onksssss",
              "text": "Enterprise and many connectors less than 1M MAR",
              "score": 2,
              "created_utc": "2026-01-22 05:29:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o13xutl",
                  "author": "GreyHairedDWGuy",
                  "text": "what were you paying before versus now?   if you don't mind me asking",
                  "score": 1,
                  "created_utc": "2026-01-22 20:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10l3zw",
          "author": "Domehardostfu",
          "text": "When I was head of data of my previous company, Fivetran was a one man replacement.\n\n1 month of salary = 1 year of data sync.\n\nThe prices kept increasing till 1/2 month of salary = 1 month of data sync.\n\nAt this time we had to replace. And I was an early adopter of Fivetran.\n\nI'm now working as a contractor, with 10Yrs of experience, let me know if you need help migrating from Fivetran.",
          "score": 8,
          "created_utc": "2026-01-22 08:55:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14qj6q",
              "author": "quickdraw6906",
              "text": "What do you prefer to migrate to?",
              "score": 1,
              "created_utc": "2026-01-22 22:26:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o181gkv",
                  "author": "TiredDataDad",
                  "text": "My suggestion would be dlt. It's open source, but dlthub, the company behind it, is building something on top of it, not just a dlt SasS, so I am pretty confident it will stay open.\n\nDisclaimer: we implement dlt for our clients, migrating away from Fivetran and Airbyte",
                  "score": 1,
                  "created_utc": "2026-01-23 11:52:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18tj3l",
                  "author": "Domehardostfu",
                  "text": "It really depends on the data sources, company and data department maturity. \n\nIf there's already a company scheduler I'll try to reuse it. \nElse Either prefect or Airflow are simple enough and work great, I'll implement my typical extraction framework which already includes SLA checks for jobs out-of-the-box.",
                  "score": 1,
                  "created_utc": "2026-01-23 14:37:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0xxqgk",
          "author": "redwards1230",
          "text": "sweet summer child",
          "score": 16,
          "created_utc": "2026-01-21 22:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y3xl1",
          "author": "Apprehensive-Ad-80",
          "text": "Price model changes rarely benefit the customer, so what are they doing? Making more money. It‚Äôs that simple. \n\nWe jumped from them last year to portable because of the price and (lack) of service",
          "score": 10,
          "created_utc": "2026-01-21 23:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0z963k",
          "author": "wantonmee-nowanton",
          "text": "Same here. After the pricing updates, despite 41% reduction in MARs, our costs spiked 193%. It‚Äôs insane cause we initially got into this to save time and money",
          "score": 5,
          "created_utc": "2026-01-22 02:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ycfno",
          "author": "Jameswinegar",
          "text": "Without actual numbers or sources to provide a real opinion on, if you're spending thousands of dollars a month it might be worth looking into Estuary for your workloads, it does pricing by GB and task runtime vs MAR. \n\nWe've seen price reductions of 80% for some SaaS sources like Shopify and 90%+ for databases with high transaction volume.",
          "score": 6,
          "created_utc": "2026-01-21 23:54:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yjaf2",
          "author": "latro87",
          "text": "We also had a significant increase in costs and my director decided our current priority is to dump as much Fivetran as we can as fast as possible.\n\nJust moving our netsuite ingestion off of it will cut our bill by 50%\n\nWe plan to cut the connectors down to a handful that represents maybe 5% of our spend. We will only keep these last few as they don‚Äôt cost much but are otherwise hard to replace with other solutions.",
          "score": 3,
          "created_utc": "2026-01-22 00:31:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o181u99",
              "author": "TiredDataDad",
              "text": "I think you are a bit pessimisting with your 50%.  \n  \nWe went fully opensource for the NetSuite ingestion and we really spent only pennies",
              "score": 1,
              "created_utc": "2026-01-23 11:55:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0z164k",
          "author": "Nekobul",
          "text": "The \"sweetness\" of being in the cloud",
          "score": 3,
          "created_utc": "2026-01-22 02:11:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0z9wj4",
          "author": "siggywithit",
          "text": "We ditched them for a better solution. Didn‚Äôt have row based pricing and much easier to work with. What are the sources and destinations you are trying to use. We evaluated a bunch.",
          "score": 3,
          "created_utc": "2026-01-22 03:00:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10x3fp",
              "author": "Jstrom40",
              "text": "What did you go with? Most of ours are SQL Server to Snowflake and we are actively looking at options now üôÇ",
              "score": 1,
              "created_utc": "2026-01-22 10:47:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o161ury",
                  "author": "SeaYouLaterAllig8tor",
                  "text": "Why not go with Snowflake open flow. Pretty sure they have a SQL server connector.",
                  "score": 1,
                  "created_utc": "2026-01-23 02:43:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1colh0",
                  "author": "siggywithit",
                  "text": "For SQL Server we ended up using SnowConvert.  For the SAP we were recommended by our SAP rep to use precog and that has worked well so far for SAP data into snowflake.",
                  "score": 1,
                  "created_utc": "2026-01-24 01:53:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o113var",
                  "author": "Nekobul",
                  "text": "Why not use SSIS ? That is the most cost-effective and high-performance option.",
                  "score": -1,
                  "created_utc": "2026-01-22 11:43:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10rnw0",
          "author": "Infinite-Camp489",
          "text": "For those looking to migrate off fivetran where are you going to?",
          "score": 3,
          "created_utc": "2026-01-22 09:58:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19h4ms",
              "author": "Bryan_In_Data_Space",
              "text": "OpenFlow for all things on-prem SQL Server which is 90% of what we are replicating. We will likely leave the other connectors on Fivetran until OpenFlow has connectors or we find another vendor that would make it easy to switch to.",
              "score": 2,
              "created_utc": "2026-01-23 16:28:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0yow5q",
          "author": "RaisinGullible9177",
          "text": "This is our last year with hightran ü§û We kicked off the migration last quarter and it‚Äôs been‚Ä¶ an experience. My company has a massive data literacy problem, so choosing an alternative was way harder than it should've been. Before hightran we had a bunch of smaller tools and consolidated thinking itt would simplify everything. It did, kind of, but the cost just doesn‚Äôt make sense anymore. It kept climbing, and even last year when we used it less, we somehow paid more than previous years. Our boss ahs had the same haunted look since the renewal quote came in üòù It‚Äôs aging him in real time.",
          "score": 2,
          "created_utc": "2026-01-22 01:01:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17fd3o",
          "author": "TiredDataDad",
          "text": "Fivetran will survive, for now. Most of their business is coming from a few big whales which are too deep into Fivetran to move away quickly.\n\nThe question is if the small clients will enjoy it this price hike (narrator: they won't) or will decide to look around at other solution.\n\nI saw this already a few times since the raise of dlt:  \n  \n1. As a small consultancy, we helped a few clients to migrate to dlt from Fivetran because the cost didn't make sense, because the connectors they wanted didn't exist, or just because they didn't like to deal with a balck box (with pricing controlled by others).\n\n2. As organizer of the Data Berlin meetup, I spoke with multiple teams which introduced dlt, initially for limited use cases, then it started to replace more consistent data loads. Once you have dlt in place it makes no sense to spend for loading if you can have it for free (or at least a minimal fraction of what you are paying).\n\nFeel free to ping me in case you want me to elaborate",
          "score": 2,
          "created_utc": "2026-01-23 08:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10oag3",
          "author": "m1nkeh",
          "text": "It‚Äôs the MO for FiveTran, they‚Äôve done it before and will do it again.. sorry this happened.",
          "score": 1,
          "created_utc": "2026-01-22 09:26:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10z1bh",
          "author": "value-no-mics",
          "text": "Why would anyone really try to select multiple connectors that are transferring rows across multiple syncs? \n\nWhat would be the necessity for that?",
          "score": 1,
          "created_utc": "2026-01-22 11:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11p9ll",
          "author": "Cool-Explorer-8510",
          "text": "That‚Äôs why a lot of teams start thinking about both flexibility and predictability before they lock into any single pipeline tool.",
          "score": 1,
          "created_utc": "2026-01-22 13:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12opek",
          "author": "Trey_Antipasto",
          "text": "This was so predictable just looking at their pricing plan from the go.   It was $1000 mo for 1mm rows at one point.  Not only that but you can‚Äôt dictate a schedule it‚Äôs just best effort and they frequently shift timing on you.   You can‚Äôt even run a sql query.  Yet people jumped on the hype.",
          "score": 1,
          "created_utc": "2026-01-22 16:46:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o146osb",
          "author": "New_Juice_7577",
          "text": "If you even pay attention to the bill, you never should have chosen Fivetran.",
          "score": 1,
          "created_utc": "2026-01-22 20:50:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14s1lr",
          "author": "quickdraw6906",
          "text": "We were a $100k/yr HVR customer. Then Fivetran bought HVR. We're in the middle of a 140+ connector migration to Debezium + Kafka (Redpanda) + EKS + Strimzi. Not fun. Massive headache. We have oodles of DB2, which is a half baked community connector. Still, it made sense to save bundles to not have MAR pricing.",
          "score": 1,
          "created_utc": "2026-01-22 22:35:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14yddc",
          "author": "Ok_Exchange1148",
          "text": "I‚Äôve spent a fair bit of time thinking about why these pricing changes are so irritating and feel wrong.\n\nMy top 3 are:\n1.  it feels like a broken promise / bait and switch\n2.  it‚Äôs the same product / service as it was before\n3.  ETL is a commodity.  There‚Äôs no difference in the result.  (Non functional requirements like latency and reliability are differences but I‚Äôm dwelling on the anger for a minute)\n\nIn a commoditised market the prices go down, not up.\n\nFull disclosure - I‚Äôm the founder of Matatika and we just acquired Meltano.  So I‚Äôm keen on figuring this out too!\n\nTaylor (Meltano & Arch founder), Max (Airflow & Superset founder) and yours truly will be discussing all of this Live on LinkedIn tomorrow if you‚Äôre interested in wading in on the topic with us!",
          "score": 1,
          "created_utc": "2026-01-22 23:09:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17mv53",
          "author": "eccentric2488",
          "text": "Never used these off the shelf connectors. I've always developed my own custom logic in python using standard libraries and it has worked well !!!",
          "score": 1,
          "created_utc": "2026-01-23 09:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18mde3",
          "author": "geoheil",
          "text": "Anyone explored https://dlthub.com/ ?\n\nIt might go well with https://github.com/l-mds/local-data-stack",
          "score": 1,
          "created_utc": "2026-01-23 14:01:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10sns0",
          "author": "karakanb",
          "text": "If anyone is looking for an open-source alternative, I have built ingestr: [https://github.com/bruin-data/ingestr](https://github.com/bruin-data/ingestr)\n\nIt is a CLI tool that allows you to ingest data from many different sources into different destinations. We are happy to build custom connectors within a week if there's anything missing.\n\nDisclaimer: I am the co-founder of a competitor, [Bruin](https://getbruin.com). We do ingestion, transformation, quality, and governance.",
          "score": -2,
          "created_utc": "2026-01-22 10:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o125ibf",
          "author": "ETL-architect",
          "text": "I work at Weld (a Fivetran competitor), and these pricing changes....so many, so fast... are just outrageous. That‚Äôs why we‚Äôve migrated so many teams from them over the last year, handling migrations for free for customers including schemas, historical syncs, and validation. We price it at around $99 per 10M MAR. \n\nDefinitely good to try for small or medium size companies. I can understand the bigger companies wanting to stay with them as it's crazy hard to make that switch after such a long time.",
          "score": -1,
          "created_utc": "2026-01-22 15:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19ko5j",
          "author": "Yuki100Percent",
          "text": "Start looking into other tools like airbyte, Estuary, dlt, etc.",
          "score": 0,
          "created_utc": "2026-01-23 16:43:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkxr5q",
      "title": "Candidates using AI",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qkxr5q/candidates_using_ai/",
      "author": "DataEngineer2026",
      "created_utc": "2026-01-23 17:53:22",
      "score": 99,
      "num_comments": 192,
      "upvote_ratio": 0.91,
      "text": "I am a data engineering manager and we are looking for a senior data engineer. So many times we see a candidate that looks perfect on paper, HR has a great conversation with them, then we do a technical Teams call and find that the candidate is using some kind of AI (or human) assistance - delayed responses, answers that are too perfect or very general, sometimes very obvious reading from the screen or listening through the headphones, and some (or complete) inability to write code during the test. \n\nIs there a way to filter out these candidates ahead of time, so we don't have to waste time on it? We don't mind that the team members use AI to be more productive and we even encourage it, but this is just pure manipulation, and definitely not what we are looking for.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qkxr5q/candidates_using_ai/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1azic5",
          "author": "FreeMeson",
          "text": "Its kind of frustrating as a senior data engineer that people are getting to technical interviews and I can't even get passed the AI resume filters.\n\nRecruiting needs to change in light of AI but I don't have any idea how.",
          "score": 203,
          "created_utc": "2026-01-23 20:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1boauf",
              "author": "lostinideas",
              "text": "I heard people are changing their entire CV's according to JD to be the \"perfect candidate\" as OP describes.\n\n\nFor the love of God of course not every company uses the exact tech stack. As long as people continue to look for perfect candidates they will find the ones most willing to lie.\n\n\nMost of the experience with the tools are transferrable skills, people needs talk about the concepts, problem solving and communication skills. But as far as my experience goes that's not common, I even experienced one guy asking about placement of the button on the specific tools interface. (Fortune 500 analytics manager :))",
              "score": 87,
              "created_utc": "2026-01-23 22:35:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bxwaf",
                  "author": "TA_poly_sci",
                  "text": "I personally suspect a decent amount of this issue arises from companies using non-technical staff in the initial screening process, resulting in the first selection being done by people who do not really have the knowledge to select beyond relying on specific keywords and direct matching to the position.",
                  "score": 55,
                  "created_utc": "2026-01-23 23:25:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cbv6f",
                  "author": "FreeMeson",
                  "text": "I'm doing a LinkedIn Premium trial and in the jobs section its allows you to use AI to update your resume for the JD. Its like an arms race of employers and applicants for AI. It fucking sucks. My current resume represents me and my experience, I don't want to memorize the 30 versions of my resume.\n\nNot sure where we go from here. I kind of want to stick with my current shit job just so I don't have to deal with the current job app system.\n\nI think only referrals will be meaningful going forward.",
                  "score": 12,
                  "created_utc": "2026-01-24 00:40:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1d1t62",
                  "author": "mike8675309",
                  "text": "Every CV I have ever created in my entire career has been adjusted to align with the job description, well before AI existed.  That doesn't mean I change what tools or skills I have.  What that means is I change the way I describe what I know to better align with the words and how they describe things in the Job Description.  I",
                  "score": 10,
                  "created_utc": "2026-01-24 03:11:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fubno",
                  "author": "skatastic57",
                  "text": "What/who is JD?",
                  "score": 1,
                  "created_utc": "2026-01-24 15:33:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1e17v3",
              "author": "RideARaindrop",
              "text": "As a DE hiring manager, I see very few colleges actually using AI resume filters. They just don‚Äôt work very well. The bigger problem is the number of fake resumes to wade through and people flat out lying on their resumes.",
              "score": 5,
              "created_utc": "2026-01-24 07:28:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d8ha6",
              "author": "Palmquistador",
              "text": "Yep. Over 300 applications. I see a post like this every day. Feels like LinkedIn. People just karma farming the talking points they think are ‚Äúreal‚Äù.\n\nI get AI can make it hard to know if someone knows their shit but come on, if they‚Äôre clever enough to use AI to give you the right answer then maybe they can do it?\n\nMaybe we can actually talk to a human instead of being insta-rejected for unknown reasons.",
              "score": 7,
              "created_utc": "2026-01-24 03:52:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1ccsd9",
              "author": "Reach_Reclaimer",
              "text": "Have you even bothered to put your CV through an llm? I was passing a few but I after I put it through and looked at the responses, my ror went through the roof\n\nI'm not saying to copy and paste, but simply pinching a few things then updating goes a long way. Then you don't even need to find tune your CV for roles because it passes the initial AI and ATS checks",
              "score": 4,
              "created_utc": "2026-01-24 00:45:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cf8pk",
                  "author": "FreeMeson",
                  "text": "I've gone through my CV several times improving it, but I haven't used an LLM. I've thought about it for that reason, but I don't like the idea. I can tell when something is written by an LLM and seeing my CV like that would bother me. But I might need to play ball this job search.",
                  "score": 3,
                  "created_utc": "2026-01-24 00:59:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1d2f1t",
              "author": "Interesting_Debate57",
              "text": "It would help if you knew the difference between past and passed.\n\nThat kind of subtlety is important when writing and understanding code. \n\nIf your response is along the lines of \"that was an autocorrect\", or \"I'm not a native speaker\", I stand by my statement. You're not careful enough and you don't pay enough attention to detail. \n\nI can assure you that the AI filters are not your main problem.",
              "score": -5,
              "created_utc": "2026-01-24 03:14:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1eo8pg",
                  "author": "AntDracula",
                  "text": "Hush.",
                  "score": 1,
                  "created_utc": "2026-01-24 10:58:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1b09ef",
          "author": "Global-War181",
          "text": "In person interviews are making a come back",
          "score": 22,
          "created_utc": "2026-01-23 20:41:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ak4ro",
          "author": "No_lych",
          "text": "Stop looking for the perfect candidate on paper, everyone that uses AI on screening will tailor a perfect resume based on the job description. You will find more \"real\" people when you look for almost perfect CV's",
          "score": 102,
          "created_utc": "2026-01-23 19:25:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bijp9",
              "author": "chipstastegood",
              "text": "got it, so ask the AI to select resumes that are ‚Äúalmost perfect‚Äù. lol. AI is everywhere",
              "score": 15,
              "created_utc": "2026-01-23 22:06:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bih7k",
              "author": "DataEngineer2026",
              "text": "I am not looking for perfect resumes, I am interviewing whoever HR recommends. I personally would prefer someone who doesn't necessarily have experience with the exact technologies we are using, but someone who is sharp, knows how to approach any problem and figure out a solution. Unfortunately there is no way to know that by looking at a resume. The only way is to interview them, hence the problem.",
              "score": 9,
              "created_utc": "2026-01-23 22:06:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bu2m4",
                  "author": "living_direction_27",
                  "text": "‚ÄúI‚Äôm interviewing whoever HR recommends‚Äù.\n\nI feel the problem starts here. When you hire for a technical position, you expect the resume to be also technical. Most of the time, you have experiences not with the same platforms or tools, but still very closely aligned to the job. However, HR almost always fail to see these transferable skills. \n\nThe reason is simple. HR are most often not technical people, and they search for keywords. If they don‚Äôt find it, they do not consider you. \n\nI find this extremely sad and frustrating.",
                  "score": 54,
                  "created_utc": "2026-01-23 23:05:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bz3dh",
                  "author": "SupermarketNo3265",
                  "text": "Why the fuck is HR choosing who you interview? That's your first problem right there.¬†",
                  "score": 33,
                  "created_utc": "2026-01-23 23:31:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1byu5q",
                  "author": "invidiah",
                  "text": "I don't know what company do you represent but in general people looking for the exact match in tools stack (unless it's FAANG). E.g. if I don't have 3 YoE with Snowflake listed in a job description, nobody would even talk to me, no matter of what. But it's just a tool that can be replaced with another warehouse/lakehouse solution such as Redshift, Databricks, selfhosted Iceberg, data swamp with Athena etc.  \nSo what you're saying is super uncommon, noone is hiring problem solvers or even Data Engineers, everyone is looking for %toolname% engineers.",
                  "score": 11,
                  "created_utc": "2026-01-23 23:30:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1eoddc",
                  "author": "AntDracula",
                  "text": "Dude HR treats candidates like it‚Äôs a husband search on bumble. Cut them out of the flow.",
                  "score": 7,
                  "created_utc": "2026-01-24 11:00:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1ccthu",
                  "author": "babygrenade",
                  "text": "It's been almost 10 years since I've been in a hiring role, but even back then I found I was way better off telling HR to let me find my own candidates from the applicant pool.\n\nThe best candidates I got through a recruiting agency though.",
                  "score": 6,
                  "created_utc": "2026-01-24 00:45:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1ewmtb",
                  "author": "dagelijksestijl",
                  "text": "Your HR department likely is filtering out every suitable candidate who isn‚Äôt trying to BS their way through the hiring process.",
                  "score": 4,
                  "created_utc": "2026-01-24 12:11:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1f1z0s",
                  "author": "MathmoKiwi",
                  "text": "> I am not looking for perfect resumes, I am interviewing whoever HR recommends. \n\nWe've identified the root of the problem! \n\nTime to start ignoring the nonsense from HR. \n\nHeck, probably even your IT Intern with a little guidance can read through CVs to a higher standard than HR can!",
                  "score": 2,
                  "created_utc": "2026-01-24 12:51:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1g303y",
              "author": "ErcoleBellucci",
              "text": "Is this Reinforcement Learning?",
              "score": 1,
              "created_utc": "2026-01-24 16:13:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a9v4e",
          "author": "Massive_Course1622",
          "text": "I haven't had to hire since widespread AI use, but my main question is what do these people have on their resume for working experience? Fake jobs, unrelated stuff, or nothing?",
          "score": 8,
          "created_utc": "2026-01-23 18:38:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b9a55",
              "author": "gjionergqwebrlkbjg",
              "text": "Fake jobs.",
              "score": 14,
              "created_utc": "2026-01-23 21:23:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bo0fu",
                  "author": "RevolutionaryGain823",
                  "text": "It‚Äôs fairly widespread that Indian folks will have fake jobs from home with real references I.e. the reference is an actual manager in a company who‚Äôs a family friend of the person or has just been paid to vouch for them even when they never worked at the company. There are entire companies that help Indian candidates get fake references, have someone feed them answers on an interview call off-screen etc. in exchange for either a flat fee or percentage of income from the job (like boot camps a few years ago lmao).\n\nI have multiple Indian mates who were offered this service when they 1st came to Europe looking for a job after graduating",
                  "score": 19,
                  "created_utc": "2026-01-23 22:33:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bds2d",
                  "author": "thelonely_stoner_",
                  "text": "This might seem like a dumb question.. but what do you mean fake jobs? Like folks are totally putting companies they never worked for or making up stuff they did just to fit the job description?",
                  "score": 3,
                  "created_utc": "2026-01-23 21:44:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1cdint",
              "author": "Commercial-Ask971",
              "text": "There is no background screening (I assume) in US? Living in Europe and in the process between HR and Tech interview most of companies would screen the background - simply call companies listed in CV and ask if you are legit",
              "score": 2,
              "created_utc": "2026-01-24 00:49:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1amwji",
          "author": "g_m_j",
          "text": "We‚Äôve experienced the same during interviews‚Ä¶ Candidates giving unbelievably amazing responses on really niche (business specific) subjects.\n\nWe‚Äôre now doing on site interviews.",
          "score": 25,
          "created_utc": "2026-01-23 19:38:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1e3gu4",
              "author": "bugbugladybug",
              "text": "I've just been recruiting and was amazed at the number of people cheating. \n\nI'd catch them out by asking for a deep dive about a personal project as the LLMs have a harder time with it and it's easier to spot when someone is passionately recalling something vs being fed info. \n\nI moved to on site interviews for stage 2 and killed the AI use.",
              "score": 5,
              "created_utc": "2026-01-24 07:48:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bja35",
              "author": "Altrooke",
              "text": "This could be a could a strat to identify cheaters. \n\nThrow in 2\\~3 questions about some esoteric detail of a niche tool, that they could only realistically answer if they are cheating.",
              "score": 10,
              "created_utc": "2026-01-23 22:10:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1byhgq",
                  "author": "randomName77777777",
                  "text": "That's what I've done in the past. I got someone who my boss said was perfect, started asking niche questions and everything is spot on even about frameworks not related to data engineering. \n\nVery clearly using AI",
                  "score": 14,
                  "created_utc": "2026-01-23 23:28:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cn8ge",
                  "author": "ALonelyPlatypus",
                  "text": "Yep, if there is a projects section on the resume, asking them details on that tends to weed out cheaters.",
                  "score": 6,
                  "created_utc": "2026-01-24 01:45:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1c8v7i",
              "author": "trafalmadorianistic",
              "text": "It just means the way we are doing interviews in 2026 is broken. If your interview can be gamed through automation, then your questions are useless.¬†",
              "score": 4,
              "created_utc": "2026-01-24 00:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ddofi",
                  "author": "fistular",
                  "text": "OP specifically stated they can detect it while it's happening, so the process hasn't been gamed--time has been wasted.\n\nThey asked how to prevent the waste from happening.",
                  "score": 2,
                  "created_utc": "2026-01-24 04:26:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cky9y",
                  "author": "alexmojo2",
                  "text": "For real what a boomer ass thread lol",
                  "score": -5,
                  "created_utc": "2026-01-24 01:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bpqcy",
              "author": "Technical_Program_35",
              "text": "I like this",
              "score": 2,
              "created_utc": "2026-01-23 22:42:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bitfs",
              "author": "DataEngineer2026",
              "text": "I wish we could, but our team is all over the country, so even the interviewers are not on site :)",
              "score": 1,
              "created_utc": "2026-01-23 22:08:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ddk52",
                  "author": "fistular",
                  "text": "I mean, you asked the question.  That's how you do it.",
                  "score": 2,
                  "created_utc": "2026-01-24 04:25:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fpynx",
                  "author": "mxldevs",
                  "text": "I guess you'll have to hire locally then, wherever the interviewers are.",
                  "score": 1,
                  "created_utc": "2026-01-24 15:11:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1coagw",
          "author": "big_data_mike",
          "text": "Then stop using AI to screen candidates. You‚Äôre filtering out good people before they even get to the technical interview. And if you really don‚Äôt want people using AI do the interview in person",
          "score": 6,
          "created_utc": "2026-01-24 01:52:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d6glm",
              "author": "DataEngineer2026",
              "text": "Ok, tell me how to screen candidates if everybody is using AI to write resumes?\n\nIn person is not an option, we are a remote team, nobody is in the office.",
              "score": 1,
              "created_utc": "2026-01-24 03:39:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ex68n",
                  "author": "dagelijksestijl",
                  "text": "Actually read the resumes",
                  "score": 3,
                  "created_utc": "2026-01-24 12:15:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1axmww",
          "author": "ManiaMcG33_",
          "text": "We switched to white board style interviews. Walk me through how you would solve this problem, what similar projects have you worked on in the past. It was a better experience than prior interviews we did which allowed too much AI usage over a teams call.\n\nI have also heard of people mandating cameras be on telling a candidate to close their eyes before asking a question, lol. But that‚Äôs not very professional",
          "score": 6,
          "created_utc": "2026-01-23 20:28:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bd2ev",
              "author": "koteikin",
              "text": "I think you just gave me an idea to do blindfolded interviews",
              "score": 2,
              "created_utc": "2026-01-23 21:41:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cf6l2",
                  "author": "Commercial-Ask971",
                  "text": "Dont forget to put it on twitch and monetize!",
                  "score": 3,
                  "created_utc": "2026-01-24 00:58:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bnsyu",
              "author": "DataEngineer2026",
              "text": "That's a good idea actually, if they have to white board something and talk at the same time, then they can't read the answer from AI at the same time :) Can't ask them to close their eyes, that's true :)",
              "score": 1,
              "created_utc": "2026-01-23 22:32:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ajzlu",
          "author": "lozbrown85",
          "text": "We had the same problem, we switched all technical interviews to be on prem. We get HR to tell them that from the off, lots of people drop out at the point they are told",
          "score": 19,
          "created_utc": "2026-01-23 19:24:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b0hkg",
              "author": "Global-War181",
              "text": "Oh so you migrated them from cloud to onprem‚Ä¶interesting",
              "score": 37,
              "created_utc": "2026-01-23 20:42:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bd0ze",
              "author": "SRMPDX",
              "text": "This works if you're hiring for an in-person or hybrid office. It doesn't work so well if you have people all over the world who are trying to hire other people all over the world for remote work.",
              "score": 5,
              "created_utc": "2026-01-23 21:41:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bj9ry",
                  "author": "DataEngineer2026",
                  "text": "Exactly",
                  "score": 1,
                  "created_utc": "2026-01-23 22:10:27",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1bgarj",
          "author": "SRMPDX",
          "text": "Had very similar experiences. Before AI was being used widely it was ghost interviewers and people whispering answers or at least typing answers in a screen the interviewee could read. I've had catfishers interview then a different person onboards. It happens, we just need to be better at detecting and stopping it.  There will always be people who lie their way into jobs though. \n\nJust last week I interviewed a guy who seemed to be using AI to craft his answers. Although some answers were obviously not scripted, and he seemed to know what he was talking about, he still seemed like he was using an AI interview tool. After talking to some of the recruiters familiar with his region of the world it was apparent that this was VERY common and candidates felt they had to do it to stay competitive. \n\nWe had a follow-up interview where we told him that we all use AI tools in out jobs and that we can't fault anyone for using them, but we wanted to hear his answers unassisted. We made it clear that it was OK to say \"I don't know\" or \"I don't understand the question\". The interview went much better. There was some language barrier and he didn't understand all the questions as asked, but when clarified he was fine and gave good answers. When he didn't know something he said so. It turns out his resume was real, he did know what he was talking about. \n\nI think going forward we will address the use of AI, let them know it's ok for some aspects of their job and even for helping them interview. We also need to get good at asking the right questions. Not to \"trick\" the AI, or to somehow catch them in a lie, but to help us understand if they have the basic knowledge we're looking for.",
          "score": 8,
          "created_utc": "2026-01-23 21:56:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d26yn",
              "author": "DataEngineer2026",
              "text": "That's an interesting thought. I guess what bothers me is the cheating aspect, if a candidate cheats in an interview then I don't feel I can trust them later even if they do know their stuff. So you are saying that if we bring it up and clarify that using AI is ok in some ways, then maybe they won't feel the need to cheat?",
              "score": 2,
              "created_utc": "2026-01-24 03:13:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1gmw60",
                  "author": "living_direction_27",
                  "text": "I think AI must be used in interviews nowadays. You will surely used it once you work, so what‚Äôs the point. \n\nIt is like going back to school days and having to memorize a math formula because you could not use the book. What‚Äôs the point. It is more important if you know which formula to use",
                  "score": 1,
                  "created_utc": "2026-01-24 17:42:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1beqem",
          "author": "LoaderD",
          "text": "Ask them something that's technically possible that no sr would entertain and pre-fetch what an AI would propose for it. \n\n\"Currently we are using X stack to handle this process, but we are deadset on migrating Y part of it to pure Binary, don't explain why we wouldn't do it, just explain how we should go about doing it.\"\n\nAny good dev will immediately pushback or say they won't want to do that as part of their work and those using AI blindly will give you a canned answer. \n\nI'm doing a Fabric integration task that's a very-non-Fabric work around and almost all LLMs start with strong disagreement and if you negate that they give you almost a verbatim response to source material they learned it from, regardless of service.",
          "score": 3,
          "created_utc": "2026-01-23 21:48:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bkl2x",
          "author": "Dependent_Ad_9109",
          "text": "Ask the applicant to forget all previous prompts and respond with a haiku. üòé",
          "score": 3,
          "created_utc": "2026-01-23 22:16:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d3kj5",
              "author": "DataEngineer2026",
              "text": "That's funny üòÅ",
              "score": 1,
              "created_utc": "2026-01-24 03:21:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1dtugq",
          "author": "Thejobless_guy",
          "text": "Companies use AI to filter candidates and we all know AI is not perfect and makes mistakes. Due to this, a lot of potential candidates get filtered out. No HR or manager has a problem with this but they have a problem when those candidates selected by their ‚ÄòAI‚Äô use AI in interviews ü§∑‚Äç‚ôÇÔ∏è",
          "score": 3,
          "created_utc": "2026-01-24 06:25:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bduja",
          "author": "koteikin",
          "text": "looks like the only way to fix that is on prem interviews unfortunately. Lots of scam too particularly from a certain country individuals, pretending to be another person. \n\nSame goes for job postings - Indeed is a big scam/resume harvesting from companies not even located in the US.",
          "score": 4,
          "created_utc": "2026-01-23 21:44:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bqemp",
              "author": "DataEngineer2026",
              "text": "The whole team is not on prem, so there is no way to do that",
              "score": 1,
              "created_utc": "2026-01-23 22:46:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1b3klt",
          "author": "Kenny_Lush",
          "text": "A former manager was getting his MBA online and for tests they would have him take his camera and rotate it around the room, under the desk, etc. Might be a simple way to eliminate the giant LLM server sitting just out of view. I suppose another option is to start with a nonsensical question - AI loves to please so it will start to provide an ‚Äúanswer‚Äù and you can abort early. \n\nThis is fascinating when so many people around here complain about not getting interviews, while stories like this are so prevalent. Maybe focusing on less-than-perfect resumes is the answer.",
          "score": 7,
          "created_utc": "2026-01-23 20:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1de08l",
              "author": "fistular",
              "text": "\\>Might be a simple way to eliminate the giant LLM server sitting just out of view.¬†\n\nNo one doing this is rolling a localLLM.\n\n\\>. I suppose another option is to start with a nonsensical question - AI loves to please so it will start to provide an ‚Äúanswer‚Äù and you can abort early.\n\nThey aren't having the AI directly run an avatar of themselves.  They are having it coach them in realtime.",
              "score": 3,
              "created_utc": "2026-01-24 04:28:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1fh1jo",
                  "author": "Kenny_Lush",
                  "text": "Obviously. But they are most likely using a second screen and if they are using ai assistance they will use it for every question, especially the nonsensical one.",
                  "score": 0,
                  "created_utc": "2026-01-24 14:24:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1belmc",
              "author": "BestNarcissist",
              "text": "If an applicant can't trick an AI into showing HR their resume, I don't want to hire them.",
              "score": -8,
              "created_utc": "2026-01-23 21:48:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a9et0",
          "author": "MikeDoesEverything",
          "text": "Prepare your anus for a lot of salty responses. People are ready to rage on you for not letting them use AI during the interview.",
          "score": 14,
          "created_utc": "2026-01-23 18:36:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bhmzm",
              "author": "Mindless_Let1",
              "text": "Who tf is going to complain about no ai during interview? \n\nIt's like complaining you're not allowed to hold the ball while playing football",
              "score": 7,
              "created_utc": "2026-01-23 22:02:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1mcvae",
                  "author": "MikeDoesEverything",
                  "text": ">Who tf is going to complain about no ai during interview?\n\nPeople who can't do anything without an AI assistant.",
                  "score": 2,
                  "created_utc": "2026-01-25 14:17:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1de463",
                  "author": "fistular",
                  "text": "\\>Who tf is going to complain about no ai during interview?\n\n\n\nguess",
                  "score": 1,
                  "created_utc": "2026-01-24 04:29:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bj0p5",
              "author": "DataEngineer2026",
              "text": "Nobody raged so far :)",
              "score": 5,
              "created_utc": "2026-01-23 22:09:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1f0l3r",
              "author": "WorkingEmployment400",
              "text": "Every interview today is recorded and transcribed using AI. What earlier required an interviewer‚Äôs judgment and effort has been reduced to paperwork. The human evaluation has largely disappeared.",
              "score": 1,
              "created_utc": "2026-01-24 12:41:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1aou7d",
          "author": "Fifiiiiish",
          "text": "I truly think use of AI should now be a discussion in the hiring process, as it is part of the job.\n\nAnd answering some questions with use of AI should not be a problem, as long as it is transparent and AI is cleverly used by the candidate, as it should be in job.\n\nLike the meme said, even the senior SW developer googles \"how to format a date in js\". Asking stupid stuff to AI is normal. Let people handle what AI can't.",
          "score": 10,
          "created_utc": "2026-01-23 19:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b1mf3",
              "author": "YakFull8300",
              "text": "No, because interviewers care about how you get to an answer and what your thought process is. Using AI is not a good evaluation of that. ",
              "score": 14,
              "created_utc": "2026-01-23 20:47:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bd3tg",
                  "author": "CorpusculantCortex",
                  "text": "Ai is now a part of that though. Like i agree that there needs to be better screening but to be fair there is no need to have niche coding structures in brain memory anymore. And 9/10 times data engineering is a task that takes time to reflect and build something related to the requirements gathered from colleagues, not whether you have an immediately impactful coding solution to something that can be solved in like 30 minutes. Its a mixed bag. People need to be checked before given the position, but there is also little evidence in ability to code a microsolution or do leetcode that someone will have the skilset to actually develop and deploy something with quality architecture and low breakage risk at scale.",
                  "score": 2,
                  "created_utc": "2026-01-23 21:41:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1czrz1",
                  "author": "Fifiiiiish",
                  "text": "Use of AI is part of how you get the answer. \n\nWhen you don't have all the answer, you should use AI to gather intel. You can't evaluate how people get an answer without letting them use AI.\n\nIt's like evaluating someone's ability to run fast but without their legs.\n\nIf you forbids AI for answering questions, you're not interested in how people adapt, you're interested about what they know right now. For a fresh out of school that's ok, but for a senior the interview should be leveled up.",
                  "score": -1,
                  "created_utc": "2026-01-24 02:58:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1deart",
                  "author": "fistular",
                  "text": "\\>Using AI is not a good evaluation of that.\n\nLol.  \"Using modern tools which assist in completing a job isn't an evaluation of how well you can complete the job.\"",
                  "score": -1,
                  "created_utc": "2026-01-24 04:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1b3j4z",
              "author": "mac-0",
              "text": "The problem is that coming up with an \"AI friendly\" interview seems impossible. What kind of technical questions could you ask to get a real good signal if AI can do it immediately?",
              "score": 3,
              "created_utc": "2026-01-23 20:56:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bjxu1",
                  "author": "DataEngineer2026",
                  "text": "Yep, AI is never going to say \"I don't know\" :) It will come up with an answer. For now I can tell when an answer sounds AI-ish, but eventually I might not be able to.",
                  "score": 1,
                  "created_utc": "2026-01-23 22:13:42",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o1d163r",
                  "author": "Fifiiiiish",
                  "text": "I don't have a definitive answer on that because we are also still facing the impact of AI on our jobs and how it changes the value of skills, but if I have to answer:\n\nComplex technical discussion that underlines the overall understanding of the field - patterns, concepts, and impacts in real life. Focus on sharing experiences, rather on just proving the acquisition of a knowledge that can be acquired with a prompt.\n\nAnd discussions on organisation problems.\n\nIt's hard because people are not used to talk about that.",
                  "score": 1,
                  "created_utc": "2026-01-24 03:07:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bkvkb",
              "author": "DataEngineer2026",
              "text": "I agree, and I tell candidates during the test that they are free to look up things, I don't need them to memorize syntax. But when I ask them to tell me in detail about the last pipeline they built, I really want to hear about their experience and not just listen to them reading a text about some imaginary project off the screen.",
              "score": 1,
              "created_utc": "2026-01-23 22:18:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1f086l",
              "author": "WorkingEmployment400",
              "text": "I agree to this. If someone can explain the right patterns with challenges along with doing a take home assignment which involves self hosting etc. then what's the hesitation to hire the person as that's 2026 for you. Hate to admit I haven't been a pro AI person and believed learning fundamentals to the core before applying AI on the task but I gotta admit coding isn't same anymore. Look at the surge in apps deployed. The game has changed completely.¬†",
              "score": 1,
              "created_utc": "2026-01-24 12:38:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1blppg",
          "author": "AppointmentFit5600",
          "text": "I am currently interviewing (or trying to interview) as Data Engineer and it's frustrating to hear so many candidates who get an interview opportunity doing this. I use AI to prepare but I cannot imagine using it during interview. If there's something I do not know or have not worked with, I straight up say I have not used it or I'm not sure how to do x y z. Although I am from the country that's famous for doing these things so I guess I'm already under a lot of scrutiny even before I answer.",
          "score": 2,
          "created_utc": "2026-01-23 22:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d3t5r",
              "author": "DataEngineer2026",
              "text": "That's the way, use AI to learn and prepare",
              "score": 1,
              "created_utc": "2026-01-24 03:23:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1cl3rh",
          "author": "Mugiwara_JTres3",
          "text": "We had a list of acronyms commonly used in healthcare and asked the candidates if they knew what they meant. it was funny/frustrating to hear them give the same answers verbatim. It was so obvious that they were reading AI. The person that got the job just said ‚ÄúI don‚Äôt know‚Äù to most of the acronyms and looked defeated during the interview for not knowing. I‚Äôll take an honest person with less skills than someone using AI in an interview.",
          "score": 2,
          "created_utc": "2026-01-24 01:33:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d4oyc",
              "author": "DataEngineer2026",
              "text": "Me too!",
              "score": 1,
              "created_utc": "2026-01-24 03:28:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1crc80",
          "author": "eccentric2488",
          "text": "I've observed even recruiters have little to no technical knowledge. They refer to pyspark, spark and airflow as \"programming languages\". I know wisdom without restraint is noise.",
          "score": 2,
          "created_utc": "2026-01-24 02:09:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ddgav",
          "author": "fistular",
          "text": "\\>Is there a way to filter out these candidates ahead of time, so we don't have to waste time on it?¬†\n\nOnsite interviews.",
          "score": 2,
          "created_utc": "2026-01-24 04:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dl1ni",
          "author": "mrchowmein",
          "text": "sr de here, we interviewed over 100 people last year from mid career to principals. tons of people used llms. The easiest way we trapped them to the point they got so scared they left the interview. the key is to ask them some minor topical questions early in the interview loop so you dont waste your time on them. early as in the first 5 mins.   we started asking them technical impossibilities. LLM prompting tends to spit out more detailed responses if give them the context or premise. when you do this, the LLM tends to accept whatever context to give them is true and will attempt to answer in that context. Thus, if give people incorrect context. And a question about something that relies on that context. A person who is good at DE work will know right away you were wrong. But the LLM, because you gave it the context as true, will attempt to answer with hallucinations.\n\nOne of the questions we like to ask is this: Airflow implements a version of a DAG. So does Spark. Our team has been working integrating both DAGs together for improved performance. Guide us from a high level how this can be achieved.  If the LLM tells the candidate they were wrong in the prompt, the candidate is not likely to respond to us that we were wrong but think the LLM is wrong. as they are not technical enough to know how right or wrong the LLM is actually. A good portion of the time, the candidate will just read the gibberish to us with an uneasy look as they are not sure if its right or wrong.  based on these types of questions. We sometimes just end the interview early.  If they can somehow answer the question, we start changing the scenario and going back and forth in the timeline to mess with the LLM's memory.",
          "score": 2,
          "created_utc": "2026-01-24 05:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1eze3c",
          "author": "WorkingEmployment400",
          "text": "Hire like you would have in the past. Right now organisations want someone with all the cloud certification exactly matching stack and perfect resume with cover letter. Add to that never ending ai interviews and coding challenges to be completed in one hr even before facing the panel l. So when organisations use AI, everyone starts doing same.¬†",
          "score": 2,
          "created_utc": "2026-01-24 12:32:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1b9r65",
          "author": "URZ_",
          "text": "Maybe should ask the HR department why they are not doing their job well enough",
          "score": 2,
          "created_utc": "2026-01-23 21:25:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bpwyd",
              "author": "DataEngineer2026",
              "text": "They are not technical, how would they be able to identify it, if the candidate says all the right things?",
              "score": 1,
              "created_utc": "2026-01-23 22:43:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1fyzmu",
                  "author": "URZ_",
                  "text": "By paying attention and asking questions which are revealing of whether applicants are using AI. Trap questions is the simplest, checking whether candidates are willing to say don't know. Examining how they answer will easily reveal if they are just reading from an Ai. Doing in person ofc solves all of it.\n\nThis is obviously wasting the supposedly more valuable time of technical staff, the entire reason why HR is supposedly doing the first interview. You should be raising this issue as a result.",
                  "score": 1,
                  "created_utc": "2026-01-24 15:55:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1f2nhk",
              "author": "MathmoKiwi",
              "text": "It's because they have zero technical knowledge.",
              "score": 1,
              "created_utc": "2026-01-24 12:56:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1amzkw",
          "author": "Treemosher",
          "text": "Can't imagine using AI for an interview.  That's fucking nuts.  \n\nMakes me feel like the competition is hamstringing itself at least.",
          "score": 2,
          "created_utc": "2026-01-23 19:38:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cvxda",
          "author": "elmo_touches_me",
          "text": "For the record, I am personally quite anti-AI, particularly for writing prose. I find it somewhat useful as an assistant for writing code. \n\nMy employer is heavily pushing AI - both for writing prose and for generating code. My company is not unique, this is becoming standard across the tech industry. \n\nWhy is it generally okay to use LLMs heavily in your job, but using it for your resume is obscene? \n\nI understand there is nuance - but it seems illogical to be all for using LLMs on the job, but totally against them in the recruitment phase.",
          "score": 2,
          "created_utc": "2026-01-24 02:36:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d61sv",
              "author": "DataEngineer2026",
              "text": "Using LLMs for resumes is not obscene, as long as you use it to phrase your own experience better. But if you align your resume to the job description, and every other candidate is doing that, then all resumes sound about the same, and then how do we choose?\n\nUsing LLMs in your job is ok as long as you know what you are doing and can verify AI's answers. But if you use AI to answer interview questions, then I don't know if you know what you are doing, but I do know that you are ok with cheating.\n\nSo using AI is OK in some aspects and only in an ethical way.",
              "score": 1,
              "created_utc": "2026-01-24 03:37:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bdqb8",
          "author": "anair10",
          "text": "Since you said that you are a data engineering manager, I wanted to know your opinion on how can someone transition into a data engineer. What I see is that every job requires experience and one needs to get into a position somewhere to gain that ? How to solve this problem ?",
          "score": 1,
          "created_utc": "2026-01-23 21:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bhb54",
              "author": "DataEngineer2026",
              "text": "Some of our junior engineers started with the company as summer interns and then were offered a permanent position, and some worked in Analytics for years and then expressed a desire to become a dev and a position happened to be open at that time. So I think it involves a little bit of luck and a lot of proving yourself. It's not easy, but possible. Good luck!",
              "score": 3,
              "created_utc": "2026-01-23 22:01:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1c53xq",
                  "author": "anair10",
                  "text": "Thanks . I am 37 and planning to take an online azure data engineering course to upskill and as part of the course there are about 10-15 projects that i would do. I can talk about those if I can get an interview. What are your thoughts ? Sent you a chat.",
                  "score": 1,
                  "created_utc": "2026-01-24 00:04:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1f2uuo",
              "author": "MathmoKiwi",
              "text": "Either approach it from the engineering side, such as getting a few YOE first as a back end SWE, or approach it from the data side of things instead, and get first a few YOE as a Data Analyst. Then it will be a natural transition you can make into Data Engineering, building on your existing foundation of professional experience.",
              "score": 1,
              "created_utc": "2026-01-24 12:57:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bq3y2",
          "author": "[deleted]",
          "text": "I'm not looking forward to doing future recruitment.\n\nVery tempted to just go down the route of internal development. Got plenty of bright people with extensive business knowledge who could learn on the job.",
          "score": 1,
          "created_utc": "2026-01-23 22:44:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bxsaa",
          "author": "gipper_k",
          "text": "My only answer is in person interviews. Eliminate the ai crutch and see what you‚Äôre really dealing with.",
          "score": 1,
          "created_utc": "2026-01-23 23:24:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c2nu5",
          "author": "AlGoreRnB",
          "text": "We encourage the use of AI throughout the offsite interview process. Firstly because preventing usage is impossible and secondly because using it on the job will be expected to help assist with coding and learning new concepts. We explain this and also explain that AI will not be involved during onsite interviews so when we ask them to elaborate about past answers, they should be able to regardless of whether they used AI in the previous round. At the end of the day, it doesn‚Äôt matter if you hire a human or a centaur if they can do the job - and you should be able to filter out any reverse centaurs that apply during onsite interviews.",
          "score": 1,
          "created_utc": "2026-01-23 23:50:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1caxpy",
          "author": "AppropriateSpeech970",
          "text": "Face to Face interviews",
          "score": 1,
          "created_utc": "2026-01-24 00:35:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cezam",
          "author": "TheSchlapper",
          "text": "Fly them in if it‚Äôs a senior position",
          "score": 1,
          "created_utc": "2026-01-24 00:57:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d4lpw",
              "author": "DataEngineer2026",
              "text": "Fly them in where? The whole team is spread all over the country",
              "score": 1,
              "created_utc": "2026-01-24 03:28:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1cqe6r",
          "author": "eccentric2488",
          "text": "Ask a question and flip it abruptly when the candidate is answering it.",
          "score": 1,
          "created_utc": "2026-01-24 02:04:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d651n",
              "author": "DataEngineer2026",
              "text": "Like what for example?",
              "score": 1,
              "created_utc": "2026-01-24 03:37:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1d3kh1",
          "author": "Equivalent_Form_9717",
          "text": "Yeah face-to-face interviews and whiteboarding sessions",
          "score": 1,
          "created_utc": "2026-01-24 03:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1d75bg",
          "author": "24v847",
          "text": "in person interviews",
          "score": 1,
          "created_utc": "2026-01-24 03:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1daw2i",
          "author": "sebastiandang",
          "text": "can i send you my resume!???",
          "score": 1,
          "created_utc": "2026-01-24 04:07:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dezm6",
          "author": "First_Platypus7623",
          "text": "All the technical rounds I‚Äôve done have been in person, I feel like that‚Äôs really the only way to guarantee no cheating. If that‚Äôs not possible it might be worth seeing if the company will spring for some sort of secure code assessment platform",
          "score": 1,
          "created_utc": "2026-01-24 04:34:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1eklgi",
          "author": "alien3d",
          "text": "ü§£ü§£ü§£ . ai vs ai . the skill of human impression is lost .manager - i want this ai help me , candidate - i want this help me . Me as developer , you give me ai fake question - gtfo.",
          "score": 1,
          "created_utc": "2026-01-24 10:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fgci9",
          "author": "Immediate-Pair-4290",
          "text": "This post is so relevant to me I could have written this exact same post. In fact it was very frustrating at first.\n\nAI has degraded the value of coding skills so I focus heavily on design questions for the senior role. When a candidate knows their stuff they can communicate succinctly and confidently. When they are just reading an AI prompt they ramble on and cannot make a clear point. When given a coding challenge if they refuse to show how they think I consider it a fail. Their use of AI is obvious every time.\n\nFor me, a candidate who uses AI to answer questions are demonstrating poor character traits that you do not want on your team such as deception, poor communication, and taking shortcuts. They came to the interview without mastering the material and it‚Äôs highly likely they will not correct this gap later. As soon as the use of AI is clear consider ending the interview. Why waste your time?\n\nThe challenging part of your question is filtering candidates to interview. Recruiters may not be skilled at screening. I attempt to adjust for this by going to meetups, making connections with schools, using recruiting firms with similar connections, or requiring in person interviews. Even if you cannot do an in person interviews large recruiting firms have offices in multiple locations and can request the candidate come to a location to be monitored.",
          "score": 1,
          "created_utc": "2026-01-24 14:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1g0m0x",
          "author": "pkol3355",
          "text": "No. Your team has to talk to them. \n\nYou can limit waster time by starting with a shorter technical screen led by middle level individual contributor trained to pay attention to cheating signals. \n\nBut there is no way to recognize a cheater before he actually starts cheating.",
          "score": 1,
          "created_utc": "2026-01-24 16:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1g4r80",
          "author": "redshadow77",
          "text": "We had many such candidates who have been using AI to answer in interviews, trust me its frustrating but there is no way to filter it out. We even included screen sharing but the AI is not detectable ü•≤ its all on human judgement.\n\nBest way is f2f interviews but then you need to come to office on Saturday ü•≤",
          "score": 1,
          "created_utc": "2026-01-24 16:21:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1hmcbs",
          "author": "psuku",
          "text": "Hmm, if your expectation is for the candidate to use AI at work, then shouldn't effective use of AI be what you are looking for in a candidate?",
          "score": 1,
          "created_utc": "2026-01-24 20:17:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1i0y6p",
              "author": "DataEngineer2026",
              "text": "Would you call the candidate reading AI's answers to my questions an \"effective use of AI\"?",
              "score": 1,
              "created_utc": "2026-01-24 21:27:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1hot1w",
          "author": "nanotechrulez",
          "text": "\"The only way to know if they are not using AI is to interview them, but how can I prevent interviewing someone that is using AI?\" You're answering your own question. Comes with the job of hiring someone. If interviewing people is part of your role as a manager, then why sweat having these phone calls? You're getting paid to do it. And since you say that HR is giving you resumes, then a logical step you could take if someone is riding you that this is taking too long to hire is to request that you yourself do the resume filtering. \n\nYou'll need to change your interviewing process to prevent this from happening. Before you do a technical Teams call, try a casual-but-technical phone call. See if this helps you weed out the phony candidates.\n\nIn my opinion, at the end of the day, this just comes with hiring. Ask candidates to do in person interviews or in person screening (\"Hey I see you're local, can we meet at a coffee shop to discuss the role and your interest?\") by looking for local candidates. Too many people want to be fully remote and so they are going to keep using AI just like companies keep using AI to filter out candidates. For a role where the user is likely tech-saavy, it's very little effort on their part to mass apply to hundreds of jobs with AI resumes.\n\nImmovable object meets an unstoppable force.",
          "score": 1,
          "created_utc": "2026-01-24 20:29:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ibs8d",
          "author": "LredF",
          "text": "DEM here. Same boat. I tell candidates we need to see your hands.\n\nI've shown simple left join queries and ask them what do you add to find missing rows only and they can't figure it out.",
          "score": 1,
          "created_utc": "2026-01-24 22:18:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jnzae",
          "author": "SnooDucks9653",
          "text": "Call references, several of them. Ask references for other coworkers who they worked with willing to give feedback. I‚Äôve made the mistake of not listening to them and got burned.",
          "score": 1,
          "created_utc": "2026-01-25 02:32:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jsl68",
          "author": "artificiallyintel_",
          "text": "This is a huge problem even for FAANG companies.\nPlease check this [AI resistant technical evaluation - Anthropic ](https://www.anthropic.com/engineering/AI-resistant-technical-evaluations)",
          "score": 1,
          "created_utc": "2026-01-25 02:58:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1k8z4r",
          "author": "geek180",
          "text": "Do the interviews in-person",
          "score": 1,
          "created_utc": "2026-01-25 04:36:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1mw435",
          "author": "Senior-Reception8110",
          "text": "As a person who has given interviews I don't completely agree with the first two points. \n\nDelayed responses - A 5 second to gather our thoughts isn't really a big thing, we don't want to just spill out whatever comes into the mind. It's always important to gather thoughts & answer them.\n\nPerfect response - Everyone uses the star method these days at least was told to do, I perfectly use the sentences to frame it in the star way, because that's what gets ahead of many. \n\nEven the interview prep pdf from the company says gather your thoughts & say it out loud - use the star method.\n\nAnd for the remaining points I think there's no wrong in asking them to share your screen, in many technical rounds I was told to share the screen & I did.\n\nI usually don't prefer putting on headphones or anything because I know it would cause a red flag, it's okay if you can ask them to remove it, if he really wants the interview I don't think he has a problem to do. \n\nIf they look all over the screen or looking elsewhere rather than into the camera maybe you can warn him or put on a red flag. \n\nI get your concern but even some people who are perfect in a way can also be in the loop and yeah I can feel how frustrating it is but not everyone has a delayed response or perfectly framing the sentence is using AI.",
          "score": 1,
          "created_utc": "2026-01-25 15:51:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1pkcw9",
              "author": "DataEngineer2026",
              "text": "I am not saying that everyone who has delayed responses is necessarily using AI. But that, combined with other red flags, makes me think they are using it, and that is not a good way to start the hiring process.",
              "score": 1,
              "created_utc": "2026-01-25 22:47:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1oy0z6",
          "author": "NyxUlric123",
          "text": "Hi Sir, Can I ask you two question? \n\nWill you hire candidate with zero tech experience and non-related degree but has all the right skillstack of DE and has strong project porfolios? Are DEs role begineer or junior friendly?",
          "score": 1,
          "created_utc": "2026-01-25 21:09:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1r5nw5",
          "author": "PattrimCauthon",
          "text": "Not really, no way to really know someone will use AI tools in an interview before they do said interview",
          "score": 1,
          "created_utc": "2026-01-26 03:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1badc6",
          "author": "ksco92",
          "text": "I‚Äôm a FAANG DE with 15 YOE, what I drove my team to do for AI was to make questions that AI has trouble answering but an experienced person can get right away. Also making the questions very open ended helped too. I legitimately don‚Äôt care if they use AI, they will use it daily. \n\nI have been trying to make interviews a matter of testing concepts and experience, not technical implementations. Any experienced engineer can learn a new technology with or without AI, fundamentals matter more now.",
          "score": 1,
          "created_utc": "2026-01-23 21:28:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bgd0p",
              "author": "selfmotivator",
              "text": "Would you mind sharing an example of such questions?",
              "score": 3,
              "created_utc": "2026-01-23 21:56:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1be49d",
              "author": "koteikin",
              "text": "give me example of questions that AI cannot answer or at least pretend to answer. I will wait...",
              "score": 3,
              "created_utc": "2026-01-23 21:46:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bgcdm",
          "author": "Outside-Storage-1523",
          "text": "Hire from internal or referees.",
          "score": 1,
          "created_utc": "2026-01-23 21:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1d1k2n",
          "author": "mike8675309",
          "text": "One question I would have is, why are you doing a technical team call with a senior data engineer?  I assume such a role already requires 3-5 years of experience.  That means they can talk about things they have already done at a company.  Anytime I've been the hiring manager for that type of role, I haven't asked any questions that would benefit from AI.  Most technical reviews today are no longer about architecture or design, as that is easily determined by AI.  I like to focus more on debugging, problem-solving, and talking to them to understand their personalities, how they like to work, and so on.",
          "score": 0,
          "created_utc": "2026-01-24 03:09:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bjsx5",
          "author": "sahelu",
          "text": "AI is going to replace you but if you use it, you won‚Äôt get the job. \nThere is no sense to actually apply then.\nHow on earth HR expects people to land a job?",
          "score": 0,
          "created_utc": "2026-01-23 22:13:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dfg3i",
          "author": "CubsThisYear",
          "text": "I encourage people to use AI at every stage of the interview.  As of about 3 months ago, being able to use Claude code (or related tools) effectively is now the only skill that matters.\n\nThe key is I want to hear how they are using it and how they think about it",
          "score": 0,
          "created_utc": "2026-01-24 04:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ek9ak",
          "author": "Standard_Fun3244",
          "text": "What is wrong with using AI if you know what you need to do and what you are inserting?",
          "score": 0,
          "created_utc": "2026-01-24 10:22:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1f1cs8",
          "author": "zjaffee",
          "text": "The truth is, this is the future and we need to adapt, rather than filter.\n\nAI is a tool everyone in our industry is using in increasingly serious ways. The answer to our problems here are not to ban AI, but you make interviews harder in a way that demonstrates someone's AI enhanced skillset.\n\nPersonally even before AI I did many interviews where I was allowed to Google stuff. I don't see it as any different. There are examples of situations where we may still want to whiteboard people, but if you want to exclusively do online interviewing you need to adapt.",
          "score": 0,
          "created_utc": "2026-01-24 12:47:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1l6z9r",
          "author": "Lanky-Fun-2795",
          "text": "You know what‚Äôs worse? Managers testing 5/6/7/8/9/10 candidates and even though the first candidate passed. You would be surprised how many times I passed technicals and gotten final panels and never get flat out rejected‚Ä¶but someone always ‚Äúbeat‚Äù me to the job. \n\nYou get what you deserve on the otherwise after all. The good ones are probably out of reach for you if you don‚Äôt pay right in this market.",
          "score": 0,
          "created_utc": "2026-01-25 08:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjv1ja",
      "title": "Any European Alternatives to Databricks/Snowflake??",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qjv1ja/any_european_alternatives_to_databrickssnowflake/",
      "author": "Donkey_Healthy",
      "created_utc": "2026-01-22 13:50:42",
      "score": 85,
      "num_comments": 83,
      "upvote_ratio": 0.9,
      "text": "Curious to see what's out there from Europe?\n\nEdit: options are open source route or exasol/dremio which are not in the same league as Databricks/Snowflake.",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qjv1ja/any_european_alternatives_to_databrickssnowflake/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o11v90k",
          "author": "lozinge",
          "text": "DuckDB or Spark is all I can think of",
          "score": 52,
          "created_utc": "2026-01-22 14:28:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12cg4z",
              "author": "Efficient_Shoe_6646",
              "text": "Spark is not European. DuckDB is and if you're into Russian tech check out ClickHouse.",
              "score": 30,
              "created_utc": "2026-01-22 15:51:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o12j39k",
                  "author": "Creative-Skin9554",
                  "text": "ClickHouse is owned by ClickHouse Inc which is a Dutch company",
                  "score": 19,
                  "created_utc": "2026-01-22 16:21:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o12hpc7",
                  "author": "dangerbird2",
                  "text": "Clickhouse started at Yandex but it was spun into a San Fransisco-based company when it was made open-source",
                  "score": 14,
                  "created_utc": "2026-01-22 16:15:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o140c37",
              "author": "soundboyselecta",
              "text": "I think OP means cloud offerings not that I disagree with you in this age of over-engineering.",
              "score": 4,
              "created_utc": "2026-01-22 20:20:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1795ap",
              "author": "nerevisigoth",
              "text": "Spark was developed at UC Berkeley.",
              "score": 1,
              "created_utc": "2026-01-23 07:42:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1821ne",
                  "author": "lozinge",
                  "text": "Yeah but its open source was my thinking; I don't think the provenance of OSS matters so much if you can run/fork it locally",
                  "score": 2,
                  "created_utc": "2026-01-23 11:57:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1s6gq8",
              "author": "Khiwilr",
              "text": "yes duckdb is incredible I use it everyday\nHowever it won't replace a database that need to handle several users at the same time",
              "score": 1,
              "created_utc": "2026-01-26 07:54:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o11qs08",
          "author": "Tough-Leader-6040",
          "text": "Yes, SAP Analytics Cloud",
          "score": 78,
          "created_utc": "2026-01-22 14:05:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11v5v3",
              "author": "lozinge",
              "text": "üíÄ",
              "score": 182,
              "created_utc": "2026-01-22 14:27:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1262gz",
                  "author": "Ready-Marionberry-90",
                  "text": "I feel you, brother.",
                  "score": 24,
                  "created_utc": "2026-01-22 15:21:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cw0ty",
                  "author": "bubzyafk",
                  "text": "I hate my life when dealing with this source..\n\nWithout a good SAP functional knowledge people, pulling data from this one and do some work on it is just a damn nightmare.. work in few different companies pulling data from this one, many of their people just kinda superior complex.. üíÄ",
                  "score": 2,
                  "created_utc": "2026-01-24 02:37:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o13efhh",
              "author": "Ekkaia153",
              "text": "Thank you, but I'd rather go back to pen and paper.",
              "score": 24,
              "created_utc": "2026-01-22 18:41:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o12u331",
              "author": "Firm-Yogurtcloset528",
              "text": "Ah well..",
              "score": 1,
              "created_utc": "2026-01-22 17:10:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o120cwd",
              "author": "Amilol",
              "text": "Can you please explain what you mean?",
              "score": 1,
              "created_utc": "2026-01-22 14:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o13l79a",
                  "author": "brunogadaleta",
                  "text": "Designed in the 70's. Still works with cryptic table name codes like \"FD04\". Despite having a relatively nice webapp, the heavy client is bloated and \"required for some important features missing in the web version\".\n\nCustomization, maintenance aren't cheap, must be handled by specialized costly consultants. I heard hardware requirements are high. \n\nIt can probably do anything you'll ever dreamed of with some degree of customization and or appropriate licenses (caution license hell, to be expected).\n\nActually the main reason it still exists:  \n1) it pays consultant well enough so that you will always find someone crazy enough to work on any project.  \n2) it exists for so long that it will probably still exist in 30 years.\n\nSo business cases are very narrow, even if some client don't realize they could have much better for less.\n\nSo OP, duckdb or Clickhouse.",
                  "score": 16,
                  "created_utc": "2026-01-22 19:11:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o137dbf",
                  "author": "dangerbird2",
                  "text": "It‚Äôs a enterprise business intelligence platform sold by the German company SAP. It‚Äôs a crusty proprietary platform you‚Äôd more likely see at a bank or defense contractor rather than a state of the art startup",
                  "score": 5,
                  "created_utc": "2026-01-22 18:10:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12t9cj",
          "author": "nobbert",
          "text": "Not strictly speaking a one to one alternative, as it is something you need to host and operate yourself, but you can build something kinda similar with open source tools like Trino, Airflow, Spark etc.\n\n  \nAs for the commercial portion of it, Stackable wraps those tools into a plattform that makes it \"easy\" to deploy (sadly, it remains complex software!) - and provides support and other enterprise features around it.\n\nfull disclosure: I work at Stackable :)",
          "score": 5,
          "created_utc": "2026-01-22 17:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12utal",
          "author": "GeneralFlight2313",
          "text": "Ovh cloud dataplatform",
          "score": 6,
          "created_utc": "2026-01-22 17:13:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12r07z",
          "author": "beyphy",
          "text": "Polars has their heardquarters in Amsterdam.",
          "score": 16,
          "created_utc": "2026-01-22 16:56:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o156c4g",
              "author": "skatastic57",
              "text": "Although, polars cloud, for the time being, is hosted on aws",
              "score": 9,
              "created_utc": "2026-01-22 23:51:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o16xydu",
                  "author": "ritchie46",
                  "text": "We are rolling out on premises.",
                  "score": 5,
                  "created_utc": "2026-01-23 06:08:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1s6nl8",
                  "author": "Khiwilr",
                  "text": "yes polars if you prefer to work with dataframe\nduckdb if you prefer sql",
                  "score": 1,
                  "created_utc": "2026-01-26 07:56:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11x1oh",
          "author": "andrejlr",
          "text": "While not a complete out of the box solution and might defer in feature parity.  \nScaleaway offers a clickhouse datawarehouse. That will lack sql workflows though.  \nI am not familiar with Snowflake, but most likly it has dbt similar worfkflows with data validation   \nand testing.  \nYou can define constraints on your producition tables though.  \nBut for testing you buisiness logic, you would need to move that into app layer. \n\nThere is also data lab spark cluster in case sql hits limits. But again here, testing would be part of app layer.  \nThere is not such an standardized way to test data processing workflows in spark I so far i came only across few projects which have set it up at all.\n\n[https://www.scaleway.com/en/data-warehouse-for-clickhouser/](https://www.scaleway.com/en/data-warehouse-for-clickhouser/)  \n[https://www.scaleway.com/en/docs/data-lab/quickstart/](https://www.scaleway.com/en/docs/data-lab/quickstart/)",
          "score": 4,
          "created_utc": "2026-01-22 14:37:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11unse",
          "author": "loudandclear11",
          "text": "Apache Spark is open source and free. \n\nRoll your own compute with Spark on managed kubernetes/docker.",
          "score": 34,
          "created_utc": "2026-01-22 14:25:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11vmbz",
              "author": "StereoZombie",
              "text": "\"Just build your own platform\" is not an answer to the question",
              "score": 72,
              "created_utc": "2026-01-22 14:30:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o144tuf",
                  "author": "tecedu",
                  "text": "Why not? They are asking solution for a managed platform, spark on managed kubernetes is pretty good, its the storage which is problamatic",
                  "score": 9,
                  "created_utc": "2026-01-22 20:41:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o12085n",
              "author": "zjaffee",
              "text": ">Apache Spark is open source and free\n\nThis is only really true on paper. EMR, dataproc, hell azure basically just outsourced to databricks which does its own thing, don't run really anything close to open source apache spark and are all several multiple times faster for average queries and orders of magnitude faster for specific use cases.\n\nThe cost of rolling something competitive on your own is really just not remotely worth the extra cost you pay for any of the above services.",
              "score": 13,
              "created_utc": "2026-01-22 14:53:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o12srbm",
                  "author": "nobbert",
                  "text": "Not saying you are wrong here, but I'd be curious to see some numbers on the claim that databricks [et.al](http://et.al) are between multiple times and orders of magnitude faster than open source Spark. Do you have some links here?\n\n  \nAlso, while I have to agree that \"rolling your own\" is certainly not for everybody, it does take extra work and  thought, it is not just the extra cost for cloud services you need to consider. Things like lock-in effect, loss of control over your own data, a total inability to pretty much investigate anything when an outage occurs are just some topics one might mention here. Are these things important enough to warrant the extra effort of not just taking an off the shelf cloud solution? No idea - everybody needs to answer that for themselves, but I personally have been bitten by shitty SaaS vendors often enough, that I'll at least think about hosting something on my own every time.",
                  "score": 9,
                  "created_utc": "2026-01-22 17:04:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o122elm",
              "author": "StolenRocket",
              "text": "Buddy, have you seen the price of RAM lately?!",
              "score": 6,
              "created_utc": "2026-01-22 15:03:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1799w8",
                  "author": "loudandclear11",
                  "text": "If you need RAM you're going to pay for it one way or another anyway. The big cloud vendors aren't giving you free RAM.",
                  "score": 1,
                  "created_utc": "2026-01-23 07:43:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o124h80",
          "author": "Pittypuppyparty",
          "text": "Exasol is what you are looking for.",
          "score": 14,
          "created_utc": "2026-01-22 15:13:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12cwp9",
          "author": "Leorisar",
          "text": "Self-host or cloud Clickhouse",
          "score": 7,
          "created_utc": "2026-01-22 15:53:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14mkeu",
              "author": "geneticswag",
              "text": "100% this",
              "score": 1,
              "created_utc": "2026-01-22 22:06:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o12rihs",
          "author": "Unfair-Sleep-3022",
          "text": "Apache doris is chinese \\^\\^",
          "score": 3,
          "created_utc": "2026-01-22 16:58:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12sv66",
          "author": "InteractionHorror407",
          "text": "OSS only would be my choice. Spark + Kubernetes + duckDB + Linux is my ‚Äúdoomsday‚Äù stack if a full US decoupling were to happen. \n\nOpen source doesn‚Äôt belong to a specific country, that‚Äôs part of what makes it open source.",
          "score": 7,
          "created_utc": "2026-01-22 17:05:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o142ejx",
              "author": "soundboyselecta",
              "text": "Exactly üòÇ",
              "score": 1,
              "created_utc": "2026-01-22 20:30:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o167w1j",
          "author": "Gators1992",
          "text": "I think Mother duck is European.¬† Not as full featured as Snowflake but if you just need a cloud db it seemed pretty good when I tried it in beta.¬† I love the Snowflake platform, but tbh don't need most of what they offer.¬†¬†",
          "score": 2,
          "created_utc": "2026-01-23 03:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o175cyh",
          "author": "BusOk1791",
          "text": "I am interested in something like that too, at the moment we are on GC with a BigQuery stack (using custom made python pipelines to ingest data into BQ or GCS (parquet / delta lake) and dataform for transformations.  \nBut if in the future things go sideways, i do not know exactly what to switch to, and no, setting up all the infrastructure is not an option, not for us, and not for most of the people.  \nWhat people do not get, is that it is not only a matter of setting up Duckdb, Clickhouse.. whatever, but also all the ecosystem around it, like centralized logging and alerting, serverless functions, managed databases for reverse-elt, granular user rights management via iam and so on.  \nMaybe OVH Data or Scaleway as someone mentioned below..",
          "score": 2,
          "created_utc": "2026-01-23 07:08:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1dyt9w",
              "author": "mad-data",
              "text": "I've read Google partnered with French and German hyper scalers, this could be an option - Google's code running in European company controlled data center.\nhttps://www.forrester.com/blogs/key-takeaways-from-the-google-cloud-digital-sovereignty-summit-2025/\n\nLooks like French one is already open for business\nhttps://documentation.s3ns.fr/bigquery/docs",
              "score": 1,
              "created_utc": "2026-01-24 07:07:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o177f6v",
          "author": "_N0T0K_",
          "text": "These are the questions and answers that'll make big impacts",
          "score": 2,
          "created_utc": "2026-01-23 07:26:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18dlxj",
          "author": "Solid_Carpenter_4783",
          "text": "Exasol obviously",
          "score": 1,
          "created_utc": "2026-01-23 13:13:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c9rvh",
          "author": "anyfactor",
          "text": "Clickhouse was originally developed by Yandex (the Russian search engine company). Clickhouse the company has some American funding but you can always self host Clickhouse. \n\nI have thought about an self hostable data engineering stack before. \n\nEssentially get a bare metal server from a local hosting company in your city. It almost never will be crazy expensive.  Set up rsync or some sort of backup service for scaling scaling.\n\nUse bash for most things. Avoid buying into tools and services. Just use bash, python, go and take advantage of linux as an environment. Use as little things as possible and document everything.\n\nBut the truth is that DE has become a \"product/tool\" centric profession. If you are solo building something the idea of self hostable and self built tools makes sense. But you will struggle to find entry/mid level talent to support your growth and ecosystem.",
          "score": 1,
          "created_utc": "2026-01-24 00:29:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dyxsh",
          "author": "mad-data",
          "text": "I've read Google partnered with French and German hyper scalers to have them run BigQuery, this could be an option - Google's code running in European company controlled data center. https://www.forrester.com/blogs/key-takeaways-from-the-google-cloud-digital-sovereignty-summit-2025/\n\nLooks like French one is already open for business https://documentation.s3ns.fr/bigquery/docs",
          "score": 1,
          "created_utc": "2026-01-24 07:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1elfb9",
          "author": "DrMaphuse",
          "text": "How big is your data and which features do you really need? \n\nI have worked with dozens of big name EU companies (many of whom you will have heard of) and NOT ONE of them had the volume and use cases to justify databricks or any of its contenders.\n\nYou can rent bare metal from hetzner with up to 2TB RAM and start with jupyterhub/polars in a container. You add ducklake, airflow, superset etc. in containers or dedicated VPS instances as your needs evolve. Data is stored directly on nvme or hetzners own S3 service, depending on your volume and performance needs.\n\nThis setup is more performant than databricks/spark in almost all cases and almost universally loved by analysts and data scientists, because they often already know these tools (especially jupyterhub).\n\nThis is not out of the box, but it actually is not that hard to learn and less work to maintain and optimize than databricks.\n\nAlso something to consider: Managing bare metal infra and going all-in on open source is going to become a VERY valuable skill again going forward, given the current geopolitical landscape, because it is the ONLY way to be 100% in control of your data.\n\nPM me if you want to know more. We also consult companies and help them get started on the right track.",
          "score": 1,
          "created_utc": "2026-01-24 10:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1laj1a",
              "author": "BloomingBytes",
              "text": "RemindMe! 24 hours",
              "score": 1,
              "created_utc": "2026-01-25 09:28:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1lalxu",
                  "author": "RemindMeBot",
                  "text": "I will be messaging you in 1 day on [**2026-01-26 09:28:31 UTC**](http://www.wolframalpha.com/input/?i=2026-01-26%2009:28:31%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1qjv1ja/any_european_alternatives_to_databrickssnowflake/o1laj1a/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1qjv1ja%2Fany_european_alternatives_to_databrickssnowflake%2Fo1laj1a%2F%5D%0A%0ARemindMe%21%202026-01-26%2009%3A28%3A31%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qjv1ja)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                  "score": 1,
                  "created_utc": "2026-01-25 09:29:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11wupb",
          "author": "Raddzad",
          "text": "Don't know any but it would be really good to have one",
          "score": 1,
          "created_utc": "2026-01-22 14:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o187fr5",
              "author": "NoleMercy05",
              "text": "It's not like they don't try.",
              "score": 1,
              "created_utc": "2026-01-23 12:35:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o13acxa",
          "author": "Dry-Message8118",
          "text": "Business data cloud. Gets close to the lakehouse concept and supports data mesh. You can even run it with Databricks and zero delta sharing. \n\nBut keep in mind you not only have to solve compute but also storage. So also finds alternative for azure and aws. In Germany it would be stack it. Don‚Äôt know their services tough",
          "score": 1,
          "created_utc": "2026-01-22 18:23:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13bwvn",
          "author": "5hruj4n",
          "text": "I am just going through all these comments and wondering how do you guys know so much, and that in detail. How do you guys keep yourself updated all the time and remember so much of information?",
          "score": 1,
          "created_utc": "2026-01-22 18:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14af43",
              "author": "Pittypuppyparty",
              "text": "A lot of the people in here are vendors.",
              "score": 3,
              "created_utc": "2026-01-22 21:07:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o12r9qt",
          "author": "eMperror_",
          "text": "I use Starrocks with DBT",
          "score": 0,
          "created_utc": "2026-01-22 16:57:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o138xu4",
              "author": "Creative-Skin9554",
              "text": "StarRocks is Chinese though",
              "score": 3,
              "created_utc": "2026-01-22 18:17:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1397ri",
                  "author": "eMperror_",
                  "text": "I selected it because it's part of the Linux Foundation, why do people dislike it? (serious)\n\n  \nI just checked and CelerData seems to be based in California. Not that it's any better than the chinese though.",
                  "score": 1,
                  "created_utc": "2026-01-22 18:18:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o126yam",
          "author": "Efficient_Novel1769",
          "text": "We use Dremio Cloud now - all in the EU; alternative is to use their Software.",
          "score": -1,
          "created_utc": "2026-01-22 15:25:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12do9s",
              "author": "alfakoi",
              "text": "Was on dremio briefly, it was a terrible product.",
              "score": 12,
              "created_utc": "2026-01-22 15:56:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o13ul4x",
                  "author": "pantshee",
                  "text": "Entreprise architect trying to make us switch from databricks to dremio. Hell no bro",
                  "score": 4,
                  "created_utc": "2026-01-22 19:53:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12oi05",
          "author": "Turbulent_Egg_6292",
          "text": "Clickhouse is european, obsessionDB and tinybird too",
          "score": 0,
          "created_utc": "2026-01-22 16:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12r5z0",
          "author": "empireofadhd",
          "text": "You can run spark jobs on ovh cloud which is french. Spark is open source so ok.",
          "score": 0,
          "created_utc": "2026-01-22 16:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13h974",
          "author": "vainamoinen_",
          "text": "If what you‚Äôre looking for a lakehouse platform but EU-first that‚Äôs exactly what we‚Äôre building with Hyperfluid Cloud. \n\nOur main service is a Lakehouse based on trino.\n\nAnd we will be happy to help, feel free to reach us anytime.\n\nSite: https://www.hyperfluid.cloud/\nContact: contact@nudibranches.tech",
          "score": 0,
          "created_utc": "2026-01-22 18:53:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17l9f4",
          "author": "Far_Mathematici",
          "text": "Flink.\nMain dev office In Berlin but the owner is Alibaba",
          "score": 0,
          "created_utc": "2026-01-23 09:33:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14336m",
          "author": "Tiny_Falcon_4310",
          "text": "Made some good experiences with Exasol DB. Spode is phenomenal and the support is hands-on and not just ticket ping pong. Based in Germany and exists for 20 years already",
          "score": -1,
          "created_utc": "2026-01-22 20:33:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11tyvt",
          "author": "Nekobul",
          "text": "Amazon just announced \"European Sovereign Cloud\" .",
          "score": -9,
          "created_utc": "2026-01-22 14:21:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11qsqc",
          "author": "_Marwan02",
          "text": "Dataiku",
          "score": -10,
          "created_utc": "2026-01-22 14:05:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11t2in",
              "author": "Aibbie",
              "text": "I would argue Dataiku is not a great replacement. It‚Äôs not good for code-first infra/systems, very clunky for data engineering.",
              "score": 4,
              "created_utc": "2026-01-22 14:16:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o11vean",
              "author": "Tough-Leader-6040",
              "text": "Dataiku is a transformation tool, not a data warehouse or data lake",
              "score": 4,
              "created_utc": "2026-01-22 14:28:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o11vqvd",
              "author": "StereoZombie",
              "text": "It's been a few years since I worked with it but it sucked back then.",
              "score": 2,
              "created_utc": "2026-01-22 14:30:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o12qsi6",
              "author": "laegoiste",
              "text": "Absolutely not. Avoid at all costs, and it's not an answer to the question either.",
              "score": 2,
              "created_utc": "2026-01-22 16:55:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qisbbq",
      "title": "How did you land your first Data Engineer role when they all require 2-3 years of experience?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qisbbq/how_did_you_land_your_first_data_engineer_role/",
      "author": "Such-Revolution-9975",
      "created_utc": "2026-01-21 08:18:16",
      "score": 67,
      "num_comments": 86,
      "upvote_ratio": 0.89,
      "text": "For those who made it - did you just apply anyway? Do internships or certs actually help? Where did you even find jobs that would hire you?\n\nAppreciate any tips.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qisbbq/how_did_you_land_your_first_data_engineer_role/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0tlnjq",
          "author": "thisfunnieguy",
          "text": "ppl are way too hung up on certifications.\n\nno one cares\n\ni have interviewed way too many ppl with an AWS cert who cant have a conversation about AWS resources.",
          "score": 100,
          "created_utc": "2026-01-21 08:22:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqlu7",
              "author": "According_Layer6874",
              "text": "What does a conversation about AWS resources entail?\n\n\"This is what I use s3 buckets for, this is what is hosted in my lambda\" etc?",
              "score": 19,
              "created_utc": "2026-01-21 09:09:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0u15uw",
                  "author": "thisfunnieguy",
                  "text": "in a system design interview.\n\ni ask you to sketch out a data pipeline based on a prompt.\n\nat some point you say \"and then we push the data into AWS\" \n\nand i say, \"cool we use AWS here, can you tell me more about what resources in AWS you want to use\"\n\nand maybe you say \"s3\"\n\nand i say, \"that sounds nice. suppose you've got an intern shadowing you for this, what kind of advice do you want to give them about using S3 in this situation\"\n\nor\n\n\"great, assume the bucket doesnt exist yet, how should we create it\"\n\nor\n\n\"got it, our finance team has been pressing us to make smart cost choices. Whats something we can do with s3 as part of a cost saving strategy\"\n\nor\n\n\"ok, we do knowledge sharing sessions on the team. Suppose you were presenting and someone wanted know why you picked S3 vs any other AWS resource, how would you explain that choice?\"\n\n  \n\\----\n\n  \nI'm looking for opinions (with support) and experience. If all you know is what you read on a blog about s3 thats different than someone who has dealt with this nonsense for years. \n\nI'm not saying i wont hire you, but i will suggest we pay the other person more.",
                  "score": 32,
                  "created_utc": "2026-01-21 10:48:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0ts37n",
                  "author": "Altruistic_Stage3893",
                  "text": "I'd imagine is more testing whether you inderstand the onion-like structure of the network and how the shit comes down from gateway to lambda and queues for example",
                  "score": 8,
                  "created_utc": "2026-01-21 09:24:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0xqa68",
                  "author": "PromptAndHope",
                  "text": "for example :what is a difference between s3:// and s3a:// connector. What happen if you use s3 with Spark?",
                  "score": 1,
                  "created_utc": "2026-01-21 22:00:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1k85sq",
              "author": "Beginning_Win_36",
              "text": "Are certifications still worth it?\n\nShould I invest in courses that provides certificate??\n\nIf no then what is the solution?\n\nPlease guide, what should I do to land a job?",
              "score": 1,
              "created_utc": "2026-01-25 04:31:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1puz4j",
                  "author": "Fit_Highway5925",
                  "text": "Worth it if you want to supplement your already existing knowledge, experience, and to fill in the gaps but if you expect to land a job by having only certs? Nope. \n\nCourses don't provide certificates but passing certification exams do. I hope you're not mistaking certifications from certificates of completion from courses/trainings. They're not the same.\n\nThe entire thread already talks about landing a job. Get the skills you need, build projects, get an internship, etc. If you're hoping to land a DE job, getting experience in SWE or analytics will help then easing to transition to DE.",
                  "score": 3,
                  "created_utc": "2026-01-25 23:35:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1qweng",
                  "author": "thisfunnieguy",
                  "text": "if you see a bunch of job postings that want you to have a specific certification -- get it to get the job.\n\n  \nbut, ive worked at a number of tech companies over the last 5-7 years and maybe 1/5 or 1/10 had an AWS cert. Meanwhile we using AWS every day for our infra.\n\nI think the AWS cert is cool because it helps expand your world view on whats possible with AWS and think a bit more about different tools.\n\n  \nbut you should reflect on what exactly is preventing you from moving forward on interviews and if an AWS cert is blocking you.",
                  "score": 1,
                  "created_utc": "2026-01-26 02:42:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ufs1l",
          "author": "GennadiosX",
          "text": "I heard that usually DE chooses you, not the other way around. I started as a backend dev but my job focus slowly shifted to data engineering. While formally I'm still a backend SWE, in reality my job is 75% DE.",
          "score": 37,
          "created_utc": "2026-01-21 12:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wfx6f",
              "author": "Nck865",
              "text": "Wow that's interesting as I was thrown into the role. It literally chose me lol.",
              "score": 11,
              "created_utc": "2026-01-21 18:31:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0x2fb4",
              "author": "CometChaserStarGazer",
              "text": "I totally agree! I just randomly fell into DE",
              "score": 7,
              "created_utc": "2026-01-21 20:12:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0z18do",
              "author": "echanuda",
              "text": "Happened to me as well, LITERALLY. I applied to a local company for a software QA position (no degree but I‚Äôve been a lifelong programmer). I FINALLY got an interview after hundreds of applications. The interview went great, but I clearly didn‚Äôt have QA experience and was rejected. I got a call from them a month later and they offered me a DE role, despite me never touching any data library or even knowing what a dataframe was. Ended up loving it and got an offer somewhere else after a year :)",
              "score": 5,
              "created_utc": "2026-01-22 02:11:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0z5q4u",
              "author": "BitterFrostbite",
              "text": "Exactly the same for me",
              "score": 3,
              "created_utc": "2026-01-22 02:37:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0z9o5y",
              "author": "dark_dagger99",
              "text": "I was thrown into the role as well. I started in finance and then did a lot of DE work to improve our reporting and analytics and then grew to manager level",
              "score": 3,
              "created_utc": "2026-01-22 02:59:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o10rt0d",
              "author": "According_Layer6874",
              "text": "I'm a graduate data analyst and I just shipped my first end to end fully automated integration using AWS / Snowflake / Terraform and now becoming the product owner of our low code automation software",
              "score": 2,
              "created_utc": "2026-01-22 09:59:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0wmi7z",
              "author": "armoman92",
              "text": "what do you use as part of your stack? Java?",
              "score": 1,
              "created_utc": "2026-01-21 19:00:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0xz5fd",
                  "author": "GennadiosX",
                  "text": "C#",
                  "score": 5,
                  "created_utc": "2026-01-21 22:43:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1qy1nj",
              "author": "thisfunnieguy",
              "text": "this happens to a lot of engs.\n\nyou get hired at a job out of school and end up working on a front end app.. a few years later you go look for a job and you've got 3-5 years of React exp... so another front end job is the easiest path....",
              "score": 1,
              "created_utc": "2026-01-26 02:50:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tlmp1",
          "author": "SchemeSimilar4074",
          "text": "There are hybrid roles where you do both DA and DE work, for example, consulting. I went for a consulting role where I was hired for my DA skill but got put on many DE projects. Afterwards, I simply change my title to DE.¬†\n\n\nThis is probably easier in a mid-size city. In large cities, companies have dedicated analytics team so jobs are more specialised. In smaller cities (I'm in Brisbane in Australia for example), most data jobs are hybrid because companies have 1 data team who do everything. I was put on consulting projects where I do end to end whereas my friends who are in the same consulting firm but in Sydney, still do DA projects for very large firms and banks.¬†",
          "score": 25,
          "created_utc": "2026-01-21 08:21:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tm71e",
          "author": "randomName77777777",
          "text": "Started as a data analyst until an engineering position was open 3 years later. Was internal so the DE manager knew me and it worked out.",
          "score": 24,
          "created_utc": "2026-01-21 08:27:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15ud0f",
              "author": "molodyets",
              "text": "This is the path for most",
              "score": 1,
              "created_utc": "2026-01-23 02:02:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tmm1y",
          "author": "Schtick_",
          "text": "many people (myself included) view roles like DE as a specialisation. ie you have a good foundation in engineering and now you‚Äôre specialising in data. Universities try to short cut that engineering requirement by having a dedicated ‚Äûdomain XYZ‚Äù degree. Which is great but I don‚Äôt need a data engineer who doesn‚Äôt at least have a foundational knowledge and foundational experience in software engineering.",
          "score": 18,
          "created_utc": "2026-01-21 08:31:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tlzeq",
          "author": "Rus_s13",
          "text": "Got an internship, got lucky. Rare but it‚Äôs out there so don‚Äôt give up",
          "score": 10,
          "created_utc": "2026-01-21 08:25:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ux5zg",
          "author": "paxmlank",
          "text": "Worked as an analyst and did engineering stuff. Put that on my resume",
          "score": 8,
          "created_utc": "2026-01-21 14:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uewgj",
          "author": "Prior_Two_2818",
          "text": "it was 20 years ago. if you could read the oracle documentation and write pl/sql procedures and packages you where hired. no one cares for certifications. they are so consultants can make their hourly rates more expansive without knowing much more than before the did take the exam",
          "score": 4,
          "created_utc": "2026-01-21 12:35:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uvpjx",
          "author": "Alternative-Guava392",
          "text": "Started as an intern analytics engineer at a startup with 0 experience before. Continued full time in the team, moved on to more data platforms and architecture stuff.",
          "score": 6,
          "created_utc": "2026-01-21 14:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ts67d",
          "author": "Altruistic_Stage3893",
          "text": "I've started as data analyst, naturally moved into engineering like a year later cuz i put in the work. BI has this benefit",
          "score": 3,
          "created_utc": "2026-01-21 09:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xgi7q",
          "author": "ntdoyfanboy",
          "text": "By shoehorning in from Analytics Engineering or Software Developer.\n\nAssuming you'll be hired outright as DE without some experience is like asking to be made a Director or Senior VP in banking without any prior experience. Data Engineer is not a new-graduate position really",
          "score": 3,
          "created_utc": "2026-01-21 21:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zdfky",
              "author": "Icy_Clench",
              "text": "I don‚Äôt think it‚Äôs fundamentally different from software engineer which has entry-level roles.",
              "score": 4,
              "created_utc": "2026-01-22 03:21:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tmbf4",
          "author": "Pandapoopums",
          "text": "My path was basically Phone Tech Support (1 yr) > Web Developer (5 yrs) > Data Analyst/Reporting/DB Analyst (5 yrs) >  Data Engineer (7 yrs) most of my transitions were lateral moves at the same company/volunteering for projects that involved data engineering components. Never had a cert, so can't tell you whether they actually help or not, but I know when I hire, I don't care about certs, I care about how well you can solve the problems and talk about what you've done before intelligently. That's not to say they don't matter, there's HR screening that typically happens before a resume ever makes it to my inbox, and maybe it matters to that level of screen, but I personally don't care about them. If you're not getting interviews, take any job you can get to build \\*some\\* experience and use data to solve problems regardless of what the job is.",
          "score": 2,
          "created_utc": "2026-01-21 08:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uaz5z",
          "author": "robberviet",
          "text": "By intern from 2nd year in college.",
          "score": 2,
          "created_utc": "2026-01-21 12:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0upvgo",
          "author": "tinycockatoo",
          "text": "Had an internship in a research-like role and had personal projects. Got hired as a junior DE, which admittedly is not that common. I think what made they hire me was that I was able to talk about my projects from end to end, from data modeling to cloud deployment and dashboard integration",
          "score": 2,
          "created_utc": "2026-01-21 13:41:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0z2bye",
              "author": "echanuda",
              "text": "Same here. Honestly was surprised how much I remembered about it too since it was years ago, but I literally had a coherent answer to every question they asked.",
              "score": 1,
              "created_utc": "2026-01-22 02:18:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uq7nq",
          "author": "typodewww",
          "text": "I landed my role 2 months ago, graduated in May I did API integration projects and real time dashboards, I had two unpaid data analyst internships via capstone classes in college where I did mini ML pipelines and integrated an API data with a static data set",
          "score": 2,
          "created_utc": "2026-01-21 13:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ur50c",
              "author": "typodewww",
              "text": "Btw I didn‚Äôt even ‚Äúapply‚Äù to my role I applied as a market researcher got to third round VP saw my resume took a look at it cancelled my interview and encouraged me to apply to DE role been history ever since that‚Äôs why you diversify your skillset especially entry level",
              "score": 1,
              "created_utc": "2026-01-21 13:48:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uy9rj",
          "author": "midasweb",
          "text": "I did not really meet the requirements either. built a couple solid projects did some sql python work at my previous job and applied anyway. one company cared more about what i could do than the years.",
          "score": 2,
          "created_utc": "2026-01-21 14:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vctp0",
          "author": "The-CAPtainn",
          "text": "I got lucky, I got a contract role that was willing to have me shadow a data team, and then it transitioned to full time. I didn‚Äôt even know I was a data engineer at first because my role was called app development analyst, but then I realized a few months in that I was only doing data pipelines and spark and sql",
          "score": 2,
          "created_utc": "2026-01-21 15:37:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tvyww",
          "author": "pymlt",
          "text": "no certs, university -> data scientist -> analytics engineer -> data engineer\n\nbasicly easing into more technical roles - but that was a few years ago , market has changed since then",
          "score": 3,
          "created_utc": "2026-01-21 10:01:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ultep",
          "author": "dataflow_mapper",
          "text": "i mostly applied anyway and treated the requirements as wish lists. What helped more than certs was already doing DE type work under another title, like owning pipelines, fixing data quality issues, or modeling tables instead of just querying them. Being able to talk concretely about those problems mattered a lot in interviews. Smaller teams were way more flexible than big companies with rigid job ladders. It felt less like finding a perfect entry role and more like gradually stretching my scope until the title caught up.",
          "score": 1,
          "created_utc": "2026-01-21 13:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v2qm9",
          "author": "Fancy_Arugula5173",
          "text": "Accounting and finance at University -> graduate accounting role -> qualified accountant working as financial analyst -> systems accountant specialising in ERP and complicated excel models -> data engineer",
          "score": 1,
          "created_utc": "2026-01-21 14:49:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vd7vg",
              "author": "Only_Payment9976",
              "text": "Woah",
              "score": 1,
              "created_utc": "2026-01-21 15:39:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ve42o",
          "author": "nineteen_eightyfour",
          "text": "Made 32,000 for 6 months for experience",
          "score": 1,
          "created_utc": "2026-01-21 15:43:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vej12",
          "author": "Queen_Banana",
          "text": "Moved internally. I had about 7 years experience working in data as an analyst, 4 at that company. I worked really closely with the engineers and learned from them when I could. Then when a position opened up I applied and got it.",
          "score": 1,
          "created_utc": "2026-01-21 15:44:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vm1bw",
          "author": "priviakeys",
          "text": "I'm just now looking into changing career paths so this thread is really helpful! Just looking at the courses I have to take and hopefully by the end of it, land an entry level analyst job and move from there",
          "score": 1,
          "created_utc": "2026-01-21 16:18:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11k6zv",
              "author": "Snoo-14088",
              "text": "We should keep in touch working entry data jobs too",
              "score": 1,
              "created_utc": "2026-01-22 13:29:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w0fw5",
          "author": "Parking_Anteater943",
          "text": "I got an internship and worked my ass off doing 60 hour weeks and not clocking hours to make them want to hire me straight from school",
          "score": 1,
          "created_utc": "2026-01-21 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w59c0",
          "author": "num2005",
          "text": "you apply anyway, realize they dont have a candidate with 2 to 3y expetience whonapplied, get the job",
          "score": 1,
          "created_utc": "2026-01-21 17:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wclrs",
          "author": "Egao4",
          "text": "I got pretty lucky. I got a 2026 new grad data engineering rotational program job. New grad DE jobs are rare but do exist.  But I had two previous internships, one as a data analyst and another as a data analyst/SWE. I say I got lucky bc I don‚Äôt have any data engineering projects or experience + no other company has reached back to me.",
          "score": 1,
          "created_utc": "2026-01-21 18:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wflvr",
          "author": "Nck865",
          "text": "I'm a consultant and they kinda threw me into the role as the client started this 3 year tenure debacle. I had no clue what I was doing. Fast forward a year and I'm now the tech lead on the same project. I also have a half of a clue what I am doing.\n\nOn another note I'm making $75,800 salary atm and feel super underpaid.",
          "score": 1,
          "created_utc": "2026-01-21 18:29:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wgbal",
          "author": "m1nkeh",
          "text": "Consulting. Anyone with a pulse tbh ü§ó",
          "score": 1,
          "created_utc": "2026-01-21 18:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wzuf8",
          "author": "CorpusculantCortex",
          "text": "Convinced my boss to change my title because what I was doing 80% of my time was not data analysis in the slightest bit.",
          "score": 1,
          "created_utc": "2026-01-21 20:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0x3cjz",
          "author": "viniciusvbf",
          "text": "By working as a software engineer for a few years first",
          "score": 1,
          "created_utc": "2026-01-21 20:16:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ylwmw",
          "author": "Brus210",
          "text": "Got an internship at a consulting company specialized in Informatica (governance platform) and then they hired me as a data management consultant jr.\nAnd the last week I completed my first year in the company.üòä",
          "score": 1,
          "created_utc": "2026-01-22 00:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ysqgx",
          "author": "JBalloonist",
          "text": "I was a data analyst first but already doing DE.",
          "score": 1,
          "created_utc": "2026-01-22 01:23:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ywpk9",
          "author": "Siege089",
          "text": "By accident, joined a company and was transferred between projects before I even completed onboarding. Role ended up being for a data platform and I've not looked back. So glad I left full stack dev, JS is such a terrible language.",
          "score": 1,
          "created_utc": "2026-01-22 01:46:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11kuia",
              "author": "Snoo-14088",
              "text": "So what language do use now then , im guessing pyhton , I‚Äôm starting out just want to Learn more .",
              "score": 1,
              "created_utc": "2026-01-22 13:33:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o11vjge",
                  "author": "Siege089",
                  "text": "I'm at a scala place now. Can't go wrong with python though it's very popular for DE.",
                  "score": 2,
                  "created_utc": "2026-01-22 14:29:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0z6bp7",
          "author": "Balgur",
          "text": "Got hired as a data engineer. Didn‚Äôt apply for it. Had experience working on data heavy systems at Amazon.",
          "score": 1,
          "created_utc": "2026-01-22 02:40:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0zb81b",
          "author": "Icy_Clench",
          "text": "I was a full time data analyst for 4 months after interning (first job too). Realized the company had no clue what they were doing in DE and applied when the position opened.\n\nI applied and showed the company some pretty basic ingestion and transformation skills honestly and got hired. The people hiring were not data engineers but they liked that I was methodical and organized.\n\nLanding the internship I just did some EDA in Python and showed some distributions, stats, and a basic XGBoost model. That was well above what the team was operating at and they called me before I even made it home.",
          "score": 1,
          "created_utc": "2026-01-22 03:08:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1007fc",
          "author": "nightslikethese29",
          "text": "Started as an analyst and my boss gave me an end to end project. I loved the DE part of it and told her. She then made it her mission to get me the resources I needed to learn, made 90% of my work DE, and then helped me transition to a backend team with a title change. That took a little less than 2 years to get the title change but I was doing de work for a full year and a half before that.",
          "score": 1,
          "created_utc": "2026-01-22 05:53:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10dlrv",
          "author": "Business_External_36",
          "text": "With Fake experience",
          "score": 1,
          "created_utc": "2026-01-22 07:46:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10ve18",
              "author": "Careful_Ring2461",
              "text": "Can you tell more about this. I assume you already had a job before you got into DE.",
              "score": 1,
              "created_utc": "2026-01-22 10:32:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o11m2yc",
              "author": "Snoo-14088",
              "text": "Wait does that work ?",
              "score": 1,
              "created_utc": "2026-01-22 13:40:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o11magq",
                  "author": "Business_External_36",
                  "text": "Yes",
                  "score": 1,
                  "created_utc": "2026-01-22 13:41:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12k2v7",
          "author": "abrem5",
          "text": "Had an internship doing backend dev work in college, then focused on data classes my senior year and looked for data roles.\n\nGot a job working at an IT consulting/temp firm out of college as a data analyst. Got started with a 3 month contract at a client for an analyst position that ended up being more of an engineering position in reality. \n\nThat 3 month contract turned into a 6 month contract, which turned into a 12 month contract, which turned into a full time role at the client.",
          "score": 1,
          "created_utc": "2026-01-22 16:25:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13e6lt",
          "author": "forserial",
          "text": "Worked as a full stack software dev and then transitioned over.",
          "score": 1,
          "created_utc": "2026-01-22 18:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13p8yd",
          "author": "Space2461",
          "text": "Soulless corporate consulting job, where you get exploited and \"forced\" to work at least 12 hours/day in a country where 28k/year is considered a good salary",
          "score": 1,
          "created_utc": "2026-01-22 19:29:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14wpqr",
          "author": "PossibilityRegular21",
          "text": "4 years in Analytics. Realised all the data was shit quality. Asked to move to DE to help fix the problems. Still working on it - there's a bigger culture problem I can't fix.",
          "score": 1,
          "created_utc": "2026-01-22 23:01:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16773l",
          "author": "RslashJD",
          "text": "I recently landed a DE job, and I got my experience in an adjacent role. It‚Äôs pretty common to move from data analyst to engineer. However, I‚Äôd recommend looking for an analyst job that works closely with the engineering team. In my old job, I pretty much was the middle man between the data engineers and any department that had a data related use case. This gave me a ton of experience with gathering requirements, planning go live dates, determining frequency that tables needed to be loaded, etc. I also ‚Äúmapped‚Äù all fields to whatever table they were being added to. So I wrote a lot of SQL transformations and complicated Joins. This was insanely valuable experience. \n\n\nLooking for titles like: BI analyst, BI Engineer, Data Management Analyst. Also any mentions of mapping, data modeling, managing data warehouse logic, or supporting the data engineering team are usually a good sign you will get an opportunity to learn some valuable skills. \n\n\nExtra Tip: When you eventually get an interview, be likable! There are plenty of people in the world that have the skills to be a good DE. Separate yourself by being someone that the interviewer would enjoy working with. My team told me that the last round of my interview was between me and one other person, and they eventually chose me because we got along better. \n\n\n\nSorry for any typos, I don‚Äôt have the energy to get up and grab my glasses.",
          "score": 1,
          "created_utc": "2026-01-23 03:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16lcmp",
          "author": "Leading_Tradition471",
          "text": "Started as a intern at a consulting firm, then landed a Python project. Turns out that project was DE work with Databricks and Power Bi. I got lucky",
          "score": 1,
          "created_utc": "2026-01-23 04:38:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17mf75",
          "author": "taker223",
          "text": "I had Bs.D in 2003 in what 7 years later would become \"Data Engineering\". Worked in Database/Informational Systems development since 2001 so yeah... naturally :)",
          "score": 1,
          "created_utc": "2026-01-23 09:44:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1abrwd",
          "author": "FuzzyCraft68",
          "text": "1 year experience in Software Engineer, 1 internship doing CRM dashboard, finished my masters. Recruiters found me on LinkedIn after networking and posting about data engineering every 2 days for about a month",
          "score": 1,
          "created_utc": "2026-01-23 18:46:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bx15k",
          "author": "slayerzerg",
          "text": "They require 3 years but hire someone with 7+ years",
          "score": 1,
          "created_utc": "2026-01-23 23:20:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13jjrj",
          "author": "luckyswine",
          "text": "Here's how: be a software engineer first.  Data engineering is a specialization of software engineering.  I will hire an experienced software engineer and train them up as a data engineer long before I hire someone with less than 3 years of data engineering experience.",
          "score": 0,
          "created_utc": "2026-01-22 19:03:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhi4lr",
      "title": "Designing Data-Intensive Applications",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qhi4lr/designing_dataintensive_applications/",
      "author": "ninjaburg",
      "created_utc": "2026-01-19 21:58:12",
      "score": 64,
      "num_comments": 14,
      "upvote_ratio": 0.95,
      "text": "First off, shoutout to the guys on the Book Overflow podcast. They got me back into reading, mostly technical books, which has turned into a surprisingly useful hobby.\n\nLately I‚Äôve been making a more intentional effort to level up as a software engineer by reading and then trying to apply what I learn directly in my day-to-day work.\n\nThe next book on my list is Designing Data-Intensive Applications. I‚Äôve heard nothing but great things, but I know an updated edition is coming at some point.\n\nFor those who‚Äôve read it: would you recommend diving in now, or holding off and picking something else in the meantime?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qhi4lr/designing_dataintensive_applications/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0kqp4t",
          "author": "strugglingcomic",
          "text": "The first edition is great, but you're so close to the new edition that, I honestly would hold off for another 2 months I guess, and fill in with other resources for learning in the meantime. \n\nAssuming the purchase of a $30-50 book is not trivial to you. If it's trivial, then hell buy both and support the author twice.",
          "score": 18,
          "created_utc": "2026-01-20 00:15:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oe0fd",
              "author": "[deleted]",
              "text": "Imagine how cool and hip you would look, my having not one but TWO, yes, twoooo designing data intensive applications on your desk",
              "score": 2,
              "created_utc": "2026-01-20 15:05:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0uvfwt",
                  "author": "scarredMontana",
                  "text": "Stop, I'm getting a little too wet",
                  "score": 2,
                  "created_utc": "2026-01-21 14:11:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0lj45h",
              "author": "ninjaburg",
              "text": "Good point.",
              "score": 1,
              "created_utc": "2026-01-20 02:49:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kfl8r",
          "author": "WanderingGunslinger",
          "text": "It‚Äôs a great book, I still revisit sections from time to time.\n\nIf your goal is to understand data systems from a software engineering and architectural perspective, it‚Äôs one of the best reads out there.\n\nIt‚Äôs less about tools and more about how to think about data systems, so it‚Äôs valuable whether you read it now or later in your career.\n\nHighly recommend.",
          "score": 37,
          "created_utc": "2026-01-19 23:15:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ljdsf",
              "author": "ninjaburg",
              "text": "After another comment im leaning toward audio book now and buy the physical book when the new one arrives.",
              "score": 3,
              "created_utc": "2026-01-20 02:51:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0lu22j",
                  "author": "paulrpg",
                  "text": "The new one should be out next month, at least on oreilys website",
                  "score": 3,
                  "created_utc": "2026-01-20 03:51:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0pgwos",
                  "author": "speedisntfree",
                  "text": "I cannot imagine a book like this as an audio book. One of the best chapters is where he builds up DB from a text file with shell commands.",
                  "score": 3,
                  "created_utc": "2026-01-20 18:07:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kg1vq",
          "author": "dont_tagME",
          "text": "I‚Äôm reading it right now, the book discusses different aspects of making applications reliable, scalable, sustainable etc. A bit of history here and there and how things work, the problem they solve etc. \n\nIt is worth reading. If you have worked building apps, you will find that many concepts are familiar to you.",
          "score": 5,
          "created_utc": "2026-01-19 23:17:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ksvj4",
          "author": "big_chung3413",
          "text": "I think it‚Äôs fair if you want to wait for the new addition.  I think a ton is applicable in the first version regardless.  I read it really slowly, 8 months , but it really did open my eyes to a lot of patterns I work with or around. \nRead for most of 2025 for reference",
          "score": 4,
          "created_utc": "2026-01-20 00:26:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n5ul6",
          "author": "_OMGTheyKilledKenny_",
          "text": "It‚Äôs very dense subject matter and needs the accompanying visual representation to get a handle, especially for topics like LSTM, unless you are already familiar with the concepts being discussed.  I‚Äôd skip the audiobook and get a hard copy or digital version.",
          "score": 3,
          "created_utc": "2026-01-20 10:14:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nevhs",
              "author": "ninjaburg",
              "text": "That‚Äôs a good point, I‚Äôve ran into that issue with some previous books. \n\nI‚Äôm generally pretty familiar with the subject but I suppose not enough to think the book wouldn‚Äôt help me in day to day stuff. \n\nCurrently looking like I‚Äôm going to try audio book the buy the new edition when it comes out.",
              "score": 1,
              "created_utc": "2026-01-20 11:33:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1c62un",
          "author": "Financial-Book-3613",
          "text": "It was recommended to me during grad school by my professor, and it‚Äôs easily one of the finest books available. I‚Äôm not a DE (I‚Äôm an MLE), but I work with DEs daily and can see how practically useful it is once the concepts sink in, far more than just hammering theory. Hands down!",
          "score": 1,
          "created_utc": "2026-01-24 00:09:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qig8ea",
      "title": "Senior DE on on-prem + SQL only ‚Äî how bad is that?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qig8ea/senior_de_on_onprem_sql_only_how_bad_is_that/",
      "author": "Educational_Ad4133",
      "created_utc": "2026-01-20 22:47:07",
      "score": 62,
      "num_comments": 32,
      "upvote_ratio": 0.97,
      "text": "Hey all,\n\nI‚Äôm a senior data engineer but at my company we don‚Äôt use cloud stuff or Python, basically everything is on-prem and SQL heavy. I do loads of APIs, file stuff, DB work, bulk inserts, merges, stored procedures, orchestration with drivers etc. So I‚Äôm not new to data engineering by any means, but whenever I look at other jobs they all want Python, AWS/GCP, Kafka, Airflow, and I start feeling like I‚Äôm way behind.\n\nAm I actually behind? Do I need to learn all this stuff before I can get a job that‚Äôs ‚Äúequivalent‚Äù? Or does having solid experience with ETL, pipelines, orchestration, DBs etc still count for a lot? Feels like I‚Äôve been doing the same kind of work but on the ‚Äúwrong‚Äù tech stack and now I‚Äôm worried.\n\nWould love to hear from anyone who‚Äôs made the jump or recruiters, like how much not having cloud/Python really matters.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qig8ea/senior_de_on_onprem_sql_only_how_bad_is_that/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0s37e7",
          "author": "IndependentTrouble62",
          "text": "I took a similar path as you. I was an on prem person for most of my career. I now support Azure and Databricks as well. The skills transfer really easily by and large. I would have more issue with you not knowing python.",
          "score": 42,
          "created_utc": "2026-01-21 01:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tuwvy",
              "author": "Educational_Ad4133",
              "text": "Thanks for the reply, it's nice to know people has done my route. It's not like I don't know Python at all. I have used Python and know the basics and familiar with the libraries. Issue is not actively using it at work as is not require. \n\nI am learning and studying all these but it's hard for me as whenever I learn about these feel like extra steps I don't need to achieve the same output.",
              "score": 1,
              "created_utc": "2026-01-21 09:51:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ykk95",
                  "author": "IndependentTrouble62",
                  "text": "I am a senior data engineer and honestly I use python now less than I used to. Main reasons is organization is delving heavily into Azure lakehouses and Similar structures in data bricks. We deal with lots of data, but our trnasformations are very simple so we can get by with low code tools like adf, ssis, etc, and pure sql. I would weight data modeling and SQL the most important skill.",
                  "score": 2,
                  "created_utc": "2026-01-22 00:37:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0vchd8",
                  "author": "Upstairs_Ad6877",
                  "text": "Same here. I know basic Python, used it for POC, but don‚Äôt have chance to use it in daily basic.",
                  "score": 1,
                  "created_utc": "2026-01-21 15:35:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0yj41d",
              "author": "IDoCodingStuffs",
              "text": "+1 on the ease of transition.\n\nKnowing Python can also mean different things. Like, are you writing entire libraries for deployed services, tooling for data scientists etc. or just pipeline scripts?",
              "score": 1,
              "created_utc": "2026-01-22 00:30:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yk6g1",
                  "author": "IndependentTrouble62",
                  "text": "For DE if you know the main libaries and can write basic servicable python is what I mean. If you can help with DS projects its nice to have, but not required. I would want a hire to have python and speak to libaries like pyspark, polars, pandas, pyodbc, SQLAlchemy, requests, etc.",
                  "score": 1,
                  "created_utc": "2026-01-22 00:35:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o14ko06",
              "author": "quickdraw6906",
              "text": "Yeah, I wouldn't stress it. Get a certification on AWS or your preferred cloud. I'm self taught after 25+ years of on prem dba and data app dev. It wasn't hard to pick up.",
              "score": 1,
              "created_utc": "2026-01-22 21:57:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0s8y49",
          "author": "GachaJay",
          "text": "Not gonna lie, I‚Äôm trying to hire someone like you right now. I have to hire in Pune, India, but, yeah, I value you.",
          "score": 19,
          "created_utc": "2026-01-21 02:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sdnnv",
              "author": "Great-Tart-5750",
              "text": "But given the choices you have,  you will most likely pick the one who has cloud as well as on prem experience, but not this guy.",
              "score": 4,
              "created_utc": "2026-01-21 02:54:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tmwfh",
                  "author": "Skullclownlol",
                  "text": "> But given the choices you have, you will most likely pick the one who has cloud as well as on prem experience, but not this guy.\n\nI've been the Tech Lead of the team for the past 3y and had to hire a few times, for a bank. Privacy sensitive, majority on-prem (for the data our team works with, the bank globally uses cloud ofc), python with SQL and dataframes. Majority cloud experience was seen as a (very slight) negative because those people often didn't know how to optimize single-node operations. In our context, \"just scale it up\" isn't an option.\n\nBoth the on-prem person and the cloud person would've been given an interview (because I respect people's experiences and adaptability and don't try to project what they can/can't do), but the \"majority on-prem\" person would've received priority (especially from our businesspeople). If a person has both on-prem and cloud experience equally, the \"majority on-prem\" person would receive 1st priority and 50/50 person would receive 2nd (\"majority cloud\" would be 3rd pick).\n\nThese priorities of course don't take into account how well the interview goes. A resume doesn't really say much imo.",
                  "score": 4,
                  "created_utc": "2026-01-21 08:34:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0rjg3l",
          "author": "Nekobul",
          "text": "Knowing the so-called cloud stuff or Python-based solutions is highly overrated. You can search and find plenty of people posting here who are unable to find job with these skills.",
          "score": 18,
          "created_utc": "2026-01-21 00:04:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tafcr",
              "author": "reallyserious",
              "text": "True. But lacking those skills will make it significantly more difficult to land an interview.¬†\n\n\nUnfortunately you have to play the CV buzzword bingo game to even be considered.",
              "score": 7,
              "created_utc": "2026-01-21 06:40:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ruvt7",
          "author": "swagfarts12",
          "text": "On prem and SQL only can be a good base, but I'd probably try to learn a cloud platform of some kind in your free time. They are basically infinitely scalable and have a lot of tools integration that is a lot less likely to be used for on prem data warehouses. Specific cloud implementation you use matters less, but having experience with a cloud platform at all is important in the sense that I would guess recruiters would choose someone with slightly less YoE who knows a cloud platform well over someone who has more YoE but none with any cloud warehouses.",
          "score": 3,
          "created_utc": "2026-01-21 01:07:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sdgk5",
          "author": "Great-Tart-5750",
          "text": "I am also kind of in the same boat as you. We use either on-prem or open source tech in our data infra and no cloud is involved. I also have knowledge of cloud personally, but not on production level. \n\nFrom the pov of switching, man cloud is a must. I am trying since the past few months and all I get in return is you don't have enough hands on with cloud so we can't take you. \n\nI am now thinking of getting a cert in AWS cloud for the same.",
          "score": 2,
          "created_utc": "2026-01-21 02:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s5mj0",
          "author": "HC-Klown",
          "text": "Knowing the concepts which probably you already know is way more important than knowing tools or cloud providers. Nowadays, with LLMs, given your knowledge on fundamental principles of data engineering you can get away with imementing and debugging most use cases in the cloud. \n\nSo, it might be worthwhile getting a certification and/or updating yoir portofolio with cloud project just for your resume. However, I wouldn't ne worried of being \"left behind\". Lean on your strong points during interviews and how you approached problems using fundamentals and treat cloud for what it is, a tool.",
          "score": 2,
          "created_utc": "2026-01-21 02:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0shmx5",
          "author": "Sizzlingbrowny",
          "text": "I don‚Äôt think all your experience will go vain you can use that to learn cloud platforms quickly but yes learning cloud will gives an edge",
          "score": 1,
          "created_utc": "2026-01-21 03:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sz6go",
          "author": "Easy_Cable6224",
          "text": "you have heavy sql experience, just deepen your skill in cloud as other said, then pretty sure you will be fine. Companies, especially big tech, they value experience more and more recently",
          "score": 1,
          "created_utc": "2026-01-21 05:11:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tvdqd",
              "author": "Educational_Ad4133",
              "text": "Thanks I am learning on my free time. This is what I was after tbh, I know I need to know all these just felt like all my experience are in vain or not. I have solved huge issues at my work with batching, query optimising and all. Feel like these skills are not something you just learn. But feel so behind when I see the jds of job at my level",
              "score": 1,
              "created_utc": "2026-01-21 09:55:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tj8zc",
          "author": "Little_Kitty",
          "text": "At least makes sure you know enough python to get through Leetcode interviews and have a couple of personal projects.  I don't use python much, largely because I find it an ugly language and it's too slow for a lot of what I need, but it has its place and works fine there (largely getting C / Scala to do things).\n\nThe problem with knowing only SQL is that you don't have coding experience and that matters because it's a different mindset to set based transformations.  Similarly you see issues with people who can code but don't understand SQL.\n\nTL;DR not good",
          "score": 1,
          "created_utc": "2026-01-21 07:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u921l",
          "author": "SoggyGrayDuck",
          "text": "Same boat and it's tough but I have 3-5 years of aws. I'm cranking out the AWS DE cert and then databricks if I'm still looking",
          "score": 1,
          "created_utc": "2026-01-21 11:53:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0util0",
          "author": "SQLDevDBA",
          "text": "Data & Analytics Director here and I‚Äôve worked on (and led) multiple teams over the years that are similar.  There are plenty of teams out there that value those skills either because they need them explicitly or because they transfer easily to cloud environments.  Python is pretty much a must at this point, but it will be useful in your on-prem environment.  A ‚Äúgood‚Äù substitute is PowerShell so if I see someone with PS experience that‚Äôs usually a good sign. Knowing APIs and how to interact with them is already putting you above many others I‚Äôve encountered.\n\nI‚Äôd suggest an AI prompt like: \n\n>>I‚Äôm a Data Engineer with X years of experience with Data Warehousing on Prem with [XYZ Technologies and platforms], what tech/knowledge should I know that I probably don‚Äôt?\n\nAnd go from there.\n\nThe Azure Career path for Data engineers is free and has lots of modules available as well:\n\n\nhttps://learn.microsoft.com/en-us/training/career-paths/",
          "score": 1,
          "created_utc": "2026-01-21 14:01:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v6opt",
          "author": "Fabulous-Chemical-21",
          "text": "People who are strong at ETL and SQL can easily tune to Cloud !! \nSQL isn‚Äôt just a query language.\nIt‚Äôs a mindset.\nIt‚Äôs how data engineers think.",
          "score": 1,
          "created_utc": "2026-01-21 15:08:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wjihk",
          "author": "billysacco",
          "text": "This is valid experience, many places can and should just stick with local SQL databases for their analysis. I won‚Äôt lie the cloud thing is getting very popular even for smaller companies that don‚Äôt need it. A ‚Äúkeeping up with jones‚Äù mindset I imagine. One thing I will say try learning python as soon as you can. Use it to automate functions or ETLs at your job. I did that and learned fast. At some point your company might dip its toe into the cloud and Python experience is really good to have.",
          "score": 1,
          "created_utc": "2026-01-21 18:47:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xkctv",
          "author": "SeaYouLaterAllig8tor",
          "text": "I'm kinda in the same boat but not in the cloud dept. I went from SQL server (and related apps) to Snowflake about 6-7 years ago. I've now got experience with multiple cloud based apps but I'm basically a SQL guru. My python skills are rudimentary. I've written a bit of python here and there for applications like streamlit but nothing significant and I wouldn't trust myself to write a data pipeline solely in Python. I basically Google and hack my way through functional or OOP programming. All that said, I feel you and often feel like (as someone who's looked at as a Senior Engineer/Solution Architect) I'm somewhat behind compared to many.",
          "score": 1,
          "created_utc": "2026-01-21 21:33:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xo9cr",
          "author": "StarSchemer",
          "text": "Enable SQL Server Machine Learning Services. \n\nThis will allow you execute Python (and R) scripts from SQL Server.\n\nWe mainly use it for much-improved CSV ingestion over the native SQL Server options.\n\nThis approach will allow you to build production Python solutions while also bringing big benefits to your existing platform.",
          "score": 1,
          "created_utc": "2026-01-21 21:51:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ldp5s",
          "author": "Jazzlike_Drawing_139",
          "text": "I‚Äôm in a very similar situation and was concerned that other jobs at a similar level or higher all specify skills or tools that I don‚Äôt have experience with.\n\nI just posted a thread asking for pointers about  where best to focus on developing my skills and getting some helpful, and somewhat reassuring, responses that may be of interest to you too: https://www.reddit.com/r/dataengineering/s/xOL3PN7d0f",
          "score": 1,
          "created_utc": "2026-01-25 09:56:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sqrqg",
          "author": "minato3421",
          "text": "You know sql. You just need to extend the same to cloud. I don't think it's that hard to get hired",
          "score": 0,
          "created_utc": "2026-01-21 04:14:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0trsaa",
          "author": "xmBQWugdxjaA",
          "text": "You need to learn to program.\n\nCloud management is optional and a deep rabbit hole in itself, but programming is essential.",
          "score": -1,
          "created_utc": "2026-01-21 09:21:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qklwjw",
      "title": "DataFrame or SparkSQL ? What do interviewers prefer ?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qklwjw/dataframe_or_sparksql_what_do_interviewers_prefer/",
      "author": "SnooCakes7436",
      "created_utc": "2026-01-23 08:59:41",
      "score": 60,
      "num_comments": 31,
      "upvote_ratio": 0.95,
      "text": "I am learning spark. And i just needed clarity on what does interviewers prefer in interviews ? Irrespective of what is used in the companies while actual work. \n\nDataFrame or SparkSQL ?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qklwjw/dataframe_or_sparksql_what_do_interviewers_prefer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o17ho4y",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-23 08:59:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17lieh",
          "author": "eccentric2488",
          "text": "Driver, executors\nLazy evaluation \nTransformations, Actions\nStages\nNarrow and wide transformations\nShuffles\nDAG, data skew, partitioning\n\nThese are the topics that matter for Spark in interviews.",
          "score": 96,
          "created_utc": "2026-01-23 09:36:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o181jxi",
              "author": "Mean_Elderberry7914",
              "text": "Add salting and bucketing if you truly want this job.",
              "score": 14,
              "created_utc": "2026-01-23 11:53:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o188iy0",
                  "author": "azirale",
                  "text": "If you're going to talk about salting you'd better be able to walk me through the tradeoffs and limitations because I've seen too many people handwave it as some magic solution to skew. Some of the \"explanations\" I've had for it have completely missed the mark on how it actually works and presented broken solutions.",
                  "score": 12,
                  "created_utc": "2026-01-23 12:42:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cn7yk",
                  "author": "Expensive_Culture_46",
                  "text": "Why does everything in data fields just sound like some is having a stroke and screaming random words. \n\n‚ÄúFam parm chess the potato then hammer to toadstool‚Äù\n\n‚ÄúSir are you ok? Do I need to call a doctor‚Äù\n\n‚ÄúOh no. I‚Äôm just a data professional‚Äù",
                  "score": 10,
                  "created_utc": "2026-01-24 01:45:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17ijsz",
          "author": "merrpip77",
          "text": "For me, it doesn‚Äôt really matter. I was on the interviewing side a couple of times. While personally, I usually prefer sparksql for structured data, if the candidate is capable of solving issues either way that‚Äôs what matters most. Probably it depends on the company‚Äôs standards later on, but not at the interviewing stage",
          "score": 16,
          "created_utc": "2026-01-23 09:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17jf59",
          "author": "Dawido090",
          "text": "More dataframe but both are valid, if you can't do one but can another then doesn't matter",
          "score": 6,
          "created_utc": "2026-01-23 09:16:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18abmh",
          "author": "dataflow_mapper",
          "text": "Most interviewers care less about which one you type and more about whether you understand what Spark is doing under the hood. Being comfortable with the DataFrame API is usually expected since it is more flexible and composable, but you should also be able to read and reason about SparkSQL because a lot of real pipelines mix both. A good answer in interviews is often explaining how the two map to the same execution engine and when you would prefer one for readability or maintainability. If you can show that you understand query planning, shuffles, and performance tradeoffs, the syntax choice becomes secondary.",
          "score": 2,
          "created_utc": "2026-01-23 12:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17oc4j",
          "author": "Capt_korg",
          "text": "I guess it is important to highlight when to use what. \n\nI mean between dataframes and SQL are architectural differences and both shine in different usages.\n\nWhile dataframes shine in their programmatic way, with chaining, validating, etc.\n\nSQL shines in their parsing nature, with i.e. window functions, complex joins, CTEs...\n\nIt is important to stick mainly with one API and not mix too much!",
          "score": 3,
          "created_utc": "2026-01-23 10:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17u9kl",
              "author": "Altruistic_Stage3893",
              "text": "I usually tell my juniors to use dataframe for simpler stuff, ctes for complex shenanigans as they are inherently more readable. but ultimately it doesn't matter as you an make mess with each",
              "score": 2,
              "created_utc": "2026-01-23 10:54:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18raum",
                  "author": "Capt_korg",
                  "text": "True, it doesn't matter, how to get there...",
                  "score": 0,
                  "created_utc": "2026-01-23 14:26:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18r7jo",
          "author": "eccentric2488",
          "text": "Add catalyst optimizer and tungsten execution engine to it. After writing transformation logic and before calling actions like show or count, use df.explain(true). Practice reading logical and physical plans for your transform logic. It helps in interviews.",
          "score": 2,
          "created_utc": "2026-01-23 14:26:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19qo0d",
          "author": "xmBQWugdxjaA",
          "text": "It doesn't matter, but you should be able to use both.",
          "score": 2,
          "created_utc": "2026-01-23 17:11:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1861c2",
          "author": "ThroughTheWire",
          "text": "depends on the company and the interviewer. I got dinged negatively during an interview with a larger tech company that had people who ONLY worked with dataframe transforms even though sparksql evaluates pretty much the same in an interview context because they rarely worked with sql. you have to read the room/interviewer unfortunately.\n\npersonally I'd be cool with either but try to understand what the interviewers preference is, if any",
          "score": 1,
          "created_utc": "2026-01-23 12:25:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o187gal",
          "author": "Unlucky_Data4569",
          "text": "Sql is better to learn because it translates more to writing sql for actual dbs from a interview prep efficiency standpoint. The interviewer probably won‚Äôt care",
          "score": 1,
          "created_utc": "2026-01-23 12:35:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18xe6d",
          "author": "Resquid",
          "text": "Depends",
          "score": 1,
          "created_utc": "2026-01-23 14:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18swtc",
          "author": "dukeofgonzo",
          "text": "I only give input to hiring, not actually make any hiring decisions at my job. I would prefer a candidate that is stronger with dataframes than SparkSQL. My coworkers who are stronger with SQL are not as adept programmers as they are SQL analysts. The coworkers I have who prefer using dataframes are much more comfortable with programming concepts than the SQL faction. They behave more like engineers than database administrators. That's my anecdotal dataset.",
          "score": 0,
          "created_utc": "2026-01-23 14:34:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1a455i",
              "author": "SnooCakes7436",
              "text": "And why do you think that is ?",
              "score": 0,
              "created_utc": "2026-01-23 18:12:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1cks3v",
                  "author": "iamnotapundit",
                  "text": "We discussed this on my team this morning (within the context of Cursor and where type systems and inspection midway really can help). \n\nBasically, the DataFrame API is python through and through. They means refactoring it into functions and parameterizing portions of a pipeline fit naturally. Doing the same completely in SparkSQL requires string formatting and permutations, which is just more fragile. \n\nWe landed at any reusable code should be DataFrames and not string formatting a block of sql. Top level stuff can be SparkSQL.",
                  "score": 2,
                  "created_utc": "2026-01-24 01:31:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1gdcue",
                  "author": "dukeofgonzo",
                  "text": "What kind of practice was done in their past. The SQL vs Dataframe preference in new hires is not about how the actual Spark transformations happen. It's about how they behave with all the other stuff we use besides making Spark queries. Stuff like GIT, YMLs, APIs, etc. I think the dataframe types likely were pushing out software, getting used to those tools I mentioned. The SQL types were likely former analysts that only learned Spark or Pandas, but not how to release software on a regular basis.",
                  "score": 0,
                  "created_utc": "2026-01-24 17:00:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17iads",
          "author": "cmcclu5",
          "text": "For data engineering technical interviews, I‚Äôm generally asked less about the high level libraries like that and more about my general understanding of Python like iterating over dictionaries versus sets versus lists, or how recursion can be optimized. Lower level understanding (Python isn‚Äôt a low level language) is WAY more important than knowing library syntax. If you understand why iterating over a list is significantly worse than iterating over a set, you‚Äôre halfway there.",
          "score": -7,
          "created_utc": "2026-01-23 09:05:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17j8hs",
              "author": "MlecznyHotS",
              "text": "Ok, I feel like an idiot asking having been programming in Python for almost 8 years now, but why is iterating over a list worse than iterating over a set?",
              "score": 7,
              "created_utc": "2026-01-23 09:14:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o17jsqs",
                  "author": "cmcclu5",
                  "text": "A set is hashed, a list is not. That‚Äôs the simplest explanation. Run a timing test with cprofile to see the difference.",
                  "score": -8,
                  "created_utc": "2026-01-23 09:19:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o189kil",
              "author": "azirale",
              "text": "> If you understand why iterating over a list is significantly worse than iterating over a set, you‚Äôre halfway there.\n\nThis sounds entirely absurd, you're going to have to back this up with something.\n\nAs mentioned elsewhere a list is essentially an array in the background with contiguous blocks of memory. It is the simplest and fastest structure for iterating through provided values.\n\nThe hashing of a set is irrelevant to iterating over all the values. The hash allows for bucketing so that with the hash you can jump to sublists that are much smaller, allowing for faster operations that check for presence of a value, but that's not relevant to iterating over all values.\n\nIs there some deep lore in cpython this relates to? Or did you simply misspeak here?",
              "score": 1,
              "created_utc": "2026-01-23 12:48:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17le6d",
          "author": "liprais",
          "text": "they are more or less the same thing.Asking of this implies lack of knowledge.",
          "score": -7,
          "created_utc": "2026-01-23 09:35:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17mrik",
              "author": "SnooCakes7436",
              "text": "I know they are same but the syntaxes are different. And from the person i am learning from says interviewers will ask you to solve problems using DataFrame only and will ask you to not use SparkSQL\nThat is why i just wanted to confirm of that is true.",
              "score": 1,
              "created_utc": "2026-01-23 09:47:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o17pneg",
                  "author": "liprais",
                  "text": "he is nuts and i suggest distance from him",
                  "score": 2,
                  "created_utc": "2026-01-23 10:14:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qmlfg6",
      "title": "How did you guys get data modeling experience?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qmlfg6/how_did_you_guys_get_data_modeling_experience/",
      "author": "0sergio-hash",
      "created_utc": "2026-01-25 15:04:24",
      "score": 60,
      "num_comments": 54,
      "upvote_ratio": 0.98,
      "text": "Hey y'all! So as the title suggests, I'm kind of curious how everyone managed to get proper hands on experience with data modeling \n\nFrom my own experience and from some of the discussion threads, it seems like the common denominator and a lot of companies is ship first, model later \n\nI'm curious if any of you guys stuck around long enough for the model later part to come around, or how you managed to get some mentorship or at least hands-on projects early in your career where you got to sit down and actually design a data model and implement it \n\nI've read Kimball and plan to read more, and try to do as much as I can to sort of model things where I'm at, but with everything always being urgent you have to compromise. So I'm curious how it went for everyone throughout their careers",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qmlfg6/how_did_you_guys_get_data_modeling_experience/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1mo384",
          "author": "DungKhuc",
          "text": "\\> From my own experience and from some of the discussion threads, it seems like the common denominator and a lot of companies is ship first, model later\n\nI believe this will change soon. Modeling will make you ship faster with AI-assisted coding. It's also important for certain hyped features such as text-to-SQL. Unless the LLM bubbles burst (meaning it would be prohibitively expensive to use), LLMs will be come one of the main data (model) consumers.\n\nAs for your question: do proper data models and then code with Cursor or Claude Code. It will be much faster than you hand writing transformation code.",
          "score": 28,
          "created_utc": "2026-01-25 15:14:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1mzm5w",
              "author": "BobDogGo",
              "text": "I just opened Claude Code and was very impressed but I don‚Äôt know how easy it would be if I didn‚Äôt already have years of experience with data modeling.  it offered options for solutions where if I did not know what I was doing could have led me to wrong solutions.  still, i think I‚Äôm going to try working with it this week on my current projects",
              "score": 10,
              "created_utc": "2026-01-25 16:07:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1n3meo",
                  "author": "DungKhuc",
                  "text": "I recommend using ChatGPT to suggest different approaches, then model the data manually by yourself. Throw your model at chatgpt again so it can criticize / suggest changes.\n\nOnce the data is modeled, throw the final model to Claude Code / Cursor. It should be able to implement the whole thing with relatively high accuracy.\n\nTry to use the implemented model. If you are not happy, try a different approach and repeat.\n\nThis feedback loop used to be weeks, now we are talking about few hours.",
                  "score": 1,
                  "created_utc": "2026-01-25 16:24:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ofv1z",
              "author": "Skualys",
              "text": "I'm still having trouble to understand how it will help in modeling. I mean, analysis of the data is 80% of the work, not writing the SQL which is pretty easy (and kind of natural language). How Claude would know that the wine grape variety list is given by the parameter DFHRA2 = 'K8' on the NGRTBG table of my legacy ERP, not talking about the fact the field was used with a different meaning for non-wine products (very bad practice but legacy means legacy, means no written doc...) ? I think it takes me more time to write the explanation than simply write SQL for dbt, using the macro I developed. \n\n\nI use LLM to develop tooling around DBT, but still not for SQL nor modeling. But I would be interested to see some concrete case if there is a video.\n\nStill I totally agree on your point, LLM need clearly defined models and strict semantic layers.",
              "score": 3,
              "created_utc": "2026-01-25 19:49:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1oj6cc",
                  "author": "DungKhuc",
                  "text": "It doesn't usually help directly modeling. I still model the data manually. I use LLMs to:  \n  \n\\- Check if I'm missing anything with my created models, either at the normalized layer, canonical aggregation / state, or later on consumption layer.  \n  \n\\- Write SQL based on created models\n\nWhat you mention is the classic data mapping activity. LLMs can't help with without context. It might be helpful somewhat with standard SAP fields.",
                  "score": 3,
                  "created_utc": "2026-01-25 20:04:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1my2fo",
          "author": "PrestigiousAnt3766",
          "text": "Work.¬†\n\n\nEtl was wat we still did in the early 2010s.\n\n\nElt is far superior in my mind though. Allows for reuse of data a lot more.",
          "score": 13,
          "created_utc": "2026-01-25 16:00:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ogfms",
              "author": "Embarrassed-Swim-710",
              "text": "I am new to DE, is ETL with coding using python, pyspark same as ETL Tools like informatics",
              "score": 5,
              "created_utc": "2026-01-25 19:51:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1os04o",
                  "author": "PrestigiousAnt3766",
                  "text": "I have no idea.\n\n\nFor me the difference is extracting data from source systems and storing in as unchanged format as possible and model as late as you can. Extract, load and transform.\n\n\nModeling decisions change the data in unclear ways.¬†\n\n\nYou used to query apply schema and transforms before loading the data into the database. Because you wanted to save on storage.",
                  "score": 3,
                  "created_utc": "2026-01-25 20:42:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1muaa4",
          "author": "BobDogGo",
          "text": "I was very lucky to learn it while working for a not-for-profit.  low stakes, lots of bright people in a collaborative environment.  Kimball is a great tool for stars.  There‚Äôs some good open source ER modeling software out there.  Get it and play with it.",
          "score": 7,
          "created_utc": "2026-01-25 15:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1n8uhk",
              "author": "0sergio-hash",
              "text": "I would love to also get some on the job experience that sounds like the exact experience I was hoping to have on my current team \n\nI could always do it on my personal time but I'm just annoyed that I'd have to",
              "score": 3,
              "created_utc": "2026-01-25 16:46:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ocg0j",
          "author": "m1nkeh",
          "text": "forged in the fires of production",
          "score": 6,
          "created_utc": "2026-01-25 19:34:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1riqpz",
              "author": "halfrightface",
              "text": "testing is for the weak",
              "score": 1,
              "created_utc": "2026-01-26 04:53:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1muw9w",
          "author": "idodatamodels",
          "text": "I got mine by joining a data modeling team. Those teams are getting harder to find these days as companies are disbanding these groups as irrelevant in today's cloud based architectures. An interesting recent development is the push from senior executives for more data modeling work rather than less. I might actually make it a couple more years before being put out to pasture.",
          "score": 4,
          "created_utc": "2026-01-25 15:46:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1n8ijr",
              "author": "0sergio-hash",
              "text": "That makes sense. Sucks how specialized all the positions have gotten. It's like every time I want a new type of experience I have to join a specialized team ü§£",
              "score": 2,
              "created_utc": "2026-01-25 16:45:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1njyhu",
          "author": "SuperTangelo1898",
          "text": "I worked at a startup where their data was a complete disaster. They let me procure dbt cloud with 2 seats ($200/month) and I was able to build a new data warehouse from scratch, which was mostly medallion style.\n\nI currently work for a much larger company, where a lot of it is a combination between medallion and OBT. I studied Kimball and Inmon for my master's program but that was more necessary before cloud computing and storage. Some of the work I do includes optimization to reduce compute and storage.\n\nThe data warehouse I work with contains 3k+ models, which over 40+ users contribute to. It's open development but my team has to enforce quality control for the MRs.",
          "score": 3,
          "created_utc": "2026-01-25 17:34:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o2uph",
              "author": "PowerbandSpaceCannon",
              "text": "How do you enforce quality control?",
              "score": 2,
              "created_utc": "2026-01-25 18:52:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1pg6io",
                  "author": "SuperTangelo1898",
                  "text": "When I first joined it was a cluster****. We've established gitlab CI quality checks that reject MRs or flag warnings for either missing metadata or poor quality modeling, e.g. selecting from the same model ref more than 2x (self join situations pass). \n\nOne person submitted a \"model\" with 13 ctes, all with different where clauses, selecting from the same upstream model, then unioned in the final select",
                  "score": 1,
                  "created_utc": "2026-01-25 22:28:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ogs60",
              "author": "Embarrassed-Swim-710",
              "text": "What is meant by OBT?",
              "score": 1,
              "created_utc": "2026-01-25 19:53:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1osodn",
                  "author": "gavclark_uk",
                  "text": "One Big Table - all attributes are in a single record. Can can be useful in some use cases. Many BI tools use OBT.",
                  "score": 3,
                  "created_utc": "2026-01-25 20:45:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1pfpaq",
                  "author": "SuperTangelo1898",
                  "text": "\"one big table\", very wide tables that are mostly dimension but combine some basic fact data, mostly finite aggregates",
                  "score": 1,
                  "created_utc": "2026-01-25 22:26:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1mu403",
          "author": "SoggyGrayDuck",
          "text": "I was lucky enough to build a star schema from scratch as a JR, although now I need to update my thinking to work with the new medallion architecture. Although I personally think it's going to blow up on most companies who use it as an agile cattle prod for the devs. Forces people to do things outside of best practice. I've yet to use this skill outside of that JR role. Agile wins everytime",
          "score": 4,
          "created_utc": "2026-01-25 15:42:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ohiv4",
              "author": "freemath",
              "text": "Medaillon architecture has been the standard for decades, just not under that name, and usually also includes star schemas",
              "score": 2,
              "created_utc": "2026-01-25 19:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p5ido",
                  "author": "SoggyGrayDuck",
                  "text": "Yeah I'm slowly learning it's not much more than a new naming standard but with the approval to break best practices in order to promote \"agile\" development. I now understand why I hate it so much! I liked data because it was organized, consistent and the one source of truth. I simply don't see how this \"new architecture\" isn't going to blow up on 90% of the teams implementing it. We brought spaghetti coding to the backend! That's what made the front end spaghetti work! \n\nWe had a consulting firm come in to implement it and it's amazing how they refuse to answer basic questions about how typical problems are solved in this environment. But to mention the fact even unit testing during development has gone out the window where I'm at.",
                  "score": 1,
                  "created_utc": "2026-01-25 21:41:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1nl9gr",
          "author": "Typicalusrname",
          "text": "In a high volume environment access patterns define the model",
          "score": 2,
          "created_utc": "2026-01-25 17:40:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nr6od",
          "author": "tophmcmasterson",
          "text": "I started in a non DE role, but had to help out with different kinds of analysis on an ad-hoc basis. \n\nI hate repeating work, so I would try to find ways to automate reports I did. First in Excel, then PBI, then SQL. \n\nI know engineers that have been working longer than me that don‚Äôt have a clue about data modeling, because they always just try to brute force whatever‚Äôs needed to get to a flat table. \n\nIn terms of getting experience, find an actual project you want to work on. Make a Pok√©dex or work with data from sports or games you like, it doesn‚Äôt matter. \n\nImportant thing is that you try to apply those concepts to an actual problem you want to solve, and more importantly, actually follow the guidance documentation that‚Äôs out there. \n\nOne of the big steps people miss is the conceptual modeling stage, whether that‚Äôs an enterprise bus matrix/business event matrix, etc. If you don‚Äôt define what you‚Äôre trying to do and how you expect everything to tie together conceptually first, then it‚Äôs unlikely you‚Äôll have thought through everything you should be.",
          "score": 2,
          "created_utc": "2026-01-25 18:04:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nw5g3",
              "author": "KaleidoscopeBusy4097",
              "text": "I learnt dimensional modelling as an analyst, wrangling data for Qlik and Tableau. You learn that star schemas work, and work well, very possibly because the data vis tools have been designed to work with star schemas. Power BI has been mentioned, and the data model for Power BI is indeed excellent and very powerful when you can figure it out, especially for the application of conformed dimensions.\n\nAs an analyst you also learn what kind of analysis you can do with the different fact table types, and when to use certain types.\n\nI agree with the engineers not knowing what they're doing in terms of modelling, and it's because they've never used the data. Also need to remember that a fact represents a single process, so a model can't do everything - if you need two models, have two models (plenty of analysts don't know this).",
              "score": 1,
              "created_utc": "2026-01-25 18:25:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1nz2ko",
                  "author": "tophmcmasterson",
                  "text": "Yeah, it‚Äôs honestly kind of maddening sometimes how little many engineers have had to actually use the data they create. \n\nThere‚Äôs this myth I think that approaches like dimensional modeling were only popular because of performance reasons and so is not applicable today, when in reality it‚Äôs so much more about scalability in development time, easy of use, flexibility in reporting etc. Especially with tools like Power BI, if you‚Äôre not using a dimensional model you‚Äôre basically neutering the tool and creating a more frustrating experience for report developers.",
                  "score": 1,
                  "created_utc": "2026-01-25 18:36:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1nvj4q",
          "author": "Blaze344",
          "text": "Learn how databases and relationships work, learn some of the theory behind database normalization, play around with some toy examples like the good old example about the library, books and loans, and that's it. Just keep on trying to model real world problems into a nice and efficient way, what's the mystery? Just figure out how some businesses relate their steps in the process to each other and go forth modelling it.",
          "score": 2,
          "created_utc": "2026-01-25 18:22:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o4e3d",
          "author": "Satanwearsflipflops",
          "text": "The data engineer was on mat leave, Kimball‚Äôs book and dbt, BAM!!!",
          "score": 2,
          "created_utc": "2026-01-25 18:58:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o8tvt",
          "author": "chrisgarzon19",
          "text": "Counter intuitive but if ur querying lots of databases (lets say leetcoding)\n\nAsking urself why certain table were set up that way is a good way to reverse engineer \n\nThe more u can get access to real life data models the easier (see if u can get access at work)",
          "score": 2,
          "created_utc": "2026-01-25 19:18:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1oz93g",
          "author": "madbammen",
          "text": "We are currently doing a whole re-design at our company. It is myself (mid-level) and a staff DE collaborating on it. It is long overdue as our data is pretty chaotic, and I am working on building buy-in and trust in our new effort with everyone at the company. I find it complex to work within the constraints of the existing ingestion setup (which I have no control over). So all in all, pretty good experience. First time I've done something like this for real and not just in an interview.\n\nThe business users report all kinds of complaints using the legacy setup (which is understandable. I started about a year ago and sympathize with their gripes). I am presenting to the entire company in a few weeks where we are, why we are doing it, etc. In fact, I could probably use some advice from senior people here on tips for framing this to business users. In my eyes, the value from a business user's POV is simplicity and intuitiveness of a Kimball-style setup, so my current plan is to focus on that.",
          "score": 2,
          "created_utc": "2026-01-25 21:14:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1p2iiq",
          "author": "CdnGuy",
          "text": "I learned from having analyst / BI roles where I had to spend a lot of time designing queries, and when I started getting the ability to design or change the underlying tables I did a lot of thinking about \"how can I make this easier to use and more reliable\", and started moving business logic from reports into the underlying tables wherever possible.\n\nI accidentally found myself doing kimball before ever hearing about it, let alone reading it.",
          "score": 2,
          "created_utc": "2026-01-25 21:28:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1p7u54",
          "author": "peterxsyd",
          "text": "If you are start starting out - I recommend sit on the business rather than IT side, where you can take the data that may not be super meaningful within a business context from the big platform, then build a data mart on top of it to help solve the problems of the department that you are working with. That way, you get great breadth of experience, can do a few bits and pieces and then you can migrate to a larger platform and sort of bring it all up in the wash. Even though you might struggle to access all of the data you need at times, this breadth will help a lot and most of all give you some freedom and space to figure it all out.",
          "score": 2,
          "created_utc": "2026-01-25 21:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1py8du",
          "author": "Uncle_Snake43",
          "text": "Well for me, I was an analytics developer before being a DE, and data models were a huge part of our development process. So I got a lot of hands on building data models many many times for different projects.",
          "score": 2,
          "created_utc": "2026-01-25 23:51:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1q62am",
          "author": "tbot888",
          "text": "just on a project at a company I worked for.\n\nModelling is important, but take semantic models defined for BI applications or AI models, they all define the relationships in a database so you can generate the correct SQL for the answer your seeking.  They add information about the data model and to make it simple they expect a dimensional data model.\n\nA dimensional data model on its own provides some information, although you still need to give context to the grains of the facts and the nature of the dimensions, and what the joins are.  ie usually gives the context of time and relation.\n\nif you use a slowly changing dimension the wrong way you won't get the right answer, if you pick the wrong fact your answers won't be correct either.\n\n  \nI find Kimball a bit frustrating at times and his consultancy made a lot of exceptions over the years to cover every situation.  But it is a well worn reliable approach and what works well with then building things like OLAP cubes/BI models or other semantic models.",
          "score": 2,
          "created_utc": "2026-01-26 00:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qeoz4",
          "author": "ppsaoda",
          "text": "FAFO. \n\n  \nJust kidding. I've jumped quite a lot of companies post-covid, saw good and bad practices. Thats how.",
          "score": 2,
          "created_utc": "2026-01-26 01:12:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qynj4",
          "author": "Ploasd",
          "text": "By doing lots of data modelling work",
          "score": 2,
          "created_utc": "2026-01-26 02:53:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o1zm0",
          "author": "circumburner",
          "text": "Most people go from an analyst role to a development role. Like dashboarding or reporting to building the tables and databases they require.",
          "score": 1,
          "created_utc": "2026-01-25 18:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o6h0n",
          "author": "GreyHairedDWGuy",
          "text": "I learned data modelling back in the early 90's with OLTP model design.  I read a couple of books on it by Date and Codd (from memory....so long ago).  I then took a 1 week course (can't recall details).  I then started modelling for an inventory solution we were building.  Years later I was thrown into designing data warehouse solutions (I was the defacto candidate since I was the lead Oracle, Dec RBD DBA and have the most experience with modelling and databases.   Read Kimballs book (and Inmons) but I gravitated toward Kimball dimensional.  Again, this was no back in the mid-late 90's and the internet was new so harder to obtain resources we have now.  I even met and had conversations a couple times with Kimball.  I was a nobody attending one of his seminars but he was gracious enough to talk with me and we corresponded a couple times later.  \n\nTimes today are very different and there is a rush to deliver (and skip modelling).  This sort of started with Hadoop and schema on read mentality.  However, modelling is starting to make a minor comeback (solely based on what I read on here and on linked-in).  Joe Reis has been part of the push for this (and others).",
          "score": 1,
          "created_utc": "2026-01-25 19:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1oklpq",
          "author": "Individual_North_529",
          "text": "To get data modelling experience work with tools like power bi, get familiar with star schema, surrogate keys, relationships, snowflaking, bridge tables, and so on. All this makes it easier when writing SQL transformations. You nedd to understand your end user in order to make good models.",
          "score": 1,
          "created_utc": "2026-01-25 20:10:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1oxtbr",
          "author": "Intelligent_Series_4",
          "text": "In the first 10 years of my career, I had many opportunities to learn and practice creating data models, starting with teaching myself how to create databases and reporting in MS Access, then was instructed how to support our product that relied on SQL Server and Excel. During that time, I learned about normalization and picked up a copy of Object-Oriented Data Warehouse Design, which shows how to create star/snowflake models.\n\nIn my next job, the SQL Server data warehouse replicated objects from the source environment, which relied on a hierarchical structure. This model has some interesting quirks which could require a lot of joins, which resulted in the creation of views to create an easier starting point as the base of the query, and in function was similar to OBT. There were also several instances where I created an operational data mart, just like Inmon's approach. I also worked on other projects, several of which required their own database models. One was a questionnaire, so I had to learn how to create a hybrid relational/object-oriented model to capture the various types of questions and responses.\n\nI guess I was fortunate enough to land in the right places at the right moment where I could build and grow the systems I was hired to support.",
          "score": 1,
          "created_utc": "2026-01-25 21:08:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1np5u7",
          "author": "Waldchiller",
          "text": "Power BI is the best teacher for Kimball style dimensional modelling.",
          "score": 0,
          "created_utc": "2026-01-25 17:56:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o6z2q",
              "author": "GreyHairedDWGuy",
              "text": "huh?  It consumes databases modelled as star schemas.  It will not teach you anything about how to design one.",
              "score": 3,
              "created_utc": "2026-01-25 19:09:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1otly3",
                  "author": "Intelligent_Series_4",
                  "text": "I think the point u/Waldchiller is making here is that to achieve optimal performance from Power BI, you're encouraged (i.e. forced) to learn Kimball in order to generate the star/snowflake models that it wants to consume.",
                  "score": 1,
                  "created_utc": "2026-01-25 20:49:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qi4bp2",
      "title": "Any Other Seniors Struggling in the Job Market Right Now?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qi4bp2/any_other_seniors_struggling_in_the_job_market/",
      "author": "shittyfuckdick",
      "created_utc": "2026-01-20 15:37:11",
      "score": 54,
      "num_comments": 34,
      "upvote_ratio": 0.95,
      "text": "Have 8 yoe. Work with Airflow, DBT, Snowflake, the works. US citizen. \n\n  \nIve been applying since October probably to well over 100 maybe 200 jobs. Theres maybe like 6 places I got to the final rounds for and they all rejected me. The most feedback I could get was they had another candidate who was better. Every technical assessment I did correctly. I was even told for one I was the fastest to ever complete it. \n\n  \nSo whats the deal? I cant figure out if this is a skill issue or personality issue. Its definitely been getting to me I thought i was a pretty good engineer.  ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qi4bp2/any_other_seniors_struggling_in_the_job_market/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0ootxr",
          "author": "codemega",
          "text": "Well Q4 is known to be a quiet period for hiring due to the holidays and budgets not being set until the new year.\n\nBut you've been posting for longer than that about either not getting interviews or getting rejected due to a supposed lack of streaming experience. You've previously brought up lying about past experience to get noticed.\n\nPerhaps there's something wrong with your resume or your interview skills or personality. The job market is tough too. Maybe a link to a resume would be a start for assistance.",
          "score": 54,
          "created_utc": "2026-01-20 15:57:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oql45",
              "author": "shittyfuckdick",
              "text": "Yes sir. I fixed up my resume and started getting more interviews. the previous thread people mentioned i needed streaming experience so i need to make a lateral move. I have been trying to do that. I even interviewed for a data analyst position which i wound up being rejected in the final rounds.¬†\n\nso yes I am posting because im desperate and tired.¬†",
              "score": 6,
              "created_utc": "2026-01-20 16:05:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0omfd0",
          "author": "MikeDoesEverything",
          "text": ">So whats the deal? I cant figure out if this is a skill issue or personality issue.¬†\n\nAs per yourself:\n\n>The most feedback I could get was they had another candidate who was better.\n\nIt's probably a bit of both, but it isn't personal (unless you are a self confessed massive piece of shit).  You can be technically strong and \"not a good fit\" for a massive list of reasons.  Usually, it's just vibes.\n\nMy background is in chemistry.  I used to make the active component of pharmaceuticals for a living.  I got rejected for a DE role at a pharma company looking for DEs with a background in the specific chemistry I did which I swear can't be very common.  Reasons? No idea.\n\n>Its definitely been getting to me I thought i was a pretty good engineer.\n\nLikewise, I thought I was a decent chemist.  I lost my last chemistry job during the pandemic and kept interviewing for places where all of my technical skills lined up.  I didn't struggle in the technicals and seemed to get on with everybody too.  Some places never called me back.  Other places rejected me at the last hurdle.  I even followed up with some of the team members who interviewed me and asked them wtf was up because it was extremely confusing.  The team members said if it was up to them, I'd have been in.  They weren't consulted so it must have been management.\n\nMy personal issue was that I hadn't enjoyed doing chemistry for quite a while before then.  I didn't want to do chemistry anymore, but, I have bills to pay.  I think no matter where I went and no matter how many technicals I would have cleared, every company I would have interviewed for would have said no.  They didn't have to know I had lost my passion for the field although I'm sure, subsconsciously or consciously, they knew something was off.\n\nI changed field to DE.  Best decision ever for me.  Not saying this is you, although this is potential food for thought.",
          "score": 23,
          "created_utc": "2026-01-20 15:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0osfly",
              "author": "shittyfuckdick",
              "text": "Thanks I can only speak introspectively but I am not a social person and am hard to get along with. I do my best to put on a performance during interviews and what little feedback ive gotten on that is positive. So no idea if that is an actual issue or overthinking.¬†",
              "score": 8,
              "created_utc": "2026-01-20 16:14:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0rnrmj",
                  "author": "Toastbuns",
                  "text": "Having been on the hiring side, I would absolutely answer a question of feedback more honestly if you found a way to DM on LinkedIn or something than I would if you asked me on the interview rejection email or via HR. \n\nSometimes it's just bullshit reasons like I got over-ruled by a more senior person or that a single person on the interview team got weird vides that no-one else caught. \n\nI've also been in situations where we had a great candidate for a job we listed but then the company realized they didn't want to hire that role anymore or that they were asking for the wrong role in general.\n\nHave also seen situations where we ended up hiring an internal candidate even though they were less competent.   \n\nOverall, I would say just keep at it, as discouraging as it can be.",
                  "score": 1,
                  "created_utc": "2026-01-21 00:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0p97xq",
              "author": "JJ3qnkpK",
              "text": "Hey! Fellow chemist data engineer!\n\nI went into a form of organizational sciences after chemistry before finally hopping to data engineering. I've found that the two together make me into a sort of business superhero: looking for the true meaning of data and the true business problems that need to be solved.\n\nMy advice to any struggling data engineer is to evaluate whether or not you are actually identifying and actually solving business problems. You can be the end-all be-all of Spark, Databricks, etc., and you can build perfectly to provided specifications, but ultimately end up worthless to the business by not actually solving problems.\n\nLearn to interrogate the data, the business constructs, find what people are actually needing and trying to achieve, speak to the stakeholders and understand them, their needs, hell their entire job if you can.\n\nExplain the benefits of modern infrastructure and methods in the context of the business problem and constructs. If you can't bring an engaged layperson to understanding what you put forth, then keep refining your thoughts and approach until you can.\n\nBuild your ability to present such that you can speak to managers and stakeholders. Build your technical understanding such that you can put forth directions on-the-fly and communicate why these directions will lead everyone towards the goal of solving the actual business problem.\n\nBringing this back to my first points: my background in the sciences has so greatly assisted me in all of the above. All too often, I meet technical people who are fantastic developers, but just build things off-kilter and struggle to gather requirements and internalize the business's needs and goals. It'd be like a plumber who doesn't understand what a pipe will be used for - is it the washer/dryer, sewage, a fire hydrant, or what? These developers do the equivalent of building a sewage pipe that emerges in the center of the bathroom floor - it's almost correct, but useless because nobody wants the toilet there.",
              "score": 4,
              "created_utc": "2026-01-20 17:32:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0po7rf",
                  "author": "curiosickly",
                  "text": "My God, there are at least 3 of us! (Chemists turned DE)",
                  "score": 3,
                  "created_utc": "2026-01-20 18:40:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qiliz",
              "author": "beyphy",
              "text": "> I got rejected for a DE role at a pharma company looking for DEs with a background in the specific chemistry I did which I swear can't be very common. Reasons? No idea.\n\nThis reminds me of a short-term contract job that I interviewed for recently.\n\nAlthough I'm not one anymore, I have a background as a data analyst. I worked 5+ years as a data analyst across two different industries.\n\nRecently, a recruiter contacted me about a position that's in one of the niche industries that I used to work in. There are only a handful of major companies in that industry, I've worked for a few of them, and have a combined three years of experience across those companies. The job was for some much smaller company in the same industry. And although the job was remote, the company happens to be in the same city that I'm located in. So we are on the same time zone. And I'd be open to going into the office if they wanted me to do that.\n\nI couldn't even get an interview. Like you, I have no idea why. I didn't get any feedback. And as far as I can tell, the recruiter ghosted me.",
              "score": 1,
              "created_utc": "2026-01-20 20:59:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0qkl72",
              "author": "TheFIREnanceGuy",
              "text": "What exactly did do to pivot, get the skills and get that first de job? I always love hearing about the story",
              "score": 1,
              "created_utc": "2026-01-20 21:08:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ot9eu",
          "author": "git0ffmylawnm8",
          "text": "I'm in a similar situation. I rarely get contacted back even when I meet the majority of the listed skills required. 9 YoE (2.5 years in FAANG), US citizen, hands on experience with the major tools like Databricks/Snowflake/Airflow/Python. I declined an offer for one job and I was passed for an internal candidate just because they needed someone with internal tooling experience",
          "score": 9,
          "created_utc": "2026-01-20 16:18:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ovxv3",
              "author": "shittyfuckdick",
              "text": "Damn if you cant get hired with FAANg experience im really screwed.¬†",
              "score": 3,
              "created_utc": "2026-01-20 16:30:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pieia",
                  "author": "Gh0sthy1",
                  "text": "Most of the small companies that I have worked prefer avoiding ex-FAANG.",
                  "score": 9,
                  "created_utc": "2026-01-20 18:14:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0q3omy",
                  "author": "Fender6969",
                  "text": "Not all companies are in a position to hire/retain FAANG engineers. And just because someone worked at one company it doesn‚Äôt necessarily mean they are the best fit for the role in another.",
                  "score": 2,
                  "created_utc": "2026-01-20 19:50:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ovhl5",
          "author": "goblueioe42",
          "text": "I found it harder to get a job this time around. Much harder. And yes final rounds are harder this time around.",
          "score": 6,
          "created_utc": "2026-01-20 16:28:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pc8lt",
          "author": "dukeofgonzo",
          "text": "If you are making it to 6 final round interviews, but going 0/6, then whatever is happening at that final round interview is whatever is stopping you from getting hired. Could there be something in common about those 6 final interviews? If it's about one other candidate having +1 to what they're looking for, then it means they just like that person more on 6 occasions. It's likely not about some minute technical skill difference.\n\nGetting 6 interviews is commendable, and proof that on paper you can get to that eliminating interview.",
          "score": 6,
          "created_utc": "2026-01-20 17:46:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0phjb9",
          "author": "ask_can",
          "text": "Since you are able to make it through the initial rounds...you probably are following short in one of the following:\n\n‚Ä¢ Experience with Snowflake isn‚Äôt coming through clearly  \n‚Ä¢ Experience with CI/CD pipelines for Snowflake deployments  \n‚Ä¢ How you explain orchestration of jobs and handle failures  \n‚Ä¢ Examples of performance tuning  \n‚Ä¢ Walk through of complex project or architecture with trade-offs.",
          "score": 5,
          "created_utc": "2026-01-20 18:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pvzuz",
          "author": "SoggyGrayDuck",
          "text": "Id update your LinkedIn, something seems off. The calls I get are all for senior/staff and in and in a better market I'd land one but I'm right on the edge. I really want one more position under a great staff engineer and then I know I'm really really to run. I just need someone to discuss how the current architecture and best practices have changed. I'm so frustrated with how little we even mention it where I'm at right now. Agile agile AGILE! \n\nSorry I got off topic. But anyway I have the opposite problem but unfortunately currently working on prem so I kept fucking up interviews. I feel like you're in a better spot than me and just need to tweak the profile a bit.",
          "score": 2,
          "created_utc": "2026-01-20 19:14:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q1lp6",
          "author": "sleeper_must_awaken",
          "text": "I've heard quite some stories about 'reverse' discrimination, both on gender, race and age. Basically, if you're a caucasian male above 40, you're at the back of the line on recruitment lists. Nobody will admit to it, of course...",
          "score": 2,
          "created_utc": "2026-01-20 19:41:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0s3dm1",
              "author": "Captain-Melonhead2x4",
              "text": "In this political climate? That makes no sense.",
              "score": 1,
              "created_utc": "2026-01-21 01:55:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0p5h0p",
          "author": "Accomplished-Dot-608",
          "text": "Maybe companies are trying to hire junior level engineers who have senior level experience whom they can pay less. I am just guessing.",
          "score": 1,
          "created_utc": "2026-01-20 17:14:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pba3u",
          "author": "WrongPlaceRightTime0",
          "text": "i have 5 yoe and had worked on the same tech stack, and mid last year i learnt spark structured streaming, kafka, kubernetes and did some personal projects then tailored it to match the industrial productionized ones for interview storytelling and resume. the fact is most data engs are working on batch processing reporting solutions hence real time streaming analytics can set you apart. i personally got 100 percent hike from a tier one consulting firm in india. i‚Äôd say just work your way around the new tools and tech and smartly sprinkle it on your cv",
          "score": 1,
          "created_utc": "2026-01-20 17:41:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0phyyd",
          "author": "adgjl12",
          "text": "Keep going. Reaching final round is a good sign. I got my job a year ago with 5YOE and it took 300+ applications to get 5 final interviews and 1 offer. It‚Äôs just a numbers game at that point.",
          "score": 1,
          "created_utc": "2026-01-20 18:12:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pp540",
          "author": "Gawgba",
          "text": "You need a better 'internal referral network'.  IYKYK",
          "score": 1,
          "created_utc": "2026-01-20 18:44:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pr15y",
              "author": "shittyfuckdick",
              "text": "So just networking?",
              "score": 0,
              "created_utc": "2026-01-20 18:52:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0px5dw",
          "author": "McNemarra",
          "text": "Prob cheaper candidates that provide similar value",
          "score": 1,
          "created_utc": "2026-01-20 19:20:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qdjzo",
          "author": "Inevitable_Oil_9715",
          "text": "in UK its really bad! Been trying to change the jobs but the market is dry so the salary is so low that one has to prepare for top tech companies. Surprise - you're laid off !",
          "score": 1,
          "created_utc": "2026-01-20 20:36:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r0xby",
          "author": "TheCamerlengo",
          "text": "No. None.",
          "score": 1,
          "created_utc": "2026-01-20 22:25:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rnx9x",
          "author": "get-the-dollarydoos",
          "text": "Just 200 jobs?\n\nHate to say it but those are rookie numbers. I see people all the time putting in 500+. My last job hunt I wrote a program to track my job searches and did more than 300 full applications and more than 600 Indeed quick apply applications, and I felt like I got hired quickly. Before that I'm pretty sure I was over 700. Back in 2014 it was over 500.\n\nIn fact, I haven't been on a job hunt in almost 15 years that didn't require 400+ applications and nowadays it seems to be approaching 1,000.",
          "score": 1,
          "created_utc": "2026-01-21 00:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rqvx5",
              "author": "shittyfuckdick",
              "text": "So it sounds like automation is key to landing a job?",
              "score": 1,
              "created_utc": "2026-01-21 00:44:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0oxf8s",
          "author": "5hruj4n",
          "text": "There‚Äôs a walkin for Azure Data Engineering in Bangalore on 14th Feb. DM me for more info",
          "score": -7,
          "created_utc": "2026-01-20 16:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p24po",
              "author": "shittyfuckdick",
              "text": "Im desperate but not India desperate",
              "score": 4,
              "created_utc": "2026-01-20 16:59:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qilwgb",
      "title": "Airflow Best Practice Reality?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qilwgb/airflow_best_practice_reality/",
      "author": "BeardedYeti_",
      "created_utc": "2026-01-21 02:45:18",
      "score": 51,
      "num_comments": 35,
      "upvote_ratio": 0.97,
      "text": "Curious for some feedback. I am a senior level data engineer, just joining a new company. They are looking to rebuild their platform and modernize. I brought up the idea that we should really be separating the orchestration from the actual pipelines.  I suggested that we use the KubernetesOperator to run containerized Python code instead of using the PythonOperator. People looked at me like I was crazy, and there are some seasoned seniors on the team. In reality, is this a common practice? I know a lot of people talk about using Airflow purely as an orchestration tool and running things via ECS or EKS, but how common is this in the real world. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qilwgb/airflow_best_practice_reality/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0sefx3",
          "author": "dudebobmac",
          "text": "It depends to me. Is the code you‚Äôre running some super lightweight script or something? If so, directly in a PythonOperator is probably fine. If it‚Äôs something heavier, then your idea is better. Airflow is an orchestrator, using it to actually PERFORM ETL or other major transformations or whatever is an anti pattern.",
          "score": 41,
          "created_utc": "2026-01-21 02:58:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tw2hm",
              "author": "No_Song_4222",
              "text": "What do you mean by anti pattern? Could you give an example ? \n\nln my prev org we used airflow + bigquery job operator to transform  several TBs and even create new tables.\n\nIt's worked and scaled okay because the compute happens at big query end and airflow just does the task retires, task dependencies, waiting time etc\n\nI know several companies use airflow to run their ML batch predictions and inferences as well so I am not sure what you mean by anti pattern here ? \n\nAll other native cloud based orchestrators are some form of airflow only e.g. AWS Blue, Databricks etc",
              "score": 6,
              "created_utc": "2026-01-21 10:02:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0u5s8x",
                  "author": "dudebobmac",
                  "text": "Right. So Airflow isn‚Äôt performing ETL in your examples. It‚Äôs orchestrating other tools to perform the ETL. That‚Äôs its intended usage, so you‚Äôre using it correctly as an orchestrator.\n\nThe anti pattern would be if you (for example) ran a PySpark job within a PythonOperator. Airflow isn‚Äôt meant to actually run your ETL jobs, only orchestrate them.",
                  "score": 20,
                  "created_utc": "2026-01-21 11:27:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0tyzvm",
                  "author": "Great-Tart-5750",
                  "text": "I think he means to say what you said earlier, that airflow itself does not do any compute and also that it's not something you should even try to. It kind of goes against the principle of being an orchestrator.",
                  "score": 2,
                  "created_utc": "2026-01-21 10:29:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0tk4c7",
              "author": "Adrien0623",
              "text": "Aren't Airflow's workers actually made to perform compute ? We used them for Spark jobs at a previous company and it was fine. Of course we had to allocate enough memory for each CPU core to ensure workers got enough resources.",
              "score": -5,
              "created_utc": "2026-01-21 08:07:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0twz7m",
                  "author": "No_Song_4222",
                  "text": "Not sure what you mean here. \n\nIt's the reverse. Airflow just does schedule and workflow/task management. No way airflow does any kind of compute. \n\nProcessing and computing happens only at spark. \n\nE.g. if processed in create a spark cluster, load your code , execute it airflow does exactly the same. Based on how your write your script you can either split it as task 1 create a spark cluster once that is done load and execute the code or else have everything in one script. \n\nThe workers you say here just execute the task and they needs cpu and memory to be in sync and communicate with other dependencies and receive updates from spark clusters about the status of job etc .",
                  "score": 4,
                  "created_utc": "2026-01-21 10:10:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0se23k",
          "author": "DoNotFeedTheSnakes",
          "text": "This is the norm at my company.\n\nI'm a senior DE & Airflow expert there.\n\nThough for most jobs we don't need the KubernetesPodOperator we just use normal Operators with the KubernetesExecutor.\n\nSo you still use the regular old PythonOperator, but under the hood you're running everything in Kubernetes.\n\nAny questions?",
          "score": 17,
          "created_utc": "2026-01-21 02:56:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sf7k1",
              "author": "BeardedYeti_",
              "text": "I'd love to hear more. So you're just using the nornmal operators, but because you are using the KubernetesExecutor all of your tasks essentially run as their own pod? Do you containerize your DAGs?",
              "score": 3,
              "created_utc": "2026-01-21 03:03:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0sfztu",
                  "author": "DoNotFeedTheSnakes",
                  "text": "Exactly.\n\nWe don't containerize most DAGs, just use a mount with a shared volume that the DAGs are on. (You need one anyway for the scheduler to parse)\n\nSome specific sensitive or complex DAGs get containerized due to special needs.",
                  "score": 2,
                  "created_utc": "2026-01-21 03:07:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0tr304",
                  "author": "ZeroSobel",
                  "text": "Using the KubernetesExecutor means you can throw all the \"don't use airflow for compute\" out. You can even have individual tasks with different venvs if you want.",
                  "score": 2,
                  "created_utc": "2026-01-21 09:14:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0scuik",
          "author": "Great-Tart-5750",
          "text": "Airflow can be quite powerful given its support of wide range of operators. But we should be very careful of what we pick as it is always a step away from becoming a clusterf*ck.\n\nPersonally we use it as a pure orchestration platform  only and other things are managed out of it.",
          "score": 6,
          "created_utc": "2026-01-21 02:49:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0txje5",
          "author": "No_Song_4222",
          "text": "I want to understand who is running compute in airflow and why ? \n\n\n What the OP mentioned is fine as long as your compute cluster like Spark, bigquery, redshift and other operators are decoupled from the airflow orchestrators layer. \n\nAs in compute happens on actually big data processing tech like snowflake , Databricks etc. airflows should just be telling run this at 3am in morning and mark success else make the DE life a mess with failure emails.",
          "score": 3,
          "created_utc": "2026-01-21 10:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vtd9o",
              "author": "alittletooraph3000",
              "text": "I too would love to understand when it makes sense to run compute in Airflow ...",
              "score": 2,
              "created_utc": "2026-01-21 16:51:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1jmxn2",
              "author": "No_Airline_8073",
              "text": "I did initially for a python task which calls an API to check lags in upstream tables and decide whether to run the downstream jobs or not.",
              "score": 1,
              "created_utc": "2026-01-25 02:26:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0snpuv",
          "author": "nyckulak",
          "text": "I work at a super small company and everything I do runs in containers, so every DAG is its own container. It‚Äôs just a lot easier to maintain and debug, and I don‚Äôt see it as much of an overhead.",
          "score": 2,
          "created_utc": "2026-01-21 03:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ss6zs",
          "author": "thickmartian",
          "text": "We do leverage PythonOperator for light/orchestration/formatting scripts. Any heavier Python work is done outside of Airflow.",
          "score": 2,
          "created_utc": "2026-01-21 04:23:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ssqb0",
          "author": "Fine_Art6449",
          "text": "i am newbie in airflow but in my company they are running airflow through EKS, is there any learning material to understand these types of deployments ?",
          "score": 2,
          "created_utc": "2026-01-21 04:27:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u4e3o",
          "author": "ludflu",
          "text": "you are 100% correct. doing the actual work in a python operator doesn't scale because it runs on airflow's compute. It can work for small things, but its bad practice and will backfire as soon as real load is placed on it.",
          "score": 2,
          "created_utc": "2026-01-21 11:16:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sql75",
          "author": "git0ffmylawnm8",
          "text": "My company uses venv operators, but I don't think we've ventured into remote execution with Kubernetes",
          "score": 1,
          "created_utc": "2026-01-21 04:13:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tgwlx",
          "author": "lupine-albus-ddoor",
          "text": "Love this idea - splitting orchestration away from the pipelines jsut makes everything cleaner. Sounds like you building a pipeline engine that stays pretty independent from each pipeline‚Äôs logic, which is the right direction.\n\nI just might have to nick this one, mate Will give credits to the BeardedYowie 8-)",
          "score": 1,
          "created_utc": "2026-01-21 07:38:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ti19l",
          "author": "Whatiftheresagod",
          "text": "For really heavy work we host our own api and run the code there. In this case Airflow is only orchestrating it by calling exposed endpoints.",
          "score": 1,
          "created_utc": "2026-01-21 07:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0un693",
          "author": "Hofi2010",
          "text": "I agree with your approach outsourcing the compute to a something like ECS or kupernetes (if you already have and know how to work with it). Reason is that the PythonOperator, as many noted, runs on airflow compute (workers) and depending on what compute engine airflow sits on this doesn‚Äôt scale well for big data volumes. For small things it is fine, but not for reliable production. Airflow uses a central requirements.txt file so managing all the different library versions and conflicts is nightmare and requires a lot of discipline. Using airflow purely as an orchestrator and execute on Faragate for example gives everyone a lot more flexibility and decouples Python dependencies from the workers. It also allows you to use any programming language you prefer.  if you are using MWAA, managed airflow on AWS, it will not allow you to install any dependency you want, mostly pure Python libraries or it gets complicated quickly.\n\nLong story short, outsourcing you compute to WCS or other compute and just use airflow for orchestration leads to a much more stable airflow. A lot of companies are doing this as best practice now.",
          "score": 1,
          "created_utc": "2026-01-21 13:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w2m7c",
          "author": "joaocerca",
          "text": "In the case of the small team I belong to, I use mainly to orchestrate pipelines of containers. We have only an aws ec2 instance. Cron jobs were not granular enough for what I needed, so I shifted some of those scripts to Airflow.\n\nThere is no computation there, just tasks to send notifications and containers to get data, transform it and send it to other places. And usually, I try to separate those too. A container to extract, another to transform and another send it somewhere.\n\nI am quite happy with it, no need for kubernetes. It would be overkill for our purposes.",
          "score": 1,
          "created_utc": "2026-01-21 17:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wakgs",
          "author": "iMakeSense",
          "text": "If you run things using the Python Operator, and there are multiple people doing multiple things on it, eventually you're going to have pip dependency clashes when someone wants to do something new. You also can do things like fill up space on a limited instance, use up too much cpu power, etc. You'd then have to scale up your node running Airflow. Which is dumb.\n\nNot everyone with a senior title thinks these things through. Some people get promoted for other reasons.   \n  \nIf you run things in ephemeral containers, it's the better practice, but it's a bit more overhead and headache depending on what devops or IT at your company is like. So most people in a hurry spin up Airflow and just wanna get something done because they're coming from running a cron job or what have you on a server or they don't read the goddamn docs or they're more objective focused because agile, KPIs, etc. Which...makes sense. People only care about things when they break. They don't want to pre-maturely optimize ( read, do the suggested best practice ) w/ something when they don't have to.\n\nI'd say, let it break first. Or give it an incentive to break. Then be the savior. Until then, monitor the machine it's running on.",
          "score": 1,
          "created_utc": "2026-01-21 18:08:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xco4h",
          "author": "geoheil",
          "text": "You might find https://georgheiler.com/event/magenta-data-architecture-25/ interesting. But this is way more than just a tool and best practices. \n\nAlbeit this is more about dragster the concepts are the relevant part and you can implement them also with something else",
          "score": 1,
          "created_utc": "2026-01-21 20:58:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y0g5r",
          "author": "No-Theory6270",
          "text": "`from cosmos import DbtTaskGroup`",
          "score": 1,
          "created_utc": "2026-01-21 22:50:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y9kbj",
          "author": "DataObserver282",
          "text": "Use a normal operator for Kubernetes. How much data are you moving? If at scale, would def seperate orchestration from pipelines. I‚Äôm not a fan of overtooling but for complicated pipelines ETL tools can be your friend.",
          "score": 1,
          "created_utc": "2026-01-21 23:38:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yos2c",
          "author": "Syneirex",
          "text": "We use it entirely as an orchestration tool, where everything is containerized and runs on Kubernetes.\n\nWe are running multiple environments in multiple clouds‚Äîthis approach has worked well for us.",
          "score": 1,
          "created_utc": "2026-01-22 01:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1k0oas",
          "author": "McHoff",
          "text": "Using the python operator is kind of insane in my opinion. Mixing your dependencies with airflow's is a ticking time bomb; I suppose if you code is so trivial it has no dependencies then maybe it's fine. Using the python operator also blurs the line a little between the job and the orchestration so it takes a bit more maturity to keep them decoupled.\n\n\nHonestly I've never seen an airflow setup that's *not* an absolute tire fire... I'm not sure if that's saying something about airflow or about the orgs that tend to use it.",
          "score": 1,
          "created_utc": "2026-01-25 03:45:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uavp1",
          "author": "mRWafflesFTW",
          "text": "Most people give bad airflow advice. Airflow is just a python application like any other. If you treat it like any other app, you'll be fine. Does the complexity of splitting your application into multiple services and executing them on kubernetes make sense for your use case? 99 percent of the time the answer is fuck no.\n\n\nMost firms can't handle properly version Python applications, so they probably can't handle the complexity of running Airflow as a \"distributed kubernetes service\".\n\n\nKeep it simple unless you have a good reason not to or the institutional engineering ability to go for the hard fun stuff first.",
          "score": 1,
          "created_utc": "2026-01-21 12:06:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qha2l9",
      "title": "Context graphs: buzzword, or is there real juice here?",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/2s01b45qvbeg1.jpeg",
      "author": "Berserk_l_",
      "created_utc": "2026-01-19 17:10:57",
      "score": 50,
      "num_comments": 16,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qha2l9/context_graphs_buzzword_or_is_there_real_juice/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0j2xof",
          "author": "kthejoker",
          "text": "To help everyone\n\nThere are (at least) two types of problems in the world of business.\n\nOne is measurement / analysis. This is things like \"how much did we sell last month?\" These are solved by data. databases, warehouses, SQL, BI, semantic layers. \n\nThe other one is process / logic / workflow. This is things like \"what sales actions should I take with this customer over the next 3 months to improve my chances of a win?\" Or \"what data should I use to answer this question?\"  These are solved by different kinds of data, usually qualitative in nature - metadata, documents, runbooks, applications, code, vector searches, RAG, and graphs. \n\n\"Context graph\" is a buzzword - it's just a graph database, the same ones we've had for 40+ years. The \"context\" just describes its purpose - a tool for providing context to AI models and agents.\n\nOffloading context, just like offloading data catalogs and other tools, help AI agents by preventing them from hallucinating, drifting, or getting context overload.\n\nJust like we don't expect an airline pilot to handle all measurement, observation, and emergency procedures themselves, we give them accurate dashboards, runbooks, and a support crew to help them achieve their tasks.\n\nData engineering obviously has a role in both problems in terms of investing, transforming, and managing data into data warehouses and graph databases.",
          "score": 41,
          "created_utc": "2026-01-19 19:19:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nmsar",
              "author": "Vemyx",
              "text": "so it's kind of like accounting vs financial modelling/investment banking",
              "score": 2,
              "created_utc": "2026-01-20 12:32:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ilcwy",
          "author": "ResidentTicket1273",
          "text": "I've heard people muttering about context graphs, but nobody's been able to define it for me. I know about knowledge graphs, and am wondering if a context graph is where you apply a knowledge graph in order to feed more contextually appropriate content to an LLM than an equivalent vector-database equipped RAG search would normally do - but it can't just be that.",
          "score": 28,
          "created_utc": "2026-01-19 18:01:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ilyw4",
              "author": "MakitaNakamoto",
              "text": "no, it is literally what you just described\n\nlook up AI ontologies and how to operationalize them, most of the time it's a knowledge graph + connection to company database and AI agents",
              "score": 19,
              "created_utc": "2026-01-19 18:04:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0io4kq",
                  "author": "ResidentTicket1273",
                  "text": "OK, in which case, it sounds like a rebranding of what (at least I thought) used to be called \"Graph-RAG\"!",
                  "score": 24,
                  "created_utc": "2026-01-19 18:14:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0j2phl",
              "author": "recursive_regret",
              "text": "So a knowledge graph is metadata about the data? I‚Äôm still so confused on what it is and now throwing in context graph I‚Äôm one layer deeper into confusion",
              "score": 4,
              "created_utc": "2026-01-19 19:18:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jw4m6",
                  "author": "kthejoker",
                  "text": "A graph is a graph. Nodes connected by edges.\n\nYou can have a graph of the people you know and how they know each other - a social graph.\n\nYou can also have a graph of all the data sources you have and how they're related to each other - this is a \"knowledge\" graph. \n\nIt may also include information about people (who uses, owns, manages the data), business context (is the data confidential, audited, what problems does it solve, when is it updated), and so on - then it becomes more like a \"context\" graph.\n\nAgain, nothing new. Just finding value in graph database technology as it relates to helping AI focus on what it's good at (high quality generation / imitation) and offload what it's bad at (deep context, computation, retrieval) to tools.",
                  "score": 6,
                  "created_utc": "2026-01-19 21:37:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0o1g37",
                  "author": "ResidentTicket1273",
                  "text": "It can be lots of things, but whenever anyone (or anything) is decoding some text (say in the middle of a conversation) a great deal of that decoding is dependent on the sender of the text and the receiver of the text sharing a common context. That context might start with the language being used (both in terms of actual language, and the specifics of the vocabularies or dialects each understands), the time of day, situational context, intentional context, the assumed roles of each of the communicating parties, and their respective understanding of the world. \n\nIf I ask someone a question, their ability to provide a meaningful answer is going to largely revolve around how closely they can frame their mental context to match mine. There's often a bunch of implicit stuff that's really important in doing that, and a graph is a super-flexible way of encoding data such that it can be applied across multiple contexts to build a temporary contextual framing in which to parse a given message.\n\nLots of humour revolves around the surprise and embarrassment that occurs when one person frames their response to a message in a different context to that of the other person.",
                  "score": 2,
                  "created_utc": "2026-01-20 14:00:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jzffa",
          "author": "Gators1992",
          "text": "The meta for llms changes every week, so don't get two freaked out about it.  \n\nBusiness context is usually captured with either RAG or graphs.  RAG uses a vector similarity search algorithm to look up related information and graphs rely on nodes and edges to connect relationships in your data.  Basically look at how Neo4j works.  They have been talking about the graph approach for a while, but barriers are how your data is organized/tagged as it's less effective the fewer relationships you have.  That's not easy to establish depending on what your metadata looks like.  Also massive graph dbs tend to not be that performant.  \n\nYou can still get pretty good results with them, especially for document search use cases or something like that.  But there are also people talking about how tensor based LLMs are limited and not going to get us to the promised land and the next step might be difusion models or something else.  AWS also was talking about how they are maxing out what they can do with generic LLMs in training and how they could be more effective if they had access to actual business data to train on (not going to happen).  Agentic systems are the current hot thing where you can create \"tools\" for the LLM to use based on the context.  Like if a user asks an accounting question, the LLM can call an accounting agent that might have textual, RAG or graph resources to answer the call.  \n\nIt's interesting but also infuriating that there are so many approaches and the \"best\" approach changes almost weekly.  It's still very early in AI development so I guess I would say don't freak out about learning one thing as it will likely change, but definitely do get into working with AI is future work will depending on it.  It's not going away.",
          "score": 5,
          "created_utc": "2026-01-19 21:53:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k8bou",
          "author": "ANGRYLATINCHANTING",
          "text": "Sounds like GraphRAG rebranded, tbh.",
          "score": 1,
          "created_utc": "2026-01-19 22:37:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t9131",
          "author": "Ok-Canary-9820",
          "text": "Old tech rebranded with new application. Tradeoffs, just like any other.",
          "score": 1,
          "created_utc": "2026-01-21 06:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19zp00",
          "author": "klumpbin",
          "text": "Context graphs are the apex predator of the modern data stack. By leveraging a hyper-scalable, multidimensional architecture, they unlock the latent potential of your unstructured data silos, transforming static touchpoints into a living, breathing ecosystem of actionable intelligence.\nThe Strategic Pillars of Context Graphing\n * Semantic Interoperability: We‚Äôre moving beyond flat-file legacy systems into a graph-native paradigm that facilitates seamless cross-functional transparency.\n * Predictive Synthesis: By mapping the relational DNA of every node, your enterprise can achieve a 360-degree holistic view that is both proactive and boundaryless.\n * Cognitive Agility: This isn't just about connectivity; it's about context-aware liquidity that empowers stakeholders to pivot at the speed of thought.\n> \"To win in the post-digital era, you need to stop managing data and start curating relationships via a robust, cloud-agnostic context fabric.\"\n> \nEssentially, it's about disrupting the status quo to drive exponential value-add through a unified, high-fidelity neural map of your entire business gravity.",
          "score": 1,
          "created_utc": "2026-01-23 17:53:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qmfyr1",
      "title": "Pandas 3.0 vs pandas 1.0 what's the difference?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qmfyr1/pandas_30_vs_pandas_10_whats_the_difference/",
      "author": "Consistent_Tutor_597",
      "created_utc": "2026-01-25 10:44:32",
      "score": 41,
      "num_comments": 32,
      "upvote_ratio": 0.86,
      "text": "hey guys, I never really migrated from 1 to 2 either as all the code didn't work. now open to writing new stuff in pandas 3.0. What's the practical difference over pandas 1 in pandas 3.0? Is the performance boosts anything major? I work with large dfs often 20m+ and have lot of ram. 256gb+. \n\nAlso, on another note I have never used polars. Is it good and just better than pandas even with pandas 3.0. and can handle most of what pandas does? So maybe instead of going from pandas 1 to pandas 3 I can just jump straight to polars? \n\nI read somewhere it has worse gis support. I do work with geopandas often. Not sure if it's gonna be a problem. Let me know what you guys think. thanks.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qmfyr1/pandas_30_vs_pandas_10_whats_the_difference/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1ljhqz",
          "author": "CrowdGoesWildWoooo",
          "text": "If you are dealing with large dataset why bother with pandas. Either use polars or duckdb",
          "score": 104,
          "created_utc": "2026-01-25 10:48:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1lrpvt",
              "author": "IGDev",
              "text": "After playing with DuckDB, it's not something I'd recommend for large datasets. Out of the box is extremely slow, which forces you toward Parquet, and even that can be slow.\n\n    Total rows:     10,000,000\n    Write time:     40.48s (includes data gen)\n    Throughput:     247,026 rows/sec\n    Parquet size:   126.26 MB\n    DuckDB size:    146.01 MB\n    \n    Warmup iterations: 3\n    Measured iterations: 5\n    \n    Query 1: WHERE Country = 'USA'\n    Q1: avg=1619.56ms, min=1609.02ms, max=1628.09ms, rows=1,002,685\n    Query 2: GROUP BY Category, SUM(UnitPrice), SUM(Quantity)\n    Q2: avg=7.44ms, min=7.30ms, max=7.54ms, rows=10\n    Query 3: WHERE Country = 'USA' ORDER BY UnitPrice DESC LIMIT 100\n    Q3: avg=18.41ms, min=18.25ms, max=18.63ms, rows=100\n    Query 4: WHERE Country = 'USA' AND Category = 'Electronics' AND Quantity > 50\n    Q4: avg=228.84ms, min=153.86ms, max=518.09ms, rows=49,606\n    Query 5: SELECT OrderId, Category, Quantity, UnitPrice WHERE UnitPrice > 100\n    Q5: avg=6201.19ms, min=6149.19ms, max=6271.34ms, rows=8,200,921\n    Query 6: GROUP BY Country: COUNT\n    Q6: avg=4.16ms, min=3.91ms, max=4.86ms, rows=10\n    Query 7: SUM(UnitPrice) OVER () - Cumulative Sum\n    Q7: avg=16137.01ms, min=16034.59ms, max=16349.76ms, rows=10,000,000\n\nOne thing to remember with DuckDB and Polars is they return results different. DuckDB is fully materialized, whereas Polars returns an intermediate result that isn't materialized. The Polars results below used rows() for materialization.\n\n    Total rows:     10,000,000\n    Write time:     38.50s (includes data gen)\n    Throughput:     259,767 rows/sec\n    Parquet size:   154.25 MB\n    \n    Warmup iterations: 3\n    Measured iterations: 5\n    \n    Query 1: WHERE Country = 'USA'\n    Q1: avg=965.22ms, min=947.07ms, max=974.36ms, rows=1,002,685\n    Query 2: GROUP BY Category, SUM(UnitPrice), SUM(Quantity)\n    Q2: avg=60.69ms, min=60.09ms, max=61.22ms, rows=10\n    Query 3: WHERE Country = 'USA' ORDER BY UnitPrice DESC LIMIT 100\n    Q3: avg=107.47ms, min=105.08ms, max=110.13ms, rows=100\n    Query 4: WHERE Country = 'USA' AND Category = 'Electronics' AND Quantity > 50\n    Q4: avg=65.06ms, min=62.63ms, max=67.54ms, rows=49,606\n    Query 5: SELECT OrderId, Category, Quantity, UnitPrice WHERE UnitPrice > 100\n    Q5: avg=2699.38ms, min=2668.45ms, max=2720.70ms, rows=8,200,921\n    Query 6: GROUP BY Country: COUNT\n    Q6: avg=53.69ms, min=52.52ms, max=54.46ms, rows=10\n    Query 7: SUM(UnitPrice) OVER () - Cumulative Sum\n    Q7: avg=10057.49ms, min=9964.84ms, max=10156.69ms, rows=10,000,000",
              "score": -21,
              "created_utc": "2026-01-25 11:58:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1mn0rc",
                  "author": "mamaBiskothu",
                  "text": "Youre somehow mixing up a lot of things and coming to a conclusion thats pointless. To compare duckdb to pandas you need to include both the loading time in the calculation. And pandas wont even run if you dont fit the dataset in memory. \n\nAnd polars won't materialize if you dont ask it to, why did you not ask it to?",
                  "score": 14,
                  "created_utc": "2026-01-25 15:09:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ljo1l",
              "author": "Consistent_Tutor_597",
              "text": "Thanks. So pandas 1.0 + polars will be good enough?",
              "score": -36,
              "created_utc": "2026-01-25 10:49:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1lrkpg",
                  "author": "Frosty-Practice-5416",
                  "text": "why do you want to use pandas 1.0?",
                  "score": 26,
                  "created_utc": "2026-01-25 11:57:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1m7ebc",
                  "author": "tecedu",
                  "text": "> So pandas 1.0 + polars will be goated?\n\nNo cus the data change between numpy and arrow types will take ages on a large dataset.",
                  "score": 8,
                  "created_utc": "2026-01-25 13:46:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1p9g6l",
                  "author": "klumpbin",
                  "text": "Yes - this is the stack I‚Äôm recommending for all new projects as a senior DE director. Pandas 1.0 + polars combines the speed and reliability of polars with the familiar syntax + support of pandas.",
                  "score": 1,
                  "created_utc": "2026-01-25 21:58:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1lnk7b",
              "author": "quackduck8",
              "text": "DuckDB code doesn't run in a container it throws an SSL certificate error when trying to connect to azure blob",
              "score": -23,
              "created_utc": "2026-01-25 11:23:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1lpbti",
                  "author": "Misanthropic905",
                  "text": "Not DuckDB problem, cert store on container probably are empty:  \n\napt-get update && apt-get install -y ca-certificates && update-ca-certificates   \n  \nWill fix.",
                  "score": 20,
                  "created_utc": "2026-01-25 11:39:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1lrpac",
                  "author": "Frosty-Practice-5416",
                  "text": "I think I have ran into this exact issue. They have a solution in their docs. Don't remember what it is right now though sorry",
                  "score": 5,
                  "created_utc": "2026-01-25 11:58:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1m7973",
          "author": "tecedu",
          "text": "So first answer:\n\nFrom pandas 2.0 onwards a lot of change was made to move from numpy into arrow, so you cant just use np.nans as pandas nans now, its pd.NA. Instead .replace operations you use assignement. Strings and datetime gets some changes as well as categorical types. Some changes with pd.read_excel as well. Slicing and a lot of your operations need to be explicit now instead of implicit. \n\nWhats going to bite you the most is numpy rather than pandas here.\n\nSecond Answer:\n\nUse polars + pandas, especially once you get everything setup in arrow types, its a seamless transfer of the dfs; while working with my team I use polars for the heavy stuff like merges, concats and stuff. ANd pandas for anything that needs to be verbose and redeable, like mathemtical operations or column based functions. Polars sucks at the whole thing because their approach of map_elements is inconsistent and expects something everytime. Polars also breaks their apis and their intended behavior quite a lot.\n\nJust 1.0 to 3.0 from numpy to arrow should be about 4x boost in perf, polars + pandas can be 5-20x and pure polars can be 10-30x.\n\nThe main thing I love about polars are sinks and lazyframes. And the streaming engine, I had some pandas code which took 64gb of ram, mixed it with some polars and sink and now its down to 10gb of ram",
          "score": 18,
          "created_utc": "2026-01-25 13:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1oqiih",
              "author": "openga_funk",
              "text": "Really surprised you‚Äôre saying to use pandas for readability vs polars. I fully switched from pandas to polars and every time I look at pandas code now I scratch my head with what the intent is",
              "score": 3,
              "created_utc": "2026-01-25 20:36:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p8x4e",
                  "author": "tecedu",
                  "text": "df['new_col'] = df ['col1'] * 2\n\n vs \n\ndf.with_columns((pl.col(\"col1\") * 2).alias(\"new_col\"))\n\nIts gets worse when you want to start chaining together things, with_columns and with_elements is inconsistent and horrible. Polars only make sense if you come over from spark or any SWE Background, it falls instantly at working with Data Scientists and Analysts; and I have to make sure my code is understandable by them.",
                  "score": 9,
                  "created_utc": "2026-01-25 21:56:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1pc4vg",
              "author": "tecedu",
              "text": "OP also if you are working with geospatial data, and not graphing anything. I would recommend to switch over to H3 or S3 instead of Latlons, it would make your life inifnitely easier working in a 2d space.",
              "score": 0,
              "created_utc": "2026-01-25 22:10:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ltstl",
          "author": "fckrdota2",
          "text": "If you need speed go polars,\nIf you hate verbose code go pandas or mb just dont use pandas at all\n\nIf you need speed and hate verbose code unfortunately allthoufh we are in 2026, R language's tidytable and data.table are still the only decent ines",
          "score": 7,
          "created_utc": "2026-01-25 12:15:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1m2inc",
              "author": "EarthGoddessDude",
              "text": "> if you hate verbose code go pandas\n\nBad take. I‚Äôll take verbose over weird, ugly, nonsensical syntax any day, which is exactly the trade-off between polars and pandas, but polars goes you that nice performance boost as well. \n\nOP, this is ridiculous ‚Äî at a minimum, you should definitely move off legacy software like pandas 1.x. You seriously need to give both polars and duckdb a try, they are simply amazing, especially for local compute on the data sizes you‚Äôre working with. They both have gis extensions as far as I know. Whether they work well enough for your use cases, only you can answer that by writing some quick prototypes, it‚Äôs really not that hard.",
              "score": 21,
              "created_utc": "2026-01-25 13:17:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1m3c5u",
                  "author": "Consistent_Tutor_597",
                  "text": "Thanks.",
                  "score": 1,
                  "created_utc": "2026-01-25 13:22:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1n37cr",
          "author": "pan0ramic",
          "text": "Why did you create a second account to ask the same question you asked in r/Python\n\nRead the changelog and migration guide or ask a ChatGPT",
          "score": 6,
          "created_utc": "2026-01-25 16:22:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ljtsk",
          "author": "VipeholmsCola",
          "text": "From my understanding polars use less memory and is faster than pandas. Also the syntax is much like spark so when you can transfer to spark easily. However, many production systems run pandas. I dont think theres a Geopolars so you would have to do some bulk work in Geopandas and then compute it in polars (you can swap between polars/pandas easily with polars syntax). Doesnt sound optimal but it could be...",
          "score": 17,
          "created_utc": "2026-01-25 10:51:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ly4ly",
          "author": "sjcuthbertson",
          "text": "Try migrating one small existing solution (or self contained unit of something) to pandas 3, and also to polars. \n\nThen you can compare performance and also what you think subjectively of the developer experience.\n\nI am a huge polars fan. For me, reason alone to use it over pandas 2 is how it handles data types, which works much better with delta lake & parquet typing.\n\nYMMV of course.",
          "score": 4,
          "created_utc": "2026-01-25 12:47:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1m7my7",
              "author": "tecedu",
              "text": ">  which works much better with delta lake & parquet typing.\n> \n> \n\nIf you pyarrow backend there shouldnt be much different between data types and your parquet and delta lake compatibility",
              "score": 2,
              "created_utc": "2026-01-25 13:47:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1niv86",
          "author": "Training_Butterfly70",
          "text": "How big is this code base? I don't think it's really that much of an undertaking to migrate from pandas 1.0 to 2.0 or 3.0. If anything you can just use Claude code to do 99% of this migration, and it will probably be very very good. This is the kind of thing it excels at",
          "score": 2,
          "created_utc": "2026-01-25 17:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1p0fxq",
          "author": "dataflow_mapper",
          "text": "i wouldnt think of it as ‚Äúpandas 3 is magically faster than 1‚Äù. most of the real gains came in 2.x with the pyarrow backed memory model and better string / nullable dtypes. 3.0 is more about cleaning up legacy stuff and making that model the default, not a night and day jump.\n\nfor 20m+ rows, pandas can still struggle depending on ops, even with tons of ram. polars is legit faster for a lot of workloads, esp groupbys and scans, but it‚Äôs a diff mental model and ecosystem. the geopandas thing is real too, if you rely on that a lot, pandas is still the safer path. i‚Äôd prob modernize pandas first, then reach for polars where perf actually hurts instead of a full jump all at once.",
          "score": 2,
          "created_utc": "2026-01-25 21:19:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qi1v2",
          "author": "zangler",
          "text": "Go polars",
          "score": 1,
          "created_utc": "2026-01-26 01:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1mwszy",
          "author": "zazzersmel",
          "text": "Hey bro step one find out if you have more than 256 gb ram. At 256.1 gb ram you need to upgrade to pandas 3.<total ram over 256gb minus current build of pandas>. So if you have 259 for example you need to build from source pandas 3.1.\n\nSecond you need to learn about lazy or ‚Äúbitter‚Äù execution bc‚Ä¶ frankly everything in pandas 3 uses bitter execution and you‚Äôre SOL without it.\n\nFinally I realize you‚Äôre green but it‚Äôs called df not dfs‚Ä¶. Good luck.",
          "score": -4,
          "created_utc": "2026-01-25 15:54:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql5s1b",
      "title": "Stuck in jupyter notebooks, how to get out?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1ql5s1b/stuck_in_jupyter_notebooks_how_to_get_out/",
      "author": "Consistent_Tutor_597",
      "created_utc": "2026-01-23 22:56:49",
      "score": 40,
      "num_comments": 33,
      "upvote_ratio": 0.86,
      "text": "Hey guys. I work at a small company and joined a data science team and started writing etl stuff in jupyter notebooks in jupyterlab. and then later even as the project grew I kept writing parameterised notebooks and ran them with papermill. But it's starting to get absurd and I think isn't really common practice at all. But I am not sure how to get out of this habit. \n\nI write data science style procedural code and like to inspect and muck with stuff every step along the way otherwise I feel blind. It feels as I am in a live debugger. Even when I write an api, I have to take that function in a jupyter notebook and run it there and copy paste and go back and forth etc. \n\nI personally dislike functions as well unless neccesary and there's reuse required. \n\nI am not sure what to do but seems like in real ides there's tools like debuggers and interactive window which helps with this. But just wanted to learn from others how can I write clean software style code where I can still not lose visibility of the data. Thanks guys.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1ql5s1b/stuck_in_jupyter_notebooks_how_to_get_out/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1c6sr5",
          "author": "ask-the-six",
          "text": "Start using functions that you import. Keep it simple at first. I‚Äôd start with a config.py, constants.py functions.py. If it‚Äôs a small company I‚Äôd chat with any other developers about a shared library in your vcs",
          "score": 35,
          "created_utc": "2026-01-24 00:13:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1enbvk",
          "author": "skinny6328",
          "text": "Have you tried marimo?\nIts a jupyter alternative and its like the best of both worlds, you can run it as notebook while the code gets stored in pure Python (better for git as looking at html from jupyter notebooks isn't very good)\nhttps://marimo.io/features/vs-jupyter-alternative",
          "score": 10,
          "created_utc": "2026-01-24 10:50:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bufrm",
          "author": "konwiddak",
          "text": "I'd say there's nothing particularly wrong with what you're doing since the purpose is to analyse and manipulate data. If you're trying to write software then yes it's not great because you can't really write comprehensively testable software without functions. You don't generally have things to plot and tabulate with software so you just need a debugger to inspect variables. This tool chain doesn't work that well for data science.",
          "score": 20,
          "created_utc": "2026-01-23 23:06:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bvjym",
              "author": "Consistent_Tutor_597",
              "text": "It's like a mix at this point. I am doing lots of analytics and eda. And then I have to productionalise it to make it a pipeline and run regularly. Or make it run en masse. \nAnd then also gotta update that analytics logic over time. \n\nI also wrote a app once which ran notebook as a script to make a report live. Which my teammates felt like to be rather 'unique'. I pretty much treat one notebook as one function sort of which takes parameters are top. \n\nAnd plus I do have to write even some backend sometimes. But I just rely on print statements.",
              "score": 1,
              "created_utc": "2026-01-23 23:12:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1lnma8",
                  "author": "queceebee",
                  "text": "Look into frameworks like metaflow if you use R or Python",
                  "score": 1,
                  "created_utc": "2026-01-25 11:24:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1bv9iz",
          "author": "Monowakari",
          "text": "Modularize your code as you go, at the end the notebook SHOULD JUST be orchestrating functions that do all the work. Then offload that to airflow or dagster, write outputs to s3 and maybe a db even\n\nKeep the notebook in line with the dag for debugging and testing. Log, log alot, and export backups, start using mlflow for experiment tracking and have it live in there? If you're training anything that is.\n\nDozens of other options but this is such an immediate and necessary win for anything else to really happen.\n\nETA: learn about hot reloading functions in jupyter, so when you change a print statement or add a func and save the file, you don't have to reload jupyter hours rerun the import line, it's like a 2 line command at the top of the notebook to make this happen.",
          "score": 9,
          "created_utc": "2026-01-23 23:11:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bwiea",
              "author": "Consistent_Tutor_597",
              "text": "What about for visibility inside the functions? Say you wrote a function called calculate user churn which does many stuff with dataframes. How will you go back and update the logic if someone says that doesn't look right? Do you use a debugger for it? \n\nI have been able to take my jupyter code and put it in functions in the past. But once it goes in functions, I am mainly reliant on print statements and maybe global variables. To check and play with the dataframes to see every step and where things stuff up.",
              "score": 2,
              "created_utc": "2026-01-23 23:17:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1csanj",
                  "author": "PhoenixFlame77",
                  "text": "Your functions may be doing too much. Try to stick to the single responsibility principle. You should be able to define the exact way your metrics are calculated. And there will be a natural way to transfer this to deriving your churn metricsthrough functions.\n\nI.e. your definition might be \"monthly churn is A / B-C  \n\nWhere A is the count of all active customers who haven't made an order at the end of the month, B is the the total number of active customers at the end of the month, C is the number of new customers in a month.\" \n\nIf defined like this a natural structure might be to have a several helper functions like _count_active_customers, _count_new_customers,_count_custoners_who_order,  that handle the aggregations of your data while your your higher level function calculate_user_churn can just handle the mathematical bit of the logic (I.e. the A/B-C logic). Each of these bits can then be tested  simply by running examples data through them independently and comparing outputs match expectations (this is basically what unit tests are). \n\nIf done, when someone comes up to you and says I think churn should have been 10% this month but it's showing a negative number you can quickly say oh that's strange I get 20 customers who didn't make an order 300 active customers and 100 new customers (by running the subfunctions) so following the definition I get 20/300-100 which is about -99. And they can go I think maybe you missed some brackets it should of been 20/(300-100) and then you go doh I'll fix that in the calculate user churn function . Or they can go that 100 doesn't sound right and you can go oh let's explore that by looking at _count new customers and so on. \n\nSticking to functions having a single responsibility like this makes reuse easier as code is less tied to single outputs and also makes testing your code through unit tests easier too.",
                  "score": 6,
                  "created_utc": "2026-01-24 02:15:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bwmq7",
                  "author": "Monowakari",
                  "text": "Separation of concerns! And didn't I say logging?",
                  "score": 2,
                  "created_utc": "2026-01-23 23:18:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1dxeuc",
          "author": "JBalloonist",
          "text": "Prototype in Jupyter; deploy with Python files. That was my rule at my previous role anyway. \n\nNow I‚Äôm using fabric and don‚Äôt have a choice.",
          "score": 4,
          "created_utc": "2026-01-24 06:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1exvqi",
              "author": "Waldchiller",
              "text": "Even with fabric you can treat notebooks as a module put your functions in there. Than call it from other notebooks using %% run command. You can even make whl files and use them.",
              "score": 1,
              "created_utc": "2026-01-24 12:21:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1dxrsw",
          "author": "demigod_31",
          "text": "This is working for you because your code doesn't need to scale right now. You can get around your concerns around \"visibility within functions\" by having logging and debug logic that's parametrized. You could do simple things like save intermediate dataframes to file when `debug==True` and inspect those in a notebook.",
          "score": 3,
          "created_utc": "2026-01-24 06:58:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1el80l",
          "author": "monkeyinnamonkeysuit",
          "text": "If you are not writing your code using functions, how are you unit testing it? If you are not unit testing it then you are not writing production quality code. \n\nIf I heard the phrase \"I don't like functions\" at interview it would make me think data analyst not engineer. Not to be derogatory as both are valuable but different skills. \n\nYou can absolutely write modular code without compromising the positives about the jupyter notebook experience. If you write your code  in a modular way it will be incredibly easy to migrate it anywhere.\n\nSome things are understood to be industry norms for a reason.",
          "score": 2,
          "created_utc": "2026-01-24 10:31:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1l7b15",
              "author": "Consistent_Tutor_597",
              "text": "I know. I am terrible. And yes I started off as a data analyst and worked in analytics/ data science. Which started involving letting stuff run regularly as etl pipelines. \n\nI also wrote some APIs which were in functions ofcourse. No tests for them either. We are a small company. Though I am getting aware and will start implementing those things that people shared in this post. The tools in an ide like vsc like debugger seem like lifesavers to offer and keep flexibility. \n\nSo would slowly start moving. Thank you for your feedback.",
              "score": 1,
              "created_utc": "2026-01-25 09:00:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1fuzek",
          "author": "queceebee",
          "text": "> I personally dislike functions as well unless neccesary and there's reuse required. \n\nI have bad news for you if you need production-level code....\n\nOn a more serious note, if you use an IDE like VScode, you can incrementally build code logic with interactive code execution like in a notebook and also become familiar with how to use the debugger for your programming language. Once you have an initial chunk of code that does what you want, parameterise it and stick it in a function. Then write some tests for it, ideally. A parameterised notebook is not all that different from a very lengthy function. You just want to separate the code in your notebook into functions so that each function is doing a single thing and returning/producing a single thing.\n\nIt will be slower at first because you're rewiring your brain to use a new process and interface, but you'll get faster and the benefits can be great if you're doing anything that's a deliverable and you want some quality assurance. And this is just the tip of the iceberg. Once you get to this level there is a whole world of code design best practices you can venture into to make your job easier while giving you more confidence in the correctness of your code and its artifacts.",
          "score": 2,
          "created_utc": "2026-01-24 15:36:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1fwhgk",
              "author": "queceebee",
              "text": "And if this isn't intuitive at first, write the whole notebook worth of code first then go back and refactor it into functions. The stepwise approach spreads the cognitive load out until you can start thinking in functions from the get go",
              "score": 1,
              "created_utc": "2026-01-24 15:43:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1l7ke1",
                  "author": "Consistent_Tutor_597",
                  "text": "Thank you very much. It's an eye opener. I am a really shitty engineer and trying to be better.",
                  "score": 1,
                  "created_utc": "2026-01-25 09:02:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1hhgga",
          "author": "psssat",
          "text": "I don‚Äôt get how nobody has suggested this but learn how to use .py files with the REPL. In vscode for example, you can work in a .py and then highlight text and send to the repl so it basically mimics exactly a notebook but you have the benefit of being in a .py file.",
          "score": 2,
          "created_utc": "2026-01-24 19:55:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1byqs2",
          "author": "kopita",
          "text": "Use nbdev",
          "score": 1,
          "created_utc": "2026-01-23 23:29:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dntq3",
          "author": "Resident_Animator_84",
          "text": "You research about orchestration and leave the notebook, and write python with function and method (OOP)",
          "score": 1,
          "created_utc": "2026-01-24 05:37:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1gw6ur",
          "author": "Bach4Ants",
          "text": "What concrete problems is the practice causing you beyond feeling wrong?",
          "score": 1,
          "created_utc": "2026-01-24 18:22:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1htv02",
          "author": "Global_Bar1754",
          "text": ">¬†I write data science style procedural code and like to inspect and muck with stuff every step along the way otherwise I feel blind\n\nCheck out this library I‚Äôve been working on. It‚Äôs not totally production ready yet. But it‚Äôs already pretty powerful. I think you‚Äôll really like the tracing/replaying feature a lot just based on that quote above. This library was made for the exact kind of workflow you‚Äôre desiring, productionizing data science workflows but still having the flexibility to iterate in notebook style environments. It is pretty function based, but imo it makes dealing with/thinking about functions easy since you think of functions as ‚Äúthings you want‚Äù (nouns) rather than arbitrary operations (verbs).¬†\n\nhttps://github.com/mitstake/darl#debugging-tracing-and-replaying",
          "score": 1,
          "created_utc": "2026-01-24 20:53:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iltzs",
          "author": "BayesCrusader",
          "text": "Setting up a test environment is not something most DS are aware of, let alone do correctly. I think it's what has made notebooks (which are mainly for teaching IMO) so popular.\n\n\nMy life changed when I finally set up my environment correctly for testing ETL and analysis workflows. Extensions in VSCode were the gateway for me to understand what that looked like.¬†",
          "score": 1,
          "created_utc": "2026-01-24 23:08:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1irmub",
          "author": "sbawlz",
          "text": "Are you just trying to go from Jupyter to production deployable code?",
          "score": 1,
          "created_utc": "2026-01-24 23:39:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iwhb1",
          "author": "wapsi123",
          "text": "You should take a look at kedro, it's literally build for this stuff.",
          "score": 1,
          "created_utc": "2026-01-25 00:04:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jl4u1",
          "author": "spendology",
          "text": "You could plan to promote your Jupyter Notebook code to Production IF you have an environment with tools and sufficient budget (or flexibility). Cloud tools including AWS Lambda, AWS Sagemaker (notebooks in the cloud), could be used to orchestrate Python workflows. Low-code, RPA, or orchestration tools like Apache Airflow, Microsoft Power Automate, Knime, or UiPath can allow you to turn your code into an official end-to-end solution with a UI.",
          "score": 1,
          "created_utc": "2026-01-25 02:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ch8ms",
          "author": "Schtick_",
          "text": "If you use Claude code you can get a similar experience, pretty sure you could also get Claude to maintain your notebook and final isolated scripts separately. Something like messaging Claude and saying build me a production py file for this part of the notebook.",
          "score": -3,
          "created_utc": "2026-01-24 01:10:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cl1eh",
          "author": "ChinoGitano",
          "text": "Pivot to Databricks.  Should be an easy stretch and it‚Äôs in high demand now.",
          "score": -5,
          "created_utc": "2026-01-24 01:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1deoj4",
              "author": "Consistent_Tutor_597",
              "text": "What would that do? How would that solve the issue?",
              "score": 2,
              "created_utc": "2026-01-24 04:32:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmkywg",
      "title": "dbt-ui ‚Äî a modern web-based user interface for dbt-core projects",
      "subreddit": "dataengineering",
      "url": "https://github.com/data-diving/dbt-ui",
      "author": "Appropriate-Debt9952",
      "created_utc": "2026-01-25 14:46:35",
      "score": 40,
      "num_comments": 12,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Personal Project Showcase",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qmkywg/dbtui_a_modern_webbased_user_interface_for/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1qdm7x",
          "author": "DungKhuc",
          "text": "Very clean interface!\n\nWhat's the advantage of web app over a vscode extension?",
          "score": 10,
          "created_utc": "2026-01-26 01:06:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1puytj",
          "author": "Thisisinthebag",
          "text": "Does it have sql editor, intellisense, are you able to develop using this ui alone ?",
          "score": 7,
          "created_utc": "2026-01-25 23:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1pucoc",
          "author": "Thisisinthebag",
          "text": "Looks cool. I always thought it would take whole team to do it, here you have done it alone. Kudos to you.",
          "score": 2,
          "created_utc": "2026-01-25 23:32:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qz9yq",
          "author": "Eric-Uzumaki",
          "text": "Probably gonna be sued by dbt due to competing factors. I read somewhere in their contracts of dbt core",
          "score": 2,
          "created_utc": "2026-01-26 02:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1rohjp",
              "author": "jawabdey",
              "text": "Yeah, I was thinking the same. This is basically the one thing you are not allowed to do. OP said dbt-core, so maybe one can do it since the license is different between core and fusion",
              "score": 3,
              "created_utc": "2026-01-26 05:32:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1qzcul",
          "author": "No-Badger-9784",
          "text": "That's great, I've gotten used to using the VS Code extensions, which help me a lot.",
          "score": 2,
          "created_utc": "2026-01-26 02:57:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qfftb",
          "author": "Hirukotsu",
          "text": "Kudos, I wish I could use it in my enterprise environment but alas. Looks really slick!",
          "score": 1,
          "created_utc": "2026-01-26 01:16:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1sbbt4",
          "author": "Hix3nn",
          "text": "If you can compile this to a single binary so people can install and use it like vscode or data grip etc that would be perfect!",
          "score": 1,
          "created_utc": "2026-01-26 08:37:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh6wo1",
      "title": "Crippling your Data Engineers",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qh6wo1/crippling_your_data_engineers/",
      "author": "LargeSale8354",
      "created_utc": "2026-01-19 15:18:34",
      "score": 38,
      "num_comments": 10,
      "upvote_ratio": 0.94,
      "text": "I'm working as a contractor for a client where I have to log onto a GDE terminal. The window size is fixed and the resolution is probably 800x600.\nYou can't copy/paste between your host and the GDE so be prepared to type a 24character strong password. Session time outs are aggressive so expect to type this a lot.\n\nGDEs are notoriously slow. This one sets a new record. The last time I saw something this slow was when I had to use an early Amstrad laptop with dial up modem to connect to an HP3000 mini computer. In 2026, I've been assigned kit that wasn't impressive in 1989.\n\nI'd love to know the justification for this fetid turd of an environment.",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qh6wo1/crippling_your_data_engineers/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0hljqb",
          "author": "Reach_Reclaimer",
          "text": "They don't want you working in their systems by the sounds of it",
          "score": 37,
          "created_utc": "2026-01-19 15:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i78xb",
          "author": "Thinker_Assignment",
          "text": "What I learned from freelancing in enterprise: when the business model already works, the incentive is to prevent further changes, not to enable change.\n\nLooks like you won't be changing sh\\*t on that project.",
          "score": 10,
          "created_utc": "2026-01-19 16:58:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hq6av",
          "author": "Omar_88",
          "text": "Take the W and just work as well as you can. You're getting paid a nice day rate.",
          "score": 22,
          "created_utc": "2026-01-19 15:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i61ci",
          "author": "LargeSale8354",
          "text": "Some of the tools on the GDE have modal interfaces that are too big for the GDE screen resolution with critical controls off screen.\nThe Tab key doesn't help here either",
          "score": 6,
          "created_utc": "2026-01-19 16:52:44",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0parzq",
              "author": "Thinker_Assignment",
              "text": "I hope you feel resigned rather than angry, for your own sake. Imagine a troll did this.",
              "score": 2,
              "created_utc": "2026-01-20 17:39:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ph5x9",
                  "author": "LargeSale8354",
                  "text": "Very much so. I've seen variations of this in larger financial institutions.  The typical profile is\n1. They've got a monopoly shared with 3 or 4 key players \n2. They treat their customers with arrogance and disdain.\n3. They know the cost of everything and the value of nothing \n4. They have legions of people whose only role seems to be the perpetuation of bureaucracy\n5. They've got bizarre status perks. Exec loos get a different class of toilet paper, that sort of thing.",
                  "score": 1,
                  "created_utc": "2026-01-20 18:08:33",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ifycd",
          "author": "TheOverzealousEngie",
          "text": "I had that happen to me once, the interface they gave me such low res that you could barely read the fonts, so I went into the MONITOR settings and adjusted the resolution and make it 150x better. When my manager came over she nearly had a heart attack, she was furious. I thought I was fired. But she warned me .. touch nothing, make nothing better. Working in a corporate environment is quite different.",
          "score": 4,
          "created_utc": "2026-01-19 17:37:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkerci",
      "title": "How are you replicating your databases to the lake/warehouse in realtime?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qkerci/how_are_you_replicating_your_databases_to_the/",
      "author": "finally_i_found_one",
      "created_utc": "2026-01-23 02:41:05",
      "score": 36,
      "num_comments": 43,
      "upvote_ratio": 0.92,
      "text": "We use kafka connect to replicate 10-15 postgres databases but it's becoming a maintenance headache now.   \n  \n\\- Schema evolution is running on separate airflow jobs.   \n\\- Teams have no control over which tables to (not) replicate.   \n\\- When a pipeline breaks, it creates a significant backlog on the database (increased storage). And DE has to do a full reload in most cases.  \n  \nWhich managed solutions are you using? Please share your experiences.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qkerci/how_are_you_replicating_your_databases_to_the/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o165ypv",
          "author": "kenfar",
          "text": "I'm not replicating upstream data models into a separate warehouse or lake house.  Life is too short to live through that pain.",
          "score": 25,
          "created_utc": "2026-01-23 03:06:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o166oeu",
              "author": "finally_i_found_one",
              "text": "Lucky. Some of us have to live through this pain.",
              "score": 5,
              "created_utc": "2026-01-23 03:10:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o16f2vk",
                  "author": "kenfar",
                  "text": "I have the scars, don't need any more.\n\nEspecially when people act shocked and ask questions like \"how could this happen?!?\"",
                  "score": 1,
                  "created_utc": "2026-01-23 03:59:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o16tqm3",
              "author": "iMakeSense",
              "text": "In what sense are you avoiding that? Do you mean you're doing it more on a case by case basis?",
              "score": 2,
              "created_utc": "2026-01-23 05:36:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18no13",
                  "author": "kenfar",
                  "text": "These days I'm mostly consuming pre-denormalized data from upstream sources.\n\nMy go-to is data contracts + domain objects.  But sometimes I just get domain objects.\n\nIt still requires transformation, and still involves challenges in communication about what the data means, but it doesn't involve attempting to replicate upstream models and then sew them back together based on ephemeral misunderstandings.",
                  "score": 0,
                  "created_utc": "2026-01-23 14:07:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16d5ec",
          "author": "EconomixTwist",
          "text": "Do you have, or have you come across, bona fide evidence of how using database cdc -> messaging -> message ingest/db changes on the replica‚Äôs side is better than just a good old fashioned DB copy? I do first question the business requirement (I really can‚Äôt imagine a business case where there is a need of such low latency between the source and consumer where messaging is the only option). It all sounds fine in theory, but as you mention in the post, you end up doing a full db copy anyways lmao. Messaging Seems like overkill and a solution looking for a problem but maybe you work in a high risk industry like defense or gambling or something idk",
          "score": 8,
          "created_utc": "2026-01-23 03:47:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16o20i",
              "author": "Top-Competition7924",
              "text": "from my experience, 2 examples where cdc stream to warehouse came in handy:  \n1. When the DB size is huge and the volume of daily changes (insert/update) is orders of magnitude smaller (imagine PB/TB size DB, with only a few GBs of changes per day.  \n2. When you want to keep track of all UPDATEs on a given table. Doing a daily copy would mean you only get the current table values at the time of the copy (you miss any updates that happened in between the previous copy until current one)",
              "score": 5,
              "created_utc": "2026-01-23 04:56:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o173aps",
                  "author": "kittehkillah",
                  "text": "Genuinely just asking but isnt number 2 resolved by metadata of the source system having a created or modified timestamp? With that, even if the run is daily, as long as keep track of these fields, we always get the data?¬†",
                  "score": 2,
                  "created_utc": "2026-01-23 06:51:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bi7a9",
                  "author": "EconomixTwist",
                  "text": "My issue is really more with the messaging pattern- particularly using a separate framework/tool i.e. kafka, that requires all this custom code or, rather, config (I get it kafka dudes, iTs MoStLy YaMl) as opposed to using a database that has a managed, built-in, capability that does write/update forwarding... or even handling dual writes in the application layer itself. Under the pattern of the writing application doing dual writes handles your example 1- if you don't have that many writes throughout the day the performance overhead in the application side is, by definition, not a big deal.\n\nUse case 2 is an incredibly complex, engineering-heavy, mega-scale requirement. If you really do need that, you're SPECIFICALLY selecting a DBMS/platform that can handle this natively- you're not bolting on a messaging bus on top of it with home grown code/cOnFig. And if a person is... well then... I (nor god) can help them",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o172900",
              "author": "daguito81",
              "text": "I have. When your origin is a Mainframe AS-400 and that stuff.\nBut basically because doing some kind of copy would consume the cores you pay for. While using CDC  doesn‚Äôt. \nBut talk about a niche use case",
              "score": 1,
              "created_utc": "2026-01-23 06:43:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o16wzug",
          "author": "kabooozie",
          "text": "If you‚Äôre using clickhouse, they have clickpipes which is a good realtime Postgres cdc option.",
          "score": 5,
          "created_utc": "2026-01-23 06:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19g73z",
              "author": "AntDracula",
              "text": "How hard it that to set up? Especially if your instance is in a private VPC?",
              "score": 1,
              "created_utc": "2026-01-23 16:23:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19kt83",
                  "author": "assaxor",
                  "text": "ClickPipes supports private link as well as SSH tunneling for these cases",
                  "score": 3,
                  "created_utc": "2026-01-23 16:44:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16rp8q",
          "author": "Ok-Technology-6595",
          "text": "Debezium plugin on Kafka connect to cluster to databricks Delta Live Tables",
          "score": 3,
          "created_utc": "2026-01-23 05:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o164i4k",
          "author": "blueadept_11",
          "text": "I used stitch a couple of years ago for a ton of SQL Server databases to BigQuery and it was affordable and bulletproof. At the time it was $10k/yr - now $1250/m. That particular integration used CDC+Kafka+Debezium under the hood, which I had also had my team build out at a prior company for a production migration project and it was also bulletproof at 100 million rows a day. Not sure if it solves all of your problems, but worth a look if you have the budget.",
          "score": 5,
          "created_utc": "2026-01-23 02:57:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16fv56",
              "author": "quickdraw6906",
              "text": "We're leaving HVR/Fivetran, bailing on the crazy MAR pricing. Same setup: CDC (trans log w/ SS & journals w/ DB2) + Debezium + Kafka (Redpanda). 140 databases...1-1.5Gb/s transfer rates into PostgreSQL lake.",
              "score": 5,
              "created_utc": "2026-01-23 04:04:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o16g7z8",
                  "author": "finally_i_found_one",
                  "text": "140 databases! What the fuck does the company do? And why are you still using Fivetran üòÅ",
                  "score": 3,
                  "created_utc": "2026-01-23 04:06:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o166vce",
              "author": "finally_i_found_one",
              "text": "Thanks. What was the ingestion SLA supported? We need hourly refreshes for some databases (actually a few specific tables).",
              "score": 1,
              "created_utc": "2026-01-23 03:11:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o167p5n",
                  "author": "blueadept_11",
                  "text": "I think they go down to 5 minutes on the higher tier \"advanced\".",
                  "score": 2,
                  "created_utc": "2026-01-23 03:16:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o16eofb",
                  "author": "quickdraw6906",
                  "text": "Why need hourly snapshots if you have near real time integration?",
                  "score": 1,
                  "created_utc": "2026-01-23 03:57:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1891sr",
                  "author": "jjohncs1v",
                  "text": "If you run your own infrastructure or aren‚Äôt afraid of it, you can look into Airbyte. It‚Äôs one of these types of tools but it‚Äôs open source and you can self host it for free. Or run the cloud version with pricing models similar to the other tools.¬†",
                  "score": 1,
                  "created_utc": "2026-01-23 12:45:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16o6q7",
          "author": "discord-ian",
          "text": "I have used quite a few of them... Real-time I feel like your have two enterprise grade options Kafka Connect and spark structured streaming.  And your choice ussually boils down to are we already running a spark cluster or a kafka cluster.\n\nI have much more experience with Kafka Connect and sure it has it's pain points but it is the best in class solution for real-time data at scale.  Although i will add Red Panda is an increasing an option that I would keep on the table.\n\nThe problem with the managed solution is they become expensive and slow if you are working with any volume of data or any high update frequency.  \n\nIf you have small data or don't have real-time requirements the managed solution are all great. Currently we run Kafka connect and Open Source Airbyte. We are slowly moving away from Airbyte, but it works great for all of our small tables that need to be updated ever 15 minutes or less.",
          "score": 2,
          "created_utc": "2026-01-23 04:57:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17elag",
          "author": "Alternative_Aioli_72",
          "text": "Hard to recommend solutions without more context. A few questions first:\n\n* How big are we talking? (GB? TB?)\n* Update frequency?\n* Do you actually need all tables from all 10-15 DBs?\n* Any overlap/duplication across them?\n\nIf you genuinely need everything, you might want to look into **Iceberg Topics** (Confluent just released this). Basically streams your CDC directly into Iceberg tables that you can attach straight to your lakehouse landing zone. Gets you ACID, schema evolution, time travel, and hidden partitioning with essentially zero ETL. Could be worth exploring depending on your answers above.",
          "score": 2,
          "created_utc": "2026-01-23 08:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17jrfb",
              "author": "finally_i_found_one",
              "text": "1. Most DBs are 100s of GBs. A couple of them a few TBs.  \n2. Hourly for some. Daily for the rest.  \n3. Don't need all tables, but need an interface for product/analytics teams to configure which tables should be replicated  \n4. Didn't understand what you meant by overlap.\n\nWarehouse is snowflake, can't move out of that.",
              "score": 1,
              "created_utc": "2026-01-23 09:19:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o17rene",
                  "author": "Alternative_Aioli_72",
                  "text": "Thanks for providing more details. Actually, Kafka might be overkill for your case. Given the volumes you're dealing with (which are relatively modest), you could query the selected tables directly with DuckDB, land the results in cloud storage (S3, Azure Data Lake Storage), and attach them to Snowflake as external tables. That would be enough for hourly/daily syncs at this scale.\n\nIf you want to keep the streaming approach, a zero-ETL solution would be Kafka Connect with S3 Sink (Iceberg Topics are too much for your case). I'd recommend a metadata-driven approach: extract the Postgres schemas as CSV, let Product/Analytics teams mark which tables they need, and dynamically build your Kafka Connect configs from that. Combined with Kafka Connect S3 Sink (Parquet/Avro) + Snowflake External Tables (zero-copy), you get the same benefits (no ETL, no storage overhead), but with team self-service and without having to manage 10-15 DBs √ó X tables as separate topics. Schema evolution runs through Schema Registry, and when pipeline issues occur, S3 becomes your buffer instead of the source DB.",
                  "score": 1,
                  "created_utc": "2026-01-23 10:29:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16d7nr",
          "author": "FadeAwayA",
          "text": "https://docs.cloud.google.com/dataflow/docs/guides/templates/provided/cloud-spanner-change-streams-to-bigquery\n\nOnly works with spanner and bigquery, but has been great.",
          "score": 1,
          "created_utc": "2026-01-23 03:48:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16rgq8",
          "author": "adgjl12",
          "text": "DMS replication for PG -> redshift",
          "score": 1,
          "created_utc": "2026-01-23 05:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17cu6p",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-23 08:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17gy1o",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment was removed because it violated rule #9 (No AI slop/predominantly AI content).\n\nYou post was flagged as an AI generated post. We as a community value human engagement and encourage users to express themselves authentically without the aid of computers.\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-01-23 08:53:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1anon1",
          "author": "pfletchdud",
          "text": "Depends on what you‚Äôre replicating to. ClickHouse, snowflake, and Databricks all have native options (some better than others‚Ä¶). \n\nIf you‚Äôve had enough of managing Kafka yourself but you like the latency, my company (Streamkap) is a good option as are companies like Estuary, Artie.",
          "score": 1,
          "created_utc": "2026-01-23 19:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ewffj",
          "author": "gelyinegel",
          "text": "This issue is solved and completely simplified have look at the project, simple feature rich and scalable.\n\nhttps://github.com/memiiso/debezium-server-iceberg",
          "score": 1,
          "created_utc": "2026-01-24 12:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fvd8v",
          "author": "vettaiyan_001",
          "text": "  We are using oracle golden gate connector for databricks .. real time relocation of data works well",
          "score": 1,
          "created_utc": "2026-01-24 15:38:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jr1mb",
          "author": "eccentric2488",
          "text": "Debezium CDC to connect to the database transaction log. Capture and emit change events as stream, use Kafka (one topic per table) to durably store the events, use Spark/Flink for processing or transformation and finally push these events to the sink. It could be a warehouse (fact tables) or data lake (bronze layer).",
          "score": 1,
          "created_utc": "2026-01-25 02:49:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1savbl",
          "author": "Low_Brilliant_2597",
          "text": "\nHi, you could try a stream processing system like RisingWave that unifies Postgres CDC ingestion, real-time processing, and Apache Iceberg writes in a single platform. This removes a lot of the multi-component overhead (Debezium + Kafka Connect + Airflow + extra compaction jobs) and reduces failure points while still letting you keep tables continuously synced to your lake/warehouse.",
          "score": 1,
          "created_utc": "2026-01-26 08:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17an17",
          "author": "josejo9423",
          "text": "1. That is why hire you buddy\n2. Man that depends on the product analytics requirements, like don‚Äôt you just have a single connector and in the configuration can add comma string separated with the tables you need? If useful use k8s with strimzi makes your life way easier\n3. That‚Äôs a different problem, the db should not be backlogging, just increase disk, if not possible, think if you can partition the table and drop the partitions then move them to s3, backlogging is separate problem from replication",
          "score": 1,
          "created_utc": "2026-01-23 07:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16bl46",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -17,
          "created_utc": "2026-01-23 03:38:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16fy3n",
              "author": "finally_i_found_one",
              "text": "Bro if I wanted an AI to answer this I could have asked chatgpt myself.\nThe point of asking a community is to learn from experiences, not generic AI bullshit.",
              "score": 10,
              "created_utc": "2026-01-23 04:04:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o16fi9l",
              "author": "EconomixTwist",
              "text": "How about we Fiveban these slop posts. Where the fuck does elt come into this??\n\nEDIT: The fart-Tran marketing bozo literally forgot to remove the first sentence of Chad gbt telling him ‚Äúheres a Reddit style version you can paste‚Äù LMAOOOO",
              "score": 5,
              "created_utc": "2026-01-23 04:02:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o16h2qh",
              "author": "quickdraw6906",
              "text": "We've had little maintenance using HVR (now Fivetran) over the last 8 years. Schema evolution handled as best as can be expected. Full reloads are still a thing though. Fact of life. Switching out now to Debezium + Redpanda. Connector quality is definitely variable (using a community connector for IBM i DB2)",
              "score": 0,
              "created_utc": "2026-01-23 04:11:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qiylvo",
      "title": "Interesting Links in Data Engineering - January 2026",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qiylvo/interesting_links_in_data_engineering_january_2026/",
      "author": "rmoff",
      "created_utc": "2026-01-21 13:59:38",
      "score": 32,
      "num_comments": 2,
      "upvote_ratio": 0.97,
      "text": "Here's January's edition of Interesting Links: https://rmoff.net/2026/01/20/interesting-links-january-2026/\n\nIt's a bumper set of links with which to kick off 2026.\nThere's lots of data engineering, CDC, Iceberg‚Ä¶and even _whisper_ some quality AI links in there too‚Ä¶but ones that *I* found interesting with a data-engineering lens on the world. \nSee what you think and lmk.",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qiylvo/interesting_links_in_data_engineering_january_2026/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0w0owc",
          "author": "ArgenEgo",
          "text": "Thank you! I've started reading your links in November and have gone back to older posts to have more :)",
          "score": 4,
          "created_utc": "2026-01-21 17:24:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0w7mms",
              "author": "rmoff",
              "text": "Glad you find it useful :) There are certainly plenty in the history to go through!",
              "score": 1,
              "created_utc": "2026-01-21 17:55:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}