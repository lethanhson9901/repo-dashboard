{
  "metadata": {
    "last_updated": "2026-02-11 03:30:00",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 312,
    "file_size_bytes": 353191
  },
  "items": [
    {
      "id": "1qvizak",
      "title": "Data Engineering as an After Thought",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/pdqlix94tfhg1.png",
      "author": "uncertainschrodinger",
      "created_utc": "2026-02-04 08:20:10",
      "score": 506,
      "num_comments": 22,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qvizak/data_engineering_as_an_after_thought/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3igd75",
          "author": "meatmick",
          "text": "Yeah... Their tools are also sometimes python scripts, written with AI (nothing againstAI for code but not like this) and are unmaintainable pieces of garbage...\nAll that for the small price of hundreds of thousands of dollars if not millions. Ask me how I know lol",
          "score": 195,
          "created_utc": "2026-02-04 11:23:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3imfy3",
              "author": "TheFach",
              "text": "I probably know the same way as you but tell the story man",
              "score": 41,
              "created_utc": "2026-02-04 12:10:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3jach2",
                  "author": "meatmick",
                  "text": "One of those 3 companies was hired to find things to optimize in our processes. They clearly sold us the dream of saving millions, which so far doesn't look like it'll ever be the case. To do their dream stuff, we needed to provide a shit-load of data from all manners of business units in the company. Then this data gets normalized by them and fed in their \"tool\". The tool uses AI to find the \"things to optimize\". Now the department that paid for this crap is trying to pawn the maintenance off on us in IT. The company also doesn't provide help on how to normalize data to fit their tool, and guess who will probably also be in charge of doing it? So far, they have not found any significant savings and the ROI vs how much their cost (1+ million so far) will take years, if it ever pays back.\n\n  \nAs others have said, it's ok because our VPs can say we're AI enabled.",
                  "score": 49,
                  "created_utc": "2026-02-04 14:31:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ip8di",
              "author": "uncertainschrodinger",
              "text": "As long as the VP can tell execs \"we are AI enabled now\" in the next quarterly report, then it's worth every penny.",
              "score": 36,
              "created_utc": "2026-02-04 12:30:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3l4xoc",
                  "author": "TheFach",
                  "text": "I guess this is sadly the reality of the moment",
                  "score": 3,
                  "created_utc": "2026-02-04 19:40:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3k1zfs",
              "author": "mertertrern",
              "text": "This has been the game with these companies for a long time. Before AI, the term used was \"Machine Learning\", but the pitch was the same. Before that, it was \"Semantic Model\" or \"OLAP Cube\". It's always the same: \"give us your data and $1M, and we'll give you back a miracle\". It's always too good to be true though.",
              "score": 12,
              "created_utc": "2026-02-04 16:42:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3lc506",
                  "author": "South_Candle_5871",
                  "text": "Agreed with the sentiment, but semantic models are real and useful abstractions to non tech data consumers",
                  "score": 2,
                  "created_utc": "2026-02-04 20:15:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qdo86",
                  "author": "JJ3qnkpK",
                  "text": "Working with the resultant product of a major tech consultancy now. I've noticed that they absolutely *fixate* on using a particular suite of products even if they're horrendous solutions to the actual problem. It's like they're trying to farm case studies for how good said suite of products is rather than use the best tool for the job.\n\nIn this case: Microsoft stuff. I've got a Synapse instance with a freakish set of pipelines and notebooks to make it function even somewhat like Databricks. This was a clean slate start from only a few years, so they could have chosen any product, but instead they chose to go all-in on Microsoft.\n\nInstead, this client company paid that consultancy tons of money to custom build janky code on an old platform when they could have saved so much time and money by just using tools made for the job. Now they're digging deeper trying to make this weird stuff work. But hey, at least you got a cool PowerPoint with a bunch of tech product logos with arrows pointing between them (and no description about how said diagram represents an actual solution to the problems at hand).\n\nRabble rabble rabble..",
                  "score": 2,
                  "created_utc": "2026-02-05 15:40:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iuwg7",
          "author": "Rift-enjoyer",
          "text": "Well It was a 3 week project, and the IT said it will take 2 weeks to just get access to data. Also the exec only paid for a POC + a roadmap slides that can score him the next year's bonus.",
          "score": 46,
          "created_utc": "2026-02-04 13:06:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jciy0",
          "author": "decrementsf",
          "text": "Professional maturity is recognizing when to laugh when the consultant leaves the room. Does your boss need political cover for a decision that must be made? That is the only time to use the consultant. Nobody got fired when the consultants advice didn't work out. They're an insurance product.",
          "score": 42,
          "created_utc": "2026-02-04 14:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jgt7o",
              "author": "passing_marks",
              "text": "Yeah a consultant that worked with us said it openly! Blame it on us üòÇ I don't know if that makes me believe in them or not lol",
              "score": 19,
              "created_utc": "2026-02-04 15:04:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ujbws",
              "author": "zazzersmel",
              "text": "pretty sure I was the consultant in this scenario, and the consultancy fired me.",
              "score": 2,
              "created_utc": "2026-02-06 04:38:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jgy7f",
          "author": "glubglublub",
          "text": "As a side question, does any of these companies do any good projects? I feel like they're a fraud at this point lol",
          "score": 14,
          "created_utc": "2026-02-04 15:04:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lbgu9",
          "author": "klubmo",
          "text": "I work for a medium size consulting firm that often gets contracts to come and fix the ‚Äúwork‚Äù that these big companies sold. Often that means completely needing to redo everything from scratch. C-suite loves these big companies, but the directors have to convince the VPs to use us constantly to fix the big firms screw ups.\n\nIt‚Äôs a very expensive way to run a business.",
          "score": 11,
          "created_utc": "2026-02-04 20:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lassb",
          "author": "engineer_of-sorts",
          "text": "Massive fuck you to all the consultants out there getting paid to literally churn out tech debt",
          "score": 12,
          "created_utc": "2026-02-04 20:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ip4tx",
          "author": "Morpheyz",
          "text": "Are you me?",
          "score": 6,
          "created_utc": "2026-02-04 12:29:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42tjuk",
          "author": "Environmental_Row32",
          "text": "They work the same way in AI they worked in any other hype. \nWe have a great tool/method, pitch to board, sell a POC and some slides, pick the easiest win ever imaginable for your POC. Take the money. Sell governance for the company wide rollout and pawn the implementation of to a partner, blame the partner company which was in charge of doing the work for the failed rollout for the failed rollout.\n\nIt is a good business modell",
          "score": 1,
          "created_utc": "2026-02-07 13:41:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oecxn",
          "author": "redeyedbiker",
          "text": "Ugh, all my homies hate BCG",
          "score": 1,
          "created_utc": "2026-02-05 06:59:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwrxe8",
      "title": "Notebooks, Spark Jobs, and the Hidden Cost of Convenience",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/g2mm7qq5lphg1.jpeg",
      "author": "mwc360",
      "created_utc": "2026-02-05 17:41:38",
      "score": 398,
      "num_comments": 91,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwrxe8/notebooks_spark_jobs_and_the_hidden_cost_of/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3rw2pa",
          "author": "Rycross",
          "text": "Whether its a notebook or not isn't really the issue.  The issue is whether there is a proper version control, change control, and rollback process.  Notebooks *usually* don't have that in practice.  But you can do VC, CI/CD, and testing with notebooks.  If you do then there's nothing wrong with using them in prod.\n\n\nSome more thoughts: The issue that I usually see in practice is that once you start introducing these things then notebooks' convenience is reduced, so there's a lot of resistance against controls that prevent people from just yeeting something into production.  And once you let people yeet their non-important work, its only a matter of time before people start yeeting important work.",
          "score": 77,
          "created_utc": "2026-02-05 19:51:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x4565",
              "author": "LandlockedPirate",
              "text": "Except that notebooks also frequently rely on side effects, %run, magic commands, comments that are actually code in a different language (sql),  typically don't have a dependency manifest, typically don't have tests etc.  The code can't really be processed correctly by commodity static code analyses tools, is painful to merge (jupyter), sometimes also contains results (jupyter) etc.\n\nYes I know you \\_can\\_ do some of these things, you \\_can\\_ avoid %run and magic commands, you \\_can\\_ avoid relying on side effects, but the tooling doesn't help.  On a large project or team the tooling is what makes it actually happen.",
              "score": 8,
              "created_utc": "2026-02-06 15:50:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4279g5",
                  "author": "No_Mongoose6172",
                  "text": "I think this shows that there's room for new tools that have the advantages of notebooks (like being able to use markdown, math expressions and photos in your comments to better document its behaviour) while avoiding those problems\n\nA production oriented notebook based ide would be great. In that sense, I like Matlab approach for notebooks, as it uses normal text files for storing them with special comments for identifying cells, equations, photos, bullet points and so on (so notebooks can also be executed like a normal script)\n\nEdit: I would love to be able to generate pdf files from my C/C++ tests with plots. It would be great for documenting scientific code (like an advanced version of something like doxygen with notebook like features)",
                  "score": 3,
                  "created_utc": "2026-02-07 10:45:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3r8uat",
          "author": "GrumDum",
          "text": "If people who used notebooks in prod could read, they would be very angry right now.",
          "score": 298,
          "created_utc": "2026-02-05 18:04:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rl8y3",
          "author": "scataco",
          "text": "Quality is subjective.\n\nIf \"most prod jobs\" are for dashboards that nobody uses, who cares if the data is consistent, interpretable and accurate!",
          "score": 89,
          "created_utc": "2026-02-05 19:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rxfvj",
              "author": "jimtoberfest",
              "text": "Someone fast track this guy to senior management",
              "score": 79,
              "created_utc": "2026-02-05 19:57:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s2exm",
                  "author": "scataco",
                  "text": "Nooooo!",
                  "score": 10,
                  "created_utc": "2026-02-05 20:21:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3svei7",
                  "author": "jun00b",
                  "text": "I'm working on a spot bonus right now.",
                  "score": 5,
                  "created_utc": "2026-02-05 22:42:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xgkld",
                  "author": "LandlockedPirate",
                  "text": "Get him an agentic coding workflow and he'll be a 1 man army",
                  "score": 1,
                  "created_utc": "2026-02-06 16:49:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vjpfw",
              "author": "CAPSLOCKAFFILIATE",
              "text": "> for dashboards that nobody uses\n\nI feel my neck veins bulging as I read this part.",
              "score": 6,
              "created_utc": "2026-02-06 09:51:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3y3k89",
              "author": "st4reater",
              "text": "Why have the dashboard then",
              "score": 1,
              "created_utc": "2026-02-06 18:38:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rapf9",
          "author": "CrowdGoesWildWoooo",
          "text": "Well databricks ‚Äúnotebook‚Äù aren‚Äôt literal notebook.",
          "score": 77,
          "created_utc": "2026-02-05 18:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3riyps",
              "author": "TripleBogeyBandit",
              "text": "This, you can have python files with a comment at the top ‚ÄúDatabricks notebook source‚Äù and it render as notebook in the ui but allow for test suites.",
              "score": 52,
              "created_utc": "2026-02-05 18:50:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xfpus",
                  "author": "LandlockedPirate",
                  "text": "Ok, i'll bite.  \n\nHow do you write tests around your non python cells?",
                  "score": 3,
                  "created_utc": "2026-02-06 16:45:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3tm7e6",
              "author": "TheRealStepBot",
              "text": "They were and once they realized how bad it was to build a platform on notebooks they have spent a better part of a decade trying to tack standard software development tooling onto them. They aren‚Äôt notebooks in only the most technical of ways. They still are square pegs trying to fit into the round hole that is the rest of software development.",
              "score": 10,
              "created_utc": "2026-02-06 01:13:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3uxlsp",
                  "author": "CrowdGoesWildWoooo",
                  "text": "The change to .ipynb default was recent, but it‚Äôs not like the ecosystem around the .py file was lacking or non-functional. \n\nAs in the issue with notebooks are inconsistency when it comes to commit because you are bringing the whole notebook state, and poor integration with testing suite. \n\nIf it behaves like a normal python file which you can do easily do testing, and it doesn‚Äôt carry the bad traits of a notebook, there‚Äôs no point to be pedantic.\n\nIt‚Äôs ironically like one of the common ‚Äúprinciple‚Äù in python. If it walks like a duck, quack like a duck‚Ä¶",
                  "score": 4,
                  "created_utc": "2026-02-06 06:27:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3sasrr",
              "author": "Atticus_Taintwater",
              "text": "Are they not? With dbr 15+ aren't they stored by default as ipynb and you have to change it to py, and I wonder how long that backward support will stick around",
              "score": 6,
              "created_utc": "2026-02-05 21:01:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3s10a4",
              "author": "Clean-Health-6830",
              "text": "Abstractions? In my software? Bah!",
              "score": 2,
              "created_utc": "2026-02-05 20:14:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ve5ml",
              "author": "SnowyBiped",
              "text": "to be fair, a few years back, in Databricks a notebook based job had better logging that a standard jobs.\n\nYou could see where there was a failure and just get that notebook and run it in the UI to replicate the problem.\n\nBut for what we were doing (copy some tables and run some SQL) Databricks was an overkill",
              "score": 1,
              "created_utc": "2026-02-06 08:57:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3s19dp",
              "author": "mwc360",
              "text": "I disagree. This works the same in Fabric, Synapse, and likely other platforms as well. A PySpark Notebook put into GIT has a bunch of comment lines that are used to parse where a cell begins/ends, magics, different cell languages, etc. ~~BUT, the actual thing in the platform backend is almost surely not a simple \\`.py\\` file, it is something more complex (i.e. \\`.ipynb\\` which is just JSON underneath) as it stores cell outputs, metadata, and other things which are not parsed into a \\`.py\\` file when the object is sync'd to GIT.~~ *Edited for those that can't see the forest through the trees:* this might have changed in DBX but this ultimately doesn't matter to my point that what is deployed to prod at the end of the day is a Notebook experience that comes with Notebook risks. Sure you can mitigate most of the risk with tests (and maybe CI validation to block usage of MAGICS that are untestable) and tight governance on your prod env, but it's still awkward.\n\nSo why does this matter? From a development perspective (and almost surely from a backend storage perspective) it is a Notebook by all measures. This matters as you can arbitrarily decide to use Scala or SparkSQL cells in your Notebook where PySpark is the default language, and when parsed into a \\`.py\\` file, none of those non-default language cells can be tested, type checked, linted, etc.. they show as commented out lines of code with a header that tells the platform's parser to interpret it as a specific language.\n\nSure, you could require your devs to not use multiple languages in a single Notebook and use an awkward process to ensure test coverage (awkward because you can't really start with local development, you'd have to do cloud>local>write tests and repeat, but even then you are still shipping into production something that comes with a built in IDE. At that point, only proper governance and access control can save you from a \"well it's super easy so I just directly applied the change in production\" scenario.",
              "score": -9,
              "created_utc": "2026-02-05 20:16:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3sb00z",
                  "author": "CrowdGoesWildWoooo",
                  "text": "Stop yapping bs, if you never used one.",
                  "score": 24,
                  "created_utc": "2026-02-05 21:02:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3sabye",
                  "author": "ADGEfficiency",
                  "text": "You are uneducated about this topic.",
                  "score": 17,
                  "created_utc": "2026-02-05 20:59:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rirkl",
          "author": "raskinimiugovor",
          "text": "I'll give you an example of how we use synapse notebooks (had no say in technology used, but generally it's enough for our needs) which are orchestrated via pipelines and triggers:\n\n* all processing logic is maintained in a custom python library covered with unit tests and a few integration tests, separate from transform logic\n* this custom library has very minor dependencies on Azure (only a few generic functions) and could be migrated to databricks or something similar if necessary\n* all notebooks import the library and use same flow, so everything is familiar from notebook to notebook\n* simple transformations are mapping based\n* more complex transformations are implemented in the notebooks but they can only output a dataframe (later handled by processing module), they can't write to the env directly or depend on some global variables (in some cases wrapper functions can be used to circumvent that)\n* changes are committed and deployed using CI/CD\n* development and debugging is generally done directly in the notebook but has no effect until it ends up on the main branch and becomes a part of the project\n* in most cases when something fails, it's related to env or env specific data and most convenient way is to debug it via notebook which is already part of the isolated workspace and connected storage accounts\n\nDo you think there's anything wrong with this workflow and how would spark jobs improve it?",
          "score": 19,
          "created_utc": "2026-02-05 18:49:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rnkeg",
              "author": "instamarq",
              "text": "If it reliably delivers the goods in a maintainable, secure, easily audited and cost effective way, the job has been done well.",
              "score": 12,
              "created_utc": "2026-02-05 19:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s2pgd",
                  "author": "mwc360",
                  "text": "100%. If your process is working well, this blog shouldn't make you question everything about your existing process. If you find that your process makes it hard to deliver reliability outcomes, that's when I'd question what parts can be improved. What you've described seems quite clean.",
                  "score": 2,
                  "created_utc": "2026-02-05 20:23:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ry9lw",
              "author": "fuhgettaboutitt",
              "text": "Without the notebooks, this is the approach my old team came up with a few years ago but we exposed the library as YAML and as the direct library. Its HARD to implement, but you know exactly how to get something reliably in prod, the uplift of data science toolkit into prod came down to days. More complex transformations were required to implement unit tests and be stored in code and reviewed as regular software. You knew the training pipe and the prediction pipe were exactly the same for transformations, so any modifications at a lower level were tested by the tests for that lower level function, as well as all of the pipes utilizing that funciton. DS only lived in notebooks as long as the project was exploratory, notebooks were sourced from a default notebook that could be checked out and had all of our pip installs and configurations loaded.",
              "score": 2,
              "created_utc": "2026-02-05 20:01:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3t72p3",
          "author": "Sufficient_Example30",
          "text": "Honestly,i don't agree with this sentiment.\nI've found notebooks in production extremely useful, especially when things have gone wrong .\nIt makes things easier for me to explain to business at what step the pipeline failed via visuals.\nIn ML workload environments ,it allows data science a chance to know from where things have gone awry easily and provides them with like a base code to fix their model.\nEverything is a trade off ,\nThere's also a cost of ci/cd  a script and a hidden cost of going the pipeline route.,maintaining multiple environments etc\nThe only difference is you build more stuff to show things for more stake holder confidence.\nI think you should decide your approach on a pipeline to pipeline basis.\nNot everyone is gonna agree with my sentiment but i heavily disagree with the post\n\n====\nI also disagree with the notion that the code being harder to test.\nIn my opinion data pipelines should be tested end to end with data and while testing see how each transformation affects stuff and using dequeue log stuff correctly.\nWriting testable code has nothing to do with using  a notebook and all common stuff can be written as a .python file of a pip package.",
          "score": 12,
          "created_utc": "2026-02-05 23:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s4ngi",
          "author": "mttpgn",
          "text": "I will refuse to share my demo notebooks for exactly this reason. \"Obviously it'll need to be productionalized first.\"",
          "score": 5,
          "created_utc": "2026-02-05 20:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s8akh",
          "author": "tjger",
          "text": "I like using notebooks for the entry points. Notebooks help explain the pipeline / job better than just plain code.",
          "score": 3,
          "created_utc": "2026-02-05 20:49:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3t4e6c",
              "author": "Teddy_Raptor",
              "text": "This is why marimo is cool. Notebook interface book backed by . Py fines",
              "score": 2,
              "created_utc": "2026-02-05 23:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3u60h4",
          "author": "Ted_desolation",
          "text": "Im in fabric. I have no choice in the matter so don't blame me.",
          "score": 3,
          "created_utc": "2026-02-06 03:11:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uxqgk",
              "author": "mwc360",
              "text": "Would love to learn more. Have you tried Spark Job Definitions or is this more of a team culture thing?",
              "score": 1,
              "created_utc": "2026-02-06 06:28:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3udhzu",
          "author": "focused_entrepreneur",
          "text": "But why? I love Databricks notebooks.",
          "score": 3,
          "created_utc": "2026-02-06 03:58:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42evcw",
              "author": "EntertainmentOne7897",
              "text": "People say you cant do this and that with notebooks which is not true. You can do all that but it seems that people writing notebook might be lazy and not do all the production ready things. Which is just an idea living in their head.",
              "score": 1,
              "created_utc": "2026-02-07 11:55:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3v9if7",
          "author": "skippy_nk",
          "text": "I agree with the post but I'll comment on another thing that I see people use to counter argue this idea.\n\nThere's this argument that notebooks make the code more explainable to stakeholders.\n\nBut really, code is not for the non-coders and they shouldn't bother with it. I prefer not to show the code to them, especially if it's in notebooks, and especially now with all this GenAI stuff. It's because notebooks make the code look simple to non technical folks. It's due to the cell layout, I believe, that they get the feeling it's basically not much more than excel formulas, while in reality, there's a huge clusterfuck of moving parts underneath. \n\nAnd there's always this one manager that half assed a Python for DE course on Udemy and \"wants to help\". Of course, we end up losing our precious time by going over their slop because we can't just tell them to fuck off and do their job and we'll do ours. \n\nCode explainability (to stakeholders) should not be a thing, ideally. Basically, development experience beats the explainability argument all day long.",
          "score": 3,
          "created_utc": "2026-02-06 08:13:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x2w5c",
          "author": "miker5555",
          "text": "Honestly this matches my experience too. Notebooks are great for exploration, but once something is ‚Äúreal,‚Äù they tend to turn into a dumping ground of half-run cells and mystery state.\n\nEvery prod issue I‚Äôve debugged that started with ‚Äúbut it worked in the notebook‚Äù ended up costing way more time than just writing the job cleanly from the start.\n\nStill‚Ä¶ I‚Äôll admit I keep one notebook around to poke at data before doing it the right way üòÑ",
          "score": 3,
          "created_utc": "2026-02-06 15:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s10ot",
          "author": "Throwaway999222111",
          "text": "I export as a .py and the script does the same thing, I just rename it as prod. That isn't what others do? Notebooks are for dev I thought",
          "score": 6,
          "created_utc": "2026-02-05 20:14:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3y450j",
              "author": "st4reater",
              "text": "A notebook is - a notebook. You need to ensure parity between what you develop and what you push to prod. Otherwise, how can you say you know what you're pushing, and what you tested represents what users will meet?",
              "score": 1,
              "created_utc": "2026-02-06 18:41:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rbdzx",
          "author": "Tushar4fun",
          "text": "You said notebooks - I heard HTML/CSS",
          "score": 4,
          "created_utc": "2026-02-05 18:16:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s7bpa",
          "author": "Arnechos",
          "text": "Using notebooks in databricks when you only write pysprark code is laziness given the option to run python script/wheel task",
          "score": 2,
          "created_utc": "2026-02-05 20:45:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v8bgn",
              "author": "ephemeralentity",
              "text": "But what if you want to make it easy to debug? If you are using PySpark you are likely doing data transformation. What is the benefit of converting that to a py file? You lose the ability to step through it next time you want to make changes. Worse, if you package in a whl you have to constantly recompile it.\n\nThere are circumstances where notebooks become inefficient, e.g. software engineering (not data engineering applications), where you have a large number of imports / component class modules and you don't want to have to instantiate them all in your notebook environment or have a large number of notebook dependencies but for simpler data transforming logic, they work well.",
              "score": 2,
              "created_utc": "2026-02-06 08:02:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3v9y83",
                  "author": "Arnechos",
                  "text": "\\> e.g. software engineering (not data engineering applications)\n\nThis is weird distinction for me, data engineering is software engineering with data product at the end.\n\n>But what if you want to make it easy to debug? If you are using PySpark you are likely doing data transformation. What is the benefit of converting that to a py file? You lose the ability to step through it next time you want to make changes. Worse, if you package in a whl you have to constantly recompile it.\n\nProper logging and stack traces already give you the debugging what is happening in production. I'm not saying don't use notebooks during development. The package argument is kinda silly, like with uv, CI/CD and IaC it's trivial - even so today when you can have claude/codex to whip up yamls\n\n\\>¬†simpler data transforming logic, they work well.\n\nFor this you could even use a GUI tool. ",
                  "score": 2,
                  "created_utc": "2026-02-06 08:17:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3uxtt7",
          "author": "DoubleAway6573",
          "text": "I'll take the bait.\n\n\nAny prod at all should be notebooks.\n\n\nAre you convinced?",
          "score": 2,
          "created_utc": "2026-02-06 06:28:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sa0um",
          "author": "SBolo",
          "text": "Most?? No prod job should be a notebook",
          "score": 3,
          "created_utc": "2026-02-05 20:58:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ske81",
              "author": "Sagarret",
              "text": "I would say something like around 95% or more.\n\nFor really simple tasks they are okay.\n\nBut yes, I totally agree and that was one of the main reasons why I left DE",
              "score": 4,
              "created_utc": "2026-02-05 21:48:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wipi8",
          "author": "Nekobul",
          "text": "Finally Miles, you are starting to see the light. But your journey will not be complete until you start to reject Spark as Anathema and not needed for the vast majority of the solutions.",
          "score": 1,
          "created_utc": "2026-02-06 14:02:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4k4ksw",
              "author": "mwc360",
              "text": "ü§£",
              "score": 1,
              "created_utc": "2026-02-10 04:10:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wq9at",
          "author": "geeeffwhy",
          "text": "i mean, i tend to agree‚Ä¶ but at the same time, a notebook is just a python file. nothing stops you from structuring your program reasonably with a notebook. it feels like a resurgence of one of my favorite old ideas, Literate Programming. \n\nSometimes the convenient interface is useful, even in prod. you can still have tests and types and clearly defined interface, modules, abstraction, etc.",
          "score": 1,
          "created_utc": "2026-02-06 14:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x7973",
          "author": "dillanthumous",
          "text": "Blanket statements are rarely true and often clickbait. Change my mind.",
          "score": 1,
          "created_utc": "2026-02-06 16:05:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xjnj5",
              "author": "mwc360",
              "text": "Ok. **Most** is not a blanket statement. Change my mind.",
              "score": 2,
              "created_utc": "2026-02-06 17:03:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xdqi7",
          "author": "sleeper_must_awaken",
          "text": "\n\n",
          "score": 1,
          "created_utc": "2026-02-06 16:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41n5ya",
          "author": "ds1841",
          "text": "Honestly they're much better than the fucking mess we've got with talend over time, but without using git it's a big risk.",
          "score": 1,
          "created_utc": "2026-02-07 07:29:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41vskr",
          "author": "Wonderful-Fold1364",
          "text": "What is a notebook ?",
          "score": 1,
          "created_utc": "2026-02-07 08:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ihcd",
          "author": "goldi8",
          "text": "You are right... But tell that Netflix they developed Papermill ü§£",
          "score": 1,
          "created_utc": "2026-02-08 11:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wo5ft",
          "author": "Mario4272",
          "text": "The fk you saying?",
          "score": 0,
          "created_utc": "2026-02-06 14:31:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3usm9e",
          "author": "shennan-lane",
          "text": "What about a well written Marimo",
          "score": -1,
          "created_utc": "2026-02-06 05:46:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy6ca4",
      "title": "AI engineering is data engineering and it's easier than you may think",
      "subreddit": "dataengineering",
      "url": "https://www.datagibberish.com/p/ai-powered-apps-dictionary-for-data-engineers",
      "author": "ivanovyordan",
      "created_utc": "2026-02-07 06:20:37",
      "score": 184,
      "num_comments": 31,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qy6ca4/ai_engineering_is_data_engineering_and_its_easier/",
      "domain": "datagibberish.com",
      "is_self": false,
      "comments": [
        {
          "id": "o42kx1t",
          "author": "DisjointedHuntsville",
          "text": "‚ÄúData engineering is just software engineering and it‚Äôs easier than you think‚Äù\n\n‚ÄúSoftware engineering is just an abstraction of mathematics and it‚Äôs easier than you think‚Äù\n\n‚ÄúMathematics is an abstraction of formally provable empirical observations and its easier than you think‚Äù\n\nFor fucks sake. . . The worst part of the data engineering world is the overkill on needless categorization of work to justify a role.",
          "score": 91,
          "created_utc": "2026-02-07 12:44:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43x5tu",
              "author": "decrementsf",
              "text": "The simplest possible form is trim out the incantations and have direct access to the upstream money printer sinecure. It's a silly game. Dilbert provided a good summary.",
              "score": 4,
              "created_utc": "2026-02-07 17:07:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48gfa9",
                  "author": "dillanthumous",
                  "text": "Don't forget to sing the appropriate psalms while communing with the Omnisiah.",
                  "score": 3,
                  "created_utc": "2026-02-08 11:00:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o448tzh",
              "author": "goatcroissant",
              "text": "It‚Äôs not that serious. I thought it was a decent write up.",
              "score": 3,
              "created_utc": "2026-02-07 18:05:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o463pkf",
              "author": "TechnicallyCreative1",
              "text": "Title was click bait, the content wasn't terrible. The sentiment was that data organization is important. That is all",
              "score": 2,
              "created_utc": "2026-02-08 00:09:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42fd55",
          "author": "mint_warios",
          "text": "AI engineering existed way before LLMs. Agree there's a lot of overlap with \"classical\" data engineering, but there's so much more to AIE/MLE than LLM pipelines and RAG mechanisms",
          "score": 62,
          "created_utc": "2026-02-07 11:59:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42fyoy",
              "author": "MonochromeDinosaur",
              "text": "MLE and AI Engineering are completely separate job descriptions. \n\nAI Engineering roles are essentially just web development using LLMs with a side of data engineering.\n\nMLE is Data Engineering+MLOps+actual understanding of ML.",
              "score": 39,
              "created_utc": "2026-02-07 12:04:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o488mih",
                  "author": "xorgeek",
                  "text": "What is MLops",
                  "score": 2,
                  "created_utc": "2026-02-08 09:46:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o445ctx",
                  "author": "Blaze344",
                  "text": "Proper AI engineering should have at least some basic ML knowledge behind the things being built. Knowing the best way to represent information from retrieval, running experiments to get the F1 score of the current solution, knowing how to debug all the moving pieces to find which one is bottle necking...\n\nThere's a lot of web dev, tho, that's true, and MLE is the one that really grits into true ML territory. It's just that current AI is \"powerful enough\" (quotes required) that you can make do without having the core skills and deliver something, just in spite of how powerful things are. Sort of how we have so much compute no one cares about delivering something memory aware nowadays, too...",
                  "score": 2,
                  "created_utc": "2026-02-07 17:48:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o42fp1f",
              "author": "ivanovyordan",
              "text": "I 100% agree with you here. But you will also agree that in 2026 AI means LLM for most people.",
              "score": 9,
              "created_utc": "2026-02-07 12:02:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o42yszk",
          "author": "genobobeno_va",
          "text": "I concur. It‚Äôs all pipelines.",
          "score": 14,
          "created_utc": "2026-02-07 14:12:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xo4e",
              "author": "decrementsf",
              "text": "There is a non zero chance this is the same as medical students experiencing every medical condition they study in sequence. Humans are a pattern recognition machine interpreting stimulus through the bounds of the information already known. What do I know? Predict what happens next. Surprise or affirms the machine is working. Output -> It's all pipelines.",
              "score": 2,
              "created_utc": "2026-02-07 17:10:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44glc8",
          "author": "gnomehearted",
          "text": "AI engineering's existence makes me want to leave the industry wholesale",
          "score": 8,
          "created_utc": "2026-02-07 18:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44juk7",
              "author": "ivanovyordan",
              "text": "A friend of mine left his job on Friday because he felt unappreciated contary to folks who build LLM solutions.\n\nWhat exactly is the thing that you dislike?",
              "score": -1,
              "created_utc": "2026-02-07 18:59:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o45fm0k",
                  "author": "Aggravating-One3876",
                  "text": "For me it‚Äôs what you can tour AI all day long but management only hears that you can do your job faster. If you can do your job faster then let‚Äôs move up deadlines and if you can get push back it‚Äôs pretty much ‚Äúwell AI should make it faster‚Äù.\n\nThe other issue is that AI makes senior devs spend more time cleaning up the AI code that gets put into production and it robs junior devs of experience in debugging. \n\nFor me the only reason to use AI is that deadlines become unreasonable and that is in part of people overselling what AI can do. Then when you do use AI it can give you wrong answers so hopefully you look at the code that you are putting in. \n\nSo for me AI does not benefit DE and is only to shorten deadlines and put pressure to preform, thus forcing you to use it just to keep up.",
                  "score": 2,
                  "created_utc": "2026-02-07 21:48:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ba5ct",
                  "author": "lolsillymortals",
                  "text": "Your friend sounds like a spoiled worker bee.\n\n‚ÄúI‚Äôm not getting the glory I used to, I‚Äôm going to throw a fit and go get another job where they think what I‚Äôm doing is amazing again! One more pat on the back is all I‚Äôm asking for!‚Äù",
                  "score": 1,
                  "created_utc": "2026-02-08 20:29:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o459gtj",
          "author": "constantly-pooping",
          "text": "probiabtistic?",
          "score": 4,
          "created_utc": "2026-02-07 21:15:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45atns",
              "author": "ivanovyordan",
              "text": "Ha-ha. That's how you know I don't use AI to write. :D\n\nThanks for that. Won't fix it though. It's funny",
              "score": 1,
              "created_utc": "2026-02-07 21:22:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46dqwq",
          "author": "Procrastinator9Mil",
          "text": "A post from someone who doesn‚Äôt understand neither.",
          "score": 2,
          "created_utc": "2026-02-08 01:09:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47labx",
              "author": "ivanovyordan",
              "text": "Interessting. What made you think so?",
              "score": 1,
              "created_utc": "2026-02-08 06:10:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fvakj",
          "author": "Thinker_Assignment",
          "text": "Thanks for this one, the community needs to hear this more, the AI layer is definitely more easily served by DEs than new SEs as AIEs",
          "score": 2,
          "created_utc": "2026-02-09 14:50:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4h51cf",
              "author": "ivanovyordan",
              "text": "I appreciate it!",
              "score": 1,
              "created_utc": "2026-02-09 18:30:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o47tdev",
          "author": "PracticalBumblebee70",
          "text": "Written by data engineer¬†",
          "score": 1,
          "created_utc": "2026-02-08 07:23:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47w72t",
              "author": "ivanovyordan",
              "text": "True",
              "score": 2,
              "created_utc": "2026-02-08 07:49:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4drc9f",
          "author": "EviliestBuckle",
          "text": "What is ideal tech stack these days? Also can you suggest some beginners courses?",
          "score": 1,
          "created_utc": "2026-02-09 04:43:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42pdpb",
          "author": "Illustrious_Role_304",
          "text": "is AI engineering is mandatory for data engineering  now ? Any recent interview experience ?",
          "score": 1,
          "created_utc": "2026-02-07 13:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42s4f1",
              "author": "ivanovyordan",
              "text": "From a hiring manager point of view, I'd say no.\nBut the tuth is that it's very easy and some \"broader\" knowledge can only help in interviews.",
              "score": 2,
              "created_utc": "2026-02-07 13:32:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o452rwa",
          "author": "dudeaciously",
          "text": "This is a beautiful, concise and meaningful article.",
          "score": 1,
          "created_utc": "2026-02-07 20:39:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45avt5",
              "author": "ivanovyordan",
              "text": "Thank you so much. I really appreciate this.",
              "score": 2,
              "created_utc": "2026-02-07 21:23:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxifq4",
      "title": "Is classic data modeling (SCDs, stable business meaning, dimensional rigor) becoming less and less relevant?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxifq4/is_classic_data_modeling_scds_stable_business/",
      "author": "Likewise231",
      "created_utc": "2026-02-06 14:02:24",
      "score": 118,
      "num_comments": 40,
      "upvote_ratio": 0.96,
      "text": "I‚Äôve been in FAANG for about 5 years now, across multiple teams and orgs (new data teams, SDE-heavy teams, BI-heavy teams, large and small setups), and one thing that‚Äôs consistently surprised me is how little classic data modeling I‚Äôve actually seen applied in practice.\n\nWhen I joined as a junior/intern, I expected things like proper dimensional modeling, careful handling of changing business meaning, SCD Type 2 being a common pattern, and shared dimensions that teams actually align on ‚Äî but in reality most teams seem extremely execution-focused, with the job dominated by pipelines, orchestration, data quality, alerts, lineage, governance, security, and infra, while modeling and design feel like maybe 5‚Äì10% of the work at most.\n\nEven at senior levels, I‚Äôve often found that concepts like ‚Äúensuring the business meaning of a column doesn‚Äôt silently change‚Äù or why SCD2 exists aren‚Äôt universally understood or consistently applied. In tech-driven organizations it is more structured, but in business-driven organizations it's less structued (Organization I mean ¬±100-300 people organization).\n\nMy logic is because compute and storage got so much cheapier over the years, the effort/benefit ratio is not there in as many situations. Curious what others think: have you seen the same pattern?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxifq4/is_classic_data_modeling_scds_stable_business/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3wqclv",
          "author": "JonPX",
          "text": "And then people wonder why data projects are so prone to failure.",
          "score": 133,
          "created_utc": "2026-02-06 14:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wlhq8",
          "author": "cream_pie_king",
          "text": "Yes.\n\nIt's because individual teams spin up their own analysts. Which then brute force their way into basically being shadow engineers. All in the name of \"faster time to insight\".\n\nProblem is, people leave, people shuffle around, people get promoted. No one aligns on what the metric really should be.\n\nIt eventually blows up in everyone's face when multiple versions of the same number hit the desks of execs and the board.\n\nThese embedded analyst fiefdoms resist change and take it as a personal insult when you tell them their 5000 line query that feeds one report is garbage, not scalable, and you can't run a business like this. \n\nYou're then targeted as slowing things down for trying to put real rigor into the data platform.\n\nI'm leaving an environment like this in a week. For a greenfield opportunity to build the stack from scratch precisely because I'm tired of this bullshit.\n\nI don't care about the minor and bootcamp you took in SQL and Python. That shit can't run a multi billion dollar business long term.\n\nHell I'm seeing intern built \"data science\" workloads being deployed. They're \"version controlled\" in SharePoint and run locally to push to reporting. When we push back it's our fault.",
          "score": 119,
          "created_utc": "2026-02-06 14:17:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wphxu",
              "author": "hectorgarabit",
              "text": ">¬†take it as a personal insult when you tell them their 5000 line query that feeds one report is garbage\n\nSome head of Analytics / BI told me, when I proposed some dimensional modeling that they were not interested in \"philosophy\". Their model is chaos and they spin countless hours untangling their spaghetti data model. They feel smart because they wrote a 1000 lines SQL query or Python notebook. They don't understand that they would be a lot smarter if their model was clean enough, so the same query only took 10 lines...\n\nThe main issue IMO is that many people come from a non-technical background, and they don't understand how data model, architecture solve the vast majority of development problems.",
              "score": 53,
              "created_utc": "2026-02-06 14:38:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xeot8",
              "author": "calaelenb907",
              "text": "Well, when you started with a green field to build an analytical system eventually you'll face the same problems you mentioned previously. People will like how your reports are accurate, faster and easier to navigate then previous ones but eventually they will target you as a person that slow things for put real rigor into the data platform yadada. Business people will act as business people even if the project is new.",
              "score": 3,
              "created_utc": "2026-02-06 16:40:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3wytyj",
              "author": "domscatterbrain",
              "text": "I always warn my manager to not to give users the freedom of running their own statements. Just drag and drop filters and pivot in their own custom dashboard is more than enough.\n\nToday by the power of chatgpt, they start creating more spaghetti. Their submitted statements looks very structured at a glance. But since, they don't give enough contexts to prompt and just copying their costly statements as is and  simply said \"this query is slow, optimize it\", the result is just anInstagramable spaghetti.",
              "score": 5,
              "created_utc": "2026-02-06 15:25:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wx36m",
          "author": "tophmcmasterson",
          "text": "No. \n\nThere are lots of people who don‚Äôt understand it and brute force implement sloppy bad practices for ad-hoc reporting. \n\nAnd then inevitably end users end up upset that the data is inflexible, report builders in tools like Power BI are seeing unexpected results, they need to make a new table or view every time they want to cross analyze things across tables, etc. \n\nAnd then the org calls on the person or consultant that actually understands data modeling to figure out where things went wrong. Or they just continue the cycle. \n\nIt‚Äôs not that it‚Äôs less relevant, it‚Äôs that there‚Äôs a huge number of developers who never understood it in the first place and think it‚Äôs not relevant because compute is faster and storage is cheap when those were never the main reasons to create a dimensional model in the first place.",
          "score": 15,
          "created_utc": "2026-02-06 15:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x5xrf",
          "author": "El_Guapo_Supreme",
          "text": "I agree with a lot of this, except the last bit about the effort to benefit not being there because of cost. You are right that compute got so cheap and efficient that people can be sloppy about architecture. \n\nBut the benefit still far exceeds the costs. The problem is leadership has a bias for action and expediency. It's hard to explain the proper modeling and architecture will make everything faster and easier down the road. \n\nBut will you get a reward for taking longer to do it correctly or fix what's broken? No. And if you have a great model, you'll never be able to point to problems that never manifested and how much time you saved. To the business it looks like you just took a long time.",
          "score": 11,
          "created_utc": "2026-02-06 15:59:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wwr5r",
          "author": "123456234",
          "text": "A few forces are pushing modeling out of the center:\n\n* Storage and compute keep getting cheaper, so the pressure to model everything 'correctly' up front is lower.\n* Dimensional modeling isn‚Äôt valuable by itself. Its real value is allowing systems to adapt as business meaning changes over time, and that benefit is easy to defer.\n* Tech debt is real, and under delivery pressure the cleanup backlog rarely wins. Even when modeling could be part of the design, timelines usually cut it first.\n* Storing source data indefinitely is becoming common, which makes replaying historical transformations feel like an acceptable substitute for managing change semantics.\n* Data teams are increasingly embedded in business units. Without a central steward, consistency across domains erodes even when the same underlying data is reused.\n* AI increases speed and lowers the cost of repetitive work, which further shifts effort toward shipping and iteration rather than integration rigor.\n* The idea of a single source of truth still matters philosophically, but if leadership doesn‚Äôt care when numbers don‚Äôt line up exactly, it‚Äôs hard to justify enforcing it.\n\nThe common thread is that modern data systems are optimized for reversibility rather than correctness. Cheap compute, infinite retention, replayability, and AI assisted iteration all increase tolerance for semantic drift. Dimensional modeling still addresses that problem, but its value only materializes when the organization is forced to care about consistency over time. \n\nModeling is rejected in favor of these other mechanisms which isn't a better approach but it does align with the systems that are readily available.",
          "score": 39,
          "created_utc": "2026-02-06 15:15:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44y0k4",
              "author": "raginjason",
              "text": "I would add to point 2 (and have done so in my organization): having a vocabulary  that every one can learn instead of being some home-grow data slop is tremendous value. If you don‚Äôt do dimensional modeling (which in reality is the only kind of modeling we use as DE), then people are calling the same concepts different words. Or mashing concepts together in a haphazard way.\n\nIf it were ‚Äúdimensional modeling vs some other modeling‚Äù I would be interested in discussion. It‚Äôs pretty much ‚Äúdimensional modeling or no modeling‚Äù, which I don‚Äôt have the patience for. This was solved over 20 years ago. The hubris of teams and organizations to think they know better than established practice is amazing to me, although extremely common.",
              "score": 3,
              "created_utc": "2026-02-07 20:13:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wxnos",
          "author": "RoomyRoots",
          "text": "LOL, no. The problem is that many companies think they are or they must be like FAANG sized ones with data projects to be successful with data products.\n\nIn the past 20 years most of the companies I worked wouldnt even be considerable to Big Data solution but still they would sink lots of money to try to mimic it.",
          "score": 8,
          "created_utc": "2026-02-06 15:19:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xg6cl",
          "author": "ding_dong_dasher",
          "text": "No they're just as relevant as before, it's just that enough platform engineers are clueless enough to not realize that this same failure-state has existed in our domain forever.\n\nIt's just in 2003 analysts were circumventing Oracle-based DW's in Excel instead of DS's marring your precious DBX deployment with AI slop.\n\nIt points to the same root cause of there having been a business need for something that the existing environment couldn't serve quickly enough. Nobody is going to tell some SVP who needs an answer yesterday that your first step is to attend the DE team's next backlog grooming session lol.\n\nThat's always going to happen and is just a reality of operating platforms used for decision support, if it feels like an adversarial thing you're probably looking at org dysfunction, not an architectural problem. Digesting analytical output and turning it into a mature reporting product is a pretty normal responsibility for data teams, imo.",
          "score": 5,
          "created_utc": "2026-02-06 16:47:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xhpi2",
          "author": "Rovaani",
          "text": "Infinite storage and compute won't help solve the problem if sales, manufacturing and logistics can't agree on what a  \"product\" or \"customer\" is or isn't and when their respective operational systems reflect that dichotomy and use different terms for same things ans same or similar terms for different things.\n\nTo solve that you need data modelling. Introduce your own terms or concepts if need be and map the source models to that. Then you can escape the trap of trying to understand several incompatible data models simultaneously just to feed the next dashboard.",
          "score": 3,
          "created_utc": "2026-02-06 16:54:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xwsp1",
          "author": "konwiddak",
          "text": "So I work for a company which several years ago purchased a drag and drop ETL tool, and handed out licenses to anyone who asked. It's an absolute mess. The tool is very expensive, and people have built these business critical monstrosities. There are workflows with over 70 inputs and outputs. IT wasn't really keeping tabs on the tool and are shitting a brick now they've realised what's out there propping up the business.\n\nFortunately there was a leader who let a few of us in the background do things properly. We've been unpicking one segment of the business for about 3 years now - and we're just finally getting to the point where people are going \"oh wow we get it now\". However, it's a constant battle to keep things under control and lots of people see us as the enemy.\n\nIf you can start well, do start well.",
          "score": 3,
          "created_utc": "2026-02-06 18:06:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ydgc5",
          "author": "kxlx_rxvi",
          "text": "I'm an entry level data engineer who started working a few months back, took courses on data warehousing and data modeling during college learnt the basics of SCDs, designing schemas and everything and loved doing it as hard as it was but haven't used any of these concepts even once so far at work.\nMakes me wonder why I spent sleepless nights learning all of these.",
          "score": 3,
          "created_utc": "2026-02-06 19:25:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42asqt",
              "author": "Data_cruncher",
              "text": "I‚Äôve said it before and I‚Äôll say it again: the value of Kimball only shines AFTER you‚Äôve tried deploying your first data warehouse.",
              "score": 2,
              "created_utc": "2026-02-07 11:18:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o44y45g",
                  "author": "raginjason",
                  "text": "That‚Äôs pretty good. I may have to steal this one.",
                  "score": 2,
                  "created_utc": "2026-02-07 20:13:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3x8tbv",
          "author": "Ploasd",
          "text": "Modelling is still important, if anything more important.",
          "score": 2,
          "created_utc": "2026-02-06 16:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40eqtj",
          "author": "drag8800",
          "text": "Honestly I think the answer depends a lot on the maturity of the org and the type of questions being asked. At places where speed to insight matters more than long term consistency, yeah people skip the modeling rigor because storage is cheap and nobody wants to wait 2 weeks for a proper star schema.\n\nBut I've seen it bite teams hard when they try to do anything cross-functional or longitudinal. Without SCDs or at least some versioning strategy you end up with a bunch of snapshots that don't stitch together and analysts reinventing the wheel every quarter.\n\nThe real issue is most teams don't feel the pain until they're 2-3 years in and by then the cost of retrofitting proper models is enormous. Classic modeling isn't dead, it's just expensive upfront and most orgs optimize for short term velocity.",
          "score": 2,
          "created_utc": "2026-02-07 02:01:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44ylkm",
              "author": "raginjason",
              "text": "Reflecting on what I have done with modeling, I admit that nobody wants to wait 2 weeks for a proper star schema. However, often you can take an engineering-first approach to star schema design and just get it done in short order. Technically you should engage business analysts and stakeholders and the like, but I‚Äôve seldom had engagement from those roles. So, do your best as an engineer, make something star-ish, and you‚Äôll be 90% of the way there.",
              "score": 2,
              "created_utc": "2026-02-07 20:16:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xd539",
          "author": "zx440",
          "text": "I'd say that \"traditional\" data modelling was becoming too rigorous, to heavy, and not agile. People were applying rules and methodologies blindly, without any real driver or value proposition. \n\nSo people went around it and went back to a tactical way of doing things. \n\nThere needs to be a middle ground. I think Data Contracts and Data Mesh are two of the very promising ways of implementing order in a chaotic data world within big (and small) enterprises. \n\nNot every data set needs SCD modelling. Not every team is ready to create a semantic layer, and you need to let people play around with the \"raw\" data before seeing a model emerge. A more decentralized data modelling approach is much more adapted for a modern world. ",
          "score": 2,
          "created_utc": "2026-02-06 16:33:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xy29b",
              "author": "cream_pie_king",
              "text": "Except that's not the reality of how everyone operates. They look at the raw data, hack together endless shadow pipelines and reports, management pushes for the next shiny thing and this tech debt becomes embedded in the org and the resulting data is shared broadly.",
              "score": 3,
              "created_utc": "2026-02-06 18:12:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3yb2ji",
                  "author": "zx440",
                  "text": "Yes, of course. I've been working to implement decentralized data approach for years. We has some success, but there's huge resistance from both sides.\n\n\"Traditionnal\" BI teams want to control everything and be in charge of all modeling, but are unable to deliver. Data consumers view any attempt at structuring their work as impeding their progress...\n\nBut eventually, they start to see the benefit of a more decentralized approach. BI team get a bit of air and can focus on platforming and infrastructure. Data consumers get the benefit of collaboration between teams that often run into the same issues.\n\nBut then management comes in, views decentralization as a menace to society, and just puts an end to this and force everyone to use the BI team... and we're back to square one...",
                  "score": 2,
                  "created_utc": "2026-02-06 19:14:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xqlmo",
          "author": "turboDividend",
          "text": "time is money. if the product works...what diff does it make?\n\nthats how mgmt look at things",
          "score": 1,
          "created_utc": "2026-02-06 17:36:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xrrda",
          "author": "OGMiniMalist",
          "text": "I‚Äôve had 3 interviews within as many months. All 3 wanted me to demonstrate my knowledge of data modeling in the interviews, IE what is a fact / dimension table? Have I ever made or used them in practice? What‚Äôs the difference between star and snowflake schema? Etc.",
          "score": 1,
          "created_utc": "2026-02-06 17:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44z2cp",
              "author": "raginjason",
              "text": "These are all very surface and any DE should be able to answer them honestly. That lack of depth suggests to me that if you worked for any of those places you would absolutely not be doing anything dimensional at all.",
              "score": 1,
              "created_utc": "2026-02-07 20:19:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xwaa9",
          "author": "aMare83",
          "text": "I don't think so. Even if your data platform is Databricks which is the ultimate choice these days, it does matter how you design the database schema and queries. It manifests in cloud compute costs, so I think it still matters.",
          "score": 1,
          "created_utc": "2026-02-06 18:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zbnbi",
          "author": "jaymopow",
          "text": "Data modeling is still very important, but the classical data modeling approaches don‚Äôt really support today‚Äôs use cases.",
          "score": 1,
          "created_utc": "2026-02-06 22:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zyf3o",
          "author": "onomichii",
          "text": "Modelling the business logically is critical.\nModelling this in physical terms that is performant, scalable and maintainable is critical.\nEngineering this well is critical.\n\n\nAll three are distinct skills. You might think you're skipping some because of the features of your target platform, but what you're really doing is just short sighted half assed modelling which you will pay for one way or another later¬†",
          "score": 1,
          "created_utc": "2026-02-07 00:23:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43o4jr",
          "author": "Relative_Wear2650",
          "text": "No",
          "score": 1,
          "created_utc": "2026-02-07 16:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43p7l2",
          "author": "Typhon_Vex",
          "text": "I have noticed the same thing. It really began with the empowering of the non-IT personall.\n\nThe self-called dahsboard developers havig no clue what a dimension is - no joke.\n\nNow the data transformations have been moved from IT-based ETL developers to the bussiness and the analysts there.\n\nMost managers or architects also don¬¥t anymore know what it is. No one is even pushing it. It has gotten so bad that I was told to stop asking job applicants to our data team about Dimensions. To keep it practicall only. Well guess what, they can¬¥t write the SQL neither, as it would require a basic Star Schema model understanding.\n\n  \nWell in the end, it will just be more work for us the data engineers. Quality - reusable models would actually mean less work. So why push it from my side.",
          "score": 1,
          "created_utc": "2026-02-07 16:28:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46v1vy",
          "author": "Impossible-End4881",
          "text": "No",
          "score": 1,
          "created_utc": "2026-02-08 02:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o475dd9",
          "author": "GreyHairedDWGuy",
          "text": "I think many of your observations are in correct but that doesn't make it the right way to go.  FAANG tend to have very aggressive deadlines and have the 'just get it done' mentality.  They see modelling as an impediment to delivery time.  \n\nI'm not with a FAANG company but the 'get it done quickly' mentality impacts the quality of our deliveries.  Someone ends up having to clean the mess at some point. ",
          "score": 1,
          "created_utc": "2026-02-08 04:07:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m9o61",
          "author": "dbjan",
          "text": "Yes, but my experience is that many junior people like to feel like experts these days and if you try to explain why to model staff properly, they feel insulted. Lack of arguments makes it just worse, on one project they took what I designed and made it a monster, I regretted I didn't leave them alone.. : D\n\nOverall you design to keep it fast long term. If not, you end up fire-fighting, the best people leaving the team and so on...",
          "score": 1,
          "created_utc": "2026-02-10 14:19:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wvnwv",
          "author": "Atticus_Taintwater",
          "text": "Yes and no\n\n\nThe ideology of a data model \"modeling the business\" and the more theoretical techniques are definitely falling out of favor for good reason.¬†\n\n\nEvery time I've seen that it's just ego stroking from a modeler and a lot of time contorting the way the systems actually behave to his Disneyland idea of \"the business\". It ends up just making everything either harder or weirder¬†\n\n\nData modeling is important up to the point where people can write sensible queries and get sensible results. Greatly diminishing returns after that.",
          "score": -1,
          "created_utc": "2026-02-06 15:09:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x4yjx",
              "author": "DungKhuc",
              "text": "What you said is true if data modeling is used for forgotten BI dashboards.\n\nIf data is at the core of the business, data modeling is critical as it's typically crucial part of the products. The value of data models in such cases only grows over time, never the other way around.",
              "score": 3,
              "created_utc": "2026-02-06 15:54:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xe34g",
                  "author": "Atticus_Taintwater",
                  "text": "I think what I said is true for most data products that aren't for operations\n\n\nWouldn't lump in scd with this. That's barely modeling.¬†I'm more talking about bloated er modeling.\n\n\nThere should be a generally sensible structure. My addresses should be collated with some kind of locations concept, etc\n\n\nBut every time I see a subrogations process modeled in 15 tables because that's how it theoretically works it becomes a counterproductive rats nest because the real world is far gnarlier.",
                  "score": 1,
                  "created_utc": "2026-02-06 16:37:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wwzhh",
              "author": "MissingSnail",
              "text": "And in practice, tech teams are understaffed and doing the best they can with the time they have.",
              "score": 1,
              "created_utc": "2026-02-06 15:16:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wx1s3",
          "author": "kjmerf",
          "text": "Yes",
          "score": 0,
          "created_utc": "2026-02-06 15:16:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0ff3b",
      "title": "[AMA] We‚Äôre dbt Labs, ask us anything!",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/",
      "author": "andersdellosnubes",
      "created_utc": "2026-02-09 20:24:08",
      "score": 115,
      "num_comments": 41,
      "upvote_ratio": 0.91,
      "text": "Hi r/dataengineering ‚Äî though some might say analytics and data engineering are not the same thing, there‚Äôs still a great deal of dbt discussion happening here. So much so that the superb mods here have graciously offered to let us host an AMA happening this **Wednesday, February 11 at 12pm ET.**\n\nWe‚Äôll be here to answer your questions about anything (though preferably about dbt things)\n\n**As an introduction, we are:**\n\n* Anders u/andersdellosnubes (DX Advocate) ([obligatory proof](https://private-user-images.githubusercontent.com/8158673/547313164-dea36821-9795-45a6-a6ec-d5f825ee7b7a.jpg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NzA2Njg4OTQsIm5iZiI6MTc3MDY2ODU5NCwicGF0aCI6Ii84MTU4NjczLzU0NzMxMzE2NC1kZWEzNjgyMS05Nzk1LTQ1YTYtYTZlYy1kNWY4MjVlZTdiN2EuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDIwOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAyMDlUMjAyMzE0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWZjZWFhNzUzMTc5YTg3NGVlM2JjNTM5ZDk1MmFkZjE5OTY4YWQ1Y2RjOTU2NWRkZjUyMjliNWU0M2Q5NzY2ZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.U7-2SR3ch9-cKqPsHzWS_yEpDSvmiW8VaIfEyOr7Wxs))\n* Jason u/More_Drawing9484 (Director: DX, Community & AI)\n* Sara u/schemas_sgski (Product Marketing)\n* Quigley u/dbt-quigley (dbt Core engineer)\n* Zeeshan u/dbt-zeeshan (Core engineering manager)\n\n**Here‚Äôs some questions that you might have for us:**\n\n* [what‚Äôs new](https://github.com/dbt-labs/dbt-core/releases/tag/v1.11.0) in dbt Core 1.11? what‚Äôs [coming next](https://github.com/dbt-labs/dbt-core/blob/main/docs/roadmap/2025-12-magic-to-do.md)?\n* what‚Äôs the latest in AI and agentic analytics ([MCP server](https://docs.getdbt.com/blog/introducing-dbt-mcp-server), [ADE bench](https://www.getdbt.com/blog/ade-bench-dbt-data-benchmarking), [dbt agent skills](https://docs.getdbt.com/blog/dbt-agent-skills))\n* what‚Äôs [the latest](https://github.com/dbt-labs/dbt-fusion/blob/main/CHANGELOG.md) with Fusion? is general availability coming anytime soon?\n* who is to blame to `nodes_to_a_grecian_urn` corny classical reference in our [docs site](https://docs.getdbt.com/reference/node-selection/yaml-selectors)?\n* is it true that we all get goosebumps anytime anytime someone types dbt with a capital d?\n\nDrop questions in the thread now or join us live on Wednesday!\n\nP.S. there‚Äôs a dbt Core 1.11 live virtual event next Thursday February 19. It will have live demos, cover roadmap, and prizes! [Save your seat here](https://www.getdbt.com/resources/webinars/dbt-core-1-11-live-release-updates-roadmap/?utm_medium=social&utm_source=reddit&utm_campaign=q1-2027_dbt-core-live_aw&utm_content=themed-webinar____&utm_term=all_all__).",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4irts2",
          "author": "Interesting_Tank_118",
          "text": "I love your product! Since merging with Fivetran: Whats the long term strategy of dbtlabs? i.e. will dbt cloud have even more advanced features than dbt core to get more paying customers?",
          "score": 73,
          "created_utc": "2026-02-09 23:23:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iwknd",
          "author": "RobG760",
          "text": "How will dbt core adapt to a world where streaming pipelines are starting to become more common?  How do you see dbt helping build a clean data lineage across all enterprise data regardless of whether batch or streaming tools are being leveraged?",
          "score": 22,
          "created_utc": "2026-02-09 23:50:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jcvg9",
          "author": "FIapdoodle",
          "text": "Some questions pertaining to Fivetran merger:\n\nSince they also acquired Tobiko Data, will we see any consolidation/standardization efforts between DBT and SQLMesh? \n\nWith Fivetran providing many data connectors, will we see a more end-to-end flow established where the ingestion and transformations will be managed together?",
          "score": 17,
          "created_utc": "2026-02-10 01:23:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j8enu",
          "author": "flatulent1",
          "text": "The gap between dbt explorer/catalog and a full scale catalog like Atlan or Datahub or Alation or Secoda etc is still huge. In 2026, data is a context game. Are yall just playing it safe as a metadata provider for more expensive, external catalogs?",
          "score": 14,
          "created_utc": "2026-02-10 00:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4io7a9",
          "author": "Sex4Vespene",
          "text": "Thanks for reaching out for questions, I love DBT and it‚Äôs been so useful for our org. I have one question that‚Äôs somewhat of a feature request. Have you considered having an ‚Äúintermediate‚Äù type table materialization? We have several large models that have to be broken up into intermediate steps because they would either overload memory, or perform poorly due to CTE‚Äôs that are called multiple times, which we can instead just process them once in a separate model. What gets annoying with this, is we don‚Äôt want any of these intermediate models taking up space in our warehouse, so we have to use a custom post-hook on any end-state models to clean up the upstream intermediate models. It would be really awesome if you integrated this automatically. Let us use intermediate as a materialization strategy, and have them be autodropped once an end-state model finishes. I know you have ephemeral and view materializations, but none of those solve the problem of having too much stuff happening in the final query that uses them. Thanks again!",
          "score": 22,
          "created_utc": "2026-02-09 23:04:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iw32u",
              "author": "Chilangosta",
              "text": "Something about this feels off... You have such massive tables that they overload memory, and are forced to break apart queries into intermediate steps. But you then delete said intermediate products presumably because they take up so much space that this saves you money.... And somehow the savings are worth rebuilding it from scratch every time?\n\nI have so many questions; this isn't making sense to me. Feels like either you're overoptimizing for cost when it's really not worth it or else doing something wrong when it comes to query optimization for the intermediate products to truly not be worth keeping around. Are your joins exploding? Is storage really so expensive that rebuilding these intermediates makes sense? Are you doing too much in your final query? Without more info it's hard to say for certain, but intermediate products aside I suspect something isn't as optimal about this scenario as you think.",
              "score": -2,
              "created_utc": "2026-02-09 23:47:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4iyv6s",
                  "author": "Sex4Vespene",
                  "text": "You‚Äôre making some incorrect assumptions here. We are on prem, this isn‚Äôt about saving cloud costs, it‚Äôs about us being somewhat low on storage and trying to minimize how much useless data is just sitting around. We are working on getting budget to expand, but that doesn‚Äôt happen immediately. I don‚Äôt understand what you mean about doing something wrong with optimization for them to not be worth keeping around. These are models that are run on a daily/weekly/monthly cadence. The previous versions of the intermediate models are useless for the next run. They either cover a completely different date range, and even if there is overlap, we have a decent amount of updates/deletes against old records so we‚Äôd want to rerun with the newest versions of the records anyways. And no, our joins aren‚Äôt exploding, I‚Äôve actually done a huge amount of work creating optimization guidelines for our models, and will go in to fine tune when needed. Since we are on prem, we aren‚Äôt paying for aggregate compute usage. We have a set amount of compute and memory that is always available at any moment. If we just ran one model at a time, we would be massively underutilizing our compute. To make the most out of our compute, we run multiple models at once. But since we aren‚Äôt just running one model, we have to set memory limits on all models, by dividing our available memory by the number of concurrent models we run, to ensure we don‚Äôt have memory related failures. Also as I mentioned, there are cases where breaking things out into an intermediate model can have massive performance improvements. Our query engine materializes CTE‚Äôs every time it is called. If you use the same CTE in a query 5 times, it quintuples the memory and compute usage, versus just running it once into a table and then just referencing the table a few times. It all makes plenty of sense, you are just evaluating it from an invalid context.",
                  "score": 12,
                  "created_utc": "2026-02-10 00:02:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4j35rw",
          "author": "midnighttyph00n",
          "text": "when will fusion support python  models",
          "score": 9,
          "created_utc": "2026-02-10 00:26:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lgyag",
              "author": "pseudo-logical",
              "text": "It already does for the big three (snow dbx and bq) which says something about their marketing and comms",
              "score": 3,
              "created_utc": "2026-02-10 11:11:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4j4wea",
          "author": "HC-Klown",
          "text": "Please, when will you support write audit publish pattern as a materialization option? I want to build the model in some temp environment then test it and then ‚Äúdeploy‚Äù it without having to rely on data branching features from for example Nessie or LakeFs. \n\nI know this can get more involved with views etc but do you guys have anything related to this in your roadmap? Or would recommend building a custom materialization?",
          "score": 7,
          "created_utc": "2026-02-10 00:36:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l0vwi",
          "author": "paujas",
          "text": "What are the priority developments dbt-Labs are concentrating on ?\n\nWhat is the long term vision for dbt-core and dbt-cloud?",
          "score": 6,
          "created_utc": "2026-02-10 08:39:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ky1in",
          "author": "pseudo-logical",
          "text": "Ok, I'll bite, _is_ Fusion going to be GA anytime soon? I feel bad for the devs who have had to keep their foot on the gas for nearly a full year since someone on the e-team decided to launch prematurely.",
          "score": 5,
          "created_utc": "2026-02-10 08:11:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mrppy",
          "author": "sleeper_must_awaken",
          "text": "How will you prevent companies being charged $350 / seat / month for an enterprise DBT Cloud subscription of three years when they need more than 8 seats? ¬†This is a real story I‚Äôve seen at two of our clients. That amount is just inordinate and betrays the trust companies and consultancies have placed in your DBT Labs.\n\nFor me, DBT Labs needs to regain my trust. I‚Äôve recommended many companies to use DBT Core and DBT Cloud since 2019, but am hesitant to continue recommending it.\n\nCompare that pricing with GitHub, which also has runners, incident management, traceability, collaboration, auditing and IdP integration (among many other things).",
          "score": 4,
          "created_utc": "2026-02-10 15:50:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iwxwj",
          "author": "Proudly_Funky_Monkey",
          "text": "Is there a better way to manage the lifecycle of parallel pipelines?¬†\n\n\nContext: we use DBT core to build features for ml models. New data is ingested weekly, and from it new model features are built through a tree of 30+ very complicated tables. Models are then fed these latest features. We're pretty happy with this.¬†\n\n\nBut when we want/need to develope new/different model features, we really struggle with versioning. we only have one database: production. So end up duplicating the entire tree of tables with _version[] appended. The development is then done in the version suffixed tables until eventually it eventually becomes prod and the old tables/definitions are deleted.¬†\n\n\nWhy is this bad? Massive PRs, drift between trees during dev, significant risk of manual mistakes, entire tree must be duplicated even for small changes (complexity and cost).\n\n\nCan DBT help with our architecture problems?",
          "score": 4,
          "created_utc": "2026-02-09 23:52:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j2h0o",
              "author": "fsm_follower",
              "text": "I don‚Äôt have a solution for you but have felt this.  Would the ability for dev pipelines to pull almost all the tables from prod then only generate those in your diff be a solution?",
              "score": 3,
              "created_utc": "2026-02-10 00:23:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4l1ez7",
              "author": "SpookyScaryFrouze",
              "text": "You could change the generate_schema_name macro in order for the target name to be appended to the schema name.\n\nThat way you would have 2 schemas : ml_models_prod and ml_models_dev, in the same database.",
              "score": 3,
              "created_utc": "2026-02-10 08:44:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4oj2su",
          "author": "uncertainschrodinger",
          "text": "What are some new trends, ideas, competitors, and schools of thought that you find to be the biggest threat to the principles and roadmap of dbt?",
          "score": 4,
          "created_utc": "2026-02-10 20:43:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kkib8",
          "author": "Ramshizzle",
          "text": "Do you have any plans for improving how dbt deployment pipelines are configured, build and run?\n\nAt my company we are brand new to dbt-cloud. So far I really love dbt and all its capabilities. There is one issue I'm having, which is the only way it seems we can create an ETL pipelines from dbt-cloud is to manually click together a 'deployment job'.\n\nI am already experimenting with dbt-jobs-as-code, but while that is a great tool, it seems like that is still in early development.\n\nAt this moment we are considering getting an outside scheduler/orchestration tool. Which would be a shame in my opinion.",
          "score": 3,
          "created_utc": "2026-02-10 06:09:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m6uf5",
          "author": "Existing_Wealth6142",
          "text": "What is your perspective on open table formats like Iceberg,  Delta Lake, and Hudi? If you are positive on the technology, what do you think are the most important features still lacking from either the formats or dbt in order to maximize their value?",
          "score": 3,
          "created_utc": "2026-02-10 14:04:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ngrbx",
          "author": "uglylookingguy",
          "text": "What‚Äôs the biggest mistake teams make when adopting dbt that doesn‚Äôt show up until months later in production?",
          "score": 3,
          "created_utc": "2026-02-10 17:46:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k3rdf",
          "author": "ActEfficient5022",
          "text": "What would you say you do here?",
          "score": 4,
          "created_utc": "2026-02-10 04:05:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lsn8q",
          "author": "GarpA13",
          "text": "Are you planning to abandon dbt core? What is your vision for on-premise software?",
          "score": 4,
          "created_utc": "2026-02-10 12:40:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ju1xp",
          "author": "superconductiveKyle",
          "text": "Hey dbt Crew, I'm Kyle Eaton, Head of Growth at Agno (https://github.com/agno-agi/agno). I've been a big fan of your product for a long time now and specifically the community you all created. I'm the Former Head of Growth at Great Expectations, so I've been following for a long time.\n\nWe recently asked some of our users who we should partner with, and dbt came up. Seeing your AMA reminded me about this. Would love the chat with you all about what a partnership with Agno and dbt could look like! \n\nHope you have fun with your AMA! ",
          "score": 2,
          "created_utc": "2026-02-10 03:03:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lhwd6",
          "author": "finally_i_found_one",
          "text": "RemindMe! 4 days",
          "score": 2,
          "created_utc": "2026-02-10 11:19:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4li1k1",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 4 days on [**2026-02-14 11:19:40 UTC**](http://www.wolframalpha.com/input/?i=2026-02-14%2011:19:40%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/o4lhwd6/?context=3)\n\n[**2 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1r0ff3b%2Fama_were_dbt_labs_ask_us_anything%2Fo4lhwd6%2F%5D%0A%0ARemindMe%21%202026-02-14%2011%3A19%3A40%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r0ff3b)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-10 11:20:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lim0t",
          "author": "set92",
          "text": "I'm deciding in moving my code from Airflow to Dbt using Cosmos. The idea is that instead of having custom sql code with jinja, I can move everything to dbt and let it run everything. \n\nI do this to improve in logging/debugging, and easiness. I suppose the speed/easiness is going to be there. But not sure about the logging part. Does dbt returns the output of queries, or is something that we can modify or specify in our own?",
          "score": 2,
          "created_utc": "2026-02-10 11:25:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ofuk2",
              "author": "Comfortable-Power175",
              "text": "Have you looked into dbt elementary? This is how we monitor model runs. FWIW we have an airflow + dbt + cosmos with elementary setup and are extremely happy",
              "score": 1,
              "created_utc": "2026-02-10 20:27:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4oqz3a",
                  "author": "set92",
                  "text": "Thanks, I'll check it. Although in general I was thinking more in the outputs itself. Like we have Snowflake, and the Operator of Airflow doesn't show you the results of the query by default, and in Snowflake itself only the owner of the query can check the results for 24h only. So, I thought maybe with dbt I could log this, like for example when I do COPY INTOs be able to see if a file has failed, and other information that comes on that results table, but I suppose the best will be to find some free moment and test it myself.",
                  "score": 1,
                  "created_utc": "2026-02-10 21:19:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ng6a3",
          "author": "domscatterbrain",
          "text": "What's the big roadmap for DBT?\n\nYou must know that, while the acquisition shenanigans are good for your team (hopefully) it made many people who's been a long fan of DBT furious.",
          "score": 2,
          "created_utc": "2026-02-10 17:43:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o5oy4",
          "author": "Adrien0623",
          "text": "When will the fix for dbt-redshift connector will come so that materialized view refresh stops failing randomly?",
          "score": 2,
          "created_utc": "2026-02-10 19:40:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q9uw0",
          "author": "infomocrat",
          "text": "What have been your favorite Coalesce talks of all time?\n\nIf you could wish any talk into existence for a future Coalesce (ok, dbt Summit) what would it be?",
          "score": 2,
          "created_utc": "2026-02-11 02:19:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kq035",
          "author": "Tall_Working_2146",
          "text": "Your certifications are interesting but the price is high, are there no initiative to make learning resources more accessible for students and people abroad?",
          "score": 4,
          "created_utc": "2026-02-10 06:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o8pge",
          "author": "Ok-Sentence-8542",
          "text": "Why did you abandon dbt core and the open source community?",
          "score": 2,
          "created_utc": "2026-02-10 19:54:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n1bel",
          "author": "Ready-Marionberry-90",
          "text": "What problem do you exist to solve?",
          "score": 2,
          "created_utc": "2026-02-10 16:35:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwd5of",
      "title": "Is someone using DuckDB in PROD?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwd5of/is_someone_using_duckdb_in_prod/",
      "author": "Free-Bear-454",
      "created_utc": "2026-02-05 05:51:13",
      "score": 109,
      "num_comments": 55,
      "upvote_ratio": 0.95,
      "text": "As many of you, I heard a lot about DuckDB then tried it and liked it for it's simplicity.\n\nBy the way, I don't see how it can be added in my current company production stack.\n\nDoes anyone use it on production? If yes, what are the use cases please?\n\nI would be very happy to have some feedbacks",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwd5of/is_someone_using_duckdb_in_prod/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3oeowa",
          "author": "ambidextrousalpaca",
          "text": "We've been using DuckDB in production for a year now, running and generating the queries we need with Python code.  \n\nSo far it's gone great. No major problems.\n\nWe switched from developing new pipelines in PySpark to doing so with DuckDB mainly on the basis that:\n\n1. We observed that the actual data loads we were processing were never big enough to necessitate a Spark cluster.\n2. Getting rid of Spark meant we could get rid of the whole complexity of running a JVM using the massive collection of libraries Spark requires (with all of their attendant security vulnerabilities) and replace it with a single, dependency-free DuckDB compiled binary.\n3. When we tested it against Spark on our real data it ran about 10 times faster and used half the resources (and _yes_, I'm sure the Spark code could have been optimised better, but that's what our testing for our specific use-case showed).\n\nPoint 3 was the major one that allowed us to convince ourselves this was a good idea and sell it to management.",
          "score": 136,
          "created_utc": "2026-02-05 07:02:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3or0x0",
              "author": "CAPSLOCKAFFILIATE",
              "text": "> actual data loads we were processing were never big enough to necessitate a Spark cluster.\n\nThe first step towards living an easy life is realizing we overcomplicate things without actual need. There is no \"big data\" in corporate, unless you work in MAG7, major banks or AI labs. 95% of companies can run just fine with DuckDB, and that's assuming they ever leave Excel as \"data management backend\".",
              "score": 57,
              "created_utc": "2026-02-05 08:57:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qtg7i",
                  "author": "reelznfeelz",
                  "text": "For sure.  People are quick to reach for these powerhouse tools but you really should consider if you need them.   Postgres, or apparently duckDB, can take you quite far.",
                  "score": 3,
                  "created_utc": "2026-02-05 16:52:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3uv1af",
                  "author": "turboDividend",
                  "text": "yes. i never got too interested in learning about 'real data engineering' because so few places actually really need it unfortunately. Most corporate enviroments are not dealing with big data. I have personal projects that actually generate/consume more data than some places ive worked at",
                  "score": 3,
                  "created_utc": "2026-02-06 06:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3oma84",
              "author": "CulturMultur",
              "text": "Yeah, Spark infrastructure completely sucks. But, Dataframe API vs templated SQLs are very different, and whenever trend is to start programming with templating (dbt macros, I‚Äôm looking at you) - I would not put any important business logic under templating. With Spark I can isolate logic into pure functions - dataframes in, Dataframe out -and test it. With templating - nope.",
              "score": 11,
              "created_utc": "2026-02-05 08:12:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3p11fb",
                  "author": "Difficult-Tree8523",
                  "text": "We use SQLFrame to get a pyspark compatibility API",
                  "score": 5,
                  "created_utc": "2026-02-05 10:34:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3r0g08",
                  "author": "New-Addendum-6209",
                  "text": "Could you provide an example of one of these pure functions and how you test it?",
                  "score": 2,
                  "created_utc": "2026-02-05 17:25:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ol9zk",
              "author": "Free-Bear-454",
              "text": "Very interesting feedback! Where do you run DuckDB though? What is the infra and architecture if you can talk about it?",
              "score": 6,
              "created_utc": "2026-02-05 08:02:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q8741",
                  "author": "ambidextrousalpaca",
                  "text": "There's very little. Just running it on Linux boxes in the cloud. That's the beauty of it. Simple.",
                  "score": 1,
                  "created_utc": "2026-02-05 15:13:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ovsug",
              "author": "singinggiraffe",
              "text": "Is spark and duckdb comparable? I don't know much but I thought spark was abiut distributed computing and duckdb is a tabular database optimized for longer tables or something, no?",
              "score": 3,
              "created_utc": "2026-02-05 09:44:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q2h8w",
                  "author": "Keizojeizo",
                  "text": "They are comparable in the sense that they write transformations in SQL - not exact same dialect but very close. They both can read and write csv, parquet, etc.\n\nOften those are the only features that people are really using from each engine.\n\nSpark is optimized for distributed compute, and duckdb is meant to execute within a single process. Spark has more overhead, always, than duckdb, and one could argue is only worth it if the data size is absolutely massive such that the data can‚Äôt fit on a single machine.",
                  "score": 5,
                  "created_utc": "2026-02-05 14:44:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3q8fco",
                  "author": "ambidextrousalpaca",
                  "text": "DuckDB actually does a better job of parallelizing queries across process cores than Spark does, based on our testing and monitoring of memory and CPU usage.",
                  "score": 2,
                  "created_utc": "2026-02-05 15:14:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ofru0",
              "author": "Difficult-Tree8523",
              "text": "+1 share same experience¬†",
              "score": 4,
              "created_utc": "2026-02-05 07:11:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o41qql2",
              "author": "FatGavin300",
              "text": "SHHHHHH dont  tell the companies about this. My contracting business runs on querying parquet in S3 (through duckdb locally) instead of using their overpriced Spark Clusters! (well until spark is actually needed))",
              "score": 1,
              "created_utc": "2026-02-07 08:03:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o76xj",
          "author": "putokaos",
          "text": "It all depends on the size, complexity, and purpose of your stack. In my case, we use DuckDB to detach some queries from Snowflake that even with the smallest compute engine size, would be an overkill, so it's very useful with our processing pipelines. Aside from that, DuckDB is fantastic for Data Analysts, as they can make use of their computers instead of draining resources from the DWH. We also use it in its WASM version as part of the Evidence.dev stack, which nurtures a lot of our dashboards.",
          "score": 26,
          "created_utc": "2026-02-05 05:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3olg3x",
              "author": "Free-Bear-454",
              "text": "Can you tell us about how it works please? Are you using DBT or something else to handle transformations?",
              "score": 2,
              "created_utc": "2026-02-05 08:04:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3p446f",
                  "author": "putokaos",
                  "text": "We mainly use dbt for transformations, so, for some of them we use DuckDB, and for some others, we use Snowflake. That said, to make this possible you must work with external tables in Snowflake, as our architecture is based on a Data Lakehouse. You'd also need an orchestrator, such as Dagster, as dbt has some limitations in this regard, especially if you want to maintain lineage. Regarding the execution engine, it's fair to say that there are alternatives that allow you to route your queries dynamically, such as Greybeam. But they are still in a very early stage.",
                  "score": 7,
                  "created_utc": "2026-02-05 11:01:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3onyal",
          "author": "ppyil",
          "text": "Yes, heavily using DuckDB. We work with less data than most companies here I suspect, enough that tables used for analytics can be loaded into instances of our webserver in-memory for extremely quick data analytics on the front end.\n\nSo each instance is a Docker image running Django and periodically redownloading the latest DuckDB file (which is an output of our data pipeline elsewhere) and then allowing for views to be constructed via direct access to DuckDB.\n\nI've been thinking about building a proper database driver between Django and DuckDB but for now, a combination of generating direct SQL and using polars have given us everything we need.",
          "score": 13,
          "created_utc": "2026-02-05 08:28:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3otnuj",
              "author": "ILoveBNTC",
              "text": "Very interested in this. We currently run a django backend that has some slow queries consumed by our frontend and have already been optimized.\n\nWould you be able to share how this integration works?",
              "score": 3,
              "created_utc": "2026-02-05 09:23:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pbgu5",
                  "author": "ppyil",
                  "text": "We've got a cron job that downloads the latest duckdb file from S3 periodically, every 15 mins or so. Luckily our final DuckDB file is pretty small, about 30MB and so we can easily just download and use",
                  "score": 1,
                  "created_utc": "2026-02-05 12:02:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3okark",
          "author": "PrinceN71",
          "text": "I do. It's very useful although currently only a very small part. Traditionally my company uses sql in database but seeing the performance benefits of duckdb, my company is planning on using a data lake like delta lake and duck DB to do the processing\n\nCurrently my biggest issue I'm trying to figure out is how I want to update the data in delta tables because I'm mainly using polars to insert the data. I don't really have much experience in this but if anyone has any tips on how I can update delta tables using polars instead of pyspark I am all ears",
          "score": 3,
          "created_utc": "2026-02-05 07:53:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p9fuj",
              "author": "commandlineluser",
              "text": "What trouble are you having exactly?\n\nThere's many examples in the delta tests:\n\n- https://github.com/pola-rs/polars/blob/0c179b5c3edcbfd9db8745507931781327950a9d/py-polars/tests/unit/io/test_delta.py#L576-L601\n\n(`LazyFrame.sink_delta()` was also added in 1.37.0)",
              "score": 1,
              "created_utc": "2026-02-05 11:46:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3uh0b8",
              "author": "losh-purler",
              "text": "Since you're in the process of figuring out your data lake, I'd suggest you check out DuckLake from DuckDB themselves. I haven't used it personally yet.\nhttps://www.youtube.com/watch?v=zeonmOO9jm4",
              "score": 1,
              "created_utc": "2026-02-06 04:22:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3oliod",
              "author": "Typical_Priority3319",
              "text": "I‚Äôm not going to tell you to not do it in Polars but what I will say is that you‚Äôre going to have a MUCH easier time just doing it in spark imo. That is if you can figure out how to get a spark instance up and running in demand (I just use glue typically)",
              "score": 0,
              "created_utc": "2026-02-05 08:05:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3om2tj",
                  "author": "PrinceN71",
                  "text": "Then I think I will just stick with spark for now. I can sacrifice abit of performance and resource if it's easier to work with",
                  "score": 2,
                  "created_utc": "2026-02-05 08:10:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3q6flx",
              "author": "shockjaw",
              "text": "Ibis supports spark if you need it to. You can switch to other coding backends if you need to without code changes.",
              "score": 0,
              "created_utc": "2026-02-05 15:04:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o6rea",
          "author": "nonamenomonet",
          "text": "If you‚Äôre using a severless function for some lighter weight ETL it can be used.",
          "score": 4,
          "created_utc": "2026-02-05 05:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3olryi",
          "author": "CulturMultur",
          "text": "We use DuckDB in production. Our dwh is Snowflake and I built a tool that runs worksheets (series of SQL statements) in Snowflake with little templating (Go text/template library). Some workloads started using Snowflake as an engine - in worssheet query from s3 and copy back to s3 immediately.\n\nThen we added support to DuckDB instead, now all processing happens inside the tool, so paying AWS instead of Snowflake.\n\nHowever, working with big parquets is still better in Snowflake - maybe it‚Äôs me, but ‚Äúselect from s3://prefix-with-parquets limit 100‚Äù hangs in DuckDB while taking 100ms in Snowflake.",
          "score": 2,
          "created_utc": "2026-02-05 08:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ooa98",
              "author": "linos100",
              "text": "At what sizes are you having issues with parquets in duckdb? Where is duckdb running? (I assume the mentioned tool in \"...inside the tool...\" is duckdb)",
              "score": 2,
              "created_utc": "2026-02-05 08:31:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3omyja",
              "author": "Free-Bear-454",
              "text": "Please let me understand, you migrated all of Snowflake workloads to DuckDB?",
              "score": 1,
              "created_utc": "2026-02-05 08:18:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3vdagd",
                  "author": "CulturMultur",
                  "text": "No, only those that used Snowflake as engine (without storage - so read from s3, write to s3) - those we migrated to either DuckDB (simple workloads) or Spark (workflows with complex business-logic).",
                  "score": 0,
                  "created_utc": "2026-02-06 08:49:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3osziz",
          "author": "pra__bhu",
          "text": "we use it for ad-hoc analytics and local development but not as a primary production db\nthe sweet spot ive found is:\n\t‚àô\trunning queries against parquet/csv exports without spinning up a full warehouse\n\t‚àô\tprototyping analytics pipelines before pushing to snowflake\n\t‚àô\tinternal tools where you need fast aggregations but dont need concurrent writes\nthe limitation is it‚Äôs single-process - no concurrent write access, so anything with multiple users writing data simultaneously is a no-go. reads scale fine though\nseen some teams embed it in data apps where users query pre-built datasets, works great for that. but if you need a traditional multi-user transactional system it‚Äôs not the right tool\nwhat‚Äôs your use case? might be able to give a more specific take‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 2,
          "created_utc": "2026-02-05 09:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pil1h",
          "author": "Thinker_Assignment",
          "text": "using it for (ELT)->L\n\ncanonical on duckdb then load",
          "score": 2,
          "created_utc": "2026-02-05 12:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pt6l5",
          "author": "ghost-in-the-toaster",
          "text": "I use it for a small internal web app. I chose it because 1) I needed complex data structures and 2) as a tool that would get infrequent use, I wanted to limit it‚Äôs resource consumption (disk-only data store and no separate service running). Otherwise, Postgres is what our company uses.",
          "score": 2,
          "created_utc": "2026-02-05 13:54:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q650k",
          "author": "shockjaw",
          "text": "Yup! Using it as a sink for data when I have to pull user information from Active Directory, a website, and another user directory. Have to reconcile all three to make sure they match or certain exceptions are met. It‚Äôs real nice to front load the LDAP query and not have to deal with latency unless I need to reach back out to Active Directory.",
          "score": 2,
          "created_utc": "2026-02-05 15:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3svjf2",
          "author": "JBalloonist",
          "text": "Yes. I‚Äôm running it in MS Fabric Python notebooks because Spark is overkill (spare me the hate‚Ä¶I know it‚Äôs not as good as other platforms but it works for our SMB). \n\nQuery raw parquet in my data lake and load to Bronze tables. Query Bronze and load to silver. Most of the logic is in the SQL. \n\nThere are a few exceptions where I have to use Pandas to add some additional business logic.",
          "score": 2,
          "created_utc": "2026-02-05 22:43:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oqyx0",
          "author": "blockchan",
          "text": "Hex.tech is using it in analytics layer as in memory db. Works v ery nice",
          "score": 1,
          "created_utc": "2026-02-05 08:57:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3or1ux",
          "author": "hoselorryspanner",
          "text": "I use it in a severless Vue app to speak to a parquet datalake. Works a treat for smallish (<10k records) tables.\n\nWhether or not you‚Äôd call this prod is a different story: it‚Äôs a web viewer for an intake catalog, just aiming to make life easier for our users.",
          "score": 1,
          "created_utc": "2026-02-05 08:57:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p1dx3",
          "author": "undergrinder_dareal",
          "text": "We use duckdb as processing engine mostly, very statisfied. Our use case is like duckdb as a pandas replacement, but in fact we never used pandas, but spark with low utilization or some kind of SQL Server.",
          "score": 1,
          "created_utc": "2026-02-05 10:37:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q1nhq",
          "author": "calimovetips",
          "text": "yes, but usually in narrow roles, not as a central warehouse. i see it used for embedded analytics, batch feature generation, or ad hoc transforms inside pipelines where spinning up infra is overkill. it works well when data fits on disk and concurrency is low, it falls apart once you expect shared state or lots of writers. what part of your stack are you thinking of replacing or augmenting with it?",
          "score": 1,
          "created_utc": "2026-02-05 14:40:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q5b06",
          "author": "phonyfakeorreal",
          "text": "We load user uploads into SQLite for intermediate processing, and I desperately want to replace it with DuckDB for its excellent column type detection",
          "score": 1,
          "created_utc": "2026-02-05 14:59:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q9crw",
          "author": "Lucky_Badger_",
          "text": "We also use it as a pandas replacement in our data pipelines . Files -> DuckDb ->  Postgres, Postgres tables -> DuckDb -> Postgres. In our event driven architecture its fantastic using it with Python. We break up the transformations into methods and we have a nice little library we have created to help us create datasets we can use in our unit tests. Loving it so far. \n\nIt does use floating point division, but we created a python udf that allows use to Pythons Decimal type which has solved that issue for us",
          "score": 1,
          "created_utc": "2026-02-05 15:19:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qoyqu",
          "author": "licyeus",
          "text": "We use it in a prod data pipeline to regularly ingest+process 10s of billions of rows of time series data. We load CSV, run a bunch of transforms + checks, and write parquet into blob storage. We wrote our own orchestration framework (though if starting over, we'd likely use dbt or sqlmesh).\n\nIt's been pretty solid, minus one problem with k8s killing the pod when it thinks it's OOM (we work around this by processing in batches).\n\nInfrastructural simplicity is the biggest benefit, IMO.",
          "score": 1,
          "created_utc": "2026-02-05 16:32:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qs1ur",
          "author": "full_arc",
          "text": "We use it very heavily at Fabi.ai\n\nAwesome for caching and quick processing for our users. Basically when you retrieve data that‚Äôs what we use to store it and reduce the load on the DB and avoid running up compute for our customers as the business vibes their way through an analysis. It also makes report loading super quick.",
          "score": 1,
          "created_utc": "2026-02-05 16:46:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3quful",
          "author": "hornyforsavings",
          "text": "We (Greybeam) help companies use DuckDB with their Snowflake workloads in production. We likely have the second or third largest DuckDB production clusters next to Motherduck and Coginiti",
          "score": 1,
          "created_utc": "2026-02-05 16:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qxg2a",
          "author": "PinkFrosty1",
          "text": "I use DuckDB for real-time and in-memory data transformations within my machine learning inference data pipeline.",
          "score": 1,
          "created_utc": "2026-02-05 17:11:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r0jf2",
          "author": "theManag3R",
          "text": "I set up a dataplatform for my friend who's a founder of a startup. I wanted to try how Ducklake fits prod and while there are some caveats, it's performing quite well.\n\nI have a dockerized app running Superset, which is. connected to Ducklake. Metadata for both Superset and Ducklake is running in Postgres (on another container) and data is on S3.\n\nPython scripts are transforming some raw data and inserting it to Ducklake.\n\nIt has been a very pleasant experience so far",
          "score": 1,
          "created_utc": "2026-02-05 17:26:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vngfl",
          "author": "BusOk1791",
          "text": "Question:  \nWhat about sync to Power-BI, does anyone use DuckDB & PowerBI combined?  \nIf so, how do you handle Power-BI synchronizing the data from Duck?",
          "score": 1,
          "created_utc": "2026-02-06 10:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vtkw4",
          "author": "peterv50",
          "text": "We use it in production mainly for analytics/log storage because it‚Äôs fast, multi-threaded, and compresses insanely well (for us it beats MySQL even with InnoDB compression).\n\nWe write logs as Parquet and use DuckDB to query/aggregate directly on those files. That gives us cheap storage + quick ad-hoc queries without running a heavy warehouse for this workload.",
          "score": 1,
          "created_utc": "2026-02-06 11:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4illi5",
          "author": "zenspirit20",
          "text": "We have built our customer facing dashboard on top of DuckDB (usecase is similar to what Google Analytics does). We evaluated it against Postgres, while it was easier to continue using Postgres, for our queries, DuckDB was an order of magnitude faster. The nice side benefit is that we are running it on the server along with our app, so there is no additional cost and so far we haven‚Äôt have had any ops overhead managing it.",
          "score": 1,
          "created_utc": "2026-02-09 22:50:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o7zj8",
          "author": "Acceptable-Sense4601",
          "text": "As a data analyst, i use it in report automation to store intermediate data. So the report starts with CSV files that need to be cleaned and manipulated. The result of that stage is stored in DuckDB, then the rest of the automation pulls data from that DuckDB file.",
          "score": 1,
          "created_utc": "2026-02-05 06:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3okz5j",
              "author": "Free-Bear-454",
              "text": "Is it some kind of adhoc/local work or production one? I mean something with orchestrated pipelines, CICD, deployments, whatever...",
              "score": 1,
              "created_utc": "2026-02-05 08:00:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3p9sw3",
                  "author": "Acceptable-Sense4601",
                  "text": "It‚Äôs either me downloading CSV‚Äôs with the raw data or me extracting the data from the production database (the CSVs come from the same place but i only have the back end access to some of it at the moment). But the data goes into reports that are used by senior leadership.",
                  "score": 1,
                  "created_utc": "2026-02-05 11:49:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxzr61",
      "title": "My boss asked about the value I bring to the company.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxzr61/my_boss_asked_about_the_value_i_bring_to_the/",
      "author": "Consistent-Appeal922",
      "created_utc": "2026-02-07 01:02:39",
      "score": 97,
      "num_comments": 92,
      "upvote_ratio": 0.92,
      "text": "Basically send me that through a message, and what exactly I generated for the company in the last quarter.. that the future of the team I work in (3 people) depends on that answer. The problem? I am not sure.. joined a year ago and they made me jump from project to project as a business analyst, ended up configuring a data quality tool and configuring some data quality checks on pipelines, help people use the tool, log in, etc. Basically I work 2 hours a day .. sometimes I don‚Äôt have any task to do.\n\nAt the same time I got a job offer from a company, is less money ( I am very well paid right now). Should I switch job and start fresh or stay and defend my position?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxzr61/my_boss_asked_about_the_value_i_bring_to_the/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4069xi",
          "author": "Think-Trouble623",
          "text": "you‚Äôre next on the layoff list, jump ship if you have an offer",
          "score": 270,
          "created_utc": "2026-02-07 01:09:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o407rap",
              "author": "Consistent-Appeal922",
              "text": "Maybe, but they are not laying off people and the quality of their data is a disaster, pipelines failing everywhere, and definitely under staffed. \n\nWhat I don‚Äôt understand is why they even hired me.. I did everything I was asked to do, but they were just not dedicating time to myself. Had a lot of initiative multiple times to participate in projects/proposals to do stuff and most of the time they said (this is handled by other team, stay in your lane). For the last 4 months being in a more ‚Äúsupport‚Äù role for this data quality tool, people reaching out to me for access, for explanations on how to use the tool, for onboarding sessions, but not much else. I many times asked my supervisor for a roadmap for the upcoming year and he said he needed to discuss that with more people, now he come back with that question.. very strange",
              "score": 23,
              "created_utc": "2026-02-07 01:18:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o409lof",
                  "author": "Think-Trouble623",
                  "text": "sorry brother, this question only works if it‚Äôs day one for your new boss. I can rattle off every single achievement, struggle, and goal of my employees without having to ask them. This question is not good and you should leave.",
                  "score": 117,
                  "created_utc": "2026-02-07 01:29:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40iees",
                  "author": "kayakdawg",
                  "text": "> but they are not laying off people\n\n\nnobody is ever laying off people\n\n\nuntil they are",
                  "score": 43,
                  "created_utc": "2026-02-07 02:24:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40u40r",
                  "author": "RoomyRoots",
                  "text": "The sad reality is that most companies are filled with useless positions and there are loads of evidence on that. Don't hang around on why you were hired, focus always on what you can learn and apply. \n\nIt is your employer that needs to understand what you can contribute to the company, not the reverse. People are delegating the very basics of management because most managers are incompetent. ",
                  "score": 20,
                  "created_utc": "2026-02-07 03:38:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o423d1u",
                  "author": "paco1305",
                  "text": "> Maybe, but they are not laying off people \n\nMy dude, some times you need to read between the lines when you are in danger of being laid off\n\n> that the future of the team I work in (3 people) depends on that answer\n\nThis is not one of those times though, they've flat out told you",
                  "score": 13,
                  "created_utc": "2026-02-07 10:07:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o426qh1",
                  "author": "Environmental_Pop686",
                  "text": "Understaffed but you work 2 hours a day? You saying their data is a disaster and pipelines are failing but are working 2 hours a day.",
                  "score": 9,
                  "created_utc": "2026-02-07 10:40:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o42j9y3",
                  "author": "Expensive_Culture_46",
                  "text": "It‚Äôs not strange. You are marked and you should bail. \n\nAnd if you‚Äôre only working like 2 hours a day then you really aren‚Äôt bringing any value because leadership doesn‚Äôt know how to effectively utilize you. However, it being a leadership problem won‚Äôt save you here.",
                  "score": 8,
                  "created_utc": "2026-02-07 12:31:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o430pgo",
                  "author": "HolyGeneralK",
                  "text": "Preface here - this got waaaayyy longer than I thought. Don‚Äôt take the ‚Äúyou‚Äù defensively below. \n\nI would encourage a little thought experiment here. Initially, take yourself out of the picture. Look at your job description (what you were hired to do). Look for value statements in there (find insights, reduce costs, improve productivity, etc.). This helps quantify ‚Äúvalue.‚Äù Then look a little broader (Reddit is a good start) - where do data engineers add value. Look at other job descriptions. Once you have a good understanding of where data engineers add value to an organization, that‚Äôs your sales pitch to you boss. ‚ÄúI am here to enable our sales and marketing teams to increase revenue by improving the breadth, depth, and quality of data available for our business analysts to use.‚Äù Don‚Äôt bring that yet. \n\nNext - if someone is questioning the value you bring,  they either don‚Äôt have a good understanding of the first part of the exercise, which can happen. That can be solved with a bit of education and managing upward. It may also be your lead is asking on behalf of another person in the organization.\n\nThe other part is that they know what your value should be but does not observe the company getting it (expectations not being met). That could be interpreted as ‚Äúyou don‚Äôt know why you‚Äôre here and look lost,‚Äù ‚Äúyou‚Äôre lazy,‚Äù ‚Äúyou‚Äôre working hard but on the wrong things,‚Äù or ‚Äúyou used to engage hard with other people but now you don‚Äôt, what‚Äôs wrong?‚Äù Or, I have seen this occasionally- ‚ÄúCan we replace you with an LLM toolset?‚Äù\n\nKeep peeling back the onion here - do a ‚Äú5 Whys‚Äù down various paths. If you do this honestly I think you will find some observations about your role and the organization that are things you can learn from (or put into consideration for your next role). \n\nFor example: ‚ÄúI believe that the value a data engineer, and my role/job description, brings to an organization is X, Y, and Z. I cannot achieve the value that I believe my role as a data engineer should bring because the organization does not have a policy or incentive to put more diverse and higher quality data sets to the Business Intelligence Suite. I don‚Äôt have the political acumen or appropriate authorities to drive a change at this level. I could use my 4-6 hours of downtime per day integrating with specific teams for a few weeks at a time. I would need support from leadership to do this because historically, teams are highly siloed and resist me working with them. Here is a plan, a timeline, and here is a specific outcome I hope to achieve.‚Äù \n\nThat is a level of maturity that I, as a leader, would respect. Be careful of assigning any blame - you need to talk about impediments to your ability to deliver value. \n\nAs a manager, if one of my employees only ‚Äúworked two hours a day‚Äù and was getting salary, that‚Äôs a red flag worth looking into. I like my developers and engineers to have a backlog of work - we currently have several months work per person - and I like to see them showing 6 hours of real good ‚Äúproductivity‚Äù each day. I assume that the other two hours are emails, conversations, helping others out - still value add, but it‚Äôs the grease in the cogs of the machine.\n\nI would be looking at that 4 hour gap. You said their data and pipelines are garbage despite having a tool. Is the tool hard to use? Do they know how to use it effectively? Are they required to use it? Are they required but don‚Äôt see a value/return on investment so they half-ass it?\n\nIf they all use the tool, and the data is great, does that translate into more work for you? Less? Think of an ideal end state. Everyone uses it. The data is fantastic. Sales go up 200%. There is a parade in your honor. What does the job look like then? \n\nAlternatively, you may have already checked out mentally from this job and are just cruising to collect a pay check. Personally I would do the introspection and 5 Whys exercise and see if there‚Äôs a path to being engaged again at this job because you want to avoid the same conditions in the future. Some places hired a bunch of ‚ÄúNEW ROLES‚Äù for fear of missing out on industry trends with no idea what to actually do with them long term. Or they do know and you‚Äôre not delivering (for any number of reasons).\n\nAlso, be aware that, in my observations, the job market is starting to tighten. If you do plan to move companies, can you use your 4-6 hours of downtime per day training on new tools?",
                  "score": 3,
                  "created_utc": "2026-02-07 14:22:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41sxrk",
                  "author": "I_Blame_DevOps",
                  "text": "Sounds a lot like my situation. Was hired 8 months ago to fix their ETL issues. Spent the first 5-6 working on building out CDC infrastructure for a high volume database. Had it mostly working but they were becoming increasingly impatient and decided to just keep using physical database replication. Outside of that my boss seems to believe that I should fix all their DB performance issues. My dude, you‚Äôre running analytical queries against an OLTP Postgres database and are surprised this is slow? He‚Äôs made it increasingly clear that he doesn‚Äôt see the value in a data engineer so at this point I‚Äôm just doing support functions until I can find somewhere that actually values a data engineer.",
                  "score": 5,
                  "created_utc": "2026-02-07 08:24:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41zqk8",
                  "author": "davf135",
                  "text": "I think, part of the problem is \"doing everything [you were] asked to do\". In some level, they should be asking YOU what to do, or else you are totally replaceable.",
                  "score": 4,
                  "created_utc": "2026-02-07 09:31:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41yc9t",
                  "author": "Ojy",
                  "text": "Don't think just about what you have done but what you can bring to the company. You have already identified the problems you can see in the company. Don't give him a list of things that you have done, highlight these problems and give him the solution, and what you think YOU need to do to fix them, give him a timeframe and cost etc. \n\nDon't think of this as an end of the world event, but as an opportunity to shine. It'll put you head and shoulders above the other workers, if they just provide a list of, I did this, I did this, I did that... Blah blah blah.",
                  "score": 2,
                  "created_utc": "2026-02-07 09:16:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41sm8u",
                  "author": "TurboMuffin12",
                  "text": "Either you don‚Äôt get it and ur at a big company where your boss can‚Äôt figure out what to do with you or your boss is an idiot",
                  "score": 1,
                  "created_utc": "2026-02-07 08:21:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4f94xh",
                  "author": "slayerzerg",
                  "text": "You deserve better. I‚Äôve experienced that ‚Äúyou don‚Äôt own this, stay in your lane‚Äù just a bunch of groups who want the more interesting or value-providing projects. And they may not be capable of actually executing a plan for it, bogs down the company, and your growth as well. Go somewhere where some role where they need you and they want you to build things for them without all those constraints",
                  "score": 1,
                  "created_utc": "2026-02-09 12:37:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o412y36",
              "author": "redditreader2020",
              "text": "Final answer.",
              "score": 2,
              "created_utc": "2026-02-07 04:40:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4082d9",
          "author": "bugtank",
          "text": "Why have you only been working 2 hours a day? Have you asked for more work? What about any of these so called improvements that the data needs? Have you pushed or taken initiative on those actions? \n\nYou always need to have the answer to this question at the tip of your tongue. If not now, then make sure you have to ready for your next job.",
          "score": 61,
          "created_utc": "2026-02-07 01:20:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o408qpx",
              "author": "Consistent-Appeal922",
              "text": "A lot of initiative. But the problem is they never put our project under any leadership since they hired us.. weeks without meetings or calls, asking for how I can help people. Then they put a supervisor that manages multiple projects to assign us work, but not enough, I asked many times what else we can do, what‚Äôs the roadmap for our team and this supervisor said (I am waiting on the manager to define that).. now that manager came to me with that question, I am like dude I been asking for the last 4 months what‚Äôs the roadmap for this team",
              "score": 18,
              "created_utc": "2026-02-07 01:24:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40bpa3",
                  "author": "Altruistic_Stage3893",
                  "text": "Sounds like you're screwed. Jump ship and focus on owning your projects and taking leadership. If you'll keep hiding behind \"the other guy did not move it\" you'll never get to management. might not be your goal. that's fine ofc just own the decision",
                  "score": 41,
                  "created_utc": "2026-02-07 01:42:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40j557",
                  "author": "kayakdawg",
                  "text": "sound like your manager is incompetent - given this and the fact they had to ask you what value you deliver¬†\n\n\ngood lesson for future, in that situation you can either take initiative and ownership, find your own roadmap or leave - otherwise the decision will eventually be made for you¬†",
                  "score": 4,
                  "created_utc": "2026-02-07 02:28:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40cjxl",
          "author": "Treemosher",
          "text": "You said multiple times in this post and replies to other comments that you ask them what the road map is.  Are you sure they're not expecting you to draft that up?\n\nAsking for a roadmap multiple times gives me the impression that they could see you as that guy who constantly needs direction.\n\nMaybe they were hoping you'd come up with your own roadmap.\n\n>Maybe, but they are not laying off people and the quality of their data is a disaster, pipelines failing everywhere, and definitely under staffed.\n\nIf you recognize this, have you come up with a road map to address these things you're seeing?  Is it possible they were expecting you to address them and communicate your plan?\n\nThe way you explain how you ask about a road map just feels like \"hey, got any work for me?  what do you want me to do today?\".\n\nI only have your words to go by here, so my impression is likely misinformed.  Just throwing it out there that if you really are asking about a roadmap and inserting yourself into other teams' projects and getting shut down, that seems to me that they're expecting you to manage and direct yourself more than you are.\n\nAnd now they're asking you what value you bring.  Without actually being there to see for myself, this is the best take I can come up with.\n\nIf I were you, I'd take the other job offer and consider the lessons to be learned here with the luxury of a fresh start.  I've been in a similar spot and it is very frustrating to navigate.  \"Do they want me to be my own manager?  Or do they want to manage me?\"  If you don't get that right, it can be really dicey I think.",
          "score": 22,
          "created_utc": "2026-02-07 01:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40f9oy",
              "author": "Consistent-Appeal922",
              "text": "You are right in many things. But I presented a roadmap , I said I will onboard teams to the data quality tool , make sure data products upstream assets have the right data quality checks, that there is an incident management response process , follow with tech that the necessary integrations are happening, etc\n\nI started with a team that owned a pipeline working on defining and enabling data quality metrics, sending alerts to them, etc.. was going well, until my manager said that‚Äôs not my role. Teams need to define their own metrics, not me, since they understand the data. And data engineers will decide the incident management process not me.. that I should help them enabling the data quality controls in the tool. So basically he reduced my scope when I offered myself as leading the data quality initiative. Few months after that? Very few people enabled alerts, critical pipelines that were used for very important business purposes failed and no one realized. My manager got pressure from his superiors, he came back yelling it us like it why we don‚Äôt have a dashboard showing all the critical alerts failing and I was like, the alerts are not even in place. Teams are not using the tool even that you asked them to use it and reach out to us for help.. we need ownership and someone telling them constantly to do it, I tried.",
              "score": 7,
              "created_utc": "2026-02-07 02:04:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40hzos",
                  "author": "Treemosher",
                  "text": "Yeah it's way too much in the for me to wrap my brain around at the moment, honestly.  \n\nYour manager and you seem to have a huge disconnect.  Sounds like you and them need to sit down and go over expectations and figure out where the drop-off was.  \n\nEven if you decide to leave, I would try to have this conversation just so you start your next job with a big lesson learned, regardless of who is at fault.  Maybe before turning in your resignation.\n\nI am not saying you should leave, that's your decision.  But if you do, I would try to learn how to avoid this situation again.  Bad experiences are ok as long as we find a way to grow and improve afterword.  \n\nThis is really hard because I don't know you and I sure as hell don't know your boss.  So toss everything I'm saying out the window if you think it'll make things worse.  \n\nThe point is to learn & grow above all else (aside from paying the bills obviously).",
                  "score": 8,
                  "created_utc": "2026-02-07 02:21:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o40ez41",
              "author": "ScottFujitaDiarrhea",
              "text": "At the same time how is something like this a surprise? Does their company not have reviews or 1:1s?",
              "score": 2,
              "created_utc": "2026-02-07 02:03:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40g18w",
                  "author": "Treemosher",
                  "text": "Without being there, who the hell knows.  It's possible the manager can also suck.\n\nThe employer's responsible for communicating expectations of the employee they're paying.  It's the employee's responsibility to understand what they're being paid to do.\n\nThis scenario, if OPs explanation is accurate, reeks of both parties failing in these responsibilities.\n\nCommunication is everything.  This kind of stuff is what lack of communication looks like to me.\n\nWe only have one side of the story though, so it's impossible to take this beyond an armchair analysis lol",
                  "score": 3,
                  "created_utc": "2026-02-07 02:09:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40zhj1",
                  "author": "minato3421",
                  "text": "There are some managers who don't conduct 1:1s. They take advantage of freshers in situations like OPs and screw them over",
                  "score": 4,
                  "created_utc": "2026-02-07 04:15:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o42tn8x",
              "author": "TA_poly_sci",
              "text": "Yeah, I have never been in or observed a data-focused position where it was not a central expectation and requirement for people to be self-driven. Chances are leadership are not data people themselves. And even if they are, they do not have the time to be.\n\nAnd as a general rule, people should not be surprised to be asked what value they bring to a company when they are getting paid (presumably) a quite nice salary.",
              "score": 2,
              "created_utc": "2026-02-07 13:41:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o40gphg",
          "author": "healthcare-analyst-1",
          "text": "Your boss needs to have something to kick up to their boss to justify the team's existence. Write up a short bullet point memo detailing actions you've done & the resulting accomplishments from them. Feel free to put *everything* on there regardless of what the actual lift ended up being, just try to avoid the appearance that you're filibustering.\n\n* Configured and implemented X Data Quality Tool\n* Implemented automated data quality checks on Y pipeline, ensuring a Y% data accuracy rate after deployment\n* Implemented data quality checks on Z pipeline, which successfully identified problem A in data quality for resolution\n* Onboarded stakeholders from business groups C, D, and E onto Data Quality Product\n* Provided training & ongoing support for users from business groups C, D, and E to allow for self-service\n\nIn the meantime, it sounds like your management is aloof & afraid of stepping on other teams' toes. To keep yourself busy maybe send a few follow ups to some of the teams that you've onboarded onto the tool to make sure everything is working properly & see if they have any issues you could resolve that fall within or overlap with your purview. Ideally initially small tasks that you can resolve with your free time & then mention to your boss afterwards, this might lead to you being able to develop a pipeline of additional work if necessary.",
          "score": 6,
          "created_utc": "2026-02-07 02:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41afec",
          "author": "Homonkoli",
          "text": "Sorry, but if you don‚Äôt have an answer then you‚Äôre really not valuable for the company from management perspective. However, don‚Äôt let that define you, poor resource management is not your responsibility, but at the same time its your responsibility to actively ask/seek proper valuable work that is impactful for your department or workplace in general.",
          "score": 7,
          "created_utc": "2026-02-07 05:37:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4knbzg",
              "author": "Sensitive-Sugar-3894",
              "text": "Most people don't know how to sell themselves. We see deliveries as \"easy stuff, no need to mention\".",
              "score": 1,
              "created_utc": "2026-02-10 06:33:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o41ge6h",
          "author": "Chowder1054",
          "text": "I would switch. I don‚Äôt get the talk here blaming you for not taking the initiative. Ambiguity has limits, you need some sort of goal/overarching project and then you can find things to do. When you have zero idea where and you need to practically scavenge for work and ideas, then it‚Äôs a leadership problem.\n\nYour manager should be the one passing down projects and ideas down to their team. And from what you said, it just sounds like a disconnected mess. I would strongly suggest you jump ship elsewhere.\n\nDealt with places like this before, and the lack of work and leadership caused teams to fall apart fast.",
          "score": 6,
          "created_utc": "2026-02-07 06:27:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40c0c0",
          "author": "Old_Tourist_3774",
          "text": "95% you are in the chopping block already and they are just checking to make sure nothing important slipped by so they can fire you without it backfiring.\n\nAnd from you comments it seems not even your fault, I had the same experience with companies that did even know what they want and need and 1 man team seldom can do something if he doesn't even have contact with the users pains and needs",
          "score": 9,
          "created_utc": "2026-02-07 01:44:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40ggi7",
              "author": "amejin",
              "text": "Little oversight and lots of problems and you think it's not on them to fix things? I fully disagree. \n\nThis is the mindset difference between a junior engineer and a senior+\n\nTake ownership. If things are a mess and you can objectively prove a better solution, that better solution should be paraded around until someone listens to it or explicitly kills it ( hopefully with a reasonably explanation as to why).",
              "score": 5,
              "created_utc": "2026-02-07 02:12:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o42c2hd",
                  "author": "Old_Tourist_3774",
                  "text": "I think you did not get it.\n\nFix what? Give a solution to what? Legit people will tell things don't work but can't even point to why, or what the tool is doing or how they interact with each other. Everything is blurry and you become isolated.\nAnd these companies tend to be massive, with decades of patchwork, incredible amounts of segregation of systems, acceses and things that does not work together.\n\nAnd honestly, i could not care less for \"having ownership\".",
                  "score": -1,
                  "created_utc": "2026-02-07 11:30:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40g5nz",
          "author": "T3quilaSuns3t",
          "text": "I just had this happen to me today. Got a talking to.\n\nLol I didn't really care üòÇ",
          "score": 3,
          "created_utc": "2026-02-07 02:10:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4knht0",
              "author": "Sensitive-Sugar-3894",
              "text": "Not caring is the best position to be at. But it's a luxury for the majority.",
              "score": 2,
              "created_utc": "2026-02-10 06:34:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o40wogo",
          "author": "bugthelady02",
          "text": "Do not jump ship. Wait until they fire you, hopefully, with severance.\n\n1- Highlight your contribution to different projects.\n\n2- Reiterate that you would have loved the chance to work on X project but we're denied.\n\n3 - Tell them what value add you can bring to future initiatives.\n\n4 - keep applying and interviewing\n\nIt sounds like they were not organized with projects lined up for you to jump in. Either that or you have not been proactive enough to create work for yourself.",
          "score": 9,
          "created_utc": "2026-02-07 03:56:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40lbh2",
          "author": "refrigerador82",
          "text": "You should ask for more work. Dedicating 2 hours per day is lowkey a dick move.\n\nThey probably noticed it and want to fire you.",
          "score": 5,
          "created_utc": "2026-02-07 02:42:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40cqbf",
          "author": "Patient_Professor_90",
          "text": "Switch immediately",
          "score": 3,
          "created_utc": "2026-02-07 01:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40jz4p",
          "author": "SRMPDX",
          "text": "What did your job description say when you interviewed? Are you doing any of that?  You've mentioned in this thread that you don't know why they hired you if they don't have the work, seems like your boss is catching up to that. He's likely pretty sure you don't do anything useful but wants to check so he can get others trained to pick it up before you're let go.",
          "score": 3,
          "created_utc": "2026-02-07 02:34:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40xuq7",
          "author": "Cruxwright",
          "text": "Reading your replies....\n\n\"I'm here so middle management can tell someone, no.\"\n\nI started doing my job as described when hired and was told, \"no, stop.\"\n\nI started initiatives to clean data and manage pipelines so things like incident X wouldn't happen. I was told, \"no, stop,\"\n\nI offered to help other teams and was told, \"no, stop.\"\n\nI asked what the roadmap for the department is and where I can help and was told, \"no, stop.\"",
          "score": 3,
          "created_utc": "2026-02-07 04:04:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o410dpi",
              "author": "Consistent-Appeal922",
              "text": "Yes. Sometimes straight ‚ÄúThat‚Äôs not our scope/your scope‚Äù and sometimes simply not getting any engagement",
              "score": 1,
              "created_utc": "2026-02-07 04:21:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f2xqg",
          "author": "llamacoded",
          "text": "That's a direct question from your boss, but also an opportunity to be specific. \"Configuring a data quality tool\" is fine, but what did it \\*do\\*? Did your checks prevent X bad records from hitting production pipelines? Did they stop Y broken feature values from affecting a critical report or even a model downstream? Did you free up Z hours for someone who used to manually clean that data every week? You need to tie it to measurable outcomes like prevented errors or saved time.  \n  \nHonestly, working 2 hours a day isn't sustainable for your career. You're not learning or building much. If the new job offers real problems to solve and actual projects, even for less money, I'd consider it. Sticking around just for the higher paycheck when you're stagnating will make you less competitive for future roles.  \n",
          "score": 2,
          "created_utc": "2026-02-09 11:49:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40chjf",
          "author": "tophmcmasterson",
          "text": "Sounds like your boss is asking the right questions honestly. \n\nI can‚Äôt imagine working someplace as a data engineer and only having two hours of work a day and expecting to remain hired. \n\nWith any job if you want to do well it‚Äôs about finding ways to make yourself valuable/indispensable. If you‚Äôre sitting around waiting to move on projects, or blaming leadership for not managing things etc. when you‚Äôre working two hours a day I don‚Äôt know what to tell you. \n\nI‚Äôd start prepping for a new job as it honestly just doesn‚Äôt sound like you‚Äôre bringing much value where you are now.",
          "score": 4,
          "created_utc": "2026-02-07 01:47:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40ct3t",
              "author": "Consistent-Appeal922",
              "text": "Definitely not adding much value currently, and I am not a data engineer anyway, I am a business analyst. My problem is they didn‚Äôt hire me and said, make yourself valuable , they really sold me the job during interviews and since I joined I didn‚Äôt have any leadership, directions, etc.\n\nI can‚Äôt just guess what I need to do",
              "score": 3,
              "created_utc": "2026-02-07 01:49:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40dm4l",
                  "author": "ATL_we_ready",
                  "text": "Honestly, nobody wants a hire that has to be told everything to do.  Learn to thrive in ambiguity and reach out to people and figure out how to make things better with skills you have.  You have to want it‚Ä¶",
                  "score": -3,
                  "created_utc": "2026-02-07 01:54:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o408you",
          "author": "Specific-Mechanic273",
          "text": "Have you tried being proactive? Not asking for tasks but just pushing improvements for the data product?\n\nsome companies just expect that from you. Not everyone will feed you with tasks if they expect you to be the subject matter expert. ",
          "score": 1,
          "created_utc": "2026-02-07 01:25:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40fm79",
          "author": "Wadix9000f",
          "text": "Does this boss exactly know what you do? \n\nIs he the one who made you jump through all those roles? \n\nWhat is your visibility to him? \n\nIs this an  engineering/tech manager or a People manager? \n\nStill asking such a question I would not be surprised if he's the one who is on the chopping block",
          "score": 1,
          "created_utc": "2026-02-07 02:06:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40g2us",
              "author": "Consistent-Appeal922",
              "text": "He is a tech manager, he hired me and bunch of people. He basically is very busy with AI stuff, and he never gave me much attention until now.. First was under a team , the team got disolved, supervisor left. Then assigned me another supervisor who wasn‚Äôt joining any call. Then another supervisor who was supposed to be aligned with my manager , they sit next to each other , I thought he was aware of our existence now. But it looks like he is not",
              "score": 2,
              "created_utc": "2026-02-07 02:09:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40wtav",
                  "author": "Wadix9000f",
                  "text": "yeah... i'll have to agree with what most people are saying here, as cliche as it sounds but most people quit their jobs because of bad managers. Perhaps you should look into some sort of applying for other teams or roles within the company if you like it there and he or she would not be your boss.",
                  "score": 2,
                  "created_utc": "2026-02-07 03:56:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40z6sr",
          "author": "mindwrapper13",
          "text": "YOE? I would say find a new job to challenge yourself regardless of what your boss says.",
          "score": 1,
          "created_utc": "2026-02-07 04:13:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41n7ym",
          "author": "Longjumping_Lab4627",
          "text": "I would ask for a call with the manager and tell him what you are saying that you did x and y for data quality. Tell him you want to work on a more interesting project and be strict. Tell him how you feel and the worst case if it didn‚Äôt change under 3-7 days leave and go to the next job.\n\nIf you have an offer from another company what are you afraid of? It‚Äôs time to be honest with yourself and the manager",
          "score": 1,
          "created_utc": "2026-02-07 07:30:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41tqjx",
          "author": "PrestigiousAnt3766",
          "text": "Try to be more proactive next time.\n\nWork is more enjoyable, you learn more and are not fired as easily.",
          "score": 1,
          "created_utc": "2026-02-07 08:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41y278",
          "author": "fistular",
          "text": "I work in an R+D role and I am \\*constantly\\* creating proposals for work with solid business cases behind them.  Some sputter and die, some I work on for months.  You need to be more proactive about identifying where you can be useful and pitching that use to stakeholders.",
          "score": 1,
          "created_utc": "2026-02-07 09:14:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o425nwq",
          "author": "TheTackleZone",
          "text": "Never answer that question with what you did generate. Answer it with what you could generate. Talk about all the opportunities missed due to the bad management of the team and what you would do if you were in charge.",
          "score": 1,
          "created_utc": "2026-02-07 10:29:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42ku7b",
          "author": "Typhon_Vex",
          "text": "ah the data quality death trap.\n\nno one cares, not the bussines, not the developers, it¬¥s fake employment. stay away",
          "score": 1,
          "created_utc": "2026-02-07 12:43:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42zcv3",
          "author": "Barbacula",
          "text": "Ask your boss what he/she brings to the company, if they don't know what their own reports are doing or why they have them. \n\n(probably don't do this unless you *really* want to be on the layoff list)",
          "score": 1,
          "created_utc": "2026-02-07 14:15:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43cqpl",
          "author": "McNoxey",
          "text": "Honestly I feel rude saying this, but if you don‚Äôt know how to answer, you‚Äôre probably not adding value.",
          "score": 1,
          "created_utc": "2026-02-07 15:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44d5yo",
          "author": "MrSquigglesWiggle",
          "text": "You mentioned that you only work 2 hrs but the company's data quality is bad. You could've used your free hours to improve those. Even planning out and creating a proposal that they would reject is better than being seen doing nothing. There are really times where you have to create your own pet projects on the side. Your team's main goal should be improving the quality of the data even without being asked.",
          "score": 1,
          "created_utc": "2026-02-07 18:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o451ei8",
          "author": "Buffalo_Burner",
          "text": "Take every little thing you worked on and send it in a list to chatgpt. Tell chatgpt to bake you up a nice bullshit answer.",
          "score": 1,
          "created_utc": "2026-02-07 20:31:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47gsn6",
              "author": "Corn-Fed-Mule",
              "text": "I think OP‚Äôs boss is indirectly telling him that you don‚Äôt provide value and would rather push you to quit instead of paying for unemployment. You would likely be let go in the new round of layoffs. I‚Äôd polish that resume and start looking for a higher paying job.. if it‚Äôs a good fit and +/-5% of your current salary, take it, else let them fire you. You don‚Äôt want to be around after round 2 anyway..",
              "score": 1,
              "created_utc": "2026-02-08 05:32:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48bfmy",
          "author": "NoleMercy05",
          "text": "Why are you working 2 hrs a day.  Really?",
          "score": 1,
          "created_utc": "2026-02-08 10:13:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48n3v0",
              "author": "Consistent-Appeal922",
              "text": "Not enough tasks assigned?",
              "score": 1,
              "created_utc": "2026-02-08 12:00:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ciahw",
          "author": "jonahnr",
          "text": "It honestly sounds like the problem is you do tasks you are assigned instead of taking initiative to find the biggest pain points for the business to solve. It sucks since your manager should be helping find those pain points, but if you want to grow, then doing what youre doing is of course going to get you laid off..you're not really providing any real value.",
          "score": 1,
          "created_utc": "2026-02-09 00:27:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dgau1",
              "author": "Consistent-Appeal922",
              "text": "Honestly? If they hired me they need to give me a job to do. If they want me to discover how to make the company work better, they need to hire me as a consultant and I will charge them 10 times what I make.. if they don‚Äôt like it I can go somewhere else",
              "score": 1,
              "created_utc": "2026-02-09 03:31:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4htrq5",
          "author": "ntdoyfanboy",
          "text": "You work two hours a day? Yeah, you're on the chopping block. Get the new gig and start to shine",
          "score": 1,
          "created_utc": "2026-02-09 20:31:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lzfn2",
          "author": "GAZ082",
          "text": "You are already cooked. You needed to show initiative asking for stuff to do (if junior) or pinpointing issues/blockers and managing with your boss a plan to fix to have visibility.",
          "score": 1,
          "created_utc": "2026-02-10 13:23:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lzqny",
              "author": "Consistent-Appeal922",
              "text": "Interestingly after I said I have another job offer they started giving me a lot of work and asked me to stay ü§î",
              "score": 1,
              "created_utc": "2026-02-10 13:25:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4m8fzx",
                  "author": "GAZ082",
                  "text": "There you go! Be vocal, don't be afraid. And if you are low on work, show initiative. Best of luck!",
                  "score": 2,
                  "created_utc": "2026-02-10 14:13:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o40d51q",
          "author": "ATL_we_ready",
          "text": "You work 2 hours a day and it probably shows!  Hence the question perhaps?",
          "score": 1,
          "created_utc": "2026-02-07 01:51:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40h518",
          "author": "chrisgarzon19",
          "text": "If ur not sure\nYou‚Äôre the problem \nStart looking for a job\nHere‚Äôs the thing though\nFIND OUT\nCause the way you nail the interview is by explaining that exact question to interviewers\n\nNot trying to be mean. Trying to help.\n\nBut it‚Äôs something I‚Äôm so passionate about cause I think 80% of engineers deal w exactly this isssue\n\nThey don‚Äôt know their business impact",
          "score": 0,
          "created_utc": "2026-02-07 02:16:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40rpyf",
          "author": "Tougher-Guy",
          "text": "First understand things like you are learning something or the other everyday , if not just leave and make your soul happy \nDon't just get money minded for your self happiness",
          "score": 0,
          "created_utc": "2026-02-07 03:22:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qym03a",
      "title": "Coinbase Data Tech Stack",
      "subreddit": "dataengineering",
      "url": "https://www.junaideffendi.com/p/coinbase-data-tech-stack",
      "author": "mjfnd",
      "created_utc": "2026-02-07 18:52:11",
      "score": 87,
      "num_comments": 17,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qym03a/coinbase_data_tech_stack/",
      "domain": "junaideffendi.com",
      "is_self": false,
      "comments": [
        {
          "id": "o45yw4e",
          "author": "Relative-Cucumber770",
          "text": "Might be a rookie question, but: What's the point of using Snowflake for warehousing if they're already using Databricks (Unity Catalog)? ",
          "score": 29,
          "created_utc": "2026-02-07 23:40:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45zmr3",
              "author": "mjfnd",
              "text": "Multiple teams owning different stacks or in the middle of migration which could take years.\n\n\nI can resonate with their stack as we also used DBX for processing core pipelines and BI related workflows on Snowflake linked to Tableau.",
              "score": 14,
              "created_utc": "2026-02-07 23:44:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o48ybve",
              "author": "a_lic96",
              "text": "Diversificaci√≥n, Risk hedging, avoiding full vendor lock-in, as well as to have more contractual power during negotiations",
              "score": 2,
              "created_utc": "2026-02-08 13:24:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47xgiy",
          "author": "PeitersSloppyBallz",
          "text": "Technology bingo much?",
          "score": 5,
          "created_utc": "2026-02-08 08:01:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45oflq",
          "author": "joeblk73",
          "text": "If you are on AWS why use Looker a GCP product ?",
          "score": 3,
          "created_utc": "2026-02-07 22:36:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45r700",
              "author": "halfrightface",
              "text": "looker core vs studio. studio is what google data studio used to be and probably what you're thinking of. they're using core as a semantic layer on top of snowflake to leverage lookml to build their views/explores.",
              "score": 12,
              "created_utc": "2026-02-07 22:52:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46d75u",
              "author": "Vautlo",
              "text": "Depending on the needs of the organization, Looker can beat Quicksight in a lot of ways. I think the value is in the modelling/semantic layer, governance, and being git native/BI as code. \n\nI've been through a migration from Tableau to Looker, as well as standing up and maintaining a self hosted Looker instance, both at AWS shops. Quicksight wasn't really considered as an option for either project - one was in the public sector and they put a lot of value on the governance baked into Looker, and the other was scared off of anything primarily UI driven and really valued the idea of BI as code.\n\nThe public sector project was pre-acquisition. I don't recall the costs from back then, but I'd bet that it was less of a factor than today.\n\nQuicksight is way less expensive, though I still doubt I'd choose it if I was the first data hire at a standup today. There are just too many no contract/free options to create decent reports that would satisfy a startup for quite a while.",
              "score": 3,
              "created_utc": "2026-02-08 01:06:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46ftwb",
                  "author": "joeblk73",
                  "text": "What does modelling and semantic layer mean here ?",
                  "score": 1,
                  "created_utc": "2026-02-08 01:22:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o45u6te",
              "author": "mjfnd",
              "text": "I think this is very common, the main reason is Looker is great and popular and it used to be a standalone product, not sure if that's true now, can we just buy looker instead of onboarding to GCP?\n\nWe also had Looker with AWS Stack.",
              "score": 2,
              "created_utc": "2026-02-07 23:09:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o45ou0v",
              "author": "data4u",
              "text": "I was wondering the same",
              "score": 1,
              "created_utc": "2026-02-07 22:38:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4576qi",
          "author": "theath5",
          "text": "Do you know if they use dbt for transformations?",
          "score": 3,
          "created_utc": "2026-02-07 21:03:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o458ejf",
              "author": "mjfnd",
              "text": "I couldn't find any mention of DBT publicly, let me know if you have any insights.",
              "score": 2,
              "created_utc": "2026-02-07 21:09:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o467bki",
                  "author": "ActEfficient5022",
                  "text": "I would have to assume databricks provides transformations I don't see what dbt would add to that given the diagram",
                  "score": 5,
                  "created_utc": "2026-02-08 00:30:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48006f",
          "author": "No_Airline_8073",
          "text": "Databricks and Snowflake and Starrocks and Looker and Airflow as well. Lot of redundancy.\nWhy not just use Databricks scheduler and warehouse and get rid of snowflake and airflow. I can understand why looker over Databricks-redash and maybe starrocks for few things",
          "score": 3,
          "created_utc": "2026-02-08 08:24:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4phuig",
              "author": "alittletooraph3000",
              "text": "Maybe someone who works for CB can chime in here but if they're using multiple compute platforms, seems pretty unlikely that they'd migrate off an orchestrator that's neutral to everything. ",
              "score": 1,
              "created_utc": "2026-02-10 23:35:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0fky1",
      "title": "Visualizing full warehouse schemas is useless, so I built an ERD tool that only renders the tables you're working on",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/706ayxj8yiig1.gif",
      "author": "Spiritual_Ganache453",
      "created_utc": "2026-02-09 20:29:55",
      "score": 85,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0fky1/visualizing_full_warehouse_schemas_is_useless_so/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4lr57a",
          "author": "ThroughTheWire",
          "text": "Pretty cool! think it could be useful for presentations for sure. maybe decent as a documentation tool as well.. I definitely do not want to ever manually draw or create UML tables ever again lol",
          "score": 4,
          "created_utc": "2026-02-10 12:30:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4odebs",
          "author": "DungKhuc",
          "text": "This looks very neat!\n\nOne thing though, besides showing relationship when pointing to a foreign key, what else does this do?",
          "score": 2,
          "created_utc": "2026-02-10 20:16:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxl981",
      "title": "Are you a Data Engineer or Analytics Engineer?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxl981/are_you_a_data_engineer_or_analytics_engineer/",
      "author": "Free-Bear-454",
      "created_utc": "2026-02-06 15:50:53",
      "score": 79,
      "num_comments": 103,
      "upvote_ratio": 0.86,
      "text": "Hi everyone,\n\nMost of us entered the Data World knowing this roles BI Analyst, Data Analyst, Data Scientist and the one only geeks were enough crazy to pick Data Engineer.\n\nLately, Data Engineer is not only Data Engineer anymore. There is this new profile that is Analytics Engineer. \n\nNot everyone seems to have the same definition of it, so my question is:\n\nAre you Data Engineer or Analytics Engineer?\n\nWhatever your answer, why are defining yourself like this?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxl981/are_you_a_data_engineer_or_analytics_engineer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3x74o9",
          "author": "CommonUserAccount",
          "text": "I appreciate the title of this sub is data engineering, but after 20+ years in the industry the obsession with job titles amazes me, and historically there have been way more roles than those you've listed.\n\nWhatever a role is called at company X, I can guarantee it would look completely different in company Y especially when the company size and tooling can vary so dramatically.\n\nBetween the two roles you present, in the current company I work for I would suggest I'm now an analytics engineer as we have a centralised team that does the heavy lifting but without domain knowledge, leaving downstream curation to people like myself. Is my title either of these things? No!",
          "score": 119,
          "created_utc": "2026-02-06 16:04:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xv97o",
              "author": "sahelu",
              "text": "Its all Marketing people in the middle. Creating new titles to sell a better image. ",
              "score": 18,
              "created_utc": "2026-02-06 17:58:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ydnfn",
                  "author": "muneriver",
                  "text": "I think there‚Äôs definitely a marketing side. But I also think it represents a type of data person that does code-first data transformations, knows the software development lifecycle, and in general, has more technical skills than an alteryx/informatica developer who creates pipelines in a GUI. \n\nIf someone is an AE, I generally know what plane of work and skill they operate in. I‚Äôd argue it‚Äôs the most defined out of DA, DS, and DE. \n\nI also think AEs are a subset of DE",
                  "score": 7,
                  "created_utc": "2026-02-06 19:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3y9ibl",
              "author": "Odd-Government8896",
              "text": "Yep. Its just a title someone tossed in workday with a pay grade associated with it.\n\nI stopped looking at titles years ago.",
              "score": 4,
              "created_utc": "2026-02-06 19:06:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47iox4",
              "author": "Python_Darchives",
              "text": "Agreed on the x vs y titlings. Was deemed a Principal Data Science Engineer in telecom when in reality it was a BI and Data Engineer merger, but on the translational level, not ingestion. In my opinion from an earlier position and patterns I‚Äôve seen recently, DE is related to the Data Architecture and ingestion to a level of making the bulk data work. The AE is tasked with an overlap of the translation of ingested data but in a BI level foresight of what the data will be used for in its final destination. They are often a main resource of denormalizing the data into special groups for the analytics and dashboards. One of the best and most haunting quotes I remember from an article was ‚Äúthe best AE is able to get the questions answered before they are even asked.‚Äù",
              "score": 1,
              "created_utc": "2026-02-08 05:48:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xatpk",
              "author": "SirGreybush",
              "text": "I find the US & Canada especially bad at this. I've seen people put engineer or ing√©nieur in their email signatures, yet when I ask them about their degree, they only have a few college-level courses.\n\nI actively encourage real engineers to add their acronym degree in their email signatures, or the analyst to put \", mba\" if they have it, as it helps people craft a proper response in a technical email.",
              "score": -16,
              "created_utc": "2026-02-06 16:22:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xuw7l",
                  "author": "glymeme",
                  "text": "You‚Äôre 51 years old with probably 20+ YOE  and talking about having people add their college degrees to their email signatures so you know how to talk to them. That‚Äôs not a them problem. That‚Äôs a you problem.",
                  "score": 13,
                  "created_utc": "2026-02-06 17:57:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3xtcqx",
                  "author": "Firm-Requirement1085",
                  "text": "Is the title engineer limited to mechanical and structural engineers, or if somebody has a degree in software engineering, could they be classed as an engineer?\n\nIf the latter is true , then it's irrelevant if they have a degree or not, they are as much a data/software engineer as somebody with a PhD if they are in that role.",
                  "score": 7,
                  "created_utc": "2026-02-06 17:49:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xhine",
          "author": "PantsMicGee",
          "text": "Mate, I don't know. I'm whatever bullshit the company decided it wasn't going to ask their Devs to do after having fired their B.I., Testers and BA teams.",
          "score": 52,
          "created_utc": "2026-02-06 16:53:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40429w",
              "author": "Even_Serve7918",
              "text": "Man this is so accurate",
              "score": 3,
              "created_utc": "2026-02-07 00:56:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y1gg2",
          "author": "Remarkable-Win-8556",
          "text": "I am a data dude.",
          "score": 48,
          "created_utc": "2026-02-06 18:28:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ysm8l",
              "author": "burningburnerbern",
              "text": "I‚Äôm someone‚Äôs data bitch üò≠",
              "score": 39,
              "created_utc": "2026-02-06 20:40:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40ewgh",
                  "author": "peppaz",
                  "text": "We are all someone's data bitch at the end of the day lol",
                  "score": 8,
                  "created_utc": "2026-02-07 02:02:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3yezjr",
              "author": "sudotrd",
              "text": "‚ÄúData Guy‚Äù checking in lol",
              "score": 13,
              "created_utc": "2026-02-06 19:33:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4035ap",
              "author": "SaintTimothy",
              "text": "I 'member Data Dude (flavor of visual studio around 2007-10ish intended to package up ssis, ssas, ssrs, and dbproj solution types)",
              "score": 3,
              "created_utc": "2026-02-07 00:50:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o44g3k2",
              "author": "dark_dagger99",
              "text": "I‚Äôm the Data guy too (I head the data team)",
              "score": 2,
              "created_utc": "2026-02-07 18:41:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y4giw",
          "author": "SasheCZ",
          "text": "I'm a Data Developer. Check mate.\n\nDon't fuss around the titles, they don't mean much.",
          "score": 33,
          "created_utc": "2026-02-06 18:42:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3zrfcl",
              "author": "Bolt986",
              "text": "I've told people I'm a \"database developer\" for at least a decade.",
              "score": 4,
              "created_utc": "2026-02-06 23:42:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3zyymd",
              "author": "Rodeo9",
              "text": "My company literally lets us choose titles. I just change it depending on applications.",
              "score": 3,
              "created_utc": "2026-02-07 00:26:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o40govp",
              "author": "Guilty_Ask_9445",
              "text": "My company gave me Data Developer/Analyst. I have to put that in my signature with a slash ‚Äò/‚Äò üòÅ",
              "score": 3,
              "created_utc": "2026-02-07 02:13:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3yreah",
          "author": "[deleted]",
          "text": "I'm a Data Plumber",
          "score": 21,
          "created_utc": "2026-02-06 20:34:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o403obq",
              "author": "SaintTimothy",
              "text": "'The internet is a series of tubes' - Sen. Ted Stevens, June 2006, when arguing opposing a net neutrality bill.",
              "score": 3,
              "created_utc": "2026-02-07 00:53:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o405ghn",
                  "author": "Even_Serve7918",
                  "text": "I mean technically everything is a series of tubes, including humans, so he‚Äôs right.",
                  "score": 0,
                  "created_utc": "2026-02-07 01:04:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o409h2l",
              "author": "krurran",
              "text": "Data Sanitation Engineer\n\n\nAka data janitor",
              "score": 3,
              "created_utc": "2026-02-07 01:29:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4326om",
              "author": "JBalloonist",
              "text": "The answer I always give to people not in the know. ",
              "score": 1,
              "created_utc": "2026-02-07 14:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xdjek",
          "author": "PrestigiousAnt3766",
          "text": "Platform engineer üòÇ, but data discounting that.",
          "score": 15,
          "created_utc": "2026-02-06 16:34:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xv004",
          "author": "soggyarsonist",
          "text": "I'm probably an analytics engineer.\n\nI have colleagues who sort out integrations into our datalake but my team does all the SQL and BI stuff.\n\nI've also set up some scheduled notebooks on the datalake running python scripts and appending data to tables used in reports.\n\nIn all honesty I'd hate being purely BI and entirely dependent on someone else transforming the data into the required format.\n\nI quite enjoy problem solving, and if I need a new skill then I just teach myself what I need to know.",
          "score": 16,
          "created_utc": "2026-02-06 17:57:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o434rm5",
              "author": "0sergio-hash",
              "text": "In the same boat. Trying to get more towards data engineering. Honestly want to do a tour through DE , and then some BI, Data Gov, MDM work, maybe a little Data Science \n\nJust out here sampling all the roles lol. Eventually would love to be \"full stack\" as much as one can be\n\nI feel like the distinctions are a bit arbitrary because to be a good analyst you need to understand master data management, the pipelines that brought you the data, the way things were modeled, the quirks of the BI tool, the quirks of the business and the random assortment of software they use etc",
              "score": 2,
              "created_utc": "2026-02-07 14:45:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4i89o3",
              "author": "HOMO_FOMO_69",
              "text": "BI is more than just reporting.... Transforming data into the required format is still under the BI umbrella",
              "score": 1,
              "created_utc": "2026-02-09 21:42:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4i8qkl",
                  "author": "soggyarsonist",
                  "text": "I see comments from quite a few people who seem to work almost entirely from prepared datasets.",
                  "score": 1,
                  "created_utc": "2026-02-09 21:44:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3y29r3",
          "author": "Distinct-deel",
          "text": "BI Analyst (~2.5 YOE) at healthcare (a small organization\naround 700-employe) . What I do: building SQL-based ETL pipelines, managing the data warehouse, and developing stored procedures for staging, dimension, and fact table loads. I also build and automate Power BI semantic models and dashboards, and develop KPI frameworks and basic predictive models for pricing and productivity. \nBasically analytics + data engineering + ‚Äúwhatever breaks.‚Äù Still not sure what my actual title is.",
          "score": 11,
          "created_utc": "2026-02-06 18:32:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41q6k5",
              "author": "sweet_dandelions",
              "text": "Data Architect/All",
              "score": 3,
              "created_utc": "2026-02-07 07:58:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o40f6lv",
              "author": "peppaz",
              "text": "I'm doing all exactly that and I'm a chief lmao so yea, titles don't mean shit- I've been doing it for 20 years now",
              "score": 3,
              "created_utc": "2026-02-07 02:04:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o423y1r",
              "author": "hereforthistoo",
              "text": "I want to be/do this.. essentially a data/bi solution architect, mind if I dm you?",
              "score": 1,
              "created_utc": "2026-02-07 10:12:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o43kngg",
                  "author": "Distinct-deel",
                  "text": "Hey sure",
                  "score": 1,
                  "created_utc": "2026-02-07 16:06:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o408rcx",
          "author": "tvdang7",
          "text": "Data imposter here....",
          "score": 6,
          "created_utc": "2026-02-07 01:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zhuor",
          "author": "Pandapoopums",
          "text": "I prefer to call myself a Data Dumbass because I think any of the other titles inflate the head to be too large - let's not forget we're fallible people at the end of the day with strengths and weaknesses, despite our expertise and experience. Out of the two options, I think my strength is definitely more in the Analytics Engineer direction, though my official title is Senior Data Engineer.\n\nI would say I'm more in the Analytics Engineer direction because I work directly with the business defining models and answering their questions, something most people who involve themselves only in ingestion and processing I've found tend to shy away from. I've handled ingestion, I've also had past lives in reporting, ETL/ELT and web dev, so I'm confident in my skills on any side they want to put me on. I don't really concern myself with title all that much, what I do care about is that the problem in front of me and ownership of responsibilities gets handed out cleanly. If you want me to do all of it end to end, I can do it, if you want me to handle just one piece just tell me where to stop and interface with another group.",
          "score": 4,
          "created_utc": "2026-02-06 22:48:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ys6yy",
          "author": "MPL206",
          "text": "I feel like everything is getting bundled, as I fresh grad who‚Äôs role is a BI analyst slowly my role is transitioning to more analytics engineer.  Most my role now is power automate for automations or data capture in excels/sharepoint list in a SharePoint type non-relational setup. This obviously isn‚Äôt the same for every company, but as a analytics team with an IT team that just got cut by 95%, strict cyber and IT red tape. Just trying to do my best with little resources I have.",
          "score": 3,
          "created_utc": "2026-02-06 20:38:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zd9sd",
          "author": "dev81808",
          "text": "25% DE, 75% AE\n\nOfficially: DE\n\nThis past week: 10% DE, 40% AE, 50% PM fml",
          "score": 3,
          "created_utc": "2026-02-06 22:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zyem5",
          "author": "iwantthisnowdammit",
          "text": "Nah, I‚Äôm data governance engineer üòÇ",
          "score": 3,
          "created_utc": "2026-02-07 00:23:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o411bo8",
              "author": "mpaes98",
              "text": "Ah yes, a fellow paperwork scientist",
              "score": 2,
              "created_utc": "2026-02-07 04:28:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42tdqc",
          "author": "HC-Klown",
          "text": "I am a what people are calling right now a Full Stack Data Engineer. \n\nIs there where the market is going? \n\nI take care of platform design & implementation, ingestion, curation, modeling, orchestration and sometimes i even create simple exposures (simple dashboards, reports etc.). On top of that i create processes and frameworks that enable DQ Assurance for data stewards. \n\nMy official title is Senior Data Engineer. We have another Non Sr. Data Engineer in our team and he mostly does platform and ingestion. Now we are trying to push him to also do more modeling and curation so he geta to know the domains better. But i guess as a Data Engineer you are expected to kind of be able to do it all.",
          "score": 3,
          "created_utc": "2026-02-07 13:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xpeor",
          "author": "MonochromeDinosaur",
          "text": "I write A LOT of code, A LOT of SQL, and a lot of user facing application code (unfortunately) but my main responsibility is DE.\n\nI came from a hybrid of data science and web development into DE best of both worlds few of the downsides IMO.",
          "score": 5,
          "created_utc": "2026-02-06 17:31:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xxfrg",
              "author": "SOLUNAR",
              "text": "Do you build datasets or foundations for others to do their analysis? Or are the one using sql for the analysis ?",
              "score": 1,
              "created_utc": "2026-02-06 18:09:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xzds9",
                  "author": "MonochromeDinosaur",
                  "text": "All of the above. Depends on the product I‚Äôm working on. \n\nMy current company has a full suite of SaaS, Data APIs, and DWaaS products. \n\nI‚Äôve implemented frontend features for the SaaS, dashboards to embed in products, backend code for serving data via the APIs, and  data modeling for the DW services we provide. \n\nWe give our customers the options to use our interface for their analytics, APIs to self serve, or set them up with OLAP warehousing, we also offer export services to DB/data dump/FTP.\n\nIt‚Äôs a little of everything. I joined when the company was small <100 people we‚Äôre at around ~1500 now.",
                  "score": 1,
                  "created_utc": "2026-02-06 18:18:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3y448x",
          "author": "Outside-Storage-1523",
          "text": "Analytic, and I fucking hate it. I don‚Äôt consider myself as an engineer either. It‚Äôs just a glorified analyst position.",
          "score": 4,
          "created_utc": "2026-02-06 18:40:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47bg2k",
              "author": "HC-Klown",
              "text": "Why do you hate it? What stage of the data lifecycle would you rather be working in? Or any at all?",
              "score": 2,
              "created_utc": "2026-02-08 04:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48togc",
                  "author": "Outside-Storage-1523",
                  "text": "I guess I don't really like this business-facing position. I'd rather go upstream to do streaming/ingestion than data modelling, which bores the majority headache from the human side. Streaming is technically more challenging but a bit further from stakeholders.",
                  "score": 1,
                  "created_utc": "2026-02-08 12:52:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3yobbj",
          "author": "a-vibe-coder",
          "text": "Yes",
          "score": 3,
          "created_utc": "2026-02-06 20:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yqt0x",
          "author": "rampagenguyen",
          "text": "Yes",
          "score": 3,
          "created_utc": "2026-02-06 20:31:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ybnpz",
          "author": "brrrreow",
          "text": "Neither, technically. Closer to AE but I find keeping up in DE communities to be helpful for my role and interests. \n\nOur Engineering team has dedicated data (platform) engineers that get software and external source data into a central datalake. I‚Äôm on the analytics team, and own the warehouse, including ingesting from the datalake and transforming/orchestrating it for use by data scientists and business analysts. \n\nI also pick up lightweight DE tasks that are too small for eng teams to pick up, like scheduled file processing/drops to external vendors.",
          "score": 2,
          "created_utc": "2026-02-06 19:16:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x93ag",
          "author": "Sensitive-Sugar-3894",
          "text": "I'm one of the geek ones. üòÅ",
          "score": 3,
          "created_utc": "2026-02-06 16:14:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xtvwn",
          "author": "nightslikethese29",
          "text": "At my company we have them separated. I'm a data engineer so for us our responsibility is to get data into and out of the data warehouse as well as transfer data between our other systems. The modeling and most data validation goes to the analytics engineers that we work closely with.",
          "score": 3,
          "created_utc": "2026-02-06 17:52:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42v4sn",
              "author": "HC-Klown",
              "text": "How much work does just doing ingestion, RETL and platform dev generate for you? In our team we have a lot of business data validation and modeling work to do. We do not have the need to keep upgrading our Platform, so data engineers end up also doing more data modeling (as I think they should by default) and business understanding.\n\nIngestion for us is fairly simple, we have a declarative way to setup ingestion and ingesting new data takes 10 minutes. After it‚Äôs in the platform it‚Äôs all about modeling and understanding the business process. \n\nWe don‚Äôt mindlessly update the platform capabilities if there is no need for it.\n\nAnd mind you we are a telecom company with over 75 different systems to ingest data from and we built our own on-prem data platform.",
              "score": 1,
              "created_utc": "2026-02-07 13:50:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4450qd",
                  "author": "nightslikethese29",
                  "text": "A lot of work. We're in a high growth phase and essentially a startup. Leadership is constantly changing systems. The infrastructure maturity isn't there and I'm helping to build it. \n\nWe also handle some non data engineering tasks that I think backend software engineers would normally do. That involves a lot of data and business validation, but I didn't include it because it's not typical DE work.",
                  "score": 1,
                  "created_utc": "2026-02-07 17:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3y6fbn",
              "author": "apache_tomcat40",
              "text": "lol, what kind of data engineering do you do if you don‚Äôt do data modeling and data validation?",
              "score": -4,
              "created_utc": "2026-02-06 18:51:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3y8m8p",
                  "author": "nightslikethese29",
                  "text": "Extracting data from source systems and loading to raw layer. Extracting data from warehouse to send externally. So essentially the EL part of ELT. \n\nThe data validation we do is much more about data types, missing data, etc. Business data validation happens downstream of us.",
                  "score": 7,
                  "created_utc": "2026-02-06 19:02:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3y9fxz",
                  "author": "paxmlank",
                  "text": "platform/infra/devops",
                  "score": 4,
                  "created_utc": "2026-02-06 19:06:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3yidbx",
          "author": "m915",
          "text": "Analytics engineer was created by dbt, and most of them use it",
          "score": 1,
          "created_utc": "2026-02-06 19:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ymtl7",
          "author": "Thatgreenvw",
          "text": "The UK Government Digital and Data Profession Capability Framework has distinct definitions for analytics engineers alongside a myriad of other data roles. This is used as the basis for job profiles across the uk civil service\n\nhttps://ddat-capability-framework.service.gov.uk/#data-roles",
          "score": 1,
          "created_utc": "2026-02-06 20:11:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yxkx2",
          "author": "stayfroggy-6",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-06 21:05:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z6e2p",
          "author": "Lucade2210",
          "text": "Role names are just HR bs. \n\nIf your team adheres to specific tasks for these specific roles, you're completely missing the point and failing at your job.",
          "score": 1,
          "created_utc": "2026-02-06 21:49:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40ehq6",
          "author": "peppaz",
          "text": "Yes but not a good one. I would for a big non profit federal health system and self host everything. So I hacked together an enterprise system lol but we don't get to use too much cool stuff",
          "score": 1,
          "created_utc": "2026-02-07 02:00:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40glbd",
          "author": "daszelos008",
          "text": "I started with DE title but I built API in java, wrote scala spark jobs, doing shit with open source technology. I interviewed another company for a DE role and they said I should be in DataOps position...\n\nNow I'm calling myself a Software Engineer specialized in data tech",
          "score": 1,
          "created_utc": "2026-02-07 02:12:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40mnhw",
          "author": "RadioactiveTwix",
          "text": "I'm the guy you call when you need to migrate the on prem Hadoop pipeline to the cloud.... Title irrelevant.",
          "score": 1,
          "created_utc": "2026-02-07 02:50:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o417aj1",
          "author": "Ace__Trainer",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-07 05:12:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o417d9r",
          "author": "Lurch1400",
          "text": "Current title: Data Integration Engineer\n\nActual title based on what I do: Business Intelligence Developer\n\n\nLearned by being a fly on the wall that the title doesn‚Äôt really matter, it‚Äôs what you‚Äôre actually doing that does",
          "score": 1,
          "created_utc": "2026-02-07 05:13:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41jx9o",
          "author": "killer_sheltie",
          "text": "I just move data around. I think people are often surprised at how little I look at the data beyond confirming it‚Äôs where it needs to be.",
          "score": 1,
          "created_utc": "2026-02-07 06:59:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41kwt0",
          "author": "nerevisigoth",
          "text": "No idea. I just do what seems useful and they keep giving me lots of money for it.",
          "score": 1,
          "created_utc": "2026-02-07 07:08:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41pzxf",
          "author": "sweet_dandelions",
          "text": "Senior DevOps and Data Engineer. So yeah, basically you are expected to know IaC, CICD, Kubernetes and whatnot besides being the true Data Engineer with building data pipelines, analyzing the business side and also developing reports in BI tools. \n\nIt's fucking crazy, but hey, how else would companies get more money for themselves if they hire 5 people for all of the above? Just sell the dream that you can and should become the one man show to rule it all üôÇ And no, I'm not the senior here, just venting",
          "score": 1,
          "created_utc": "2026-02-07 07:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41rqnh",
          "author": "davf35",
          "text": "I am glad I am not alone. I often feel like an overpaid analyst. \n\nNo warehouse. No constant new pipelines.\n\nJust solving whatever data needs a specific application has.\n\nIdk how I will ever be able to find a real DE job with only experience like this, yet DE is in my title and DE was what I was trained on.",
          "score": 1,
          "created_utc": "2026-02-07 08:12:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41wlt8",
          "author": "freedumz",
          "text": "Non tech people callee me data wizard",
          "score": 1,
          "created_utc": "2026-02-07 08:59:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42ujhj",
          "author": "hardrock2474",
          "text": "i think i am more of an analytics engg rather than data engg.\n\n\ni do mostly etl work, but i really don't delve into systems architecture anymore, compared to when i was a software engineer in my previous job. then i do dashboarding in power bi as well.",
          "score": 1,
          "created_utc": "2026-02-07 13:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44o904",
          "author": "dev_lvl80",
          "text": "Both. If there are third differential in title, still same answer.\nMean, does not matter how many titles are in data.¬†\nIf you work long enough in this field, you should know end to end stack and be able to adapt quickly.",
          "score": 1,
          "created_utc": "2026-02-07 19:22:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o469c0m",
          "author": "Amar_K1",
          "text": "Call it data analyst end of story\n\nBusiness intelligence, data science, data engineer, analytics engineer its all the same thing. Use excel, sql and python.",
          "score": 1,
          "created_utc": "2026-02-08 00:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47gzo3",
          "author": "ninja_age",
          "text": "part time plumber over here, just left my tool bag in the car",
          "score": 1,
          "created_utc": "2026-02-08 05:34:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4857gw",
          "author": "grungedimi",
          "text": "So what would be the most correct title for someone who doesn't develop the ETL pipelines and such, but makes data models (conceptual, logical, physical) based on what business needs, to then check the as is physical data structures to see what is missing and needs to be built, and communicates all of that to the developers?\n\nSome places call them data analyst, but in other places that title is for the power users who come to business insights based on what their BI tool shows. Some would call them data architects.\n\nI agree with most people here who say there really isn't any consistency in terminology across organisations. But i'm still curious what you would call the role described above.",
          "score": 1,
          "created_utc": "2026-02-08 09:14:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4blzpj",
              "author": "Free-Bear-454",
              "text": "Great question. Indeed the role definition depend a lot on the company, the teams and the timing¬†",
              "score": 1,
              "created_utc": "2026-02-08 21:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49uwk4",
          "author": "stavroblofeldd",
          "text": "I can understand why Analytics Engineering term popped up. Since demands are getting higher and higher every day on shifting business dynamics and people expect you to know everything, you cannot exist as pure data analyst/engineer or BI developer. \n\nI am currently working on an engineering company‚Äôs R&D department as data analyst but actively doing data engineering, BI development, data analytics and also minor business analyst tasks. Due to recent layoffs, I am forced to do all those tasks as a single person! \n\nIn conclusion, analytics engineering is polite way to say ‚Äúdo all related data tasks‚Äù",
          "score": 1,
          "created_utc": "2026-02-08 16:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ec9sx",
          "author": "mattiasthalen",
          "text": "I‚Äôm an Analytics Data Engineer üòÖ j/k\nI‚Äôm an Analytics Consultant and I do both DE & AE.\nClients doesn‚Äôt want DEs or AEs, they want full-stack.",
          "score": 1,
          "created_utc": "2026-02-09 07:35:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fig05",
          "author": "gabyzochloride888",
          "text": "There is only one Engineering",
          "score": 1,
          "created_utc": "2026-02-09 13:37:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y8zes",
          "author": "Treemosher",
          "text": "I have no idea.  I am the first DE person at my employer, they're working on my new title right now, but their titles are all over the place anyway.  Network engineers are called system administrators here, for example.\n\nI am building a CDW basically from scratch along with learning all the major platforms our data is sourced from.\n\nSince it is all supporting analytics, I would assume \"analytics engineer\" is that?  \n\nI'm just having a blast though.  I don't care about the title or even the money as long as I can pay my mortgage and work on cool projects",
          "score": 1,
          "created_utc": "2026-02-06 19:03:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ythka",
              "author": "Unlikely-Loss5616",
              "text": "What is your education and credentials?",
              "score": 1,
              "created_utc": "2026-02-06 20:45:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3zj1zc",
                  "author": "Treemosher",
                  "text": "I'll try to keep it brief - I started as a paper pusher who got really mad at a terrible data migration with our billing system.  Very long story that still irks me to this day.  Left that company after the dust settled and got started in IT at another company.\n\nDid very well in IT for a few years, then was an awful data analyst for a couple years.  But while being terrible at analytics, I did convince IT to spin me up a couple VM servers and I built my own end-to-end orchestration in Python because I hated spending 2 days a week updating dashboards.\n\nThe system I built ended up running all the analyst's updates so they could focus on customers more.\n\n(To anyone thinking of all the things wrong with that, yes I know.  We all knew, which is why it was temporary.  Sometimes you have to pick up a machete and force a path forward.  It worked and I'm retiring those VM shitballs as soon as I can.  I wrote the systems myself and will be the first to say let's burn it all in fire.)\n\nTwo years later we got a director who agreed with me that we need a proper data warehouse.  Surprise surprise, it's amazing and everyone else now realizes it's not as scary as they thought.\n\nEducation - I've got a BS in IT and always strive to follow best practices with coding, governance etc.  I'm not just saying that.  Following best practices goes a very long way.",
                  "score": 2,
                  "created_utc": "2026-02-06 22:55:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3y4mhv",
          "author": "Typhon_Vex",
          "text": "Analytics engineer is a joke position and outcome of the ideology that the bussiness should handle as much of the data wranglig as possible themsleves.\n\nSee it goes like this. Supposedly the IT profesionsals handling data in the past were too expensive, slow and asking many annoying questions.\n\nThe bussines needed shipping their crappy dahsboards and reports in high frequency. So they gained more and more permissions to achieve just that and do their own crappy tranformations regardless of any modelling aor achitecture.\n\nSurprisingly eventually they are swamped in spaghetti code and tech debt. Eventually the called data analysts has to maintain that crucial report by himself 24/7 and becomes a single dashboard person.\n\nAlso the bussines needs more talking and show off people. And they can¬¥t waste their time with SQL.\n\nAnd so the analytics engineer is born. It¬¥s a developer outside of IT, to do the slave work, but not cool enough to run around with piecharts.\n\nHe does it for the bussines salary , and not the IT professional salary - thats your main identifier, how you will know if you are an IT professional, or a data analytics bozo.\n\n  \nAs for me, since the company started to move to the cloud, I¬¥m fully on data engineering - meaning moving data reliably between systems, in this case from legacy to the cloud. I¬¥m damn gonna make sure to go nowhere near a metric or piechart. Anyway we used to do that too, but freedom was given to the data analysts, to do that.\n\n",
          "score": 0,
          "created_utc": "2026-02-06 18:43:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o402jsl",
              "author": "glymeme",
              "text": "Wow. Moving data from A to B is so much better than building data products. üôÑ",
              "score": 2,
              "created_utc": "2026-02-07 00:47:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o40avzy",
              "author": "murphire",
              "text": "I‚Äôm sure it varies from company to company, but this description is not reflective of my position as an analytics engineer. Well, except the parts where they find me expensive and slow, and not cool enough to run around with pie charts very often.",
              "score": 1,
              "created_utc": "2026-02-07 01:37:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x9omp",
          "author": "SirGreybush",
          "text": "Oxymoron - analytics engineer\n\nAn engineer supposes advanced math, chemistry & physics with a Uni degree in any engineering field. They have advanced problem solving skills. Thus engineers can also be decent with actual coding and applying best practices.\n\nA data analyst usually know basic + statistics math, maybe basic calculus, and would have an MBA. Some excellent schools have within their MBAs dimensional modeling + advanced SQL courses. Or a good student will do a minor in SWE.\n\nAlso - hotels in the US call janitors \"maintenance engineers\" - I mean WTF???",
          "score": -15,
          "created_utc": "2026-02-06 16:17:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xq1rd",
              "author": "MiserableLadder5336",
              "text": "\nen¬∑gi¬∑neer\n/Àåenj…ôÀànir/\nnoun\n1. A person who designs, builds, or maintains machines, structures, or systems.\n\n\nGet over yourself.",
              "score": 4,
              "created_utc": "2026-02-06 17:34:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3xjqtt",
              "author": "EricMichaelHarris99",
              "text": "Chemistry?",
              "score": 2,
              "created_utc": "2026-02-06 17:03:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xmz2b",
                  "author": "SirGreybush",
                  "text": "Chemistry - it's a required STEM subject to obtain your engineering Bachelor's degree.\n\nIt's a jab at all the non-engineers that give themselves the title just because they occupy a job role.",
                  "score": 2,
                  "created_utc": "2026-02-06 17:19:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3xiq3s",
              "author": "SirGreybush",
              "text": "LMAO the downvotes, seems I'm rubbing some analysts the wrong way",
              "score": 0,
              "created_utc": "2026-02-06 16:59:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xtmlt",
                  "author": "glymeme",
                  "text": "No, you just come off as combative. Analytics engineering is literally applying software engineering best practices to analytics work. I‚Äôve seen just as many CS majors do worse system designs than non-CS majors. Problem solving skills aren‚Äôt limited to people with STEM degrees.",
                  "score": 3,
                  "created_utc": "2026-02-06 17:51:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qwvy5y",
      "title": "Data Modeling expectations at Senior level",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/",
      "author": "Outside_Reason6707",
      "created_utc": "2026-02-05 20:04:50",
      "score": 66,
      "num_comments": 29,
      "upvote_ratio": 0.98,
      "text": "I‚Äôm currently studying data modeling. Can someone suggest good resources?\n\nI‚Äôve read Kimballs book but really from experience questions were quite difficult.\n\nIs there any video where person is explaining a Data Modeling round and is covering most of the things that Sr engineer should talk. \n\nEnglish is not my first language so communication has been barrier, watching videos will help me understand what and how to talk.\n\nWhat has helped you all?\n\nThank you in advance!",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3ryvy2",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-05 20:04:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s0lgf",
          "author": "Ok_Tough3104",
          "text": "Joe Reis is dropping a book on data modelling in 1 month, if you're patient enough...\n\nAlso he has a whole substack about that book if you can read from a PC screen without having your eyes bleeding\n\nhttps://practicaldatamodeling.substack.com/",
          "score": 49,
          "created_utc": "2026-02-05 20:12:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xixpa",
              "author": "mightregret",
              "text": "RemindMe! 1 month",
              "score": 6,
              "created_utc": "2026-02-06 17:00:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ti6tn",
              "author": "studentofarkad",
              "text": "Thank you, thats the book I'm waiting for to drop!",
              "score": 1,
              "created_utc": "2026-02-06 00:49:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3v5b83",
              "author": "AccomplishedTax2306",
              "text": "Is it possible to pre-order?",
              "score": 1,
              "created_utc": "2026-02-06 07:34:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vbidi",
                  "author": "Ok_Tough3104",
                  "text": "The whole book is on the substack. (If you can read from a screen)\n\nIts a pay sub. I havent heard Joe mentioning anything about pre ordering, im also in europe, so compared to the US market the book will be delayed by a couple of weeks\n\nApologies for not being able to provide better insights üòÖ",
                  "score": 1,
                  "created_utc": "2026-02-06 08:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3xing2",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-06 16:58:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xitrv",
                  "author": "RemindMeBot",
                  "text": "I will be messaging you in 1 month on [**2026-03-06 16:58:46 UTC**](http://www.wolframalpha.com/input/?i=2026-03-06%2016:58:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1qwvy5y/data_modeling_expectations_at_senior_level/o3xing2/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1qwvy5y%2Fdata_modeling_expectations_at_senior_level%2Fo3xing2%2F%5D%0A%0ARemindMe%21%202026-03-06%2016%3A58%3A46%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qwvy5y)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                  "score": 1,
                  "created_utc": "2026-02-06 16:59:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ekjpk",
              "author": "HODLING_APE",
              "text": "RemindMe! 1 month",
              "score": 1,
              "created_utc": "2026-02-09 08:56:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sn0h5",
          "author": "Gullible_Buy427",
          "text": "Another great read is data modeling made simple by Steve Hoberman.",
          "score": 7,
          "created_utc": "2026-02-05 22:00:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uvyiq",
              "author": "dehaema",
              "text": "Anything by steve hoberman really. His \"data modeling masterclass\" is the best course i ever took",
              "score": 2,
              "created_utc": "2026-02-06 06:13:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uuivo",
          "author": "tophmcmasterson",
          "text": "It depends on the role. I know tons of data engineers, maybe even most of them are pretty terrible at data modeling. \n\nThere‚Äôs a large group of engineers that have gotten by just basically moving data into the warehouse and then brute forcing OBT/flat tables ad-hoc and never really learned best practices in dimensional modeling. \n\nMy recommendation is actually play around with a front end tool like Power BI and understand how data is used and what is recommended for best practices for how data should be structured. If you understand that and refer to the Kimball modeling techniques and can actually internalize it that will get you most of the way there. \n\nIt‚Äôs not really something that is easy to explain in a video I don‚Äôt think. You need to be able to really mentally visualize how data ties together and what shape will make it easiest and most flexible to work with.",
          "score": 10,
          "created_utc": "2026-02-06 06:01:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x07z3",
              "author": "Outside_Reason6707",
              "text": "Okay understood. I'm struggling with performance in data modeling interviews, and I'm unsure what's expected of me. In the past, I've asked clarifying questions, proposed entities, and developed dimensional models with fact tables and dimension tables. I've also written SQL code for my proposed solutions and modified my schema based on follow-up questions. However, I haven't received positive feedback, and I'm starting to wonder if I'm missing something fundamental or if it's just a communication issue. I'd love to find a recommended video that demonstrates how to excel in a data modeling interview. Something like demo interviews",
              "score": 2,
              "created_utc": "2026-02-06 15:32:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3x2rlo",
                  "author": "tophmcmasterson",
                  "text": "I‚Äôd again just recommend reviewing some of the well established documentation on Kimball techniques or even going through the Microsoft guidance documentation on star schema (it‚Äôs aimed at designing for Power BI but broadly applicable I think).\n\nIf you internalize the concepts and thought process through working on actual projects you‚Äôll be able to speak to it more naturally.",
                  "score": 3,
                  "created_utc": "2026-02-06 15:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3v0cb8",
              "author": "Hear7y",
              "text": "We just got forced by business to make this absolutely awful flat table (think here both business keys and foreign keys BOTH present) in an increasingly wise table, because they didn't want to have to build any sort of relation when doing stuff in Excel.\n\nFeels like a massive App that was made to solve multiple issues and serve a variety of internal customers is exclusively used to serve a crappy table for Excel. :D",
              "score": 1,
              "created_utc": "2026-02-06 06:50:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vd3dp",
                  "author": "BrownBearPDX",
                  "text": "That‚Äôs when you keep your data models as you should for all the goody goods that will stick to them forever and ever and ever because of that good thinking. \n\nWhat you do then is you build them a freaking view as wide as their stupid little brains can handle. Don‚Äôt change the actual schemas that the business actually relies on and more intelligent people will rely on in the future. Don‚Äôt destructure good thinking into bad and actually implement it. Lie to them if you have to.  Retain your ability to sleep at night.",
                  "score": 7,
                  "created_utc": "2026-02-06 08:47:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3vp67i",
              "author": "Ploasd",
              "text": "Kimball is one of many methods of modelling and is only really good if your building OLAP style infrastructure but people really should understand alternative methodology - 3NF and all that.",
              "score": 0,
              "created_utc": "2026-02-06 10:41:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x2oy1",
          "author": "miker5555",
          "text": "At senior level, interviews usually aren‚Äôt about memorizing modeling patterns as much as **talking through real tradeoffs**.\n\nWhat helped me most was experience explaining *why* I modeled something a certain way, not just what pattern I used. In interviews they often care more about:\n\n* how you handle messy data\n* how models evolve over time\n* what breaks when requirements change\n* and how you explain things to non-engineers",
          "score": 5,
          "created_utc": "2026-02-06 15:44:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xhx91",
              "author": "Outside_Reason6707",
              "text": "Thank you for explaining! I think I miss the point of explaining why I model something a certain way. I focused on patterns and writing sql. Would you be open for a continued discussion, can I dm you?",
              "score": 2,
              "created_utc": "2026-02-06 16:55:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3vpbs8",
          "author": "Ploasd",
          "text": "I do think Database Design for Mere Mortals by Michael Hernandez is a good easy to read reference around database design that can also help with understanding how to model data.",
          "score": 2,
          "created_utc": "2026-02-06 10:43:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hig0x",
          "author": "BitterAcanthisitta67",
          "text": "two words: DATA VAULT",
          "score": 1,
          "created_utc": "2026-02-09 19:34:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vwkyd",
          "author": "IrquiM",
          "text": "You only get to senior level in data modeling after having spent 10 years at a lower level. No books kan teach it to you, and anyone who says otherwise, are not at a senior level.",
          "score": 0,
          "created_utc": "2026-02-06 11:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x0l1p",
              "author": "Outside_Reason6707",
              "text": "I‚Äôve 7-8 years of experience. And what you said is very much valid. I'm struggling with performance in data modeling interviews, and I'm unsure what's expected of me. I haven't received positive feedback, and I'm starting to wonder if I'm missing something fundamental or if it's just a communication issue.",
              "score": 3,
              "created_utc": "2026-02-06 15:33:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3xvn5e",
                  "author": "IrquiM",
                  "text": "Modeling is just a part of it. To get a senior position, you need to show that you do not require supervision, you can take decision yourself, you can plan ahead and decide what to prioritize, etc.",
                  "score": 2,
                  "created_utc": "2026-02-06 18:00:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxhzhs",
      "title": "In what world is Fivetran+dbt the \"Open\" data infrastructure?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qxhzhs/in_what_world_is_fivetrandbt_the_open_data/",
      "author": "finally_i_found_one",
      "created_utc": "2026-02-06 13:43:47",
      "score": 64,
      "num_comments": 31,
      "upvote_ratio": 0.98,
      "text": "I like dbt. But I recently saw these weird posts from them:\n\n* [https://www.getdbt.com/blog/what-is-open-data-infrastructure](https://www.getdbt.com/blog/what-is-open-data-infrastructure)\n* [https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future](https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future)\n\nWhat is really \"Open\" about this architecture that dbt is trying to paint?\n\nThey are basically saying they would create something similar to databricks/snowflake, stamp the word \"Open\" on it, and we are expected to clap?\n\nIn one of the posts, they say \"I hate neologisms for the sake of neologisms. No one needs a tech company to introduce new terms of art purely for marketing.\" - its feels they are guilty of the same thing with this new term \"Open Data Infrastructure\". One more narrative that they are trying to sell.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qxhzhs/in_what_world_is_fivetrandbt_the_open_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3wlke3",
          "author": "codykonior",
          "text": "Open (your wallet for) data infrastructure.\n\nCompanies who use FiveTran must be the billion dollar types with money burning holes in their pockets.\n\nI had a look at migrating a small ELT process to it last year, which I can run almost free inside Azure SQL DB with scripts and elastic job agent, for a few minutes each night.\n\nFiveTran was going to cost $50kpa, before the recent price increases üòí And you'd be locked in to more. And you'd still have to spend tons of time scripting up stuff.",
          "score": 71,
          "created_utc": "2026-02-06 14:18:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wzt0i",
              "author": "CulturalKing5623",
              "text": "A recent client had maybe 10 sources, none of them larger than 10K records per day. I told them all they needed was to throw some python scripts in an EC2 to handle it, had it built and ready to go. Total cost was probably somewhere around $50/month and it just chugged along, rarely had any issues ever. \n\nFast forward to them hiring a chief \"go to market strategist\" or something like that, the person responsible for getting them acquired, and they decide they need a \"mature data stack\" to be more attractive to outside investors. So we hooked everything up to Fivetran and data bricks and built a medallion architecture and the whole shebang. All great stuff.\n\nThe last time I checked their Fivetran is running at $15k/year and is _constantly_ throwing errors for this reason or that.",
              "score": 16,
              "created_utc": "2026-02-06 15:30:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x0j49",
                  "author": "contrivedgiraffe",
                  "text": "That‚Äôs a great example of the difference between trying to run a business and trying to get acquired.",
                  "score": 19,
                  "created_utc": "2026-02-06 15:33:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3yh2p2",
              "author": "baronfebdasch",
              "text": "To be fair, the value proposition of FiveTran is always competing against a ‚Äúroll your own‚Äù extracting method. It‚Äôs not rocket science. \n\nIf your data environment is relatively fixed I would agree there is almost no point. \n\nBut if you‚Äôre in the business of having to extract data from dozens of systems, then it‚Äôs a matter of ‚Äúdo I pay my engineers to keep the lights on at making sure our data extraction jobs are always running, up to date, and can manage various versions of source systems, or do I simply outsource that part of the value chain and focus on actually making the data usable? \n\nIf you are a company that needs to focus on integrating data from say dozens of ERPs‚Ä¶ maybe it‚Äôs worth it to let FiveTran expedite when a new ERP hits the market (or one you haven‚Äôt seen before). \n\nOr you‚Äôre setting up a brand new data infrastructure and your sponsors are breathing down your neck to integrate your new HR system. You can spend days/weeks working through building jobs to extract said data, or have it with FiveTran in minutes. \n\nBecause they typically price on monthly deltas volumes there‚Äôs kind of a middle tier where it makes sense as part of your tech stack. Too low and it‚Äôs too expensive, and if your data volumes are massive, again, too expensive. But if you‚Äôre in that sweet spot, it may be worth paying a vendor than paying an engineer to perform those tasks.",
              "score": 9,
              "created_utc": "2026-02-06 19:43:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o42iuqw",
                  "author": "dillanthumous",
                  "text": "100% we use Fivetran tactically to keep up with fast changing APIs (Amazon etc.) and in house we handle all the stable data sources the old fashioned way.",
                  "score": 2,
                  "created_utc": "2026-02-07 12:28:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wp6l2",
              "author": "finally_i_found_one",
              "text": "No doubt they are going to raise prices. They now own the first and the middle layer of the data architecture. Also, they are now a monopoly in the data transformation space.",
              "score": 3,
              "created_utc": "2026-02-06 14:36:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4d4zrk",
              "author": "pro-taco",
              "text": "They openly scoff at people who use open stacks. If you're not snowflake or databricks, you're not important to them. \n\nVery unimpressed by their vision: it's Fusion.\n\nSqlmesh is probably dead but unclear",
              "score": 2,
              "created_utc": "2026-02-09 02:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3woj7w",
          "author": "Known-Huckleberry-55",
          "text": "The world they are pitching is one where data is stored in Iceberg tables in storage owned by companies (S3, ADLS2) and that the compute layer becomes a commodity that can become easily swapped out. One of the big features of Fusion is that it can cross-compile across different SQL dialects. Instead of getting locked into Snowflake, you can easily switch to duckdb, Databricks, whatever for different use cases.\n\nAll that said, my Fivetran and dbt Cloud bill is much higher than my Snowflake bill so I'm not worried about the compute layer like they seem to think companies are.",
          "score": 22,
          "created_utc": "2026-02-06 14:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wkcg5",
          "author": "drew-saddledata",
          "text": "dbt core is pretty good.  It's funny, I have build the same thing they envision in that blog post, ETL pipeline tool and dbt working together as a SaaS.",
          "score": 16,
          "created_utc": "2026-02-06 14:11:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4d56ue",
              "author": "pro-taco",
              "text": "Love dbt core or sqlmesh but seems like it'll die a slow death. Hoping not",
              "score": 1,
              "created_utc": "2026-02-09 02:32:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wka75",
          "author": "Illustrious_Web_2774",
          "text": "No surprise. They fucked up the word \"model\" pretty badly.",
          "score": 10,
          "created_utc": "2026-02-06 14:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wxg1y",
          "author": "Nekobul",
          "text": "The \"modern\" keyword is now toxic. The new psyop is called \"open\". ",
          "score": 6,
          "created_utc": "2026-02-06 15:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wj1ut",
          "author": "omonrise",
          "text": "well there's OpenAI ü§£",
          "score": 5,
          "created_utc": "2026-02-06 14:04:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wq3zx",
              "author": "Any_Tap_6666",
              "text": "Like the 'Democractic Republic of Congo'",
              "score": 9,
              "created_utc": "2026-02-06 14:41:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3x3swm",
                  "author": "blueadept_11",
                  "text": "And Democratic People's Republic of Korea",
                  "score": 7,
                  "created_utc": "2026-02-06 15:49:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3wosm6",
              "author": "finally_i_found_one",
              "text": "haha",
              "score": 2,
              "created_utc": "2026-02-06 14:34:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zggge",
          "author": "muneriver",
          "text": "My POV is someone who is closely following the work happening in iceberg, arrow, ADBC, data fusion, etc. These are technologies that are making data tools more interoperable and standardized which is what open here refers to.\n\n‚Äî-\n\nSo back to my point: The majority of the disagreement here comes from how people are defining ‚Äúopen.‚Äù This doesn‚Äôt mean open source. If you pay attention to the current developments, it‚Äôs about open standards and moving away from ‚Äúproprietary interfaces‚Äù to tools and formats that can talk to one another and in general, enable much more efficient data transfer. These two alone unlock many downstream applications!\n\nAs a small example: warehouses bundled storage, compute, and proprietary file formats together. That‚Äôs where the lock-in came from. If your data lived inside a proprietary format  (like in Snowflake), you were effectively tied to that engine.\n\nThe thing that‚Äôs really exciting and evolving is the maturation of standardized components of technological primitives that many modern tools use today. Open table formats like iveberg and delta, arrow (as a shared in-memory format), ABDC for super fast data transfer ,and newer engines like duckdb and data fusion all are working towards the same future. They‚Äôre all open source, want to converge to open standards, and if used together, enable an ‚Äúopen data infrastructure‚Äù. Which means the engine you use for AI/ML, real-time applications, and BI can all be based on data that lives in one storage layer and yet, can be run in any compute engine. Developers can live in a world where you can work towards running local dev in DuckDB and prod workloads in Snowflake. Minimizing vendor lock-in to me is just the a small side-benefit.\n\nVendors are still vendors. Nothing about this means tools like Fivetran+dbt are suddenly open source. The idea is that they operate on top of this new infrastructure that is less restrictive than the old warehouse model for the technological benefits, but also allows them to compete with Snowflake/Databricks/etc at a completely different angle. If engines are swappable, these big platforms lose a lot of their architectural leverage. Now the power and thing to control is the stuff outside of that (I will let you think through that part as an exercise haha).  \n\nAll of this to say, I try not to take anything with face value. There‚Äôs always nuance. Yes ‚Äúopen data infra‚Äù is a buzz word and is marketing for sure, but if you follow the current state of technology, there‚Äôs real nuance here!",
          "score": 8,
          "created_utc": "2026-02-06 22:41:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ce6ks",
              "author": "georgewfraser",
              "text": "This üëÜ\n\nThe data stack of the future is based open standards: Iceberg, dbt, sql. ",
              "score": 3,
              "created_utc": "2026-02-09 00:04:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wip08",
          "author": "West_Good_5961",
          "text": "dbt core is pretty open",
          "score": 8,
          "created_utc": "2026-02-06 14:02:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wo81g",
              "author": "finally_i_found_one",
              "text": "Doesn't really answer what I am asking. I hope you don't believe that Fivetran (who just ate dbt and SQLMesh) is going to create something \"Open\".",
              "score": 9,
              "created_utc": "2026-02-06 14:31:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3yvzhf",
          "author": "thisFishSmellsAboutD",
          "text": "Remember a year ago when SQLMesh didn't the same, but for free and much faster?\n\nThey were super responsive and moved fast towards a pretty decent maturity level.\n\nThen, acquisition.\n\nWho else is dreading the inevitable license rug pull from Fivetran?",
          "score": 6,
          "created_utc": "2026-02-06 20:57:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xtwwk",
          "author": "Possible_Ground_9686",
          "text": "Apache NiFi still going strong üí™üí™üí™",
          "score": 5,
          "created_utc": "2026-02-06 17:52:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40pgqo",
              "author": "Nekobul",
              "text": "Keep dreaming.",
              "score": 1,
              "created_utc": "2026-02-07 03:08:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y25qn",
          "author": "GreyHairedDWGuy",
          "text": "I tend to filter out all the nonsense terms vendors use to promote their offerings.  At the end of the day, using Fivetran (for example) is an economic decision....is it lower cost/reliable/faster to use FT versus paying a developer to build it and maintain it.  For some things yes, other no.  We use Fivetran and it works well for us but it's not economic to use is all situations and so we have rolled our own replication processes as needed.",
          "score": 1,
          "created_utc": "2026-02-06 18:31:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y62r2",
          "author": "Typhon_Vex",
          "text": "open source mostly often only means a demo or shareware that will eventually be sold and monetized.\n\nthe word open source is way overused.\n\nit shouldn¬¥t be used for pieces of software maintained by typically a lone company, typically of the same name, and which only work well when you buy the fully supported version",
          "score": 1,
          "created_utc": "2026-02-06 18:50:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41q66a",
              "author": "Thinker_Assignment",
              "text": "Have you heard of Linux, python, Kafka? Postgres? You're mistaking open source for open washing.\n\nIt's overused because sales people are using it.\n\nThere's open source and open core that aim to produce open standards\n\nThen there's open saas which is partly working software designed to upsell you to saas.\n\nThen there's open washing which is not open at all.",
              "score": 1,
              "created_utc": "2026-02-07 07:57:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o449c19",
          "author": "GoodLyfe42",
          "text": "There is always a new tool that a leader wants to use that keeps the data engineers employed. Then you have the data engineering team led by an actual data engineer who builds it in python for a fraction of the cost, fetches 5x faster, is truly portable and has far fewer incidents.\n\nIt‚Äôs hard to go to the fancy tool when you know that tool will eventually die or increase 5x in price forcing you to have a huge project to migrate off to another tool. Then you look over at all your python ingestion flows (you never moved over) and see them reliably chugging along.",
          "score": 1,
          "created_utc": "2026-02-07 18:08:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a7wom",
          "author": "Hot_Map_7868",
          "text": "While things like Iceberg and duck lake make the compute/storage more interoperable. I think that there are other things that need to be considered. Case in point, security. It's one thing to be able to run compute in Snowflake or DBX. It is another to have the same RBAC model on both platforms. \n\nSometimes I see technical teams advocate for openness, lower costs, etc without considering the additional cost of integration, maintenance, and administration. \n\n",
          "score": 1,
          "created_utc": "2026-02-08 17:26:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41nrhp",
          "author": "Thinker_Assignment",
          "text": "It's called Gaslighting, same energy as Truth social. Open bigly.",
          "score": 1,
          "created_utc": "2026-02-07 07:35:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzswfm",
      "title": "are we a dime a dozen?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qzswfm/are_we_a_dime_a_dozen/",
      "author": "turboDividend",
      "created_utc": "2026-02-09 03:08:12",
      "score": 57,
      "num_comments": 36,
      "upvote_ratio": 0.94,
      "text": "hearing alot of complaining on the cscareers subreddit and one comment that stuck out was that the OP was a front end guy and one of the responders said being a react/node.js guy isnt special. sometimes i feel the same way about being an  etl guy who does alot of sql.....",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qzswfm/are_we_a_dime_a_dozen/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4exg5o",
          "author": "Tender_Figs",
          "text": "I left corporate finance for analytics and then data engineering across a 15-year time frame. I feel more of a commodity now than I did when I was a staff accountant unless I really focus on using my domain experience. It is also why I am trying to formally get out of data engineering. \n\nI'm in a group that is constantly obsessed about tooling while paying no attention to technical debt or scale, nor the purpose of what we do in the first place. It feels very far removed from any \"so what?\" in my opinion, and yes, I do understand what the \"so what?\" is.",
          "score": 70,
          "created_utc": "2026-02-09 11:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fabxw",
              "author": "A_Poor_Economist",
              "text": "I read an article once that said there are 2 types of IT. IT that's just tech nerds and IT that is tied to Finance.\n\nTech nerds tend to get obsessed with shiny new objects. Finance tied ones tended to weigh tradeoffs and more \"so what?\"\n\nA gross overgeneralization but there seems to be tech people obsessed with just the tech and people who can do more strategic thinking about what to use when and why. \n\nOf course if you're on an island that sucks. Been there.\n\nWhat are you trying to transition to?",
              "score": 26,
              "created_utc": "2026-02-09 12:45:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4fni7x",
                  "author": "Gedrecsechet",
                  "text": "The 2 types are in the name. Information and Technology. In my 25years plus working from the trenches up have noticed some people care about the tech and don't care about info it holds and others are visa versa.  Both are necessary but one exists for the purposes of the other. Like plumbing, the pipes exist to carry water and have no purpose without it.",
                  "score": 13,
                  "created_utc": "2026-02-09 14:06:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4gvdug",
                  "author": "scarredMontana",
                  "text": "I used to work as software eng. at a famous investment bank in NYC (now I'm at a fintech in Times Sq.), but you quickly learn that engineering is 2nd and business is first. Everything is done with the attitude of 1) how can we make money and stay in business and then 2) how do we make this resilient and scalable. It pains me now to work with engineers who are just to up their own ass to realize why we're building things.",
                  "score": 6,
                  "created_utc": "2026-02-09 17:45:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4fgd3h",
              "author": "Tender_Figs",
              "text": "To answer where I want to go - I would love to get back into analytics with a very heavy finance bend that may also mix data science into it. It‚Äôs where I was headed in 2022 before detouring into data engineering.",
              "score": 9,
              "created_utc": "2026-02-09 13:24:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4fr4ur",
                  "author": "RandomAccount0799",
                  "text": "What made you detour into data engineering? Do you prefer analytics to corporate finance?",
                  "score": 2,
                  "created_utc": "2026-02-09 14:27:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4fewnn",
              "author": "lozinge",
              "text": "Its a good point - also raises the question of how far can domain experience get you / how much of a moat is it?\n\nDo you know what you're going to try breaking into?",
              "score": 3,
              "created_utc": "2026-02-09 13:15:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4gfoy5",
          "author": "THBLD",
          "text": "Yes and no. I don't know where your skill level is but:\nthe ability of people to actually do quality in-depth SQL, writing functions and procedures, while understanding how it works under the hood is very far and few ppl. \n\nAs someone who's done a lot of ETL and works very heavily with SQL procedures - I do ALSO unfortunately feel that's it's nowadays not a very appreciated skill set, given the complexity to do it well.\n\nEveryone is way too focused on tool sets, AI and relying on Python for way too much. Proper SQL is still very powerful in the right hands and NEEDED.",
          "score": 13,
          "created_utc": "2026-02-09 16:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4gq18t",
              "author": "turboDividend",
              "text": "yeah dude, like...I can understand using python to parse unstructured data or something, like scrapring a website or pulling information out of a word doc/flat file/etc but i dont see the purpose of using it for doing regular ETL type stuff when a proper database can do alot of the heavy lifting, granted you know what you're doing.\n\nI've made functions in sql, stored procs, know window functions , cte, temp tables very well and have even used cursors ( lol ) . I understand how pivots work and have done outer joins/cross joins (this seems to be a bit outdated though) ive come across it in older dbs",
              "score": 3,
              "created_utc": "2026-02-09 17:19:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f9l9n",
          "author": "ThroughTheWire",
          "text": "If you're working in a cost center rather than a profit center then it can really feel that way. I do recognize that my job is almost completely subject to automation within the next few years and so I need to make sure I'm in a position to be an influential decision maker from a business / technical point of view rather than just following the directions of management/stakeholders.",
          "score": 29,
          "created_utc": "2026-02-09 12:40:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fnbol",
              "author": "turboDividend",
              "text": "most of these jobs are cost centers unfortunately. what data engineering jobs are profit centers? working in trading, Adtech, or supporting some sort of high volume sales business?",
              "score": 9,
              "created_utc": "2026-02-09 14:05:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4fowi1",
                  "author": "snarleyWhisper",
                  "text": "I‚Äôm an embedded data engineer within a sales org. All my projects have a very specific roi and are low cost. They are happy to keep expanding the scope and investing in it because they are cost sensitive but are getting business value.",
                  "score": 6,
                  "created_utc": "2026-02-09 14:14:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4fqgsp",
                  "author": "BoringGuy0108",
                  "text": "If you're driving sales or cost reductions, you could be considered a profit center. It depends on your KPIs. Is your goal to accomplish a minimum expectation at the lowest possible cost? You're a cost center. Is your goal to drive the most overall business value and cost is just one factor? You're a profit center. Or at least more of one. \n\nAlso, if your company's product is technology that requires data movement, you're a profit center by default. At my company, IT is broadly a cost center, but my team is often treated more like a profit center because we actively drive sales.",
                  "score": 6,
                  "created_utc": "2026-02-09 14:23:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4fqve8",
                  "author": "thisfunnieguy",
                  "text": "there are companies that sell data or data products\n\nadtech is one example but not the only example.\n\n",
                  "score": 3,
                  "created_utc": "2026-02-09 14:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4fg4mc",
          "author": "CorpusculantCortex",
          "text": "Idk i work as a 700 person global saas company that provides an industry specific data product that has a dedicated data science team. And I get roped into so many random etl and automation jobs because I'm the one who knows python and does etl stuff. So im not feeling very dime a dozen.",
          "score": 16,
          "created_utc": "2026-02-09 13:23:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fn25q",
              "author": "turboDividend",
              "text": "if you know python/sql and are good at it, it seems like you can write your ticket.",
              "score": 4,
              "created_utc": "2026-02-09 14:04:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4gxvz8",
                  "author": "outlier_fallen",
                  "text": "Huh? Every data engineer should know python and SQL. This kind of contradicts the point of this thread.. now I'm questioning it",
                  "score": 5,
                  "created_utc": "2026-02-09 17:57:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4fqmz4",
          "author": "thisfunnieguy",
          "text": "how \"special\" do you need to be? theres like 400 million ppl in this country. Something like 200-300million of that are adults.\n\n  \n",
          "score": 8,
          "created_utc": "2026-02-09 14:24:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4golu2",
          "author": "cokeapm",
          "text": "Branch out deeper into infra. Learn cloud, bigger tools like spark, Kafka, etc. Just go bigger. As you grow less and less people compete with you. Also git gud at being a value provided. Learn how to talk to different people, how to drive initiatives, etc",
          "score": 3,
          "created_utc": "2026-02-09 17:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hv1vd",
          "author": "RoleAffectionate4371",
          "text": "As a staff engineer, in a 100+ person data org, I very much do not feel a dime a dozen. \n\nIt‚Äôs still exceptionally hard to hire skilled engineers with agency, work ethic, and an ounce of business instinct. \n\nThe key is to not just be someone who writes etl. But someone who influences the bottom line through data engineering",
          "score": 3,
          "created_utc": "2026-02-09 20:37:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h5llq",
          "author": "TA_poly_sci",
          "text": "If you are good at DE, very much no",
          "score": 1,
          "created_utc": "2026-02-09 18:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jk7v6",
          "author": "molodyets",
          "text": "If you don‚Äôt understand the business and how other departments think and just want to be an order taker - yes",
          "score": 1,
          "created_utc": "2026-02-10 02:06:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mxehf",
              "author": "Accomplished_Cloud80",
              "text": "I think just take orders is priority. Understand business and share ideas always good and being part of the team.",
              "score": 0,
              "created_utc": "2026-02-10 16:17:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nohss",
                  "author": "molodyets",
                  "text": "being able to take orders is table stakes. if you can't do more than that, you are going to have a very hard time in a down job market.",
                  "score": 1,
                  "created_utc": "2026-02-10 18:21:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4k9uh5",
          "author": "JuggernautSad10",
          "text": "Yes",
          "score": 1,
          "created_utc": "2026-02-10 04:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ki7mo",
          "author": "szrotowyprogramista",
          "text": "Surfing cscareers to get a read on the market is kind of like reading feedback about parcel delivery services online (in absolute terms). People who are doing fine are not posting there. People who are anxious, venting or desperate are. So you're dealing with some serious sampling bias. If you value your mental health I see no point visiting that subreddit.\n\nWith that said - yeah. We are a dime a dozen. So are most people working in the more-or-less modern and commercially relevant branches of software engineering. We are not special, neither are react/node devs, neither are ios/android mobile devs, neither are infra/devops, neither are (run-of-the-mill) data scientists, etc. The non-dime-a-dozen people are those that work in more niche technologies, like dedicated graph DB engineers, or SAP stack devs or maybe these few guys that some US state government urgently hired in 2020 because they knew FORTRAN. \n\nIt's not obvious to me that one is better than the other. If you're niche, you probably have one or two employers that really need your services, but once they finally retire the legacy application they had that required you - you're in a bad position, because you're probably not finding another job. If you're a dime a dozen - you face a lot of competition, but it would be relatively easier to find something new if you lose your job. (This is of course ignoring how good you are - of course there's always many beginners and few extremely knowledgeable people, but that is true with any technology.)\n\nAlso, just a small remark, I'm not sure it is informative to say \"does a lot of SQL\". SQL is a language that has broad support across different databases and data processing engines, it's one thing to be doing a lot of SQL on a huge on-prem Postgres cluster, another to be doing a lot of SQL on a managed platform like Snowflake.",
          "score": 1,
          "created_utc": "2026-02-10 05:50:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ltqm3",
          "author": "Commercial-Ask971",
          "text": "Back in the day I was power bi developer who would establish metrics and discuss how to calculate things or why, however I felt bad because I was chased for silly things like metric doesnt fit to one MD expectations.. or ‚Äûlets make this report more aesthetic‚Äù etc so I switched to data engineering and while I rarely make anything related to metrics anymore (just deliver semantic model and finish), now I feel like nobody cares and just expect me to move and shape the data then get into next. ‚Äû if it works it works‚Äù so no time for technical debt or scabalility unless something fair miserably, then an asap fix is required.. I feel that I do more ‚Äûvaluable‚Äù things but I guess only mine imagination. In both positions I feel like third wheel. When would it end?",
          "score": 1,
          "created_utc": "2026-02-10 12:47:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ixyal",
          "author": "LCuevad",
          "text": "switch to data platform ",
          "score": 1,
          "created_utc": "2026-02-09 23:57:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0rt35",
      "title": "Are people actually use AI in data ingestions? Looking for practical ideas",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r0rt35/are_people_actually_use_ai_in_data_ingestions/",
      "author": "[deleted]",
      "created_utc": "2026-02-10 05:03:57",
      "score": 48,
      "num_comments": 22,
      "upvote_ratio": 0.9,
      "text": "Hi All,  \n\n\nI have a degree in Data Science and am working as a Data Engineer (Azure Databricks)  \n\n\nI was wondering if there are any practical use cases for me to implement AI in my day to day tasks. My degree taught us mostly ML, since it was a few years ago. I am new to AI and was wondering how I should go about this? Happy to answer any questions that'll help you guys guide me better. \n\nThank you redditors :)",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0rt35/are_people_actually_use_ai_in_data_ingestions/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4kv87x",
          "author": "SharpRule4025",
          "text": "The biggest practical win right now is using LLMs to extract structured data from unstructured web sources. Scrape a product page, get back clean JSON with price, description, specs fields instead of maintaining brittle CSS selector pipelines that break every time the source site changes a div class.\n\nAlso useful for classifying and routing incoming data during ingestion - deciding which pipeline a document goes through based on content type rather than hardcoded rules.\n\nFor Databricks specifically, you could experiment with running smaller models to do schema inference on messy source data before it hits your bronze layer. Saves a lot of manual mapping work.",
          "score": 67,
          "created_utc": "2026-02-10 07:44:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l6x25",
              "author": "pceimpulsive",
              "text": "I would use the AI to generate the CSS selector pipeline.\n\nOnce you get an error reading you can re-run the CSS selector generator.\n\nThis way you don't burn tokens like crazy, and you get higher performance too!",
              "score": 23,
              "created_utc": "2026-02-10 09:38:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4lfyi5",
              "author": "Ultimate_Foreigner",
              "text": "For data ingestion with AI, getting back clean JSON from a web page can be tricky and easily break but using [Pydantic AI](https://ai.pydantic.dev/) would likely help here - basically data validation for LLM responses with auto retries etc.\n\nFor any use case other than web scraping, I don‚Äôt really think it is worth trying to wedge in any LLM steps here. Data integration is really a solved problem that would only be hindered by adding in superfluous AI tooling.",
              "score": 6,
              "created_utc": "2026-02-10 11:02:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4lpq9e",
              "author": "tadtoad",
              "text": "This is brilliant! I need to crawl a page where the html changes frequently enough to make traversing the page a nightmare because of the daily monitoring. I think this LLM JSON output would work for me. Thanks for sharing!",
              "score": 3,
              "created_utc": "2026-02-10 12:20:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kyet9",
          "author": "drag8800",
          "text": "honestly the biggest win for us has been using LLMs during validation. not type checking, but catching semantic weirdness that rules miss. like when a field is technically valid but contains \"N/A\" or \"TBD\" or \"pending\" and those all mean different things downstream. having an LLM tag those during ingestion saves so much debugging later.\n\nother thing that's been useful is throwing sample records at an LLM when you inherit a data source with garbage documentation. \"what do these fields probably mean and what types should they be\" gets you 80% there way faster than playing detective.\n\nfor actual pipeline dev i've been using claude code to scaffold ingestion jobs. not shipping the code directly but it's good at recognizing patterns for common sources like REST APIs or SFTP drops. still review everything but cuts initial dev time.\n\nwhat hasn't worked: trying to be clever with dynamic schema evolution. sometimes you want the pipeline to fail loudly when something breaks, not silently adapt and cause problems downstream.\n\nif you're on databricks, check out unity catalog's AI stuff for metadata enrichment. more governance side but still useful.",
          "score": 15,
          "created_utc": "2026-02-10 08:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lefc5",
          "author": "Which_Roof5176",
          "text": "Yep, people use ‚ÄúAI‚Äù in ingestion, but mostly around the pipeline, not inside it: schema mapping, data quality checks, log/alert summarization, and writing connector/ETL code faster.",
          "score": 3,
          "created_utc": "2026-02-10 10:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qjm4c",
              "author": "GAZ082",
              "text": "mmmh, how you would use it for data quality without sharing the actual data?",
              "score": 1,
              "created_utc": "2026-02-11 03:19:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lqe14",
          "author": "tadtoad",
          "text": "I use LLMs for classification/tagging. A stage in my pipeline requires classification of the ingested data into one of 100 categories. I send the category list and the content and get by the right category. It barely costs anything.",
          "score": 3,
          "created_utc": "2026-02-10 12:25:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l72ii",
          "author": "pceimpulsive",
          "text": "Just hell naww to me.\n\nI want my data ingestions to be very fast and have as little dependencies as possible, I also don't want to them to change when openAI changes their guardrails or guts their model a little more to save costs ....",
          "score": 5,
          "created_utc": "2026-02-10 09:40:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lzgx5",
              "author": "Skullclownlol",
              "text": "> I want my data ingestions to be very fast and have as little dependencies as possible, I also don't want to them to change when openAI changes their guardrails or guts their model a little more to save costs ....\n\nExactly the same here. Ingestion = source copy, no transformations.",
              "score": 1,
              "created_utc": "2026-02-10 13:23:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4odhna",
                  "author": "pceimpulsive",
                  "text": "I do ELT,\n\nSmall transforms via uoserts.\n\nE.g. my source system stores timestamps as epoch and a few fields are ints that I want as enumerated strings. I achieve this via a view in a staging layer in the destination DB.\n\nOutside that though... It's copy copy",
                  "score": 1,
                  "created_utc": "2026-02-10 20:16:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ldkj9",
          "author": "Reach_Reclaimer",
          "text": "Unless it's for actually scraping data, there's no reason to use it over a traditional source as far as I'm aware. Would be more expensive for little gain and no ability to troubleshoot",
          "score": 2,
          "created_utc": "2026-02-10 10:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n1hn0",
          "author": "mckey86",
          "text": "I guess U can use automation",
          "score": 2,
          "created_utc": "2026-02-10 16:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l984h",
          "author": "DungKhuc",
          "text": "I'm using AI to ingest news that's relevant to the user profile from different news feeds. LLM is used to transform the news into signals (in JSON format) for UI to consume.",
          "score": 1,
          "created_utc": "2026-02-10 10:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lijg7",
          "author": "Nearby_Fix_8613",
          "text": "Heading our data science and ml dept\n\nIts a blessing and a curse for us",
          "score": 1,
          "created_utc": "2026-02-10 11:25:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lsw2m",
          "author": "reditandfirgetit",
          "text": "Data analysis. Using AI to find fast answers or confirm your theories. For example, a properly trained model could help catch fraud",
          "score": 1,
          "created_utc": "2026-02-10 12:42:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m96v8",
          "author": "ppsaoda",
          "text": "I'm working on medical datasets. And it's messy with clinical notes, so we have developed in-house LLM model to classify diagnosis. Other than that, not much except helping to write code based on my ideas.",
          "score": 1,
          "created_utc": "2026-02-10 14:17:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mcjuk",
          "author": "share_insights",
          "text": "Great conversation. For those training models (even toy models) and looking for ways to make money off of their hard work, we'd love to chat. We believe (read: know) there is a market for the intelligence encapsulated in the code.",
          "score": 1,
          "created_utc": "2026-02-10 14:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kn3yl",
          "author": "Prestigious-Bath8022",
          "text": "Depends what you call AI.\n\n",
          "score": 1,
          "created_utc": "2026-02-10 06:31:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ki7ze",
          "author": "Thinker_Assignment",
          "text": "I'm co-founder of an oss ingestion library so I can give you some community observations \n\nFirst, everyone uses LLMs for coding at this time, some do it completely by chat interface. We support them with tools to do so with less bad consequences, and faster.\n\nSecond, there's a small group of people that does a lot of ingestion from unstructured sources like multimodal and social media, or in document heavy industries. Those folks do an order of magnitude more ingestion than the rest of the community combined - so the LLM data processing use cases far outweigh normal data engineering in data engineering work at this time.\n\nOn the other hand we're moving towards complete agentic coding, Wes recently said python is going to no longer be coded by humans but agents. So maybe learn in that direction. Check out skills, they are the latest thing that works well.",
          "score": -8,
          "created_utc": "2026-02-10 05:50:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvoj0i",
      "title": "Financial engineering at its finest",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qvoj0i/financial_engineering_at_its_finest/",
      "author": "SignalMine594",
      "created_utc": "2026-02-04 13:27:12",
      "score": 45,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "I‚Äôve been spending time lately looking into how big tech companies use specific phrasing to mask (or highlight) their updates, especially with all the chip investment deals going on. \n\nEarlier this week, I was going through the Microsoft earnings call transcript and (based on what seems like shared sentiment in the market), I was curious how Fabric was represented. From my armchair analyst position, its adoption just doesn‚Äôt seem to line up with what I assumed would exist by now...\n\nOn the recent FY26 Q2 call, Satya said:\n\n>Two years since it became broadly available, Fabric's annual revenue run rate is now over $2 billion with over 31,000 customers... revenue up 60% year over year.\n\nThe first thing that made me skeptical is the type of metrics used for Fabric. ‚ÄúAnnual revenue run rate‚Äù is NOT the same as ‚Äúwe actually generated $2B over the last 12 months.‚Äù This is super normal when startups report earnings, since if a product is growing, run rate can look great even when realized trailing revenue is still catching up. Microsoft chose run rate wording here.\n\nThen I looked at the previous earnings where Fabric was discussed. In FY25 Q3, they said Fabric had 21k paid customers and ‚Äú40% using Real-Time Intelligence‚Äù five months after GA, but ‚Äúusing‚Äù isn‚Äôt defined in a way that‚Äôs tangible, which usually is telling. In last week‚Äôs earnings, Satya immediately discusses specific metrics, customer references, etc. for other products.\n\nA huge part of why I‚Äôm also not convinced on adoption is because of the forced Power BI capacity migration. I know the world is all about financial engineering, and since Microsoft forced us all to migrate off of P-SKUs, it‚Äôs not hard to advertise those numbers as great. The conspiracist in me says the numbers line up a little too neatly with the SKU migration:\n\n* $2B in revenue run rate / 31,000 customers ‚âà $64.5k per customer per year.¬†\n* That‚Äôs conveniently right around the published price of an F64 reservation\n\nObviously an average is oversimplifying it, and I don‚Äôt think Microsoft is lying about the metrics whatsoever, but I do think the phrasing doesn‚Äôt line up with the marketing and what my account team says‚Ä¶\n\nThe other thing I saw was how Microsoft talks when they have deeper adoption. They normally use harder metrics like customers >$1M, big deployments, customer references, etc. In the same FY26 Q2 transcript, Fabric gets the run-rate/customer count and then the conversation moves on. And that‚Äôs it. After that, I was surprised that Fabric was never mentioned on its own again, nor expanded upon, and outside of that sentence, Fabric was always mentioned with Foundry.\n\nEarnings reports aren't everything, and 31,000 customers is a lot, so I went looking for proof in customer stories, and the majority of the stories are just implementation partners and consultancies whose practices depend on selling Fabric (Boutiques/Avanade types), not a flood of end-customer production migrations with scale numbers. (There are are a couple of enterprise stories like LSEG and Microsoft‚Äôs internal team, but it doesn‚Äôt feel like ‚Äúno shortage.‚Äù)\n\nPlease check me. Am I off base here? Or is the growth just because of the forced migration from Power BI?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qvoj0i/financial_engineering_at_its_finest/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3lbqv3",
          "author": "engineer_of-sorts",
          "text": "It's literally power bi\n\n  \nthe idea there are $2bn of data engineering workloads running on fabric cannot be true",
          "score": 11,
          "created_utc": "2026-02-04 20:13:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j8wly",
          "author": "Kobosil",
          "text": ">forced migration\n\nah the Microsoft way",
          "score": 15,
          "created_utc": "2026-02-04 14:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j30gf",
          "author": "Nofarcastplz",
          "text": "It would definitely validate what I read here on this subreddit",
          "score": 9,
          "created_utc": "2026-02-04 13:52:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nbkzp",
              "author": "EversonElias",
              "text": "People here just want to hate Fabric. I got downvoted hard because I said I like it.",
              "score": -2,
              "created_utc": "2026-02-05 02:31:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwdlph",
      "title": "Offered a client a choice of two options. I got a thumbs up in return.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwdlph/offered_a_client_a_choice_of_two_options_i_got_a/",
      "author": "Shadowlance23",
      "created_utc": "2026-02-05 06:15:00",
      "score": 44,
      "num_comments": 27,
      "upvote_ratio": 0.92,
      "text": "I'm building out a data source from a manually updated Excel file. The file will be ingested into a warehouse for reporting. I gave the client two options for formatting the file based on their existing setup. One option requires more work from the client upfront, but will save time when adding data in the future. The second one I can implement as-is without extra work on their end but will mean they have to do extra manual work when they want to update the source.\n\nI sent them a message explaining this and asking which one they preferred. As the title suggests, their response was a thumbs up.\n\nIt's late and I don't have bandwidth to deal with this... Looks like a problem for Tomorrow Man (my favourite superhero, incidentally).\n\nEDIT: I hate you all üòÇ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwdlph/offered_a_client_a_choice_of_two_options_i_got_a/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3o9kvc",
          "author": "LoaderD",
          "text": "üëç",
          "score": 40,
          "created_utc": "2026-02-05 06:17:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oajv2",
          "author": "MichelangeloJordan",
          "text": "üëç LGTM",
          "score": 17,
          "created_utc": "2026-02-05 06:26:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3obkec",
          "author": "Thisisinthebag",
          "text": "üëå",
          "score": 11,
          "created_utc": "2026-02-05 06:34:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oero4",
          "author": "every_other_freackle",
          "text": "üëç",
          "score": 8,
          "created_utc": "2026-02-05 07:02:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3omnof",
          "author": "Ok_Smell_453",
          "text": "Always choose the option with \n\nLittle to no maintenance once setup \nTime spent vs time saved\n\nFirst one is key.",
          "score": 13,
          "created_utc": "2026-02-05 08:15:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p5okr",
              "author": "MK_BombadJedi",
              "text": "üëç",
              "score": 8,
              "created_utc": "2026-02-05 11:15:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pdn20",
              "author": "Shadowlance23",
              "text": "In this case, the extra effort is on the part of the client. It's up to them to keep the source updated. On my end, it makes no difference. Basically, the choice was to either add a couple extra columns to the source table to capture data they aggregate manually now and the warehouse will handle the automation, or they can just do the aggregation themselves and the warehouse will read it directly. \n\nMaybe it's my fault for giving them the option in the first place.",
              "score": 9,
              "created_utc": "2026-02-05 12:18:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3zozka",
                  "author": "Ok_Smell_453",
                  "text": "It's a learning curve but if possible, you want code or a process to not involve any updating going forward. \n*With the exception of new fields, etc*\n\nüëçüëçüëçüëçüëçüëç",
                  "score": 1,
                  "created_utc": "2026-02-06 23:28:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ohtpb",
          "author": "je_grootje",
          "text": "üëç",
          "score": 6,
          "created_utc": "2026-02-05 07:30:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oov8b",
          "author": "Putrid-Kale-1793",
          "text": "üëçüèª",
          "score": 7,
          "created_utc": "2026-02-05 08:37:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oqnfn",
          "author": "pndrng",
          "text": "üëç",
          "score": 5,
          "created_utc": "2026-02-05 08:54:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ov3rp",
          "author": "Strange-Ninja3214",
          "text": "üëç indeed",
          "score": 3,
          "created_utc": "2026-02-05 09:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p1xvi",
          "author": "mushashi_san",
          "text": "üëç",
          "score": 3,
          "created_utc": "2026-02-05 10:42:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3par5n",
          "author": "SoggyGrayDuck",
          "text": "Isn't it getting insane, they no longer understand what they're even asking for. Are they not the ones who are actually asking for the metrics? Are executives telling directors they need these metrics without any direction? Is this more BS rolling downhill from some conference?",
          "score": 3,
          "created_utc": "2026-02-05 11:56:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v9da4",
          "author": "Cruxwright",
          "text": "Some things to keep in mind when sending e-mails and requesting feedback:\n\n1- Some people only read the first line and will write their entire reply based on that.\n\nB- Only ask Yes/No questions as many people are incapable of making a choice.\n\niii- Posit the solution that works for you while keeping points 1 and B in mind.",
          "score": 3,
          "created_utc": "2026-02-06 08:11:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p9z0c",
          "author": "poroloid1337",
          "text": "üëç",
          "score": 2,
          "created_utc": "2026-02-05 11:50:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3palxj",
          "author": "Maximum_Syrup998",
          "text": "üëç",
          "score": 2,
          "created_utc": "2026-02-05 11:55:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3te4db",
          "author": "reditandfirgetit",
          "text": "![gif](giphy|RJwdVNdPGxyYQwKu4K)",
          "score": 2,
          "created_utc": "2026-02-06 00:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rzdt7",
          "author": "hubert1224",
          "text": "üëç",
          "score": 1,
          "created_utc": "2026-02-05 20:07:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3u317g",
          "author": "Daddy_data_nerd",
          "text": "üëç",
          "score": 1,
          "created_utc": "2026-02-06 02:53:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uhre8",
          "author": "Childish_Redditor",
          "text": "They're letting you choose",
          "score": 1,
          "created_utc": "2026-02-06 04:27:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vf8rd",
          "author": "BrownBearPDX",
          "text": "Grow up and push for a real answer that will actually be documented and signed off on. Are you afraid of this person who gave you the thumbs up? Tell them ha ha I need a real answer. I can‚Äôt work with a thumbs up for two options. \n\nSign off Will save your skin when this idea of using actual Excel spreadsheet with manually input data blows up, and the whole thing comes tumbing down. If you don‚Äôt have strong data types and validation and schema and you have somebody who is this slack in their care of the project and the dev implementing it, it‚Äôs gonna slide into hellville about two seconds after you launch.",
          "score": 1,
          "created_utc": "2026-02-06 09:08:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3vlh7s",
              "author": "Shadowlance23",
              "text": "Whoa dude calm down. I was having a little joke at the end of the day, not an existential crisis.",
              "score": 3,
              "created_utc": "2026-02-06 10:08:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3wejhv",
          "author": "Expensive_Culture_46",
          "text": "üññ",
          "score": 1,
          "created_utc": "2026-02-06 13:40:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xm0tw",
          "author": "jorbai",
          "text": "üëçüèª",
          "score": 1,
          "created_utc": "2026-02-06 17:14:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pf0bc",
          "author": "Ploasd",
          "text": "Just ring them up and ask them",
          "score": 1,
          "created_utc": "2026-02-05 12:27:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pkftq",
              "author": "Shadowlance23",
              "text": "That's great advice! I'll do that first thing in the morning!",
              "score": 2,
              "created_utc": "2026-02-05 13:03:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r15015",
      "title": "2026 State of Data Engineering Report - 1000+ responses from data engineers",
      "subreddit": "dataengineering",
      "url": "https://www.linkedin.com/posts/josephreis_recently-i-surveyed-1101-of-you-about-the-share-7426990778536583168-fqMr/?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAajovEBZaTvKT0qIqHq9ItYb5C1EMVsVSY",
      "author": "DungKhuc",
      "created_utc": "2026-02-10 16:12:59",
      "score": 43,
      "num_comments": 0,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r15015/2026_state_of_data_engineering_report_1000/",
      "domain": "linkedin.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qzb76a",
      "title": "Tech stack in my area has changed?How do I cope",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qzb76a/tech_stack_in_my_area_has_changedhow_do_i_cope/",
      "author": "Sufficient_Example30",
      "created_utc": "2026-02-08 15:05:00",
      "score": 42,
      "num_comments": 16,
      "upvote_ratio": 0.86,
      "text": "So basically my workplace of 6 years has become very toxic so I wanted to switch.\nOver there i mainly did spark (dataproc),pub sub consumers to postgres,BQ and Hive tables ,Scala and a bit of pyspark and SQL\nBut I see that the job market has shifted.\nNowadays \nThey are asking me for knowledge of\nKubernetes\nDocker\nAnd alot of questions regarding networking along with Airflow \nHonestly I don't know any of these.\nHow do I learn them in a quick manner.\nLike realistically how much time do I need for airflow,docker and kubernetes ",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qzb76a/tech_stack_in_my_area_has_changedhow_do_i_cope/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o49jswk",
          "author": "Darkendfearz",
          "text": "Honestly you can learn the basics of kubernetes and enough information to pass most interviews in a day. I also have used airflow a ton and would consider myself pretty comfortable with the tool but I have never been asked an interview question about it. Docker is also super simple to learn. Just take a step back, breath, and reading about it before freaking out. What kind of networking questions are you getting?",
          "score": 40,
          "created_utc": "2026-02-08 15:28:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49l6nb",
              "author": "Sufficient_Example30",
              "text": "Very wierd ones.\nHow do you setup Ray clusters.\nWhat are the firewalls rules you would need to enable\nIf the company services are behind a NAT gateway how do you ensure that you can hit them.\nIt's very wierd nowadays \nWhy use spark serverless over a spark cluster\nHow does networking work there .\nHow do you ensure IP resource management so they don't exhaust more IPs than needed.\nI expected these to be either platform engineer interview questions but I have never done any of this.\nI would just build the image,use the subnetwork provided to me and would usually be done",
              "score": 9,
              "created_utc": "2026-02-08 15:35:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4cxu6p",
                  "author": "West_Good_5961",
                  "text": "These aren‚Äôt DE questions. That‚Äôs cloud engineer territory. They‚Äôre probably looking for a unicorn who can do 3 jobs at once and still not pay them enough.",
                  "score": 9,
                  "created_utc": "2026-02-09 01:54:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4cnju7",
                  "author": "sib_n",
                  "text": "Yeah, they need a platform/devops/cloud/network engineer to set up their data platform, before the data engineering starts and they are trying to take the shortcut to find someone who can do both. If you're not experienced in setting such as thing, I would move one. I feel like you will be studying for weeks to match the requirements, it's not just learning the Kubernetes basics, only for them to take a guy who has years of experience in cloud platform set up. They will eventually focus on data engineer hiring.",
                  "score": 4,
                  "created_utc": "2026-02-09 00:55:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o49lz26",
                  "author": "Darkendfearz",
                  "text": "That's actually wild. What kind of companies are you interviewing for?",
                  "score": 5,
                  "created_utc": "2026-02-08 15:39:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4a9c6t",
          "author": "tiredITguy42",
          "text": "Wait, there was a time when tech-stack did not change each few months?\n\nBut seriously. Fake it till you make it. All these technologies are easy to use when you are forced to work with them. Just watch some videos, so you have some idea what it is about.\n\nThere are differences in details for each company as the DevOps team is different in each place.",
          "score": 5,
          "created_utc": "2026-02-08 17:33:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bo7c8",
          "author": "turboDividend",
          "text": "data engineering is becoming dev/data ops it seems. you need to be a networking gguy and a pipeline guy. \n\nmost of the devops ppl i met were not developers, not knocking them but it wasnt what they were about.",
          "score": 4,
          "created_utc": "2026-02-08 21:39:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d0ilb",
          "author": "calimovetips",
          "text": "you don‚Äôt need deep kubernetes, just enough to run and debug jobs. airflow plus docker can be picked up in a few weeks, kubernetes basics in about a month if you practice consistently.",
          "score": 2,
          "created_utc": "2026-02-09 02:08:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dq9j8",
          "author": "EviliestBuckle",
          "text": "What is data stack these days?",
          "score": 1,
          "created_utc": "2026-02-09 04:35:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eavf3",
          "author": "al_tanwir",
          "text": "Binge watch a few Kubernetes tutorial on YouTube, and you're good to go. :)",
          "score": 1,
          "created_utc": "2026-02-09 07:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4onjgv",
          "author": "LilParkButt",
          "text": "The way I see things, data engineering is getting split into DataOps, Analytics Engineering, and MLOps.",
          "score": 1,
          "created_utc": "2026-02-10 21:03:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0wwrn",
      "title": "Our company successfully built an on-prem \"Lakehouse\" with Spark on K8s, Hive, Minio. What are Day 2 data engineering challenges that we will inevitably face?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r0wwrn/our_company_successfully_built_an_onprem/",
      "author": "seaborn_as_sns",
      "created_utc": "2026-02-10 10:08:31",
      "score": 35,
      "num_comments": 40,
      "upvote_ratio": 0.9,
      "text": "I'm thinking \n\n\\- schema evolution for iceberg/delta lake  \n\\- small file performance issues, compaction\n\nWhat else? \n\nAny resources and best practices for on-prem Lakehouse management?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r0wwrn/our_company_successfully_built_an_onprem/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4la04a",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-10 10:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lccan",
          "author": "liprais",
          "text": "minio will be your biggest pain of ass",
          "score": 46,
          "created_utc": "2026-02-10 10:30:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lde2s",
              "author": "jupacaluba",
              "text": "I second that. Just reading gave me the itch",
              "score": 6,
              "created_utc": "2026-02-10 10:39:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ldpak",
              "author": "seaborn_as_sns",
              "text": "is it because they abandoned foss? what else is there for on-prem? ceph?",
              "score": 3,
              "created_utc": "2026-02-10 10:42:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lkli5",
                  "author": "rmoff",
                  "text": "garage, seaweedfs, apache ozone, and several others. depends what you need. I wrote about it here (although from a PoC/demo perspective, not production usage): https://rmoff.net/2026/01/14/alternatives-to-minio-for-single-node-local-s3/",
                  "score": 5,
                  "created_utc": "2026-02-10 11:42:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ljukg",
                  "author": "liprais",
                  "text": "i am running hdfs ,works smooth",
                  "score": 2,
                  "created_utc": "2026-02-10 11:36:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4nln7l",
                  "author": "Colafusion",
                  "text": "It‚Äôs also AGPL, which depending on what you‚Äôre doing can be a massive issue.",
                  "score": 1,
                  "created_utc": "2026-02-10 18:08:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4m127x",
              "author": "543254447",
              "text": "Can't agree with you more. Literally cannot delete some files for no reason.......\n\nAlways run into weird error with spark due to it.....",
              "score": 2,
              "created_utc": "2026-02-10 13:32:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4met9m",
                  "author": "seaborn_as_sns",
                  "text": "how big is your dataeng/dataops team?",
                  "score": 1,
                  "created_utc": "2026-02-10 14:47:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4p6daw",
              "author": "zikawtf",
              "text": "What justify the MinIO as a storage tool in production environment? I mean, store data is cheap, so why not S3?",
              "score": 1,
              "created_utc": "2026-02-10 22:33:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lh0gn",
          "author": "Gold_Ad_2201",
          "text": "it sounds like you buit now a 20 year old architecture.\n1. is spark the only access to data? what about lower latency? trino, duckdb?\n2. hive partitioning will only delay your problems. you def need to look into table formats (iceberg, delta). and more importantly - they are also designed badly. you need to look into having catalog with them to have the good speed\n3. I assume minio and k8s are because you have some requirement to have air gapped env? if not, do consider S3/blob to save your maintenance team",
          "score": 15,
          "created_utc": "2026-02-10 11:12:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mf2uk",
              "author": "seaborn_as_sns",
              "text": "1. experimenting on trino too  \n2. we have iceberg and delta too, unified hive catalog. should we adopt polaris or something else do you think?  \n3. yes we need airgapped. i think ceph is better option but no experience to advocate for it.  ",
              "score": 3,
              "created_utc": "2026-02-10 14:48:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4mwg0o",
              "author": "Doto_bird",
              "text": "Do you have any experience with MotherDuck (from DuckDB)? They critized iceberg and delta quite harshly in their announcement video and they addressed those issues (in their opinion), but I've never talked with anyone who's actually used it for big data workloads yet.",
              "score": 2,
              "created_utc": "2026-02-10 16:12:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mxgfv",
                  "author": "Gold_Ad_2201",
                  "text": "didn't use it in production, no. their comments are fair. but let's see if this tech becomes adopted and supported. their idea of DuckLake sounds pretty logical but other than MotherDuck I didn't hear of any commercial implementation.\nbut duckDB itself is awesome engine!",
                  "score": 1,
                  "created_utc": "2026-02-10 16:17:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ltl6j",
          "author": "Hackerjurassicpark",
          "text": "Upgrading your K8S, Hive and Minio when your current versions go EOL",
          "score": 4,
          "created_utc": "2026-02-10 12:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfa2j",
              "author": "seaborn_as_sns",
              "text": "you think thats near-term (2yrs) or bit later? ",
              "score": 2,
              "created_utc": "2026-02-10 14:49:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4p5ima",
                  "author": "Hackerjurassicpark",
                  "text": "Depends on the version you‚Äôre using. Go check the EOL dates for the exact version you‚Äôre using",
                  "score": 1,
                  "created_utc": "2026-02-10 22:28:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4le43p",
          "author": "dragonnfr",
          "text": "Run aggressive compaction (bin-packing, 128MB targets). For schema evolution, only add fields. Check Delta docs for OPTIMIZE + ZORDER BY on small files.",
          "score": 4,
          "created_utc": "2026-02-10 10:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4leirv",
              "author": "seaborn_as_sns",
              "text": "any tool to monitor general health of delta tables or do teams build inhouse monitoring scripts?",
              "score": 1,
              "created_utc": "2026-02-10 10:50:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lsdb6",
          "author": "Eitamr",
          "text": "Minio is for testing, avoid on prod if you can",
          "score": 3,
          "created_utc": "2026-02-10 12:38:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfh1k",
              "author": "seaborn_as_sns",
              "text": "even enterprise minio? the \"aistor: Exabyte-Scale Storage Engineered for the AI Era\"",
              "score": 1,
              "created_utc": "2026-02-10 14:50:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ltxgx",
          "author": "6nop_",
          "text": "Q: How are you supporting multiple writers using Delta Lake ? See [DeltaLake S3 Docs](https://docs.delta.io/delta-storage/#amazon-s3)\n\nWe have been running an on prem data warehouse for over 1.5 years. Our setup looks like.\n\n* [S3 Compatible Objectstore](https://vastdata.com/)\n* K8S compute.\n* Iceberg and Kafka Connect\n* Hive Metastore (don't use 4.0.1 ) see [issue](https://github.com/apache/iceberg-python/issues/1222)\n* Trino - Runs great!\n* Kafka - Strimzi - Also Great!\n* OPA for permissions\n* Okta for Auth\n\nOur biggest issue is doing table maintenance, removing snapshots without getting corrupted tables. [see issue](https://github.com/trinodb/trino/issues/19638)\n\nOur S3 Compatible objectstore has been a problem lately. When it gets stressed, it introduces latency and not all S3 clients deal with that properly, ie default 3 sec request timeouts.",
          "score": 3,
          "created_utc": "2026-02-10 12:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfyxl",
              "author": "seaborn_as_sns",
              "text": "thanks so much! what was the decision-making process that you guys arrived to that stack? followed some tried-and-tested blueprint from some similar company's experience or arrived purely based on internal discussions and evaluations?",
              "score": 1,
              "created_utc": "2026-02-10 14:53:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mtd7n",
          "author": "ShanghaiBebop",
          "text": "Governance and access management will be a PITA.¬†",
          "score": 3,
          "created_utc": "2026-02-10 15:58:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ldmck",
          "author": "FunAd6672",
          "text": "Data quality checks become your real Day 2 job not pipelines.",
          "score": 2,
          "created_utc": "2026-02-10 10:41:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4le9qw",
              "author": "seaborn_as_sns",
              "text": "how do you manage them? via dbt or inhouse tools via great expectations or something? ",
              "score": 2,
              "created_utc": "2026-02-10 10:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lg82w",
          "author": "reallyserious",
          "text": "How can one handle access control like row level security and table level security?",
          "score": 1,
          "created_utc": "2026-02-10 11:05:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfc28",
              "author": "seaborn_as_sns",
              "text": "experimenting with ranger now",
              "score": 3,
              "created_utc": "2026-02-10 14:49:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4n92oq",
          "author": "SuperTangelo1898",
          "text": "Ghost objects that exist in the backend but don't exist in Minio's front end UI object manager",
          "score": 1,
          "created_utc": "2026-02-10 17:11:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nbpub",
          "author": "swapripper",
          "text": "Tenancy/Cost attribution \nGovernance/PII masking / RLS\nLogs/Lineage/Observability/Performance monitoring\nSemantic layer possibly\nCDC if you need it\nEasy abstractions for backfills/backups/compaction/cleanup",
          "score": 1,
          "created_utc": "2026-02-10 17:23:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nw2e9",
          "author": "efxhoy",
          "text": "Just curious, how much data do you have? 1TB? 100TB?¬†",
          "score": 1,
          "created_utc": "2026-02-10 18:56:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pn6dc",
          "author": "Due_Carrot_3544",
          "text": "Whats your total data volume stored right now?",
          "score": 1,
          "created_utc": "2026-02-11 00:05:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4psyls",
          "author": "Rich-Ad5460",
          "text": "May I ask how long does it take to build this? And with how many people?",
          "score": 1,
          "created_utc": "2026-02-11 00:38:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n14a3",
          "author": "ChinoGitano",
          "text": "Why use Hive when Unity Catalog is now open-source?  Governance and performance may be your biggest headache ‚Ä¶ assuming you actually have the component integration licked. üòÖ",
          "score": 1,
          "created_utc": "2026-02-10 16:34:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzxr0f",
      "title": "How are you debugging and optimizing slow Apache Spark jobs without hours of manual triage in 2026?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qzxr0f/how_are_you_debugging_and_optimizing_slow_apache/",
      "author": "AdOrdinary5426",
      "created_utc": "2026-02-09 07:19:23",
      "score": 32,
      "num_comments": 10,
      "upvote_ratio": 0.9,
      "text": "We've seen Spark jobs dragging on forever lately: stages with skew, small files, memory spills, or bad shuffles that take hours to pinpoint, even with the default Web UI. We stare at operator trees and executor logs, guess at bottlenecks, then trial-and-error code changes that sometimes make it worse.\n\nOnce the job is running in production, the standard Spark UI is verbose and overwhelming, leaving us blind to real-time issues until it's too late.\n\nKey gaps frustrating us right now\n\n*  Default Spark UI hard to read with complex plans and no clear heat maps for slow stages.\n*  No automatic alerts on common perf killers like small files IO, data skew, or partition imbalances during runs.\n*  Debugging relies on manual log parsing and guesswork instead of actionable insights or code suggestions.\n*  No easy way to rank issues by impact (e.g., cost or runtime delta) across jobs or clusters. Team spends too much time firefighting instead of preventing repeats in future pipelines.\n\nSpark is our core engine but we're still debugging it like it's 2014. Anyone running large-scale Spark (Databricks, EMR, on-prem) solved this at scale without dedicated perf engineers?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qzxr0f/how_are_you_debugging_and_optimizing_slow_apache/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4eedot",
          "author": "noobcoder17",
          "text": "I'll give it to you straight, YOU DON'T.\n\n\nThere's all these talk, all this theory about spark optimizations and debugging, yada yada.¬†\n\n\nIn reality you have to spend those hours in triage.¬†\n\n\nBut usually once you get a hang of it, you shouldn't be spending too many hours next time.¬†",
          "score": 33,
          "created_utc": "2026-02-09 07:55:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jmx7c",
              "author": "ubelmann",
              "text": "Some of it is taking time to adhere to best practices in the first place.  You could argue it's overkill in some cases, but being proactive about things like too many small files, being thoughtful about partitions and such can go a really long way.\n\nBut I agree that once you've seen a few bad jobs, you get better at finding the root causes more quickly, or maybe I should say less slowly.",
              "score": 1,
              "created_utc": "2026-02-10 02:21:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4jolho",
                  "author": "noobcoder17",
                  "text": "Yep! it's always \"BEST\" to follow best practices. On the contrary, what i've noticed in my experience working for many years in this field, engineers are rushed to deliver and the people who are taking these arch decisions are also in a rush and juggling around multiple projects and they give us the best practice that they know of which may not always work in production. \n\nI've found, no matter how much we do, things will break at one point and that's the real opportunity to learn and optimize.   \n  \nHeck i used to think big tech is immune to this, remember times when google, chatgpt went down? or the Korian guy making this \"gangnam style\" video and breaking youtubes views pipeline?- all were learning opportunities and DE is same as such. ",
                  "score": 1,
                  "created_utc": "2026-02-10 02:31:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4enuhm",
          "author": "not-an-AI-bot",
          "text": "Follow good practices, avoid functions that are already documented for slow performance, avoid too much custom code, use modularity, specially the ones you know perform very well. And keep logs for steps/substeps so you can monitor and adjust where necessary.",
          "score": 6,
          "created_utc": "2026-02-09 09:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ji1vi",
          "author": "MonochromeDinosaur",
          "text": "You don‚Äôt this is unfortunately the reality of self managed spark.\n\nLooking at the SQL execution DAG in the spark UI for long steps and finding the longest duration ones or bottle necks is what I would do for performance. It was the only useful view\n\nThankfully I moved on to Snowflake and hoping to never look back.",
          "score": 3,
          "created_utc": "2026-02-10 01:53:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eazm1",
          "author": "Efficient_Agent_2048",
          "text": "Well, I would say the key is moving from reactive debugging to proactive instrumentation. Integrate structured logging and metrics, for example SparkListener events, Ganglia, Prometheus, so you get live alerts for small files, skew, or memory spills. Use automated stage analysis to highlight the top N bottlenecks by runtime or cost impact. Combine that with CI tests for job profiles, so regressions get flagged before hitting prod. It is not magic, but layering metrics, alerts, and profiling drastically reduces the manual triage.",
          "score": 4,
          "created_utc": "2026-02-09 07:23:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f75os",
              "author": "One_Citron_4350",
              "text": "What do you mean by automated stage analysis? How do you do it?I'm curious, is it something you implemented internally because I don't know of such a tool.",
              "score": 4,
              "created_utc": "2026-02-09 12:22:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4em6fu",
              "author": "DeepFryEverything",
              "text": "Suggestions for tooling? Our platform team has set up Grafana, but I am not sure how to plug that into Databricks-clusters.",
              "score": 1,
              "created_utc": "2026-02-09 09:12:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}