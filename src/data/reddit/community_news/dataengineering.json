{
  "metadata": {
    "last_updated": "2026-03-01 03:29:57",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 424,
    "file_size_bytes": 459002
  },
  "items": [
    {
      "id": "1rdv80s",
      "title": "Am I missing something with all this \"agent\" hype?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rdv80s/am_i_missing_something_with_all_this_agent_hype/",
      "author": "KindTeaching3250",
      "created_utc": "2026-02-24 22:37:48",
      "score": 315,
      "num_comments": 128,
      "upvote_ratio": 0.98,
      "text": "I'm a data engineer in energy trading. Mostly real-time/time-series stuff. Kafka, streaming pipelines, backfills, schema changes, keeping data sane. The data I maintain doesn't hit PnL directly, but it feeds algo trading, so if it's wrong or late, someone feels it.\n\nI use AI a lot. ChatGPT for thinking through edge cases, configs, refactors. Copilot CLI for scaffolding, repetitive edits, quick drafts. It's good. I'm definitely faster.\n\nWhat I don't get is the vibe at work lately.\n\nPeople are running around talking about how many agents they're running, how many tokens they burned, autopilot this, subagents that, some useless additions to READMEs that only add noise. It's like we've entered some weird productivity cosplay where the toolchain is the personality.\n\nIn practice, for most of my tasks, a good chat + targeted use of Copilot is enough. The hard part of my job is still chaining a bunch of moving pieces together in a way that's actually safe. Making sure data flows don't silently corrupt something downstream, that replays don't double count, that the whole thing is observable and doesn't explode at 3am. \n\nSo am I missing something? Are people actually getting real, production-grade leverage from full agent setups? Or is this just shiny-tool syndrome and everyone trying to look \"ahead of the curve\"?\n\nGenuinely curious how others are using AI in serious data systems without turning it into a religion. On top of that, I'm honestly fed up with LI/X posts from AI CEOs forecasting the total slaughter of software and data jobs in the next X months - like, am I too dumb to see how it actually replaces me or am I just stressing too much with no reason?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rdv80s/am_i_missing_something_with_all_this_agent_hype/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o78tyzr",
          "author": "toabear",
          "text": "Earlier today, I took 78 views that were created in SQL server. I need these in Snowflake (DBT really). I don't have all of the source data I need to make these and use work either so I need to identify those, build views in SQL server for the source systems that the orchestrator can query and add to the extractors. \n\nIt took Claude Code an hour with almost no interaction on my part aside from approving the plan upfront. It one shotted the whole thing. All models compiled. Then I had it build a tool to cross validate the data from the old system with the new system.\n\nBy no means was this sexy or even complicated work but it was insanely time-consuming. That would've been a couple days worth of work doing it by hand. Hell, just cross referencing out which source data I was missing would've been annoying and painful. I know because I did pretty much this exact same task by hand about six months ago.\n\nI spent effectively 25 to 30 minutes on the whole thing planning upfront.",
          "score": 59,
          "created_utc": "2026-02-25 01:12:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79s8la",
              "author": "exjackly",
              "text": "This is where I see everything shaking out.  AI is good at doing those tedious tasks that you can plan clearly up front.  The real thinking is still - at least for now - still the purview of engineering.",
              "score": 46,
              "created_utc": "2026-02-25 04:33:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cgjfk",
                  "author": "Thinker_Assignment",
                  "text": "The real thinking skill is not captured by data models but ontologies. data models just serve retrieval",
                  "score": 1,
                  "created_utc": "2026-02-25 16:00:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7bd2zo",
              "author": "zazzersmel",
              "text": "tbh, i don't even understand what the task is that you're describing here.",
              "score": 9,
              "created_utc": "2026-02-25 12:30:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cih0a",
                  "author": "SevenEyes",
                  "text": "sounds like they just needed to migrate a bunch of sql views from onprem to snowflake",
                  "score": 6,
                  "created_utc": "2026-02-25 16:09:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ezqnr",
                  "author": "toabear",
                  "text": "The company I joined was running everything off power BI. Power BI dashboards were all driving off a series of views loaded in SQL server.\n\nWe are moving away from power BI and moving to a centralized data warehouse. This was part of the migration. Rather than rethinking all of the views that do a very good job of joining and describing the existing data structures, I wanted to migrate them and convert into DBT models in snowflake.",
                  "score": 3,
                  "created_utc": "2026-02-25 23:04:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7bzh4j",
              "author": "Firm_Bit",
              "text": "Similar experience. It’s very good. \n\nWe’ve removed 2 job reqs because we don’t think we need the capacity anymore. It’s one shotting some pretty medium sized tasks to a pretty good quality. And then the last bit of QA + fixes is significantly easier.",
              "score": 2,
              "created_utc": "2026-02-25 14:39:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7idk45",
                  "author": "doryllis",
                  "text": "Ironically, we just laid off QA",
                  "score": 1,
                  "created_utc": "2026-02-26 13:24:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7byqi0",
              "author": "reelznfeelz",
              "text": "Was that with the existing sub-agent mode or the new agent teams feature?  At first I thought agent teams seemed wicked cool.  But it seems like people are finding that outside of a pretty huge lift, it’s just not that much better than sub-agents and it burns through tokens.  ",
              "score": 1,
              "created_utc": "2026-02-25 14:35:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cel63",
                  "author": "toabear",
                  "text": "Just standard subagent. I have superpowers and context7 plugins installed.",
                  "score": 1,
                  "created_utc": "2026-02-25 15:51:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7dsw7j",
              "author": "marymalu_h",
              "text": "We develop AI-native OS that connects your data & AI and this completely solves your problem)",
              "score": 0,
              "created_utc": "2026-02-25 19:40:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o782d8i",
          "author": "Ok-Recover977",
          "text": "I think the effectiveness highly depends on how well integrated your AI tools are with your internal systems and whether your datasets are well documented, and most organizations don't have an environment like that.",
          "score": 121,
          "created_utc": "2026-02-24 22:43:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o782z38",
              "author": "bamboo-farm",
              "text": "None do.",
              "score": 33,
              "created_utc": "2026-02-24 22:46:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7blaky",
                  "author": "McNoxey",
                  "text": "I don’t understand this line of thinking. \n\nYou are ENGINEERS. You BUILD the tools. That is literally our secret power right now. \n\nWe don’t NEED the tools to work in our internal systems. We can just build them. \n\nThis is what is going to separate engineers moving forward imo",
                  "score": 13,
                  "created_utc": "2026-02-25 13:22:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7biogm",
                  "author": "cky_stew",
                  "text": "As a contractor that sets up new GCP lakes for SME’s - mine all do!\n\nI’m going to propose an agent to my current client for modifying these pipelines, as there will be no engineer when I leave - I’ll be honest with them that they don’t NEED it but it will potentially save someone some pain down the line from reading my documentation should they need to add a new connection and bring it through ELT to the BI tool - at the risk of me being unsure how good the agent itself will be. I hope they take me up on it as I can see it working if I put sufficient guardrails in place. However I also worry it will be a disaster. I just want to personally try it out.",
                  "score": 4,
                  "created_utc": "2026-02-25 13:06:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o78dqcc",
              "author": "doryllis",
              "text": "We at least have schema definitions and procedures defined in source control which means so much for context. \n\nThen you get the issue of “the data you get versus the data you expect” which is well beyond the bounds of even Claude to imagine.",
              "score": 9,
              "created_utc": "2026-02-24 23:43:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7b8ozo",
                  "author": "bamboo-farm",
                  "text": "Agreed! Same issue.",
                  "score": 0,
                  "created_utc": "2026-02-25 11:59:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7byrrr",
              "author": "Firm_Bit",
              "text": "Idk about this. So far I’ve gotten pretty good results with very little input beyond some example files and sample data. Similar to OP, not totally hands off but easily cutting the time required by a lot.",
              "score": 1,
              "created_utc": "2026-02-25 14:35:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o786mpm",
          "author": "jaredfromspacecamp",
          "text": "Depends a lot on your tech setup I think. If your company has ample confluence docs, uses jira well, uses datadog or some central observability, GitHub, Aws, then just using the relevant mcps + clis with an agent cli can do pretty wild stuff. If you have multi-repo setup, you can run the agent at a parent directory with a minimal md for context about what each repo is, with more robust md in each repo. You can use skills that teach it your particular workflows (eg when you make a pr, watch the ci to pass, if it fails investigate logs on circleci using circleci mcp).",
          "score": 64,
          "created_utc": "2026-02-24 23:05:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aandh",
              "author": "Mescallan",
              "text": "i just want to point out that this question is asked regularly in this sub, and this is the first time I'm seeing the most upvoted comment being \"yes, sometimes\" Every other time I've checked these threads it's always been \"no stop asking\"",
              "score": 15,
              "created_utc": "2026-02-25 06:55:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7dtiwk",
              "author": "nikaburu",
              "text": "Exactly that. I used to click through a million pages in the clouds, docs, and files in git to gather the context I needed to do my job as an architect. Now it's all automated for me by an agent, way fewer clicks. It generates CLI calls much faster than I click buttons and grep myself. \n\nThe other thing is code reviews, both fixing and leaving comments - agents can fetch comments from pull requests, fix and push back. Then to fetch errors from the CI run and address those.\n\nThis is qualitatively different from using a chat and copy-pasting things around.\n\nIt requires a bit of prep, though, to record memory/skills with config info and some examples of CLI commands so agents can reliably connect to your data/systems. It's all done by trying out and asking the agent “Now save what we learned in this session as a skill”. Otherwise, it keeps hitting and solving the same roadblocks in each session again and again.",
              "score": 1,
              "created_utc": "2026-02-25 19:43:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o781rly",
          "author": "trentsiggy",
          "text": "Shiny-tool syndrome, mostly.  ",
          "score": 139,
          "created_utc": "2026-02-24 22:40:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o789n9d",
              "author": "Vast_Dig_4601",
              "text": "I truly believed this until a couple weeks ago when we started using Claude Code, and this isn't like hype, all seniors are having existential meltdowns over it. I don't know how to react to what it can do. Can feed it 50 microservices and spend a few hours working on context building and literally can just feed it tickets and it does them for me. \n\nI have a feel Anthropic is purposely losing huge money pushing this out for the cost it's at right now and will scale it's capabilities way the fuck back once they IPO but right now it's absolutely capable of doing my job for me. I fucking hate that i'm even saying this but it's on such a different level if you haven't used it you won't believe me.",
              "score": 35,
              "created_utc": "2026-02-24 23:20:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78e57o",
                  "author": "bamboo-farm",
                  "text": "We have been using for a few months. It’s a cycle. \n\nEventually you realize the bottleneck is review and processes. \n\nThe latter two cannot be automated. So a lot less changes relative to expectations or what you even think right now. \n\nWhat’s funny is folks think less technical folks can now take on technical roles where it’s the inverse. You need a technical expertise and mindset to get the most out of those tools.",
                  "score": 67,
                  "created_utc": "2026-02-24 23:45:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o78d4m4",
                  "author": "Forsaken-Promise-269",
                  "text": "Yes - we’ve moved up a capability level in the past two months with Opus and Claude code - that doesn’t mean it replaces you yet but that it has become MUCH more capable than just a few months ago",
                  "score": 16,
                  "created_utc": "2026-02-24 23:39:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7a117g",
                  "author": "nerevisigoth",
                  "text": "Same here. I was a big skeptic until recently, but this newest generation of models really has me wondering about the future of the industry. It's just so good and it's improving so quickly.",
                  "score": 4,
                  "created_utc": "2026-02-25 05:36:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7a6w0q",
                  "author": "powpow198",
                  "text": "I used it yesterday and it broke a regex which completely changed the data structure, i pointed this out and it made an edit which still didn't work.\n\nI'm not sure if I'm asking too much of it, or perhaps it's because it's better suited to green fielding or what.",
                  "score": 3,
                  "created_utc": "2026-02-25 06:23:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7eiiy9",
                  "author": "anakaine",
                  "text": "Similar with Gemini, and Id say the quality is very much similar. \n\n\nI grabbed the Antigravity editor recently and set up a workspace. Told the editor what I was after and the thing scaffolds out multiple directories, interfaces, modules, data connectors, and built up a well connected interface. Refinememts were straightforward. \n\n\nWas it perfect? Of course not. Was it insanely good? Yup.\n\n\nIt even hooked Chrome and navigated the thing it was building on its own via vision and clicks instead of just browser automation.\n\n\nI wont use this in production - it was purely a look-and-see. What I am using is coding assist and refactoring assistance. ",
                  "score": 1,
                  "created_utc": "2026-02-25 21:39:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7967yo",
                  "author": "IAMHideoKojimaAMA",
                  "text": "Lol get rekd fake seniors",
                  "score": -3,
                  "created_utc": "2026-02-25 02:22:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7blp89",
                  "author": "McNoxey",
                  "text": "Now consider what you are discovering from a couple of weeks ago has been the case for all of 2025. Claude code didn’t just magically come out when you discovered it and that’s the problem that all other people are experiencing right now. Everyone seems to be having this lightbulb moment not recognizing that the moment occurred a year ago already.",
                  "score": -1,
                  "created_utc": "2026-02-25 13:24:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o782wlk",
              "author": "bamboo-farm",
              "text": "Not 100%. There are use cases just doesn’t match all of expectations.",
              "score": 17,
              "created_utc": "2026-02-24 22:45:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78b4ex",
                  "author": "nemec",
                  "text": "> Not 100%\n\nTrue. I think they're also putting drugs in the water.",
                  "score": 22,
                  "created_utc": "2026-02-24 23:28:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o782aee",
          "author": "bamboo-farm",
          "text": "Yes and no. There’s a lot of ai psychosis that I am dealing with as well where many think they can now do more than before. \n\nIn some ways they can but unfortunately this leads them to believe they can now do all sorts of data roles in using data Eng and SE. \n\nIt’s another cycle. We likely just need to be tolerant and wait it out. \n\nI for one am having a hard time with leadership wanting to enable everyone to do everything with data. \n\nI’ve accepted that they will just waste their time and nothing I say will stop them so I’m just waiting for the dominos to inadvertently fall.",
          "score": 30,
          "created_utc": "2026-02-24 22:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78hcbc",
              "author": "the-wx-pr",
              "text": "that people can do anything with data sounds dangerous without the propper knwoledge of how when and who and the permissions they have over it",
              "score": 1,
              "created_utc": "2026-02-25 00:03:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o78eb8z",
          "author": "bamboo-farm",
          "text": "Wait till everyone starts building our their own local dbs and pipelines. \n\nFun fun fun \n\n/s",
          "score": 7,
          "created_utc": "2026-02-24 23:46:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a7ctw",
              "author": "powpow198",
              "text": "Already happened to me!",
              "score": 1,
              "created_utc": "2026-02-25 06:26:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7amngz",
          "author": "BuildingViz",
          "text": "I like using it for boilerplate stuff and to learn, but I just don't trust vibe coding. We have Cursor and access to Claude and Gemini, but I usually use it to bounce ideas and to troubleshoot/explain solutions to me. By default I tell it to not even make changes because it's important to me to be a filter for what it wants to change. I get suggestions and explanations, and make code changes I think make sense.\n\nInterestingly I recently had an all-hands where our CEO was imploring everyone to use it more often, not just for the company but for our professional growth. And I think it does make sense to an extent, but I've found it either hallucinates too much or doesn't fully grasp the context that I do, so I don't just let it run amok.",
          "score": 7,
          "created_utc": "2026-02-25 08:44:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o785a5y",
          "author": "stuckplayingLoL",
          "text": "Agreed with you on using AI to make editing faster. I haven't seen any good uses of agents or llms that are truly game changing in our space.",
          "score": 6,
          "created_utc": "2026-02-24 22:58:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o782vpq",
          "author": "mjam03",
          "text": "I’d say a fair amount of shiny new tool syndrome and also like you mentioned people trying to sound ahead of the curve.\n\nA good way to figure out where you stand is review PRs from those who are running their gaggle of sub agents. I’ve found (based on the code they’re submitting) that it tends to be those most impressed with what they can get out of AI are the least discerning. In other words, they’re happy to slam their sub agent code out because it was much better than what they did before, but not because it was necessarily sound concise maintainable code.",
          "score": 17,
          "created_utc": "2026-02-24 22:45:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78cpl0",
              "author": "CorpusculantCortex",
              "text": "For sure our ceo is always saying \"use ai to do this\" \"ai first if you didn't start yesterday start at the end of the meeting\" but has no concept of what the capacity of ai is. Like for an experienced de or swe who knows how to build context it can help us be way faster *IF* the tooling you are working on is ai first. But when we are forced to put out powerbi dashboards instead of something code native that ai can really help with, agents are kinda useless. But also to someone who knows little about system design they are a dangerous weapon because they can give people who dont know enough WAY too much confidence.",
              "score": 5,
              "created_utc": "2026-02-24 23:37:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o78d5o6",
          "author": "doryllis",
          "text": "My boss is literally constantly saying “use AI” and haranguing DEs who haven’t installed it yet. \n\nAt best it’s a tool and can save time, at worst it’s a monkey chopping out necessary bits of legacy code. \n\nEspecially if there is an errant logic error in that legacy code. \n\nGood lord help you if you’re trying to solve an issue and you make four new ones.\n\nYou may never find what one letter it omitted.",
          "score": 14,
          "created_utc": "2026-02-24 23:40:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79bb80",
              "author": "Emergency-Ad-7833",
              "text": "Shouldn't be using AI if a git revert is not possible",
              "score": 4,
              "created_utc": "2026-02-25 02:50:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o79rxd4",
                  "author": "iknewaguytwice",
                  "text": "You’re absolutely right, I should not have dropped all the tables in the production database without taking a backup first. You have every right to be upset, this is unacceptable. \n\nLet me try to fix this.\n\n\n    Git revert xe6uy2a\n    Git push orgin main\n\n\nI have removed the sql files that dropped the tables. Please verify the data in the database has been restored. \n\n\n\nYou’re absolutely right, reverting the code changes will not bring back the data in the sql databases. That data is gone forever and cannot be recovered. We will have to start fresh. Would you like me to provision a new server and install SQL Server on it?",
                  "score": 29,
                  "created_utc": "2026-02-25 04:31:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o79ioi7",
                  "author": "doryllis",
                  "text": "When everything is restructured by AI it can be hard to identify what the “real change” is, tho. So reversion is possible, but figuring out what that subtle logic change is sometimes hard.",
                  "score": 4,
                  "created_utc": "2026-02-25 03:32:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ee6ww",
                  "author": "MasterPackerBot",
                  "text": "Bingo!  \n  \nWe are a startup in this space. We are trying to build something where we AI to work on data workflows, but the same safety that software engineers get with git for code. (eg: with full Data+Schema+ETL versioning, branching and cascading rollback support etc). DEs also would need to know that the operations are repeatable and reproducible (unlike an LLM hallucinating the steps every time).\n\nOverall the idea is that without making the \"write\" operations safe, data engineers will not go all in on AI like software engineers did. When we talk to potential customers, we do see some excitement with the possibilities around these (even if they are skeptical at first). Of course only time will tell if we can crack the DE space, since there is a lot of AI skepticism (for good reasons I agree).\n\n(PS: Please DM me if you are willing to try our product or give feedback. We are always looking for real practitioners to give honest feedback).",
                  "score": 2,
                  "created_utc": "2026-02-25 21:19:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78bnwq",
          "author": "VanillaRiceRice",
          "text": "Some of it is hype IMO. But IME, with some restraint, and careful deployment, I think it has the opportunity to really change our scope for impact. Also in the same industry. Drop a DM if you're open to chat.",
          "score": 3,
          "created_utc": "2026-02-24 23:31:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79ccbd",
          "author": "zangler",
          "text": "Like all the other AI coding instruments...the people that are on the leading edge of AI tool productivity are fewer than those that attempt to use the tools. \n\nAgents are more difficult to use productively. Signals of use are not easily proven and not necessarily expressed in numbers of agents or tokens burned. This is not how people that are productive with AI or agents speak about their productivity.\n\nOn the flip side, the people calling it shiny toys or whatever, are basically repeating the statements from a year ago as AI coding became serious. \n\nI'm a big enough workplace...inspect their work against their claims. You will find the person that actually knows how to leverage AI and agentic coding.",
          "score": 3,
          "created_utc": "2026-02-25 02:55:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78dbs3",
          "author": "ClittoryHinton",
          "text": "People are just overexcited because the models are no longer totally useless, and everyone knows the execs are going to start tracking your agent usage so they are trying to get ahead of the curve. Just the latest flavour of corporate bullshit really",
          "score": 7,
          "created_utc": "2026-02-24 23:41:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o782v8t",
          "author": "IDoCodingStuffs",
          "text": "Literal shiny tool syndrome. Agentic pattern is like the newest major ore vein discovered in this gold rush, so everyone is running in that direction.\n\nWhat makes it major is because we only had the RAG and chatbot patterns with any production use for LLMs so far. \n\nIn my personal opinion it’s just pyrite. ",
          "score": 9,
          "created_utc": "2026-02-24 22:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79fvw5",
              "author": "Proof_Escape_2333",
              "text": "whats the value of AI agent? does it automate tasks for you? What if it is eating up more resources than value it produces? ",
              "score": 1,
              "created_utc": "2026-02-25 03:16:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o79pi8p",
                  "author": "IDoCodingStuffs",
                  "text": "> does it automate tasks for you\n\nThat’s exactly it. You can expose some APIs and write a prompt for it to execute through them, say “if I get an angry email notify me on my smartfridge”\n\nBiggest problem right now is that people just forget every single computer science or software engineering principle that exists (we replaced all those overpaid peasants didn’t we after all) and grant full permissions to everything and get their shit rekt\n\nThen of course there is the part it gets expensive because we forgot principles about efficiency too",
                  "score": 3,
                  "created_utc": "2026-02-25 04:15:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78uoal",
          "author": "circusboy",
          "text": "I think it will depend on how you plan to use it.  Is it a neat new tool, yes. will it automatically fix all your pipeline woes? doubt it.  \n\nCan it do cool shit? depends on your imagination i guess.  We got access to it via github copilot extension in VSCode, along with all of the other major players in the LLM space via enterprise license, so we are able to use it carte blanche. \n\nwith that said. i have done a number of things over the last 2 weeks.  \n\n1. Built a form input web app to push data to a snowflake table. hosted by databricks apps.  --i didnt need any other infrastructure which was nice. 1 hour 20 minutes from initial prompt to fully functioning and hosted simple webapp. \n\n2. I have been doing A LOT of heavy lifting in my snowflake DB over the last few months. things like data categorizing, describing, etc all via json within column and table comments.  i was able to analyze a table today that was 3b records with 96 columns. in almost 2 hours. extracted the analysis (which was quite good despite some issues), extract the analysis to a word document report, and a powerpoint executive summary.\n\n3. Another webapp hosted on databricks, that stole the scripting from jsoncrack to display all of the executed query stats and explain plans i have been collecting. connect it to the table in snowflake, display the variant column in the graph area.  i did ZERO coding to get this done, it simply ripped off another site.\n\n4.  Yesterday i vibe coded an executable that i could hare across the greater team to get them setup with all of the tools we are being pushed to use by management. double click the icon and it will scan the machine and install anything missing, from VSCode with the required extensions and python, as well as go to jfrog so that the users can register their tokens to access the pip artifactory. \n\nim also doing standard DDL and DML work from VSCode by prompting what i want now that i have a connector file defined in python.  i just tell claude to login to the snowflake account and drop a table by name. it does it. I was able to restore a dropped table via timetravel as well by specifying the date it was dropped on.  it just writes the .py scripts for me and executes them. it shows me the scripts so i can review then before i allow it to do its thing in terminal. \n\nall of that said.  i can only imagine how much this is costing my company, but they dont seem to give two shits.  so im figuring I would engage in some malicious compliance and get EVERYONE using it to blow up the costs.  i probably used enough water to hydrate a small city over the last couple of weeks though.   \n\n  \nVERY cool tool set to have, but it definitely feels icky to use. \n\n  \n23 yrs xp at a fortune whatever company.",
          "score": 2,
          "created_utc": "2026-02-25 01:15:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79h9zl",
          "author": "MindlessTime",
          "text": "For coding, I’ve been using Cursor. I’ll type up a really detailed Jira ticket or grab an issue from GitHub (the MCPs/connectors/plug-ins/whatever you wanna call them). Then I’ll have it make a plan and refine the plan a lot, making sure it has all the detail. Then I’ll have an agent write the code. It works. When I read through it , I get the nagging feeling it’s not very clean. Like it’s nice the agent can update a reference in six different places in the codebase. But also it shouldn’t have to update something in six different places in the code base. It would be hard to maintain without an AI. Which might be what they are going for.\n\nI still think AI works best when the volume of info in context <= than volume of info coming out. So great for summarizing or translating.",
          "score": 2,
          "created_utc": "2026-02-25 03:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aqdod",
          "author": "theoneandonlypatriot",
          "text": "The people saying it’s mostly hype and shiny tool syndrome are revealing that they have not thoroughly examined this most recent batch of models. \n\nYou need to at a minimum go pay the 20$, and get claude pro, run the curl command to install it in a terminal. Next, create a few agents (it’s not hard). Last, give it a complex challenge ( of reasonable size ) and let it fly",
          "score": 2,
          "created_utc": "2026-02-25 09:19:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o785042",
          "author": "AntVirtual209",
          "text": "Shiny-tool syndrome. There is come convenience to using embedded agents in your IDE like in Cursor, but the essence doesn't change",
          "score": 4,
          "created_utc": "2026-02-24 22:56:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78uskr",
          "author": "hibikir_40k",
          "text": "Something like Claude Code connects the bits you are using the AI in one box, which often makes it faster. You go into planning, chat through the task, the edge cases, it looks at your code, and then you have a set of reasonable steps to get the work done. And then, barring any step you actually think you must do by hand, you just do it. And yes, part of the plan you ask for is the safety steps. Make sure you like the safety steps, and see if there's a risk for them. \n\nForget the whole \"7 agents at once\" bits: You don't need it. But having a coordinator just spawn a separate context that puts on a \"hat\" to check for observability, or that tries to figure out a good safety check to make sure that the numbers line up from the beginning to the end makes it far more effective than a one-shot.\n\nIs your plan good enough? Sure. And I bet it was good enough with no AI whatsoever. But that's not the question: The question is whether you can end up with a workflow that is faster and just as safe. For me there's many tasks where it just speeds things up. A setup where the agents do absolutely everything takes a lot more tooling around everything, and it might not make sense for you: It sure doesn't for me. But the interactive agents level has a very low barrier of entry. It's like your existing chat but it just accomplishes more without going out of control.",
          "score": 2,
          "created_utc": "2026-02-25 01:16:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o783x0o",
          "author": "United-Stress-1343",
          "text": "The problem with the agents and LLMs is that people now can do more things, and it seems like the more things you do, the better you are. When honestly it's not the case at all, but we're sold that idea everywhere (Youtube solopreneurs that hit 20k mrr in a month, Instagram's \"tech influencers\", etc). \n\nI've always stuck to what best fits me and keep adding stuff along the way, as long as it's useful, not just because. ",
          "score": 1,
          "created_utc": "2026-02-24 22:50:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78b4e8",
          "author": "DenselyRanked",
          "text": "I think it's partially hype today, but agentic coding is getting better and AI is quickly moving from assistant to developer. The major hurdles to production-grade development are being worked on at a much faster rate than any of us anticipated.\n\nI use AI as an assistant, but the [Agentic Context Engineering](https://github.com/ace-agent/ace) framework looks very promising. I can see development evolving into context and playbook management very soon. ",
          "score": 1,
          "created_utc": "2026-02-24 23:28:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78dh65",
          "author": "Slggyqo",
          "text": "I’d say I’m getting production grade leverage from it but is not like…absurd stuff. \n\nEg I’m using AI to easily open up a bunch of excel files, read the schema, and output all of that information into a yaml file which is then consumed by software I wrote to build data pipelines. \n\nThe thing is…you don’t need AI to do that. I’m using AI to do it because it’s lower friction than figuring out how and where I’m going to deploy that entire process myself. It’s not like I’m building a new pipeline every day (except right now I am but it’s not BAU time) \n\nBut I’m an analytics engineer with a foot solidly in platform engineering. A full on back engineer might find that trivial to implement without AI. \n\nIt’s useful, it saves the company time and money, and it makes my life easier.",
          "score": 1,
          "created_utc": "2026-02-24 23:41:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78ilb9",
              "author": "Childish_Redditor",
              "text": "Does it save the company money though? In your example, they are paying for however many model calls you make to fulfill a task you could have done without the models assistance. In exchange, you have more time to perform other tasks. Whether this is a good exchange for the company is unclear",
              "score": 2,
              "created_utc": "2026-02-25 00:10:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78oce0",
                  "author": "Moxmox1337",
                  "text": "fully agree and i think alot of companies or departments at least are going to feel some pain as the pricing model for tokens changes in the near future.",
                  "score": 1,
                  "created_utc": "2026-02-25 00:41:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78pd5u",
          "author": "Tall-Wasabi5030",
          "text": "I use agents a lot for exactly that chaining pieces around. I mean, I just use claude code and ask it to do stuff for me, that's the only agent I need. ",
          "score": 1,
          "created_utc": "2026-02-25 00:46:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78siq1",
          "author": "tabdon",
          "text": "Have you tried the OpenAI Codex CLI? \n\nIf not this is a good place to start. [https://github.com/openai/codex](https://github.com/openai/codex)\n\nGet it setup and give it a task in a repo. It is quite powerful.\n\nI think someone taught a course/trained an LLM how to write X/LI post hooks and now we have to live in that world. ",
          "score": 1,
          "created_utc": "2026-02-25 01:03:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78uvgo",
          "author": "varwave",
          "text": "Where I see it being good is less on the dev side and more for businesses. It’s our job to get clean, scalable, timely and reliable data. Designing databases takes critical thinking. SQL queries are already typically automated in software and are simple patterns \n\nPeople aren’t going to get rid of Excel or PowerPoint, but imagine business people can pull data easily and automatically create a near perfect looking spreadsheet or slide deck for a presentation? White collar professionals that flex Excel knowledge that don’t know how to code have been kinda insufferable for decades. This is just basic Python embedded into the application. Like a grown up VBA \n\nClearly the actual database should be the source of truth and developed by actual software engineers. On top of this you don’t need the most powerful models to do this and need far less data. This is a huge edge to Microsoft and Alphabet that own their own application environments. Also why Anthropic (now partnered with Microsoft) is focusing on corporate ties vs chat bots",
          "score": 1,
          "created_utc": "2026-02-25 01:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7960g8",
          "author": "gtepin",
          "text": "Yeah, this hype is calculated and actually part of a marketing strategy to boost sales. Agents are definitely an improvement, I use them a lot and they’ve already saved me some time, but this level of excitement doesn’t really match the reality of the product, at least not yet",
          "score": 1,
          "created_utc": "2026-02-25 02:20:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a3gv8",
          "author": "One-Employment3759",
          "text": "Try using claude code, try use codex.\n\n\nTry the CLIs and the web interfaces that run the agents in the cloud.\n\n\nClaude code in particular works by dispatching work to specialised subagents.\n\n\nThere is definitely hype, but underneath there is something powerful. In the last couple of months the amount of actual code I've written myself has plummeted.",
          "score": 1,
          "created_utc": "2026-02-25 05:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ajdgo",
          "author": "Nielspro",
          "text": "It’s not clear to me if you are using the “agent” mode from copilot? If not, maybe that’s a nice thing to try out.",
          "score": 1,
          "created_utc": "2026-02-25 08:13:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7at949",
          "author": "TeamAlphaBOLD",
          "text": "You’re not missing anything. In serious data engineering, the hard part isn’t writing code, it’s correctness, idempotency, schema changes, and making sure nothing breaks downstream at 3am.  \n\nAgents are great for scaffolding, drafting configs, or generating tests, but they shouldn’t own replay logic or production-critical decisions. The real boost comes from careful Copilot-style use, with humans reviewing diffs and validating backfills. That’s augmentation, not replacement. ",
          "score": 1,
          "created_utc": "2026-02-25 09:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b7m5i",
          "author": "Gullyvuhr",
          "text": "just understand when someone says agent, they mean automation. But since every board is driving \"ai first!\" with no actual strategy, they have to turn shit we already did into the \"AI\" version of itself.",
          "score": 1,
          "created_utc": "2026-02-25 11:51:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7baptz",
          "author": "tomullus",
          "text": "I'm starting to think part of it is that AI let's people brag at/about work. I'd be skeptical of someone being like 'I smashed that pipeline in 2 hours bro I work so fast', but when it's AI it's more acceptable for various reasons.",
          "score": 1,
          "created_utc": "2026-02-25 12:14:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bbbhf",
          "author": "riv3rtrip",
          "text": "AI is useful but the people who brag about running armies of agents aren't possibly working on anything serious. I guess they're prompting like multiple claude code windows with \"what should we do next\" and then it writes the code, submits a PR, a human reviews it. I can see that occasionally having some hits but that's a bit of a silly way to write software.\n\nIn data stuff specifically just make sure that your instructions have instructions on how to access the data and metadata. Not much else to do I believe.",
          "score": 1,
          "created_utc": "2026-02-25 12:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bgvb3",
          "author": "Certain_Leader9946",
          "text": "try claude and zed combo for a first pass",
          "score": 1,
          "created_utc": "2026-02-25 12:55:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bpc8p",
          "author": "LooseLossage",
          "text": "A big unlock comes when you use Claude Code or another agentic loop to not just code, but to write detailed plans and specs, and have good tests so Claude Code can check stuff works. That’s when it starts coding autonomously for 30 minutes at a pop on a complex spec.\n\nif an agent can do not just one prompt but many prompts in a loop with intent, and then you can have many agents, yeah it helps, no shit.\n\npeople are starting to implement complex dev workflows with CI/CD integration, tee up a queue of work in the morning after looking at what agents did overnight, add bug reports and feature requests during the day, at EOD look at what's been done, accept PRs, queue work for overnight.",
          "score": 1,
          "created_utc": "2026-02-25 13:45:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bu4dj",
          "author": "Incanation1",
          "text": "An Agent is a persistent prompt that can self reference. You can train it to be very focused and learn your tastes. I'm training a couple to do tasks like project management documentation and data change documentation. My team talks and thinks and the agent writes. Eventually we'll train an agent to follow and provide recommendations on new technical approaches but not for decisions making or integration. I find them very useful. But I have experience on all these fields so I can \"manage\" it. ",
          "score": 1,
          "created_utc": "2026-02-25 14:11:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bwx14",
          "author": "bengen343",
          "text": "I'm currently engaged in a big dbt rearchitecture. The last time I did one of these LLMs were still in their infancy and I can certainly feel the productivity boost. I'd say I'm moving as fast as my entire team would have on the last project. But a lot of this is making batch changes to the code outputting certain fields, just fancy autocomplete really.\n\nI've yet to be able to ask one of the Anthropic models to produce a dbt model from skratch and get something usable. They do an almost perfect job, but nuance and edgecases abound in data and it just falls apart on those. For example, properly classifying and propogating certain field types. There's nuance in which fields should be classified as identifiers vs. facts vs. dimensions etc. It just can't wrap it's head around this. If the source field is a number it treats it as a metric. Full stop. \n\nI'd love to hear from anyone who has overcome this to actually produce some clean, well-architected pipelines in one or two prompts?",
          "score": 1,
          "created_utc": "2026-02-25 14:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c0n6p",
          "author": "Firm_Bit",
          "text": "It’s very good. One shots medium sized tasks to a pretty good quality standard. It will still require you to check and iterate but it’s very good. \n\nUntil this year I used it mostly the way you are, as a more convenient google and as a sounding board. \n\nYesterday I completed a task in a day that would have taken a week before. Including summarizing a few interconnected services and how they interacted with one another. And then added a new code path. From first time seeing the code in any of the repos to a prototype in 3ish hours. Definitely not perfect but 0 doubt it’s a power tool. \n\nI would definitely spend some time exploring and trying to experiment with it. The upside is huge and worst case you end up with slightly better understanding of when to use it. \n\nFor what it’s worth, it’s sparking conversations around whether or not we need to hire another engineer this year.",
          "score": 1,
          "created_utc": "2026-02-25 14:45:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dbm28",
          "author": "Lingonberry_Feeling",
          "text": "It’s funny how all of a sudden we just started calling markdown files with prompts agents. Agents do sound cooler though.",
          "score": 1,
          "created_utc": "2026-02-25 18:21:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dldy9",
          "author": "RexehBRS",
          "text": "Hate it. Along with the \"here is a 3000 line PR on final day of sprint\" please approve fast.\n\nThe genuine stuff I witness of someone talking nonsense because they haven't understood the tech their using is infuriating and sad.\n\nI'm not against AI development, but hate it in a team where some people put thought into their output and others fire garbage out not consistent with any standards or practices or understanding, burdening others to maintain it when it goes wrong.",
          "score": 1,
          "created_utc": "2026-02-25 19:05:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7drgmy",
          "author": "marymalu_h",
          "text": "We’re building an AI-native data OS, and honestly, the real leverage we see isn’t “autonomous agents replacing engineers.” It’s reducing cognitive load in the boring-but-risky parts:\n\n\t•\tscaffolding pipelines aligned with existing contracts\n\n\t•\thighlighting downstream breakage risks when schemas evolve\n\n\t•\thelping reason about edge cases before deploy\n\n\t•\tautomating documentation without adding README noise",
          "score": 1,
          "created_utc": "2026-02-25 19:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7duyaz",
          "author": "Necessary-Change-414",
          "text": "I use it daily since a couple of weeks. When I refactor things I plan my stuff with ai. I use it as a sane copilot, that scrambled out but I need to check all the things and usually check granularity levels. What I notice is often that I have far more hindrances that I need to tackle what I did in the past, and still need to do that the AI does not think about on the first iteration, like speed, compliance, normalizing stuff for easier maintenance. \nI then make my corrections to the plan, and let them go to work afterwards.\nI like it very much, because it is a nice and necessary exchange and I learn a lot, but I'm sure the AI could learn a lot from me as well 😜",
          "score": 1,
          "created_utc": "2026-02-25 19:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7itgqf",
          "author": "changejkhan",
          "text": "Just build a skill in codex to do your task",
          "score": 1,
          "created_utc": "2026-02-26 14:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7iwhk1",
          "author": "Sufficient_Example30",
          "text": "I will be extremely honest, in software engineering or data engineering. My honest take is LLM generates alot of unnecessary code.  \nSometimes , its just painful and comes out bloated.  \nI actively try not using it,but then again i always try to build smaller efficient pipelines.  \nLike one of them was using shell script , wal2json,awk to process data by streaming it from WAL or kafka if i can get away with it rather than spring,python,spark and stuff  \nIf you are in a big corporate setting agents might be useful.  \nBut in small shops / mid size corpos with 1 or 2 folks per project , i would say use it wisely .Because at 3AM you are gonna end up debugging a 20k line of a codebase",
          "score": 1,
          "created_utc": "2026-02-26 15:05:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7j9ktg",
          "author": "Compilingthings",
          "text": "I use them only to produce datasets, send to the compiler, check over it. That’s the only use case that I’ve found worth it for me so far.",
          "score": 1,
          "created_utc": "2026-02-26 16:06:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78765p",
          "author": "ActionOrganic4617",
          "text": "The industry is in for a rude awakening, I can spin up 6 Opus 4.6 agents and in half a day do what I used to do in a sprint. It’s going to have an impact on headcount’s across the industry.\n\nIf you’re still in denial, it’s not going to help you.",
          "score": -5,
          "created_utc": "2026-02-24 23:07:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78850m",
              "author": "KindTeaching3250",
              "text": "Which part of my post makes you Think I am in denial? I don’t understand some things and don’t see proper use cases and that’s what I am asking about. Will you provide an example of what those agents did?",
              "score": 7,
              "created_utc": "2026-02-24 23:13:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o788y71",
                  "author": "ActionOrganic4617",
                  "text": "Not saying that you’re in denial, it was a broader statement. \n\nI’m using agents to troubleshoot data issues, create pipelines, notebooks etc in parallel. \n\nAt home I use Claude code to ssh into my Proxmox cluster to troubleshoot issues and deploy new containers. \n\nI think data engineering is most at risk because of how proficient AI is at writing python.",
                  "score": -5,
                  "created_utc": "2026-02-24 23:17:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o79tkhf",
          "author": "Fifiiiiish",
          "text": "AI agent is the new extension of AI, allowing to be even more useful. But still, like LLMs, it's just a tool.  \n\nPeople who use it because it exists, or refuse to use it because whatever reason aren't the smartest. You have to know how and why you use it in your environment, to use it or not in an optimal way, and integrated with your process and other tools.\n\nIt requires of course a good evaluation of the tool itself, first by discovering what it can do, then what problems it raises, to finally estimate ROI.\n\nThe question is how do you use them in your process, what activities do you delegate to them, how do you prepare its tasks, what outputs do you check. It will change deeply how we work - what activities we do. And for the moment I've seen nobody using them like that. Even people using agents.\n\nSo yeah, you should see and explore what agents can do. And yeah, people slamming agents everywhere are mostly suffering from shiny tool syndrom. \n\nBut also yeah, AI and agents are a revolution that will deeply impact the SW community. They'll do most of the \"realisation\" steps instead of SW engineers and the valuable skills will change (coding is not valuable anymore).",
          "score": 0,
          "created_utc": "2026-02-25 04:42:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o782pxp",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 0,
          "created_utc": "2026-02-24 22:44:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7832su",
              "author": "bamboo-farm",
              "text": "That’s going to be very hard and impossible to do. \n\nThere will be a lot of pressure from non technical leadership soon.",
              "score": 4,
              "created_utc": "2026-02-24 22:46:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7l2m7f",
          "author": "mipscc",
          "text": "They're just being happy about the new shiny toy.. till they finally get bored, like anything else.",
          "score": 0,
          "created_utc": "2026-02-26 21:09:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pggrw",
          "author": "Mr_Again",
          "text": "Yes you are missing out. Instead of asking reddit, get a $20 Claude subscription and try it out for a month. Be ambitious with what you ask it, put it in plan mode first and iterate on a plan, then let it go. It's going to need serious review but it will do incredible amounts in 5 minutes. Especially because data engineering is not really that complex. I recently wahted to learn Claude + duckdb + rustfs + ducklake + dagster, so I just decided to ask it to set up a sample project using all of the above and in about 20 minutes I had the skeleton which taught me a lot about all the tools. Is it production ready? No. Is it very very helpful, yes. https://github.com/adammarples/testbed",
          "score": 0,
          "created_utc": "2026-02-27 14:35:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdqsaz",
      "title": "My experience with DE Academy’s “job guarantee” program (1-year review)",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rdqsaz/my_experience_with_de_academys_job_guarantee/",
      "author": "Hour-Yesterday-6197",
      "created_utc": "2026-02-24 19:56:29",
      "score": 175,
      "num_comments": 47,
      "upvote_ratio": 0.96,
      "text": "I wanted to share my experience for anyone considering DE Academy’s data engineering program with the job guarantee.\n\nI enrolled in February 2025 under a one-year agreement. The contract stated they would apply to 5–25 jobs per day on my behalf and provide unlimited support (mock interviews, Slack, coaching, etc.).\n\nIn practice, that’s not what I experienced. The daily job applications were inconsistent, and access to some of the “unlimited” support resources wasn’t always available when needed.\n\nI stayed in the program for the full year and remained engaged throughout. By the end of the guarantee period:\n\n* I did not receive a data engineering job offer\n* My refund request under the guarantee was denied\n* I now have a one-year gap in my professional timeline due to participation in the program\n\nBased on my experience, I do not recommend doing business with them. They did not uphold their side of the services and I was not able to get my money back.\n\nHappy to answer questions about my experience.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rdqsaz/my_experience_with_de_academys_job_guarantee/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o772x00",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-24 19:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78qamb",
          "author": "james2441139",
          "text": "The owner of DE academy has less than two years of entry level data engineering experience. It’s well known in the DE community that he is a scam artist. Definitely stay away from such “guaranteed” shenanigans.",
          "score": 99,
          "created_utc": "2026-02-25 00:51:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78yn3u",
              "author": "Trick_Letterhead7770",
              "text": "Never heard of it🤷‍♂️",
              "score": 10,
              "created_utc": "2026-02-25 01:38:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7bgstc",
                  "author": "justin107d",
                  "text": "He has a lot of ads on YT",
                  "score": 4,
                  "created_utc": "2026-02-25 12:55:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o79f8wk",
              "author": "SoggyGrayDuck",
              "text": "If it's the ads I'm getting right now they scared me away with how hard they pushed it. If it was legit you'd see maybe one or two ads placed in good locations like forms, not reddit and social media",
              "score": 7,
              "created_utc": "2026-02-25 03:12:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7f15x6",
              "author": "QianLu",
              "text": "It's always wild to me how many influencers/people selling some type of content have so little experience. Especially if they got in during COVID, they might still be on their first or second job. How can they possibly know enough to speak for what you need for the industry?\n\nAlso any type of guarantee pretty much tells me it's a scam.",
              "score": 4,
              "created_utc": "2026-02-25 23:12:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o77ygbi",
          "author": "MrNoSouls",
          "text": "Sorry to hear this, but that is pretty common with many \"Academies\".",
          "score": 57,
          "created_utc": "2026-02-24 22:23:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7djyhi",
              "author": "Hour-Yesterday-6197",
              "text": "I wish I knew that a year ago",
              "score": 2,
              "created_utc": "2026-02-25 18:59:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o77y6cc",
          "author": "Outside_Reason6707",
          "text": "You literally showed up as a savior to me! I lost job recently and was wondering if I should get in touch with DEA, had a call with sales person but the numbers were just too much and out of my reach. I’m in US",
          "score": 55,
          "created_utc": "2026-02-24 22:22:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79212n",
              "author": "Hour-Yesterday-6197",
              "text": "Glad I could stop you making a mistake and saving whole bunch of money, effort and time. you better off doing on your own. ",
              "score": 15,
              "created_utc": "2026-02-25 01:58:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o781zrd",
          "author": "Ok-Recover977",
          "text": "Yeah if you search this sub you'll see a lot of bad reviews. /u/chrisgarzon19 should be ashamed that this is how he chooses to make a living but he's shameless.\n\n\nHe even has his own separate sub /r/dataengineeracademy with a bunch of positive reviews from bot accounts.",
          "score": 44,
          "created_utc": "2026-02-24 22:41:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79w7iv",
              "author": "kenncann",
              "text": "Amazing how many of his posts are [removed by moderators] of various subs",
              "score": 7,
              "created_utc": "2026-02-25 05:01:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7bnw83",
                  "author": "Hour-Yesterday-6197",
                  "text": "I just crossposted this post in their sub [r/dataengineeracademy](https://www.reddit.com/r/dataengineeracademy/). Lets see if they delete it. ",
                  "score": 6,
                  "created_utc": "2026-02-25 13:37:10",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7a18ve",
              "author": "VipeholmsCola",
              "text": "Thats one of the saddest subs Ive ever seen",
              "score": 2,
              "created_utc": "2026-02-25 05:38:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7a70o6",
          "author": "New-Composer2359",
          "text": "On what grounds did they deny your refund?",
          "score": 9,
          "created_utc": "2026-02-25 06:24:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7blnnz",
              "author": "Hour-Yesterday-6197",
              "text": "They denied my refund based on a technicality in the contract (section 1.2.c), saying I missed the required “weekly progress” updates multiple times, so they claim I’m not eligible for the guarantee.\n\nThe issue is they never told me at the time that I had lost eligibility. They kept applying to jobs on my behalf for months like everything was fine. I only found out I was supposedly “disqualified” after I requested the refund.\n\nInstead of honoring the guarantee, they offered to:\n\n* keep applying to jobs for me for free for a few more months\n* give me their internship module for free to “fill resume gaps” and get more interviews\n\nSo essentially: no refund, just more services, even after a year with no job outcome.",
              "score": 13,
              "created_utc": "2026-02-25 13:24:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7a9wpz",
          "author": "ThroughTheWire",
          "text": "sorry that you got scammed but there are many posts in this subreddit about this place being no good. hope you are able to make it through this",
          "score": 8,
          "created_utc": "2026-02-25 06:48:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a7xwz",
          "author": "thickyherky",
          "text": "sorry to hear that,hopefully you at least learned something new or got better at DE interviews. to be honest if anyone is considering this. your way better off doing a masters or some form of official education in data science or CS or IS and getting a few industry recognized DE certifications",
          "score": 4,
          "created_utc": "2026-02-25 06:31:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aob1t",
              "author": "thisfunnieguy",
              "text": "be careful about wasting a bunch of money on grad school.\n\ni do not see it having much of a return on investment when it comes to salary change.\n\n",
              "score": 2,
              "created_utc": "2026-02-25 09:00:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7acdyn",
          "author": "thisfunnieguy",
          "text": "why did they reject your refund request?",
          "score": 2,
          "created_utc": "2026-02-25 07:10:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bliok",
              "author": "Hour-Yesterday-6197",
              "text": "They denied my refund based on a technicality in the contract (section 1.2.c), saying I missed the required “weekly progress” updates multiple times, so they claim I’m not eligible for the guarantee.\n\nThe issue is they never told me at the time that I had lost eligibility. They kept applying to jobs on my behalf for months like everything was fine. I only found out I was supposedly “disqualified” after I requested the refund.\n\nInstead of honoring the guarantee, they offered to:\n\n* keep applying to jobs for me for free for a few more months\n* give me their internship module for free to “fill resume gaps” and get more interviews\n\nSo essentially: no refund, just more services, even after a year with no job outcome.",
              "score": 2,
              "created_utc": "2026-02-25 13:23:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7d7327",
          "author": "Ok_Record3939",
          "text": "Sorry to hear that, hopefully you will get a job soon, thanks for sharing your experience",
          "score": 2,
          "created_utc": "2026-02-25 18:01:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dj6z0",
              "author": "Hour-Yesterday-6197",
              "text": "Thank you! Situations like this feel especially frustrating because it’s not just about the money, it’s about trust and expectations",
              "score": 1,
              "created_utc": "2026-02-25 18:55:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7f3955",
          "author": "w_savage",
          "text": "well well well, I just talked with one of them on the phone yesterday. I might have been considering it, but I'm not near as desperate as they would have hoped.",
          "score": 2,
          "created_utc": "2026-02-25 23:23:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7giiii",
          "author": "SatisfactionBoth1215",
          "text": "Yes, im program right now, and I started about 6 months ago. I lost my job and all they did was hound me for money. Luckily, I never stopped applying and got a job. I gave them most of my assets but I can recover I just landed high paying tech job. No thanks to them",
          "score": 2,
          "created_utc": "2026-02-26 04:17:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7kk2gw",
              "author": "Hour-Yesterday-6197",
              "text": "Congratulations on landing a new job on YOUR own! It was a smart move. Were you able to get your refund?",
              "score": 1,
              "created_utc": "2026-02-26 19:40:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7mt5sb",
                  "author": "SatisfactionBoth1215",
                  "text": "No, they told me that they will send me over to the retention team. So I got a meeting with them. I think they're going tell me the same thing.",
                  "score": 1,
                  "created_utc": "2026-02-27 02:46:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7j2fa5",
          "author": "CatostraphicSophia",
          "text": "Thanks for this post. I didn't know about this. There are so many scams out there. Some data which reached out to me as well and I'm questioning it's legitimacy.",
          "score": 2,
          "created_utc": "2026-02-26 15:33:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nujjf",
          "author": "MayhemNana",
          "text": "🔥🔥🔥",
          "score": 2,
          "created_utc": "2026-02-27 07:09:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qp1ga",
          "author": "Brilliant-Gur9384",
          "text": "Thank you for both sharing and warning others.\n\nIt sucks, but this ishow I feel about college, except they didn't even try to place us! Also, $80K gone too. It took me a while, but I ended up with a job but left off that I had a degree when I got it, so the piece of paper did nothing.\n\nBut yes, it sucks when people aren't hoest in their products",
          "score": 2,
          "created_utc": "2026-02-27 18:09:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7atz72",
          "author": "Adventurous-Job-2557",
          "text": "I was actually going to make a post about the founder asking if he was a grifter since Facebook has decided to show me their ad’s non-stop 😂",
          "score": 1,
          "created_utc": "2026-02-25 09:53:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cilur",
          "author": "WilhelmB12",
          "text": "Who was it Andreas Kretz or that Zack guy?",
          "score": 1,
          "created_utc": "2026-02-25 16:10:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l0x73",
              "author": "Jonesy-2010",
              "text": "Chris garzon actually.",
              "score": 1,
              "created_utc": "2026-02-26 21:01:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7l62gu",
                  "author": "WilhelmB12",
                  "text": "Never heard of him",
                  "score": 1,
                  "created_utc": "2026-02-26 21:26:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7thzu4",
          "author": "nowens95",
          "text": "Sorry to hear that. I definitely looked into it plenty too. I recommend data engineer zoom camp if you need extra practice! Also I will say in your case if you’re still pursuing, I’d look into something called surfalytics. They mentor and seem to be really cool. Not really an “academy” but depending on where you’re at in your journey they may be able to help!",
          "score": 1,
          "created_utc": "2026-02-28 03:19:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78bocz",
          "author": "IllContribution6707",
          "text": "Did you get any interviews?",
          "score": -2,
          "created_utc": "2026-02-24 23:31:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7928wp",
              "author": "Hour-Yesterday-6197",
              "text": "Yes, I did! But it is not the same as landing a job or we return your money as they promised when sold the course to me. ",
              "score": 7,
              "created_utc": "2026-02-25 01:59:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rg6fjo",
      "title": "Which data quality tool do you use?",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/ucl3p1dve1mg1.png",
      "author": "arimbr",
      "created_utc": "2026-02-27 13:18:37",
      "score": 155,
      "num_comments": 56,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Personal Project Showcase",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rg6fjo/which_data_quality_tool_do_you_use/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7pyazh",
          "author": "SpookyScaryFrouze",
          "text": "I use the one as old as time : users telling me \"something seems wrong\".",
          "score": 196,
          "created_utc": "2026-02-27 16:03:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qdv8k",
              "author": "SupaWillis",
              "text": "And my classic response: “Huh weird, that shouldn’t happen…”",
              "score": 88,
              "created_utc": "2026-02-27 17:16:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7qq2uv",
                  "author": "PantsMicGee",
                  "text": "\"Can you create a ticket? We'll add it to our backlog.\"",
                  "score": 41,
                  "created_utc": "2026-02-27 18:14:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7t4yee",
                  "author": "ToothPickLegs",
                  "text": "“The team will look into it”",
                  "score": 5,
                  "created_utc": "2026-02-28 01:57:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ry4ta",
              "author": "Drkz98",
              "text": "My work it's done, If something is wrong just let me know. No testing, no quality, just feeling",
              "score": 1,
              "created_utc": "2026-02-27 21:51:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qk3zc",
          "author": "OkPrune5871",
          "text": "I just use python to be honest",
          "score": 76,
          "created_utc": "2026-02-27 17:46:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r2hnr",
              "author": "iupuiclubs",
              "text": "Well this gave me a huge sigh of relief.",
              "score": 21,
              "created_utc": "2026-02-27 19:13:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7rof0r",
              "author": "Ltothetm",
              "text": "What’re you implementing?",
              "score": 1,
              "created_utc": "2026-02-27 21:03:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7q07d7",
          "author": "kenfar",
          "text": "I don't use any of them.  \n\nNot that there's necessarily anything wrong, but:\n\n   * They can be expensive, and often have severe limitations.  So, this means that I need to get approval to spend $100k+, which means I need to evaluate a handful of tools, document requirements, etc.  Which means a lot of delay & time spent.\n   * Some capabilities are trivial - and really don't need a product.  Others can be easily built by a single programmer in 1-4 weeks.\n   * Data contracts don't need a product.\n   * MDM doesn't need a product.\n   * Anomaly-detection can benefit from a product, but most of the products had annoying limitations when I looked at them a couple of years ago.  So, I built my own in a month and it worked great.\n   * Data dictionaries can start as a simple google sheet and that can handle their needs for quite some time.\n   * Data-diff tools are great.  There's a ton of open source ones, it's a great data engineer project that only takes a few days to build.\n   \nIn a way engineering can be like a hobby like photography or woodworking:  some people buy a ton of stuff and really don't do much with it.   Others focus on the end results and don't need the shiniest equipment to produce great results.\n\nEDIT: typo",
          "score": 30,
          "created_utc": "2026-02-27 16:12:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qq3gl",
              "author": "thomasutra",
              "text": "what even is a data contract?",
              "score": 5,
              "created_utc": "2026-02-27 18:14:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rrnxd",
                  "author": "kenfar",
                  "text": "So, when I look back at how data warehousing (and data lakes, lakehouses, etc) has evolved over the past 30 years there's a handful of developments that to me personally are extremely exciting.  \n\nData Contracts are one of them. \n\nData Contracts give a team an opportunity to create a specification for a feed - to define its schema in a format that both the publisher and the consumer to automatically use.  Combine that with semantic versioning and now you can have rules about what versions they both support.\n\nCombine this with upstream systems publishing domain objects rather than warehouses replicating upstream database schemas and you have a solution that dramatically improves on common warehouse/lake ETL patterns.",
                  "score": 11,
                  "created_utc": "2026-02-27 21:19:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7qs153",
              "author": "SilentSturm",
              "text": "Do you mind sharing more details on the anomaly-detection product you custom built or any references you could share so I can learn? Currently upgrading the DQ testing process I have at work and would love some guidance! We basically have simple dbt tests on various data models without anomaly detection or volume monitoring.",
              "score": 4,
              "created_utc": "2026-02-27 18:23:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7s164e",
                  "author": "kenfar",
                  "text": "Sure, the problem that we had was that a critical feed going into the warehouse stopped receiving some record types.  So, we were still getting data, just only maybe 25% of the total volume, with some kinds of data completely missing.\n\nWe had some simplistic checks set up to alert us if the data flow stopped completely, but these checks didn't care if the data volume was cut because some record types were stopped completely.\n\nSo, we simply wrote a query to alert us if this happened again:\n\n   * Compare the most recent hour to the same hour of the day-type over the past 60/90 days.  day-types were mon-thur, fri, sat, sun.  So, we had 4 types.\n   * If the current hour's data was more than X stddevs from the mean, write relevant data to the log - which will automatically go out over pagerduty.\n\nThis was very simple, worked great, and from that point forward we were the first to know of any kind of issue in that system.  While it was missing some bells & whistles, the great things about it were that it only took a couple of days to build, and used the same alerting process as the rest of our system.\n\nWe were planning to expand on this - to support checking on distribution frequencies of values within low-cardinality columns, on binned numbers, etc.  But never got around to it.  Looked like a two-week project.\n\nAnd this is obviously the simplest method you could use, and doesn't work great for rapidly growing/declining data.  But it's a great starting point.\n\n\n",
                  "score": 3,
                  "created_utc": "2026-02-27 22:07:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7qcnu4",
              "author": "arimbr",
              "text": "Very interesting, thanks for sharing!  \n1. Indeed, most enterprise plans are priced at $50k-$150k per year. You have Soda and Elementary that have starter plans from $10k per year, but these are limited in the number of users or tables. DataKitchen, DQOps, and Recce are the only ones with public pricing, starting under $10k.  \n2. It was some years ago, but I also ended up building custom UIs for data-diff and MDM. Fast forward to today, and I am still surprised that there are still not so many tools here with a modern UI and open-source. Recce and Datafold sell data-diff. Recce is specific to dbt and partly open-source. The Datafold data-diff OSS project is now archived and forked as reladiff.  \n3. I would think that most teams would be better off adopting or buying an efficient UI/UX for data quality management, rather than building one in-house. Even today that is so easy to vibe code any UI, I thought that the tools here could still provide a best-in-class UX/UI worth the $$$ for most teams.  \n3. For data testing and observability, I think that the UI/UX would be worth the most. Writing tests is easy now that you can prompt an AI to do so, but you still need a UI/UX to consume the test results and act on them. I keep thinking that the moat for data quality tools will end up being the UX/UI, not the library of tests or integrations.\n\nI wonder when data quality becomes commoditized? I mean, when will there be a data quality tool or tools that any data team would want to buy vs build? From what I heard, data quality is still a hard sell.",
              "score": 3,
              "created_utc": "2026-02-27 17:10:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qjbl8",
                  "author": "kenfar",
                  "text": "Testing is not that simple.  \n\nFirst take quality-control tests.  These are tests of the incoming data and how it's handled.  They're best at detecting source data that doesn't meet requirements:\n\n   * Constraint-checks:  validates types, foreign keys, uniqueness, business logic, etc.\n   * Reconciliation-checks:  ensures the end result still matches the source - and you didn't drop/duplicate/mangle data in the process.\n   * Anomaly-detection-checks: looks for data suspiciously different - which could indicate an unknown upstream business rule change, dropped data, etc.\n\nThen quality-assurance tests.  These are tests of the code against synthetic data prior to deployment to confirm that the logic is correct, and can handle known & theoretical cases before shipping.\n   * Unit-tests:  tests of specific cases for numeric overflow, business logic, regex (!), etc.\n   * Integration tests: higher-level tests that ensure that synthetic data will flow from upstream sources, through data pipelines to destination and be correct.  Data Contracts are incredibly valuable to simplify this.\n\nThen there's testing-adjacent stuff:\n\n   * audit-trails:  how many rows did you extract, then transport, then read and write at each step, along with how many rows rejected and for what reasons.  Rather than dump a trillion logging sentences and attempt to derive metrics from them, one can use an actual audit log with structured fields for counts.  And then easily get very reliable numbers.\n   * data-diff tools:  invaluable for code reviews.  These can show in the PR how a proposed change to a complex transform only impacted exactly the columns expected for exactly the rows expected.\n\nThat's a ton to cover.  And along the way deal with scaling & performance, when to use random or rotating sampling & partitioning, when to reprocess, where to avoid duplicate coverage, how to tell what coverage you've got, how to annotate known-bad data, etc, etc, etc.",
                  "score": 9,
                  "created_utc": "2026-02-27 17:42:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7qf4b4",
                  "author": "HenriRourke",
                  "text": "Just seriously curious, why would you want a UI for MDM? Isn't that a practice that you should do rather than observe where you'd need a fancy UI?",
                  "score": 2,
                  "created_utc": "2026-02-27 17:22:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qdxz4",
          "author": "FridayPush",
          "text": "I think most vendors are unnecessary but we actively use Datafold and Elementary(oss) for anomalies. Datafold is pricey but using it in CI has caught multiple issues that pretty strenous testing missed. Being able to diff in-development models against prod tables is really helpful and it's consistently saved me enough time that the business gets it's roi every month. We're refactoring quite a few models and onboarding new datasets that will replace existing ones, so we have to 'stitch' them together and want the same historical values. If you're stable shop that doesn't change a lot it's probably less worth it. \n\nMixed on elementary's tests but having the dbt artifacts pushed back to your warehouse is worth adding the package alone, if you use dbt.",
          "score": 11,
          "created_utc": "2026-02-27 17:16:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qr8hp",
          "author": "Lower_Peril",
          "text": "Microsoft Excel 2016",
          "score": 11,
          "created_utc": "2026-02-27 18:20:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qhruy",
          "author": "Usurper__",
          "text": "Lol, I have never heard of these",
          "score": 16,
          "created_utc": "2026-02-27 17:35:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7tm9ts",
              "author": "Achrus",
              "text": "For real though.  A lot of them look like low code / no code bloat or another flavor of a logging dashboard.\n\nActually I have heard of Monte Carlo.  Just not *The Monte Carlo* that’s just another log dashboard with *maybe* alerting that doesn’t actually do Monte Carlo simulations.",
              "score": 3,
              "created_utc": "2026-02-28 03:47:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qouwy",
          "author": "tzt1324",
          "text": "Data what?",
          "score": 16,
          "created_utc": "2026-02-27 18:08:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r993v",
              "author": "Altruistic-Spend-896",
              "text": "Yeah we rawdoggin that bitch",
              "score": 6,
              "created_utc": "2026-02-27 19:46:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qxl80",
          "author": "CadeOCarimbo",
          "text": "How are they better than Python scripts?",
          "score": 6,
          "created_utc": "2026-02-27 18:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7r5hv1",
          "author": "Advanced_Addition321",
          "text": "Dbt data test",
          "score": 5,
          "created_utc": "2026-02-27 19:28:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s676e",
              "author": "inaynaynay",
              "text": "I’m a DA trying to pivot to AE and currently focusing on dbt. Can dbt test handle all of the data quality needs an organization can have?",
              "score": 1,
              "created_utc": "2026-02-27 22:33:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7s6t3t",
                  "author": "Advanced_Addition321",
                  "text": "If you can write them in SQL, maybe yes",
                  "score": 2,
                  "created_utc": "2026-02-27 22:37:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7tb5b3",
                  "author": "harrytrumanprimate",
                  "text": "lol, data quality is a technical and human problem. Technical problem, it can solve for things that are more schedule and batch oriented. Usually there are tradeoffs between latency and depth of understanding of a problem. For example, you can know event volume in near realtime, but you can't know a unique count. Dbt tests can do the slower, deep understanding type of checks well. It's not great for near-realtime alerting. It's usually best to shift checks as far left as you can, and that can sometimes be before anything is visible to dbt.",
                  "score": 1,
                  "created_utc": "2026-02-28 02:36:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7tvda1",
          "author": "RobotechRicky",
          "text": "I actually created my own \"data test\" and \"data monitoring\" framework using typescript and Playwright with my plug-in for logging results to Azure Log Analytics Workspace.  I then query the results in Grafana along with alerts.",
          "score": 6,
          "created_utc": "2026-02-28 04:51:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qvhew",
          "author": "updated_at",
          "text": "None lol. I build one inhouse (Cloudera btw), using airflow dynamic tasks",
          "score": 4,
          "created_utc": "2026-02-27 18:40:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7upse9",
          "author": "Zeddyorg",
          "text": "Nothing to add other than Atacama is the most awful thing I’ve ever seen. It’s insanely expensive for some 1990s software",
          "score": 4,
          "created_utc": "2026-02-28 09:14:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7uxcov",
              "author": "arimbr",
              "text": "What is the nicer and cheaper alternative there that has the same appeal to enterprises?",
              "score": 0,
              "created_utc": "2026-02-28 10:28:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qr0rl",
          "author": "SutMinSnabel4",
          "text": "I use [https://frictionlessdata.io](https://frictionlessdata.io)",
          "score": 2,
          "created_utc": "2026-02-27 18:19:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qsejl",
          "author": "SilentSturm",
          "text": "I've been following synq.io's guide on testing data products: https://www.synq.io/guide/definitive-guide-to-building-data-products\n\nEssentially it breaks down your data products into layers (sources, transformation, mart) and you run tests on models tailored to the layer. Pretty interesting stuff.",
          "score": 2,
          "created_utc": "2026-02-27 18:25:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rdhe2",
          "author": "poinT92",
          "text": "dataprof",
          "score": 2,
          "created_utc": "2026-02-27 20:07:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rhf2r",
              "author": "arimbr",
              "text": "That looks like a solid and fast data profiling CLI for files. Kudos for building it! Which data profiling metrics does it support? From the screenshots in the GitHub readme I see a few metrics: table-level (total variables, total rows), column-level (count, missing, distinct, uniqueness).",
              "score": 1,
              "created_utc": "2026-02-27 20:27:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rysgu",
          "author": "brittleirony",
          "text": "My company uses Alation's (catalog)DQ tool (relatively new).\n\nThe main reason being it integrates into the catalog so the commercial and merchandising team stop asking us why their report is wrong.",
          "score": 2,
          "created_utc": "2026-02-27 21:54:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0kya",
              "author": "arimbr",
              "text": "Nice to see consolidation between data quality and data governance tools. I noticed a few of the data quality tools listed above implemented a data catalog last year. Good to see data governance tools also implementing data quality features. I see these two categories merging in 2026.",
              "score": 1,
              "created_utc": "2026-02-27 22:04:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qrtux",
          "author": "m1nkeh",
          "text": "DQX ✌️",
          "score": 3,
          "created_utc": "2026-02-27 18:22:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vq7vm",
          "author": "munamadan_reuturns",
          "text": "Is it because I am a beginner or am I just the only one who doesn't get any of this wtf",
          "score": 1,
          "created_utc": "2026-02-28 14:08:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w9vqa",
          "author": "i-slander",
          "text": "what the hell is all of that lol",
          "score": 1,
          "created_utc": "2026-02-28 15:54:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xtni1",
          "author": "tdawgs1983",
          "text": "None",
          "score": 1,
          "created_utc": "2026-02-28 20:37:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xwx8u",
          "author": "TheSchlapper",
          "text": "GX is the only in ours",
          "score": 1,
          "created_utc": "2026-02-28 20:54:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xx70y",
          "author": "ArionnGG",
          "text": "plain python and/or dbt tests",
          "score": 1,
          "created_utc": "2026-02-28 20:56:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7z1h31",
          "author": "mycocomelon",
          "text": " I’ve never heard of any of these. Then again, we run a very small shop with small to medium size data.",
          "score": 1,
          "created_utc": "2026-03-01 00:43:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7zcmvh",
          "author": "hmccoy",
          "text": "“Claude, user said something  doesn’t feel right about this report can you fix?”",
          "score": 1,
          "created_utc": "2026-03-01 01:51:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qwctm",
          "author": "decrementsf",
          "text": "A business model is design for dependency. Installing them in a legacy corporation is what you do for your resume builder to check off the box you implemented thing. Then you leave that company for the job the resume update gets you somewhere else.\n\nIf you want to get things done, right. You learn for fundamentals and run the company you care about on those fundamentals.\n\nThe problem with design for dependency is they become tools for button clickers. The business admin team member who has no business playing in the data science toolkit. Doesn't understand it. Can't check. And the models are limited to how closely they can match conditions for that specific business. But the business admin is locked in. Struggles doing any work outside that vendor ecosystem. Gotcha! Expensive to move your org out of the play toys it just works things. So it goes.",
          "score": 1,
          "created_utc": "2026-02-27 18:44:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdhkua",
      "title": "can someone explain to me why there are so many tools on the market that dont need to exist?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rdhkua/can_someone_explain_to_me_why_there_are_so_many/",
      "author": "Next_Comfortable_619",
      "created_utc": "2026-02-24 14:23:41",
      "score": 134,
      "num_comments": 138,
      "upvote_ratio": 0.75,
      "text": "I’m an old school data guy. 15 years ago, things were simple. you grabbed data from whatever source via c# (files or making api calls) loaded into SQL Server, manipulated the data and you were done.\n\nthis was for both structured and semi structured data. \n\nwhy are there so many f’ing tools on the market that just complicate things?\n\nFivetran, dbt, Airflow, prefact, dagster, airbyte, etc etc. the list goes on.\n\nwtf happened? you dont need any of these tools. \n\nwhen did we start going from the basics to this clusterfuck?\n\ndo people not know how to write basic sql? are they being lazy? are they aware theres a concept of stored procedures, functions, variables, jobs?\n\nmy mind is blown at the absolute horrid state of data engineering. \n\njust f’ing get the data into a data warehouse and manipulate the data sql and you are DONE. christ.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rdhkua/can_someone_explain_to_me_why_there_are_so_many/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o759nzc",
          "author": "Massive_Course1622",
          "text": "First of all, you're right that there is a really large number of competing tools. A lot of them are propped up by VC cash until they sink or swim (and sometimes more VC even after that).\n\n\nBut if you never saw the usefulness of something like Airflow in 15 years it makes me wonder if your scope of work has been smaller - and that's not a bad thing. Have you had to work on an environment with hundreds of jobs, and all the interaction of objects that comes with that? Cron and SSMS or whatever you're used to works, sure, but these tools are a more graceful way to handle them (and save on compute).",
          "score": 178,
          "created_utc": "2026-02-24 15:01:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7651jn",
              "author": "supernumber-1",
              "text": "I think the frustration op is expressing is less about whether they are useful, but that every data engineering related activity now has its own set of tooling. Each with their own terminology, abstraction, and incentives which adds cognitive overhead to what is ultimately a 3 step process, get data -> make it useful -> provide useful data.    Sometimes it can absolutely feel like complexity (accidental or essential) masquerading itself as value.\n\nETLCL made an attempt at solving some of this which might be useful reading for those that feel they are in the same position.\n\n https://pmc.ncbi.nlm.nih.gov/articles/PMC10909202/\n\nEdit: typo",
              "score": 34,
              "created_utc": "2026-02-24 17:24:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o788xxg",
                  "author": "galactictock",
                  "text": "Yeah, every data platform is a UI disaster because of this. AWS and GCP each have proprietary terms out the wazoo and it’s all slapped together with so little organization",
                  "score": 11,
                  "created_utc": "2026-02-24 23:17:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o78w5n0",
              "author": "sib_n",
              "text": "OP was probably relying on the scheduling offered by the SQL Server ecosystem, probably SSIS. It's a UI oriented ETL, so it abstracts a lot of components. Components over which we have more control now since the Hadoop era and then the \"modern data stack\". But this also means more complexity to handle.",
              "score": 8,
              "created_utc": "2026-02-25 01:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o792kmz",
                  "author": "Massive_Course1622",
                  "text": "Yes, I'm familiar with it, because I worked in it too. The scheduling method was SSMS jobs, usually written up in TSQL, which offers basically as much function as cron. I assume he's using cron or something similar for anything else. None of these options can provide the same thing as the tools OP listed. We can pretty safely assume OP doesn't know what ADF is, or he either wouldn't be making this post or would have included it. ",
                  "score": 1,
                  "created_utc": "2026-02-25 02:01:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75b2jb",
          "author": "snarleyWhisper",
          "text": "A lot of these shift the cost from a person to opex and cloud services which makes the books better. A lot of these are about “doing more” with less people, ie shifting the spend to online cloud resources. We also have data lakes and lake houses now , not just DWH.",
          "score": 27,
          "created_utc": "2026-02-24 15:07:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75deeh",
          "author": "Old_Tourist_3774",
          "text": "Your post is quite makes me think you only worked in some very specific data jobs.\n\nSQL is not enough for big data that's why you need spark.\n\nYou need orchestration to define dependencies on jobs so they run in proper ordering and context, hence airflow, dbt, dagster.\n\nSo on so forth.\n\nThe tools exist because they are needed but many fight for the same space and client",
          "score": 58,
          "created_utc": "2026-02-24 15:18:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o768g47",
              "author": "Skullclownlol",
              "text": "> Your post is quite makes me think you only worked in some very specific data jobs.\n\nExactly this. I'm 15YoE, but OP's post gives even me the vibes of \"old man yells at cloud\".\n\nAnd comments like these:\n\n> just f’ing get the data into a data warehouse and manipulate the data sql and you are DONE. christ.\n\nMakes me hope OP is retired or has a stable job, because the job market will not be kind if they haven't progressed with the tech in over 15 years.",
              "score": 31,
              "created_utc": "2026-02-24 17:39:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cc1ih",
                  "author": "molodyets",
                  "text": "Boy wait until he figures out what dbt does",
                  "score": 2,
                  "created_utc": "2026-02-25 15:40:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o75lxx5",
              "author": "imani_TqiynAZU",
              "text": "Good point, the OP didn't even mention orchestration.",
              "score": 5,
              "created_utc": "2026-02-24 15:58:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76db7n",
                  "author": "umognog",
                  "text": "You could do this in SQL with jobs & status tables...but the thing is products like airflow just do it better.\n\nI don't spend labour working on logging, state and so on. I just crack on with the job at hand much quicker.\n\nPersonally, with 4-digit data pipelines in batch & streaming states, Id be in absolute hell without CI/CD and products like airflow, dbt, open lineage, dlt, flink...there is a small list.\n\nYeah, it's a product choice he'll and none of them are perfect, but it's way better than being locked into a DIY product.",
                  "score": 8,
                  "created_utc": "2026-02-24 18:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ajzz4",
              "author": "codek1",
              "text": "Or, as Joe Reis just posted today, the tools exist because of VC funding, and good sales people.\n\nNot all of these tools are needed, and not a lot of them will be around in 2 years. They have got too niche, too specialised, and too expensive for what they deliver.",
              "score": 2,
              "created_utc": "2026-02-25 08:19:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7asx79",
                  "author": "Old_Tourist_3774",
                  "text": ">Not all of these tools are needed\n\nYes, just like I don't need a hammer to weld something, different tasks need different tools.\n\n>They have got too niche, too specialised, and too expensive for what they deliver.\n\nExamples?\n\nSpark is just a fad right? Or perhaps airflow? Dbt? The list goes on.",
                  "score": 0,
                  "created_utc": "2026-02-25 09:43:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7bd5pw",
              "author": "New-Addendum-6209",
              "text": "You rarely *need* Spark. There are SQL-based systems that can scale to huge data volumes.",
              "score": 2,
              "created_utc": "2026-02-25 12:31:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7betye",
                  "author": "Old_Tourist_3774",
                  "text": "Spark and sql are fundamentally different engines or whatever you want to call it and enable horizontal scaling versus vertical scaling that has a hard limit due to hardware.\n\nBig data only become a thing because spark exists.",
                  "score": -1,
                  "created_utc": "2026-02-25 12:42:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o758ze7",
          "author": "gibsonboards",
          "text": "Have you actually used any of these tools? \n\nDbt literally is just sql. Airflow/dagster/prefect are just functions/jobs.",
          "score": 23,
          "created_utc": "2026-02-24 14:57:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o758ugy",
          "author": "jpers36",
          "text": "15 years ago we had:\n\nSQL Server\n\nTeradata\n\nNetezza\n\nSSIS\n\nSSRS\n\nSSAS\n\nAb Initio\n\nDatastage\n\nInformatica\n\nJAMS\n\nPostgreSQL\n\nMySQL\n\nSQLite\n\nMariaDB\n\nCognos\n\nXcelsius\n\nSAP\n\nMicroStrategy\n\nOracle\n\nERWin\n\nPDW\n\nCrystal Reports\n\nS3\n\nEC2\n\nHadoop\n\nHive\n\ncron\n\nAnd on and on ...\n\n",
          "score": 94,
          "created_utc": "2026-02-24 14:57:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75egte",
              "author": "Active_Lemon_8260",
              "text": "What’s your point? Half of that list are just databases.. what OP is getting at is you can use c#/python whatever to go grab data from ANY source database and deliver it to ANY destination. \n\nThese tools on the market seem to remove that functionality and say “you must pick up here and deliver there, on and there’s a massive paywall and contract to use us…”",
              "score": 24,
              "created_utc": "2026-02-24 15:23:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75fh18",
                  "author": "jpers36",
                  "text": "My point is that OP is starting from a vast misunderstanding of the market.  \"15 years ago, things were simple\" is laughable.  It's been this way for a lot longer than SQL Server has existed. Leading with that misunderstanding makes the rest of his analysis worthless.",
                  "score": 53,
                  "created_utc": "2026-02-24 15:28:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ak4me",
                  "author": "codek1",
                  "text": "their point is clearly that tool inflation is nothing new.",
                  "score": 2,
                  "created_utc": "2026-02-25 08:20:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o759769",
          "author": "TheOverzealousEngie",
          "text": "Mostly because old school engineers were arrogant enough to believe what they produced was just perfect. Pristine and Unquestionable. The height of hubris, did those same engies ever stop to ask .. what if a column datatype changed? What if a table was dropped? What if the sync stopped right in the middle of its 20 hour run? Does it HAVE to start from the beginning?  That's nothing to talk about governance : like who can see what. \n\nYou're oversimplifying a complex subject and blaming the market because you can't answer tough questions. It's pure foolishness to blame the market because if these tools weren't needed : capitalism would never allow them to exist. ",
          "score": 77,
          "created_utc": "2026-02-24 14:58:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76l3am",
              "author": "DiabolicallyRandom",
              "text": "OP is oversimplifying, yes, but many in modern DE roles overcomplicate it too.\n\nThe idea that schema evolution is always a thing and always needs to be accounted for isn't accurate, and dbt is not needed for every single transform usecase either.\n\nThe problem is less that these tools exist, and more that those who use them start to use them for literally everything, without exception.\n\nSomething like airflow makes far more sense in a broad use case than something like dbt. It makes sense people would build much of their ETL in a specific toolset. \n\nIt makes less sense to build dbt models and transforms regardless of the specific usecase. Not all data engineering is \"rapidly evolving schemas stored in document stores that have to be flattened for data warehousing\".",
              "score": 17,
              "created_utc": "2026-02-24 18:35:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o75lwj5",
              "author": "AndreasVesalius",
              "text": ">did those same engies ever stop to ask .. what if a column datatype changed? What if a table was dropped? What if the sync stopped right in the middle of its 20 hour run? Does it HAVE to start from the beginning? \n\nNope, not a single engineer thought about those things in ye olde…2011",
              "score": 10,
              "created_utc": "2026-02-24 15:58:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o75m9ep",
              "author": "Online_Matter",
              "text": "A lot of the tooling available is also about be able to change with your requirements. Adding a new field to a table in mssql might be fine but modern tools make sure that your data can change. Same with data lineage, why did this piece of data end up in a wrong state? Modern tools can help you backtrack rather than combing through sql statements.\n\n\nThis is the case in many other aspects of engineering which I believe has been coined as the term evolutionary architecture: You want to be able to evolve your codebase/Pipelines, not just write them once and pray they run on a mainframe for 50 years. ",
              "score": 1,
              "created_utc": "2026-02-24 15:59:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o78lfgw",
              "author": "Environmental-Web584",
              "text": "Could you explain \"capitalism would never allow them to exist.\" ?",
              "score": -2,
              "created_utc": "2026-02-25 00:25:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7d7xoh",
                  "author": "TheOverzealousEngie",
                  "text": "Go read up on natural selection. You’ll see the parallels to capitalism.",
                  "score": 2,
                  "created_utc": "2026-02-25 18:05:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o79xj2g",
                  "author": "Inner_Butterfly1991",
                  "text": "If they weren't valuable, companies wouldn't pay money for them and they'd die. Obviously there are inefficiencies but the fact that all the top successful companies are shifting more towards using more of these tools rather than less shows there's value they're seeing.",
                  "score": 1,
                  "created_utc": "2026-02-25 05:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o758t3i",
          "author": "AlgorithmGuy-",
          "text": "Airflow ? if you don't understand why you can't replace Airflow with basic sql, you have a big problem.",
          "score": 51,
          "created_utc": "2026-02-24 14:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o763jx5",
              "author": "alfred_the_",
              "text": "Yeah idk that they understand what airflow is. Being able to easily set dependencies is a game changer. Doing that with just scheduling cron jobs is hard because you have to build the checks into the different jobs.",
              "score": 4,
              "created_utc": "2026-02-24 17:17:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o770z1k",
                  "author": "RandomSlayerr",
                  "text": "Cant you for example just use SSIS with C# script tasks and SPs  and set the dependencies between them and get the same job done?",
                  "score": 4,
                  "created_utc": "2026-02-24 19:47:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7cp6u0",
                  "author": "jeffhlewis",
                  "text": "You can 100% do orchestration and dependencies with SQL Server, SSIS, and a bit of config code + state tables - we did this back in like 2014 for tons of customers. We even had configurable concurrency with ETL jobs.\n\nI'm not trying to argue that it's the best option in 2026 (Airflow is proven tech) but I feel like most people never got past basic OOTB stuff with SQL Server's ecosystem. It's extremely capable in the right hands.",
                  "score": 2,
                  "created_utc": "2026-02-25 16:40:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7hrtdv",
                  "author": "NoleMercy05",
                  "text": "Wtf. It's not hard. You don't need a GUI. Lol",
                  "score": 1,
                  "created_utc": "2026-02-26 10:45:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o75jwna",
              "author": "amejin",
              "text": "Or they haven't been exposed to problems at that scale.\n\nCheck your tone, champ. Not everyone gets inserted into a place where this is common usage.",
              "score": 8,
              "created_utc": "2026-02-24 15:49:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75s9t8",
                  "author": "Certain_Leader9946",
                  "text": "i disagree. in my whole career, working with some of the largest data providers and data systems in the world. sql and api callbacks have always been enough.\n\ndo they translate and communicate well, not always, but we are far too quick to rush to state machines and dags.\n\ni think its like that graph, just use postgres, no we need abcdef, just use postgres.\n\nhaving went from being a junior, to senior, to lead, to principal. it really do be like that.\n\ndo you need help crunching olap workloads. sometimes. but. thats less often a problem. in truth analytical queries can often wait, nothing says it cant be done in a reasonable time by running the same workload OLTP given a parallel fetch across a b+ tree then doing an idempotent split combine across the cluster (which is honestly a single sql statement in modern transactional databases), and more a problem of disk storage costs v. hyperscalers these days.\n\nand schema evolution is just creating tech rot in organisations everywhere, gets way too out of hand, and i keep getting hired to clean it up.",
                  "score": 6,
                  "created_utc": "2026-02-24 16:26:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75leof",
                  "author": "imani_TqiynAZU",
                  "text": "I concur.  Some folks are fortunate enough to have work environments with simple situations.  ",
                  "score": 4,
                  "created_utc": "2026-02-24 15:55:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76mysa",
                  "author": "turboDividend",
                  "text": "yea, OP sounds like hes worked at banks/insurance companies",
                  "score": 1,
                  "created_utc": "2026-02-24 18:44:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o79xu8w",
                  "author": "Inner_Butterfly1991",
                  "text": "It's fine if your own personal solution doesn't require that complexity because scale is low. But to then complain on reddit about these tools being useless, when the entire point of those tools is for larger scale, is the problem. My last job we used Airflow and had over 2k jobs that ran per day with varying dependencies. The idea that we could \"just use sql\" for that is asinine. Airflow wasn't built for teams with one etl job that runs once/day that takes 5 minutes and you just re-run it if it fails.",
                  "score": 0,
                  "created_utc": "2026-02-25 05:12:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75gsr3",
          "author": "IamAdrummerAMA",
          "text": "What’s so bad about DBT? Shit is glorious!",
          "score": 28,
          "created_utc": "2026-02-24 15:34:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76ofx2",
              "author": "glwillia",
              "text": "was going to say, OP is bitching about how all you need is SQL and then asking what dbt is useful for?",
              "score": 15,
              "created_utc": "2026-02-24 18:50:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7591q4",
          "author": "Reach_Reclaimer",
          "text": "The volume of data has massively increased in just about every facet of life. Different markets need different solutions, competition encourages different solutions, basic SQL doesn't always cut it.\n\nSeems a bit silly to have expected dats engineering to be just a few api calls",
          "score": 9,
          "created_utc": "2026-02-24 14:58:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75zflc",
          "author": "ManufacturerWeird161",
          "text": "I felt the same frustration a few years back until our team hit 20+ data sources and 5 analysts - suddenly our handwritten C# pipelines became a maintenance nightmare. The modern stack isn't about replacing SQL skills but managing scale and collaboration.",
          "score": 5,
          "created_utc": "2026-02-24 16:58:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75j21i",
          "author": "BardoLatinoAmericano",
          "text": "They exist because different people want to make money.",
          "score": 5,
          "created_utc": "2026-02-24 15:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75ln6d",
          "author": "socratic_weeb",
          "text": "Yes, one of the reasons I left data engineering: the tool hell.",
          "score": 4,
          "created_utc": "2026-02-24 15:56:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77jpon",
          "author": "MindlessTime",
          "text": "Ooo ooo ooo! I like this one.\n\nIt’s a mix of business fads, a mini bubble in SaaS, and the natural tendency for SaaS product bloat.\n\nStarting the mid-2000s there were a string of data-centric business fads. “Big data” was the first, followed by “Data Science”, followed by “ML”. Each of these *are* real, legitimate things, but I say “fad” because C-Suite execs didn’t understand them but knew they “had to have them because it’s the future”. This led to wasteful spending but LOTs of company budgets dedicated to data-related tools and teams.\n\nIn the mid-to-late 2010s there was also a mini-bubble among VCs about SaaS companies. My opinion is that there were some embarrassing consumer sector VC-funded busts like WeWork. So VC money pivoted to SaaS. You could also say they were following the dumb easy money that was all those execs throwing money at anything “data” so they can impress their friends.\n\nAround 2020 this started to die down. The market got more competitive. Growth stalled. So a company like Hightouch that built a really good, really specific tool (reverse ETL for non-technical users) started slapping on half-assed features so they can compete on other functionality or create stickiness. (In Hightouch’s case, they invented the concept of “composable CDP” so they could convince execs to keep their product and replace their CDP system.)\n\nSo now the data tool landscape is a data tool hellscape. It’s littered with redundant companies with redundant functionality and nothing is being improved anymore.\n\nI always tell people to at least be familiar with the open source tool set (especially anything from the Apache foundation). They are purpose-focused tools with les bloat. Even if a paid alternative is worthwhile, knowing the open source tools gives you a cleaner landscape of what each tool does and how they work together.",
          "score": 5,
          "created_utc": "2026-02-24 21:14:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o762eaw",
          "author": "Whtroid",
          "text": "Ok there grandpa, let's get you to bed",
          "score": 10,
          "created_utc": "2026-02-24 17:12:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75dop1",
          "author": "DaveMitnick",
          "text": "In large org one team decides to implement scheduling with cron, other team chooses windows task scheduler, someone else tries to write their own python wrapper, you cousin uses stored procedures and so on. As the technical debt accumulates the company decides to create new dedicated platform team that consolidates above approaches and launches airflow platform for everyone. They make sure that it’s easy to use, robust and scalable. It’s their only responsibility. They manage updates, security fixes, platform monitoring, CI/CD blah blah. That’s it.",
          "score": 4,
          "created_utc": "2026-02-24 15:20:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7740bw",
          "author": "peterxsyd",
          "text": "You are 100% right",
          "score": 4,
          "created_utc": "2026-02-24 20:01:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75p8po",
          "author": "Accomplished_Cloud80",
          "text": "I feel like everyone trying to build a tool to make money not to help or ease of our jobs. Especially cloud and software as a service arrived. Everything subscribed and they are way too expensive and people notice this is the way to get rich quickly. \n\nThese days free version and paid version. Some version walk you all the way to the end to make you buy paid version. So Money is the motive.",
          "score": 3,
          "created_utc": "2026-02-24 16:13:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77b3ux",
          "author": "StewieGriffin26",
          "text": "Money",
          "score": 3,
          "created_utc": "2026-02-24 20:34:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79nb3q",
          "author": "chestnutcough",
          "text": "Fivetran answers the question: Why can’t this tedious extract and load code be standardized and made dead simple (for $)\n\ndbt answers the question: Why is it so annoying to keep track of the order I need to run my cascading sql scripts?\n\nAirflow answers the question: how the heck am I gonna wrangle these 100s of cron jobs I’ve created?\n\nDagster and Prefect answer the question: why is it so painful to use Airflow?\n\nAirbyte answers the question: What if we transferred data using json using standard connectors?\n\n*never used Dagster, Prefect, or Airbyte personally.  May have gotten some of that wrong.\n\nI think the reason that the data world has so many tools, is that compared to software development in general, the problem space is minuscule, repetitive, and very rarely a business’s core value proposition.  So it’s very appealing for a company to buy their way into a solution instead of paying software engineers to develop an in-house custom solution.\n\nI bet that equation changes, now that a vaguely technical person can generate simplified, bespoke replacements for these tools in an afternoon.  \n\nMy not-so-hot-take is that tools like Claude code are going to put many of these niche SaaS tools out of business.",
          "score": 3,
          "created_utc": "2026-02-25 04:01:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75baf7",
          "author": "MikeDoesEverything",
          "text": ">why are there so many f’ing tools on the market that just complicate things?\n\nThis is like somebody from the 90s asking why do smartphones exist.  Back then, you could text and call with a great battery life.  Why are phones closer to computers these days?\n\nSimilarly, why is everything online? Why can't we just go back to filling out forms on pieces of paper? Paper doesn't run out of battery or need an internet connection.\n\nHaven't really been in this game that long, although from what I gather it's because data is a lot more complicated now than it was 15 years ago.  So complicated to the point where not everything is one size fits all, thus, you have a lot of tools which do \"the same thing\" except they aren't the same because they might have features others don't and/or fit other use cases better.\n\n>just f’ing get the data into a data warehouse and manipulate the data sql and you are DONE.\n\nSomebody I know has this attitude.  Not quite the same although, in short, they have completely rejected everything about the modern world to the point where they have \"modern tech\" which, ironically, resembles much older tech and struggle participating in society.  Partly due to stubborness, partly due to being a recluse and having nobody around to challenge their worldview.\n\nMy suggestion? It's very unlikely we are going to go backwards, so you may as well get used to it.  Their view point? \"Things should go back to the way I want\".",
          "score": 8,
          "created_utc": "2026-02-24 15:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75a2jx",
          "author": "gsxr",
          "text": "why do so many different cars and trucks exist?  Why are there 17 different types of tomatoes at the store?  Don't get me started on pasta shapes....\n\nBecause people see a niche, and try to fill it.  The project bloom out from there to cover other, overlapping, related areas.\n\nIn reality most of the types of tools(dbt/airflow/fivetran for example) are not chosen on technical merits or fit for purpose, but on what the engineering and manager teams like best.",
          "score": 5,
          "created_utc": "2026-02-24 15:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75ad63",
          "author": "i_hate_budget_tyres",
          "text": "Why are there so many crossover SUV’s?  Like the roads are festooned with them.  They don’t need to exist either!",
          "score": 5,
          "created_utc": "2026-02-24 15:04:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75hlwr",
          "author": "banjo215",
          "text": "https://xkcd.com/927/",
          "score": 5,
          "created_utc": "2026-02-24 15:38:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75xfjs",
              "author": "billionarguments",
              "text": "It's sad that I already know by the number which relevant xkcd that is, without clicking the link",
              "score": 2,
              "created_utc": "2026-02-24 16:49:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75v2cs",
          "author": "zucchini0478",
          "text": "Because headcount is more expensive than software. I went to a Snowflake presentation a few years ago and there were a number of government agencies present. They can't hire developers because they can't pay them the market rate, but they can easily spend millions on software.  In my company there's a push for tools over bespoke solutions coming down from above. The promise is that your less technical staff can now do more. I'm not convinced, but no one's asking me :)",
          "score": 5,
          "created_utc": "2026-02-24 16:39:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75etlo",
          "author": "ScroogeMcDuckFace2",
          "text": "more money to be made in creating a startup / new product than extending existing ones.\n\nhow are you gonna become a bazillionaire tech bro otherwise",
          "score": 2,
          "created_utc": "2026-02-24 15:25:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75j93z",
          "author": "Bach4Ants",
          "text": "Cargo-culting big data tooling from big tech companies that truly need the scalability?",
          "score": 2,
          "created_utc": "2026-02-24 15:46:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76cqor",
          "author": "turboDividend",
          "text": "VC $$ and low interest rates",
          "score": 2,
          "created_utc": "2026-02-24 17:58:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76f04i",
          "author": "Delicious-View-8688",
          "text": "Well, if you can afford it, then Databricks will kinda do it all.",
          "score": 2,
          "created_utc": "2026-02-24 18:09:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76m213",
          "author": "Muted_Bid_8564",
          "text": "I agree with your sentiment. What users here are missing is that the tools today have a large amount of overlap, and people more on theHR side of the industry seem to think you need to know these new tools to work. \n\n\nThe reality is, these tools are mostly wrappers/UIs for things that people have done for a while. Some of them really help you scale, but some older data engineers wrote their pipelines for scalability anyway.\n\n\nThere's a lot of money in the data world, it's attracted a lot of VCs who make more bloatware than useful tools. However, some of these new tools are super useful. ",
          "score": 2,
          "created_utc": "2026-02-24 18:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76mnwx",
          "author": "SoggyGrayDuck",
          "text": "It's insane and dumb. Companies are now looking for people with x years in a handful of different specialized tools. They used to hire for general understanding of the big picture. It's harder to teach the big picture but we're basically in the wild wild West of data where speed makes every decision. It might cost you 10x as much in the long run but we only care about one quarter at a time now",
          "score": 2,
          "created_utc": "2026-02-24 18:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76nek9",
          "author": "Informal_Pace9237",
          "text": "Everyone tries to reinvent the wheel and results in a new tool. How useful? Depends on how well they can market it as lazy proof.\n\nWe had python. Why did we need perl?\nWe had perl. Why did we need php? Why did we need ASP or JSP?\n\nWhy did we need c# or Java/beans etc.",
          "score": 2,
          "created_utc": "2026-02-24 18:46:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76psr3",
          "author": "decrementsf",
          "text": "There is an archived hackernews post somewhere that covers this.\n\nEach year a fresh batch of graduates arrives in tech companies. Each of them were the large fish in their small pond of genius whiz kids with arrogance of having always been the smartest kid in the room through every level of their prior education. They arrive on the job and immediately throw out everything that was done before. Begin reinventing everything from the ground up. Then start running into road blocks. Revisit all the same pitfalls that every prior developer ran into in that seat previously, because each prior developer in that seat was also the smartest kid in the room all the way through. Now that junior associate starts listening and having conversations with the more senior developers and start to understand pitfalls.\n\nThis process explains the wild swings in previously stable services that worked great before. Now seemingly broken.\n\nAlso explains why every few years is a new batch of tools that already existed before.",
          "score": 2,
          "created_utc": "2026-02-24 18:56:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78fb1u",
          "author": "Plane_Bid_6994",
          "text": "I come from a similar place where OP is coming from. I come from a shop where we do everything in Sql server, ssis, sql agent jobs. \n\nEven I wonder why there are so many tools but if these companies are making so much money they must be useful and trying to learn about them. \n\nIt would be great if some of the commenters help my understanding. \n\nWhile I do see the usefulness of something like airflow, I just don't see the usefulness of dbt and fivetran especially given their pricing model.\n\nI have been going through dbt courses and they are so full with so much corporate fluff for such a simple thing. I mean it is a sql parser and linter. Half of the stuff it does your db engine does anyway. And fivetran, granted, it allows you to deliver quickly but their pricing model based on the number of rows just doesn't register with me.\n\nI can see a lot of people talking about handling schema evolution in comments, as per my understanding if, schema changes the context changes as well. While I understand handling those in my staging/ ingestion layer I don't understand why schema changes should be handled through out the pipeline. Please help me what I am missing over here",
          "score": 2,
          "created_utc": "2026-02-24 23:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b5349",
          "author": "soltiamosamita",
          "text": "As a person who rewrote and unified 4 pipelines made by experienced engineers with YoE like yours - using dbt makes it all much, MUCH simpler. Instead of learning how 4 homegrown \"technologies\" work, all you need to know is, indeed, SQL. And how your database works. It *reduces* complexity, not increases it.",
          "score": 2,
          "created_utc": "2026-02-25 11:31:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7k8qc2",
              "author": "GAZ082",
              "text": "boy i need to learn dbt, so much hype in this sub, hope it delivers 😂",
              "score": 1,
              "created_utc": "2026-02-26 18:47:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7s53h1",
          "author": "Lix021",
          "text": "Hi, there are too many tools indeed.\n\nBut the main problem is that people like you don't want to learn python and you consider data ingestion, tabular ML and AI as a second class citizen.",
          "score": 2,
          "created_utc": "2026-02-27 22:27:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75dnj5",
          "author": "asevans48",
          "text": "Airflow is 11 years old today. I would highly encourage brushing up on your skillset if you think its too much. Airflow and its derivatives like dagater power more workflows than any other tool. You could not find a de job 6 year ago.without it. You'll still have trouble today. Dbt + Airflow.is an incredibly.common pattern. In fact. 3 year ago dbt + Airflow + databricks knowledge was necessary. The other tool are icing on the cake. Today feels like you throw in some AI, governance, and infrastructure knowledge on those 3, so maybe a tool like open metadata.  These tools, in comjunction with redshift, snowflake, or big query if you need them, vastly simplify the compex.workflows of 2018. Todays databases even tske care of an enormous cunk of the queueing knowledge of yeateryear. Its really time to cone off of 2011. The messy days of sql server agent and ssis are long gone. Ssrs is a legacy product replaced with power bi ffs.",
          "score": 4,
          "created_utc": "2026-02-24 15:20:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75imtq",
              "author": "reddit_time_waster",
              "text": "SSRS was always garbage. SSIS, I say is still useful like a running pickup truck paid off 15 years ago.",
              "score": 2,
              "created_utc": "2026-02-24 15:43:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75lloi",
                  "author": "imani_TqiynAZU",
                  "text": "As a 20-year SQL Server survivor, I endorse this message.  ",
                  "score": 3,
                  "created_utc": "2026-02-24 15:56:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76hdy6",
                  "author": "asevans48",
                  "text": "If you like maintainint c# and running processes everywhere, sure. Its 100x easier to find a junior engineer skilled in python and create software using best practices in airflow. SSIS shops tend to be a mess where airflow shops trend toward organization and software best practices. Been using both since 2013.",
                  "score": -1,
                  "created_utc": "2026-02-24 18:19:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o76lkkz",
              "author": "DiabolicallyRandom",
              "text": "Airflow, and other orchestration tooling makes sense most of the time, regardless of which is chosen (we use dagster, for instance).\n\ndbt on the other hand, while having its use cases, should not be shoehorned into every single data engineering process - and yet so many are convinced everything should be done in dbt, and just writing SQL should never be done.\n\nThis isn't a product problem but a people problem.\n\nThe over-reliance on tooling by the younger workforce is only going to lower competency and proficiency over time.",
              "score": 0,
              "created_utc": "2026-02-24 18:38:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o771lp1",
                  "author": "RandomSlayerr",
                  "text": "isnt dbt just sql but with quality of life adjustments?",
                  "score": 1,
                  "created_utc": "2026-02-24 19:50:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o758jaq",
          "author": "DisjointedHuntsville",
          "text": "Career-maxxing",
          "score": 2,
          "created_utc": "2026-02-24 14:55:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75xjfd",
          "author": "dadadawe",
          "text": "capitalism\n\nedit after reading the post: \n\nan oldschool, gray bearded data-consultant told me back in 2019-2020, when \"cloudification\" was the buzzword, that in a couple of years we'll see a shift away from cloud\n\nIt probably will never be server-racks in the broom-room again, but the last months I'm seeing more and more questions like yours. I'm probably going to build a (managed, serverless) postgress warehouse for a very small client. It's a cycle and only the useful will remain\n\nI need to buy him a beer if I get the chance...",
          "score": 2,
          "created_utc": "2026-02-24 16:50:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7623kr",
          "author": "reditandfirgetit",
          "text": "Why do things manually when tools exist? Thats not a senior level thought process. \n\nThe *right* tools save time",
          "score": 2,
          "created_utc": "2026-02-24 17:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75tdyc",
          "author": "sahelu",
          "text": "There is a tendency in the data field, as in many other fields, toward increasing abstraction. As systems grow and more components are added, complexity increases. Therefore, we need tools that can manage large amounts of data in a simpler and more efficient way.\n\nI once had a colleague who was reluctant to implement CASE-type BI tools. He even complained to managers about their functionality and potential drawbacks. His foundational experience was in writing SQL scripts within a banking enterprise environment. He preferred to stick with that framework, which was probably effective for him.\n\nMy approach, however, has been to learn new technologies as the field expands and becomes more context-driven. Being an expert in SQL is valuable, but with AI advancing rapidly, it may become harder to compete solely as a SQL specialist. So why focus only on specialization when everything is evolving into a complex network of interconnected systems?\n\nI might be wrong, but I believe generalists are increasingly needed as the field continues to broaden.",
          "score": 1,
          "created_utc": "2026-02-24 16:31:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75x3wg",
              "author": "Lilpoony",
              "text": "This, become T shaped. Go board but go deep in something. With the direction moving towards multiple roles rolled into one, it's worth learning / owning the whole stack so you provide end to end service.\n\nAlso its the path to management as you won't always be managing a team of only engineers, it's usually a mix (analyst, engineers, etc) going board will help you understand their areas as well.",
              "score": 1,
              "created_utc": "2026-02-24 16:48:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76m76y",
          "author": "DonJuanDoja",
          "text": "Probably the cloud. Yea, pretty sure the cloud caused all this. Plus competition. So cloud plus competition equals data tool spaghetti monster.",
          "score": 1,
          "created_utc": "2026-02-24 18:40:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76m8g1",
          "author": "Sufficient-Buy-2270",
          "text": "I interviewed with a data infancy company that was working off spreadsheets. I said I would move everything to GCP to keep it contained there and they rejected me because they wanted to use snowflake as well 🤷‍♂️",
          "score": 1,
          "created_utc": "2026-02-24 18:40:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77bpok",
          "author": "nus07",
          "text": "Again this quote from DDIA - \n\nComputing is pop culture. [...] Pop culture holds a disdain for history. Pop culture is all about identity and feeling like you’re participating. It has nothing to do with cooperation, the past or the future—it’s living in the present. I think the same is true of most people who write code for money. They have no idea where [their culture came from].\n—Alan Kay, in interview with Dr Dobb’s Journal (2012)",
          "score": 1,
          "created_utc": "2026-02-24 20:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77ojw7",
          "author": "kortnor",
          "text": "Startup, venture Capital, bulky MVP that get sold off.\nGreedy dude thinking it can move the world.\nI can go on and on.\nYet, toolings  are merging in one area like etl to only get more tooling in another area like ai and co. At the moment",
          "score": 1,
          "created_utc": "2026-02-24 21:36:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78g0sg",
          "author": "dillanthumous",
          "text": "Long run equilibrium in a competitive market will result in an increase of suppliers until such time as marginal unit costs exceed revenues i.e. Competitors grow until new ones can't survive as the remaining pie is too small.",
          "score": 1,
          "created_utc": "2026-02-24 23:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o791nfj",
          "author": "solo_stooper",
          "text": "Imagine how the person who was working 30 years ago feels lol",
          "score": 1,
          "created_utc": "2026-02-25 01:56:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o791tys",
          "author": "solo_stooper",
          "text": "how long did it take to build a new pipeline?",
          "score": 1,
          "created_utc": "2026-02-25 01:57:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o795pxh",
          "author": "EdwardMitchell",
          "text": "You’ll love BigQuery. Until someone tries to sync a table through updates, one cell at a time.\n\nIt’s still nice to have airflow, DBT, or Dataform to track sub tasks.",
          "score": 1,
          "created_utc": "2026-02-25 02:19:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79jwbh",
          "author": "Much_Pea_1540",
          "text": "I don’t agree with you. Smaller Companies need low code solutions too and they can’t spent 120k USD to hire an engineer to bring the data to sql and maintain the pipelines. \n\nNot telling you are old school, but you are ignoring other parts of the business.",
          "score": 1,
          "created_utc": "2026-02-25 03:40:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79s17s",
          "author": "Euphoric-Battle99",
          "text": "So I recently came to the same conclusion.  Also that they all charge by volume or transaction.. meanwhile I can code these from scratch and host in AWS for a fraction of the cost.  Also now I can have ai help me code them.  I don't really see these expensive platforms surviving now that ai can code it quickly and I can host cheaper",
          "score": 1,
          "created_utc": "2026-02-25 04:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ajv8q",
          "author": "codek1",
          "text": "haha brilliant question, have you seen Joe Reis's latest article? ",
          "score": 1,
          "created_utc": "2026-02-25 08:18:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dutvy",
          "author": "marymalu_h",
          "text": "Will you be using a platform that builds pipelines and provides real-time analytics?)",
          "score": 1,
          "created_utc": "2026-02-25 19:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7q6ndb",
          "author": "GardenShedster",
          "text": "Plus there's all the platforms now. Databricks, Fabric, Snowflake etc.",
          "score": 1,
          "created_utc": "2026-02-27 16:42:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ryj0n",
          "author": "Mountain-Crow-5345",
          "text": "20+ years in data experience here. Agree with codek1 and others that VC money created a Cambrian explosion of tools. SQL is great for some problems and not so good for others.\n\nGood for SQL:\n\nWe have used the FITT pattern for years: Functional, Idempotent, Tested, Two-stage. Raw data is immutable, every transformation is a pure function (same input always produces the same output), and dev runs today's code against yesterday's data while production runs yesterday's code against today's data. You never push untested code to production and you can reproduce any result from any point in time. https://datakitchen.io/fitt-data-architecture/.\n\nData tests. Null checks and row counts are not enough. You need tests covering distribution shifts, referential integrity, and business checks before problems reach downstream users. Most data teams write too few of them.\n\nA few things go beyond SQL:\n\nOrchestration and pipeline dependencies. When dozens (or thousands) of jobs are interdependent, cron is not enough. You need orchestration that tracks dependencies, retries intelligently, and runs tests inline so you can stop bad data from reaching customers.\n\nSource schema changes. You need monitoring that catches this so they don't break pipelines.\n\nData freshness. A pipeline that ran successfully on stale data is still a broken pipeline.\n\nThe tools that solve these real problems are worth having. The ones built to maximize vendor revenue are not.",
          "score": 1,
          "created_utc": "2026-02-27 21:53:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ubmwo",
          "author": "EtherPersonified",
          "text": "I can appreciate the thrust of this argument, simplicity is a good thing.  People learn this same lesson across disciplines (Having written a good bit of Clojure at earlier jobs, [this book](https://www.manning.com/books/grokking-simplicity) really confirmed my subjective experiences).\n\nThat said, which of the tools make your life easier?  I think most people agree dbt, Airflow, and maybe also Astronomer, make life easier.  And I agree too.\n\nIs the cognitive burden too high to learn using these tools before they become useful?  I didn't think so.  The learning curve wasn't steep, and maintainability wasn't *more* burdensome.  Airflow has a docker file that you can run locally and get a hang of.\n\nSome of what's available today sucks, let some shit sink while the winners prevail.  Who cares really as long as you don't work for management hellbent on specific tools.  Yeah, sometimes companies buy a tool and are amendment it's used: to me this used to mean something from Oracle but today is more often agentic bullshit (hello Block!).\n\nAlso, old tools sometimes really do need to be superseded by newer ones.  I worked on replacing an expensive Talend (pre-QLlik acquisition) pipeline with Apache Nifi and came to realization that a many popular Apache projects were built to satisfy frustrations with existing products that we're steered from \"customer priorities\" to \"business priorities.\"  Such is the management class.\n\nThat said new tools do find new ways for people to abuse in novel, **incredibly novel,** ways.  This is legitimate complaint.  I worked on re-shoring a project from ${WELL\\_KNOWN\\_OFFSHORING\\_COMPANY} that had nightly Spark jobs that ran for over 24 hours.  This was the textbook issue of not using rollups and reprocessing an entire dataset.  The number of anti-patterns involved we're astounding; six tables were used for just storing SQL as text *in the fucking tables*, every other table had dozens of columns name \"places\\_holder\\_#\" because they didn't know about schema evolution.  These we're third-rate java devs, asked to write Scala, and learn SQL *and* Spark.  Truly a human way to absolutely fuck up that no AI will surely ever replicate.\n\nWe'll probably relearn these lessons with ChatGPT and the like thoug.  People are vibe coding some dogshit pipeline right now that will take four years to run per job, kicks off daily, and every job sends a seven digit check to Jeff Bozos.   \n  \nSo maybe there's something to be said for being skeptical of new things.  The burden of learning and vetting everything new is really high today.  I liked having DuckDB to explore data over Presto personally - and now there's Trino?  Is it different, does it improve on my experience with Presto (i.e. running a query against a Kafka topic?).  IDK man, pray younger folks can help sort out the chaff.",
          "score": 1,
          "created_utc": "2026-02-28 07:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75cq95",
          "author": "SBolo",
          "text": ">just f’ing get the data into a data warehouse and manipulate the data sql and you are DONE. christ.\n\nThis take is so hilarious it doesn't even deserve to be commented.",
          "score": 1,
          "created_utc": "2026-02-24 15:15:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75lui0",
              "author": "imani_TqiynAZU",
              "text": "Almost spat out my imaginary coffee on this one!",
              "score": 1,
              "created_utc": "2026-02-24 15:57:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76g7u9",
          "author": "Compilingthings",
          "text": "Because you have people like me who can’t even really use a computer, but is above average with using AI producing engineered datasets for fine tuning, using agents with compilers in the loop. Although I am thinking about learning python just to understand what’s going on. It’s amazing what you can get done with AI and a little grind these days.",
          "score": -1,
          "created_utc": "2026-02-24 18:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75dgsb",
          "author": "confusing-world",
          "text": "Hi, I’m a beginner in the data field, and I’m a bit curious about how you would approach the following scenario without using specialized those tools:\n\nYou need to retrieve documents from three different MongoDB collections, extract report metrics from them, insert the results into another database, and display them to users on a dashboard. Additionally, the reports need to be updated periodically.",
          "score": 0,
          "created_utc": "2026-02-24 15:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76ncfr",
              "author": "DiabolicallyRandom",
              "text": "You describe a good usecase for tools. I disagree with OP's absolutist take.\n\nHowever, your scenario paints a picture of why I think so many younger DE's are convinced this tooling is always needed.\n\nNot everything is a NoSQL database collection. Not everything is a document with rapidly changing schema evolution. Yes, that can be super common in some places and spaces.\n\nBut take healthcare in the US for instance - rapidly changing schemas for data is *not* a normal thing. Schema evolution is slow and methodical, on the order of decades, not years. We use identical data format standards for decades before we upgrade to a new version.\n\nIt's not that the newer tools and libraries are bad. It's that they are overused, over-pushed, and over-relied-upon.\n\nMany have their place (dbt makes sense where its needed), jumping on to the latest new hotness is always a bad idea (dbt has been around for awhile, other new competitors have not, and so switching because its new and shiny is bad), but sometimes those tools are just not needed, and overly complicate otherwise simple workflows.\n\nUsing a single platform for orchestration is good, and OP's comments about airflow are pretty weird, but at the same time, if you are using airflow for just a few things, while having everything else elsewhere, it doesn't make sense to force airflow, you know?\n\nFull disclosure here: I have been in the business 18 years, I started out building raw ETL's in SQL, moved on to using mostly Talend, then started building out back end realtime processes in Java, and recently was laid off and am now using dagster + python for everything at the new job.\n\nWe don't force dbt where it doesn't make sense, and we don't insert libraries just because. But we DO use those things where it makes sense.\n\nOP is off in their position, but the opposite is not also true either.",
              "score": 3,
              "created_utc": "2026-02-24 18:45:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77r3vg",
                  "author": "confusing-world",
                  "text": "Thanks for the reply. You have talent to explain things, have you ever thought about writing a blog?",
                  "score": 1,
                  "created_utc": "2026-02-24 21:48:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75esah",
          "author": "Thinker_Assignment",
          "text": "is this really about tools, or your post history?",
          "score": 0,
          "created_utc": "2026-02-24 15:25:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76hp8l",
              "author": "GreyHairedDWGuy",
              "text": "his posts do cover a variety of topics :)",
              "score": 2,
              "created_utc": "2026-02-24 18:20:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75fogf",
          "author": "bamboo-farm",
          "text": "I stopped reading at I’m an old school data guy. \n\nHoly cow. \n\nData is one of the fastest changing fields. \n\nMy job has literally changed every 2 years. \n\nThere are many still working in bigger orgs doing things that should have been eliminated years ago. \n\nThey likely will. \n\nThen all of them will have the same posts. \n\nHonestly ngmi. \n\nGood luck.",
          "score": 0,
          "created_utc": "2026-02-24 15:29:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m6uo",
              "author": "imani_TqiynAZU",
              "text": "I wouldn't be surprised if OP worked in a government role of some sort.  ",
              "score": 3,
              "created_utc": "2026-02-24 15:59:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75hu09",
          "author": "Nekobul",
          "text": "Two factors:\n\n\\* Hundreds of different web applications and their different APIs that take tons of time to create and maintain.  \n\\* Big chunk of \"easy money\" from VCs to throw around and hope something sticks.\n\nThe approach you have used might make sense if you have to deal with 1-2 APIs. For more, it is simply not a wise approach.",
          "score": 0,
          "created_utc": "2026-02-24 15:39:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75yxhv",
          "author": "fckrdota2",
          "text": "BTW just imagine using old school methods in a columnar dwh",
          "score": 0,
          "created_utc": "2026-02-24 16:56:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hsgi9",
              "author": "NoleMercy05",
              "text": "Columnar dwh is old school though. Or do you think that is a new thing?",
              "score": 1,
              "created_utc": "2026-02-26 10:51:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7hv1m0",
                  "author": "fckrdota2",
                  "text": "Nah I was thinking of something imaginary",
                  "score": 1,
                  "created_utc": "2026-02-26 11:14:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76og18",
          "author": "defnotjec",
          "text": "A tool exists because it solves a problem or set of problems to some degree that it's value is offloading the task to the tool \n\nIt's no different than a hammer and a wrench. Both could work reasonably well at blunt force... Ones definitely better at a specific size nut",
          "score": 0,
          "created_utc": "2026-02-24 18:50:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77hscn",
          "author": "Klutzy_Phone",
          "text": "Went from a job that was using dagster to a job where they're buikding a dwh with stored procedures and doing basically no orchestration. \n\n\nI'm happily uninvolved",
          "score": 0,
          "created_utc": "2026-02-24 21:05:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78o43f",
          "author": "Tall-Wasabi5030",
          "text": "Software is all about evolution and keeping up. I'm managing 6 petabytes of data across 80 datasets, how exactly would you do that without proper tools? ",
          "score": 0,
          "created_utc": "2026-02-25 00:40:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fifff",
          "author": "Hot_Map_7868",
          "text": "in your way of doing things:  \n1. Did you just have one db e.g. prod?   \n2. How did you handle testing and deployment, was it automated?  \n3. How did you isolate one developer's changes from another (so one isnt impacting the other)?  \n4. How did you do Data Quality checks?  \n5. How did you do unit tests? (if you did them)  \n6. How long did it take you to create a script to load data if MS didnt have a connector for the source?  \n7. How did you do code reviews?  \n8. Did you let advanced business users use the same tools  and processes?  \n9. How did you do impact analysis?  \n10. How did you build in conventions / guardrails so it was simpler to debug issues.  \n  \nI am not suggesting there aren't a lot of tools, but if you try dbt as an example, you will realize what it is solving for and you might change your mind :)  ",
          "score": 0,
          "created_utc": "2026-02-26 00:46:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hsnea",
              "author": "NoleMercy05",
              "text": "None of what you listed is new or difficult.",
              "score": 1,
              "created_utc": "2026-02-26 10:53:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7i5ow5",
                  "author": "Hot_Map_7868",
                  "text": "Indeed it is not new. Please describe your solution. Just doing code review on gui tools is not fun.",
                  "score": 1,
                  "created_utc": "2026-02-26 12:35:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75q5jp",
          "author": "Witty_Tough_3180",
          "text": "Is this satire? Stored procedures are the sign of a failing data project",
          "score": -2,
          "created_utc": "2026-02-24 16:17:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75oczk",
          "author": "Apprehensive-Ad-80",
          "text": "Someone's Pa'Paw got a hold or reddit\n\nI'm still fairly new to the DE world but have spent 15 years in BI and analytics.. while I consider myself very solid in SQL it's pretty clear to me why there's more tools than before. Yes some only add small incremental value and are mostly duplicative of others but most of those will either fail or get bought by a bigger player, the rest have very strong use cases and make work much more efficient. Data today is MUCH larger and from way more sources than yesteryear, AI is a thing now, ERPs and billing systems have evolved from green screens, CPG companies serve direct to consumer and B2B channels with greater scale and efficiency than ever... sure you can race the Indy 500 in a Camry, but you sure a hell ain't gonna win it",
          "score": -1,
          "created_utc": "2026-02-24 16:09:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76ucx7",
          "author": "BrownBearPDX",
          "text": "15 years ago, data wasn’t what data is today, not even close. 15 years ago you could just reach out and grab a batch from some API and pull it over and do what you need to and stick it in the database. That was that. Now we’re dealing with terabytes per hour of streaming data which needs to be \nCleansed, split for analytics, AI, warehousing, functional apps, real time and long term reporting, analytics and analysis of all types in all departments, merged, validated obfuscated, and everything else before it lands anywhere, deal with the exceptions in the in-house and cloud based orchestrations, deal with decision-making on exceptions and individual data messages, waiting for breakages in the data layers of third parties and little outfits and enormous data pumping engines which change their API’s every couple months without warning and we are also dealing with demands on the data from so many different sources that want to look at the data and totally different levels of authorization.\n\nWe have thousands of tables, we have transformations running constantly competing for resources and waiting for other dependencies while the CEO is waiting for his damn iPad report on how much money he just made and complaining about how slow everything is.\n\nEvery day there’s new demands on the old pipelines and for new pipelines to be created. This is not just data that lives at rest after it’s been dealt with and it’s easy to use C sharp to write some scripts that live on a mile, thick infrastructure and it’s 15 years ago. Have you not dealt with the real dating engineering problems that require real  modularized components that serve mini masters and our enterprise class and pluggable?  These tools have specialized and singular strengths because of volumes we’re dealing with and the problems we’re dealing with require such specialized pieces of software.\n\nI’m all for keeping things simple and never overbuilding, so if your problems don’t require all these tools that we’re using for other issues, orchestration, storage, and transformation, don’t use them. It’s best to use what you’re comfortable with and what works for you. Don’t get all angry at the tools that are out there and use them because you feel you have to, just use what you need. Duh.",
          "score": -1,
          "created_utc": "2026-02-24 19:17:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76pbdh",
          "author": "num2005",
          "text": "writing sql is cancer compared to a tool like Matillion, sql in itselves is a cancer language by being forced to alwats repeat the column name anyway\n\nespecially for readability and even more if you have a to share your work with you colleague, and those tools even have seamlest integration built it to query other software, like salesforce or jira or s3 bucket.  also orchestrating stuff?! \n\n\nhonestly, it seems like you are working in a small shop 1 man guy that dont need a datavault and bit integration or process or different datamart, etc",
          "score": -6,
          "created_utc": "2026-02-24 18:54:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbk3ov",
      "title": "New CTO has joined and is ignoring me",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rbk3ov/new_cto_has_joined_and_is_ignoring_me/",
      "author": "anxiouscrimp",
      "created_utc": "2026-02-22 12:00:41",
      "score": 133,
      "num_comments": 89,
      "upvote_ratio": 0.92,
      "text": "Keen for any thoughts or feedback.\n\nBackground - I’ve worked at my current employer, a mid-sized luxury retailer. We turn over about £200m annually. I’m the sole BI architect and have been for the last 5 years or so. I’ve been with the company for 11 years. I do everything - requirements, building out the data warehouse, building and maintaining the cubes, some SSRS development. In the last two years I’ve designed and built a new ELT framework for us to move away from SSIS and integrate to all of our various disparate systems - ERP, CRM, GA4, digital marketing platforms etc etc. Then I’ve cleaned all of this data, modelled it and built a PBI semantic model on top to bring everything together. That’s the first (and biggest) phase of replacing our existing estate.\n\nChallenge - I had a very good relationship with our previous CTO. Now a new CTO (a contractor) has joined and he seems to be completely ignoring me. We’ve barely had any interaction. He’s worked with GCP in the past and immediately has set up meetings with a google partner. In the first meeting they opened with ‘so we understand that you’ve got a very fractured data estate with no single source of truth’ which is just totally untrue. But this CTO seems to have no interest in engaging with me in the slightest and I’m hearing from other people that he just wants to ‘move us to bigquery’. We’re entirely on Microsoft for everything - not just BI - so this is an enormous piece of work without a clear benefit. In my opinion the issues we have are generally people based - not enough people and certainly not enough people translating data into something actionable or understandable. I’m open to the idea of moving some or part of our estate to GCP - but shouldn’t such a large move like this be considered in the context of ‘what problem are we trying to solve?’\n\nI’m feeling pretty upset - I’ve given a lot to this company over the years and this behaviour feels disrespectful and weird. I’m keen to hear from anyone if they’ve seen this behaviour in the past and how to approach it. At the moment my plan is to write a document outlining our current data estate for him to read and then talk him through. Obviously I’ll also update my CV.\n\nTLDR: new contract CTO has joined and is ignoring and sidelining me. He seems very intent on moving us to GCP despite not really understanding any of our actual challenges. Why is he doing this? Is this a strategy?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rbk3ov/new_cto_has_joined_and_is_ignoring_me/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6rfma8",
          "author": "ThroughTheWire",
          "text": "contract cto is already a yellow/red flag\n\nbeing ignored entirely is a red flag.\n\ncto trying to make sweeping architectural changes within weeks of joining without understanding the context is a red flag.\n\ni think you can see already that there isn't much hope in this situation which is why you're gonna update your resume. I wouldn't waste my time too much trying to make their life any easier if they've already been ignoring you this much so far - they're just gonna ignore whatever output you give them. why waste your energy that could be spent on literally anything else?",
          "score": 260,
          "created_utc": "2026-02-22 12:32:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ujo6s",
              "author": "dknconsultau",
              "text": "Sage advice. The winds of change can not be stopped. The only upside is to do the GCP project get the experience and certs then leave. ",
              "score": 25,
              "created_utc": "2026-02-22 21:58:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rffvm",
          "author": "financialthrowaw2020",
          "text": "If the CTO intends and succeeds to migrate to Google it'll take a long time and you'll have a job at least for that duration of time. Use that time to start looking for work. The CTO has come into this job thinking you are the problem. Not much you can do about this, I'm sorry it's happening. Usually, when migrations to new stacks occur, they focus on hiring experts in that stack, which is why he's writing you off early.",
          "score": 150,
          "created_utc": "2026-02-22 12:31:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rg088",
              "author": "anxiouscrimp",
              "text": "Yeah this is exactly my thoughts/fear!",
              "score": 36,
              "created_utc": "2026-02-22 12:35:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6va0z7",
                  "author": "chock-a-block",
                  "text": "Don’t burn daylight. Update the resume and burn every hour of PTO before GTFO. \n\nDo not look back. Do not put any effort for the transition. If the CTO is that unskilled, they made their bed. ",
                  "score": 22,
                  "created_utc": "2026-02-23 00:23:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6remoj",
          "author": "kitsunde",
          "text": "Reading your post at face value, it’s pretty common for C-level executives to show up on the back of whatever he’s heard interviewing (data issues, we need to leverage data more, it’s hard to get a data picture bla bla) and get frustrated in an unfamiliar situation. Second system syndrome is incredibly common at all levels.\n\nYou can try to document everything, and particularly provide metrics around how things are running to make a case that it’s actually in hand. I would assume there’s a deeper issue with data access that you aren’t fully informed about, so you might not even know what you’re arguing against.\n\nUltimately these decisions are completely out of your hands, a C-level executive that’s recently hired has absolute authority to start changing things entirely by opinion. It’s going to take several quarters for wrong decisions impact to be felt to the point of them being blamed for them.\n\nIf your new CTO doesn’t buy what you’re selling, and you’re not willing to go along for the ride with an open heart, absolutely look for the quickest exit.\n\nI say all this as the C-level executive. It’s also very possible the new CTO is seeing/know something you don’t, and what you’re reacting to is the first step in a long term plan that they themselves can’t clearly articulate because they are new.\n\nIf you do stay on, you should try to build a new relationship and pull in the same direction for the next year before passing judgement. Good luck!",
          "score": 50,
          "created_utc": "2026-02-22 12:24:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rfgmv",
              "author": "anxiouscrimp",
              "text": "Thanks for the reply! Yeah I do think we’ve got an issue with data being translated/available to the highest levels and I expect that’s what he’s been told. I’m just not sure why his solution is to go full speed onto a technical answer when he doesn’t understand the underlying problems. I’ll try and be open-minded and challenge the points empirically - and just scream into a pillow privately.",
              "score": 10,
              "created_utc": "2026-02-22 12:31:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6tp0q8",
                  "author": "RyanTheTourist",
                  "text": "Let's consider the other C-Suite members, are they able to draw insights from what is available to them? It NOT would surprise me if part of the issue is their inability to infer what actions to take when looking at the available metrics and viz.\nIf this is the case do you have capacity to make a \"given we observe a,b,c - options x,y,z are worth considering\" - reposition yourself from technical resource to strategic partner.\n\nBut also start working on your next step, the well may already be poisoned against you. I'm sorry it sucks, been there and in time better things do come along\n\n(edited - missed the NOT)",
                  "score": 6,
                  "created_utc": "2026-02-22 19:23:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6wloel",
                  "author": "thatguydr",
                  "text": "Don't do that. Don't challenge anything.\n\nThey hired him *because he said he could fix the problem they perceived.* The problem isn't him - it's the people you've been working for.\n\nYour clout is mostly gone. Just polish the resume and wait to be let go. Sorry about that.",
                  "score": 5,
                  "created_utc": "2026-02-23 05:30:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sge4r",
              "author": "randrews1886",
              "text": "I can clearly see this with our new head of. My issue is with comms. They seem so scattered and uninformative. I would have thought recruiting someone at that level would mean their comm skills would have to be good. Saying they can't articulate because they are new seems very poor to me",
              "score": 2,
              "created_utc": "2026-02-22 15:59:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6slgao",
                  "author": "kitsunde",
                  "text": "I suppose, but you don’t really get hired on how you communicate with your reports. You get hired by how you communicate with your peers and the boss. Some people are also really brilliant on a narrow part of the job, and it makes up for the parts they aren’t good at.\n\nIf your boss is unclear and scattered, they might need some help and it can be a great opportunity for you to feed them whatever direction you want. Turn a problem into an advantage if you can, that’s what I do.",
                  "score": 3,
                  "created_utc": "2026-02-22 16:21:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7jafhm",
              "author": "thisfunnieguy",
              "text": "How much power to change things do you think a CTO that’s on a contract has?\n\nThis person is a short timer.",
              "score": 1,
              "created_utc": "2026-02-26 16:10:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rcl48",
          "author": "reditcyclist",
          "text": "We had this with a contract CTO who could talk the talk but.... Anyway it took a good 18mths for the CEO to get rid. If you have other contacts in C suite keep those active and open.",
          "score": 81,
          "created_utc": "2026-02-22 12:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rfhc0",
          "author": "codykonior",
          "text": "Ride it out. Contract C suite don't last long. He's just playing the game spreading butter on the toast until his time is up. Nod, smile, and you'll outlast, and likely absolutely nothing will change.",
          "score": 24,
          "created_utc": "2026-02-22 12:31:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sfhax",
          "author": "reviverevival",
          "text": "I feel like every time a new CTO comes in they have to change things for the sake of changing things in order to justify their own position.",
          "score": 23,
          "created_utc": "2026-02-22 15:55:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t6x1z",
              "author": "One-Employment3759",
              "text": "These kind of CTOs are either incredibly insecure or just idiots.",
              "score": 9,
              "created_utc": "2026-02-22 17:59:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ts8ip",
                  "author": "MrLyttleG",
                  "text": "Les deux !",
                  "score": 4,
                  "created_utc": "2026-02-22 19:39:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6tyscx",
                  "author": "fueltank34",
                  "text": "Or they only know how to do things one way. Which puts them in the idiot category. 😅",
                  "score": 3,
                  "created_utc": "2026-02-22 20:12:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6t7kin",
              "author": "WallyMetropolis",
              "text": "If the org makes a leadership change, it means they've decided they want to change things. A new CTO who doesn't make any changes is pointless. ",
              "score": 6,
              "created_utc": "2026-02-22 18:02:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v34cp",
                  "author": "One-Employment3759",
                  "text": "There are many changes you can make while actually first understanding the context of the business and the existing systems. If you don't understand that and just make changes without context, that is madness.",
                  "score": 1,
                  "created_utc": "2026-02-22 23:44:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6vsmgr",
              "author": "my-sweet-fracture",
              "text": "A tale as old as time",
              "score": 1,
              "created_utc": "2026-02-23 02:14:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6s97t6",
          "author": "Hulainn",
          "text": "I have seen this before.  My advice - if the CTO won't talk to you, you are cooked.  I am sorry to say it, but he is already planning to get rid of you, otherwise your input would be valued.  Don't assume that a long tenure of good work, or good relationships elsewhere in the company, will save you - if your reporting line is against you, it's over (unless you can move laterally within the org, but you would likely have to substantially change roles to get out from under the CTO.)  Your performance reviews are about to get worse as well, due to downward pressure to push you out.  They do not have to be fair, and defiance is pointless - if the CTO wants it, a \"case\" will be built for removing you, even if it takes months or years.\n\nThe safest bet is to update your resume and reach out to contacts you trust.  Presumably you have those, from former coworkers happy with what you accomplished.  It is far easier to change your environment than to change the nature of a CTO who is not interested in engaging with you on goals, tech, costs, etc. on their merits.  I am sorry you are dealing with this, but you should not pass up outside opportunities while holding onto \"hope\" that something gets better there.",
          "score": 19,
          "created_utc": "2026-02-22 15:27:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6uu5e2",
              "author": "Personal_Ad1143",
              "text": "This happened to me word for word as a senior DA near the top of a 40k FTE org. It is 1000% pointless to fight it when the machine is against you. ",
              "score": 5,
              "created_utc": "2026-02-22 22:53:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6sbd68",
          "author": "kthejoker",
          "text": "In BI your most important job security is making business friends in high places who either directly benefit from the value of your work or see you as an ally pushing the company in the right direction.\n\nOne thing you didn't mention is how the business perceived all of this ELT framework and Power BI model. Does everyone in the company use it every day? How long does it take to make a change? Are they knocking down your door asking for more?\n\nIf all you have is a tech stack and your own interpretation of the value you provide, you are going to be easily waylaid by either a smooth talking chav or someone who actually can potentially 10x a company.\n\nTale as old as time.",
          "score": 14,
          "created_utc": "2026-02-22 15:37:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6shm45",
          "author": "TodosLosPomegranates",
          "text": "The fact that they hired a contract CTO kind of tells you all you need to know. He’s going to try and make big bold moves so he either gets a good recommendation for his next contract role and maybe a bonus or he’s making a big bet so that he can become full time cto. You’re in his way with your common sense objections based on experience and fact. And there’s nothing you can really do about it. \n\nLeadership is taking a big swing on this guy and they need him to succeed as much as the guy himself wants to “succeed” and they want to move fast. That contract is a constraint that ensures he’ll put his head down ignore the things that usually slow teams down (like rationality) and do something “bold”\n\nDon’t waste your energy. Document everything,earn what you can (GCP on your resume is a good thing) and get prepared to leave.",
          "score": 13,
          "created_utc": "2026-02-22 16:04:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t21da",
          "author": "RBeck",
          "text": "In my experience a contract CTO's mission is to hire as many people from their company as possible, until they are fully embedded and hard to remove.\n\nI'd start looking for a job.",
          "score": 9,
          "created_utc": "2026-02-22 17:37:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6trkps",
              "author": "MrLyttleG",
              "text": "Je valide à 100% pour l'avoir vécu !",
              "score": 2,
              "created_utc": "2026-02-22 19:36:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ri7v6",
          "author": "Budget-Juggernaut-68",
          "text": "You all move 200mil only and need bigQuery?",
          "score": 14,
          "created_utc": "2026-02-22 12:52:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rihaq",
              "author": "anxiouscrimp",
              "text": "Yeah and our biggest fact table is probably only 500m rows",
              "score": 19,
              "created_utc": "2026-02-22 12:54:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6s77ng",
                  "author": "tomrosmono",
                  "text": "500m rows is a small DHW and any modern tool can manage that volume.",
                  "score": 13,
                  "created_utc": "2026-02-22 15:17:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6rnssw",
                  "author": "Sufficient_Example30",
                  "text": "Which means your  warehouse  isn't even a couple terabytes and he wants to be on cloud ,use a data warehouse and use bigquery",
                  "score": -2,
                  "created_utc": "2026-02-22 13:29:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rwxhy",
          "author": "coalesce2024",
          "text": "Leave as fast as possible. Leave him (cto) with the new project and legacy without the expert (you)",
          "score": 13,
          "created_utc": "2026-02-22 14:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6u7acq",
              "author": "powpow198",
              "text": "Yeah fuck this guy tbf",
              "score": 6,
              "created_utc": "2026-02-22 20:55:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uk92b",
          "author": "davetemplin",
          "text": "The problem isn’t the CTO — he’s a symptom.\n\nFirst, this is a very common scenario. Far more common than you might think.\n\nThe core problem is your executive leadership has lost confidence in the existing technical organisation and is under pressure to show transformation, likely driven by AI anxiety. They don’t want to hear that the real answer is hiring more operational people. The new CTO’s mission is to shake things up, and you’re perceived as part of the legacy problem. That’s why you’re being sidelined — you’re a threat to the new charter.\n\nWhat comes next? New vendor commitments (to GCP in this case), new hires and contractors (many coming from his personal network) all unfolding rapidly and without involving you. You’ll find yourself outside more and more decisions that you perceive as falling squarely within your domain and hearing of shifts that undermine you second and third hand.\n\nYou have three options.\n\nGet on the bus. Recognise this is a relationship problem between you and the new CTO and invest in aligning yourself with his agenda. This requires swallowing some pride but keeps you relevant and inside the tent. You have to be willing to give everything up. But you may find there is a lot of opportunity to learn new things. You don’t know it all.\n\nRide it out. The CTO will succeed or fail, but it will take 12-18 months to know which. If you choose this path, lay low. Don’t initiate actions that accelerate your own marginalisation — including writing that document you mentioned without being asked for it. And be clear-eyed about what failure actually looks like: it won’t revert to how things were. It will be a Pyrrhic victory. You’ll be in a new fractured world that is in many ways harder to operate within and the core problem with executive leadership will still be there. Your reputation will never return to what it was within the organization.\n\nGet off the bus. If getting on the bus isn’t something you can do with integrity, this is probably your best option. Leave on your own terms, with your reputation intact, before the situation inflicts more damage on your motivation and self worth.",
          "score": 7,
          "created_utc": "2026-02-22 22:01:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wsvgm",
              "author": "yo_sup_dude",
              "text": "i think many would argue that even if he can get on the bus \"with integrity\", that would not be the best option for him",
              "score": 2,
              "created_utc": "2026-02-23 06:30:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6s6oel",
          "author": "tomrosmono",
          "text": "Man, this is totally true and you have the right mindset and very clear points. Changing/Migrating just for the sake of it is just plain wrong.",
          "score": 6,
          "created_utc": "2026-02-22 15:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sx09p",
          "author": "doubtful62",
          "text": "Likely unpopular opinion. You can do what others suggest and update your resume. However, if you do want to make it work, find reasons to say yes. This person was brought in to stir things up. Go figure out what their motivations are and top 3 priorities. How do you accelerate them? How do you surface the issues that will pop up and show the CTO how you will solve them aligning to their priorities. If they see you as an ally to their mission, youll start being listened to over time (though likely not immediately)",
          "score": 4,
          "created_utc": "2026-02-22 17:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6thnix",
          "author": "decrementsf",
          "text": "\"Your job is to get a better job.\"\n\nIf this CTO is coming in as contract he is coming in trying to break into CTO roles. Has in mind the next role beyond this role. Adding to the resume that they managed a transition to XYZ builds onto their story for getting the role they may actually want. Incentives of the organization and incentives of what is good for the contract CTO are misaligned.\n\nThat is a potential err introduced above your pay grade. Getting incentive alignment right is a responsibility of board or whichever senior management selected a contract CTO.",
          "score": 7,
          "created_utc": "2026-02-22 18:48:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v6aro",
          "author": "West_Good_5961",
          "text": "Give them zero assistance. Don’t tell them anything critical unless they specifically ask for it. Let them fail due to lack of business knowledge. I’ve done this recently with 2 new hires who thought they could redesign everything in a couple of weeks. ",
          "score": 5,
          "created_utc": "2026-02-23 00:02:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rnc29",
          "author": "Hagwart",
          "text": "From my experience as a 'one-man-army' or 'swiss-army-knife' myself in the world of Qlik over the last 15+ years;\n\nEverytime I came to an organisation that current (Qlik) platform was in shambles. My job / goal was always to bring it up to par again from architecture to governance, from processes to documentation, from data source to data visualisation. Basically  everything you have done in your current role.\n\nBut the pattern that always happens to me in the end; Someone swoops in, claims credit and thinks they can handle it alone from here.\n\nThat's where they are wrong. Because that you made it look simple is not that it makes it simple and from experience most people always overestimate themselves and underestimate the other.\n\nFrom this sad experiences I have learned a valuable lesson; Start owning what you have done early and as soon as possible. Document everything on for instance Confluence, share architectural documents to whomever needs them, give presentations on improvements. I never was this focal, because I am not that \"Hey loooook aaaaaat meeee\"-kinda guy, but in the end I had to protect my legacy. Make sure what you did reaches at least one level above your direct manager. \n\nStart doing the same ...",
          "score": 8,
          "created_utc": "2026-02-22 13:26:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rkx2d",
          "author": "addtokart",
          "text": "Couple of thoughts as someone in management for the last decade or so:\n\n1. CTO is likely hired specifically to \"modernize\" or \"transform\". \n\n2. CTO is spending more time navigating the business with leadership. His first priority is to do right by them and be a good partner. \n\n3. CTO likely knows you were close to previous CTO who presumably left for a reason \n\nBigquery/GCP may on surface seem like a bad idea. Maybe it is. But CTO has likely done the math of migration cost. His math might be wrong but this ship may have already sailed.\n\nYour value here is to help guide this for better or worse. And maybe through guiding it you can minimize migration times. But you kinda have to go in this with \"how can I help\"",
          "score": 10,
          "created_utc": "2026-02-22 13:11:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rocsz",
              "author": "Sufficient_Example30",
              "text": "I don't know \nAll I know is when cto change the tech stack change.its like a line item that buys them at least a couple years",
              "score": 4,
              "created_utc": "2026-02-22 13:33:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tw8vy",
          "author": "compubomb",
          "text": "Your head is on the chopping block. He's researching how to replace you as we speak. Sorry to say, you already felt this, it's in the pipeline. If he was smart, he would be nice to you so when he does burn you, at least he might have had some relationships, he likely is not overly technical.",
          "score": 3,
          "created_utc": "2026-02-22 19:59:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xqyn4",
          "author": "SnooDingos8194",
          "text": "Too many red flags so you already know what to do - you and everyone else should jump ship.  Even if they dangled carrots like RSUs or some other phantom stock unit, they are terrible one sided deals and almost impossible to get paid out. Your best bet is to quit.  Hopefully,  your colleagues will do the same. No matter what, thats the smart move.",
          "score": 3,
          "created_utc": "2026-02-23 11:51:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ulhsz",
          "author": "boomskats",
          "text": "lol i knew this was gonna be a GCP steak and brandy post less than two sentences in. sorry dude ",
          "score": 2,
          "created_utc": "2026-02-22 22:07:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6un348",
              "author": "anxiouscrimp",
              "text": "What is a steak and brandy post?!",
              "score": 1,
              "created_utc": "2026-02-22 22:16:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6xsccz",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 2,
                  "created_utc": "2026-02-23 12:02:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vdue2",
          "author": "valorallure01",
          "text": "This situation just happened to me and I went through this exact same scenario. Company brought on a new director of technology who immediately wanted to move on prem sql server database to the cloud. I solely did this project. Yeah it was tough and I think we didn't need to move to the cloud but honestly I learned spark sql and fabric which was a big plus. Also, I built the new architecture which I believe gives me some decent leverage. Still have my job and the director gets to show off the new shiny object. Common corporate politics and diplomacy worked for me.",
          "score": 2,
          "created_utc": "2026-02-23 00:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vhzps",
          "author": "jdzndj",
          "text": "It’s a common pattern with newly joined but incompetent people who hold some influential titles. They often perceive the most experienced and capable team members as threats and try to sideline or marginalize them. They tend to align themselves with another new, desperate bootlicker who becomes overly loyal and helps enable their petty internal politics. I’d quiet quit and focus on planning an exit. Staying any longer than necessary in a toxic situation is just a waste of time and energy.",
          "score": 2,
          "created_utc": "2026-02-23 01:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70aqni",
          "author": "MnightCrawl",
          "text": "If I were you, I would seriously start updating your resume and applying for jobs as a backup\n\nIf they’re not paying attention to you or giving you their time it’s a strong possibility you can end up being let go even though you do heavy lifting with tasks and responsibilities. \n\nThis happened to me (Data Manager), but was actually happy I got laid off - I had been wanting to leave, but the team I made kept me there and seeing them grow was important to me. I was there for 9 years",
          "score": 2,
          "created_utc": "2026-02-23 19:46:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o71zs24",
          "author": "Hofi2010",
          "text": "Who is the contract CTO reporting to mad what is his brief. I agree just moving to Bigquery by itself doesn’t solve anything.  I also agree with keeping the resume fresh is a good idea. \n\nAt a bigger picture do you think your current data landscape can support more than just BI? He might be trying to align to more AI friendly technologies and ecosystem.",
          "score": 2,
          "created_utc": "2026-02-24 01:01:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74rnx3",
          "author": "codek1",
          "text": "Point him to the principal engineering tenant - \"Respect what came before\"\n\n[https://www.amazon.jobs/content/en/teams/principal-engineering/tenets](https://www.amazon.jobs/content/en/teams/principal-engineering/tenets)",
          "score": 2,
          "created_utc": "2026-02-24 13:26:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nrnz7",
          "author": "Actual-Specific-3595",
          "text": "The insanity wolf solution is to counter hard with a management presentation on why the tech (GCP) is wrong and why you should move to Databricks on Azure to build out your AI capabilities.",
          "score": 2,
          "created_utc": "2026-02-27 06:44:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rmayd",
          "author": "cellularcone",
          "text": "Where’s the CEO from / located?",
          "score": 4,
          "created_utc": "2026-02-22 13:20:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rqftq",
          "author": "snarleyWhisper",
          "text": "I had a similar situation happen. New IT c level came in, we were on on-prem sql server shop with a really robust data warehouse with over 400 dimension and fact tables, really well integrated with all business units in the company. The new ceo comes in, hears some pitch for Microsoft and says “we need to transition to fabric by the end of the year” , we rush to get things implemented - it’s a nightmare , buggy and the CU model was awful for our needs, CTO thought fabric would solve all problems, no cost controls. Anywho they lasted about 12 months before being fired but our entire department was outsourced before a new one was hired. Basically someone above you coming in making a bunch of changes means you are in the way out - sorry to say. Especially if they are lining up external partners.",
          "score": 1,
          "created_utc": "2026-02-22 13:46:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rpz4k",
          "author": "Bosshappy",
          "text": "It sounds like the new CTO cast the magic spell “I can do it for cheaper” on the C-level.  My best advice is to cozy up to him.  Tell him you’re on board and you want to help.  Get him to lay out his vision then decide if you want to be a part of it.  I’ve seen this a lot.  Most likely you need to update your resume and start networking",
          "score": 2,
          "created_utc": "2026-02-22 13:43:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6si173",
          "author": "tfehring",
          "text": "There are “not enough people translating data into something actionable or understandable,” but you spent the last 2 years *building an ELT framework*? At a £200M revenue retailer? Just use dbt core (or whatever off the shelf thing you want, I don’t care) and give your users some dashboards. And not in SSRS, come on, that was obsolete a decade ago and was too ugly to put in front of business users from the day it was released. Probably too late now but that’s what you should have done.",
          "score": 2,
          "created_utc": "2026-02-22 16:06:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6skwuo",
              "author": "anxiouscrimp",
              "text": "You’re missing the nuance. It’s taken 2 years from project inception - getting buy-in from the stakeholders etc. I’ve also had to continue building out the existing data warehouse for ‘we need this now’ requirements plus I’ve had a baby and taken pat leave. It’s taken longer than expected on top of this because of softer things - requirements changing etc - rather than technical reasons. I also am not building out new dashboards in SSRS - I was just giving example of what ‘BAU’ has been.",
              "score": 2,
              "created_utc": "2026-02-22 16:19:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6smota",
          "author": "Material-Hurry-4322",
          "text": "I've been in this situation. The CTO sounds like a dick to me who obviously doesn't know anything about BI and data engineering. Probably heard a few buzzwords and throws them around to sound like he knows what he's talking about. Every C level person I've worked for has been of this mold, except my current chief data officer.\n\nMigrating to GCP might not be terrible work if it's well managed and staffed so don't be totally set against it. Could be a valuable experience for you. If it turns into a shit show unfortunately you might need to look for a new job. Maybe get an offer then take that to the business asking for a raise to offset the BS you're dealing with.",
          "score": 2,
          "created_utc": "2026-02-22 16:27:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rl4he",
          "author": "Astherol",
          "text": "Seems like you are having a bit soft power in your org and he tries to sideline you without direct confrontation which he could lose when all the BI will come to crash someway. \nI would get started to interview in other companies for the emotional well-being and try to have a vulnerable chat (best if in-person) with CTO to find a middle ground. I just guess he sees you as an opponent when a skillful CTO would make you an ally to-be retrained for new stack as you have a lot of tribal knowledge.\nBe human, give him some gift to assure him that you will not collaborate with stakeholders against him.",
          "score": 1,
          "created_utc": "2026-02-22 13:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s7983",
          "author": "Xman0142",
          "text": "Brush up that resume and leave as there’s a lot of job openings for your skillset and it is a sinking ship.",
          "score": 1,
          "created_utc": "2026-02-22 15:17:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sffe4",
          "author": "randrews1886",
          "text": "I have such a similar experience with my new head. I was so excited that DE was being recognised as requiring a head but they just don't engage with me at all. Been thinking for a while to either jump ship or wait for him to be discovered as the fraud I believe him to be.... Not sure what to do",
          "score": 1,
          "created_utc": "2026-02-22 15:55:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6shkjj",
          "author": "Pab_Zz",
          "text": "Give your opinion when you can, but if they ignore you what can you do. Take your pay check and let the big wigs do what they do. It'll keep you busy for a while and if you're unhappy jump ship.",
          "score": 1,
          "created_utc": "2026-02-22 16:04:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sp3i1",
          "author": "wbrd",
          "text": "Use it to learn new tools and technology.\n\nGcp has a lot of things that will do what you built with just a bit of terraform and it's all managed for you.",
          "score": 1,
          "created_utc": "2026-02-22 16:38:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6te2uf",
          "author": "andyagtech",
          "text": "There is a chance that the CTO is looking to bring in his friends, and \"data\" is an area where it is easy to promise a lot and take some time to deliver.\n\nAnd when it comes to throwing people under the bus, relatively expensive data people are an easy target. Plus the amount of stuff published by companies in the data space promising everything is just nuts and hard for most non-data people to wade through.",
          "score": 1,
          "created_utc": "2026-02-22 18:32:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ucd1q",
          "author": "Standard_Fun3244",
          "text": "Talk to a superior asap",
          "score": 1,
          "created_utc": "2026-02-22 21:21:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uk1np",
          "author": "sciencewarrior",
          "text": "I'll have to agree with the prevailing opinion here. Get in contact with you previous CTO and former colleagues. When asked why you're moving, you can always pull the old reliable, \"I've been at the same company for a decade, and I finally felt this was the right time to look for new challenges.\"",
          "score": 1,
          "created_utc": "2026-02-22 22:00:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6unyn3",
          "author": "lzwzli",
          "text": "First time I've heard of a contract CTO. Is your company in the process of being set up for sale?\n\nIn any case, if you've been at the same company, at the same position for 10+ years, you're doing your career a disservice to continue there, regardless of the CTO situation.",
          "score": 1,
          "created_utc": "2026-02-22 22:20:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6usf4h",
          "author": "colincclark",
          "text": "You were not clear about whether you had initiated a discussion with the new CTO or not. That should be your first step, regardless of their lack of initiative.\n\nFurther, your documentation about the estate should be preexisting, alongside ADRs that demonstrate your reasoning and choices over the past 2 year refsctor. A document outlining your vision for the future would be your responsibility as well.\n\nAs someone else commented, however, a new CTO coming in and trying to make an early big splash by proposing a junk idea is not uncommon, unfortunately. In this situation, it is often better to jump before you are pushed. You will often find the grass is greener after 5 years at a company, and your pay increase will heal any frustrations or upset you currently feel.",
          "score": 1,
          "created_utc": "2026-02-22 22:44:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v304b",
          "author": "Commercial-Ask971",
          "text": "What? What does mean he is contractor? Like a consultant? or a freelancer ",
          "score": 1,
          "created_utc": "2026-02-22 23:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vfwm7",
          "author": "TheOverzealousEngie",
          "text": "sadly in IT some jobs are demolished due to politics. if I had an example of that I’d point to this post. that said, it’s time to leave. why? because did they ever consult you before hiring this cto? ever ask what you thought? look immediately for a new job and think carefully where this one went wrong.",
          "score": 1,
          "created_utc": "2026-02-23 00:57:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6w83y8",
          "author": "foresythejones",
          "text": "this happens a lot with contractor ctos, they come in with a default playbook and preferred stack, sometimes before understanding what’s already working. write the document, but frame it around business outcomes, cost, risk, and what problem a move to bigquery would actually solve versus your current setup. then ask for a direct 1:1 and position yourself as the person who can de risk any transition, not the person defending the old world. and yes, quietly updating your cv is just smart risk management.",
          "score": 1,
          "created_utc": "2026-02-23 03:51:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77mt86",
          "author": "ntdoyfanboy",
          "text": "When he said \"we understand you have a fractured data state,\" what was your reply? I hope it was \"No, who told you that, and what makes you think this?\"",
          "score": 1,
          "created_utc": "2026-02-24 21:28:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o781b9d",
              "author": "anxiouscrimp",
              "text": "Haha, I said ‘I’m quite surprised to hear that we’ve got no central source for data when a) we’ve got a functional data warehouse that’s been in use since 2016 and b) I’ve been working hard to create a new data warehouse and semantic model to replace this which integrates and models data from 16 different sources.’ I hope I didn’t come across as angry as I felt. But it did seem to steer the conversation towards ‘how can google work with your current estate’ - in that meeting at least.",
              "score": 2,
              "created_utc": "2026-02-24 22:37:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ryxgp",
          "author": "MrLewArcher",
          "text": "You used some outdated terminology. Do you support digital marketing? What are the companies actual problems?",
          "score": 1,
          "created_utc": "2026-02-22 14:34:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rzyio",
              "author": "anxiouscrimp",
              "text": "What do you mean? No, I don’t support digital marketing but I do need to consolidate data from all of our digital marketing platforms into a single model.",
              "score": 3,
              "created_utc": "2026-02-22 14:39:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6s3bwd",
                  "author": "MrLewArcher",
                  "text": "Times are changing. Not saying it’s right but if I were a CTO and I heard someone talking to me about BI and Cubes, I’d go looking for someone else because I’m responsible for progressing the company forward. Does your data support prediction, forecasting, or any other advanced modeling? If it only supports reporting on what’s already happened - that’s likely why you are struggling to get his attention.",
                  "score": 4,
                  "created_utc": "2026-02-22 14:57:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ri1o6",
          "author": "moosic",
          "text": "Go learn Databricks now. Walk away from everything you’ve learned around MS SQL. Your career is going to depend on it. You’re invested in a dying technology. \n\nLearn python and start using Claude code to do your transforms. Your skill set is about to be replaced by agentic coding. \n\nDon’t let pride get in the way of learning new technology.",
          "score": -10,
          "created_utc": "2026-02-22 12:50:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rj9i0",
              "author": "anxiouscrimp",
              "text": "I appreciate the reply but I’m already using python and spark for a lot of the initial data extracts into adls. I love to learn new things and have never shied away from something new just because it’s an unknown.",
              "score": 3,
              "created_utc": "2026-02-22 12:59:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6rih2h",
              "author": "kitsunde",
              "text": "That’s the spirit, you can be the CTO after the current one has finished the BQ migration.",
              "score": 1,
              "created_utc": "2026-02-22 12:54:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ybfsm",
          "author": "Gullyvuhr",
          "text": "A CTO cares about the outcomes, not how you did it. He doesn't just do technology for the sake of it, it is in service to the business. You're a cost center, not something generating revenue. He's responding to what he has been told the needs of the business are, and what they perceive they are not getting.\n\nFurthermore, not once did you mention anything about your consumers. Just coming in, getting them what they are asking for is the win. You're saying everything is fine because you say it's fine, and I think you might be missing the point.\n\nThe HOW is moot, and clearly the WHAT is being provided isn't meeting your consumers perceived needs or this wouldn't be an initiative he'd key in on as important enough to do first. You keep wanting to talk everyone though what you've done so you can be right, but I think you may need to zoom out a little.",
          "score": -1,
          "created_utc": "2026-02-23 14:06:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfqzvh",
      "title": "Low Code/No Code solutions are the biggest threat for AI adoption for companies",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rfqzvh/low_codeno_code_solutions_are_the_biggest_threat/",
      "author": "boogie_woogie_100",
      "created_utc": "2026-02-27 00:02:53",
      "score": 110,
      "num_comments": 120,
      "upvote_ratio": 0.88,
      "text": "Because they suck and can't edit them and maintaining them is a nightmare. \n\nAny company who wants to move fast with AI driven development needs to get rid of low code no code data pipelines. ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rfqzvh/low_codeno_code_solutions_are_the_biggest_threat/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7mg2j2",
          "author": "OGMiniMalist",
          "text": "As someone who works on a team of \"non-technical\" data engineers. I can confirm. Low code / no code data engineering solutions are not great.",
          "score": 69,
          "created_utc": "2026-02-27 01:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7obfss",
              "author": "salma311",
              "text": "do you know why solutions like informatica, abinitio are so prevalent",
              "score": 3,
              "created_utc": "2026-02-27 09:46:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7tyyvi",
                  "author": "ShaybantheChef",
                  "text": "They get sold to executive managers, not engineers",
                  "score": 4,
                  "created_utc": "2026-02-28 05:18:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7phy85",
                  "author": "OGMiniMalist",
                  "text": "I do not. Do you?",
                  "score": 3,
                  "created_utc": "2026-02-27 14:43:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7n847f",
              "author": "Nekobul",
              "text": "\"non-technical\", yet able to deliver working solutions. Thank you for confirming it!",
              "score": -22,
              "created_utc": "2026-02-27 04:18:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7n9ema",
                  "author": "OGMiniMalist",
                  "text": "\"working solutions\" != Elegant solutions. The company pays the salary of multiple people as a result. It has also been difficult to get my team to transition to using Git to version control our stuff (let alone when someone needs to roll back a change they made to the pipeline). Data engineering solutions should be owned and executed by technical team members capable of abstracting beyond what a low code / no code solution offers.",
                  "score": 36,
                  "created_utc": "2026-02-27 04:27:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7nbxrn",
                  "author": "boogie_woogie_100",
                  "text": "you can build entire data engineering solution microsoft access and call it a working solution. That does not mean it is a elegant solution.",
                  "score": 9,
                  "created_utc": "2026-02-27 04:44:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7mx9oy",
          "author": "calimovetips",
          "text": "low code is fine until it becomes your core data layer and no one can version, test, or refactor it. once ai workloads depend on that pipeline, the brittleness shows up fast.",
          "score": 17,
          "created_utc": "2026-02-27 03:10:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7neayl",
              "author": "boogie_woogie_100",
              "text": "Exactly.",
              "score": 2,
              "created_utc": "2026-02-27 05:00:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7m27ty",
          "author": "JaceBearelen",
          "text": "They were shit before AI for the same reason. I hate having to go through a vendor to fix a broken integration.",
          "score": 49,
          "created_utc": "2026-02-27 00:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n8bo1",
              "author": "Nekobul",
              "text": "I think you will hate it more having to reason in tons of code, generated by a machine, driven by junior who is learning on the job.",
              "score": 7,
              "created_utc": "2026-02-27 04:20:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nenvy",
                  "author": "JaceBearelen",
                  "text": "I have done both and prefer the ai powered junior. Just set up good rules files, ci, branch protection, and access policies. If they can really mess anything up thats not their fault.",
                  "score": 3,
                  "created_utc": "2026-02-27 05:03:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7mfsjb",
              "author": "boogie_woogie_100",
              "text": "Same. They shouldn't exist in this world. ",
              "score": 0,
              "created_utc": "2026-02-27 01:28:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7n17ra",
          "author": "throwaway0134hdj",
          "text": "Low code is better only in that it has safety guardrails and boundaries built in. AI sounds great in theory but who handles the updates, who ensures security and authentication? \n\nManaging code with LLMs is weird, it can feel like a house of cards to where you want to make a small change and it ends up touching a bunch of unrelated files and bloats a bunch of new ones, and before you know it the codebase is in shambles. I think LLM codebases work only when you have someone behind the wheel who actually knows how to read and debug the code.",
          "score": 11,
          "created_utc": "2026-02-27 03:34:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n7fe6",
              "author": "Nekobul",
              "text": "Preach it, brother. I can't believe what some other people are commenting here. We are approaching the Idiocracy realm quickly.",
              "score": 4,
              "created_utc": "2026-02-27 04:14:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7n908o",
              "author": "Healthy-Educator-267",
              "text": "Managing code with LLMs is fine as long as you make sure it makes minimal changes. These models have a tendency to be verbose and to overengineer things like an eager junior as opposed to iterating with minimal viable changes. You just have to get it do do that so you can actually review the changes rather than face a mountain of slop which is what slows down devs when using AI",
              "score": 1,
              "created_utc": "2026-02-27 04:24:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ndw7s",
                  "author": "boogie_woogie_100",
                  "text": "That is what skills.me, claude.md and agents are for so that it doesn't hallucinate.",
                  "score": -2,
                  "created_utc": "2026-02-27 04:57:54",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ndqhr",
              "author": "boogie_woogie_100",
              "text": "By the way have you worked with Tools like claude code? No one is talking about vide coding here. You can literally manage Claude code to boost your productivity 100x. It is up to you how you manage claude code and it has tons of safety mechanism.  i have been in this field for almost two decades and work that used to take me 10 days i am doing in 1 day. I am debugging entire code base which I have never seen before in matter of minutes rather than days. I am designing data pipeline, writing test cases, generating reports in matter of hours  rather than days.",
              "score": -2,
              "created_utc": "2026-02-27 04:56:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7no1fd",
                  "author": "daguito81",
                  "text": "“It’s up to you to….” In enterprise normally means “Nobody will ever….” \n\nWhich is why all this low code tools keep coming and keep exiting and be successful, because of those guardrails",
                  "score": 4,
                  "created_utc": "2026-02-27 06:15:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7m2ivv",
          "author": "BleakBeaches",
          "text": "Honestly it depends. Most of them are composed of atomic units described by a structured markup language. Text. So as long as your model can generate these then low/no code may have benefits.\n\nFor example: SSIS packages and projects are just XML. I use models to build and/or modify the underlying xml all the time. Agents can do them in mass.",
          "score": 12,
          "created_utc": "2026-02-27 00:14:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nnrmb",
              "author": "GetSecure",
              "text": "The same with logic apps. I copied and pasted the code and asked it to do what I asked. I mean it, totally screwed it up and I had to spend 2 hours back and forth before it finally fixed it, but... I expect it'll get there eventually.\n\n\nI now just copy the code and ask for advice, then implement it myself.",
              "score": 1,
              "created_utc": "2026-02-27 06:12:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7p18a8",
                  "author": "boogie_woogie_100",
                  "text": "oh logic apps is worst. you will be scratching your head what happened when multiple devs working same logic app",
                  "score": 1,
                  "created_utc": "2026-02-27 13:10:51",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7p1psq",
              "author": "Outrageous_Let5743",
              "text": "I use SSIS sadly but how do you use agents or LLMs for it? Even a simple ssis package is already like 500-600 lines of xml with different ID every time you save.. LLMs choke at xml.",
              "score": 1,
              "created_utc": "2026-02-27 13:13:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7mewdc",
              "author": "boogie_woogie_100",
              "text": "\"described by a structured markup language\" - That is the exact problem which I am talking about. I have worked with SSIS(XML), ADF (json) and other low code no code solutions. AI Models are meant to generate XML Language which gets rendered into an UI. it makes development process very very unnatural. Also, version control of these becomes a night mares. One block on messed XML and your entire pipeline can't even rendered. \n\nYou can't convince me, we build data pipeline by editing/writing xml files. ",
              "score": 0,
              "created_utc": "2026-02-27 01:23:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ntqm3",
                  "author": "Lyesh",
                  "text": "Note that Apple. Motherfucking APPLE, kings of making everything a GUI, went from a highly visual, low-code drag n drop paradigm for their UI design program to a text-first affair that just has a UI appearance preview.\n\nThe ability to easily see changes, control them, and so on are that vital to development. \n",
                  "score": 2,
                  "created_utc": "2026-02-27 07:02:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7n6qdh",
                  "author": "Nekobul",
                  "text": "The XML is a very well defined protocol that can be also verified against XSD schema. If you are messing up the XML, it is clear you don't know what you are doing.",
                  "score": 2,
                  "created_utc": "2026-02-27 04:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7n8fln",
              "author": "Nekobul",
              "text": "I think the OP is a junior. All his comments are pointing in that direction.",
              "score": 0,
              "created_utc": "2026-02-27 04:20:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ncg2n",
                  "author": "boogie_woogie_100",
                  "text": "I work in this field for 19 years. I have seen all kinds of low code no code solution and pure code solutions. Pure code solutions are always maintained by engineers, easy to maintain, and debug. Low code solutions are always cumbersome to maintain, scale and mostly maintained by non technical people.",
                  "score": 5,
                  "created_utc": "2026-02-27 04:47:51",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7mlvso",
          "author": "buckeyemtb",
          "text": "I've had luck getting AI to write python scripts to update ADF PPL JSONs in bulk, but not to do real logic changes (partly because of how the chucklefucks who set up our system parameterized things.). And data flows...those can go straight to hell.\n\nI do think an AI agent may well prove useful migrating off these however.",
          "score": 3,
          "created_utc": "2026-02-27 02:04:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nm6ib",
          "author": "musty_mage",
          "text": "Low-code/no-code has always been at best a dead end and at worst a total scam",
          "score": 3,
          "created_utc": "2026-02-27 05:59:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7npzx5",
              "author": "boogie_woogie_100",
              "text": "can't agree more!",
              "score": 2,
              "created_utc": "2026-02-27 06:31:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7o8m2a",
                  "author": "musty_mage",
                  "text": "At my previous workplace the low-code framework was almost 10 million lines of unmaintainable Java horror and the applications on top of it a massive pile on unintelligible XML.\n\nThe replacement LoC for all 30 or so endpoints / applications was circa 60k lines (of modern Java). Still not small, but easily maintainable by 1 senior person.\n\nAnd it's been the same shit every single time I've seen one of those stupid thingamagicks.",
                  "score": 1,
                  "created_utc": "2026-02-27 09:19:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7oyqyy",
              "author": "Nekobul",
              "text": "I guess Snowflake and Databricks  and Microsoft disagree with you because all three of them now provide their own low/no code tooling.",
              "score": 1,
              "created_utc": "2026-02-27 12:55:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7oz0z6",
                  "author": "musty_mage",
                  "text": "I mean sure they disagree because they love vendor lock-in",
                  "score": 2,
                  "created_utc": "2026-02-27 12:56:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7m358p",
          "author": "BrupieD",
          "text": "I wouldn't be so sure of that.\n\nLow code/No code solutions are usually just graphic interfaces on top of regular software. Think of a process performed in Excel. Then create that same process with an Excel macro recorder on. You've created a programmatic solution based on a low code process.\n\nWhat type of low code solution are you thinking?",
          "score": 10,
          "created_utc": "2026-02-27 00:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mk5zl",
              "author": "unexpectedreboots",
              "text": "Lol. Fire up a Talend project and let me know about that.",
              "score": 10,
              "created_utc": "2026-02-27 01:54:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7mx4dh",
                  "author": "breakawa_y",
                  "text": "Was about to say, dudes never been through the circles of hell. \n\nI’m dealing with a similar tool to extract/import from Salesforce and it’s been absolute hell within the constraints of an enterprise.",
                  "score": 6,
                  "created_utc": "2026-02-27 03:09:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7mfoze",
              "author": "boogie_woogie_100",
              "text": "They are not like Excel Macro. They are based on static xml/json files. Take an example of SSIS or ADF. one line of messed up xml , your entire UI won't rendered. Also, You can't tell UI to go through XML files and create another pipeline by tweaking certain changes. it also produces bunch of unnecessary xml/json garbage which will chew lots of tokens. Taken a look into simple pipeline build on Either SSIS or ADF you will understand what I am talking about. ",
              "score": 7,
              "created_utc": "2026-02-27 01:28:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7n73q4",
                  "author": "Nekobul",
                  "text": "Based on what you are writing, I wouldn't permit you anywhere near a data pipeline. You are a trainee at best.",
                  "score": -1,
                  "created_utc": "2026-02-27 04:11:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7m3rkt",
          "author": "Repulsive-Beyond6877",
          "text": "Would have to say it’s not necessarily that. It’s more about closed box coding more so than low or no code solutions only.\n\nAn example would be some of the code generators from hashicorp. They work fine until you want to leave hashicorp, then you have zero code to work off of and no engineers that know how to build that code or maintain it.\n\nAI is worse because you end up with brainless people that can’t code trying to debug issues or maintain code repositories they haven’t had to use their brains to build or maintain before.\n\nA good chunk of the issue, at least in my opinion, is the lack of development of critical thinking, decision making, problem solving skills. Brains that are heavily exposed to and rely on AI are severely under developed in comparison to brains that aren’t.",
          "score": 6,
          "created_utc": "2026-02-27 00:21:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m86l9",
              "author": "CorpusculantCortex",
              "text": "I dont think ai has been around long enough to be able to reliably make the assertion that: \n\n>Brains that are heavily exposed to and rely on AI are severely under developed in comparison to brains that aren’t.\n\nI think this is partially just a feeling people have but when it comes to neuroscience and how brains actually work, fully developed engineers using ai for 3 or 4 years doesn’t remove their capacity to reason or code.\n\nThis is more of a concern for the kids going thru school now. But the same can be said for computers. Because of computer based learning in schools Gen z is the first generation in recorded history of testing (about 100 years) who are less smart than their parents. So gen alpha with untethered access to ai will probably be worse off if things arent changed. \n\nBut that is a developmental thing, not a 'fully developed brain uses a tool for a couple years' thing.\n\nIt does give people who don't know what they are talking about too much confidence though, but that is a different issue.",
              "score": 5,
              "created_utc": "2026-02-27 00:45:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7mjiuy",
                  "author": "Repulsive-Beyond6877",
                  "text": "I’m not necessarily referencing experienced devs. This is the Jr dev class that shows up consistently that cannot code. Also a lot of the contractors that show up from India just vibe code and can’t fix anything. Nothing wrong with devs from India, just the last 60 or 70 I’ve encountered that are based there legit got fired because they couldn’t code and all their vibe codes crap we had to bin and start over.\n\nAn article illustrating some of your points, but it’s also not difficult to extrapolate it out to a person who’s still learning how to code.\n\nhttps://time.com/7295195/ai-chatgpt-google-learning-school/?fbclid=IwY2xjawQN1oNleHRuA2FlbQIxMQBzcnRjBmFwcF9pZA80MDk5NjI2MjMwODU2MDkAAR4OaBq_Q9Nq6c1BSubE53LSVBJFp5h9o6FBdPYHML1RTq78DQqQUQHpjdGLXQ_aem_AknOFGN16AEFlYTlMZMkLg",
                  "score": 1,
                  "created_utc": "2026-02-27 01:50:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7mgjel",
              "author": "boogie_woogie_100",
              "text": "There is no coding in SSIS or ADF or similar tool. You just drag and drop. I have never seen anyone writing xml or json in visual studio building pipeline. \n\nI am not talking about vibe code to build data pipeline. You still need to define structure, design framework etc but you can delegate mundane tasks such as connector, looping, etc to AI and you can parallelize the development to boost your productivity. dbt is one of the example, once you build the framework for one model you can use it for build any number of models. ",
              "score": 2,
              "created_utc": "2026-02-27 01:33:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7mlgi2",
                  "author": "Repulsive-Beyond6877",
                  "text": "Look, if you’re talking about ripping out SSIS packages, that’s relatively easy to do and automate in any cloud. You don’t need any specialized skills to do it.\n\nJust curious, what scale are you at if you’re using SSIS?",
                  "score": 0,
                  "created_utc": "2026-02-27 02:01:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7n7vc8",
                  "author": "Nekobul",
                  "text": "The goal with SSIS is to avoid writing code as much as possible. Otherwise, you are not taking advantage of the platform. Writing code is only for novices, juniors.",
                  "score": -2,
                  "created_utc": "2026-02-27 04:17:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nyfyx",
          "author": "Lastrevio",
          "text": "Agreed. I hate debugging SSIS spaghetti arrows written 15 years ago.",
          "score": 2,
          "created_utc": "2026-02-27 07:43:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ncfw0",
          "author": "SoloArtist91",
          "text": "My company has been using Alteryx for almost a decade at this point and it's become an unwieldy mess. Any AI I used for help is really limited since I can't copy and paste my workflow into a prompt to get feedback.\n\nI've been slowly replicating the core pipelines in Dagster + DBT and AI is way more impactful there. After handling tricky ingestion logic myself, I can give Claude Code the business context for a star schema, review what it gives me back, and then it can create models faster than I could ever in Alteryx.",
          "score": 3,
          "created_utc": "2026-02-27 04:47:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nfk74",
              "author": "boogie_woogie_100",
              "text": "yup. Some user in this thread write xml to build data pieces.",
              "score": 2,
              "created_utc": "2026-02-27 05:09:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mp524",
          "author": "WilhelmB12",
          "text": "Nope, any competent LLM agent can just check the JSON files for those tools and convert them to an SQL, python, or java data pipeline",
          "score": 0,
          "created_utc": "2026-02-27 02:23:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nemlq",
              "author": "boogie_woogie_100",
              "text": "i am not talking about converting code.",
              "score": 1,
              "created_utc": "2026-02-27 05:03:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7npi2d",
          "author": "Euphoric_Yogurt_908",
          "text": "Agreed. if the solution is traditional drag-n-drop solution type of no code solution, then it's doomed.  In the AI era,  you should look for solutions that are powered by code in the back. In the end, AI is really good at writing code, and you can easily get other developers to collaborate.  code review, approval, versioning. ",
          "score": 1,
          "created_utc": "2026-02-27 06:27:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nptu4",
              "author": "boogie_woogie_100",
              "text": "Exactly. I had a client who was using Azure Data Factory for pipeline and wanted to implement AI powered development and just hit the wall. ",
              "score": 2,
              "created_utc": "2026-02-27 06:29:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ouwr0",
                  "author": "vickelajnen",
                  "text": "Curious to know what went so terribly wrong? As long as you have a well structured repo it's just a bunch of JSON's? Is it that models suck at ADF specifically? Thinking about how e.g. agents would fail in this setting when compared to a dbt repo, which we're currently starting to work with at my client with some initial success in boosting productivity.",
                  "score": 2,
                  "created_utc": "2026-02-27 12:29:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ozjzr",
                  "author": "Nekobul",
                  "text": "Soon that client will start hitting the wall with the head when the \"AI\" crapola starts hitting the fan.",
                  "score": 1,
                  "created_utc": "2026-02-27 13:00:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ozbxk",
              "author": "Nekobul",
              "text": "You are right, LLM is very good at writing meaningless, throw-away code.",
              "score": 1,
              "created_utc": "2026-02-27 12:58:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7o1wq2",
          "author": "Snappyfingurz",
          "text": "I completely agree, the rigid black box nature of low-code tools makes version control and debugging an absolute nightmare for complex AI pipelines. it makes you wanna smash your own head through the monitor",
          "score": 1,
          "created_utc": "2026-02-27 08:15:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7p2bda",
              "author": "boogie_woogie_100",
              "text": "oh i have stitches on my head debugging low code solutions",
              "score": 1,
              "created_utc": "2026-02-27 13:17:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7obww0",
          "author": "lugovsky",
          "text": "As someone who has been building a low-code solution for a while, I can say that visual building in low/no-code is probably coming to the end of its lifecycle. Low/no-code needs to redefine itself and either become code-first or become part of history.",
          "score": 1,
          "created_utc": "2026-02-27 09:51:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ozvnq",
              "author": "Nekobul",
              "text": "Build better OS than Linux with LLM. Waiting.",
              "score": 1,
              "created_utc": "2026-02-27 13:02:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7oeont",
          "author": "New-Addendum-6209",
          "text": "Low code makes it easy to get started with simple data movement projects: load a file every X minutes, transfer data from database A to database B.\n\nThe real problem is that it becomes difficult to properly version, test and deploy code.\n\nThe one advantage is that it provides clear guard rails and encourages simplicity. I have seen some crazy things built by engineers that would have been prevented if they were forced to use SSIS or similar. The worst was an in-house declarative ETL framework using a custom markup format...",
          "score": 1,
          "created_utc": "2026-02-27 10:16:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7p02ys",
              "author": "Nekobul",
              "text": "You can build anything with SSIS if you know what you are doing.",
              "score": 1,
              "created_utc": "2026-02-27 13:03:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7osnt4",
          "author": "Fermabowl",
          "text": "We are still stuck with some SSIS logic. Any idea how to transform/migrate? All tries with AI failed because it just doesn't get all informations out of the XMLs, but it must be possible, right?",
          "score": 1,
          "created_utc": "2026-02-27 12:12:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7p064t",
              "author": "Nekobul",
              "text": "Why do you want to migrate away from SSIS? What is the issue?",
              "score": 0,
              "created_utc": "2026-02-27 13:04:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7x8xwe",
                  "author": "Fermabowl",
                  "text": "It's not good enough for automated testing and the logic is hidden somewhere in packages, quite tedious to debug. And finally not suitable to access for AI agents, at least not as good as plain code.",
                  "score": 1,
                  "created_utc": "2026-02-28 18:49:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7x9a3s",
                  "author": "Fermabowl",
                  "text": "And it got outdated, e.g. Fabric doesn't have a possibility to run ssis packages",
                  "score": 1,
                  "created_utc": "2026-02-28 18:51:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7posvk",
          "author": "acana95",
          "text": "Couldnt aggree more. I was dev low code/no code and integration with legacy systems was a pain in the ass",
          "score": 1,
          "created_utc": "2026-02-27 15:17:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q6gwd",
              "author": "boogie_woogie_100",
              "text": "True. It's truly a curse for modern data engineers. ",
              "score": 1,
              "created_utc": "2026-02-27 16:41:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7x829d",
          "author": "thevnom",
          "text": "Thats a lot of words to say that you wont hire engineers for your engineering.",
          "score": 1,
          "created_utc": "2026-02-28 18:44:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7xatvu",
              "author": "boogie_woogie_100",
              "text": "what are you talking about? just because they use AI meant they are not engineers? AI is a tool to boost productivity and i encourage everyone to use AI. Note: I am not talking about vibe coding.",
              "score": 1,
              "created_utc": "2026-02-28 18:58:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rfdft0",
      "title": "Hardwood: A New Parser for Apache Parquet",
      "subreddit": "dataengineering",
      "url": "https://www.morling.dev/blog/hardwood-new-parser-for-apache-parquet/",
      "author": "gunnarmorling",
      "created_utc": "2026-02-26 15:39:44",
      "score": 88,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Open Source",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rfdft0/hardwood_a_new_parser_for_apache_parquet/",
      "domain": "morling.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o7ljavl",
          "author": "Typical_Priority3319",
          "text": "Looking at the projects page of your blog is insane. How do you even find the inspiration to work on so many things that actually end up being important? I need to stop making excuses and lock in lol",
          "score": 24,
          "created_utc": "2026-02-26 22:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7orx86",
              "author": "gunnarmorling",
              "text": "Haha, thank you! Scratching my own itch is usually where it starts.",
              "score": 7,
              "created_utc": "2026-02-27 12:07:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7jys5t",
          "author": "ssinchenko",
          "text": "That is beautiful! Finally we have a Hadoop-free parquet in JVM ecosystem!",
          "score": 12,
          "created_utc": "2026-02-26 18:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l8kb0",
              "author": "gunnarmorling",
              "text": "Yes! Avoiding that dependency was one of the main motivations for kicking off this project.",
              "score": 10,
              "created_utc": "2026-02-26 21:37:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7m5ord",
                  "author": "pungaaisme",
                  "text": "Bro! Thank your for giving us hope to finally get rid of the gazillion Hadoop dependencies",
                  "score": 4,
                  "created_utc": "2026-02-27 00:31:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7mlqho",
          "author": "goblueioe42",
          "text": "This is great!",
          "score": 3,
          "created_utc": "2026-02-27 02:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pj78e",
          "author": "ImpossibleHome3287",
          "text": "This looks great! Thanks for sharing. I'll give it a spin this weekend.",
          "score": 3,
          "created_utc": "2026-02-27 14:49:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7k1wzl",
          "author": "seeksparadox",
          "text": "great stuff Gunnar, congrats!",
          "score": 3,
          "created_utc": "2026-02-26 18:16:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l8elt",
              "author": "gunnarmorling",
              "text": "Thank you so much!",
              "score": 2,
              "created_utc": "2026-02-26 21:37:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ren5fc",
      "title": "What kinds of skills should I be working on to progress as a Data Engineer in the current climate?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1ren5fc/what_kinds_of_skills_should_i_be_working_on_to/",
      "author": "Patrick_Gently",
      "created_utc": "2026-02-25 19:26:59",
      "score": 76,
      "num_comments": 33,
      "upvote_ratio": 0.95,
      "text": "I've built some skills relevant to data engineering working for a small company by centralising some of their data and setting up some basic ETL processes (PostgreSQL, Python, a bit of pandas, API knowledge, etc.). I'm now looking into getting a serious data engineering job and moving my career forward, but want to make sure I've got a stronger skillset, especially as my degree is completely irrelevant to tech.\n\nI want to work on some projects outside of work to learn and showcase some skills, but not sure where to start. I'm also concerned about making sure that I'm learning skills that set me up for a more AI heavy future, and wondering if aiming for a Data Engineering to ML Engineering transition would be worthwhile? Basically what I'd like to know is, in the current climate, what skills should I be focussing on to make myself more valuable? What kinds of projects can I work on to showcase those skills? And is it possible/worthwhile including ML relevant skills in these projects?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1ren5fc/what_kinds_of_skills_should_i_be_working_on_to/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7dq064",
          "author": "AutoModerator",
          "text": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-25 19:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dtntw",
          "author": "mrbartuss",
          "text": "Soft skills",
          "score": 89,
          "created_utc": "2026-02-25 19:44:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7e974o",
              "author": "WallyMetropolis",
              "text": "I'll expand because this is crucial. \n\n\nIf you can make a business case for your own position, if you can solve measurable business problems and not just pull tickets, if you can help the people who decide who gets a raise and who gets fired to be more successful at their jobs, if you can talk to stakeholders and keep them happy then you can weather any economic or technological storm. ",
              "score": 48,
              "created_utc": "2026-02-25 20:56:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7f1hqm",
                  "author": "Alternative-Guava392",
                  "text": "This is true and I learnt it the hard way. \nI can complain that my job is to be in charge of the data platform and keep it state of the art, that business is the responsibility of my manager / stakeholders.\n\nBut it is not true. You have to be responsible for business, stakeholders, reliability of your team and of the data. Can't just build solutions and be \"data-driven\" anymore.",
                  "score": 10,
                  "created_utc": "2026-02-25 23:13:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7l8rh3",
                  "author": "bigbunny4000",
                  "text": "I think this requires natural talent though. This cannot be learned.",
                  "score": 0,
                  "created_utc": "2026-02-26 21:38:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7f4ij4",
              "author": "makesufeelgood",
              "text": "It actually has always been this and it's the hardest pill for most people to swallow lol",
              "score": 8,
              "created_utc": "2026-02-25 23:30:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7fe37u",
              "author": "reppoc0308",
              "text": "This is the answer.",
              "score": 2,
              "created_utc": "2026-02-26 00:23:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7dyi3b",
          "author": "Cloudskipper92",
          "text": "I think given you already experienced what it means to do the basics of the job, you ought to now look around at the tools that DEs at places with larger data systems use as you'll be required to use them at some point. Those being proper orchestrators (Airflow, Dagster, Prefect to name a few), transformation systems (Spark/Ray, Warehouses, etc), and if you wanted to, 'accessory systems' like Kafka and vector extensions to common DBs since you mentioned Postgres and ML/AI. To be clear, I don't think you ever need all of them. Each shop has, unfortunately in many cases, so many options that you'll be unable to really cover everything. If you did, say, an example of streaming some mock data (or real if you can get it) into Kafka and using the operators in Airflow to do some light filtering and dropping that in like TimescaleDB (a PG extension for time series), you'll have enough to go on to speak about the topics of orchestration, real time workflows, and useful DB system choices if you spend the time!\n\nOn the other hand you mentioned the transition from Orchestrating ML workflows as a DE to going to creational ML workflows as an MLE. I don't think the transition is impossible, but I will say it's difficult. When I/my company looked for MLEs we specifically waited for very skilled candidates. Many applicants were trying to make the same transition you're mentioning but the reality is the skills are harder to obtain or practice on your own than SWE or DE skills. Hell I positioned myself to at least cross-train for it to fill the gap while we waited, but I was ultimately turned down. That's all anecdotal. MLE is a bit of a hot job right now, so you will definitely have competition up and down the skill spectrum and there are only so many positions to go around. \n\nOtherwise yeah soft skills like another commenter said. If you do a personal experimentation project, practice documenting it like it was going to be used by other engineers and was production-ready. Social skills, communication skills, etc. are never bad things to take on!",
          "score": 15,
          "created_utc": "2026-02-25 20:06:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7e1au6",
              "author": "Patrick_Gently",
              "text": "Thanks for the pointers! I'll dig into what you've mentioned. And totally agree on the soft skills - wouldn't want to be advertising myself with an undocumented mess in my portfolio lol.\n\nHow come MLE is harder to learn on your own out of interest? Is it a scale thing?",
              "score": 1,
              "created_utc": "2026-02-25 20:19:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7fhcw4",
                  "author": "Cloudskipper92",
                  "text": "Yeah mostly a scale thing. Also that the tools MLEs would use require both scale to show effective use cases and are either quite expensive generally or hard to set up for personal trials. It's all up to your drive though, in the end!",
                  "score": 2,
                  "created_utc": "2026-02-26 00:41:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7gx8f7",
          "author": "Able-Term-1689",
          "text": "Data modeling basics ie. 3NF and normalization vs data warehouse (star schema, dimensional, etc...)\n\nNot exciting in an interview or on a resume, but feel it's vital to create robust solutions aka actually be good at data engineering.\n\nFeels like 90% of my data issues are because of poor designed tables.\n\nData issues because 3NF wasn't used.\nExisting data model pigeon holes us so can't build on existing framework.\nBad data types so can't index properly or bad data allows (ie dates as strings).\nHave to query 10 tables to answer 1 basic question because data is spread out for no reason\n",
          "score": 9,
          "created_utc": "2026-02-26 06:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fyce1",
          "author": "onestupidquestion",
          "text": "1. If you don't already know how to use AI tools in your workflow, that's an easy start. Learn about strengths and weaknesses of the available models, configuration and setup, prompt engineering, and context management\n2. Get familiar with streaming architecture. Kafka is still the gold standard for event delivery, and you have a few different choices for processing engines and interfaces: Flink, Spark Streaming, Kafka Streams, and Beam, to name a few\n3. Learn about the metadata management, from data catalogs to lineage tooling. GenAI requires context to function properly, so this isn't just documentation your data consumers will ignore\n4. If you're more on the analytics end, semantic layers are becoming hot again for much the same reason as metadata management. If metadata gives GenAI asset discoverability, semantic layers help it understand how to use the assets it finds",
          "score": 5,
          "created_utc": "2026-02-26 02:17:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7e5b8j",
          "author": "KookaB",
          "text": "Spark and Kafka. Look at job postings, everyone wants those.",
          "score": 12,
          "created_utc": "2026-02-25 20:38:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ea6kq",
              "author": "Efficient_Shoe_6646",
              "text": "I think this is kind of short term. \n\nSpark and Kafka both are JVM based and where moving more and more towards languages that prioritize vectorized operations. Not necessarily ease of distribution. \n\nI have a feeling the future will look more like:\n\n\\- Clickhouse\n\n\\- DuckDB\n\n\\- Snowflake\n\n\\- Kafka operates kinda outside of the ETL stack, but I think a lot of companies are trying to reduce their complexity there. Like Fivetran, Airbyte and dlt. Database replication. Queueing. Streaming. etc.\n\nI would suggest: \n\n\\- Learn the problems these solutions are trying to solve.\n\n\\- Learn how these technologies work and how to interact with these API's.",
              "score": 14,
              "created_utc": "2026-02-25 21:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7f271d",
                  "author": "Aggressive_Sherbet64",
                  "text": "Don't forget sail!",
                  "score": 1,
                  "created_utc": "2026-02-25 23:17:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7gq7s1",
          "author": "pradeep_muppana",
          "text": "RemindMe! 5 days",
          "score": 2,
          "created_utc": "2026-02-26 05:11:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7gqbv7",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 5 days on [**2026-03-03 05:11:24 UTC**](http://www.wolframalpha.com/input/?i=2026-03-03%2005:11:24%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1ren5fc/what_kinds_of_skills_should_i_be_working_on_to/o7gq7s1/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1ren5fc%2Fwhat_kinds_of_skills_should_i_be_working_on_to%2Fo7gq7s1%2F%5D%0A%0ARemindMe%21%202026-03-03%2005%3A11%3A24%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201ren5fc)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-26 05:12:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ht207",
          "author": "Thinker_Assignment",
          "text": "Ontology driven data modeling",
          "score": 2,
          "created_utc": "2026-02-26 10:57:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gr0ka",
          "author": "dev_lvl80",
          "text": "As usual:\n \n\nAss  licking\n\npython \n\nsql\n\nA bit ai\n\nAss l… just reminder the higher you go, this is key for next step.\n ",
          "score": 2,
          "created_utc": "2026-02-26 05:17:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dq041",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-25 19:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h2kb1",
          "author": "Own-You1124",
          "text": "Following",
          "score": 1,
          "created_utc": "2026-02-26 06:49:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hbzlz",
          "author": "icryinmysleep12",
          "text": "RemindMe! 2 days",
          "score": 1,
          "created_utc": "2026-02-26 08:14:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7i9yi3",
          "author": "[deleted]",
          "text": "I think understanding some foundational concepts like row based storage vs column based storage, data modelling, and orchestration will take you a long way. There will always be new tools coming up. But if you build a good foundation on concepts, tools will just be a means to an end. You will build scalable and tool agnostic solutions.",
          "score": 1,
          "created_utc": "2026-02-26 13:03:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7igc4b",
          "author": "CautiousChicken5972",
          "text": "RemindMe! 2 days",
          "score": 1,
          "created_utc": "2026-02-26 13:40:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7q2kwp",
          "author": "AssistanceCold8411",
          "text": "Remindme! 2 days",
          "score": 1,
          "created_utc": "2026-02-27 16:23:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7du7dj",
          "author": "LoudSphinx517",
          "text": "follwoiing",
          "score": 1,
          "created_utc": "2026-02-25 19:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7e5bef",
          "author": "SubjectWitty9612",
          "text": "Following",
          "score": 0,
          "created_utc": "2026-02-25 20:38:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7egxyb",
              "author": "Kaze_Senshi",
              "text": "Following skill isn't so useful for data engineers 🤔",
              "score": 3,
              "created_utc": "2026-02-25 21:32:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7eocsr",
                  "author": "f00dot",
                  "text": "Following the data usually is how debugging works",
                  "score": 1,
                  "created_utc": "2026-02-25 22:07:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rf4cxi",
      "title": "Life before LLMs",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/r4tsphz1qslg1.jpeg",
      "author": "soluto_",
      "created_utc": "2026-02-26 08:02:02",
      "score": 76,
      "num_comments": 8,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rf4cxi/life_before_llms/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7i8lb2",
          "author": "seaefjaye",
          "text": "Nostalgia is great, but don't get lost in it. If there is one certainty with this career it's that things are going to change, sometimes intensely. I've been doing this for 20 years, and I'm sure there are folks here who have been doing this longer. How you adapt to these changes over your career is what makes or breaks it for most of us.",
          "score": 33,
          "created_utc": "2026-02-26 12:54:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ifs46",
              "author": "The-original-spuggy",
              "text": "It's like looking back at people in the 90s who couldn't understand what an email was. Oh how naive we were\n\n[https://www.youtube.com/watch?v=UlJku\\_CSyNg](https://www.youtube.com/watch?v=UlJku_CSyNg)",
              "score": 11,
              "created_utc": "2026-02-26 13:37:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7mp0tu",
              "author": "soluto_",
              "text": "Yeah I know! It’s just crazy to me, like before I had to sometimes get harsh comments online with my stupid questions (totally my fault btw) haha and how different life is now. It’s more of a reflection how far we’ve come",
              "score": 1,
              "created_utc": "2026-02-27 02:22:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pcc2o",
                  "author": "amm5061",
                  "text": "It's people like you who actually asked the stupid questions that enabled people like me to Google the answers. Thank you for your service.",
                  "score": 3,
                  "created_utc": "2026-02-27 14:13:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pc3ko",
              "author": "amm5061",
              "text": "I think doing it for so long is really the biggest indicator that we have been able to adapt to the changes as the come.  I'm coming up on 20 years myself at this point, and it's pretty ridiculous how much I've done that would be considered obsolete now.\n\nIt's also depressing how many times people come to me with problems that start with: \"Okay, so we have this Access database....\"",
              "score": 1,
              "created_utc": "2026-02-27 14:12:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mrghh",
          "author": "solo_stooper",
          "text": "Cant believe we wasted years of our lives in these trivial questions, lol!",
          "score": -1,
          "created_utc": "2026-02-27 02:36:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n46ao",
              "author": "soluto_",
              "text": "I wouldn’t call them trivial at the time. The python package I was using at the time is fairly new, so not much resources. Also, the creator of the package himself usually replies at that time!",
              "score": 1,
              "created_utc": "2026-02-27 03:53:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rdf9gk",
      "title": "Dev, test and prod in data engineering. How common and when to use?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rdf9gk/dev_test_and_prod_in_data_engineering_how_common/",
      "author": "No-Buy-3530",
      "created_utc": "2026-02-24 12:44:47",
      "score": 67,
      "num_comments": 69,
      "upvote_ratio": 0.95,
      "text": "Greetings fellow data engineers!\n\nI once again ask you for your respectable opinions. \n\nA couple of days ago had a conversation with a software engineering colleague about providing a table that I had created in prod. But he needed it in test. And it occured to me that I have absolutely no idea how to give this to him, and that our entire system is SQL server on prem, SQL server Agent Jobs - all run directly in prod. The concept of test or dev for anything analytics facing is essentially non-existent and has always been this way it seems in the organisation. \n\n  \nNow, this made me question my assumptions of why this is. The SQL is versioned and the structure of the data is purely medallion. But no dev/test prod. I inquired AI about this seeming misalignment, and it gave me a long story of how data engineering evolved differently, for legacy systems its common to be directly in prod, but that modern data engineering is evolving in trying to apply these software engineering principles more forcefully. I can absolutely see the use case for it, but in my tenure, simply havent encountered it anywhere.\n\n  \nNow, I want my esteemed peers experiences. **How does this look like out there \"in the wild\". What are our opinions, the pros and cons, and the nature of how this trend is developing.** This is a rare black box for me, and would greatly appreciate some much needed nuance. \n\n  \nLove this forum! Appreciate all responses :)\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rdf9gk/dev_test_and_prod_in_data_engineering_how_common/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o74lmva",
          "author": "reditandfirgetit",
          "text": "The answer is always. Even if it's the same server and different instances. At the very least, test and product.\n\nIn 20+ years I've only been at one place that did not have 3 environments",
          "score": 80,
          "created_utc": "2026-02-24 12:50:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74on05",
              "author": "quackduck8",
              "text": "In my organisation, I can't test certain KPIs with data from the dev environment, because it's not realistic enough.",
              "score": 17,
              "created_utc": "2026-02-24 13:08:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o74swbt",
                  "author": "reditandfirgetit",
                  "text": "So you can't look over the raw data to verify your calculation is correct?\n\nEdit: dev is generally for ensuring your process works, test is for making sure it's right. Thats generally how i work",
                  "score": 24,
                  "created_utc": "2026-02-24 13:33:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o767krk",
                  "author": "limeslice2020",
                  "text": "We use DBT and when we make changes to a model then we can defer the input state to pull from Prod data and then run the model and have it's outputs go to a dev schema. This lets us make model sql changes and validate our results against prod data before going to review.",
                  "score": 5,
                  "created_utc": "2026-02-24 17:35:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o74twxy",
                  "author": "Infinite_Team_9677",
                  "text": "Can't you copy data from production to test by masking it or doing limited randomization?",
                  "score": 3,
                  "created_utc": "2026-02-24 13:39:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7swd1o",
                  "author": "Blitzboks",
                  "text": "IME, this is the most common scenario. Of course there are AT LEAST dev and prod, hopefully test. But good luck having them actually serve all your dev needs because the data on dev is probably too old",
                  "score": 2,
                  "created_utc": "2026-02-28 01:04:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7528nm",
                  "author": "MrMisterShin",
                  "text": "Do you mean the volume of data or are you referring to something else?",
                  "score": 1,
                  "created_utc": "2026-02-24 14:23:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o79kdgu",
              "author": "doryllis",
              "text": "“Every company has a dev environment, sometimes they also have a separate prod environment”-I don’t remember where I heard this.\n\n\nI swear, sibling in data, get yourselves managed code, source control, automated rollouts, and for the love of your brain’s (and company’s stability) a test/dev environment. \n\nIf you are feeling super happy, write something to simulate data too. If you are unable to do that a “staging” that clones prod data so devs aren’t taking out prod when they test is still better than nothing.",
              "score": 4,
              "created_utc": "2026-02-25 03:42:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76eiau",
              "author": "Gadion",
              "text": "We're too agile to have more than 1",
              "score": 0,
              "created_utc": "2026-02-24 18:06:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76j7m5",
                  "author": "reditandfirgetit",
                  "text": "Thats not Agile, it's irresponsible",
                  "score": 4,
                  "created_utc": "2026-02-24 18:27:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o74x0e3",
          "author": "BardoLatinoAmericano",
          "text": "Dev exists so no one says \"but it works in my pc\"\n\nTest exists so you can tell users they approved the changes before they went to prod.\n\nProd is prod.\n\n(By this definitions, Dev and Test can be the same, but I prefer to separate so Test will be cleaner)",
          "score": 25,
          "created_utc": "2026-02-24 13:55:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o759y06",
          "author": "PushPlus9069",
          "text": "tbh this is way more common than people admit. at a large ecommerce company I worked at, the analytics team ran everything straight in prod for almost two years. what finally forced the change was someone running a bad join that broke a dashboard right before an exec review lol. after that we got a staging environment real quick.",
          "score": 11,
          "created_utc": "2026-02-24 15:02:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74lopf",
          "author": "vikster1",
          "text": "always use dev/uat/prd. always. this is professional. everything else is winging it. learn some dbt. it makes it much easier to have multiple environments.",
          "score": 34,
          "created_utc": "2026-02-24 12:50:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o752xkc",
              "author": "domscatterbrain",
              "text": "Since we're here talking about data and the data in prod is always wild, having multiple environments to develop pipelines is hard and very costly.\n\nEven after using sampling from prod to test in uat/stg env, the chance of getting a surprise hot fix is still high after it deployed in prod.\n\nEpecially when we involving DBT. As per standard in my team here, we do develop and test with different target switch for dev. We don't have uat and the dev is in the same real environment with production. We do that to have clear view to how it will behave with actual data. To safeguard the load, the dev target strictly set with single thread only and the role is it only can read from tables in prod schemas but only write in a single shared dev schema.",
              "score": 5,
              "created_utc": "2026-02-24 14:27:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75752d",
                  "author": "vikster1",
                  "text": "it's not. read about zero copy cloning in snowflake.",
                  "score": 4,
                  "created_utc": "2026-02-24 14:48:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75c8oc",
          "author": "MikeDoesEverything",
          "text": ">our entire system is SQL server on prem, SQL server Agent Jobs - all run directly in prod.\n\nThis is a war crime.\n\nSerious answer: if your team has more than one person and you need to serve it to people other than yourself, an extra environment where you don't have to basically deploy to prod and hope it works is a god send.  Prod only where you have customers who rely on prod being up is a war crime either waiting to happen or already in progress.\n\nSomewhere I have worked was \"prod only\".  No source control or anything, so we introduced it.  Before, it was literally \"send to prod and see if it catches fire\".  After, it was \"send it to test and see if it catches fire\".\n\nStill had that one guy who said \"I'm only making a small change so I'm committing to main directly\".  Told them to branch and make PRs. Literally has never had a single PR which hasn't had a merge conflict.  Guy with \"two decades of experience\", btw.",
          "score": 6,
          "created_utc": "2026-02-24 15:13:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74rtc2",
          "author": "Murky-Sun9552",
          "text": "Yeah this is more common than you would think although in my experience as a 13yo DE veteran it has evolved to the following :\n\nthe modern data warehouse / data mesh structure has versioning built in, in my stack we have ingestion into S3 where the raw immutable data is stored(this is ingestion tested but structurally immutable) we then have a raw staging layer (QA tested against obvious datatype misconfiguration) in the DWH which is now available for transition and interrogation by the next layer. next is the SL2 or F/D layer where we run QA tests and produce a working Fact/Dimension layer that creates the Kimball structure, then a G1 or gold layer that has a domain led curated approach with query optimised views (this is the only layer that runs through CI/CD checks as it is officially prod ready). \n\n  \nThe modern data architecture differs from the older legacy architecture in the way that it only treats the semantic layer G1 as a prod layer, even though the previous layers are in prod and allows for a lightweight downstream EOP product that significantly reduces report load times by normalizing the data upstream and reducing the cannibalisation rate upstream.",
          "score": 6,
          "created_utc": "2026-02-24 13:27:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74y9jy",
              "author": "wallbouncing",
              "text": "do you have test/prod at the G1 layer ? are these in different systems altogether or different schemas / views ?  Where do you create views or updates for the next iteration",
              "score": 1,
              "created_utc": "2026-02-24 14:02:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o74zp0i",
                  "author": "Murky-Sun9552",
                  "text": "we have testing at increasing levels that are linked to the layers, they are all in one Lake/Mesh. The final semantic layer is the G1 layer, that is where we create the views which are then parsed through the final testing pipeline. This is robust and test the final output as this is the one with operational data being consumed.",
                  "score": 1,
                  "created_utc": "2026-02-24 14:10:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o74m632",
          "author": "Repulsive-Beyond6877",
          "text": "Dev and Prod are always.\n\nTesting can be done in all environments, just make sure that area doesn’t have PII/SPII exposed.\n\nFrom your description it sounds like analytics is being run on customer data? \n\nIf he/she has a test server or environment you can make a read replica or a view of the data there depending on how things are structured.",
          "score": 5,
          "created_utc": "2026-02-24 12:53:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74r0pb",
          "author": "GodfatheXTonySoprano",
          "text": "Can someone explain how TB scale data is tested? I mean for SWE they test a particular feature , but in DE we have TB scale dataset for which test like querying would add so much cost.\n\nOr people have a small subset of original data which they test?",
          "score": 4,
          "created_utc": "2026-02-24 13:22:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74mng9",
          "author": "loudandclear11",
          "text": "Are you developing in prod?\n\nYes, I have worked in such environment and every fiber of my being screams that it's wrong.",
          "score": 6,
          "created_utc": "2026-02-24 12:56:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o751vew",
          "author": "PrestigiousAnt3766",
          "text": "Always.\n\nThis was different in 2010. But we have advanced quite a bit as a field since then.\n\nIf your modern data platform doesn't have it, it's time to migrate imho.",
          "score": 3,
          "created_utc": "2026-02-24 14:21:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o761ly4",
          "author": "BadKafkaPartitioning",
          "text": "When I tell people that Data Engineering as a discipline is still very immature, these are the kinds of things that I gesture towards.",
          "score": 3,
          "created_utc": "2026-02-24 17:08:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7anovo",
          "author": "BuildingViz",
          "text": "We run Prod, QA, and Dev. Dev is basically, \"I can do whatever I want.\" Schemas and pipelines are fluid for testing and building things out. The dataset is smaller and frequently gets destroyed and rebuilt from scratch.  QA is for the engineers to test their frontend/backend code against. This schema and pipelines are in source control, but I have a lot of leeway to make changes. The dataset is also just as complete as Prod. Prod is the functional environment for external customers to access. Again, all under source control with a lot more guardrails around data and code changes compared to QA.\n\nAs a best practice, no changes should go directly to prod except for *maybe* emergency fixes. Even then, QA first would be preferred. Because what you definitely don't want to do is make a change to Prod that breaks things. Because if you have customers and SLAs, when they ask, \"How did this bug get into production?\", the last thing you want to say is \"Because that's the only env we have and we didn't properly test it.\"",
          "score": 3,
          "created_utc": "2026-02-25 08:54:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74m2z2",
          "author": "bacondota",
          "text": "We had an analytics db but every project had some test schema. Only after everything was validated we pushed it to prod that would then write to the right schema (information dominion? Don't know the term in english)\n\nAnalytics db had copies of the \"system prod db\" but there was no system writing to it, so it could be down without affecting operations. So it was kinda of a mix. No separate db for dev/test, only separate schema.",
          "score": 2,
          "created_utc": "2026-02-24 12:52:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75cxx3",
          "author": "dadadawe",
          "text": "Always for DE\n\nSometimes for analytics\n\nRarely if the customer can't tell the difference between both",
          "score": 2,
          "created_utc": "2026-02-24 15:16:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76dmca",
          "author": "KazeTheSpeedDemon",
          "text": "Small company but we just have prod and are hoping to get dev and prod setup in the next year. To be honest we haven't had issues but we know it's best practice to do this! It is a bit embarrassing if we get something wrong in prod but the reality is we'd probably get it wrong in dev AND prod because normally a stakeholder will raise an issue when looking at prod.\n\nFor big companies with thousands of procedures obviously this wouldn't fly!",
          "score": 2,
          "created_utc": "2026-02-24 18:02:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76ptb9",
          "author": "No-Buy-3530",
          "text": "Some great comments here pointing in a singular direction. \n\nFor clarification, we are a legacy company, on prem, where all prior analytics work has been done by external consultants, and it’s a one mans show (my show) from architecture to analytics. My main priority has been to stabilise this foundation and deliver small tactical wins to get leadership buy in. \n\nThe next step is obviously clear as day, and I thank this community for their valuable responses",
          "score": 2,
          "created_utc": "2026-02-24 18:56:38",
          "is_submitter": true,
          "replies": [
            {
              "id": "o7fdhbf",
              "author": "Table_Captain",
              "text": "What tech stack are you all using?",
              "score": 1,
              "created_utc": "2026-02-26 00:19:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o78sb5f",
          "author": "Equivalent_Quit_1223",
          "text": "Look up dbt-sqlserver package. I was also on a sql server database (azure sql server) and the dbt-sql-server community adapter dbt core version allows you to very easily use software engineering best practices (like git, trunk based feature development, different envs, etc.). The dbt labs documentation is so thorough and easy to read. Without any prior git / dbt experience it may take 1-2 weeks to get used to but after that the productivity you get is well worth the investment. Also look up kimbal dimensional modeling if you are unfamiliar with that, which is arguably as important if not more important than dbt and git.",
          "score": 2,
          "created_utc": "2026-02-25 01:02:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7d9gwf",
          "author": "blobbleblab",
          "text": "While this is reasonably common, it's a real problem. It won't look like a problem until something bad happens, some untested piece of code (which sounds like everything) blows up business critical things.\n\nYou have identified it as being bad. Great first step, many don't come to this realisation until after everything has blown up.\n\nSo I will give you advice having done this heaps of times for businesses, without mentioning technology. What you need to do is figure out how to move forward. Usually step one is to realise that the code running your systems IS DIFFERENT to the data. Once you have realised this you can take steps to master that code in a source code repository. Do this from production, then work on making the connections to your database within the code variables.\n\nOnce you have connections as variables, you can then stand up a new server/endpoint system and call it test. Now using a deployment tool, attempt to build your database and deploy the build into test, using the dynamic connections variable for test. This will take a lot of trail and error to get right. At the end you want an empty database that looks just like production. Note you can also make the database name a variable too, adding the environment on the end (name_test) for extra points and future proofing. \n\nNext do the same but for a dev instance. This should now go a lot smoother, but because of the time taken, prod code base has likely drifted from test and dev. That's OK, you need to download prod again and get your source control to compare prod with old dev. You will see the changes. This is called database drift. \n\nNow you have to get any changers to be synced to dev. Software helps to do this, essentially writing change scripts based on the difference and applying them. This will need to be tweaked but there is plenty of software to help with this.\n\nNow comes one of the hardest parts. You have to get the people using the product to shift their mindset to commit to only developing in dev, allowing the pioeline you have made to be _the only thing_ that is allowed to make prod changes. Lots to cover here, you will need to present why, risks, development flow, branching strategy, lots to think about.\n\nOnce you get this all over the line, you need to establish what type of data you want in each environment. Sometimes people want prod in every environment and if data security is the same on each, you can get away with restoring prod regularly to other environments, but that cones with problems, active dev or test changes may be overwritten, so you need to think about it.\n\nBest is to have cut down prod data in test and synthetic data in dev.\n\nLet us know how the journey goes!",
          "score": 2,
          "created_utc": "2026-02-25 18:12:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g6467",
          "author": "Admirable_Writer_373",
          "text": "This topic boils my blood. If you ask a team of SWEs what the various environments are for, they’ll give you a decent answer. If you ask a team of data engineers the same question, you’ll get nonsense.",
          "score": 2,
          "created_utc": "2026-02-26 03:01:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7iz6ir",
          "author": "the-wx-pr",
          "text": "Devops Eng help a lot with this. You can have at least two envs separate from each other to build your pipelines with a copy of prod data and then when youre finished then you deploy your etl package to prod",
          "score": 2,
          "created_utc": "2026-02-26 15:18:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o757qre",
          "author": "ManufacturerWeird161",
          "text": "On my last gig we only had prod, and it was a constant headache. We eventually built a test env by restoring last quarter's prod data and it saved our butts so many times for testing transformation changes.",
          "score": 1,
          "created_utc": "2026-02-24 14:51:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o759pm4",
          "author": "Successful-Daikon777",
          "text": "Make sure your test environment actually mimics the prod environment to a sensible degree.",
          "score": 1,
          "created_utc": "2026-02-24 15:01:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75nxw2",
          "author": "here_n_dere",
          "text": "I found this to be true for my situation as well. I would attribute a lack of dedicated dev and test pipelines and Datasets to couple of arguments (can't advocate enough myself to at least have physical isolation for compute and storage at least, ETL etc would surely need some mechanism as well) -\n1. no use case served by maintaining a copy with any data, since each dataset adds 3x operational burden (quality, performance, compliance). Datasets dev / test (uat) are better shortlived and discarded by making replication and isolation easier on all fronts (separate ETL sys account adn worker queue, DB user, Schema, etc). Data lake decouples storage for cross team project dependencies like you mentioned requested of you.\n2. cost savings (1/3) resource needs\n\nNow downsides to this are as the saying goes - \"with great power..\", kill switch right besides coffee mug.. :D\n\nAlso, more pain for developers in dev test setup, being manual (unless automated via tools/scripts), while CI/CD like in software pipelines would ease life and standardize stuff across teams (fast paced teams and business priorities often also demand cutting corners here I would assume)..",
          "score": 1,
          "created_utc": "2026-02-24 16:07:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79x99h",
          "author": "Winterfrost15",
          "text": "Dev and Prod always. Test, if needed and not too much control restrictions over it.",
          "score": 1,
          "created_utc": "2026-02-25 05:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7amvei",
          "author": "marranator91",
          "text": "Opinions are very unanimous, it would be good if you set up at least dev. \n\n\nCheck zero copy mechanisms when you are setting the dev and test environments to avoid replicating stuff unnecessarily.\n\n\nDbt or sqlmesh too",
          "score": 1,
          "created_utc": "2026-02-25 08:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74wxki",
          "author": "bucobill",
          "text": "Why does this question feel like the responses are just going to be used to train AI?",
          "score": 0,
          "created_utc": "2026-02-24 13:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o752lir",
              "author": "MilwaukeeRoad",
              "text": "Is that not literally every post on Reddit?",
              "score": 4,
              "created_utc": "2026-02-24 14:25:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rfhg8b",
      "title": "Breaking Into FAANG",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rfhg8b/breaking_into_faang/",
      "author": "Serious-Jury8464",
      "created_utc": "2026-02-26 18:03:15",
      "score": 62,
      "num_comments": 32,
      "upvote_ratio": 0.86,
      "text": "Hey all,\n\nLooking for some advice on any programs or resources that could be helpful for anybody who has experience getting a job at a FAANG or equivalent company.\n\nSo just for some background, I’ve been doing DE for about almost 10 years.  I’ve mainly worked at startups in the Denver Metro area.  I’ve definitely had a good experience and learned a lot, but I don’t have a traditional CS background. I’m a staff level data engineer as of now and my TC is around 200k.\n\nI’m really trying to put the resources into getting into one of the big tech companies as I stated. I am looking for any programs or resources anyone found useful in when obtaining these roles.  I do thrive under structure when learning so I am definitely open to some sort of program even if it’s self-guided and I’m definitely willing to sink some money into this. \n\nAppreciate any feedback I could get, thanks so much.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rfhg8b/breaking_into_faang/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7jz0kw",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-26 18:03:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lbl5n",
          "author": "randomuser1231234",
          "text": "Ex-FAANG, you couldn’t pay me enough to go back. There is not enough money on the planet.\n\nI’m going to give y’all the advice I was given and didn’t take to heart before I started — they pay you that much because when you burn out, you’re going to need at LEAST a year off work entirely before you can make your brain understand code again.",
          "score": 52,
          "created_utc": "2026-02-26 21:52:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lrxjz",
              "author": "Dunworth",
              "text": "Not ex-FAANG, but after working with a bunch of people who are, I wholeheartedly agree with you. All of them were super bright, but completely dead on the inside. They all stuck with us for a little over a year, and the second that they didn't feel burnt out anymore, they were off to something more challenging.",
              "score": 13,
              "created_utc": "2026-02-26 23:15:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7lo0z8",
              "author": "543254447",
              "text": "Meta or amazon？",
              "score": 6,
              "created_utc": "2026-02-26 22:54:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7w88w8",
              "author": "bkl7flex",
              "text": "Man, yes. At best work at big tech that's more relaxing. We had a saying \" working 1 year here equals to 3 years of civilian life\". Worked for around 3 years, learned an awful lot but it feels like you're in a time machine but looking back I'm kinda glad I did as getting interviews ever since has been easier and makes negotiating a lot easier.",
              "score": 2,
              "created_utc": "2026-02-28 15:45:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7kc6oz",
          "author": "henryofskalitzz",
          "text": "It's much easier than you think. I cannot speak on senior interviewing but I've passed midlevel interviews for Google, Meta, and Microsoft for DE roles in the past year and they all ask pretty similar questions. The most challenging part for the vast majority of applicants is even landing an interview.\n\nBe strong on:\n\n1. Behavioral \n\n2. SQL (Hard - Very Hard)\n\n3. Leetcode (Easy-Medium)\n\n4. Architecture (Lambda / Kappa) OR Data Modeling - usually companies ask one or the other\n\n  \nBehavioral gets underrated a LOT. I once had a MS DE loop where they asked zero SQL / Python and basically 3 rounds behavioral and 1 architecture. HMs love it when you can explain high impact projects you've worked on (both technically and business value wise).\n\nI also think the scope of work for a DE in FAANG companies are generally quite limited. In Meta / Google in particular most DE work is more akin to a Analytics engineer where you're spitting and shitting out SQLs all day. Microsoft / Amazon is a mixed bag in that regard",
          "score": 62,
          "created_utc": "2026-02-26 19:03:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7kq9ct",
              "author": "SentinelReborn",
              "text": "Google? I didn't think they had DEs",
              "score": 7,
              "created_utc": "2026-02-26 20:10:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7kqvbm",
                  "author": "henryofskalitzz",
                  "text": "They do, but the vast majority are more like customer data engineers where they work with outside clients integrating with Google cloud services. I got quite \"lucky\" in finding a DE team that reported internally",
                  "score": 13,
                  "created_utc": "2026-02-26 20:13:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ki9nw",
              "author": "dresdonbogart",
              "text": "Do you have any resources to learn/up-skill data modeling skills?",
              "score": 3,
              "created_utc": "2026-02-26 19:32:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7kr0mg",
                  "author": "henryofskalitzz",
                  "text": "first few chapters of the data warehouse toolkit",
                  "score": 10,
                  "created_utc": "2026-02-26 20:14:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7mees9",
              "author": "BeeLive9842",
              "text": "Would you be open for a DM?",
              "score": 1,
              "created_utc": "2026-02-27 01:20:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nrqv4",
              "author": "One_Citron_4350",
              "text": "For the FAANG, the more interesting work is for SWEs? I assume they built their own internal tools for data but someone has to maintain it, right?",
              "score": 1,
              "created_utc": "2026-02-27 06:45:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ko20c",
          "author": "Eleventhousand",
          "text": "I can't tell you about all FAANGs, but when I interviewed at Amazon, they cared a lot more about behavioral skills and stories about making an impact over your career.  The technical and architecture stuff was easy.  I wouldn't recommend working there though, it kind of drains your life energy.  Maybe decent for younger folks who don't mind working non stop.",
          "score": 14,
          "created_utc": "2026-02-26 19:59:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lalat",
          "author": "james2441139",
          "text": "Ex-FAANG here (left FAANG 2 years ago voluntarily after RSU matured). IF you can get an interview (hardest part of the job hunting process now): leetcode medium to hard, SQL hard (focus on different types of joins), Kimball modelling book, good Spark knowledge. Some infra questions are also sometimes asked. Also, behavioral is very important from mid to senior roles.",
          "score": 13,
          "created_utc": "2026-02-26 21:47:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mf97y",
              "author": "BeeLive9842",
              "text": "Should I do sql on leetcode or should I do on strata scratch or similar?\n\nAlso what kind of behavioural should I expect? Can you share Any examples? \n\nAlso what’s the best approach to even get interviews? I never get reached out by big companies",
              "score": 1,
              "created_utc": "2026-02-27 01:25:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mbq6p",
          "author": "pimpsmackula",
          "text": "As someone there now, don’t.",
          "score": 7,
          "created_utc": "2026-02-27 01:05:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pksof",
              "author": "0sergio-hash",
              "text": "Why not?",
              "score": 1,
              "created_utc": "2026-02-27 14:58:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pq8vw",
                  "author": "pimpsmackula",
                  "text": "Ton of pressure to ramp up ASAP and produce impact coupled with AI hype driving unrealistic expectations of output just makes this a really difficult time to be a new joiner in FAANG. It’s kind of manageable for people familiar with the game but especially awful for new people.",
                  "score": 4,
                  "created_utc": "2026-02-27 15:24:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7kk7ga",
          "author": "jadedmonk",
          "text": "Main prep for interviewing at those companies is leetcode - you should master all of the hardest SQL leetcode questions, and all easy/medium python question",
          "score": 4,
          "created_utc": "2026-02-26 19:41:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mp5zx",
          "author": "newredditacctj1",
          "text": "15 year in analytics at faang here. Agree with Henry. Landing interview right now specifically is really hard, but if you can get a referral it is a breeze. So if you’ve worked with anyone there, that’s your first stop.\n\nBeyond his comment, crank some on leetcode. There are also some streams , influencers, camps that might help many people but if you have 10 YOE, not a good fit for you IMO.\n\nAlso agree with some comments it is a mixed bag working there. Money is great but stress is high.",
          "score": 4,
          "created_utc": "2026-02-27 02:23:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7k4qdd",
          "author": "MrNoSouls",
          "text": "It's rough, but personally I stopped trying to join them once I found out they are all involved with Epstein.\n\nI got interviewed with both Microsoft, Meta, I hard no to Amazon/AWS. Now looking back the best misses I have ever done. Even if I got a job with them what is the point if they lay off the teams in 3 months?",
          "score": 21,
          "created_utc": "2026-02-26 18:29:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7kf8wr",
              "author": "Nekobul",
              "text": "I agree. I don’t want to work for these cannibals either.",
              "score": 13,
              "created_utc": "2026-02-26 19:17:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ljuzl",
          "author": "clutchkobe24",
          "text": "Best of luck to you! I would make sure you are clear on why you want to join and whether it is worth it before you go down this path. I joined faang as a senior de within the last year and regret it. The WLB, stress, and overall toxic environment are not worth the increase in pay/prestige for me. \n\nEveryone has different experiences though and I’m sure there are good situations out there. I would just make sure this is actually something you want before taking the leap.",
          "score": 3,
          "created_utc": "2026-02-26 22:33:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nkp42",
          "author": "Parking-Mud-8328",
          "text": "Meta is the easiest FAANG to go into as a data engineer",
          "score": 2,
          "created_utc": "2026-02-27 05:48:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nxksz",
          "author": "dataenfuego",
          "text": "DE FAANG here, 7 years already, close to burnout.\n\nBut just to be helpful, lately:\n\n* domain expertise is King! I.e. ads, entertainment, personalization, finance, some travel well across domains , i.e. you’ve worked on product / member analytics.\n* python…. But some interviews are already shifting to no leetcode.. more conversationsl, case studies, open ended questions, so ideally still practice with leetcode but be ready for some real situational cases.\n* data warehousing / SQL etl\n* spark optimization situationa\n* data modeling (modern + kimball, layers, patterns)\n* soft skills are also HUGE lately\n\nSource:\nI interview twice a week in my company. \n\nI also interview in other companies to keep up. But I am exhausted so I will stop now.",
          "score": 2,
          "created_utc": "2026-02-27 07:36:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ny06j",
              "author": "dataenfuego",
              "text": "Getting that first recruiter call is usually the hardest part. Referrals help a lot, so use them whenever you can. Some FAANG companies offer referral bonuses and some don’t. For example, Netflix doesn’t pay employees for referrals that get hired.",
              "score": 2,
              "created_utc": "2026-02-27 07:40:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7piltb",
          "author": "hoxtonious",
          "text": "For someone that is still in or was in the past recent years, how are they dealing with AI-assisted coding?\nOr have their expectations changed coding-wise?",
          "score": 1,
          "created_utc": "2026-02-27 14:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7zjcay",
          "author": "Signal-Card",
          "text": "Grind LeetCode + system design, read Designing Data Intensive Apps, then spam referrals. You’re already senior enough.",
          "score": 1,
          "created_utc": "2026-03-01 02:31:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rcwoz",
          "author": "anair10",
          "text": "Is FAANG for someone looking to transition into DE ? If yes then what is the way to prepare ? What resources to use etc ?",
          "score": 1,
          "created_utc": "2026-02-27 20:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7p1qk2",
          "author": "Ok-Obligation-7998",
          "text": "You need to be a maintainer of multiple large OSS projects",
          "score": 0,
          "created_utc": "2026-02-27 13:13:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rgki1m",
      "title": "What is actually stopping teams from writing more data tests?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rgki1m/what_is_actually_stopping_teams_from_writing_more/",
      "author": "Mountain-Crow-5345",
      "created_utc": "2026-02-27 22:07:14",
      "score": 53,
      "num_comments": 45,
      "upvote_ratio": 0.76,
      "text": "My 4-hour pipeline ran \"successfully\" and produced zero rows instead of 1 million. That was the day I learned to test inputs, not just outputs.\n\nI check row counts, null rates, referential integrity, freshness, assumptions, business rules, and more at every stage now. But most teams I talk to only do row counts at best.\n\nWhat actually stops people from writing more data tests? Is it time, tooling, or does nobody \\[senior enough\\] care?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rgki1m/what_is_actually_stopping_teams_from_writing_more/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7s1zdd",
          "author": "Evilcanary",
          "text": "Writing data tests that catch actual bugs and aren’t incredibly noisy is difficult. People should write more good tests. But it’s tough and you need to have good tests at every stage, including ideally at the event/client producer level.",
          "score": 100,
          "created_utc": "2026-02-27 22:11:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7uw2ao",
              "author": "GrotesquelyObese",
              "text": "Something I have started doing is using a snapshot of data from our sources to test.\n\nDuplicate what is currently being collected. Watch it process through.\n\nObviously if you are not collecting the data then you don’t have any testing data. If possible, I start collecting potentially useful data as soon as we identify we want to utilize it.\n\nI find this to be the easiest way to manage data collection as this is one of many hats. Plus we can back date data analysis to the planning phase of a project. Bosses don’t push so hard on timelines.",
              "score": 6,
              "created_utc": "2026-02-28 10:16:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ww9x5",
              "author": "brrrreow",
              "text": "Yes the noise can be killer. I tried implementing a basic testing practice at my workplace (row count, unique/not null primary key on tables) to get us off the ground from nothing and my manager insisted we need some version of unit testing on every table too as part of the policy. \n\nJust adding tests for the sake of claiming we test has been unnecessary extra work to think of something just to check a box. Then when those tests eventually fail and break a job it turns out we actually don’t care or the dev never verified the rule was legitimate in the first place and have to go back to remove them.",
              "score": 2,
              "created_utc": "2026-02-28 17:46:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7zpeeh",
              "author": "ProfessionCrazy2947",
              "text": "Agreed, and if you scale this up across multiple pipelines and teams your compute costs can go up significantly.\n\nA lot of input tests (presuming you’re working out of a data warehouse or similar) should be tested independently for many of these items in my opinion.",
              "score": 1,
              "created_utc": "2026-03-01 03:09:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7somn7",
          "author": "SearchAtlantis",
          "text": "Literally a week ago in the *Data Quality Stack in 2026* thread you said \" — full disclosure, I co-founded DataKitchen and we built TestGen for exactly this problem.\"\n\nIs this marketing or an actual discussion.",
          "score": 85,
          "created_utc": "2026-02-28 00:18:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7sxsy1",
              "author": "ferrywheel",
              "text": "His picture tels a thousand words",
              "score": 13,
              "created_utc": "2026-02-28 01:13:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7uxtc5",
              "author": "dillanthumous",
              "text": "Lol. Nice spot.",
              "score": 3,
              "created_utc": "2026-02-28 10:33:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7u8sqk",
              "author": "IAMHideoKojimaAMA",
              "text": "Hahaha ahhh never change reddit",
              "score": 6,
              "created_utc": "2026-02-28 06:40:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7s30qi",
          "author": "kenfar",
          "text": "Lack of skill, domain knowledge, and/or concern.\n\nI like to start by defining KPIs for data quality, collect data, publish this for your customers.\n\nNext any time a data-quality incident occurs (or availability or whatever), hold an incident-review meeting.  This should be a \"blameless post-mortem\".  And at the meeting walk through exactly what happened:\n\n   * timeline with exactly what happened by who when\n   * how to prevent this from happening again?\n   * how to detect the problem earlier?\n   * how to communicate with users more quickly?\n   * how to handle incorrect data that was use and published already?\n   * how to automate any steps?\n\nReally, the first three bullets are the most important - and generally drive things like increasing test coverage.\n",
          "score": 29,
          "created_utc": "2026-02-27 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tgs1b",
          "author": "lzwzli",
          "text": "Writing tests isn't the hard part. It's deciding the operational playbook for each of the tests that gets tricky. \n\nGreat so you have 100 tests.\n\nDo you stop the pipeline if any of those fail? No? Ok, then which ones should stop the pipeline?\n\nWhat do you do with the results of the others? Send you a report? Great. \n\nAre you reading the report that is sent for every pipeline run? How do you decide which failing, non-critical test deserves action?",
          "score": 10,
          "created_utc": "2026-02-28 03:11:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7v6yag",
              "author": "Certain_Leader9946",
              "text": "you should stop everything if a critical test fails, yes. doesn't matter how much money you're losing, if you're fucking up the business in deeper less repairable ways on production (and the tests should be catchihng these issues before they hit prod).\n\nif you're going to ignore a test, you may as well have never written it.",
              "score": 1,
              "created_utc": "2026-02-28 11:55:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7wx9ja",
                  "author": "brrrreow",
                  "text": "Agree - I’ve come to stop believing in warnings! If it’s something you care about that truly impacts quality then fire the hard alert. If it’s something you can safely ignore, what’s the real threshold at which you need to care?",
                  "score": 1,
                  "created_utc": "2026-02-28 17:51:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7sya6d",
          "author": "MonochromeDinosaur",
          "text": "Input tests work, then you have GBs of fixtures you need to correct because your data source changed their schema for the millionth time \n\nAfter the data source changes out from under you for the billionth time you learn to write input schema validation, null rates, integrity etc and to error out and bail the pipeline early and often.\n\nI’d rather get a page in the middle of the night that the pipeline failed 10 minutes in than find out we got no data when everyone is trying to pull data first thing in the morning.\n\nI don’t count dbt tests in this. They don’t really count as tests IMO they’re just audit queries which I’m all for. \n\nI’m tallking about ingestion pipelines. \n\n**Edit:** This is to say I think time is better spent writing assertions and schema validation than setting up a bunch of brittle fixtures for end-to-end data tests. Unless you have the time to setup automation to refresh the fixtures but then you need to test the fixture generation and that’s a matryoshka situation.\n\nI do make unit tests for transformations and try to make all my transformation pure functions but I just use the built-in data structure and the minimum viable amount of dummy data in-line to test the behavior.",
          "score": 7,
          "created_utc": "2026-02-28 01:16:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sofqm",
          "author": "Captain_Strudels",
          "text": "> That was the day I learned to test inputs, not just outputs.\n\n> produced zero rows instead of 1 million\n\nIsnt that an output",
          "score": 4,
          "created_utc": "2026-02-28 00:17:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tej1m",
          "author": "DungKhuc",
          "text": "Testing is usually cheap but hard to cover real life scenarios, you have to build it up over time.\n\nWhat you are referring to is validation, which is not only hard, but slow and expensive. Very often teams can't afford having extensive validation steps in between stages. \n\nI'd even argue that assumptions and business rules should not be in validation, but in testing because they are known.\n\nReferential integrity is a tough one. Most modern data warehousing platform doesn't enforce it not because they can't, but because it's very expensive. You might need to evaluate if you truly want to to validate this every run or not.\n\nThe rest are just usual monitoring / observability. You shouldn't check them, but set reasonable alerts, and react when necessary.  ",
          "score": 4,
          "created_utc": "2026-02-28 02:57:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7v6zpt",
              "author": "Certain_Leader9946",
              "text": "use BDD syntax and map your tests to your user stories",
              "score": 1,
              "created_utc": "2026-02-28 11:55:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7wr3ok",
                  "author": "DungKhuc",
                  "text": "To me BDD is always wishful thinking for data engineering unless you only create simple dashboards. ",
                  "score": 1,
                  "created_utc": "2026-02-28 17:19:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7s2nc1",
          "author": "zesteee",
          "text": "I’m actually keen to hear about the tests you currently do in more detail.  For me, when I get a new data feed I import it and write all my procedures. Often it’s come as a csv file, so I literally open it in excel, and use auto-sum on the entire column, then compare that to my final table.  If it’s too big to do that, then I have to faff around a bit more, but that’s basically the gist of it.  I’m really aware that I want to be doing a better job at it, so would love to learn better techniques.  Maybe that’s the answer to your question in my case - because I haven’t come up with good ways to perform the tests. \n\nFor the record; that’s just the initial data load. Once the pipeline is in place; I have a qc table which loads figures from raw, staging, and dev tables. It compares them and notifies me of any variance. And compares against previous weeks, looking for larger than acceptable differences. And a few other checks, depending on the data, such as if a bunch of products have moved to a new category but they haven’t carried the old products with them as they’re not selling. Still important when calculating growth so I address it. \n\nBut yeah, I’d love to see how other people do their testing.",
          "score": 3,
          "created_utc": "2026-02-27 22:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7si1rh",
          "author": "rycolos",
          "text": "I’m a team of one and I’m burdened by way way too much to do and way too much data. I implement tests when I can, and generally the most important one, but definitely not on everything I’d like. Like anything, it’s a balance. ",
          "score": 3,
          "created_utc": "2026-02-27 23:40:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7s7txh",
          "author": "PrestigiousAnt3766",
          "text": "I test code.. ",
          "score": 2,
          "created_utc": "2026-02-27 22:42:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sb4vs",
          "author": "Atmosck",
          "text": "Lack of experience. Those of us who have been burned like you were with that four-hour pipeline that did nothing write data tests.",
          "score": 2,
          "created_utc": "2026-02-27 23:00:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7twych",
              "author": "Reasonable_Tooth_501",
              "text": "Exactly. You don’t realize you need them until you’ve scrambled to get shit fixed cuz things are broken and the heat is on and it’s embarrassing. \n\nThat’s when you realize oh wow it doesn’t have to be like this.",
              "score": 1,
              "created_utc": "2026-02-28 05:03:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7skhtg",
          "author": "Adventurous-Pea7776",
          "text": "Data volume and metric latency sla. Getting 3/4 of an exbibyte a day. We have validations that run after the metrics are computed, we sample some of the input in near real time.  We have anomaly detection on key attributes of the incoming and produced data. At this volume some of the data is always bad. We have experienced cases of nafarious actors injecting welformed data but real data.  We have seen cases of data corruption in mass because a bad batch of memory in certain class of device which we detected before the manufacturer. \n\nIs too slow and too expensive, we can measure a select subset of the data before that at least notifies us something may end up being wrong or bad, we evaluate input data after the fact to train our anomaly detection and provide data for any investigation into issues.  \n\n\nWe have extensive test datasets and do back testing on on pipeline deployments. So if it is a production pipeline a very bad outcome like 0 rows is near impossible ( if I was on call this week that near impossible event would happen tonight, but I'm not on call). I tell our new hires and interns.  At our volume something that is 1 in a billion will happen several times a day, so if it can happen, it will happen  so plan for the possibility. one funny example is the framework we were using did not include North Korea as valid iso country code. We ought that in test because we used the list of iso choices from the iso docs not from the framework docs. Then we checked and even though we should not be getting data from north Korea we actually were getting a little bit on and off.  \n\nThat's why we don't test our data fully.  \n\n\nBigger question though why does it take 4 hours for a pipeline of the size you referenced?",
          "score": 2,
          "created_utc": "2026-02-27 23:54:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7sl9kw",
              "author": "angur0807",
              "text": "What industry are you where you have that much come in a day? Your storage and compute costs must be through the roof for that amount",
              "score": 1,
              "created_utc": "2026-02-27 23:58:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7srtb9",
              "author": "sHORTYWZ",
              "text": "holy crap, how much data are you actually retaining at that scale of ingestion?",
              "score": 1,
              "created_utc": "2026-02-28 00:37:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7t0hlu",
          "author": "calimovetips",
          "text": "it’s usually ownership and incentives, nobody wants to be on the hook for flaky tests or spend sprint time on “no new features.” also a lot of teams don’t have stable expectations, schemas and upstream logic shift, so tests rot fast unless you budget time to maintain them.",
          "score": 2,
          "created_utc": "2026-02-28 01:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sbbyr",
          "author": "rarescenarios",
          "text": "For my team, the value of most input checks just isn't there in advance. We add another one every time upstream data problems break one of our pipelines.",
          "score": 1,
          "created_utc": "2026-02-27 23:01:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sme8m",
          "author": "Table_Captain",
          "text": "We use a mixture of data tests and unit tests in dbt and Monte Carlo for dat observability",
          "score": 1,
          "created_utc": "2026-02-28 00:05:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t1hnj",
          "author": "GreatMinds1234",
          "text": "Mainly time and resources",
          "score": 1,
          "created_utc": "2026-02-28 01:36:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tevhz",
          "author": "KeeganDoomFire",
          "text": "We sold the project and told them the data could be delivered 4 days ago.  Can you have a test file for them yesterday?",
          "score": 1,
          "created_utc": "2026-02-28 02:59:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tkale",
          "author": "Foreign_Clue9403",
          "text": "Is it possible to turn this 4 hour pipeline into 2 2-hour pipelines or more?  That is to say, with medallion architecture you can set up checkpoints that confirm a -limited- set of rules on pipeline output before considering the data clean enough to advance to the next stage.  Doing all tests at every stage is expensive, slow, and in quite a few cases unnecessary imo.  Business rules don’t get applied until data needs to move somewhere where that’s required.  On the other hand, that interface likely does not need to enforce freshness, at least not as much as the interface closest to the ingestion.  However you can maintain access to that knowledge and correlate a record through the different medallion stages through an NK or something.",
          "score": 1,
          "created_utc": "2026-02-28 03:34:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7uhynh",
          "author": "Upbeat-Conquest-654",
          "text": "We're doing it a lot an it really helps. The key is deciding when to interrupt the pipeline and when to simply create a warning so that someone can check it out later without the pressure of prod standing still.",
          "score": 1,
          "created_utc": "2026-02-28 08:02:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7v6tah",
          "author": "Certain_Leader9946",
          "text": "not investing into a local development first environment is basically your biggest bottleneck",
          "score": 1,
          "created_utc": "2026-02-28 11:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7v7120",
          "author": "Certain_Leader9946",
          "text": "the sheer quantity of people who don't seem to know how to write good tests in this thread concerns me.",
          "score": 1,
          "created_utc": "2026-02-28 11:56:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vmxgl",
          "author": "ncist",
          "text": "Seen teams with hundreds of tests that still miss \"revenue went to 0\" because they didn't understand the business. Need to understand what we're all doing to write useful tests",
          "score": 1,
          "created_utc": "2026-02-28 13:48:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vu1y3",
          "author": "danryushin",
          "text": "If you caught an error, it turns into your problem. If you delivered wrong data where the root cause is not the pipeline, it is not your problem, that's the mentality on most places, which is not right nor wrong imo.",
          "score": 1,
          "created_utc": "2026-02-28 14:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w42es",
          "author": "makesufeelgood",
          "text": "Its hard and it takes time",
          "score": 1,
          "created_utc": "2026-02-28 15:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ygpk8",
          "author": "CornflakesKid",
          "text": "From what I've seen, it is more of that last one. No one cares, there's too much work and too little time to do it in. Just deploy and if there are bugs, take them up in subsequent sprints.",
          "score": 1,
          "created_utc": "2026-02-28 22:42:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ywl8y",
          "author": "updated_at",
          "text": "maybe they need a place set up to write the tests. ",
          "score": 1,
          "created_utc": "2026-03-01 00:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7zqadk",
          "author": "bobbruno",
          "text": "Well, it's hard. You don't control the sources. They can change schemas, they can send \"bad\" data in ways you didn't know, they can have their own errors that you, as downstream will be impacted by.\n\nCatching all of these and still meeting the requirement of delivering the numbers (i.e., not just rejecting and stopping with \"upstream broke contract\") is never going to happen 100%. As time passes, you catch more errors, but sources will always be creative.\n\nSo yes, test what you know and accept things will fail in previously unknown ways. In 30 years, I never saw a company willing to control all changes and quality of their operational systems just to guarantee that downstream analytics wouldn't break from time to time.",
          "score": 1,
          "created_utc": "2026-03-01 03:14:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdmrho",
      "title": "How to handle unproductive coworker?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rdmrho/how_to_handle_unproductive_coworker/",
      "author": "earthsnoozer22",
      "created_utc": "2026-02-24 17:34:34",
      "score": 52,
      "num_comments": 51,
      "upvote_ratio": 0.92,
      "text": "I have a coworker who used to work mostly on his own but recently got pulled into the team I'm on to increase our bandwidth. \n\nHe submits PRs that require a substantial amount of feedback, refactoring, and research on my end. For example, he'll submit code that doesn't run, is missing requirements clearly laid out in the ticket, or has logical issues such as incorrect data grain. \n\nMy options are to do nothing or to talk to him directly, our tech lead, our PO/PM, or our manager. I'm leaning toward talking to him directly or talking to our tech lead rather than our PO/PM or manager. In addition to his technical issues, he often misses stand up, calls out of work frequently, and I doubt he's ever putting in a \"*full day of work*\" (we're remote). If I talk to our PO/PM or manager I'm worried he'd be let go. I'm big believer in work/life balance, async meetings and Slack > traditional meetings, and output > time spent at work.\n\nIf I talk to him directly, I would offer to pair on his next ticket or during my code review. \n\nHas anyone dealt with someone similar and how did you address it, if you addressed it at all?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rdmrho/how_to_handle_unproductive_coworker/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7688bk",
          "author": "Ok-Recover977",
          "text": "I think if you can have a conversation where you can connect with him thatd help, he might just be checked out and waiting to be laid off and get severance though.",
          "score": 66,
          "created_utc": "2026-02-24 17:38:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76wtc5",
              "author": "thickyherky",
              "text": "same, i usually try talking to people like this first. best case he just needs somebody to connect",
              "score": 7,
              "created_utc": "2026-02-24 19:28:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76bspx",
          "author": "DenselyRanked",
          "text": "If you believe that he is making errors unintentionally, then send a dm to go over the code. You will find out quickly if it's an \"oops\", \"oh\", or \"eh\".\n\nIf it's an \"oops\", where they didn't see the mistake at the time but can recognize the issue, then I wouldn't worry too much about it. In my experience, they tried to use shortcuts to save time and the solution usually is to ask for test results or a test table in the PR.\n\nIf it's \"oh\", where they misunderstood the requirements or had no idea what they were doing, then that's a little concerning but give them the benefit of doubt that they would have done better if they had better information. \n\nIf it's \"eh\", where you care more about the quality of their work than they do, then talk to your supervisor because they are wasting your time.",
          "score": 42,
          "created_utc": "2026-02-24 17:54:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77bqhc",
              "author": "squadette23",
              "text": "That's an interesting classification, thank you!",
              "score": 6,
              "created_utc": "2026-02-24 20:37:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77xeni",
                  "author": "DenselyRanked",
                  "text": "I am certain that someone smarter than me has a better way to classify this, but I hope it helps.",
                  "score": 4,
                  "created_utc": "2026-02-24 22:18:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7bp7xs",
              "author": "Remarkable-Win-8556",
              "text": "Fantastic classification model.  This is good.",
              "score": 3,
              "created_utc": "2026-02-25 13:44:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7a2u54",
              "author": "thisfunnieguy",
              "text": "this.\n\nthere is a low return on investment for putting your effort into trying to help someone who is not trying at work. \n\nyou are likely not going to be rewarded by helping them, and at worst you're going to drag on your projects while you try and do this.",
              "score": 1,
              "created_utc": "2026-02-25 05:50:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o769mr6",
          "author": "HOLY_TERRA_TRUTH",
          "text": "I always offer constructive feedback but I also say I do not allow the same mistake twice. If they're repeating the same issues between PRs, especially glaring ones like what you're describing, that's a serious issue. Tell them to be more conscientious about their output.",
          "score": 18,
          "created_utc": "2026-02-24 17:45:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76k9ap",
              "author": "Ok_Tough3104",
              "text": "what about repeating the same issue like +50x ?\n\njust trying to understand how i should behave with my colleagues",
              "score": 6,
              "created_utc": "2026-02-24 18:32:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76vd6i",
                  "author": "HOLY_TERRA_TRUTH",
                  "text": "50 way higher than 2 bro",
                  "score": 8,
                  "created_utc": "2026-02-24 19:21:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77zdc2",
          "author": "Awkward_Ostrich_4275",
          "text": "I mean… just reject the pull request.  Add some comments saying something like:\n\nDoesn’t run, missing x and y requirements, z is not working to the correct specifications, and does not follow our code standards (naming conventions).\n\nThen he redoes it and sends another, more appropriate pull request.",
          "score": 9,
          "created_utc": "2026-02-24 22:28:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76inb9",
          "author": "BardoLatinoAmericano",
          "text": "It is always better to talk to the person first.\n\nIf the problem persists, talk to their superior.\n\nBut remember to register them making the same mistakes more than once.",
          "score": 4,
          "created_utc": "2026-02-24 18:25:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76yf5o",
          "author": "thisfunnieguy",
          "text": "its one thing to put in effort to help them catch up on a project, but i would be careful about making it your role to coach them through negative feedback.\n\none reason i have avoided being a manager is i want to be able to pair up with folks who want to go faster but not have the responsibility of fixing poor performers. \n\nits usually not hard to tell who is willing/able to put in the effort to do better vs those who are skating bye.\n\na manager gets paid to deal with ppl nonsense.\n\nthe problem i have is those ppl piss me off, and its hard to focus on my work when i know this knucklehead is just mucking around.",
          "score": 6,
          "created_utc": "2026-02-24 19:35:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7796sg",
              "author": "num2005",
              "text": "people like you piss me off, how ironic",
              "score": -10,
              "created_utc": "2026-02-24 20:25:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o780cb7",
                  "author": "could-it-be-me",
                  "text": "Why",
                  "score": 3,
                  "created_utc": "2026-02-24 22:32:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7a2j0k",
                  "author": "thisfunnieguy",
                  "text": "oh interesting. how so?",
                  "score": 1,
                  "created_utc": "2026-02-25 05:48:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78na2v",
          "author": "Leopatto",
          "text": "I read the comments and its clear 99% never had a managerial and above position. \n\nSure, talk to them, say their work is ass and they need to improve. Otherwise, go to your manager tell the issue, and their ass will be gone by next week.  \n\nIt's a business, not a daycare.",
          "score": 5,
          "created_utc": "2026-02-25 00:35:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ac0e1",
              "author": "thisfunnieguy",
              "text": "also, these replies seem way more extraverted than a typical eng.\n\nlotta leaning into difficult convos in this thread.",
              "score": 1,
              "created_utc": "2026-02-25 07:06:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7at1wi",
              "author": "Little_Kitty",
              "text": "As someone who's had to deal from both positions, getting rid of people who sap time and produce negative value can be difficult because of different teams.  Business analyst staff who chat with the clients, don't understand style guides, databases etc. but write \"urgent\" PRs are everywhere, and getting their code up to passable seems to often be a 'DE' job.  If the attitude exists that has allowed this situation to develop, getting those responsible out also means getting their (similarly incompetent) managers out.\n\nRoot cause, IME, is managerial staff who value more and cheap over good and paid properly.",
              "score": 1,
              "created_utc": "2026-02-25 09:45:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76es26",
          "author": "davrax",
          "text": "Chat with him 1:1 to see if there’s anywhere you might be more familiar, then make it your Tech Lead’s problem.",
          "score": 2,
          "created_utc": "2026-02-24 18:08:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77c2xo",
          "author": "Certain_Leader9946",
          "text": "you have to be harder on people without being harsh. its a difficult skill. sometimes it helps to really get in there with the weeds when coaching. tell them once and bollock them a bit if they keep rehashing mistakes you talked about. eventually you'll iron them out. it takes time.",
          "score": 2,
          "created_utc": "2026-02-24 20:39:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a8qjc",
          "author": "theBvrtosz",
          "text": "How big is your company? \nIf it’s a huge corporation then talk to him once, if that doesn’t work, talk to his supervisor, if that doesn’t work, stop worrying about it and play along. Sad truth is that in corporate the responsibility is so vague that no one will want to fix this, and you pressing on the coworker can make your situation worse, just like someone said, it’s a low return investment. \n\nJust make sure you document your conversations and comment the PR pointing out your concerns. From my experience when shit hits the fan things like this are coming back after some time and then you need a ground proof that you noticed that, and notified the person responsible (manager/supervisor). Especially if you are the one to accept the PRs, it’s a shared responsibility for the code quality. \n\nIf it’s a smaller software house then I would be more persistent, because his performance has bigger impact on the product. And we are “all sailing on the same ship” :)",
          "score": 2,
          "created_utc": "2026-02-25 06:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7og5w0",
          "author": "Ulfrauga",
          "text": "How much do you want to go in on a potentially awkward conversation, when it's arguably not your accountability?\n\n\n\nGive clear, actionable (and as *concise* as possible, considering the detailed nature of things\\*) PR feedback.  Get on a call to talk it through, gauge the reception.  Is it the \"oops\", \"oh\", or \"eh\" like u/DenselyRanked wrote about?\n\n  \n\\* I've found conciseness incredibly important.  Depends on people, though.  You described \"PRs that require a substantial amount of feedback\".  I've reviewed some where that was my conclusion.  I'd send back a whole bunch of bullet points, with explanations and reasoning as to why I'm raising it.  And basically, TLDR.  Quality didn't lift, I got more and more frustrated.  Manager didn't really support, because I guess, TLDR.\n\n\n\nI get wanting to improve the team you work in or even extend yourself in that direction, if it's a direction you want to go in.  I have been in the same boat.  Unless you *are* the manager, or your remit involves this, someone else is paid to do that shit.  Especially if it ends up in an uncomfortable, potentially accusatory and defensive conversation.\n\n\n\nEdit:  My position is/would be: Review PRs and give feedback.  Try and identify a training issue.  Collect evidence of you doing that, as well as the standard of PRs you review, and frequency of that standard.  Do you have any solutions to propose?  Then escalate it.",
          "score": 2,
          "created_utc": "2026-02-27 10:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76cy48",
          "author": "Chowder1054",
          "text": "I’d talk with him and work with him the next ticket as you mentioned. Maybe he has other things going on that’s impacting his work, maybe not.\n\nBut no reason to escalate things if a conversation can possibly solve things",
          "score": 1,
          "created_utc": "2026-02-24 17:59:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77gndk",
          "author": "m915",
          "text": "I think you should talk to them first. But also, why not try and implement CI/CD, well documented standards, and automated code review that uses your standards? \n\nFor example, Claude code review can have a Claude.md file with all of your standards in it, and can reference your other MD files. Automatically flags for common things \n\nCI/CD that runs and flags when it doesn’t run, etc",
          "score": 1,
          "created_utc": "2026-02-24 21:00:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a5sfb",
              "author": "thisfunnieguy",
              "text": "haha ive done this before.\n\njust setup a CI/CD that will prevent their PRs from merging b/c is fails some standards.",
              "score": 1,
              "created_utc": "2026-02-25 06:13:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o77qjyc",
          "author": "thecity2",
          "text": "Jim is that you?",
          "score": 1,
          "created_utc": "2026-02-24 21:45:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77wex4",
          "author": "MazurianSailor",
          "text": "Tbh I think depends, if you’re noticing it likely your team lead is - so might be something to bring up to them. \n\nI think there’s a difference between “snitching”, and being candid with your team lead where someone else is making your life substantially more difficult. \n\nI think having a 1:1 where you’re not the point of leadership in the team may come out of bounds, so they may take that badly..",
          "score": 1,
          "created_utc": "2026-02-24 22:13:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a5mvt",
          "author": "colincclark",
          "text": "Why has your tech lead not picked up on this? Why have you not spoken directly to the offending colleague or the tech lead to surface this? You need to look at the radical candour framework and take responsibility for calling out this person. Why are you reviewing PRs that are missing requirements and/or don't run? Call it out publicly on Slack and ask the tech lead to be more engaged in the management of the team. Escalate! Or things will not improve, which is unfair on everyone, including the person who is doing a shitty job.",
          "score": 1,
          "created_utc": "2026-02-25 06:12:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a6i68",
              "author": "thisfunnieguy",
              "text": "not everything is done out in public.  \nlast time i went to my manger about someone i found out they were already on a PIP",
              "score": 1,
              "created_utc": "2026-02-25 06:19:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7afbx7",
                  "author": "colincclark",
                  "text": "To keep that secret from the tech lead or from a colleague that it is clearly having a huge impact on is an organisational failure. It risks churn as there are no visible repercussions for the disengagement. Regardless, the PIP might be low-key or private, but it does not change the responsibility OP has for calling it out and making it a known thing.",
                  "score": 1,
                  "created_utc": "2026-02-25 07:36:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7a64zt",
          "author": "dontpanicmorty",
          "text": "Is your company hiring data or analytics engineers? Asking for a friend",
          "score": 1,
          "created_utc": "2026-02-25 06:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a7cjh",
          "author": "jj_HeRo",
          "text": "Talk to your manager or start looking for another job, or project in the company.",
          "score": 1,
          "created_utc": "2026-02-25 06:26:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7afd91",
          "author": "dataindrift",
          "text": "Unless you have management responsibilities, this is NOT your issue. \n\nIt's for his direct line management to address this. Talk to them.",
          "score": 1,
          "created_utc": "2026-02-25 07:37:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7alu0b",
          "author": "MattEOates",
          "text": "Sounds like you have a bigger issue of managing work to be honest. How and why is there a PR you are looking at that doesn't run? Why was the ticket shit but selected for work if it didn't pass any ready to work criteria. Why aren't there any tests to show this is true. Something isn't ready for review then its not ready for review. Then this persons work is far more visibly delayed and their struggle is noticed as their effort. You've got bigger problems than this guy, because you're not even in an environment where he doesn't impact quality or work plans. Id be talking to your lead about delivery planning and management with the specific point of solving your specific problem first by tweaking how you work. If you are the lead, you are the problem...",
          "score": 1,
          "created_utc": "2026-02-25 08:36:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bsykf",
          "author": "BeatTheMarket30",
          "text": "Meets requirements in ticket is the first thing I would validate when reviewing a PR. Every ticket must be sufficiently defined before devs start working on it. Unrelated changes must be kept to minimum and if extra unrelated effort is benefitial then a new ticket should be created.\n\nAs for whether he is slacking, you can verify by jumping on ad-hoc calls with them to explain things.",
          "score": 1,
          "created_utc": "2026-02-25 14:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gkihw",
          "author": "External-Economics40",
          "text": "He may be depressed and need a friend. I've been at the same job for 15 years working remotely for the last four and it's awfully depressing",
          "score": 1,
          "created_utc": "2026-02-26 04:31:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7guj94",
          "author": "vermillion-23",
          "text": "As a fairly fresh manager, I'm dealing with exactly the same thing. In the UK, it's difficult to fire someone, especially if they've been with a company for more than 2 years. There's a guy who does exactly the same, and more (or less, in performance context).\nIf you're worried about moral consequences of your own conscience - stop. They most likely know their work quality is bad - they just don't care and they know that someone will come and fix it for them. They make conscious decisions not to revise or test their work before submission, they deliberately put other matters before their contractual work commitments.\nRemember - if they do get fired eventually - it's not your fault for reporting it - it's their fault for taking the piss off their (most likely) sole income source, and for so long and so obvious to get themselves fired.",
          "score": 1,
          "created_utc": "2026-02-26 05:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h60xu",
          "author": "Sea_Fun_5479",
          "text": "You people don't write test cases?\n\nWe would take a look at a PR only after it has compiled successfully, have unit test cases with certain percentage of code coverage and evidence of functional test cases attached.\n\nThis is a case that can be handled by a little bit of automation. That takes care of 70-80% issues.\n\nAt this stage PR is only for suggesting improvements, considering edge cases, checking if any domain specific knowledge is missing etc.",
          "score": 1,
          "created_utc": "2026-02-26 07:19:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7im2na",
          "author": "Educational_Creme376",
          "text": "if you want to be a nice colleague, offer to mentor first. \n\nyou don't need to be critical, offer mentorship if you want to be helpful, if it's not appreciated, it's your call what to do next. \n\nnot everyone is on the same level, patience in order to help others grow, that's what fosters trust, safety and camaraderie in the work place. \n\n",
          "score": 1,
          "created_utc": "2026-02-26 14:11:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7kirx8",
          "author": "Delly_boi_80",
          "text": "I’m with everyone else’s advice to speak first but with one caveat.  Be prepared to also speak to your manager. Remember it’s their job to manage to team and deal with issues like this as that’s their responsibility.  \nThey might not be up to the job or be going through some issue which is why there game seems off. I know most people in this group are in the USA, but in the UK is normal to raises issues like this to a manager. A good one should have the discretion and experience how to deal with this.",
          "score": 1,
          "created_utc": "2026-02-26 19:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77903p",
          "author": "Fresh-Secretary6815",
          "text": "set up a meeting with a very clear and succinct bulleted list in the body. during the meeting, cover only those bulleted items exactly as written. on your next PR, yes YOURS you better have your shit together and it better include items from the list you’re trying to get this asshat to do. on his next PR, you will very politely reject it with notes specific to exactly what’s missing from what you covered in the meeting. reference your last “golden pr” in the rejection as a reference. you can do this twice, and if he needs a third, you will then have what you need to get the tech lead involved. however, you might need someone with more authority to weigh in on your list especially if those things aren’t already documented somewhere. if there were documented somewhere, this person was either not onboarded correctly so they understood expectations, or they are incompetent, or ignorant and you’ll need to train them like above. either way, same outcome.",
          "score": 1,
          "created_utc": "2026-02-24 20:24:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ac6oe",
              "author": "thisfunnieguy",
              "text": "what are you trying to accomplish with all that process?\n\n  \n\"you will then have what you need to get the tech lead involved\"\n\n  \nyou shouldnt need much to say \"hey boss, that dude's creating more work for the rest of us, can you talk to him about this and that.\"",
              "score": -1,
              "created_utc": "2026-02-25 07:08:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7b6x1f",
                  "author": "Fresh-Secretary6815",
                  "text": "since you are having a hard time understanding what “all that process”, the approach isn’t just “process for the sake of process” — theres a clear strategic logic behind each step, so let me break it down barney style: \n\nWhen you go to your tech lead and say “hey, that dude’s creating more work for us,” you’re handing them a problem with no evidence and no attempt at resolution. That puts your lead in a tough spot, makes you look like someone who escalates before trying to solve things, and frankly doesn’t help the struggling coworker improve at all. You’ve accomplished nothing except creating friction.\n\nWhat im is outlining is a paper trail with intent. The meeting with a clear agenda serves two purposes: it gives the coworker a fair, explicit chance to understand expectations, and it documents that you made that effort. Submitting a “golden PR” yourself isn’t just performative — it gives you a concrete reference point so your feedback isn’t just subjective criticism, it’s “here’s the standard, here’s how it’s done.” That’s mentorship, not bureaucracy.\n\nThe structured rejection of subsequent PRs with specific, referenced notes means you’re not being vague or personal. You’re saying “here are the exact gaps, here’s what we agreed on.” That’s the kind of feedback that actually helps someone improve.\n\nBy the time you do bring the tech lead in — if it gets there — you’re not handing them a nothing salad. You’re handing them a documented pattern: “I had a conversation, I provided a reference, I gave specific feedback twice, and here’s where we still are.” That’s actionable. That’s something a lead can actually work with.\n\nGoing to your boss immediately without any of that groundwork doesn’t make you efficient, it makes you someone who can’t navigate team dynamics without escalating. so, “all that process” approach demonstrates ownership of the problem. Yours just delegates it.​, making you look the same as the shitbag coworker.",
                  "score": 3,
                  "created_utc": "2026-02-25 11:46:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78ytox",
          "author": "Acrobatic_Intern3047",
          "text": "Since this job is remote, he is most likely over employed and will not care about your feedback",
          "score": 1,
          "created_utc": "2026-02-25 01:39:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76em3z",
          "author": "Altruistic_Stage3893",
          "text": "how many times has he dones this and why haven't you valled him out and shot him a message the first time this happened?\ni usually do this:\n> i don't like something, i call it out, provide ample resources so they can do better\n> happens again - i just tell them to fix it, takes couple of minutes of my time usually to recognize it\nrince and repeat. worst thing he'll be stuck resubmitting the same pr forever which will land him under the microscope anyway",
          "score": 0,
          "created_utc": "2026-02-24 18:07:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76qyju",
          "author": "rtmymynbklmn",
          "text": "Like everybody else said talk to him directly but I rekcon he is doing OE",
          "score": 0,
          "created_utc": "2026-02-24 19:01:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o778x20",
          "author": "num2005",
          "text": "pay him a vacation is usually what help, also you can have a chat that low output is tolerated but the output needs to be good",
          "score": 0,
          "created_utc": "2026-02-24 20:24:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a2ci5",
          "author": "Schtick_",
          "text": "You fire them",
          "score": 0,
          "created_utc": "2026-02-25 05:46:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbbft9",
      "title": "Is Data Engineering Becoming Over-Tooled?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rbbft9/is_data_engineering_becoming_overtooled/",
      "author": "saketh_1138",
      "created_utc": "2026-02-22 03:43:41",
      "score": 50,
      "num_comments": 28,
      "upvote_ratio": 0.87,
      "text": "With constant new frameworks and platforms emerging, are we solving real problems or just adding complexity to the stack?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rbbft9/is_data_engineering_becoming_overtooled/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6r9oaw",
          "author": "VEMODMASKINEN",
          "text": "Becoming? Has been for ages. \n\n\nIt's called resume driven design. ",
          "score": 163,
          "created_utc": "2026-02-22 11:42:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x3xqi",
              "author": "dillanthumous",
              "text": "Hadn't heard this one Love it. Will be stealing and will credit you Reddit pal.\n\nAlso applicable to the frontend. If the user is happy to have that particular data in a spreadsheet let's just do that, no need to build a multi purpose dashboard of doohickeys unless it delivers some value.",
              "score": 7,
              "created_utc": "2026-02-23 08:13:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rc8bu",
          "author": "BufferUnderpants",
          "text": "At the end of the day, what matters for interviewers is that you know SQL, Python, one of the big orchestrators, probably Spark, very maybe one of the big streaming platforms, that you’ll keep it tidy, and that you can communicate \n\nDimensional modeling if it’s a Data Warehousing role\n\nYour CTO may talk about tools they’re being pitched on all day and you can tune it out because they’ll forget about it the week after",
          "score": 52,
          "created_utc": "2026-02-22 12:04:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sb6r9",
              "author": "doubtful62",
              "text": "And speak to business impact. So many DEs I know talk to the tools/architectures/solutions but have little knowledge on why their role exists in the first place, and don’t connect them to tangible impactful outcomes for the company. You exist because the company believes you will make them more money than they pay you. If that belief goes away, so do you",
              "score": 21,
              "created_utc": "2026-02-22 15:36:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6redzz",
              "author": "romainmoi",
              "text": "But tool is definitely a tie breaker especially in the current market.",
              "score": 2,
              "created_utc": "2026-02-22 12:22:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6s65q7",
                  "author": "BufferUnderpants",
                  "text": "That’s a lot of tooling already, and they’re the heavy lifters, the buzzword-powered (AI!) automation or observability tool of this week usually doesn’t take a lot of time to pick up, it’s the other ones that businesses want you to have invested on upfront on your side\n\nEdit: A bigger deciding factor is if you have experience in exactly the cloud provider they use and the database or data warehouse they use, but I don’t think that’s what worries the OP, because one comes out once a decade maybe",
                  "score": 4,
                  "created_utc": "2026-02-22 15:12:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6r5ahx",
          "author": "PaymentWestern2729",
          "text": "Yes",
          "score": 10,
          "created_utc": "2026-02-22 11:01:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xmrh4",
              "author": "SufficientFrame",
              "text": "Honestly that “yes” kind of sums up how it feels half the time  \n\nI do think a lot of the tooling is solving real pain (like dealing with messy pipelines, governance, observability, whatever), but it’s also created this weird arms race where every team feels like they need 10 extra layers just to move data from A to B.\n\nHalf the job now is learning which tools to ignore. The stack that actually works is usually boring: a warehouse/lake, a scheduler, some transformations, and monitoring that people actually look at. The rest is just resume candy.",
              "score": 4,
              "created_utc": "2026-02-23 11:15:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ul40y",
          "author": "No_Soy_Colosio",
          "text": "Just imagine being a Js dev",
          "score": 8,
          "created_utc": "2026-02-22 22:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xh2u1",
              "author": "IshiharaSatomiLover",
              "text": "Exactly my thought. Played as a JS developer for a while and glad I escaped. Not 30 yet but already feel to old to keep up with framework after framework. At least Dataeng is slower(exclude azure fabric, nightmare for me also)",
              "score": 3,
              "created_utc": "2026-02-23 10:22:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76iwma",
                  "author": "Simple-Box1223",
                  "text": "It’s not really like that if you don’t engage with the churn, and that churn exists in most ecosystems.",
                  "score": 1,
                  "created_utc": "2026-02-24 18:26:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vjihn",
          "author": "marketlurker",
          "text": "You hit a hot button for me. I think it is worse than that. It isn't just the tools. It is vendors, like Databricks, trying to redefine old concepts with a new coat of paint and crowing like it is revolutionary. Not new ideas or even new ways of working. The whole \"medallion architecture\" thing is stupid. It isn't new just new names that actually causes confusion in a field that is already difficult enough. \n\nThe lack of business understanding and thinking tools are the most important part of the job blows me away. I am very comfortable saying that tools are the least important part of the job. You can pick up a tool in a month or so but knowing where and how to use it will take a lot longer.\n\nThe trouble is employers want a way to measure talent. Unfortunately, they think knowing a given tool is the answer. They get what they deserve.",
          "score": 14,
          "created_utc": "2026-02-23 01:19:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70mi97",
              "author": "Old_Tourist_3774",
              "text": "What are some examples? I am relatively new to the field and only really used OLAP systems",
              "score": 1,
              "created_utc": "2026-02-23 20:42:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rcx9c",
          "author": "Few_General_881",
          "text": "Yes",
          "score": 6,
          "created_utc": "2026-02-22 12:10:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wngz3",
          "author": "soluto_",
          "text": "It’s only a concern for me when I was at the early stages of my career. Now, I only care about the simplest stack possible that gives my VP WoW growth of revenue by Monday 9am.",
          "score": 3,
          "created_utc": "2026-02-23 05:45:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u0tvv",
          "author": "mycocomelon",
          "text": "Yeah. And still trying to solve the same problems that are always just out of reach.",
          "score": 3,
          "created_utc": "2026-02-22 20:22:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x4bx2",
              "author": "dillanthumous",
              "text": "My constant refrain to stakeholders:\n\nIf you couldn't solve the problem manually with the right data and infinite time then we can't automate that non solution.\n\nAnd if we don't even have the data to theoretically solve the problem in the first place then we can't even test the theory until we procure it.",
              "score": 5,
              "created_utc": "2026-02-23 08:17:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wr2ss",
          "author": "Next_Comfortable_619",
          "text": "yes. i can do just about everything with powershell and sql.",
          "score": 3,
          "created_utc": "2026-02-23 06:15:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xxr85",
              "author": "Altruistic-Spend-896",
              "text": "\"But But i want crdt replicated, highly available, p99 ingestion for realtime feeds!\" -uses postgres.",
              "score": 1,
              "created_utc": "2026-02-23 12:42:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tp7n4",
          "author": "Chance_of_Rain_",
          "text": "It used to be, I think it’s streamlining",
          "score": 6,
          "created_utc": "2026-02-22 19:24:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r28d2",
          "author": "thinkingatoms",
          "text": "lol no one is forcing anything down your throat, pick whatever fits",
          "score": 5,
          "created_utc": "2026-02-22 10:32:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7469ur",
          "author": "theBvrtosz",
          "text": "If you mean that there is a shit ton of tools resolving the same problem then yeah. \n\nBut I was lucky and in my companies we tended to use 2-3 tools to get the job done. \nUsually snowflake /  databricks (I focus on cloud data engineering) + some orchestrator + database migration tool. \n\nI am not including not data related tools like devops layer.",
          "score": 2,
          "created_utc": "2026-02-24 10:53:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ysc6p",
          "author": "pkk888",
          "text": "Yes! Its horrible! Tools for you, tools for me - TOOLS FOR EVERYONE!",
          "score": 1,
          "created_utc": "2026-02-23 15:34:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yvnwc",
          "author": "ScroogeMcDuckFace2",
          "text": "its been over tooled forever",
          "score": 1,
          "created_utc": "2026-02-23 15:50:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70rpi4",
          "author": "BardoLatinoAmericano",
          "text": "Nah.\n\n5 things get you going",
          "score": 1,
          "created_utc": "2026-02-23 21:08:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73mssm",
          "author": "GreatMinds1234",
          "text": "Yep...",
          "score": 1,
          "created_utc": "2026-02-24 07:50:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l0pbd",
          "author": "Guepard-run",
          "text": "Over-tooling isn’t innovation it’s decision debt  \nTeams keep adding new tools without removing old ones, so the stack bloats and ownership gets blurry. The fastest teams don’t use the fanciest stacks they use boring, stable tools with clear ownership and tight feedback loops.",
          "score": 1,
          "created_utc": "2026-02-26 21:00:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdo2te",
      "title": "I made my first project with DBT and Docker!",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rdo2te/i_made_my_first_project_with_dbt_and_docker/",
      "author": "Lastrevio",
      "created_utc": "2026-02-24 18:20:28",
      "score": 50,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "I recently watched some tutorials about Docker, DBT and a few other tools and decided to practice what I learned in a concrete project.\n\nI browsed through a list of free public APIs and found the \"JikanAPI\" which basically scrapes data from the MyAnimeList website and returns JSON files. Decided that this would be a fun challenge, to turn those JSONs into a usable star schema in a relational database.\n\n[Here is the repo.](https://github.com/Lastrevio112/MyAnimeListPipeline)\n\nI created an architecture similar to the medallion architecture by ingesting raw data from this API using Python into a \"raw\" (bronze) layer in DuckDB, then used Polars to flatten those JSONs and remove unnecessary columns, as well as seperate data into multiple tables and pushed it into the \"curated\" (silver) layer. Finally, I used DBT to turn the intermediary tables into a proper star schema in the datamart (gold) layer. I then used Streamlit to create dashboards that try to answer the question \"What makes an anime popular?\". I containarized everything in Docker, for practice.\n\nHere is the end result of that project, the front end in Streamlit: https://myanimelistpipeline.streamlit.app/\n\nI would appreciate any feedback on the architecture and/or the code on Github, as I'm still a beginner on many of those tools. Thank you!",
      "is_original_content": false,
      "link_flair_text": "Personal Project Showcase",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rdo2te/i_made_my_first_project_with_dbt_and_docker/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7g1k91",
          "author": "InterestingExistance",
          "text": "Simple. Efficient. Gets the point of the data across. And an application of what you learned. Loved checking it out",
          "score": 3,
          "created_utc": "2026-02-26 02:35:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dbn4m",
          "author": "Background_Ice_3202",
          "text": "Loved seeing the project.",
          "score": 2,
          "created_utc": "2026-02-25 18:21:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dlqij",
              "author": "Lastrevio",
              "text": "Thank you !",
              "score": 2,
              "created_utc": "2026-02-25 19:07:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7vzmqo",
          "author": "Square-Mind-4206",
          "text": "may i ask what resources/courses/materials you used to learn data engineering. im now trying to get into it.",
          "score": 2,
          "created_utc": "2026-02-28 15:01:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wl312",
              "author": "Lastrevio",
              "text": "I think SQL and Python are the fundamentals, which I learned in college.\n\nFor Python in particular, you might need to know a dataframe library (pandas, polars or PySpark) in which case I recommend the website datawars.io\n\nDBT can be learned from learn.getdbt.com\n\nDocker I learned from Youtube.\n\nBefore jumping into any tools however, you need to learn the fundamentals. It very often helps to work as a data analyst or BI developer before jumping into data engineering as that gets you familiar with data warehousing and SQL. For example, I started out as a BI specialist working in QlikSense and SQL Server.\n\nGood luck!",
              "score": 1,
              "created_utc": "2026-02-28 16:49:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7wxw6e",
                  "author": "Square-Mind-4206",
                  "text": "thank you",
                  "score": 1,
                  "created_utc": "2026-02-28 17:54:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7oqa0a",
          "author": "No-Animal7710",
          "text": "Nice!\n\nPlay around with some dbt macros now that you have a schema you can validate it against. Transforms you do outside of dbt dont show up in the docs. if you can move that transformation logic back into a bronze -> silver model youll maintain lineage through dbt's internal dag. \n\nWhen Im pushing out stuff at work i typically rock through it in a similar way; blast as much python as i can because i can write / validate it faster, then go back and push that logic back into dbt.\n\nGets you a whole extra transform layer in the docs page that 'users' might want to know and catalog tools can immediately read it from dbts own files.\n\nRock on!",
          "score": 1,
          "created_utc": "2026-02-27 11:55:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ougwu",
              "author": "Lastrevio",
              "text": "Thanks, how is it possible to flatten and/or explode JSON files with DBT? I know that DBT recently added support for Python but I'm not sure it's posssible to do this with pure SQL + Jinja.",
              "score": 1,
              "created_utc": "2026-02-27 12:25:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7uu0nf",
                  "author": "PowerbandSpaceCannon",
                  "text": "[https://duckdb.org/docs/stable/sql/query\\_syntax/unnest](https://duckdb.org/docs/stable/sql/query_syntax/unnest)",
                  "score": 2,
                  "created_utc": "2026-02-28 09:56:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7p1lzt",
                  "author": "No-Animal7710",
                  "text": "Syntax depends on the target db. Dig in to your underlying db's json handling stuff. \n\nIts definitely a bit more difficult than just doing it in python which is why i typically get the structure down with python first then work backwards to get to the matching sql. \n\nBut end state youll have all of your transformation logic in one place and can rebuild all your tables / tests / documentation with just dbt.",
                  "score": 1,
                  "created_utc": "2026-02-27 13:13:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rgm1bs",
      "title": "Work Quality got take a hit due to being a single DE + BI guy",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rgm1bs/work_quality_got_take_a_hit_due_to_being_a_single/",
      "author": "Secure_Firefighter66",
      "created_utc": "2026-02-27 23:08:32",
      "score": 49,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "As the title suggests, I’m a Data Engineer (DE) with three years of experience working in a small company with less than 100 employees for over a year. I’m the only DE and BI professional in the company.\n\nBefore I joined, there was no one working as a DE, and the last person in that role left three years ago.\n\nWhen I started, I migrated from Microsoft SQL Server to Databricks and integrated other data sources. At that time, I had to handle migrations and take care of old systems and reports.\n\nThen, we had to meet reporting requirements. We had around 100 reports, but now we only have 8. While working, I realized that not only did no one know how the business logic was set up, but a few teams didn’t even understand how our ERP system worked.\n\nSome reports were showing incorrect data because the source of that data was an Excel sheet that was last updated three years ago.\n\nWhen setting up new reports based on defined logic, I encountered a number mismatch. Upon investigation, I discovered that the old logic they were referring to was incorrect.\n\nOn top of these issues, no one in sales has been properly trained in our ERP system. People create a lot of data quality problems that disrupt the pipeline or show incorrect numbers in reports, and I get asked why the report numbers are wrong.\n\nWhenever a new requirement comes from a team, they implement it and check the numbers. They then say, “Try to update the logic,” and they raise a ticket as a bug. I have no control over this.\n\nBecause of these problems, I try to complete tasks as quickly as possible, which affects the quality of my output.\n\nI would appreciate any suggestions on how to address these issues and improve the situation. ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rgm1bs/work_quality_got_take_a_hit_due_to_being_a_single/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7siv61",
          "author": "MK_BombadJedi",
          "text": "This sounds like every job I've had.",
          "score": 39,
          "created_utc": "2026-02-27 23:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sl7l7",
          "author": "vasim07",
          "text": "Pretty much the same for me.",
          "score": 11,
          "created_utc": "2026-02-27 23:58:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7soakz",
          "author": "Historical-Fudge6991",
          "text": "Try to limit your users input capabilities. Continuously having to account for edge cases is death by paper cuts. You might need to do some training on the new vs old logic. \n\nIt can kind of suck but to me the difference between developer and engineer is that you are expected to guide solutions to the right framework/kpi/report etc. so that it makes everyone’s life easier (hopefully)",
          "score": 20,
          "created_utc": "2026-02-28 00:16:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t24vb",
          "author": "Truth-and-Power",
          "text": "Can you create hierarchies that the business controls in erp and base the logic on those hierarchies?  Sometimes that can reduce the number of code changes.",
          "score": 3,
          "created_utc": "2026-02-28 01:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t7cpt",
          "author": "rando3225",
          "text": "Literally my last job, seems to be the consensus",
          "score": 3,
          "created_utc": "2026-02-28 02:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ts65s",
          "author": "Necessary-Change-414",
          "text": "I was in the same position. People can't communicate what they want. Do not thinks through before giving a requirement and have to change them a million times while developing phase is already ongoing. \nWhat helped me here was thinking gross on phases like this is data retrieval and I make interface tables to retrieve them. \nThen I make a combination step. \nThen I do a business logic area. \nAfter that comes the important part:\nI build kind of a rule based web interface with AI, where the colleagues who have no idea what they talking about, and do not have any documentation, define their mappings and rules. \nAfter that the rules are applied and facts and dimensions are build automatically. \n\nThat was the moment they eat their own shit, and I was free",
          "score": 5,
          "created_utc": "2026-02-28 04:28:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vss9l",
          "author": "lzwzli",
          "text": "I'm not sure things get better when you're not single.../s",
          "score": 1,
          "created_utc": "2026-02-28 14:23:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1req902",
      "title": "Where should Business Logic live in a Data Solution?",
      "subreddit": "dataengineering",
      "url": "https://leszekmichalak.substack.com/p/where-should-business-logic-live",
      "author": "Astherol",
      "created_utc": "2026-02-25 21:19:36",
      "score": 47,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1req902/where_should_business_logic_live_in_a_data/",
      "domain": "leszekmichalak.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7fwaur",
          "author": "Think-Trouble623",
          "text": "Really agree & love the post. We have significant data transformations and imputation of business logic in our Bronze to Silver layer, but then silver to Gold are more simple filters or pre-aggregations that are just quality of life for our end users. They don’t have to worry about filtering or handling conversions. \n\nAny power user that does need that additional information (in silver) has the context and understanding of how to transform it without getting the wrong answer.",
          "score": 6,
          "created_utc": "2026-02-26 02:06:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7i0yz9",
              "author": "Astherol",
              "text": "Do you think I should pinpoint exact example about medalion storage pattern like: you do it in both gold/silver?",
              "score": 1,
              "created_utc": "2026-02-26 12:01:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7flud3",
          "author": "wellseasonedwell",
          "text": "Nice article. I think the tension I find is trying to not reload upstream (and therefore everything downstream) with biz logic that changes frequently.  Especially true if that logic is feeding other systems and trying to keep everything idempotent, sending signals that a particular record not longer qualifies (ie soft delete and not filtering), etc.",
          "score": 6,
          "created_utc": "2026-02-26 01:06:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fufnj",
          "author": "ch-12",
          "text": "I agree. Now if you can please help me convince leadership that it’s worth spending time on making it a reality instead of consistently dealing with problems caused by the business logic sprawling everywhere.",
          "score": 2,
          "created_utc": "2026-02-26 01:55:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7f8syv",
          "author": "IronAntlers",
          "text": "Enjoyed it",
          "score": 1,
          "created_utc": "2026-02-25 23:54:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7i0ul3",
              "author": "Astherol",
              "text": "Good, I'm glad to hear it :)",
              "score": 1,
              "created_utc": "2026-02-26 12:01:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rccu65",
      "title": "Can seniors suggest some resource to learn data pipeline design.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rccu65/can_seniors_suggest_some_resource_to_learn_data/",
      "author": "GodfatheXTonySoprano",
      "created_utc": "2026-02-23 09:20:56",
      "score": 46,
      "num_comments": 13,
      "upvote_ratio": 0.86,
      "text": "I want to understand data pipeline design patterns in a clear and structured way  like when to use batch vs streaming, what tools/services fit each case, and what trade-offs are involved. I know most of this is learned on the job, but I want to build a strong mental framework beforehand so I can reason about architecture choices and discuss them confidently in interviews. Right now I understand individual tools, but I struggle to see the bigger system design picture and how everything fits together.\n\nAny books/Blogs or youtube resource can you suggest.\n\nCurrently working asJunior DE in amazon",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rccu65/can_seniors_suggest_some_resource_to_learn_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6xar2h",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-23 09:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xdt9a",
          "author": "aisakee",
          "text": "There are very few cases when you should use Stream processing. Actually if you can avoid it the better. Almost all pipelines can be done in batches, just define the frequency of the updates.\n\nBooks:\n- designing data intensive applications from Kleppmann\n- fundamentals of data engineering from Joe Reiss\n\nDon't fall for expensive tools that are just drag and drop, focus on SQL, Python/Java/Scala/Rust (any of them), Spark, but if you're going to use a specific tool then learn the basics of Databricks/Snowflake. Focus on data modeling, learn the pros and cons of choosing the right data storage technology (Data Warehouse vs Data Lake vs Lake house, marts, vaults, silos).\n\nPersonal recommendation: focus on learning about the business, what you're doing, the impact etc.",
          "score": 49,
          "created_utc": "2026-02-23 09:51:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70khbz",
              "author": "Chewthevoid",
              "text": "Lol so many projects where leadership wants *real time data*, and we’ve just done frequent batch updates behind the scenes. Most of the time they don’t actually care, they just want to be able to put the buzzword in their decks.",
              "score": 16,
              "created_utc": "2026-02-23 20:32:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o70q7p2",
                  "author": "aisakee",
                  "text": "They want \"real time\" but they check the dashboard once a month, lol.",
                  "score": 14,
                  "created_utc": "2026-02-23 21:00:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6y5z2j",
              "author": "paxmlank",
              "text": "Both of these books are expected to have a new edition released soon! DDIA should be coming out in a few days",
              "score": 6,
              "created_utc": "2026-02-23 13:34:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o74dgau",
                  "author": "atrus72",
                  "text": "March 24th according to Amazon.",
                  "score": 2,
                  "created_utc": "2026-02-24 11:52:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6xkoz4",
          "author": "Inner_Warrior22",
          "text": "What helped me was sketching simple architectures for real use cases. For example, event ingestion for product analytics vs nightly finance reporting. Different failure tolerance, different infra, different monitoring needs. Even just whiteboarding trade offs like state management, replayability, and schema evolution will get you thinking at the system level. Since you are already at a large org, try to reverse engineer one pipeline you can see internally. Ask why it is not streaming, or why it is. That mental model work compounds way more than memorizing another stack. I hope it helps.",
          "score": 10,
          "created_utc": "2026-02-23 10:56:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ygxjj",
              "author": "Outside_Reason6707",
              "text": "Very helpful!",
              "score": 1,
              "created_utc": "2026-02-23 14:36:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xsor3",
          "author": "speedisntfree",
          "text": "Data Engineering Design Patterns by Bartosz Konieczny might be close what you are after. I have only just bought this and not read much of it yet though.",
          "score": 7,
          "created_utc": "2026-02-23 12:05:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xy9bu",
          "author": "mycocomelon",
          "text": "Dagster university. Dbt documentation and their courses. Both are obviously product centric, but they go into a lot of practical hands-on application of generally good data engineering practices for designing pipelines. Has helped me immensely.",
          "score": 6,
          "created_utc": "2026-02-23 12:46:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbs8sk",
      "title": "How close is DE to SWE in your day to day job",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rbs8sk/how_close_is_de_to_swe_in_your_day_to_day_job/",
      "author": "Icy-Ask-6070",
      "created_utc": "2026-02-22 17:45:29",
      "score": 43,
      "num_comments": 20,
      "upvote_ratio": 1.0,
      "text": "How important is software engineering knowledge for Data Engineering? It's been said many times that DE is a subset of SWE, but with platforms like Snowflake, DBT and Msft Fabric I feel that I am far from doing anything close to SWE. Are times changing so DE is becoming something else?  ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rbs8sk/how_close_is_de_to_swe_in_your_day_to_day_job/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6tbi0b",
          "author": "BufferUnderpants",
          "text": "I work on Spark pipelines, and also online services to serve or update the data. Devops too, because you always fiddle with infrastructure and build systems these days.\n\nThis is a very large company (a bit messy as an org though)",
          "score": 22,
          "created_utc": "2026-02-22 18:20:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v7i5z",
          "author": "lzwzli",
          "text": "The SWE workflow still applies to DE even if you purely work with SQL. You need to have a way to manage your code.\n\nFor any large enough DE shop, the DRY (don't repeat yourself) principle should also apply. If you have to write the same pattern of SQL more than twice, it should be a function/procedure and now you pretty much in SWE land.\n\nIf you work with DBT, that is definitely a SWE platform.",
          "score": 19,
          "created_utc": "2026-02-23 00:09:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t4hbz",
          "author": "DexTheShepherd",
          "text": "Might depend on who you ask. For me I wear both hats - I do strict DE and even some analytics but there's also traditional SWE mixed in. I don't see how I could be a DE without a strong SWE background.",
          "score": 15,
          "created_utc": "2026-02-22 17:49:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t7d9i",
              "author": "Cyphor-o",
              "text": "I've only ever been in data and a SWE background is not required. They have similar elements used different. \n\nIf you see SWE data pipelines vs DE data pipelines you will see the SWE pipelines are over engineered and treated like software programming. \n\nI'm not a SWE but I'm a DE and a very successfully one.",
              "score": 15,
              "created_utc": "2026-02-22 18:01:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o70t552",
                  "author": "Old_Tourist_3774",
                  "text": "Same thing here, I am working with a guy who was a SWE and it's exactly that. A lot of unnecessary work.",
                  "score": 3,
                  "created_utc": "2026-02-23 21:16:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vq7ko",
          "author": "DenselyRanked",
          "text": "Generally, the core principles are the same but the tasks within them are different. There is more to Software Engineering than backend software development and shipping code, so it really depends on what you mean by software engineering knowledge. You should still have to get requirements, build something, write tests, get feedback, provide support, maintenance, etc. \n\nI find it better to think of data engineering as a discipline or specialty of software engineering, rather than a subset. However, the other disciplines are less tool dependent, and because of that, tend to be standardized across the industry. \n\nYou may find that a data platform engineer role is better fit for you if you want to solve data problems but ship code to a large codebase.",
          "score": 3,
          "created_utc": "2026-02-23 01:59:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ydtpo",
          "author": "Lower_Sun_7354",
          "text": "Start with fabric.  Its cheap and easy to setup.  Look at each of their key offerings.  It will show lakes, databases, adf, notebooks, etc.  Its all in one place.  Don't become an expert there.  Just understand the basics.  What are the buzzwords. Then go look at their counterparts directly in Azure and AWS.  Then look for the open source versions of each of those.\n\nGives you an idea of how open source tools evolve into packaged products.  If you went fully opensource, how would you automate the deployment of those pieces?  How would you secure them?  The more you think of the shell services, the more you are looking at platform engineering.  The more you look at the inside portion, the more you are data or software engineering.  \n\nIt's a lot to cover, so most people will gravitate towards one area or another based on either preference or job requirements.",
          "score": 3,
          "created_utc": "2026-02-23 14:19:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yfl9t",
              "author": "Icy-Ask-6070",
              "text": "Got it, I guess I am gravitating towards Platform Engineering as you mentioned. But I will spend some time learning some concepts from the open source offerings to understand a bit more the software side of the role.",
              "score": 1,
              "created_utc": "2026-02-23 14:29:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6y00ua",
          "author": "Lower_Sun_7354",
          "text": "If you're in a fabric shop, it will feel a lot different.\n\nBut in my world, I had to build a lot of my own infra.  Databases, data lakes, events and queues, small apps like function apps or lambdas, some apis like FastAPI, think about gateways, the occasional user interface.  The goal of software and data engineering has always been the movement of data.  Its really just a question of who is your audience?  Historically, software engineers would focus on transactional data and data folks would focus on batch or analytical.  Once streaming and microservices showed up, the lines really blurred.  So you could be a data engineer who does a lot of platform engineering and a lot of backend streaming, or you could be a data engineer who builds star schemas for power bi.  There's a lot of overlap depending on where you fall.",
          "score": 2,
          "created_utc": "2026-02-23 12:57:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y2kkm",
              "author": "Icy-Ask-6070",
              "text": "Thanks for the insights. What would you recommend to someone to move towards the first example of DE and not the second in which I feel I am getting trapped. I come from the business world, so it has been kind of a natural progression, but I am more interested in the technical stuff rather than the analytical portion of it.",
              "score": 1,
              "created_utc": "2026-02-23 13:14:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tn61j",
          "author": "onestupidquestion",
          "text": "Data engineering used to require much more development work since modern tooling didn't exit. Larger companies have also started to build larger data teams, so it's more common to have dedicated data infrastructure teams and data modeling teams. It's very possible to have a career doing just data modeling, dbt, and Airflow. Even on the infra side, if your data is relatively small and simple, you can get a lot of work done just configuring and managing tools and services like Fivetran, dbt, and Airflow.\n\nI personally don't think data engineering (or analytics engineering) is software engineering, but there's still a lot of skillset / mindset overlap. Even if you're \"only\" doing data modeling and SQL, that process is much more rigorous than it used to be: design reviews, code reviews, source control, and established frameworks.",
          "score": 4,
          "created_utc": "2026-02-22 19:14:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v4w7v",
              "author": "mh2sae",
              "text": "To me data engineering is just a subcategory of software engineering. In fact, IMO it is closer to traditional backend and infra than front end roles, which are considered software engineering.\n\nEven if you do SQL and closer to analysis, as long as you are automating and making software, it is software engineering.",
              "score": 8,
              "created_utc": "2026-02-22 23:54:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v9wl4",
                  "author": "onestupidquestion",
                  "text": "But is writing dbt models and Airflow DAGs \"making software\"? I don't want to dismiss that work, since it can be challenging and important, but it's very different from building applications or services.\n\nI'm saying this as someone whose primary expertise is data warehousing. Between personal projects and hackathons, I've been able to do some more traditional dev work, and I find it makes me think in very different ways from my day-to-day.",
                  "score": 4,
                  "created_utc": "2026-02-23 00:23:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6yelmb",
          "author": "anti_humor",
          "text": "I'm at a very small company, so I'm basically just a shittier back end SWE who's really good at SQL and builds ad hoc dashboards when that is needed.",
          "score": 1,
          "created_utc": "2026-02-23 14:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yjn9d",
          "author": "Lastrevio",
          "text": "We have to maintain and debug a lot of legacy SSIS spaghetti packages and I feel like we don't conform to a lot of software engineering best practices on those old on-prem implementations, lol.",
          "score": 1,
          "created_utc": "2026-02-23 14:50:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yk49r",
              "author": "Lastrevio",
              "text": "*Also accentuated by the fact that it's technically a 'low code' tool so we just drag and drop boxes and stare at arrows",
              "score": 1,
              "created_utc": "2026-02-23 14:53:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o73ixs1",
          "author": "dyogenys",
          "text": "Very close. I'm the \"backend\" DE which is SWE in contrast to my Fabric residing colleague. I do a lot with kafka, k8s, and SQL servers. I code Daily with one or multiple of C#, java, Python, SQL, YAML, bash so pretty much feels like SWE",
          "score": 1,
          "created_utc": "2026-02-24 07:14:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7awxhn",
          "author": "thisfunnieguy",
          "text": "writing scripts in snowflake is different from using dbt or airflow to manage ETL process through snowflake\n\n",
          "score": 1,
          "created_utc": "2026-02-25 10:20:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c7b2j",
          "author": "Senior_Temporary_500",
          "text": "DE is still very close to SWE day to day, just abstracted. You are writing production code (Python/SQL), designing systems, handling failures, performance, and versioning. dbt reduce infra work not engineering thinking. The role is not disappearing, it’s shifting from build everything to build reliable systems on top of platforms.",
          "score": 1,
          "created_utc": "2026-02-25 15:17:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wlt88",
          "author": "dinosaurkiller",
          "text": "![gif](giphy|3L8avUvLSVY0EhOegE|downsized)",
          "score": 0,
          "created_utc": "2026-02-23 05:31:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcmam2",
      "title": "Has anyone found a self healing data pipeline tool in 2026 that actually works or is it all marketing",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1rcmam2/has_anyone_found_a_self_healing_data_pipeline/",
      "author": "CharacterHand511",
      "created_utc": "2026-02-23 16:36:01",
      "score": 36,
      "num_comments": 31,
      "upvote_ratio": 0.89,
      "text": "Every vendor in the data space is throwing around \"self healing pipelines\" in their marketing and I'm trying to figure out what that actually means in practice. Because right now my pipelines are about as self healing as a broken arm. We've got airflow orchestrating about 40 dags across various sources and when something breaks, which is weekly at minimum, someone has to manually investigate, figure out what changed, update the code, test it, and redeploy. That's not self healing, that's just regular healing with extra steps.\n\nI get that there's a spectrum here. Some tools do automatic retries with exponential backoff which is fine but that's just basic error handling not healing. Some claim to handle api changes automatically but I'm skeptical about how well that actually works when a vendor restructures their entire api endpoint. The part I care most about is when a saas vendor changes their api schema or deprecates an endpoint. That's what causes 80% of our breaks. If something could genuinely detect that and adapt without human intervention that would actually be worth paying for.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1rcmam2/has_anyone_found_a_self_healing_data_pipeline/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6zbwo8",
          "author": "Nekobul",
          "text": "No tooling can self-adjust if API endpoint suddenly disappears or the spec changes. What you are looking for is \"science fiction\". ",
          "score": 83,
          "created_utc": "2026-02-23 17:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75febi",
              "author": "Thinker_Assignment",
              "text": "i hate to be that guy but we are getting community reports of using maintenance agents to bridge the gap our tool doesn't",
              "score": 3,
              "created_utc": "2026-02-24 15:28:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zd79s",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 26,
          "created_utc": "2026-02-23 17:11:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77g23u",
              "author": "Skylight_Chaser",
              "text": "i like ur idea ",
              "score": 1,
              "created_utc": "2026-02-24 20:57:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7o644i",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment violated rule #4 (Limit self-promotion). \n\nWe intend for this space to be an opportunity for the community to learn about wider topics and projects going on which they wouldn't normally be exposed to whilst simultaneously not feeling like this is purely an opportunity for marketing.\n\nA reminder to all vendors and developers that self promotion is limited to **once per month** for your given project or product.  Additional posts which are transparently, or opaquely, marketing an entity will be removed.\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-02-27 08:55:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zcmm9",
          "author": "Zer0designs",
          "text": "I mean, API schemas or deprecated endpoints can be handled way before they actually change. And notifications should be sent ahead of time (check your contracts/SLA's).\n\nThat being said: I think self-healing doesn't exist. Schema evolution does (which is probably the non-marketing term for self-healing) but changing endpoints or completely different schema's, I've never seen. But that should be handled with stong contracts SLA's monitoring for deprecations and downstream API versioning.\n\nI wouldn't trust agents for 'self-healing',  but maybe for monitoring logs for deprecation logs of API endpoijts and generating a report I would.",
          "score": 2,
          "created_utc": "2026-02-23 17:09:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7h44ah",
              "author": "codek1",
              "text": "*should* be sent",
              "score": 1,
              "created_utc": "2026-02-26 07:02:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7h4dia",
                  "author": "Zer0designs",
                  "text": "So fix it in a contract? Never blindly trust parties.",
                  "score": 1,
                  "created_utc": "2026-02-26 07:05:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zcvvs",
          "author": "smartdarts123",
          "text": "Imo pipelines and data contracts should be rather rigid. There are not many scenarios where I'd want an upstream schema or API change to freely flow into my warehouse and propagate throughout all of my data.\n\nWhat does self healing even mean to you? Anything beyond automatic retry on task failure feels like overstepping without some level of human intervention or review.\n\nI want my pipelines to fail loudly when something unexpected happens, not self heal and cause inadvertent impact to downstreams.",
          "score": 3,
          "created_utc": "2026-02-23 17:10:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70fu65",
          "author": "ivanovyordan",
          "text": "You don't have a tooling problem. You have a process problem.\n\nStop looking for a way to spend money. Check these vendors. Do you use versionised APIs? Can you ask them if they can provide stable endpoints and APIs? Is there a way to get notified before breaking changes? Can you use push instead of pull mechanics? CSV data dumps maybe?\n\nI mean, there are loads of other things to consider before burning cash on fake promisses.",
          "score": 3,
          "created_utc": "2026-02-23 20:10:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z9uwr",
          "author": "OkAcanthisitta4665",
          "text": "I’m not aware of any self-healing data pipeline tools. Could you please let me know some popular names?",
          "score": 2,
          "created_utc": "2026-02-23 16:56:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dtpxv",
              "author": "ApprehensiveVast5241",
              "text": "Check out precog",
              "score": 1,
              "created_utc": "2026-02-25 19:44:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z726s",
          "author": "Vast_Shift3510",
          "text": "Same question is running in my head & I have checked or tried doing research but couldn’t find much info\nLet me know if you find any useful resources",
          "score": 1,
          "created_utc": "2026-02-23 16:43:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zcnhe",
          "author": "jadedmonk",
          "text": "It’s a newer terminology but self healing pipelines have become a thing now that LLMs can “make decisions” on the next steps for a failed job. I’m on a team where we’re attempting to build it. \n\nHowever we haven’t seen any marketed self healing pipeline, I don’t think a true one of those exists on the open marketplace",
          "score": 1,
          "created_utc": "2026-02-23 17:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zhq71",
          "author": "galiyonkegalib",
          "text": "The interesting part is when tools detect that an api schema changed and automatically adjust the extraction logic. Some managed tools do this for their maintained connectors because they have teams monitoring vendor api changes across all their customers.",
          "score": 1,
          "created_utc": "2026-02-23 17:33:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o71anln",
          "author": "Astherol",
          "text": "I guess you misunderstood what self-healing pipeline is. It's not self-repairing but using redundant data injection to heal wrong data",
          "score": 1,
          "created_utc": "2026-02-23 22:41:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o73e73w",
              "author": "DJ_Laaal",
              "text": "So a regular data pipeline with a lookback interval. What a novel idea! (NOT).",
              "score": 0,
              "created_utc": "2026-02-24 06:33:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o71x4ib",
          "author": "Firm_Bit",
          "text": "What do you think “self healing” looks like in practice? I’m curious.",
          "score": 1,
          "created_utc": "2026-02-24 00:46:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72cvmg",
          "author": "sib_n",
          "text": "> Because right now my pipelines are about as self healing as a broken arm.\n\nWell that would be nice, because those do self-heal, although it takes time and sometimes they need some help with alignment!  \nJokes part, I agree with others, it does not exist, unless you count on letting an LLM with agentic mode modify your code in production directly.",
          "score": 1,
          "created_utc": "2026-02-24 02:17:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73s1zv",
          "author": "rgcoach",
          "text": "Completely Self-Healing - don't think it exists yet. However, being solved in smaller bits and pieces - be it through automatic detection of infra resource issues or through capture of upstream source level changes to modify and update entry configs and pipelines. Of course, still needs a human hand to make that decision rather than break things down the line!",
          "score": 1,
          "created_utc": "2026-02-24 08:39:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7483fv",
          "author": "NoFerret8153",
          "text": "Depends what you mean by self healing imo. If you mean zero human intervention ever then no that's not real. If you mean the tool handles routine api updates and schema drift automatically and only escalates truly breaking changes, then yeah a few tools do that reasonably well now.",
          "score": 1,
          "created_utc": "2026-02-24 11:09:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pf9l8",
              "author": "CharacterHand511",
              "text": "Yeah this is kinda where my head is at too. I think I was being too binary about it. like either it fixes everything magically or it's useless. The distinction between \"handles routine stuff automatically\" vs \"zero human involvement ever\" is useful framing. I guess what I really want is something that reduces the 3am pagerduty alerts for stuff that shouldn't require a human in the first place. The truly novel breaks I can deal with, it's the repetitive api version bumps and schema additions that kill morale on the team.",
              "score": 1,
              "created_utc": "2026-02-27 14:29:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o749tto",
          "author": "fckrdota2",
          "text": "My Airbyte instance failed due to logs being full once, other than that it always recovered itself for ms sql to bq  connectors,\n\nSometimes people close cdc when adding new cols, as solution we wrote a job that opens cdc when closed\n\n\nThere are problems with self hosted mongodb and Google sheets though",
          "score": 1,
          "created_utc": "2026-02-24 11:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zsv72",
          "author": "LumpyOpportunity2166",
          "text": "We switched our saas ingestion to precog and the connector maintenance went to basically zero because they handle the api changes on their end. I wouldn't call it self healing exactly but the effect is the same. The pipelines auto update when sources change.",
          "score": 0,
          "created_utc": "2026-02-23 18:24:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ztqa7",
              "author": "CharacterHand511",
              "text": "interesting, so basically you offloaded the connector maintenance problem entirely instead of trying to build self healing logic around it yourself? That's a different approach than what I was thinking but honestly it might be the more pragmatic move. My concern with any managed approach is you're trading one dependency for another but if they're actually keeping up with vendor changes faster than my team can then the math works out.",
              "score": 1,
              "created_utc": "2026-02-23 18:28:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6zykgw",
                  "author": "Nekobul",
                  "text": "Right there. That is one of the major reasons you should be using a third-party vendor.",
                  "score": -3,
                  "created_utc": "2026-02-23 18:50:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zbg1s",
          "author": "NaturalBornLucker",
          "text": "That's new concept for me. Would love to hear about it more even though tbh I doubt it would help us with our pipelines (2 DE, 170 airflow DAGs running spark jobs) cuz often either auto restart helps or something's changed/broken so I'll need to manually investigate. For now the most helpful thing was deploying auto messaging to the corpo messenger in airflow through webhooks in case a DAG fails",
          "score": 0,
          "created_utc": "2026-02-23 17:03:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}