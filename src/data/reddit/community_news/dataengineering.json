{
  "metadata": {
    "last_updated": "2026-02-20 17:10:00",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 387,
    "file_size_bytes": 431574
  },
  "items": [
    {
      "id": "1r83xku",
      "title": "Designing Data-Intensive Applications - 2nd Edition out next week",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/yhoznavzd9kg1.png",
      "author": "sspaeti",
      "created_utc": "2026-02-18 14:07:36",
      "score": 886,
      "num_comments": 102,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r83xku/designing_dataintensive_applications_2nd_edition/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o627c1o",
          "author": "GrandOldFarty",
          "text": "Nice, I cannot wait to buy it and not read it again.",
          "score": 776,
          "created_utc": "2026-02-18 14:46:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62kysu",
              "author": "MadT3acher",
              "text": "When I was interviewing last year, I was telling myself to pick a chapter and focus for 15mn on a topic. It was a great motivator to check stuff I didnâ€™t know.\n\nOtherwise youâ€™re only going to pick it up at 2am to combat insomniaâ€¦",
              "score": 72,
              "created_utc": "2026-02-18 15:50:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o631djn",
                  "author": "kadhi_chawal2",
                  "text": ">Otherwise youâ€™re only going to pick it up at 2am to combat insomniaâ€¦\n\nOr the intense motivation spike of turning your life around at 2 am. \n\n\nGot a bit too specific xd",
                  "score": 42,
                  "created_utc": "2026-02-18 17:04:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62a46q",
              "author": "godmade5",
              "text": "ðŸ˜­ðŸ˜­ðŸ˜­",
              "score": 32,
              "created_utc": "2026-02-18 14:59:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62k56s",
              "author": "Capt_korg",
              "text": "Those books contain a lot of information, but in my experience, they are dust collectors. \n\nAlways motivated to read them and then... Naaah not enough traction to get to the point...",
              "score": 48,
              "created_utc": "2026-02-18 15:46:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o62kuye",
                  "author": "No_Lifeguard_64",
                  "text": "The problem is you are trying to read them cover to cover. Don't do that. Use the table of contents and read the chapter that is applicable to you right now.",
                  "score": 88,
                  "created_utc": "2026-02-18 15:49:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o630427",
                  "author": "LookAtYourEyes",
                  "text": "I just started reading it last week. I have a friend who has read it cover to cover more than once, and treats it like his bible. Dude is dedicated.",
                  "score": 4,
                  "created_utc": "2026-02-18 16:58:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62a4nz",
              "author": "Insighteous",
              "text": "Are you I?",
              "score": 14,
              "created_utc": "2026-02-18 14:59:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62p4y6",
              "author": "richardrietdijk",
              "text": "Thanks. Thereâ€™s coffee on my monitor now. ðŸ˜…",
              "score": 4,
              "created_utc": "2026-02-18 16:09:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6a0j6z",
              "author": "ThatNewWeirdGuy",
              "text": "Wait, is this the adhd subreddit?",
              "score": 3,
              "created_utc": "2026-02-19 17:50:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6a6dij",
                  "author": "GrandOldFarty",
                  "text": "There are non-ADHD subreddits?",
                  "score": 3,
                  "created_utc": "2026-02-19 18:17:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6byj7c",
              "author": "AwkwardBugger",
              "text": "Damn, I donâ€™t remember writing this comment",
              "score": 2,
              "created_utc": "2026-02-19 23:39:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6256o0",
          "author": "Effective_Degree2225",
          "text": "I purchased the 1st one years ago. i think i will buy this and read it finally. thank you",
          "score": 55,
          "created_utc": "2026-02-18 14:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o647gt9",
          "author": "Mclovine_aus",
          "text": "Whatâ€™s is new in this version, compared to first edition?",
          "score": 22,
          "created_utc": "2026-02-18 20:13:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67aqvg",
              "author": "sspaeti",
              "text": "\\> Updated for the cloud and modern times.\n\nComment from a reviewer of the book.\n\nUpdate: Also check out the just newly released talk about edition with with Chris and Martin: [https://youtu.be/UHdPnubbzBI?si=O6AgtxQk0NUWD9rR](https://youtu.be/UHdPnubbzBI?si=O6AgtxQk0NUWD9rR)",
              "score": 4,
              "created_utc": "2026-02-19 06:58:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6aq0bk",
                  "author": "ryati",
                  "text": "that garage gym makes me jealous",
                  "score": 3,
                  "created_utc": "2026-02-19 19:50:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o64f5rg",
              "author": "Commercial-Ask971",
              "text": "Second this",
              "score": 2,
              "created_utc": "2026-02-18 20:50:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o67991c",
              "author": "ares623",
              "text": "I bet $100 there's RAG crap in there",
              "score": 1,
              "created_utc": "2026-02-19 06:46:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o66a85i",
              "author": "tzt1324",
              "text": "Want to know too",
              "score": 1,
              "created_utc": "2026-02-19 02:42:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62guhc",
          "author": "samvander",
          "text": "Would you say the previous version is quite out of date?",
          "score": 12,
          "created_utc": "2026-02-18 15:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68azcc",
              "author": "MathmoKiwi",
              "text": "Lots is still timelessly relevant. But it's good it's getting an update! ",
              "score": 5,
              "created_utc": "2026-02-19 12:25:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o68jbvk",
                  "author": "samvander",
                  "text": "I'm in the early stages of applying for senior data engineer roles and this seems like a godsend, but I'm wondering whether it's better to wait the few weeks for the new one. Do you have any opinion there?",
                  "score": 2,
                  "created_utc": "2026-02-19 13:19:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o62af2h",
          "author": "hau5keeping",
          "text": "Genuinely asking: what is so special about this book?",
          "score": 35,
          "created_utc": "2026-02-18 15:01:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62cbv1",
              "author": "amejin",
              "text": "It breaks down how to handle data flow at a very small and very large scale.\n\nIt's basically a \"how did <insert massive enterprise here> solve their data problems and what organic way did those things come about?\" cookbook. Except it's super generalized in an effort to give you insight on how data, resiliency, and consistency works, so that you can make informed decisions.\n\nBecause of that, and it shows generalities and processes, you understand why we have things like Kafka, reddis, and all the other flavors of big data ingestion and management that has wonderful names that you may or may not have thought to yourself \"what is this crap and why does AWS have 14 services for it?\"\n\nIt will help give you a mental model of data pipelines and how to design \"good\" software that will stand the test of time, with an enterprise mindset. Slow to change, consistent and reliable, and most of all, predictable.\n\nYou know - everything the AI revolution, and shit tier sys admins, have thrown out the window because \"moving fast and breaking shit\" is now an acceptable business model.",
              "score": 122,
              "created_utc": "2026-02-18 15:10:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o62opw2",
                  "author": "Cloudskipper92",
                  "text": "I agree with everything you said BUT \"move fast and break shit\" has been a business model for a long long time, and I'd say isn't going anywhere either for precisely the reason you mention haha.",
                  "score": 14,
                  "created_utc": "2026-02-18 16:07:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o62q2mz",
                  "author": "hau5keeping",
                  "text": "amazing answer, ty!",
                  "score": 3,
                  "created_utc": "2026-02-18 16:13:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6471zr",
                  "author": "gman1023",
                  "text": "I found it was tailored towards software engineering / application development compared to data engineering. ",
                  "score": 2,
                  "created_utc": "2026-02-18 20:11:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o651wd3",
                  "author": "Axel_F_ImABiznessMan",
                  "text": "Would this together with the Kimball data warehouse toolkit cover everything for a data engineer knowledge base?",
                  "score": 1,
                  "created_utc": "2026-02-18 22:35:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o68fjew",
                  "author": "munamadan_reuturns",
                  "text": "So basically system design?",
                  "score": 1,
                  "created_utc": "2026-02-19 12:55:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62c030",
              "author": "MckyIsBack",
              "text": "It is a good and fairly wide introduction into the design of data-centric applications and integration technologies. It is well written and easy to read.",
              "score": 14,
              "created_utc": "2026-02-18 15:08:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62bl99",
              "author": "No_Lifeguard_64",
              "text": "This is the bible on distributed systems and data architecture.",
              "score": 23,
              "created_utc": "2026-02-18 15:06:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62ccpb",
              "author": "JohnPaulDavyJones",
              "text": "Itâ€™s a seminal work in the field, specifically for people who are making the transition from the usual building/repairing/maintenance work that we do at the mid-level/senior DE level to the actual work of *designing* systems at the staff DE/architect level.\n\nItâ€™s not as useful for the more junior folks in the field, except as a reference to help you understand why your senior technical leaders are making the design decisions that youâ€™re seeing.",
              "score": 8,
              "created_utc": "2026-02-18 15:10:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62dj29",
              "author": "mttpgn",
              "text": "It's an overview of several different data storage, transformation, and transmission technologies, organized by problem domain. Helps you think about trade offs in application design by giving a wide breadth of perspective on what types of data processing problems one sees at production-scale, what solutions are out there, and when you'd want to consider implementing certain patterns.\n\nYou could call it a well-researched response to the \"just use postgres\" meme.",
              "score": 6,
              "created_utc": "2026-02-18 15:15:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o642h0l",
              "author": "Kaze_Senshi",
              "text": "It has Pumba as the cover animal. ðŸ—",
              "score": 1,
              "created_utc": "2026-02-18 19:50:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o62s7dq",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -1,
              "created_utc": "2026-02-18 16:23:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64fuv6",
                  "author": "Commercial-Ask971",
                  "text": "What would you recommend for data engineers then?",
                  "score": 1,
                  "created_utc": "2026-02-18 20:53:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o62km06",
          "author": "Grinding_Hard",
          "text": "Thanks. Just a note to myself; itâ€™s not about the book, but what you do after reading it.",
          "score": 5,
          "created_utc": "2026-02-18 15:48:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66agoe",
              "author": "tzt1324",
              "text": "Note to myself; it's not about the book, you have to read it as well.",
              "score": 2,
              "created_utc": "2026-02-19 02:43:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6302up",
          "author": "sisyphus",
          "text": "A modern classic.  I do miss the days when everyone had books at their desk and I could make snap judgments about them by their taste.",
          "score": 3,
          "created_utc": "2026-02-18 16:58:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62bucm",
          "author": "One-Neighborhood-843",
          "text": "Please put NSFW tags on books making people cry.",
          "score": 3,
          "created_utc": "2026-02-18 15:07:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62j6zb",
          "author": "redsoxcraze12",
          "text": "As a heads up, this is released already on O'Reilly",
          "score": 2,
          "created_utc": "2026-02-18 15:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o666nt6",
          "author": "BurgundyTile",
          "text": "FFS, why does O'Reilly put pictures of animals on its book covers?!! ðŸ˜•",
          "score": 2,
          "created_utc": "2026-02-19 02:21:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o672jk3",
              "author": "Spitfire_ex",
              "text": "I like it though? I buy the books for the animals. lol",
              "score": 2,
              "created_utc": "2026-02-19 05:50:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o675aqq",
                  "author": "BurgundyTile",
                  "text": "Why not buy a picture book of animals instead? Much cheaper, isn't it?",
                  "score": 1,
                  "created_utc": "2026-02-19 06:12:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o65mc8n",
          "author": "icehot54321",
          "text": "Donâ€™t buy the book from Amazon \n\nChinese publishers copy and reprint the book and sell it alongside the originals (in the same listing). I ordered a few and some came with yellow pages, others with thin pages like a bible, others with awful printing mistakes. \n\nOâ€™reilly used to only sell through Amazon and I tried to contact them and let them know and their customer service was only interested in closing my ticket.  \n\nGlad to see they at least have one other vendor now.",
          "score": 4,
          "created_utc": "2026-02-19 00:24:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62hpuu",
          "author": "xDragod",
          "text": "Damn. $70 though.",
          "score": 2,
          "created_utc": "2026-02-18 15:35:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63g7ej",
              "author": "decrementsf",
              "text": "Equivalent to $20 in 2020. Not bad.",
              "score": -3,
              "created_utc": "2026-02-18 18:10:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o68822p",
                  "author": "PabloZissou",
                  "text": "But salaries did not keep up with the same increases in prices...",
                  "score": 2,
                  "created_utc": "2026-02-19 12:03:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o69kbje",
                  "author": "kaystar101",
                  "text": "I dont know how true that is lol",
                  "score": 1,
                  "created_utc": "2026-02-19 16:32:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o62hgi6",
          "author": "meSmash101",
          "text": "Started it yesterday on Oâ€™Reilly! Finally!",
          "score": 1,
          "created_utc": "2026-02-18 15:34:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62rxmf",
          "author": "PitifulOpportunity99",
          "text": "I was just about to start with the 1ed (I had the book for like 3+ years)",
          "score": 1,
          "created_utc": "2026-02-18 16:21:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66aqnd",
              "author": "tzt1324",
              "text": "I am also around 3+ years about to start it. Now I have an excuse to wait.",
              "score": 1,
              "created_utc": "2026-02-19 02:45:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62y7f7",
          "author": "mikelson_6",
          "text": "Itâ€™s already available for Kindle - just bought it",
          "score": 1,
          "created_utc": "2026-02-18 16:50:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62yllz",
          "author": "duckenjoyer69",
          "text": "I have the old one from a couple years ago but haven't cracked it yet. Still worth going through? What do we expect the big changes to be (AI presumably)?",
          "score": 1,
          "created_utc": "2026-02-18 16:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o632umr",
          "author": "paxmlank",
          "text": "RemindMe! 1 week",
          "score": 1,
          "created_utc": "2026-02-18 17:11:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o632yr6",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 7 days on [**2026-02-25 17:11:12 UTC**](http://www.wolframalpha.com/input/?i=2026-02-25%2017:11:12%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1r83xku/designing_dataintensive_applications_2nd_edition/o632umr/?context=3)\n\n[**5 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1r83xku%2Fdesigning_dataintensive_applications_2nd_edition%2Fo632umr%2F%5D%0A%0ARemindMe%21%202026-02-25%2017%3A11%3A12%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r83xku)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 3,
              "created_utc": "2026-02-18 17:11:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o634qt9",
          "author": "BlackBeard-007",
          "text": "RemindMe! 1 week",
          "score": 1,
          "created_utc": "2026-02-18 17:19:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63aouw",
          "author": "No-Elk6835",
          "text": "finally!! I've been waiting for this son long!! I love this book!",
          "score": 1,
          "created_utc": "2026-02-18 17:46:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63fghm",
          "author": "ActionConnect5973",
          "text": "The first one was how I cut my teeth when I went from applied math to SWE, but even then it was a little outdated. It's great for people who have zero practical knowledge in backend/data and want a basic overview of how stuff works, or used to work. ",
          "score": 1,
          "created_utc": "2026-02-18 18:07:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63plzj",
          "author": "CriticalComparison15",
          "text": "RemindMe! 30 days",
          "score": 1,
          "created_utc": "2026-02-18 18:51:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63xggw",
          "author": "RealMrHeatmiser",
          "text": "RemindMe! 30 days",
          "score": 1,
          "created_utc": "2026-02-18 19:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63yy9p",
          "author": "JeromeChauveau",
          "text": "RemindMe! 7 days",
          "score": 1,
          "created_utc": "2026-02-18 19:34:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64pvnb",
          "author": "summitsuperbsuperior",
          "text": "RemindMe! 1 week",
          "score": 1,
          "created_utc": "2026-02-18 21:39:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o652mwx",
          "author": "leolas95",
          "text": "I remember watching a talk gave by the author last year and he was explaining that they are making this edition more \"AI friendly\". I'm curious and wonder what that will be! Amazing book.",
          "score": 1,
          "created_utc": "2026-02-18 22:38:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65c2uu",
          "author": "peterxsyd",
          "text": "Why is there a stupid big man bear pig on the front?",
          "score": 1,
          "created_utc": "2026-02-18 23:27:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65kfbh",
          "author": "SearchAtlantis",
          "text": "RemindMe! March 31st, 2026",
          "score": 1,
          "created_utc": "2026-02-19 00:13:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65scft",
          "author": "expialadocious2010",
          "text": "RemindMe! 2 week",
          "score": 1,
          "created_utc": "2026-02-19 00:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69rnrw",
          "author": "Regular-Volume-7344",
          "text": "Just bought the first edition in JanðŸ™‚\n\nAny idea will there be drastic change b/w editions?",
          "score": 1,
          "created_utc": "2026-02-19 17:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69ypm1",
          "author": "wolk-spetter",
          "text": "Any idea what the updates are yet?",
          "score": 1,
          "created_utc": "2026-02-19 17:41:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6akciu",
          "author": "ninjaburg",
          "text": "i tried the audio book of the first edition and realized that was a mistake. i have the 2nd edition ordered for a physical copy.",
          "score": 1,
          "created_utc": "2026-02-19 19:23:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bto04",
          "author": "CyberGoatPsyOps",
          "text": "Is this the special AI edition?",
          "score": 1,
          "created_utc": "2026-02-19 23:10:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6byekk",
          "author": "messi_b91",
          "text": "Lol i just started reading the first one would this be very different and more apt for the current data platform trends",
          "score": 1,
          "created_utc": "2026-02-19 23:38:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c3e0n",
          "author": "swingst",
          "text": "Almost bought the first edition yesterday lol. I guess now Iâ€™m going to order the new edition.",
          "score": 1,
          "created_utc": "2026-02-20 00:07:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fi9dq",
          "author": "Jazzlike-Complex9532",
          "text": "I have the first edition in the post ðŸ˜­ðŸ˜­ðŸ˜­",
          "score": 1,
          "created_utc": "2026-02-20 14:50:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63nre7",
          "author": "PepegaQuen",
          "text": "claude read it and summarize",
          "score": -5,
          "created_utc": "2026-02-18 18:43:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65lr7h",
              "author": "icehot54321",
              "text": "The illusion of knowledge",
              "score": 9,
              "created_utc": "2026-02-19 00:21:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r73l52",
      "title": "In 6 years, I've never seen a data lake used properly",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r73l52/in_6_years_ive_never_seen_a_data_lake_used/",
      "author": "wtfzambo",
      "created_utc": "2026-02-17 11:31:23",
      "score": 427,
      "num_comments": 224,
      "upvote_ratio": 0.97,
      "text": "I started working this job in mid 2019. Back then, data lakes were all the rage and (on paper) sounded better than garlic bread.\n\nBeing new in the field, I didn't really know what was going on, so I jumped on the bandwagon too.\n\nThe premises seemed great: throw data someplace that doesn't care about schemas, then use a separate, distributed compute engine like Trino to query it? Sign me up!\n\nFast forward to today, and I hate data lakes.\n\nEvery single implementation I've seen of data lakes, from small scaleups to billion dollar corporations was GOD AWFUL.\n\nMassive amounts of engineering time spent into architecting monstrosities which exclusively skyrocketed infra costs and did absolute jackshit in terms of creating any tangible value except for Jeff Bezos.\n\nI don't get it.\n\nIn none of these settings was there a real, practical explanation for why a data lake was chosen. It was always \"because that's how it's done today\", even though the same goals could have been achieved with any of the modern DWHs at a fraction of the hassle and cost.\n\nChoosing a data lake now seems weird to me. There so much more that can be done wrong: partitioning schemes, file sizes, incompatible schemas, etc...\n\nSure a DWH forces you to think beforehand about what you're doing, **but that's exactly what this job is about**, jesus christ. It's never been about exclusively collecting data, yet it seems everyone and their dog only focus on the \"collecting\" part and completely disregard the \"let's do something useful with this\" part.\n\nI understand DuckDB creators when they mock the likes of Delta and Iceberg saying \"people will do anything to avoid using a database\".\n\nAnyone of you has actually seen a data lake implementation that didn't suck, or have we spent the last decade just reinventing RDBMS, but worse?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r73l52/in_6_years_ive_never_seen_a_data_lake_used/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5um6li",
          "author": "Secure_Firefighter66",
          "text": "All this is happening because the management needs to adapt to new technologies. \n\nMy company was running in On Prem until 1.5 years back and I was specifically hired to setup AWS + Databricks. Because the management decided its cloud era. \n\nSame tables , same dimensions, but within Databricks. \nOnly positive thing is I get paid to do this.",
          "score": 278,
          "created_utc": "2026-02-17 11:42:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5urpe6",
              "author": "Thavash",
              "text": "And then they release Databricks SQL (after all this damage) and celebrate  \"new features\" like Temp Tables and Stored Procedures",
              "score": 104,
              "created_utc": "2026-02-17 12:23:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5y6m2k",
                  "author": "BakersCat",
                  "text": "This lmao, Databricks/Delta Lake have basically spent the past 6 years reinventing what SQL Server, Postgres etc have been doing anyway for the past 20+ years.",
                  "score": 28,
                  "created_utc": "2026-02-17 22:39:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o60i12p",
                  "author": "ummitluyum",
                  "text": "The wheel reinvention cycle is real ðŸ˜‚ We spent 10 years convincing everyone SQL was \"legacy\" while building complex MapReducelihon/Scala. Now weâ€™re heroically adding SQL interfaces, ACID transactions, and constraints back because... surprise! The business needs reliability, and analysts need SQL\n\nNext step: theyâ€™ll invent Foreign Keys and rebrand it as \"revolutionary semantic linking\"",
                  "score": 11,
                  "created_utc": "2026-02-18 07:10:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5v75ss",
                  "author": "kthejoker",
                  "text": "Neither temp tables nor stored procedures are good patterns for modern OLAP style data warehouse work, even worse on a lakehouse with access to object storage.\n\nIntroducing these is capitulation to migrating legacy system, that's all",
                  "score": 2,
                  "created_utc": "2026-02-17 13:57:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5whuoy",
                  "author": "bornagainsmiles",
                  "text": "This is hilarious and the current state of the times. Lol",
                  "score": 1,
                  "created_utc": "2026-02-17 17:52:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5umtjl",
              "author": "tbot888",
              "text": "Donâ€™t fight it you need to get paid to do something.",
              "score": 39,
              "created_utc": "2026-02-17 11:47:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5uno9u",
                  "author": "Secure_Firefighter66",
                  "text": "Doing that",
                  "score": 9,
                  "created_utc": "2026-02-17 11:53:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5uomsr",
              "author": "runawayasfastasucan",
              "text": "\"What if we made all querying with a lag?\" - databricks.",
              "score": 62,
              "created_utc": "2026-02-17 12:01:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5v0g79",
                  "author": "Visionexe",
                  "text": "Does this not described any modern cloud platform/software as a service? ðŸ¤£ (With some exceptions.) I feel what most companies need is the reliability of IaaS, maybe with a few off the selve db systems. And thats about it.Â ",
                  "score": 10,
                  "created_utc": "2026-02-17 13:19:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5woo2m",
                  "author": "KWillets",
                  "text": "Not a lag, a coffee break.",
                  "score": 3,
                  "created_utc": "2026-02-17 18:23:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5uojwi",
              "author": "PossibilityRegular21",
              "text": "Didn't on-prem have scaling costs and maintenance challenges? I'm not strictly against it, especially with the dominance of AMG, but I couldn't imagine going back.Â ",
              "score": 18,
              "created_utc": "2026-02-17 12:00:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5uoph0",
                  "author": "Secure_Firefighter66",
                  "text": "Well for us the data size is small less than 500 GB. \n\nSo 2 tb itself is good for few years.",
                  "score": 18,
                  "created_utc": "2026-02-17 12:01:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5uop72",
                  "author": "wtfzambo",
                  "text": "37signals spend the last 2 years moving away form cloud and back to on-prem and estimate a $2kk savings or something like that",
                  "score": 18,
                  "created_utc": "2026-02-17 12:01:38",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o5uq2al",
                  "author": "Budget-Minimum6040",
                  "text": "Depends on the data size and data needs.",
                  "score": 7,
                  "created_utc": "2026-02-17 12:11:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5uqvaa",
              "author": "bubzyafk",
              "text": "Many companies goes with modernization as you mentioned.. but many realized itâ€™s similar to data warehouse, then people question â€œwhy need to go with datalakeâ€â€¦\n\nSince you are using Dbx already, then at least you should know.. long time back all started with big data.. 1 variable of big data is the â€œVariatiesâ€, meaning, in this world data is not only Structured.. there are semi structured like log data or IoT and unstructured.. (yeah I know nowadays newer Db has builtin json/xml reader or whatnot to process semi structured, Iâ€™m referring to old classic dwh).. there are Streaming use cases, and not only batch one.\n\nDatabricks or similar hyperscaler not only trying to solve datalake, but they introduced Lakehouse, which tldr â€œdata warehouse on top of datalakeâ€.. you can do many stuffs.\n\nCompany complained and saying, having hyperscaler/cloud/databricks is overkilled. But once your company grows, many different use cases, and if you trying to fit it into old-system dwh, many would fail when you trying to connect it all together. But when you do that to modern tech, even it can process your grandmotherâ€™s picture in binary or do some Machinelearning on top of itâ€¦",
              "score": 8,
              "created_utc": "2026-02-17 12:17:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xuijj",
              "author": "sparkplay",
              "text": "There are other benefits of Cloud though: data retention security, connectors, no single point of failure Head Priest, etc. I've worked in one of many on premise situations where the connection speed was worse than a Cloud POC; we had and one time someone forgot to turn on the AC and all servers crashed.\n\nAlso OP's question isn't about on-prem vs Cloud but DWh vs Data Lakes.",
              "score": 6,
              "created_utc": "2026-02-17 21:40:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5yf5n9",
              "author": "iknewaguytwice",
              "text": "Not even kidding, Iâ€™ve been asked to migrate SQL views and stored procs for Fabric warehouses to replace read only database replicas.",
              "score": 3,
              "created_utc": "2026-02-17 23:24:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5yfduk",
                  "author": "Secure_Firefighter66",
                  "text": "My next project is AWS + Databricks to Microsoft Fabrics. This is due to our parent company wants to centralise the data for all subsidiaries",
                  "score": 1,
                  "created_utc": "2026-02-17 23:26:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5xsgam",
              "author": "thisisntinstagram",
              "text": "Good to know Iâ€™m not alone in this hell.",
              "score": 1,
              "created_utc": "2026-02-17 21:30:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xu78s",
              "author": "Sufficient_Meet6836",
              "text": "Edit: nvm looked your profile a bit and other details didn't match up. Damn that would have been funny\n\nDoes your company do software as a service...\n\n>My company was running in On Prem until 1.5 years back and I was specifically hired to setup AWS + Databricks. Because the management decided its cloud era.\n\n>Same tables , same dimensions, but within Databricks.\nOnly positive thing is I get paid to do this.\n\nWe might work together LMAO",
              "score": 1,
              "created_utc": "2026-02-17 21:38:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5z55c2",
              "author": "thatguywes88",
              "text": "Sounds about what my company is in the process of startingâ€¦",
              "score": 1,
              "created_utc": "2026-02-18 01:46:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5unagf",
          "author": "PossibilityRegular21",
          "text": "I sort of like a bit of lake and a bit of warehouse. A common loading pattern we have been using is:\n\n\n- for streaming: source --> Kafka --> snowflake (snowpipe streaming to tables)\n\n\n- for batches: source --> AWS s3 (~lake) --> snowflake (external tables)\n\n\n- in both cases once in Snowflake: raw staged tables (bronze) --> structured, type-cast, deidentified views (silver) --> Kimball/star/mart views with metadata (gold)\n\n\nI've been liking this system so far. The key difference with streaming and batch in the above cases are that the batch method keeps the raw/bronze data in s3 via external tables, so I guess that's a \"lake\", while the streaming method loads the CDC events into a table resting in the snowflake data warehouse. We use dagster to orchestrate and dbt to run the jobs. The technologies are good - the challenges are behavioural in nature.\n\n\nThere's probably a more consistent way to do the above, but it does work. I guess the lake/s3 component just exists because it is simple and cheap to read from some provided s3 dump than to add a \"copy into\" step. We would probably would have done the same for streaming, but snowpipe streaming is a good enough solution at the moment so we can skip a redundant intermediate load to s3.",
          "score": 74,
          "created_utc": "2026-02-17 11:50:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uox5y",
              "author": "wtfzambo",
              "text": ">for batches: source --> AWS s3 (~lake) --> snowflake (external tables)\n\nWhy to S3? Why not directly to Snowflake, especially since you're already using it as a destination for other data?",
              "score": 7,
              "created_utc": "2026-02-17 12:03:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5v43lg",
                  "author": "Scary-Constant-93",
                  "text": "S3 is like cheap landing zone for data much cheaper than storing everything in snowflake \n\nAlso you donâ€™t need to decide on schema or model data  first as you can store raw data as it is. \n\nAnd most importantly it acts as source of truth which you can use as replay layer it also avoids vendor locking for your raw data\n\nNothing wrong in skipping s3 but you wonâ€™t loose on above benefits",
                  "score": 31,
                  "created_utc": "2026-02-17 13:40:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5uqet8",
                  "author": "Budget-Minimum6040",
                  "text": "In the end you can use every storage, it's just about saving raw payloads without knowing the schema beforehand / guarding against schema drift.",
                  "score": 10,
                  "created_utc": "2026-02-17 12:14:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5uyzy7",
                  "author": "strugglingcomic",
                  "text": "Believe it or not, this can actually be cheaper at the end of the day, vs writing everything directly to physical Snowflake storage (even with the extra storage cost of an extra \"copy\" of data in S3). Also gives you the option of choosing to leave infrequently used data in the S3 storage layer, and only bring the more commonly used columns into physical Snowflake storage (or rarely, sometimes people use this pattern to filter rows and not just columns, in terms of which rows they choose to bring into Snowflake).",
                  "score": 8,
                  "created_utc": "2026-02-17 13:11:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5uq1he",
                  "author": "clbarb",
                  "text": "I used to do this when I led data analytics at a small company. After a while I realized there was no need for S3 (all our data was structured) and I only did it because I was told to. Eventually I scrapped it.",
                  "score": 9,
                  "created_utc": "2026-02-17 12:11:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5vdcuv",
                  "author": "throw_mob",
                  "text": "i did it because access to files from other places was harder when files were stored in snowflake vs s3, but yes it is possible to just save files into snowflake.",
                  "score": 1,
                  "created_utc": "2026-02-17 14:31:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5vkyb5",
              "author": "MgmtmgM",
              "text": "So all of your batch tables are external tables in your raw layer? And then are you using dynamic tables on top of them to build silver?",
              "score": 1,
              "created_utc": "2026-02-17 15:10:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5vm4wt",
                  "author": "pimadd_",
                  "text": "Not op, but we have a similar structure, I use Airflow to build the silver layer. Most of our sources are either apis or databases, so I built two custom dags, one ApitoS3Operator, and one DBToS3Operator which takes yaml configs as input, and then outputs it to S3, then I also have an SQLExecuteOperator which runs the script from raw to silver.",
                  "score": 3,
                  "created_utc": "2026-02-17 15:16:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5y0taj",
                  "author": "PossibilityRegular21",
                  "text": "Not using dynamic tables. As I understand it, the benefit of dynamic tables would be more if we had streamed data and we wanted low latency reads downstream, such as to send data back out of our data warehouse to salesforce. But for slow batches, we are already committing to low enough latency for tables and views in orchestrated DBT jobs.\n\n\nBasically I try to convince stakeholders that they don't need rapid access to OLAP data (they virtually never do) and 24 hr latency is virtually always enough.",
                  "score": 2,
                  "created_utc": "2026-02-17 22:09:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5umrbw",
          "author": "Splun_",
          "text": "I think datalakes exist because data-driven stuff got popular, people started accumulating more data since like 5 years ago when it was all the rage, and then suddenly huge decentralized companies figured that their data infrastructure is hot garbage.\nDatalake and databricks, although costly with money/time/resources, allows to handle that hot garbage in some way â€” easily pump in money into a solution that works within a few clicks, giving people a few tools to pull and process everything in one place.\n\nI always try to choose a proper DB like clickhouse, snowflake, whatever, whenever I can. Model the infrastructure (make it modular and scalable), create some processes, and give power to the people within some defined boundaries. Itâ€™s more work, but I feel itâ€™s easier â€” after inital cost I can go do streaming, swap out tools, optimize DB tables, create alert systems and stuff.\n\nPlus the experience managing your own files, metadata, debugging fucking notebooks is atrocious. But maybe thatâ€™s just me. I like sitting in my black terminal with a box cursorâ€¦.",
          "score": 25,
          "created_utc": "2026-02-17 11:46:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5up5qd",
              "author": "wtfzambo",
              "text": ">itâ€™s more work, but I feel itâ€™s easier â€” after inital cost I can go do streaming, swap out tools, optimize DB tables, create alert systems and stuff. \n\nExactly. Yet I've seen nearly nobody do this.\n\n> Plus the experience managing your own files, metadata, debugging fucking notebooks is atrocious. But maybe thatâ€™s just me. I like sitting in my black terminal with a box cursorâ€¦. \n\nI'm with you on this. If one puts notebooks in prod they should be sent to jail.",
              "score": 12,
              "created_utc": "2026-02-17 12:05:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5wbluy",
                  "author": "SilverShyma",
                  "text": "There's a lot that I would never wanna do in my db or warehouse. It's actually a solid landing zone, I don't wanna deal with unnesting json ingested via APIs or store it all in my db. \n\nPlus the lake gives replayability, so i don't have to go back and talk to slow paginated APIs just to check what went wrong.",
                  "score": 3,
                  "created_utc": "2026-02-17 17:23:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5uq8bp",
              "author": "Budget-Minimum6040",
              "text": "Notebooks are not for prod. Don't run notebooks in prod.",
              "score": 9,
              "created_utc": "2026-02-17 12:12:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5vakui",
                  "author": "R0kies",
                  "text": "And what do you run in prod? Sequence of scripts?",
                  "score": 2,
                  "created_utc": "2026-02-17 14:16:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5vt1ug",
                  "author": "pboswell",
                  "text": "I get what youâ€™re saying, but not everyone has the know-how to productionslize scripts. In a data mesh world, that puts the bottleneck on the engineering team to convert other folksâ€™ stuff.",
                  "score": -3,
                  "created_utc": "2026-02-17 15:50:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5unb3k",
          "author": "dadadawe",
          "text": "Data lake yes, Lakehouse no\n\nMy last 2 projects use a data lake as staging and structured store as warehouse and it works great. Tools and teams can share data onto S3 in their native format and this gets used for many things:\n\n\\- Our own operational dashboards with basically 0 extra costs, no other teams needed\n\n\\- Some local transformations we run for our own processes\n\n\\- Sharing a subset of data with other teams\n\n\\- Staging for the data warehouse (with an SQL abstraction layer)\n\nNow if you try to make your silver layer purely file based... yeah I wouldn't do it if I just have financial and sales data...",
          "score": 24,
          "created_utc": "2026-02-17 11:51:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uo6yg",
              "author": "PossibilityRegular21",
              "text": "Agreed - data lake is fine for bronze/raw. You really want well-defined schema in a data warehouse for the silver/structured layer. Otherwise you introduce so many complications around regulatory compliance, schema evolution, tests and type casting.",
              "score": 12,
              "created_utc": "2026-02-17 11:57:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5uz5sc",
                  "author": "fourby227",
                  "text": "Isnâ€™t this the idea behind a data lakehouse? An hybrid where you may use a data lake for bronze and silver/gold are data warehouses but perhaps in form of iceberg tables on s3.",
                  "score": 11,
                  "created_utc": "2026-02-17 13:12:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5up2v2",
              "author": "confusing-world",
              "text": "Hi. I'm a beginner in the field. Can you elaborate better what is the problem of using files in the silver layer? For example, using parquet there is a bad idea? What technology would you suggest in the silver layer?",
              "score": 4,
              "created_utc": "2026-02-17 12:04:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5uq2xa",
                  "author": "wtfzambo",
                  "text": "Imagine you go to class and take notes. You do this all day every day, so you end the week with a lot of notes but not really organized.\n\nYou can choose to keep them as is and try to arrange them as best you can, or you can choose to re-write them, categorize them, color code, create an index etc, even maybe transcribe them to Notion so that when you need to go and prepare for the DSA exam you don't neet to scamble through 3 binders of notes to find them, you just open Notion and in the search box type \"DSA\".",
                  "score": 8,
                  "created_utc": "2026-02-17 12:11:49",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o5uq5iu",
                  "author": "dadadawe",
                  "text": "The answer is always \"it depends\". \n\nIf your primary use case is data that is inherently structured (which most business data is) then forcing it into Parquet files, building complex compute pipelines is just waste. In the end you'll flattened it into PowerBi or expose an SQL view, so why not use an SQL database, those things are great at structured workloads. Plus everyone can read SQL\n\nThis changes when you have lots of complex data formats, or your data structure changes a lot, or your use case is not analytics or simple data feeds into CRUD tools. Maybe you just have so much data that SQL would explode (unlikely nowadays, but maybe). In those cases, knock yourself out",
                  "score": 5,
                  "created_utc": "2026-02-17 12:12:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5uqrla",
                  "author": "Budget-Minimum6040",
                  "text": "Technology? A database.",
                  "score": 2,
                  "created_utc": "2026-02-17 12:16:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5yxoz2",
                  "author": "pboswell",
                  "text": "Itâ€™s not a bad idea to use parquet. Every database literally just stores the data as files. It basically comes down to portability (i.e. vendor lock-in). If you go with Microsoft SQL server, youâ€™re locked into proprietary file formats. Parquet is portable and almost any technology can interact with them.",
                  "score": 2,
                  "created_utc": "2026-02-18 01:07:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5upc7h",
              "author": "wtfzambo",
              "text": "Interesting take. Lemme ask you this: why not raw directly in the DWH? Are you using a lot of unstructured data?",
              "score": 1,
              "created_utc": "2026-02-17 12:06:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5uqr8q",
                  "author": "dadadawe",
                  "text": "No, mostly JSON and structured tables. I'm sure it can be achieved too with some ETL or messaging platform, but this is the architecture that we used (my two last clients actually) and I think it works well\n\nFor me the main direct benefit is that our own team can just use the data lake data directly. We can add, remove, report etc. Whereas the persistent staging you had in older architectures would be super complex to maintain\n\nI also think there is benefit in storing your data raw in the native format for reuse later (LLM feeding for example) but that's a personal opinion\n\nEdit: it's also very helpful that our team can manage our own folder in the lake, without needing write access to the DWH. We just agree on the overall architecture and the data contracts, but for the rest we manage our own back yard. Back in the day you'd possibly need to spin up a server for that (get it approved) or have some guy's PC run in the background. In the end a datalake in this setup is nothing more than a file server with Cron jobs on steroids",
                  "score": 7,
                  "created_utc": "2026-02-17 12:16:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5uwtv3",
                  "author": "vdueck",
                  "text": "In several projects I depend on other teams exporting data from their own tools. Itâ€™s much easier to tell them to dump files into storage than to explain how to load data into a database.",
                  "score": 3,
                  "created_utc": "2026-02-17 12:57:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5vd9kd",
                  "author": "TheRealStepBot",
                  "text": "Very little real world data is structured in any system of any meaningful complexity. If all you do is push data between systems you control then a warehouse is fine. Most interfaces across org boundaries are minimally documented and ever changing json. If itâ€™s critical to store all this data and process every one of these records you need to be able to have traceability back to how it was parsed and what the original payload was.",
                  "score": 0,
                  "created_utc": "2026-02-17 14:30:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5upteq",
          "author": "siliconandsteel",
          "text": "Because it really is a database, just leveraging cheap cloud storage.",
          "score": 9,
          "created_utc": "2026-02-17 12:09:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uqjdt",
              "author": "wtfzambo",
              "text": "it really isn't a database. Even just getting concurrent writes properly is a goddamn nightmare.",
              "score": 6,
              "created_utc": "2026-02-17 12:15:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5veman",
                  "author": "TheRealStepBot",
                  "text": "You do understand that acidity is not a requirement of all systems right? Itâ€™s a very specific ability that is used to solve very specific issues. There are no free lunches. Blanket acid guarantees are extremely expensive. \n\nBy only providing the concurrency guarantees where you need them when you need them you can independently scale various parts of the system to hit much better throughout than a single blanket guarantee like you find in a traditional database can handle. \n\nWhy do you need concurrent writes? Itâ€™s very easy to coerce concurrent writes into shard bounded writes that only need concurrency within a particular shard which is vastly more performant. Keep following this idea and you eventually get to lakes that have limited inherent concurrency guarantees.",
                  "score": 9,
                  "created_utc": "2026-02-17 14:38:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5v7nil",
                  "author": "kthejoker",
                  "text": "You can turn on isolation modes for pessimistic concurrency like a traditional database if you want to.\n\nLocks everywhere? Go for it",
                  "score": 5,
                  "created_utc": "2026-02-17 14:00:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5v58wl",
          "author": "nus07",
          "text": "Computing is pop culture. Pop culture holds a disdain for history. Pop culture is all about identity and feeling like youâ€™re participating. It has nothing to do with cooperation, the past or the futureâ€”itâ€™s living in the present. I think the same is true of most people who write code for money. They have no idea where [their culture came from].\nâ€”Alan Kay, in interview with Dr Dobbâ€™s Journal (2012) , DDIA\n\nMy leadership sells datalake with the idea that data scientists can do exploratory analysis on the raw unstructured data. Itâ€™s been over a year and I have yet to see any exploratory analysis or insights happen.",
          "score": 9,
          "created_utc": "2026-02-17 13:47:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wbu1c",
              "author": "wtfzambo",
              "text": "That's a very unique and interesting take. I find myself agreeing to it.",
              "score": 1,
              "created_utc": "2026-02-17 17:24:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v0k8u",
          "author": "billionarguments",
          "text": "It's the continuation of the concept of democratization of data, only on steroids. For years it's been all the rage to position data lakes as some sort of magic data library where \"data managers\" float around and browse every byte of the corporate data mass, somehow promoting and furthering those data, preferably delegating the quality and cleaning it up with the insanely over-engineered and dubious conceptual process of data stewardship, and then somehow with no-code UI design a pipeline to make perfect and automatically published and semantically described data sets that anyone can consume at every whim of middle management and executives.\n\nAnyone in this business clearly understood from the beginning that this in 99% of organizations and use cases is a utopian pipe dream. The result are what we see right now.",
          "score": 8,
          "created_utc": "2026-02-17 13:20:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uz7rc",
          "author": "MaverickGuardian",
          "text": "Disagree on the cost part. Depends on usage and data amounts but s3 and Athena in AWS is lot cheaper for us than spinning up redshift. And we can't use other products than what aws has to offer. Data amounts are so big that postgres can't handle adhoc aggregates fast enough anymore. Talking about multiple billions of rows tables.\n\nBut yeah. Setting things up and keeping it running in AWS is painful.",
          "score": 6,
          "created_utc": "2026-02-17 13:12:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wbe7l",
              "author": "wtfzambo",
              "text": "In another comment I wrote about how in some org I worked for, someone had set up a system that managed to rack up $20-40k/month in S3 costs due only to PUT requests, because they were streaming a gazillion of data in 24/7 to iceberg tables from the company's ERP.",
              "score": 1,
              "created_utc": "2026-02-17 17:22:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o615rix",
                  "author": "MaverickGuardian",
                  "text": "Yeah. S3 can get really expensive when written outside AWS.",
                  "score": 2,
                  "created_utc": "2026-02-18 10:48:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5up645",
          "author": "snackeloni",
          "text": "It's because so many people have a tool first mentality. Our staff data engineer is an aws fan boy and I've never seen such a badly implemented, convoluted and overengineered mess. As the analytics engineer I've unfortunately had very little say in all off this. And the fun part: he's the only person that seems to know how any of this works. If this guy leaves, we're fucked. I mean for management I suppose, I'm going to laugh my ass off if that happens :p",
          "score": 10,
          "created_utc": "2026-02-17 12:05:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5upjp1",
              "author": "wtfzambo",
              "text": "> It's because so many people have a tool first mentality\n\nOh man I feel this. I had a glimpse of this horror when an acquaintance of mine asked me \"what's the best tool to learn for data engineering\" and I was like \"no such thing, go study the fundamentals\" and he was pissed at me.",
              "score": 5,
              "created_utc": "2026-02-17 12:07:56",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5vdit0",
              "author": "TheRealStepBot",
              "text": "Just like op with is always use a database idea ironically",
              "score": 1,
              "created_utc": "2026-02-17 14:32:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5umqlw",
          "author": "No-Satisfaction1395",
          "text": "I donâ€™t see any reason why I would want to go back to a database after adopting Delta?",
          "score": 8,
          "created_utc": "2026-02-17 11:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uqe3o",
              "author": "wtfzambo",
              "text": "Because it's like we invented lighters, someone was not happy with it and decided to invent their own version of the lighter but it's a convoluted Rube Goldberg machine that is 1.000.000 times slower and every now and then can explode killing everyone in a mile radius.",
              "score": 2,
              "created_utc": "2026-02-17 12:14:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5uqxaz",
                  "author": "No-Satisfaction1395",
                  "text": "Idk about that, youâ€™re sort of implying that databases are always neat, tidy and faster. They suffer from the same problems. You ever seen a database thatâ€™s a mess? I have.\n\nI just donâ€™t see a reason to pick a database now, unless Iâ€™m forced",
                  "score": 9,
                  "created_utc": "2026-02-17 12:17:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5vg6t4",
                  "author": "TheRealStepBot",
                  "text": "Databases arenâ€™t general, unopinionated abstractions. They are leaky abstractions designed under specific technical constraints to serve particular uses. \n\nYes they are useful in many cases but this idea that they are some perfect abstraction is absolutely ludicrous. Most database engines can trace their histories back to a time when data was stored on tape drives and having a 10mb disk as a â€œfast cacheâ€ in front of that was impressive. They retain much of the accompanying assumptions about what one would want to store and how you would like to store it. \n\nItâ€™s not the 1970s anymore where data arrives in neatly minimalist little individual numbers and varchar arrays. \n\nThere is an absurd amount of unstructured or semi structured data floating around that need to be stored and organized and worked with and traditional databases architecturally just arenâ€™t ready to absorb that.\n\nI think this was more true 5 or 10 years ago that today as you actually are starting to see a lot more hybrid systems that look like databases but behind the scenes are actually managed lakehouses that store stuff to blob storage",
                  "score": 3,
                  "created_utc": "2026-02-17 14:46:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5urm8z",
          "author": "ReporterNervous6822",
          "text": "Maybe. I have implemented a successful data lake and data lake house. The first is just a nice lookup table against blob storage for super raw data (literally encoded chunks of bytes) that we might need at some point in time but always do when they land in s3. The lake house is a massive iceberg table about 10 trillion rows and growing which costs about 8k a month to maintain and provides massive value for the org without any fancy infrastructure other than S3.",
          "score": 5,
          "created_utc": "2026-02-17 12:22:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uwx66",
              "author": "wtfzambo",
              "text": "I'm sure there are good implementations out there. My rant is due to the fact that the majority of what I have seen did not qualify as \"good\".\n\nAnd I wanted to know if I was an isolated case, or not.",
              "score": 3,
              "created_utc": "2026-02-17 12:58:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v8m0d",
          "author": "drag8800",
          "text": "only one data lake i've seen work was at a place that treated it like actual infrastructure. had a dedicated person whose entire job was lake governance - file formats, partition schemes, access patterns, everything. most places want the benefits without the discipline.\n\nthe irony is that the whole pitch was \"avoid upfront schema design\" but the ones that work have MORE discipline than traditional DWH, not less. they just chose to skip the thinking-beforehand part and paid for it in engineering time.\n\n\\~10% of orgs genuinely need a data lake for the unstructured stuff, ML pipelines, etc. the other 90% should've just used snowflake or bigquery and called it a day.",
          "score": 4,
          "created_utc": "2026-02-17 14:05:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wcdmm",
              "author": "wtfzambo",
              "text": ">but the ones that work have MORE discipline than traditional DWH\n\nExactly. I feel that the lvl required is higher.",
              "score": 1,
              "created_utc": "2026-02-17 17:26:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vdkd2",
          "author": "exjackly",
          "text": "Data Lake isn't about recreating a DWH in the cloud.  Though it is what a lot of places do with it.  If all you have are a dozen RDBMS systems that have transactional or MDM data, skip the lake and go straight to a DWH.  The Lake won't get you any benefits.\n\nData Lake makes sense when you are pulling a lot of silos of data together to do analytics on it.  Especially when those silos have the different types of data.\n\nIf you are pulling together video, pictures, audio files, stacks of JSON and XML files, streamed IOT readings, and GIS inputs in addition to your structured database sources, the Lake is going to make your life much easier.  \n\nYou can run the analysis processes on the video, pictures, audio, and GIS inputs in place and have that be in the lake too.  If those analysis tools get updated, it is still easy to reprocess all the impacted source data to feed it forward.\n\nThe semistructured data, similar thing - you choose what elements to bring forward, and when/how to flatten it so you can combine it with the traditional relational data.  And, you have the raw data so you can reprocess if there is a new or changed requirement.\n\nI'm still convinced however, that all of this variety is a distraction that people get caught up in.  We don't process as humans this data in binary, vector or unstructured form.  We don't actually get value out of it until it is reduced/restructured into a relational form of some sort that we can use to make a decision and take an action.",
          "score": 4,
          "created_utc": "2026-02-17 14:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wdvtb",
              "author": "wtfzambo",
              "text": "Correct, unfortunately most people use them for the first case you described, rather than the second.",
              "score": 1,
              "created_utc": "2026-02-17 17:33:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5wrjl9",
              "author": "KWillets",
              "text": "There is no unstructured data, only structures we haven't met yet.",
              "score": 1,
              "created_utc": "2026-02-17 18:37:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5xgw2o",
          "author": "JimiZeppelin1012",
          "text": "I donâ€™t think Iâ€™ve ever seen any software architecture used properly",
          "score": 3,
          "created_utc": "2026-02-17 20:36:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ygaa9",
              "author": "wtfzambo",
              "text": "word",
              "score": 1,
              "created_utc": "2026-02-17 23:31:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5xxrxg",
          "author": "exact-approximate",
          "text": "I agree that the data lake architecture is now being abused and the original purpose of the architectural concept was lost, mainly due to vendor disinformation. At least in my view:\n\n* Data Lakes started somewhere in 2017 providing two main features; streaming unstructured data into some storage easily, and storing a lot of data cheaply outside of a DWH.\n* Data Lakes were super popular in setups which were either spark native or pricey DWH setups (Databricks, Redshift). But in parallel DWH platforms with native separation of storage and compute started to emerge (Snowflake, BigQuery). \n* After some time with companies having massive data lakes, the need for a better file format/engine came around - and Hudi/Iceberg were born from the OSS community, and Delta from Databricks.\n* Somewhere in between people just started to misuse data lakes as data warehouses because it was cheap and easy to do, and allowed for poor planning. Also open table formats became the hot new tech.\n* Today - Snowflake entered the datalake business, Databricks are entering the datawarehouse business, and AWS/BigQuery lets you do anything. \n* For primarily streaming data, a data lake ingestion is still the best architectural concept.\n\nSo no we are in a situation where any platform allegedly allows you to implement whichever architecture you want, irrespective of the roots of the platform.\n\n* You run AWS? Datalake on S3+Iceberg/Hudi+Athena with Redshift as the DWH\n* You run Snowflake? Datalake on S3+Iceberg with Snowflake as the DWH\n* You run Databricks? Datalake on S3+Delta with Databricks Compute Engine and Postgres OLTP\n* You run GCP? BigQuery + GCS + Iceberg\n\nThis is now why data lakes are misused, because all the vendors wanted a slice of any architecture even if it didn't make sense for their product.",
          "score": 5,
          "created_utc": "2026-02-17 21:55:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5y069j",
              "author": "asarama",
              "text": "At the end of the day doesn't this help consumers?\n\nOr do you feel like in the long run we are all footgunning ourselves?",
              "score": 1,
              "created_utc": "2026-02-17 22:06:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ygvi2",
                  "author": "wtfzambo",
                  "text": ">At the end of the day doesn't this help consumers?\n\nI think this is heavily up for debate. For sure, it does help AWS shareholders.",
                  "score": 1,
                  "created_utc": "2026-02-17 23:34:31",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o609vyd",
                  "author": "exact-approximate",
                  "text": "Yes it probably does as a tool no longer restricts your architecture choices, but selecting a tool should be an architecture discussion to begin with.\n\nThe native cloud providers have closed off the gaps which Snowflake and Databricks were positioned to close a while ago, and will continue to do so. I feel it's questionable why one might opt for Snowflake or Databricks in 2026 when you can do everything with a native cloud providers.\n\nOn the other hand people who have gone with Snowflake and Databricks won't be limited.\n\nSo yes the consumer does win here. The thing is that in most cases the consumer is so poorly educated that winning doesn't necessarily result in a good experience. Hence OP's frustrations.",
                  "score": 1,
                  "created_utc": "2026-02-18 06:01:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5uoc3m",
          "author": "DeliriousHippie",
          "text": "For wide variety of users there are no benefits from using data lake instead of DWH. Same goes for much of today's hype. Maybe it's always been that. I've seen many fads during my time. Self Service, Machine Learning, Business Data Warehouse, ELT, etc.\n\nYou know why Iceberg files/tables exist? Because Netflix had problems. Iceberg solves problems when you're size of Netflix. Most of my B2B customers have less than 100 million rows in their largest table, schemas don't change, 90% of tables can be easily read in one go without needing delta loads.\n\nI thought about delta loads awhile back. In past companies owned their servers and data transfer and compute was free. It didn't matter if you fetched half of the tables completely every night and ran all through transformation layer since it didn't cost anything. Now that's bad practice because in cloud everything has a cost.\n\nBut that's the way it is and has been. That's what they pay us to do.\n\nEdit: [https://www.youtube.com/watch?v=b2F-DItXtZs](https://www.youtube.com/watch?v=b2F-DItXtZs)",
          "score": 8,
          "created_utc": "2026-02-17 11:58:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5upou1",
          "author": "rupert20201",
          "text": "For very large datasets, datalake can be cheaper, faster and more flexible to implement BI than traditional EDW like Teradata. ONLY if itâ€™s large enough.",
          "score": 3,
          "created_utc": "2026-02-17 12:08:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ursep",
          "author": "DungKhuc",
          "text": "I don't see any reason why data lake is is bad. And it's even better if you can query that data too.\n\nIf you have an actual data warehousing problem, then build a data warehouse as the next layer after data lake.\n\nYou don't have to choose between a data lake and data warehouse.\n\nI do believe skipping data lake layer nowadays is more often than not a bad decision both tactically and strategically.",
          "score": 3,
          "created_utc": "2026-02-17 12:24:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uyabb",
              "author": "wtfzambo",
              "text": "> I don't see any reason why data lake is is bad\n\nMy take: because you can make the same mistakes you can make on a database AND a lot of other mistakes that a database would not allow you to do.\n\nWhenever I saw datalakes as the core implementation of a stack, it was obvious that a lot of concepts were completely disregarded: file sizing, partitioning structure, I/O latency, I/O cost etc...\n\nOne enterprise I worked for a few years ago was spending ~$20-40k a month in S3 PUT requests alone because someone had decided to stream their entire SAP database to Iceberg tables 24/7, non stop. Needless to say management was not happy about it, but the system they had set up was so phenomenally convoluted that it would have taken a year (pre-AI) to tear down and redo from scratch.",
              "score": 3,
              "created_utc": "2026-02-17 13:06:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vr4ee",
                  "author": "DungKhuc",
                  "text": "I mean that's not the problem with data lake, but more with bad engineering?\n\nI've seen companies wasting millions on Oracle DW, Teradata, and lately Snowflake. The set up can be as convoluted as you can imagine, and most likely not portable and hard to examine at scale.\n\nOn top of that, in my experience, different EDW providers also give you huge licensing headache, so much that most people would give up doing anything innovative.\n\nAnd as said, you don't have to pick one, picking both is usually the right choice.",
                  "score": 2,
                  "created_utc": "2026-02-17 15:40:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5v77yj",
          "author": "KWillets",
          "text": "Database ~~Management System~~\n\nI've worked on a lot of large-scale systems, and the reality is that there's little need to deconstruct the RDBMS architecture, and people who do quickly blow up their headcount. The consistency guarantees are more important at scale, not less.\n\nMy last job had hundreds of thousands of queries running daily on 2000 cores, managed by 2 people, me and a contractor. The data lake had less than a tenth of that load, managed by 4+ FTE's. The main complaint against the RDBMS was that too many people were using it (!).  \n",
          "score": 3,
          "created_utc": "2026-02-17 13:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vhfb7",
              "author": "DatabaseSpace",
              "text": "I work in healthcare which is heavily Azure based and i'm trying to learn new things, so I'm studying Microsoft Fabric, which is based on a specific kind of data lake.  I'm kind of a dinosaur and use SQL, Python and normal databases.  I'm trying to have an open mind about this stuff, but I just keep thinking, how is this better? is this all marketing bullshit to get money to cloud providers by monitizing every single thing that I now do almost free?  The answer from AI is always about scale so maybe I get that a little bit, but I'm not sure.  I'm going to learn it because I feel like I have to, maybe i'm wrong.  ",
              "score": 1,
              "created_utc": "2026-02-17 14:52:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5wdfyu",
                  "author": "wtfzambo",
                  "text": ">so I'm studying Microsoft Fabric\n\nI'm sorry this happened to you",
                  "score": 5,
                  "created_utc": "2026-02-17 17:31:50",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o5wfjeh",
                  "author": "KWillets",
                  "text": "Fabric seems to be taking a fairly reasonable approach. Just this morning in my linkedin feed I see a \"why the warehouse still matters\" story from their product people.\n\n  \n[https://www.linkedin.com/pulse/why-data-warehouse-still-matters-fabric-world-luke-matthews-ezt7e/?trackingId=BiDouGOuaLF5hkmeOk7Ulg%3D%3D](https://www.linkedin.com/pulse/why-data-warehouse-still-matters-fabric-world-luke-matthews-ezt7e/?trackingId=BiDouGOuaLF5hkmeOk7Ulg%3D%3D)",
                  "score": 1,
                  "created_utc": "2026-02-17 17:41:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vjbep",
          "author": "pragmatica",
          "text": "Data swamps have been a thing since Hadoop got popular.\n\nItâ€™s sounds great, dump your data into the lake and figure it out later.\n\nIn practice itâ€™s a mess.",
          "score": 3,
          "created_utc": "2026-02-17 15:02:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5z1kgr",
              "author": "Frosty-Hair6123",
              "text": "Yep, canâ€™t agree more. Unified lake house sounds nice, but users has to be engineers, no analysts really know how to use it unless you have some basic trino or spark knowledge. Enterprise like it because it is cheap, not user friendly",
              "score": 1,
              "created_utc": "2026-02-18 01:27:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yn9m0",
          "author": "hyper24x7",
          "text": "Thank you omg. In 20 years Ive never seen a manager actually know how a data warehouse works let alone a data lake.",
          "score": 3,
          "created_utc": "2026-02-18 00:09:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60d7qd",
          "author": "ummitluyum",
          "text": "The problem is that \"Schema-on-Read\" is the biggest lie in data engineering history. In reality, it means \"Data-Quality-Never\"\n\nWithout enforced schema on write (like in a DWH), your Data Lake turns into a Data Swamp in six months. Engineers spend 90% of their time not on insights, but on writing regexes to parse broken JSON that changed without warning. It's technical debt raised to an absolute",
          "score": 3,
          "created_utc": "2026-02-18 06:29:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61pucf",
              "author": "wtfzambo",
              "text": ">\"Schema-on-Read\" is the biggest lie in data engineering history. In reality, it means \"Data-Quality-Never\" \n\nman, I know right!",
              "score": 1,
              "created_utc": "2026-02-18 13:12:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5umd6k",
          "author": "RandomSlayerr",
          "text": "I havent ever seen it either, i think it sounds cool so some people decide to take that route even though it is complete overkill",
          "score": 4,
          "created_utc": "2026-02-17 11:43:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uq3kw",
          "author": "Thin_Original_6765",
          "text": "It works like technical debt. Itâ€™s meant to be a mean to get things done but not the final product itself.\n\nItâ€™s why you can find teams having well managed data lake, but across the enterprise itâ€™s a mess.",
          "score": 4,
          "created_utc": "2026-02-17 12:11:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vcifd",
          "author": "TheRealStepBot",
          "text": "You are on your soapbox yelling about stuff you obviously donâ€™t understand. \n\nMost trivially all Iâ€™ll say is the DuckDb guys created ducklake. Maybe go watch their technical talk about that as it provides a great explanation for why databases by themselves are limited as well as why blob storage by itself is limited. Traditional databases are basically concurrency managers. They suck at storing any meaningful amount of data however. \n\nLakes, lakehouses are primarily about decoupling storage from compute. It serves two functions when you do this, decreasing cost and decoupling compute scaling. You can have multiple teams scale their own trino or spark or python instances to meet their requirements. \n\nTo the degree they correctly mock religious opposition to structured databases the flip side is just as true. Religious insistence on database engines built for the needs and tradeoffs mainly of the 1970s and 80s is just stupid. \n\nThere are things traditional databases are good at but even comparatively small amounts of data can quickly begin to choke them out. Additionally their scaling properties are complex as they can run into many separate limits that can force scale out or worse yet force a scale up leading to over provisioning. \n\nDatabases are also always hot. They are virtually incapable of handling read almost never data. And you can argue but if itâ€™s almost never going to be read just thrown it away. But thatâ€™s not an argument for traditional databases itâ€™s a limitation. \n\nYou are merely lost in the hype of the technology and donâ€™t actually understand the technical tradeoffs being made. There is a ton of money chasing executives to build lakes because there are vendors with lakes to sell. Things built like this are almost always a mess. That not because of the tech but because of who is building it under what pressures. \n\nThat doesnâ€™t make them a bad an idea. They are a specific tool in the toolbox that can handle a variety of issues that affect traditional systems. They especially are good at enabling self serve data analytics, and other such democratization efforts as the materialization of some absurd table for the vpâ€™s personal use is much less likely to effect the rest of the system. \n\nThey also are very good at recording point in time snapshots of data that would be prohibitively expensive to maintain in most traditional databases which can be a critical enabler for challenging ML problems. \n\nThey go hand in hand with event sourcing systems that are recording a change feed of events rather than an absolute state. If your system doesnâ€™t have this point in time requirement itâ€™s easy to see why you would not appreciate the issues lakes set out to solve. \n\nThere are more use cases they shine at but merely because you already have an oltp database that you treat as a magic black box you donâ€™t understand is no reason to dismiss lake technology you also donâ€™t understand.",
          "score": 3,
          "created_utc": "2026-02-17 14:26:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wd6c5",
              "author": "wtfzambo",
              "text": "You make a lot of assumptions about me, most of them are wrong.\n\nThis said I agree on one point:\n\n> That doesnâ€™t make them a bad an idea.\n\nTrue, they're not a bad idea. Much as dynamite isn't a bad idea. But you wouldn't give it to someone careless now, would you?\n\nNow swap dynamite with data lake, same principle.",
              "score": 2,
              "created_utc": "2026-02-17 17:30:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5wyanj",
                  "author": "TheRealStepBot",
                  "text": "I would actually agree this a mostly apt explanation of the comparison. The primary building blocks are somewhat like fissile material. It can be packaged up in various useful ways. Some to build power plants and some to build bombs. Data lakes use the fissile primitives themselves to potentially very powerful effect. \n\nBut not everyone is a nuclear engineer and giving even nuclear engineers fissile material can lead to mistakes that go boom. Worse yet giving it to the homeless guy on the corner. Itâ€™s gonna go wrong.\n\nTraditional databases are like giving people specific prepackaged power plants already arranged correctly to harness the fissile material into something comparatively useful and mostly safe. \n\nI just tend to get irked by people who act as if these trades donâ€™t exist. They exist and they can give massive boosts to people who know when and how to make use of them.",
                  "score": 2,
                  "created_utc": "2026-02-17 19:08:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5z001p",
              "author": "roararoarus",
              "text": "Great response",
              "score": 2,
              "created_utc": "2026-02-18 01:19:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60ic5a",
              "author": "ummitluyum",
              "text": "Fair point regarding ML and audit, but let's be honest: 90% of data lake users aren't ML engineers looking for snapshots. They are BI analysts who just want to run a simple SUM(sales), and for them, \"cold\" storage is a nightmare because every query triggers a scan of terabytes",
              "score": 1,
              "created_utc": "2026-02-18 07:13:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63psjj",
                  "author": "TheRealStepBot",
                  "text": "Congratulations you just invented open table formats that allow the engine to bound scans without loading data into memory. \n\nThe main challenge is actually counting things by some grouping key that occurs in every file like say \n\nsum transaction_total group by org id\n\nBut even that can be largely solved by first z ordering by important keys at write time.",
                  "score": 1,
                  "created_utc": "2026-02-18 18:52:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6465t2",
              "author": "New-Addendum-6209",
              "text": "Databases designed for analytical workloads are almost always better (and much easier to work with) unless you need to store huge amounts of data.",
              "score": 1,
              "created_utc": "2026-02-18 20:07:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64d88w",
                  "author": "TheRealStepBot",
                  "text": "Which analytical databases are you thinking of when you say this?",
                  "score": 1,
                  "created_utc": "2026-02-18 20:41:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vaaip",
          "author": "Hofi2010",
          "text": "Even though I think datalakes as are useful not every company needs one. Same with a lakehouse. And companies listening to their AWs or Azure solution architect too much and building for scale too early. That is the beauty of a datalake actually you can start small just s3 and scale when you need it, but that doesnâ€™t do much for your solutions architects goal.",
          "score": 2,
          "created_utc": "2026-02-17 14:14:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vd6i0",
          "author": "Nearby_Fix_8613",
          "text": "Honestly I truly believe itâ€™s because most data execs are not data people and have no idea how to use data\n\nBut they make the same promise all the time, this latest tech will solve all problems , then they move on before they are held accountable for any business  impact and rinse and repeat for the next company",
          "score": 2,
          "created_utc": "2026-02-17 14:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vh8dd",
          "author": "PizzaSounder",
          "text": "Why wouldn't you have defined schemas in a datalake?\n\nWe used it as a central store for dozens of teams and it worked well. Individual teams drop their new data on their schedule, in their format. New data merged with existing data, schema is enforced. You can move massive amounts of data in with Spark jobs. Also, I personally love time travel in Delta tables. Free snapshots, rollback protection for those \"oh shit\" updates. \n\nBest part, access is managed centrally and is in a single format. The datalake manages those transformations. You don't have team A requesting access to Team Bs data (which is SQL) and Team C requesting access to Team As data (which is a delta table), Team B requesting access to Team Cs data which is an SAP system. Then there is Team Z which only has incremental CSV files or parquet or some shit. Different systems, different technologies, different requirements. Only the datalake has to deal with that, not every team.",
          "score": 2,
          "created_utc": "2026-02-17 14:51:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vn501",
          "author": "UhhSamuel",
          "text": "The one thing I'll say for DWHs even if they're poorly design (unless they're not just poorly designed, but catastrophically designed): They save you money in the long run. Traditional on-prem DWH requires replacements, upkeep, and people. Within 5-7 years, most mid-to large companies will see a 100% return on investment and then it's all savings.",
          "score": 2,
          "created_utc": "2026-02-17 15:20:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vscg8",
          "author": "Straight-Health87",
          "text": "If I told you that 99% of the data systems I saw and worked with/on donâ€™t need more than a properly designed postgres warehouse backend, would you believe me?\n\nPeople invented all kinds of products and technologies to cater for people (usually management) who donâ€™t have a clue what data is and how it works.\n\nKeep it simple, stupid!",
          "score": 2,
          "created_utc": "2026-02-17 15:46:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5we990",
              "author": "wtfzambo",
              "text": ">If I told you that 99% of the data systems I saw and worked with/on donâ€™t need more than a properly designed postgres warehouse backend, would you believe me?\n\nYes.",
              "score": 2,
              "created_utc": "2026-02-17 17:35:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vwp45",
          "author": "Quaiada",
          "text": "I agree with you. I also see a lot of data lakes being built in a very poor way. But thatâ€™s not my problem. Right now i'm just a data engineer. And if you want me to do a task and are willing to pay me well for it, letâ€™s go.\n\nTo be honest, Iâ€™m tired of trying to explain things and improve the environment.\n\nStakeholders, POs, project management, tech leads, Scrum Masters, directors, and everyone else â€” the overall understanding of the solution on the business side is very low.\n\n At this point, I just want to move my tasks.\n\nAt the end of the day, itâ€™s a company policy where thereâ€™s budget available and the organization needs to spend it. So, in the end, no one really cares whether the product will deliver real value or not. What ultimately matters is the story thatâ€™s being told.",
          "score": 2,
          "created_utc": "2026-02-17 16:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w020h",
          "author": "Skullclownlol",
          "text": "> Anyone of you has actually seen a data lake implementation that didn't suck\n\nYeah, I've had the opposite experience: It has consistently been the easiest to get right in larger teams (for the parts it's good at, not to replace a DWH), even at the bank I worked at. They didn't replace DWHs though, they just fulfilled a specific role.\n\nOld source data goes to long-term archival on (extremely cheap) cold storage, ingestion doesn't break on schema changes, ingestion is idempotent and replayable, significantly cheaper costs compared to storing all source data in the DWH, DWH only serves newest revisions needed for outputs, etc...\n\nThis was all on-prem during my first 3 years at that bank, afterwards parts started to be migrated to Databricks. But only parts of the lake, and the DWH was kept on-prem. So I disagree with other commenters saying this only works either on-prem or either on the cloud.",
          "score": 2,
          "created_utc": "2026-02-17 16:24:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w8la7",
              "author": "wtfzambo",
              "text": "> They didn't replace DWHs though, they just fulfilled a specific role.\n\nAh! See this I think is one of the key differences, when people try to use lakes as if they ware data warehouses as well.",
              "score": 1,
              "created_utc": "2026-02-17 17:08:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5wh9sx",
          "author": "ActionConnect5973",
          "text": "Yes, beautiful truth. Finally. Thing is we will inevitably have to deal with the optimization problem at hand formally. Data lakes are a convenient \"fire and forget\" solution and are still somewhat transparent/configurable, since you can still determine plans and abuse the infrastructure for things it wasn't intended for.\n\nSo... as somebody who likes to get their hands dirty in the name of saving costs, it offers a lot of opportunities. Is it optimal? No. Is it better than a single DWH? Absolutely, because you generally have more freedom (delta lake implementations like databricks for instance, though they are now making it harder to be a dev with hidden stuff that your jar will not contain...)",
          "score": 2,
          "created_utc": "2026-02-17 17:49:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xkm1r",
          "author": "Content-Soup9920",
          "text": "Data lakes are like communism.  Theoretically, if you would go al the way through, lift all Metadata, create a good catalog, provide self seevice data services, it could work, would be good. But nobody ever implements it \"full\" so it is always a disgrace.",
          "score": 2,
          "created_utc": "2026-02-17 20:53:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y01ix",
          "author": "TheSchlapper",
          "text": "I started at a new mid sized company who had one guy prop up the entire medallion by himself from scratch. Now we have a single day source to call on in all of our reports. Best Iâ€™ve seen thus far\n\nBut this guy also runs Microsoft events and such so heâ€™s definitely keeping up with best practices",
          "score": 2,
          "created_utc": "2026-02-17 22:06:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yh1gj",
              "author": "wtfzambo",
              "text": "massive envy",
              "score": 2,
              "created_utc": "2026-02-17 23:35:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5z91xu",
                  "author": "TheSchlapper",
                  "text": "Yeah Iâ€™m realizing that if a business has sensitive data then it takes things about 10-20 years longer to catch up to current industry standards\n\nIf you can, work in an industry that doesnâ€™t base value of off PII and other strict data standards",
                  "score": 1,
                  "created_utc": "2026-02-18 02:05:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ymn21",
          "author": "DJ_Laaal",
          "text": "Datalakes were a promising concept about a decade ago when it started off as an alternative for storing semi structured and unstructured data. The traditional database technologies with a Kimball/Inmon style data architecture on top served the structured data storage and querying usecases really well. \n\nIt all turned to shit when companies (and vendors) started abusing it as a â€œthrow all your data here and weâ€™ll think about what to do with it laterâ€. It became an unorganized data swamp right out of the gate. \n\nThen came the newer vendors like Databricks and Snowflake. Layered a distributed, separate compute layer on top of the datalake, added few governance capabilities and it started to become slightly better. However, I see them going down the same path now with crap like â€œlakebaseâ€ (i.e a traditional database but on cloud storage). Why do we even need this shit? We already have dozens of database techniques that do exactly that. \n\nNowadays, I equate datalake with just scalable cloud storage and nothing more.",
          "score": 2,
          "created_utc": "2026-02-18 00:06:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zvwkn",
          "author": "Personal-Reflection7",
          "text": "Very recently we suggested a client to build a simple warehouse (i.e. limited data, modeled for reporting n dashboards etc) - and later move to a lakehouse when the need arises for use cases that need dumps of data for EDA etc\n\nThe C level asked us to specifically rephrase it to calling a Data Lake - despite agreeing with this route",
          "score": 2,
          "created_utc": "2026-02-18 04:19:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61pqwv",
              "author": "wtfzambo",
              "text": "> The C level asked us to specifically rephrase it to calling a Data Lake - despite agreeing with this route \n\nJesus christ",
              "score": 1,
              "created_utc": "2026-02-18 13:12:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65nbii",
          "author": "wildthought",
          "text": "Let me let you in on a little secret, and it's very much impacted my career and direction.  Large consulting revenues are starting to drop or plateau in the data space.  Then something needs to be done.  Ideas are created and then disseminated because they ENRICH vested interests.  I have implemented Data Lakes in the largest scenarios within US Corporate structures.  The winners of the game are always the Big 4 and consulting arms of large tech companies.   They also swap roles over time between the C-suite in corporate and Senior Partners in consulting.   This game, where vendors push the latest technology and we, as practitioners, support them because it's good for our resumes, is why technical data engineering has not advanced.  ",
          "score": 2,
          "created_utc": "2026-02-19 00:29:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67raen",
              "author": "wtfzambo",
              "text": "Makes me wanna cry. There's few things that I hate more than the Big4 on this planet. On top with it is subpar engineering because some C-level bitch needs to \"maximize shareholder value\".",
              "score": 2,
              "created_utc": "2026-02-19 09:36:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65ox0b",
          "author": "Hot_Map_7868",
          "text": "lol, totally agree. some ppl like to focus on \"cool\" tech, for no good reason. I was on a project doing a lake using Databricks. We ended up creating a file based DW. These days I say skip the mess and just go with Snowflake.   \nI also like the premise of DuckLake, keep things simple.",
          "score": 2,
          "created_utc": "2026-02-19 00:38:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5us0ek",
          "author": "Thavash",
          "text": "There is also further damage in that many young professionals never developed skills in dimensional modelling (ie how to properly design a Kimball style warehouse ) as they entered the industry during the Databricks / Data Lake mania era",
          "score": 4,
          "created_utc": "2026-02-17 12:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uyh6s",
              "author": "wtfzambo",
              "text": "Indeed. TBH I am one of those victims, I have to figure it out myself and it's quite difficult when no one around you is doing it.",
              "score": 4,
              "created_utc": "2026-02-17 13:07:51",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o60j8w6",
              "author": "ummitluyum",
              "text": "Itâ€™s the Big Data marketing brainwash. We spent 5 years being gaslit into believing \"JOINs are slow\", so everyone denormalized everything to death\n\nNow we have analysts terrified of writing a JOIN, scanning 50TB tables just to fetch three columns. The funniest part is watching them reinvent the wheel trying to enforce data integrity in this mess - basically jankily reimplementing Foreign Keys in Python inside their DAGs. Kimball is probably rolling in his grave (even though heâ€™s still alive) looking at these \"modern\" data lakes",
              "score": 1,
              "created_utc": "2026-02-18 07:21:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60wccy",
                  "author": "Thavash",
                  "text": "Just awful",
                  "score": 1,
                  "created_utc": "2026-02-18 09:23:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5uqffl",
          "author": "k00_x",
          "text": "Our work data lake is literally just a SQL Server 2019.",
          "score": 2,
          "created_utc": "2026-02-17 12:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uzgoc",
          "author": "neuromantic13",
          "text": "If you have a primarily spark based etl, then a data lake makes some sense, though in many cases itâ€™s easier to just have an external hive catalog, which basically does the same thing and doesnâ€™t force you to constantly do table maintenance to clean up old data. I was forced to implement iceberg to make snowflake cheaper to run so we could save on storage.",
          "score": 1,
          "created_utc": "2026-02-17 13:13:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v145p",
          "author": "New-Addendum-6209",
          "text": "I agree. If you don't have huge volumes of event data you don't need a data lake.",
          "score": 1,
          "created_utc": "2026-02-17 13:23:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v1tuk",
          "author": "Comfortable-Power-71",
          "text": "Preach!",
          "score": 1,
          "created_utc": "2026-02-17 13:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v2wdu",
          "author": "kevkaneki",
          "text": "But have you tried a Data Lakehouse though? \n\nlol",
          "score": 1,
          "created_utc": "2026-02-17 13:33:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v48xt",
          "author": "Eleventhousand",
          "text": "I think it worked decently for us when I worked at Amazon.  I wouldn't really recommend one for a small or medium sized company though.",
          "score": 1,
          "created_utc": "2026-02-17 13:41:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v7qy6",
          "author": "Bosshappy",
          "text": "With over 25+ years of experience, I have to say, in general, I like data lakes.  Back in ye olden days, writing ETL was touch heavy and very expensive.  Mistakes, double loads, missing loads would take a day to fix, going back to the 80s-90s all week to fix.\n\nNow itâ€™s just a matter of dropping the tables and recreating them.  With that said, data architects are notoriously spineless when talking to business.  Business will state: â€œWe need 10 TB of data, but we have no idea who will use it and whyâ€.  After the project is built and the dust settles, one guy will use it twice a year and when you go back to business with proof of the cost and effort to maintain their â€œnecessaryâ€ data, business will insist they still need it",
          "score": 1,
          "created_utc": "2026-02-17 14:00:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wdniq",
              "author": "wtfzambo",
              "text": ">With that said, data architects are notoriously spineless when talking to business.\n\nOh my god, preach! I say this all the time! No one fucking listens. It's always \"but they said they want all data and what if it scales?\". Jesus christ.",
              "score": 2,
              "created_utc": "2026-02-17 17:32:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v91rn",
          "author": "Professional_Eye8757",
          "text": "Iâ€™ve seen the same thing. Most â€œdata lakesâ€ end up as expensive dumping grounds with a thin SQL veneer slapped on top. The few that work well only do so because a disciplined team treats them like an actual database instead of a magical bucket that will somehow organize itself.",
          "score": 1,
          "created_utc": "2026-02-17 14:07:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v992h",
          "author": "RoestG",
          "text": "As I understand it a lakehouse architecture is more suited if there is a lot of demand for ad hoc analyses where there is no clear picture of the desired end result. Which would primarily be data scientists. When you are looking for uniform and standardized data sets suited for dashboards and standard vetted reports, then you would use a data warehouse, or its younger brother a data lake house. The latter has a data lake as a base layer, with a uniform and standardized layer on top which functions more as a dwh.",
          "score": 1,
          "created_utc": "2026-02-17 14:09:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vb3h6",
          "author": "SLTxyz",
          "text": "My org's data lake is an absolute shit show",
          "score": 1,
          "created_utc": "2026-02-17 14:19:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vb9sn",
          "author": "FantasticEquipment69",
          "text": "As a data engineer with 2 years of experience (specifically DWH modeling), I struggle to understand sometimes why this customer wants a Data Lake. Like fr what's wrong with the OG architecture of \"Data Sources --> Staging --> DWH\" ESPECIALLY WHEN YOUR DATA IS ONLY STRUCTURED DATA.\n\nAlso, it's quite confusing for me when do you decide that you need a data lake instead of your current running DWH?\n\nIs it just a marketing strategy (as many claims) to get big corporates to think they are outdated which will lead the mid-level/small companies to follow the trend as well?",
          "score": 1,
          "created_utc": "2026-02-17 14:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vjwmr",
          "author": "defuneste",
          "text": "I will gave you an example: bigish data that get updated every 6 months but rarely revised (and revised here could be fine), same schema where you just append files in a hive partitioned parquets. \n\nDo that use cases match all types of data? hell no! but did it match a lot of analytics data? hell yes! (doing it monthly is perfectly fine) A lot of analytics related decisions should not be \"realtime data\" anyway.",
          "score": 1,
          "created_utc": "2026-02-17 15:05:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5we346",
              "author": "wtfzambo",
              "text": "This is the type of use case I endorse but not the type of use case that the average business (ab)uses data lakes for.",
              "score": 2,
              "created_utc": "2026-02-17 17:34:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vjxej",
          "author": "West_Good_5961",
          "text": "Data lake as a dumping ground. Then load it to data warehouse. Seems like the sensible and popular pattern.Â ",
          "score": 1,
          "created_utc": "2026-02-17 15:05:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vkw1g",
          "author": "asevans48",
          "text": "I get ya. Use them for API calls. My last boss took a year or so to cone to terms with how they werent the holy grail or data. She wasnt technical at all. Had a gov background in data analytics. I dont think data warehousing is 100% a solution either. Flat and even denormalized native tables in an olap engine are great for analytics. Its possible to save data in cloud storage in aws and gcp for n amount of time if anyone wants to build an iceberg table. Other use cases might include fintech where you may need time travel or its schemas arrive entirely in JSON via kafka which still requires a curated zone. Literally had to convince my boss that sticking 1 million custom 20 row excel files in anything othet than cloud storage for power bi was a waste.",
          "score": 1,
          "created_utc": "2026-02-17 15:09:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vtm3k",
          "author": "albsen",
          "text": "we are running pgduck on parquet files that are generated from OLTP databases, querying those using duckdb via pgduck is a fraction of the query time compared to SQLServer or postgres. not sure if you'd call this a datalake or a dwh. the ETL job syncronizes the schemas so that you don't have a hard time joining in pgduck.",
          "score": 1,
          "created_utc": "2026-02-17 15:52:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wd3p9",
          "author": "Kilnor65",
          "text": "As someone who has only worked with normal SQL, could you just list a couple of things that makes it worse than SQL? I always have use cases where just \"throwing the data in a pile\" would be kind of nice instead of making a bunch of new garbage tables or columns.",
          "score": 1,
          "created_utc": "2026-02-17 17:30:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5x3u52",
              "author": "wtfzambo",
              "text": "> \"throwing the data in a pile\" \n\nDo this with your clean laundry the next 4 weeks and tell me if you'll still be able to find the clothes you're looking for.",
              "score": 1,
              "created_utc": "2026-02-17 19:34:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ynndj",
          "author": "spendology",
          "text": "Data lakes have electrolytes - that's why!!",
          "score": 1,
          "created_utc": "2026-02-18 00:12:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z69ru",
          "author": "IllAppeal4814",
          "text": "In our case, we moved from redshift (dwh+query engine+ metadata store) to more like lakehouse (not dumping everything, but sort of partitioned based storage eg: client/yyyymm/datasource/ strategy) composed of s3, query engine + glue catalog as metadata store, in order to increase only the compute, but keeping storage cost bare mininum as we required more compute (although we were okay with current storage)\n\nWe maintained partitioned storage as our reporting were based on client filtering based OLAP query, that usually demanded aggregated result of certain time period. So it was stored to make query engine filter fast from the partitioned storage",
          "score": 1,
          "created_utc": "2026-02-18 01:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z7si8",
          "author": "Disastrous_Answer905",
          "text": "I just export the same excel set up everydayâ€¦",
          "score": 1,
          "created_utc": "2026-02-18 01:59:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zrjrr",
          "author": "Next_Comfortable_619",
          "text": "im coming from a very heavy sql server background and have been watching hundreds of hours of videos on YouTube about databricks and snowflake. databricks makes me cringe but i do like snowflake. the modern data engineering stack is a dumpster fire though. also, lol @ using python ti manipulate data instead of sql. cringe.",
          "score": 1,
          "created_utc": "2026-02-18 03:51:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63km6v",
          "author": "givnv",
          "text": "No. Me neither. The new normal is also to gasp over a table with 30 columns and a 100M rows and call it for huge. 5 years ago, my poorly managed and not maintained SQL Server would laugh at table of this size.\n\nBut oh well, it is cloud, it is smart and it is AI so who am I to judge.",
          "score": 1,
          "created_utc": "2026-02-18 18:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a888q",
          "author": "alx-net",
          "text": "In a Trino+Iceberg setup I don't see any issues, it is basically like a normal database. You have to define schemas etc but you are still very flexible with storage and compute? Ofc when you load parquet files randomly into a bucket things get messy. ",
          "score": 1,
          "created_utc": "2026-02-19 18:26:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c1wy4",
          "author": "Alternative-Adagio51",
          "text": "My experience has been a bit different. I am currently using both Oracle Exadata on OCI and Databricks on Azure datalake and I find Databricks to be far superior in developer workflows, compute flexibility, and scaling.\n\nDatalake by itself is of less value but when using with Databricks itâ€™s a different story.",
          "score": 1,
          "created_utc": "2026-02-19 23:59:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c98db",
          "author": "soundboyselecta",
          "text": "Yes spaghetti in and spaghetti out equals phat pockets for JB.",
          "score": 1,
          "created_utc": "2026-02-20 00:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ecviz",
          "author": "Tzimitsce",
          "text": "The silver bullet syndrome is very common in tech place:  \n[https://www.youtube.com/watch?v=qamzvLfX-Zo](https://www.youtube.com/watch?v=qamzvLfX-Zo)",
          "score": 1,
          "created_utc": "2026-02-20 10:17:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uwnpq",
          "author": "MonochromeDinosaur",
          "text": "Data lake is only needed of your data is so unstructured you canâ€™t get it into a table format or so big your optimized queries are slow. \n\nAlmost no company has this problem. Hell most companies could use postgres for analytics for years. \n\nExecs fall for marketing.",
          "score": 1,
          "created_utc": "2026-02-17 12:56:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ur2sc",
          "author": "iammerelyhere",
          "text": "I thought I was the only one! Omg life was simpler when all I had to manage was a handful of sql servers and a file systemÂ ",
          "score": 1,
          "created_utc": "2026-02-17 12:19:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v31eu",
          "author": "peterxsyd",
          "text": "You are 100% right.Â ",
          "score": 0,
          "created_utc": "2026-02-17 13:34:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v3bvu",
              "author": "peterxsyd",
              "text": "The thing is cloud providers love databricks because it is unstable as fuck suffering from OOM java errors, so that means big data job re runs on their rented compute. Literally make microsoft more money.",
              "score": 3,
              "created_utc": "2026-02-17 13:36:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r83gjr",
      "title": "Microsoft UI betrayal",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/l91uf1qlc9kg1.jpeg",
      "author": "daxdaxy",
      "created_utc": "2026-02-18 13:48:32",
      "score": 174,
      "num_comments": 22,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r83gjr/microsoft_ui_betrayal/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o62b7sa",
          "author": "SupaWillis",
          "text": "{\"code\":\"BadRequest\",\"message\":null,\"target\":\"pipeline//runid/XXXX\",\"details\":null,\"error\":null}\n\nThank you ADF",
          "score": 111,
          "created_utc": "2026-02-18 15:04:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63u7p2",
              "author": "mertertrern",
              "text": "My table is now full of rows with nothing but NULL values. Job failed successfully ðŸ‘.",
              "score": 20,
              "created_utc": "2026-02-18 19:12:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o650tfp",
              "author": "igna_na",
              "text": "Oh no, no this again",
              "score": 8,
              "created_utc": "2026-02-18 22:29:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o65d6mv",
              "author": "dentinn",
              "text": "Error code equivalent of ðŸ‘",
              "score": 6,
              "created_utc": "2026-02-18 23:34:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62wyc2",
          "author": "RipProfessional3375",
          "text": "Never, ever touch a technology that is not designed for the people using it. Worst mistake of my life.",
          "score": 42,
          "created_utc": "2026-02-18 16:44:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o673br6",
              "author": "Outrageous_Let5743",
              "text": "The only good thing in ADF is the copy activity, that thing is  quick. The rest is designed like ' what if a non tech person want to make a data pipeline'  which never happens anyway",
              "score": 11,
              "created_utc": "2026-02-19 05:56:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o64ni3z",
              "author": "dfwtjms",
              "text": "And by the people using it.",
              "score": 4,
              "created_utc": "2026-02-18 21:28:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o66ei9k",
              "author": "kbisland",
              "text": "What do you mean? Sorry donâ€™t get it",
              "score": 1,
              "created_utc": "2026-02-19 03:07:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67dwpq",
                  "author": "RipProfessional3375",
                  "text": "'programming' UIs of products designed to be literally sold to managers rather than figuratively sold to developers.",
                  "score": 2,
                  "created_utc": "2026-02-19 07:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64arpe",
          "author": "xean333",
          "text": "I really love and hate ADF man.",
          "score": 18,
          "created_utc": "2026-02-18 20:29:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6531zn",
          "author": "sparkplay",
          "text": "I truly and passionately abhor ADF. Not a single actual user or even tech minded person could have contributed to such an app's  requirements. For anyone saying, \"oh but it works\", well, so does a horse-drawn carriage even today.",
          "score": 17,
          "created_utc": "2026-02-18 22:40:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62g3nn",
          "author": "Outrageous_Let5743",
          "text": "Have you seen SSIS UI. That is even worse",
          "score": 20,
          "created_utc": "2026-02-18 15:27:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64fr2h",
              "author": "Toe500",
              "text": "Well SSIS is also from MS, so not surprising",
              "score": 11,
              "created_utc": "2026-02-18 20:52:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o680ixz",
              "author": "circumburner",
              "text": "Who needs UI when you can edit XML like a gigachad?",
              "score": 5,
              "created_utc": "2026-02-19 11:02:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o64cjmf",
          "author": "Astherol",
          "text": "Oh yeah, and rolling back commits on Azure DevOps because it throws some weird ass stuff during publishing.",
          "score": 8,
          "created_utc": "2026-02-18 20:37:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6611kn",
          "author": "Mightygamer96",
          "text": "not DE, but i have the same hatred for all their online services.\n\nPower Automate, PowerApps, Fabric.",
          "score": 3,
          "created_utc": "2026-02-19 01:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o688mqn",
              "author": "EclecticEuTECHtic",
              "text": "PowerBI is best in class though.",
              "score": 5,
              "created_utc": "2026-02-19 12:08:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6cp12e",
                  "author": "Mightygamer96",
                  "text": "I hate how restrictive it is and you have to find weirdly creative ways to do things.\n\nbut then i try to find alternatives. and get sent straight back to PBi.",
                  "score": 1,
                  "created_utc": "2026-02-20 02:18:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6fytg8",
                  "author": "Lastrevio",
                  "text": "Qlik is much more intuitive to use",
                  "score": 1,
                  "created_utc": "2026-02-20 16:09:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o69cd8g",
              "author": "Outrageous_Let5743",
              "text": "I have never ever seen a use case for power automate",
              "score": 1,
              "created_utc": "2026-02-19 15:54:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o69wq77",
                  "author": "Tee_hops",
                  "text": "I have a weird one. \n                                                 \nWe used azure devops to allow in field PMS to make changes on parts of their major projects. They all fed up into the program manager. So we used power automate to run scheduled queries in AzDo to pull the info and extract it to a csv file in SharePoint. From there we used SnapLogic to load into Snowflake to power a dashboard made in Power BI.\n                                       \nThough we did use the SharePoint CSV to also send alerts via teams that there was a change made in specific rows to bring awareness to our program manager.",
                  "score": 1,
                  "created_utc": "2026-02-19 17:32:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ezl2u",
                  "author": "SirBardsalot",
                  "text": "I had the glorious experience of having to make transactional flows between our dataverse CRM system and on-premise ERP system using Power Automate.   \n\nThey didn't want to hire a developer to build an actual API interface between the two systems so they had me build this in Power Automate. Hundreds of millions are made here and the company still runs on my shitty flows. ",
                  "score": 1,
                  "created_utc": "2026-02-20 13:09:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r6rz37",
      "title": "Just overwrote something in prod on a holiday.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r6rz37/just_overwrote_something_in_prod_on_a_holiday/",
      "author": "Due_Rich_616",
      "created_utc": "2026-02-17 01:07:55",
      "score": 143,
      "num_comments": 32,
      "upvote_ratio": 0.95,
      "text": "No way to recover due retention caps upstream.\n\nPray for me.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r6rz37/just_overwrote_something_in_prod_on_a_holiday/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5su1nw",
          "author": "ChipsAhoy21",
          "text": "when big fuck ups happen itâ€™s important to remember they donâ€™t happen in a vacuum. There are systems missing that should have prevented that, whether itâ€™s better backups or better access controls or better testing. \n\nWrite up a strong post mortem, and prescribe a system you can implement that will prevent someone else from doing the same thing in the future, and turn it into a win for yourself",
          "score": 182,
          "created_utc": "2026-02-17 02:55:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5sy42x",
              "author": "delftblauw",
              "text": "Adding in on this great advice, make sure the post mortem doesnâ€™t sound like itâ€™s avoiding personal accountability and is forward looking.  \n\nIf you find adding in an approval gateway would be helpful, itâ€™s a world of difference between reading, â€œIf we had approval gateways for execution this would never have happenedâ€ versus â€œAdding in approval gateways for execution will help to limit production execution exposure in the futureâ€.  \n\nIf the problem was severe, I would fire the person who wrote the former and work to keep the latter.",
              "score": 47,
              "created_utc": "2026-02-17 03:20:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5skyoa",
          "author": "LaserKittenz",
          "text": "The best way to deal with the stress chemicals you are probably flooded with is to exercise. Â Â ",
          "score": 127,
          "created_utc": "2026-02-17 02:00:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5sn4cm",
              "author": "Due_Rich_616",
              "text": "Genuinely couldnâ€™t stop pacing around the room. Beyond cooked. I was having such a nice day too ðŸ˜¢",
              "score": 62,
              "created_utc": "2026-02-17 02:13:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tklnj",
                  "author": "heretoask23",
                  "text": ":((( what do you think will happen?",
                  "score": 9,
                  "created_utc": "2026-02-17 06:00:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5scxu4",
          "author": "SimpleSimon665",
          "text": "You don't have backups to restore from?",
          "score": 32,
          "created_utc": "2026-02-17 01:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5se27t",
              "author": "Due_Rich_616",
              "text": "Not for some PII heavy tables pipelines upstream, they get purged after n days, lost maybe like 6 months of stuff :( (essentially fucked up the easiest backfilling job of my life)",
              "score": 49,
              "created_utc": "2026-02-17 01:19:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5sg5ty",
                  "author": "Atticus_Taintwater",
                  "text": "Happens to the best of us\n\n\nIn the future what you should do is not that",
                  "score": 123,
                  "created_utc": "2026-02-17 01:31:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5snz1p",
                  "author": "Prinzka",
                  "text": "Just have AI hallucinate some bs to fill in the gaps.",
                  "score": 43,
                  "created_utc": "2026-02-17 02:18:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5t2iod",
          "author": "datascientistdude",
          "text": "Having a downstream with longer retention than upstream and no way to recover (cold storage, undelete, etc) was a disaster waiting to happen anyway. You just happened to be the catalyst. Your company data warehouse and infrastructure isn't set up correctly.",
          "score": 29,
          "created_utc": "2026-02-17 03:49:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t519g",
              "author": "no_4",
              "text": "100% this, OP. This was *going to happen someday*. It just so happened it was right now. \n\nThat lack of a backup of your downstream data is the real fault. Not that it's an uncommon one.",
              "score": 15,
              "created_utc": "2026-02-17 04:05:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5snzlt",
          "author": "Patient_Professor_90",
          "text": "Send wishes for a president day miracle, for you",
          "score": 10,
          "created_utc": "2026-02-17 02:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sv5tb",
          "author": "SearchAtlantis",
          "text": "It's not your fault - there are policy and system issues that allowed the event to occur. The swiss cheese theory of accidents",
          "score": 10,
          "created_utc": "2026-02-17 03:02:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5suvjd",
          "author": "MonochromeDinosaur",
          "text": "I know that feeling. I caused an incident like this by deleting a kafka topic once.",
          "score": 10,
          "created_utc": "2026-02-17 03:00:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tliuh",
          "author": "Thlvg",
          "text": "One of us! One of us!\n\nEdit to add: it happened to all of us, it's almost a rite of passage at that point. And seeing the setup you described, it was going to happen at some point, it's not on you. \n\nNow use that incident to learn how you can protect yourself for next time :)",
          "score": 10,
          "created_utc": "2026-02-17 06:08:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sl8cd",
          "author": "eagerunicorn",
          "text": "Sending virtual hugs.Â ",
          "score": 7,
          "created_utc": "2026-02-17 02:02:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t250c",
          "author": "gandhishrugged",
          "text": "I know that feeling mate. Own up, and if the company is good, they will give you a break. If not, they are not worth it",
          "score": 5,
          "created_utc": "2026-02-17 03:46:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5szjpp",
          "author": "huessy",
          "text": "F",
          "score": 3,
          "created_utc": "2026-02-17 03:29:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tjya9",
          "author": "dudeaciously",
          "text": "This happens to every one of us eventually.  Live and learn.  Tragedy plus time equals comedy.",
          "score": 4,
          "created_utc": "2026-02-17 05:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tp2z9",
          "author": "BubbleBandittt",
          "text": "Whatâ€™s tech stack are you using? Some techs allow for time travel.",
          "score": 5,
          "created_utc": "2026-02-17 06:38:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sv9jx",
          "author": "MissionBad732",
          "text": "Their should be systems and processes in place to stop this sort of thing even being possible, so if it's any comfort this is everyone f up, you just happen to be in the center ðŸ˜…",
          "score": 7,
          "created_utc": "2026-02-17 03:02:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vonea",
          "author": "purpleWord_spudger",
          "text": "On the very rare occasion something like this happens on my team, I call my friendly neighborhood DBA (aka grumpy, too-good-for-this dba) to restore the database to a new temporary location, recover what I can, and get really uptight about making our own local backups before any change action for a while. We do weekly full and daily incremental backups so this works well. The embarrassment helps too, since everyone hates exposing their own stupidity.",
          "score": 3,
          "created_utc": "2026-02-17 15:28:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y4gm7",
          "author": "Sandinmyshoes",
          "text": "We donâ€™t know anything about your system but Iâ€™m hoping thereâ€™s some time travel mechanism. I think controls should be in place, if you give people access to a big button to destroy everything, someone will come along and press it one day.\n\nSaying that, I feel for you haha.",
          "score": 3,
          "created_utc": "2026-02-17 22:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5suczu",
          "author": "EmotionalSupportDoll",
          "text": "![gif](giphy|81xwEHX23zhvy)",
          "score": 2,
          "created_utc": "2026-02-17 02:57:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t8a8e",
          "author": "Embarrassed-Swim-710",
          "text": "Keep us updated bro",
          "score": 2,
          "created_utc": "2026-02-17 04:28:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v98qo",
          "author": "ScroogeMcDuckFace2",
          "text": "ill pour you out one, brother",
          "score": 2,
          "created_utc": "2026-02-17 14:09:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5swfia",
          "author": "Afraid-Donke420",
          "text": "No staging environment?",
          "score": 1,
          "created_utc": "2026-02-17 03:09:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t9uvl",
          "author": "Tee-Sequel",
          "text": "Were you playing around in a Break glass account? Can we get more details? Also, my condolences",
          "score": 1,
          "created_utc": "2026-02-17 04:39:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sry1q",
          "author": "NoleMercy05",
          "text": "![gif](giphy|d8KOpGnzaAEI7JiVUp)",
          "score": -9,
          "created_utc": "2026-02-17 02:42:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4j3bw",
      "title": "Iâ€™m planning to move into Data Engineering. With AI growing fast, do you think this career will be heavily affected in the next 5â€“10 years? Is it still a stable and good path to choose?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r4j3bw/im_planning_to_move_into_data_engineering_with_ai/",
      "author": "False_Square1734",
      "created_utc": "2026-02-14 12:10:21",
      "score": 115,
      "num_comments": 89,
      "upvote_ratio": 0.82,
      "text": "Iâ€™m planning to move into Data Engineering. With AI growing fast, do you think this career will be heavily affected in the next 5â€“10 years? Is it still a stable and good path to choose?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r4j3bw/im_planning_to_move_into_data_engineering_with_ai/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5bujal",
          "author": "ProfessorNoPuede",
          "text": "5 - 10 years? Dude, that time horizon is so far in the future, nobody knows. 5 years ago lakehouse wasn't mainstream yet. They just released the paper.\n\nIn 5 years, it could be everyone is on-premise again. Heck, it might the year of the Linux desktop.",
          "score": 311,
          "created_utc": "2026-02-14 12:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5c1iuy",
              "author": "neoneat",
              "text": "After 4 years of uni, working market changed alr. I dunno how to say about 5 years term, unless telling a lie.",
              "score": 29,
              "created_utc": "2026-02-14 13:09:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5d6wnn",
              "author": "Awkward-Cupcake6219",
              "text": "What I really like of this comment is \"it could be everyone is on-premise again\". I see so many companies using databricks for at most hundreds of megabytes of data. Like running over a tree with a tank to clear some farming land.",
              "score": 14,
              "created_utc": "2026-02-14 16:59:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ekwpn",
                  "author": "geek180",
                  "text": "Why do people assume small data = cloud services are pointless or â€œoverkillâ€?\n\nCloud services are *perfect* for small teams and small projects. Itâ€™s all consumption based billing that scales with you and eliminates a lot of infra setup and maintenance that small teams donâ€™t want to deal with.",
                  "score": 10,
                  "created_utc": "2026-02-14 21:19:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5flm4v",
              "author": "ThatSituation9908",
              "text": "Can someone cite the paper? Thanks in advanceÂ ",
              "score": 1,
              "created_utc": "2026-02-15 00:55:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5gq3z5",
              "author": "virgilash",
              "text": "I have the feeling 2026 is going to be the year of Linux workstation ðŸ¤£",
              "score": 1,
              "created_utc": "2026-02-15 05:46:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bypcm",
          "author": "Flat_Mammoth_7010",
          "text": "My 2 cents is to learn more on domain knowledge and to understand the business meaning of data.",
          "score": 104,
          "created_utc": "2026-02-14 12:49:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5czf80",
              "author": "543254447",
              "text": "this is also a risky move. Once you move outnof the domain, all wasted effort. Be sure to commit to an industry before doing this.",
              "score": 29,
              "created_utc": "2026-02-14 16:22:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5dymyv",
              "author": "TaartTweePuntNul",
              "text": "And the basics, never forget the basics of DE! Principles of DB management, how to handle different granularities, batch v stream,... These ideas always stay around, same with SWE best practices.\nOnce you have these two you can grow into whatever direction you want. And specializing in a specific domain will amplify this even more.",
              "score": 11,
              "created_utc": "2026-02-14 19:19:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5eekwi",
                  "author": "pinamanpongole",
                  "text": "Can you suggest resources for someone who wants to become a data engineer. I do have access to aws skill builder but I fear whatever I learn there will be domain specific.",
                  "score": 1,
                  "created_utc": "2026-02-14 20:44:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5d4v2j",
              "author": "SpareSmileBravo",
              "text": "Could you elaborate more on why more focus on domain would be helpful?",
              "score": 2,
              "created_utc": "2026-02-14 16:49:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5d5bfa",
                  "author": "Reach_Reclaimer",
                  "text": "Why wouldn't domain knowledge be helpful? Unless you're doing pure bronze layer integration or API calling, you need to know about the data you're working with",
                  "score": 5,
                  "created_utc": "2026-02-14 16:51:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5budz2",
          "author": "AverageGradientBoost",
          "text": "we actually had a engineering all hands this week and one of the topics that came up was how the difference in AI for software engineering and data engineering is quite big and AI has a lot of catch up to do in DE. Lots of people complaining that it struggles to build queries and work with data. ",
          "score": 86,
          "created_utc": "2026-02-14 12:15:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5c1ko5",
              "author": "PaddyAlton",
              "text": "This is a good point.\n\nI think this is because the behaviour of systems that use data is defined by the code, the schema, and the actual data values.\n\nYou can document schemas, but the more vague the constraints on what the data might look like, the harder it is to build something robust and the more context switching (between code and the actual contents of the upstream source) is required.\n\nNevertheless, I don't think we should rely on this as a 'moat'. It's not a fundamental constraint, more of a context engineering problem - one which people are working on solving. In the last month I've seen the emergence of agentic data analytics implementations that finally look promising. I expect some of these use cases to be cracked by the end of this year.",
              "score": 28,
              "created_utc": "2026-02-14 13:10:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cj4sn",
                  "author": "jupacaluba",
                  "text": "To a certain extent, youâ€™re right. However, Iâ€™ve used Claude to build full transformation logic and I was shocked at how good it was. \n\nItâ€™s a game changer when you donâ€™t need to worry about coding anymore.",
                  "score": 9,
                  "created_utc": "2026-02-14 14:57:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5g4fsz",
                  "author": "NoleMercy05",
                  "text": "It's a terrible and incredibly incorrect point.",
                  "score": -1,
                  "created_utc": "2026-02-15 03:01:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cb20p",
              "author": "nineteen_eightyfour",
              "text": "I am in our works ai workgroup and I think the biggest issue is that people suck. Iâ€™m our data scientist and I use to work for a consulting company. So Iâ€™d work with Google 1 year or oracle 1 year so I got lots of exposure. The only similarity is that everyone sucks at entering data correctly ðŸ¤£",
              "score": 10,
              "created_utc": "2026-02-14 14:10:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cgdzz",
                  "author": "anti_humor",
                  "text": "Lol yeah - even if you give it access to all the relevant docs, it won't help because the docs are incorrect. Gotta love it.",
                  "score": 1,
                  "created_utc": "2026-02-14 14:42:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cfzqt",
              "author": "anti_humor",
              "text": "I think a huge issue here is data quality. Garbage in garbage out, same as always - sometimes I think hardcore AI evangelists have never worked with messy data in the wild lol. \n\nThe issues I see in data I have to write pipelines for range from things I could see an LLM spotting, to completely normal looking data that is incorrect for super idiosyncratic reasons, to CSVs that are broken in ways that I literally made chatGPT short circuit and enter a death spiral trying to solve. \n\nIt might get there soon, but as of now nontechnical human beings touching data are more chaotic than LLMs seem able to neatly account for. Some of the information needed to contextualize all of the relevant business logic is also risky in terms of exposing to an LLM you aren't spinning up yourself. \n\nThat all being said - they definitely save me a ton of time with things like writing DDL based on a file sample or spitting out SQL and application code syntax I don't feel like looking up. I just haven't seen any evidence they could write any of the pipelines I own effectively without giving it so much context I could've just built it myself in the same time.",
              "score": 5,
              "created_utc": "2026-02-14 14:39:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cdlc8",
              "author": "brittleirony",
              "text": "Only because they lack context about the structured data. Plenty of companies pushing agents that have decent accuracy querying structured data with suitable context (metadata, descriptions etc). That being said I haven't seen an agent writing pyspark or building a jobs (should be possible with MCP)",
              "score": 4,
              "created_utc": "2026-02-14 14:25:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5e9d6b",
              "author": "Express-Patience8874",
              "text": "There was actually a post not too long time ago. Apparently, AI agent used data and made bunch of false claims. No one checked. VP level made certain moves based on that data lol",
              "score": 2,
              "created_utc": "2026-02-14 20:16:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5d027g",
              "author": "TH_Rocks",
              "text": "Microstrategy Mosaic is supposed to be able to flesh out a full schema by itself.  \nMicrostrategy already writes great SQL if the schema is properly defined.\nWe haven't upgraded yet to really test it out.",
              "score": 1,
              "created_utc": "2026-02-14 16:25:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5f22cd",
              "author": "spoopypoptartz",
              "text": "claude works perfectly for me but my teamâ€™s docs and data modeling are on point. \n\n\ncurrently experimenting to see if i can get acceptable performance on local models since i need similar capabilities in an air-gapped environment",
              "score": 1,
              "created_utc": "2026-02-14 22:54:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5fkqjn",
              "author": "idiotlog",
              "text": "This is not true. Context for the AI is just bad.",
              "score": 1,
              "created_utc": "2026-02-15 00:49:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5gum6m",
              "author": "Faintly_glowing_fish",
              "text": "This is not an ability problem but rather an integration problem.   In most cases the AI just can access the same data people can and they end up having no way other than hallucinating.   When given the ability to actually access data I find it doing fine.  The hard part is to get it access while maintaining proper way of sandboxing and audit",
              "score": 1,
              "created_utc": "2026-02-15 06:26:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cm6t8",
              "author": "_weined",
              "text": "Everything around building jobs, provisioning infrastructure, automating a portion of quality checks, and especially cookie cutter ingestion is ripe for AI. The business logic layer is not so much at risk for complex enterprises but a lot of the surrounding work DEs typically do is already able to be commoditized by AI.",
              "score": 0,
              "created_utc": "2026-02-14 15:14:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5dmrx0",
              "author": "nowrongturns",
              "text": "You must not work at big tech. Itâ€™s a solved problem. I just prompt with business logic and give it context and it authors near perfect sql.",
              "score": 0,
              "created_utc": "2026-02-14 18:19:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5g4d78",
              "author": "NoleMercy05",
              "text": "![gif](giphy|ko4UuHFAOZE3jN3qRB)",
              "score": 0,
              "created_utc": "2026-02-15 03:01:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bzp4v",
          "author": "PaddyAlton",
          "text": "Two big uncertainties re: AI -\n\n1. speed of takeoff: do compounding gains make performance improvements accelerate over the next year, or do fundamental bottlenecks start to put the brakes on?\n2. performance ceiling: just _how_ good can LLM-based models get (disregarding whether they get there quickly or slowly)? \n\nI think even if AI foundation models get no better from now on, they are _already_ good enough that harnessing them and rolling them out across industry will lead to a shift in ways of working on the scale of the invention of the world wide web. So if you take this path, assume you're going to be very focused on data-engineering-applied-to-AI.\n\nNow, given the actual pace at which human institutions move, I am convinced that even if foundation models get _quite a lot better_ it will take five years to reorient a bunch of legacy businesses around the new technology. But from there, all bets are off.\n\nA reorientation around AI may well make _experienced technologists_ even more important as staff for competitive businesses, but don't expect 'data engineering' specifically to still be prominent (consider how the database administrator role has faded in salience due to the Cloud revolution, for comparison).\n\n---\n\nAll in all: don't let AI put you off. But go in with your eyes open: none of us can make precise predictions about 2035, and even on the shorter horizon you need to prepare to be flexible and stay abreast of this new technology.",
          "score": 21,
          "created_utc": "2026-02-14 12:56:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bv4fc",
          "author": "i_fix_snowblowers",
          "text": "No question that DE will be affected by AI.\n\nBut as the economists say there are \"substitution effects\" and \"income effects\".\n\nSubstitution effects are the first-order job displacement things that you're asking about.\n\nIncome effects are the overall increase in data processing as data engineering tasks become cheaper to execute. \n\nIf I'm being optimistic, I'd say that the overall increase in data processing would lead to growth in DE, it's just that the day-to-day for a DE will change. Like instead of manually fixing 5 pipelines, you monitor 50 pipelines and manage the agents that fix them.",
          "score": 17,
          "created_utc": "2026-02-14 12:21:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bzzth",
          "author": "i_hate_budget_tyres",
          "text": "DE is more insulated than SWE because LLM's scraping the net can't know business domain information.\n\nYou'd have to develop custom LLM's trained on data across the business that can ingest documents, databases, the codebase etc.  And keep a no doubt very expensive team to keep tuning and updating the model as business requirements change.\n\nWhere I work, SWE's are finding 'generic' LLMs much more useful than DA's, DS's and DE's.  All apps tend to resemble each other and complete codebases for all kinds of apps are available to scrape on the internet, so the models have a wealth of solutions to fall back on.\n\nAs a DE I'm finding its more a glorified google search.  If I unleash it in agentic mode, it utterly balls stuff up.  It can't see the databases nor final dashboards etc so is missing a lot of information that I hold in my head and get a steer on from SME's across the business.  This information is proprietary and often just held in peoples heads, so there is no way a 'generic' LLM would have access to it.\n\nHaving said this, I think DEâ€™s working in smaller companies with less complex tech stacks and environments and are finding â€˜genericâ€™ LLMâ€™s more useful.  I work in a multi-cloud, multi vendor environment.  We have every permutation of pipeline you can imagine weaving its way in and out of multiple platforms.  There is no way a â€˜genericâ€™ LLM can see across all of it so its usefulness is limited.",
          "score": 28,
          "created_utc": "2026-02-14 12:58:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5d3vy8",
              "author": "slayerzerg",
              "text": "Pretty much. Esp industries with sensitive data. DE work is hard",
              "score": 3,
              "created_utc": "2026-02-14 16:44:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cf6s3",
          "author": "SchemeSimilar4074",
          "text": "I think DE will become a jack of all trades, with AI advancing as it is. Business people will dabble here and there and might do their own dashboards like a PowerPoint but they have too many meetings to actually do technical works. There are many components but with the help of AI, a very small team can do it all, from deploying cloud infrastructure, testing, data engineer etc.Â \n\n\nSo a DE will be expected to know SRE, SDET, DE, DA and even ML. A few years ago, my job was heavily DE and DA and now it also involves building infrastructure and test suite, which are the jobs of SRE and SDET. Its much easier to build pipelines and dashboards these days. It means more people from other tech areas transition to DE, increasing the competition. For people in the industries, as long as you're expanding your skill sets, it's OK. For someone new, it'll hard to break into, because you might even be competing with SWE, SDET etc who lost their jobs and tried to transition to DE for example.Â \n\n\nIf you wanna get into tech, be prepared to learn everything from every areas. And save a lot, just in case ðŸ˜‚",
          "score": 8,
          "created_utc": "2026-02-14 14:35:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bzzlq",
          "author": "TripleBogeyBandit",
          "text": "I disagree with most of the comments here. I do the more complex data engineering; Kafka, spark, building api services, touching dozens of cloud resources, etc..  ai use to suck at doing these things a year ago but now, itâ€™s kicking ass. Iâ€™ve written entire pipelines, api services, even small business apps with Claude code. I think the people that are trashing donâ€™t know how to leverage the ai tools and feel threatened by their capability. You need to learn how to use these tools effectively or youâ€™re gone.",
          "score": 28,
          "created_utc": "2026-02-14 12:58:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ce1ue",
              "author": "danielfrances",
              "text": "I agree, with some caveats:\n- Even if you learn how to use these tools effectively, the speed of improvement with agentic tools is insane and we might end up redundant anyways.\n- I think another category of people are ones like me - I know how to leverage the tools and see their utility while also feeling threatened by their existence.\n\nA lot of times when this topic comes up people are judging agentic tools by their capabilities right now. At my job, we test drove a bunch of AI tools last summer and it was a total fail with our codebase. I personally started seeing value around October/November. Two weeks ago our entire developer team got told we need to use Claude every day - and honestly, it is SO MUCH better today than even a few months ago.\n\nMy point is - when you see people saying things like \"it can't really handle xyz right now\" just know that statement might be false in as little as 3-6 months.\n\nAs such, I don't think we can even make predictions 2 years out. Maybe the cost of research kills a bunch of the big companies and the progress slows. Maybe the cost of subs goes so high we can't afford it. Or, maybe things keep going as they have been and agentic tools can fully automate our jobs in 2 years. We can't know right now, but you should prepare for the possibility that the hype is real, just in case.",
              "score": 5,
              "created_utc": "2026-02-14 14:28:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5dc73p",
                  "author": "TripleBogeyBandit",
                  "text": "Youâ€™re spot on, anyone who writes these tools off is a fool.",
                  "score": 2,
                  "created_utc": "2026-02-14 17:26:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5f1vyw",
                  "author": "Murtz1985",
                  "text": "Exactly how I see it. Just in case.",
                  "score": 1,
                  "created_utc": "2026-02-14 22:53:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5eq05p",
              "author": "rotterdamn8",
              "text": "For sure, definitely agree that people donâ€™t realize how fast things are moving. \n\nMy company gave us the tools last year and Iâ€™ve been using them as the low hanging fruit coding assist, like â€œrewrite this pandas code for pysparkâ€. Basic stuff.\n\nBut now I keep hearing about Claude Opus 4.6 since it came out a few weeks ago, and I realized holy shit, I need to catch up.\n\nOP, my advice is to learn how to use the tools, especially Claude. Forget 5 years, things are changing quickly. It sounds like some DEs here are sleeping on it. That would be a mistake.",
              "score": 4,
              "created_utc": "2026-02-14 21:46:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5g409s",
                  "author": "CluckingLucky",
                  "text": "Is this how the world felt when aws was launched? lol",
                  "score": 1,
                  "created_utc": "2026-02-15 02:58:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5ccxdn",
              "author": "bubzyafk",
              "text": "I think you are right to some extent, but the other people is also right, particularly on Business domain.\n\nAI can do that exact math stuffs, e.g: Build API to connect based on SaaS documentation etc. itâ€™s a straight forward engineering with error or non error as the output.\n\nBut asking AI to replicate complex business knowledge and on top of it, some ERP complexity, is still way long to go or even impossible without Human intervention. E.g: Theoretically Net Income = revenue - Expenses, but imagine apps A provides Column ABC and XYZ to calc Expenses, and ERP B Provides col C123 and D456 to calc revenue. Requires some window function, sum, and what not.. And col name is not very descriptive enough to tell itâ€™s to calc Revenue, giving 0 context for AI to process\n\nSo, yeah.. in data engineering, AI wonâ€™t 100% do the magic.. it can help us faster to build API, make some Pyspark/scala/whatever code, sql (if connected with our metadata), give some reasoning/exploration, etc.. but it canâ€™t remove human entirely.",
              "score": 2,
              "created_utc": "2026-02-14 14:21:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5dc3nr",
                  "author": "TripleBogeyBandit",
                  "text": "What youâ€™re talking about is a semantic layer and there are plenty of great examples of ai delivering exceptional performance and value when given access to a semantic layer.",
                  "score": 3,
                  "created_utc": "2026-02-14 17:26:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cnuqg",
              "author": "IAMHideoKojimaAMA",
              "text": "I dont think that's more complex de, thats like intro to de sruff",
              "score": 0,
              "created_utc": "2026-02-14 15:23:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cy4yv",
          "author": "Suspicious-Spite-202",
          "text": "Figure out how to do machine learning over relational databases and graph databases â€” relational deep learning.  Also look into graph databases as semantic layers.  Finally, figure out exploratory data analysis (eda) and visualizations via an Llm interface.  \n\nStar schemas and kimball techniques are still relevant for having a stable backbone. Basic principles of modular etl are still relevant too.",
          "score": 5,
          "created_utc": "2026-02-14 16:16:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bv0ll",
          "author": "takenorinvalid",
          "text": "I have a theory that the data engineers working on AI deliberately sabotaged its ability to do data engineering to make sure they'd be the only people with job security.Â ",
          "score": 17,
          "created_utc": "2026-02-14 12:20:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5catj6",
          "author": "PeterDowdy",
          "text": "So far, AI coders are bad at data engineering because itâ€™s hard for them to reason about the size of data - they can get the structure and transformations right but they donâ€™t do scaling and performance.",
          "score": 3,
          "created_utc": "2026-02-14 14:09:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1q26",
          "author": "Illustrious-Pound266",
          "text": "It's already impacted data engineering. Truth is that you need to learn how to use AI in development now",
          "score": 5,
          "created_utc": "2026-02-14 13:11:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5c1wnf",
              "author": "False_Square1734",
              "text": "Is that possible to replace data engineers then?",
              "score": 1,
              "created_utc": "2026-02-14 13:12:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5c35cw",
                  "author": "n_ex",
                  "text": "No, because you still need to guide the AI to implement the solution - though data engineers are becoming faster at implementing things (as all other developers) so companies might need less of them down the line I guess",
                  "score": 7,
                  "created_utc": "2026-02-14 13:21:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5ckpj7",
                  "author": "jadedmonk",
                  "text": "AI doesnâ€™t just replace people. Itâ€™s not like you can plop an AI on a chair to replace the human. Even the best ones are only at like ~80% benchmark - imagine if you wrote wrong production code 20% of the time how poorly things would go. \n\nAI is here to make us more efficient, and it does. Perhaps as those efficiency gains are made theyâ€™ll hire less engineers, but Iâ€™ve seen the opposite as they need more engineers to build and maintain the AI",
                  "score": 3,
                  "created_utc": "2026-02-14 15:06:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5d4w9d",
                  "author": "SRMPDX",
                  "text": "Data engineers who use AI will replace those who don't",
                  "score": 2,
                  "created_utc": "2026-02-14 16:49:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5buftv",
          "author": "ThroughTheWire",
          "text": "nobody can tell you the answer for this. In my semi informed opinion I think we will have a role for a period of time in creating pipelines for data to feed AI models but that will only last for so long and may not be a role available to you by the time you switch. Otherwise I think there will be data engineering jobs and software engineering jobs over the next 10 or so years while AI technology advances exponentially and then who knows where we are after that. I wouldn't bet my entire life on moving into any software engineering discipline at this point.",
          "score": 7,
          "created_utc": "2026-02-14 12:15:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c0pw3",
          "author": "AdministrationAny136",
          "text": "In the future, I'd also focus more on domain knowledge.",
          "score": 2,
          "created_utc": "2026-02-14 13:04:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cg9kf",
          "author": "randomperson32145",
          "text": "Toolbox and tools, those change.",
          "score": 2,
          "created_utc": "2026-02-14 14:41:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ch7c8",
          "author": "gn-musa",
          "text": "Fancy AI eats data. Someone's got to build the damn pipelines.",
          "score": 2,
          "created_utc": "2026-02-14 14:46:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dl8j5",
          "author": "TheCamerlengo",
          "text": "5-10 years? Even before the emergence of AI and LLMs, that was a long stretch of time. I donâ€™t think data engineering will be a thing recognizable in 5 years as to what it is today.",
          "score": 2,
          "created_utc": "2026-02-14 18:12:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e6ens",
          "author": "reviverevival",
          "text": "24 months ago, the smartest people in the world could look at the evidence and call LLMs \"auto-complete on steroids\". I did not agree at the time, but it was a credible assertion. If anyone is still saying that in 2026, they are not credible based on the research that's come out since then. In 2024 people said LLMs can't solve Wordle, and they can't count the Rs in strawberry. No frontier model fails at those tasks in 2026 but people are still repeating the same memes.  \n  \nPeople who are not using AI to (effectively) code think it's supposed to be some kind of maestro that 1-shot generates you a script out of thin air. I would characterize the latest iteration of AI to be more akin to a swarm intelligence. Even a single frontier model agent is not very impressive by itself. I've found that even given a well defined list of tasks, a single Claude agent will degrade rapidly in performance because of context rot. But if you start orchestrating: creating and destroying agents for singular purposes (cattle, not pets), then the capabilities become very impressive. Your agents can make a plan, execute on it, _check the results_, adjust the plan, retry, and so forth all autonomously. This is the scary part, not because it's really good at leetcoding, because planning and iteration is something that's transferrable to all professions.  \n  \nSecondly people misunderstand, especially after the ChatGPT-5 fiasco: GPT-5 is not a single model, it is a router, a reverse proxy, that assesses your query and routes it to one of its 10s of actual models behind the curtain. Despite the marketing it was primarily a cost engineering tool for OpenAI, because it removes choice from the user about what model you are being served with. So you could be using \"ChatGPT-5.2\", and you get some shit answer because it decides your question wasn't worth its time (or their servers are overloaded, or any other reason) and routed your question to some shit model. All frontier \"models' work this way, \"Opus 4.6\" does the same. So all those seemingly cracked models that Google is sending out to dominate benchmarks? Yeah, no guarantee that's the one serving you (or is even one of the possible options).\n  \nThat means you cannot one-shot some chatbot on your free account and have an accurate picture of the state of the art. Anyone who is isn't using harnessed agents and burning tokens have no idea what they're talking about.  \n  \n18 months ago I thought the role of humans will be as model whisperers, guiding these mercurial and finicky chatbots. Well, prompt engineering came and died as a profession in less than 12 months. 3 months ago I thought the role of humans would be building mcp integrations to connect agents to the business domain. Well, Claude is pretty well capable of being pointed at any API and building an integration by itself right now.  \n  \nCurrently I would say my comparative advantages are understanding the business domain, architecture, and security. If you notice, none of these are junior attributes. As an OG AI hater, it pains me to say that if you gave me a list of projects to complete, and I had a choice between an intern or Claude Code and an intern's salary of tokens, for effectiveness I would take Claude Code every time hands down. (I'm not saying that the AI is better in every way, rather there's no comparative advantage).\n  \nAnd I don't even know how long my moats will hold. There is a degree of skill involved with using agents, which can explain why some people are getting poor results, but tbh the skill curve is not that high, and any clever tricks people think of to squeeze more performance out of the agents (e.g. chain-of-thought, ralph-loop, sub-agents) just get baked into the harness and democratized. I think the only reason people don't get better at it is a psychological aversion to AI.\n\nAgainst all odds, my company managed to assemble a competent team of AI engineers that built an in-house agentic framework that _actually delivered business value_...for about 12 months. Now I wonder what was the whole point if every analyst will be rolling with Claude Cowork on their laptop in 6-12 months. If you look at where we were just 24 months ago vs now, it's hard to imagine where we'll be 24 months from now.  \n  \nSo all that to say, we're all guessing for the next 5 years. My hope is a small business renaissance and a democratization of knowledge, but I fear we just end up in a world where 12 rich guys own everything until one day they betray each other. But I wanted to give a deep and nuanced answer, and get my own thoughts out. We can only nudge the world to the better scenario if we're honest to ourselves.",
          "score": 2,
          "created_utc": "2026-02-14 20:00:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fb1vx",
          "author": "rambouhh",
          "text": "Data is the backbone of ai, and ai is worthless without good data. Worry about learning principals, the business meaning of data, and you are going to be better off than 95% of people even if the job itself is gone or looks completely different in 5 years",
          "score": 2,
          "created_utc": "2026-02-14 23:49:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fikc4",
          "author": "CluckingLucky",
          "text": "Ok, so there are two ways to answer your question.\n\nFirst off, as u/ProfessorNoPuede pointed out, no one knows what will happen five or ten years into the future in terms of tooling or capability. No one knows what the industry is going to be calling for.\n\nHowever, and this leads to the second way to answer your question--- look at the fundamentals of what drives demand for data, and, consequently, what drives demand for data engineers.\n\nIt's these things that suck up a lot of data to deliver correlative approximations that can never be accurately used in the exact processes  data engineers excel in. LLMs.\n\nSo, synthesising this: yes, the tooling will change, but data engineers will only be riding this AI bubble as much as they have been already. Maybe more of them will be data scientists. Maybe more of them will be AI, but I doubt it.\n\nThere might be less of them. If that's the case, those that remain (or enterprise) will be very highly paid.\n\nSincerely,\n\nNo one smarter than your average CEO thought leader",
          "score": 2,
          "created_utc": "2026-02-15 00:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d60ua",
          "author": "SRMPDX",
          "text": "AI is already heavily affecting DE. There would be no AI without DE. Figure out how to use it, and how to market your knowledge to people who need it in their organization. \n\nIn AI we're seeing huge changes in 5-10 months, nobody knows what's coming in 5-10 years.",
          "score": 2,
          "created_utc": "2026-02-14 16:55:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cu6y6",
          "author": "shittyfuckdick",
          "text": "Bro im losing my mind you realize this thing is just autocomplete right? The only people saying its gonna replace devs are the CEOs of AI companies who are trying to pump the stock.Â ",
          "score": 3,
          "created_utc": "2026-02-14 15:56:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5drn5a",
              "author": "alexlazar98",
              "text": "Looking at the rest of the comments, this is really not your audience, lol. The blinders are on.",
              "score": 0,
              "created_utc": "2026-02-14 18:43:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fcifx",
                  "author": "shittyfuckdick",
                  "text": "Are you saying the blinders are on me? I could be totally wrong and im preparing for worst case scenario. but i really think most of AI is driven by hype.Â ",
                  "score": 1,
                  "created_utc": "2026-02-14 23:58:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5c7tx6",
          "author": "andrew2018022",
          "text": "I think itâ€™s the most ai proof of the â€œdataâ€ domains because there is so much analytics slop on social media nowadays, the barrier to entry of analytics and BI is so low. DE requires more technical knowledge you canâ€™t just vibe code solutions",
          "score": 1,
          "created_utc": "2026-02-14 13:51:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cbu19",
          "author": "hibe1010",
          "text": "Of course it will be affected- a job like that will always and was always heavily affected by latest emerging technologyÂ \n\nYou will need to stay on top of those then I am very sure it is still an interesting and challenging field to choose - just donâ€™t expect that your skill set will not have to change over timeÂ ",
          "score": 1,
          "created_utc": "2026-02-14 14:15:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ci7g4",
          "author": "DenselyRanked",
          "text": "It's a difficult question for anyone to answer. Data engineering as a practice will still exist but the methods, tools, and skill set needed will evolve. \n\nThere are smart people putting a lot of thought into this and I tend to agree with much of [this presentation](https://www.youtube.com/watch?v=Fu6JBodxqGQ), where there is not going to be a Data/Analytics Engineer title in the near future for data teams, opting instead for titles like Data Product Owners and Data Domain Experts. AI can help close the technical gap between product management and engineering, so DE's will need more emphasis on stakeholder communication and requirements gathering. ",
          "score": 1,
          "created_utc": "2026-02-14 14:52:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ct19x",
          "author": "Lastrevio",
          "text": "Between \"it will replace me\" and \"it's not helping me at all\" there will have to be a transitory phase where it will increase your productivity. So far, AI is barely helping in making me 5% more productive, and I'm doing quite simple things. I'll worry that it's gonna replace me when it will double my productivity, until then it's next to useless.\n\nMoreover, there are academic studies showing that programmers are 20% *less* productive using AI.",
          "score": 1,
          "created_utc": "2026-02-14 15:50:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cu9nk",
          "author": "rajekum512",
          "text": "If data engineering is falls under \"white collar\" jobs then it would be safe to be classified under endanger threat",
          "score": 1,
          "created_utc": "2026-02-14 15:56:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cx82c",
          "author": "billysacco",
          "text": "My opinion itâ€™s already starting to be affected with many employers going to the offshore combined with AI route. It will probably take a few years to come back around, the off shoring stuff always seems to go in a circular cycle. Or the AI is as good as they say (I am still skeptical on that) and things donâ€™t come back around. Hard to say.",
          "score": 1,
          "created_utc": "2026-02-14 16:11:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dvtkm",
          "author": "melvinroest",
          "text": "Yea, I think doing data engineering is AI engineering-lite in some cases",
          "score": 1,
          "created_utc": "2026-02-14 19:04:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dy6d5",
          "author": "frozengrandmatetris",
          "text": "in 5 to 10 years, the number of orgs locked into legacy low-code ETL tools like ODI and SSIS will be almost exactly the same",
          "score": 1,
          "created_utc": "2026-02-14 19:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e0ku1",
          "author": "Least-Possession-163",
          "text": "DE or anything code driven will be impacted. Companies might ask you to do everything end to end. AI augmentation will lead to fewer jobs (leaner team) but more work. 5 years is too long. 5 years back NLP was a big deal and now people have AI girlfriends. So take your bet.",
          "score": 1,
          "created_utc": "2026-02-14 19:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e656w",
          "author": "ImpressiveProgress43",
          "text": "AI is heavily affecting data engineering. It is still stable and good. I havent seen a single year where de's werent over demanded in my area.",
          "score": 1,
          "created_utc": "2026-02-14 19:58:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e7ksf",
          "author": "decrementsf",
          "text": "<< any professional role >> Will be affected in the next 5-10 years.\n\nFor << any professional role >> study the profession, and practice applying the current AI trends to it.",
          "score": 1,
          "created_utc": "2026-02-14 20:06:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h911d",
          "author": "po1k",
          "text": "It you want smth stable go with c/c++. DE is tough and far away from being stable. At this point I realized c++ might easier",
          "score": 1,
          "created_utc": "2026-02-15 08:43:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c6g4r",
          "author": "Nekobul",
          "text": "I think when the LLMs start to perform brain surgeries on their own, you will have to start worrying if your job is next. Until then, breathe! Everything will be fine.",
          "score": 1,
          "created_utc": "2026-02-14 13:42:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cjs47",
          "author": "itsMineDK",
          "text": "I wouldnâ€™t do it, but thatâ€™s just me.. a lot of tech folks were making bank on software engineering when i started uni, I wanted to go there but I didnâ€™t and did finance instead.. that was in 2008 l, always regretted UNTIL NOW.. \n\nitâ€™s been rough for SEs in general but things might turn around nobody has a crystal ball",
          "score": 0,
          "created_utc": "2026-02-14 15:01:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5guc05",
          "author": "Faintly_glowing_fish",
          "text": "Yes it will be very heavily affected in the future.  By 5 years much of what DE does today will be completely gone.  Some of the skills will be useless, and some of the things will be as pointless as formatting the code with your hand. But that is fine really.\n\nThe distinction between different kinds of engineering will break down a lot and you will be doing very different things",
          "score": 0,
          "created_utc": "2026-02-15 06:23:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5gv5hw",
              "author": "False_Square1734",
              "text": "Then do u think IT jobs will be gone?",
              "score": 1,
              "created_utc": "2026-02-15 06:31:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5gviy2",
                  "author": "Faintly_glowing_fish",
                  "text": "You will have a job that will still involve computer programs and data but I honestly donâ€™t know what you really call it.   You will be doing a mixture of what DE DS and product engineer do today and some infra too",
                  "score": 1,
                  "created_utc": "2026-02-15 06:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r88m8b",
      "title": "Why do so many data engineers seem to want to switch out of data engineering? Is DE not a good field to be in?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r88m8b/why_do_so_many_data_engineers_seem_to_want_to/",
      "author": "Illustrious-Pound266",
      "created_utc": "2026-02-18 17:02:32",
      "score": 99,
      "num_comments": 120,
      "upvote_ratio": 0.91,
      "text": "I've seen so many posts in the past few years on here from data engineers wanting to switch out into data science, ML/AI, or software engineering. It seems like a lot of folks are just viewing data engineering as a temporary \"stepping stone\" occupation rather than something more long-term. I almost never see people wanting to switch out of data science to data engineering on subs like r/datascience .\n\nAnd I am really puzzled as to why this is. Am I missing something? Is this not a good field to be in? Why are so many people looking to transition out of data engineering? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r88m8b/why_do_so_many_data_engineers_seem_to_want_to/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o630y9j",
          "author": "AutoModerator",
          "text": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-18 17:02:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o632lz1",
          "author": "SuperTangelo1898",
          "text": "Not every company has people doing actual data engineering - there are a lot of unclear boundaries and oftentimes folks end up doing 3 jobs in one: data engineer, analytics engineer, and analyst (some roles specifically state building dashboards for end users)",
          "score": 242,
          "created_utc": "2026-02-18 17:10:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63bmx5",
              "author": "ThePunisherMax",
              "text": "Hell I even have to be a Business Analyst sometimes. Its honestly quite an intensive job and a lot of people think its be in a hole and just get tickets.\n\nIts not, its really interactive and very very (internal) client facing, you deal with stakeholders a lot more than a SWE",
              "score": 82,
              "created_utc": "2026-02-18 17:50:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63iqv9",
                  "author": "PantsMicGee",
                  "text": "DE at my company means whatever they didnt tell the Developers to do.Â \n\n\nWe have no BA, testers, BI, Analysts.Â \n\n\nJust Developers and Data Engineers.Â \n\n\nThe burnout is insane.Â ",
                  "score": 64,
                  "created_utc": "2026-02-18 18:21:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63o8zi",
                  "author": "Successful-Daikon777",
                  "text": "As a business analyst I'm doing data engineering, analyticsÂ and dashboard building. It is also intertwined. You got to be lucky just doing one \"thing\" while being at a company for multiple years.\n\nThe other issue is if you go looking for ways to make an impact you find yourself doing other things naturally.",
                  "score": 11,
                  "created_utc": "2026-02-18 18:45:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o63i40t",
              "author": "Splun_",
              "text": "Some have you also work as devops or simple crud backend.",
              "score": 14,
              "created_utc": "2026-02-18 18:18:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o63txp9",
              "author": "bert_891",
              "text": "This is exactly it.\n\n\nJust like \"data analyst\"... There are a lot roles assigned under that title. It's just a \"title\", but the actual job or duties are something else",
              "score": 6,
              "created_utc": "2026-02-18 19:11:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o63jkdl",
              "author": "Eastern-Rip2821",
              "text": "Meee",
              "score": 4,
              "created_utc": "2026-02-18 18:25:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o69iece",
              "author": "Colt2205",
              "text": "I was looking through threads here to see if people had helpful resources on getting started with data engineering as someone who is an SWE with 13 years experience.  The job I'm in actually requires an ETL pipeline to work, and the entire time I was building the system for this company I kind of noticed the pattern of how everything I was doing was going from a fullstack application to a backend application, with a clear flow.  \n\nThere was an ELT pipeline built going to a DataLake already.  After doing just some surface learning on concepts I realized that what I was doing was building a very inefficient ETL pipeline off the supposed ELT pipeline.  It was like having an ELETL flow!\n\nAnd when someone else here mentioned DAs getting BA work, I also noticed I'm having that situation crop up as well.  So I'd definitely say the boundaries are very murky.",
              "score": 1,
              "created_utc": "2026-02-19 16:23:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bdw7s",
              "author": "OverEngineeredPencil",
              "text": "This is the real reason as far as I can tell. Data Engineer is just a catch-all and most companies want you to hook things up lickity split and then you spend the rest of your time duct-taping all the problems with modern plug-and-play, black-box cloud solutions that are extremely fragile and incomplete solutions. Like missing proper CI/CD integration, or robust testing methods, or node updates cause outages, etc.. But they have these super simple dashboards that management likes because it makes it all feel like it is super easy and quick to set up.",
              "score": 1,
              "created_utc": "2026-02-19 21:47:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o635a5y",
          "author": "MakeoutPoint",
          "text": "In short, nobody walks into a house and praises the plumbing, which is an easier field than most trades but requires more knowledge than your average handyman, and some people *need* that praise and glory.\n\n\nI see it as an important role that software engineers don't want to do, and that basic analysts aren't technical enough to do (or that it's too time-intensive to do whole-ass, rather than half-assing two roles).\n\n\nYou're invisible to the higher ups, but your immediate leadership knows you're essential, so your job is secure but thankless. I don't care about my org or what they sell, so that's fine by me as long as the money comes into my account so I can enjoy life....but others need a gold star and kudos and \"feeling like they make a difference\".",
          "score": 151,
          "created_utc": "2026-02-18 17:22:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63ocy7",
              "author": "LaserKittenz",
              "text": "being invisible is a superpower.  Every sysadmin aims to reach this state lol",
              "score": 35,
              "created_utc": "2026-02-18 18:46:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o647lep",
                  "author": "the_fresh_cucumber",
                  "text": "It can be. Unless cost cutting comes and the 23 year old MBA McKinsey analyst has no idea what you do when the layoff list is drafted for leadership.",
                  "score": 22,
                  "created_utc": "2026-02-18 20:14:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o63l7xz",
              "author": "dfwtjms",
              "text": "Consiser yourself lucky if your immediate leadership knows that much.",
              "score": 37,
              "created_utc": "2026-02-18 18:32:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o64m1nd",
              "author": "Commercial-Ask971",
              "text": "If you want a praise, become product owner or project manager, or c-suite. They get the clout for bringing something to life, not devs",
              "score": 11,
              "created_utc": "2026-02-18 21:21:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o64tdvz",
              "author": "selfmotivator",
              "text": "> You're invisible to the higher ups, but your immediate leadership knows you're essential, so your job is secure but thankless\n\nThis has been my experience for years, now. Outside of my immediate leadership, no one else seems to know why I'm even kept around... until a major pipeline breaks. LOL",
              "score": 7,
              "created_utc": "2026-02-18 21:55:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o688jf9",
              "author": "dillanthumous",
              "text": "Good comment. Very true at Junior/Mid level. But when you get senior enough and are responsible for leading the team, budgets, justifying spend etc. You do end up having both more influence on the business - but also a lot of annoying flak protecting your team from bullshit.\n\nAsk me how I know... :D ",
              "score": 3,
              "created_utc": "2026-02-19 12:07:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o636rau",
          "author": "Orzhov_Syndicalist",
          "text": "I enjoy data engineering. I switched into it from database administration 6 years ago because I felt (pretty rightly, in retrospect) that database's would become automated quickly, and data engineering would be the more robust job market. \n\nKeep in mind that reddit is largely an area for complaints, arguments, and regrets. You simply are not going to encounter a lot of people here that post \"Data Engineering is A-OK!\"",
          "score": 43,
          "created_utc": "2026-02-18 17:28:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6322vx",
          "author": "Evilcanary",
          "text": "Confirmation bias maybe. A lot of people who got into it and found that it's one of the least glamorous roles. It's a weird niche without a lot of understanding from other people what all it can entail. So you've got a weird bucket of weird expectations that has attracted a lot of weird people. And here we are. ",
          "score": 80,
          "created_utc": "2026-02-18 17:07:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o633lna",
              "author": "Illustrious-Pound266",
              "text": "But I feel like data engineering has never really been advertised as a glamorous role.Â  So I'm puzzled as to why people go into it thinking it's something glamorous.Â ",
              "score": 15,
              "created_utc": "2026-02-18 17:14:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o634cjp",
                  "author": "ZirePhiinix",
                  "text": "People think working at Google is glamorous.\n\nI always ask them if they understood Google's revenue stream. They make money from ads. You're going to be pushing ads to people at Google.",
                  "score": 36,
                  "created_utc": "2026-02-18 17:17:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63dobx",
                  "author": "One_Citron_4350",
                  "text": "It's because of the company, they think working for one of the Big Tech automatically results in glamorous work. Name, prestige, recognition, resume-driven careers for some. \n\nSome DE work is probably very boring over there and some might be very interesting depending on the product, department etc.",
                  "score": 9,
                  "created_utc": "2026-02-18 17:59:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63d69k",
                  "author": "Massive_Course1622",
                  "text": "For an analyst it is the default \"next step\" other than management.",
                  "score": 1,
                  "created_utc": "2026-02-18 17:57:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o636zbt",
          "author": "PeitersSloppyBallz",
          "text": "Well it is the most needed role is my opinion.\n\nThe key is that the role often is placed in a company with small amounts of data, with the ambition to use the most expensive marketed product, where your creditcard is the limit. Or you end in a company on a budget where you have large amounts of data. Here you learn to be good, while the first is where you learn to be a consultant ðŸ˜‚\n\nBut my experience, the business starts by hiring data science / â€œMLâ€ experts and then they find out they need data. At this moment the salary of the experts is ticking, so when the data engineer comes in, he/she is already behind schedule. Therefore you will never be successful.\n\nI think a lot of newcomers experience this. While the data science people will always be against you, because it is easy to blame the data engineer.",
          "score": 21,
          "created_utc": "2026-02-18 17:29:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fso1d",
              "author": "mianbai",
              "text": "One thing I've found (I've sat both as a data scientist and as an analytics engineer), is in most orgs leaders don't realize there's a deep tradeoff between analytical velocity and data engineering maintenance costs.\n\n\nData engineering is kinda like building highways where there is induced demand. So once one thing gets built the bottleneck immediately shifts elsewhere.\n\n\nBusinesses rightly so are infinitely hungry for data to answer their questions.\n\n\nThe best orgs to work for are those whose leaders have realized the true girls cost of answering a question in terms of roadmap diversion & headcount, and only bet and fund what's most necessary.\n\n",
              "score": 1,
              "created_utc": "2026-02-20 15:40:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o631upr",
          "author": "stuckplayingLoL",
          "text": "I'm not entirely sure if that's the sentiment. I've been watching the sub on and off and have seen more posts about people swapping roles to data engineering. Honestly regardless, you're gonna find people that burn out from data engineering or any role in general.",
          "score": 14,
          "created_utc": "2026-02-18 17:06:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63id0l",
              "author": "volkoin",
              "text": "This is a lot more reasonable",
              "score": 2,
              "created_utc": "2026-02-18 18:20:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o636mxq",
          "author": "Phantazein",
          "text": "I feel like as a DE you are kinda stuck as a middle man, which is frustrating. There is a lot out of your control and trying to organize all these sources and destinations can be painful.",
          "score": 14,
          "created_utc": "2026-02-18 17:28:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64ndt0",
              "author": "Commercial-Ask971",
              "text": "This",
              "score": 1,
              "created_utc": "2026-02-18 21:27:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o632s02",
          "author": "andrew2018022",
          "text": "A lot of people get into DE by accident and the end goal for them is to ultimately be on the model building side",
          "score": 27,
          "created_utc": "2026-02-18 17:10:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6339ns",
              "author": "Illustrious-Pound266",
              "text": "I don't understand how people can get a DE job by accident. Do people also get ML/AI jobs by accident?",
              "score": 3,
              "created_utc": "2026-02-18 17:13:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o636av7",
                  "author": "Ok-Recover977",
                  "text": "get jr data scientist job -> data is messy so I need to write pipelines -> experience on resume is a lot SQL/Python for pipeline building -> oops I'm a DE now",
                  "score": 57,
                  "created_utc": "2026-02-18 17:26:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63401h",
                  "author": "magnumchaos",
                  "text": "I quite literally fell into data engineering. Got hired on as a 'systems integrator' at one of my previous jobs, merely because they didn't know that the job itself was data engineering. Once I figured that out, I moved on to greener pastures.",
                  "score": 17,
                  "created_utc": "2026-02-18 17:16:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63amtx",
                  "author": "Typical_Priority3319",
                  "text": "In my case I did some weird science shit that involved building pipelines (bioinformatics) at a startup while trying to do ML on genetic data. \n\nYears later I was at a faang just as a business analyst trying to be a SWE and every SWE I talked to was like â€œjust be a DE pay is basically the same at lower levelsâ€ and I needed money so now here we are",
                  "score": 8,
                  "created_utc": "2026-02-18 17:46:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o635nti",
                  "author": "andrew2018022",
                  "text": "You said it yourself in another reply. It isnâ€™t advertised as a job a ton. You just sorta get into it.",
                  "score": 3,
                  "created_utc": "2026-02-18 17:23:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o635poz",
                  "author": "sephraes",
                  "text": "I have been voluntold for several jobs in my career life. I am absolutely certain I am not unique.",
                  "score": 2,
                  "created_utc": "2026-02-18 17:24:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o637p5y",
                  "author": "Squididilliliam",
                  "text": "I applied to my current company for a frontend dev role, and they put me on a data engg team lol.",
                  "score": 2,
                  "created_utc": "2026-02-18 17:33:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o64qi79",
                  "author": "MikeDoesEverything",
                  "text": ">Do people also get ML/AI jobs by accident?\n\nI don't think so purely on the assumption that the \"base skill\" for DS is typically a quantitative science e.g. physics, chemistry, some sort of maths etc.\n\nThe base skill for DE is some sort of SQL.  One of these is a lot harder to come by than the other.",
                  "score": 2,
                  "created_utc": "2026-02-18 21:42:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63ax3c",
                  "author": "mean_king17",
                  "text": "In big consultancies it can happen pretty easy actually.",
                  "score": 1,
                  "created_utc": "2026-02-18 17:47:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o65oyqb",
                  "author": "srodinger18",
                  "text": "This is my case, after graduate I originally planned to get DS related job. Apply to entry level DE job as I thought it will be similar as it has \"data related\" job description lol. And here I am 6 years later still works as DE",
                  "score": 1,
                  "created_utc": "2026-02-19 00:39:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o688s8i",
                  "author": "dillanthumous",
                  "text": "10 years ago companies were gagging for data roles (the height of the \"big data\" grift), so a lot of people who were doing adjacent things got sucked in. Similar to web dev 15-20 years ago. If you could create an index.html you could end up in charge of the app dev team. ",
                  "score": 1,
                  "created_utc": "2026-02-19 12:09:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o63dxt0",
              "author": "One_Citron_4350",
              "text": "This is true. It wasn't always called DE even though the work was the same. I believe a lot of us did not start out by wanting to be a data engineer when those job titles didn't really exist.",
              "score": 1,
              "created_utc": "2026-02-18 18:00:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o632wmg",
          "author": "colouredzindagi",
          "text": "It depends what you're working and who you're working with. As with any job.\n\nIf you're working with people who communicate well and bounce ideas off each other and work well together, it's great.\n\nWhen there's no clear vision, progress, and a general disconnect, it sucks. \n\nI'm only guessing, but most data engineering jobs are probably the latter.",
          "score": 8,
          "created_utc": "2026-02-18 17:11:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63iqfp",
          "author": "Simonaque",
          "text": "When I was a data analyst I was so excited to be a data engineer, but after fighting with broken ELT pipelines and dbt for a while I realized data infrastructure/platform is a lot more interesting and frankly better compensated. Now I work mostly with Java/Kotlin and interact with our Data Lake using Kafka, Iceberg, Flink, etc",
          "score": 8,
          "created_utc": "2026-02-18 18:21:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64oaqi",
              "author": "Commercial-Ask971",
              "text": "Isnt that basically devops at this point? Also arent you worry that it will get automated as it was/is in case databases, so there is no need for database admins as much as in the past? LLM are way better to spin up a data platform using yaml files than understand business acumen and edge cases, which makes DE work more prone to being automated, especially if you perform things after staging area. I am also very interested in being in data platform than ingesting data and creating semantic models or data marts out of it, but very afraid that LLM soon will have better price:speed:quality ratio than human",
              "score": 2,
              "created_utc": "2026-02-18 21:31:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64ta1x",
                  "author": "Simonaque",
                  "text": "I wouldn't say so, I have friends who are DevOps Engineers and anecdotally their work is pretty different from mine, there's some overlap like IaC, CaC, Platform level work, etc for sure but the goal is entirely different. If you saw a diagram of our Data / ML Infra you would probably agree it's a lot more complex than a few ETL/ELTs, we have dozens of services (FAANG+ company)\n\nRegarding your second point, I don't think anyone is really 'safe' from being automated except for now, really low level systems engineers working on GPUs, TPUs, Kernel level work, that's really specialized, and Engineers working on proprietary languages, believe it or not it still exists in a lot of legacy industries",
                  "score": 3,
                  "created_utc": "2026-02-18 21:55:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o631qu2",
          "author": "ludflu",
          "text": "sometimes its a real schlep.",
          "score": 11,
          "created_utc": "2026-02-18 17:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o637sdf",
          "author": "DoomsdayMcDoom",
          "text": "I run a very large SaaS / PaaS consulting company and all of the data engineers exit interviews mentioned the same theme.  The random hours of pipeline events occurring was too demanding for them & their family.",
          "score": 5,
          "created_utc": "2026-02-18 17:33:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63p3tf",
          "author": "Syneirex",
          "text": "I enjoy data engineering quite a bit. What drives me crazy and makes me want to run for the hills are mostly leadership and cultural issues.\n\nâ€œI know itâ€™s midday and the team already has plans and commitments, but can you drop everything and deliver this new thing on short notice, say, by tomorrow? Then we will scramble up plans and priorities again in a couple of days. Itâ€™ll be fun!â€\n\nâ€œWhat do you mean that there is a good reason we have consistent ways of doing thingsâ€”we already promised the customer we could do this one off thing. Again. By tomorrow.â€\n\nAnd the endless meetings and meetings about meetingsâ€”but thatâ€™s not unique to DE.",
          "score": 5,
          "created_utc": "2026-02-18 18:49:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64mwig",
          "author": "Faye-pas94",
          "text": "I switched 3 months ago from data science to data engineering. Very good choice",
          "score": 4,
          "created_utc": "2026-02-18 21:25:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63easp",
          "author": "Outside-Storage-1523",
          "text": "Fuck I really hate writing complex queries and bath in the glory of business logics.\n\nBut Iâ€™d be happy if I can switch out from Analytical engineer to a better DE position that is a bit further away from analysts and stakeholders.\n\nTried a few years to no avail. Now recruiters just assume I love and can only do Analytic engineeringâ€¦",
          "score": 3,
          "created_utc": "2026-02-18 18:02:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o647j8l",
              "author": "thecity2",
              "text": "Writing queries....these days it's just prompting queries into an LLM. ",
              "score": 2,
              "created_utc": "2026-02-18 20:13:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64jd0i",
                  "author": "Outside-Storage-1523",
                  "text": "That makes it even more boringâ€¦",
                  "score": 3,
                  "created_utc": "2026-02-18 21:09:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o63stum",
              "author": "hayek29",
              "text": "what exactly made you want to go from analytics eng to DE?",
              "score": 1,
              "created_utc": "2026-02-18 19:06:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63wqhq",
                  "author": "Outside-Storage-1523",
                  "text": "Just getting tired of writing large queries full of business logic, which is a more suitable job for the Analytics.",
                  "score": 3,
                  "created_utc": "2026-02-18 19:23:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64kaev",
          "author": "addictzz",
          "text": "When they mention data engineer, sometimes you maybe a data platform engineering. Doing a mix of DE and devops stuff and a little bit of analytics/dashboard potentially. \n\nYour data platform is used by data analysts and scientist in the team. So the scope can widen and people may not like it.",
          "score": 3,
          "created_utc": "2026-02-18 21:13:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o655ve7",
          "author": "winnieham",
          "text": "I think it's going to depend on the person. I went fr DS->DE myself recently.",
          "score": 3,
          "created_utc": "2026-02-18 22:55:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66n4m4",
              "author": "Illustrious-Pound266",
              "text": "And have you been enjoying the transition so far?",
              "score": 1,
              "created_utc": "2026-02-19 04:00:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o63c5sy",
          "author": "cyamnihc",
          "text": "Most DE roles are disguised data analyst roles and if a technical person gets into an analyst role, they would want to move out of it",
          "score": 3,
          "created_utc": "2026-02-18 17:53:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63d60u",
          "author": "One_Citron_4350",
          "text": "Simply put, Data Science, ML/AI have more visibility, they have more coverage in the media, and highly demanded. A lot of buzz and noise around those jobs being glamorous but in fact they are not or not all of them. Even as DS, you don't necessarily work on cutting edge work even in Big Tech. Data Engineering is more like backend work that is not visible unfortunately due to different reasons.\n\nOutside big tech, in non-tech companies data teams are rather small and sometimes not formal per say. They're composed of a few people who sometimes are not experienced or do not have the resources for an interesting project. In this case, they're seen more like cost centers rather than profit centers. So they end up doing the work of data engineer, data analyst, analytics, and data science, you name it.",
          "score": 2,
          "created_utc": "2026-02-18 17:57:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63hcix",
          "author": "Plane_Bid_6994",
          "text": "I think it is anxiety about becoming irrelevant. With so many tools to automate data engineering work or tools claiming to \"solve\" data engineering there is a question about relevance in the minds of a lot of people working in this field, including me. Thus people are looking for greener pastures where it is more difficult to become irrelevant",
          "score": 2,
          "created_utc": "2026-02-18 18:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63rs1o",
              "author": "simms4546",
              "text": "Please explain which tools are going to automate data engineering...",
              "score": 6,
              "created_utc": "2026-02-18 19:01:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o646ss0",
          "author": "JJ3qnkpK",
          "text": "You'll see this sentiment with a lot of programming and IT roles. Look at your own career, talents, wants, and goals, and don't sweat the people who are fretting their own too much.",
          "score": 2,
          "created_utc": "2026-02-18 20:10:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64r474",
          "author": "reelznfeelz",
          "text": "Not sure, probably job scope creep.   As a \"DE\", I get pulled in to do damn near everything that nobody else knows how to do.  But, I'm a contractor/freelance so I get paid for it.",
          "score": 2,
          "created_utc": "2026-02-18 21:45:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65bosa",
          "author": "Captain_Strudels",
          "text": "I like the job when I do interesting things, but I feel pretty second class. For example my org recently did a mini restructure and we got sorted away from the other engineers and sorted with the \"extras\" like IT. My direct report is the CTO lol The org should really know better but it kinda says everything about how we are valued\n\nConversely the devs are tight as shit. All the founders love them, the CTO loves them, the org celebrates them. Same as in my last role. So yeah kinda hard to justify asking for a raise when you're seen as a lesser engineer",
          "score": 2,
          "created_utc": "2026-02-18 23:25:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66sqd7",
          "author": "IAMHideoKojimaAMA",
          "text": "Hey more roles for me idc",
          "score": 2,
          "created_utc": "2026-02-19 04:38:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69gw4r",
              "author": "Illustrious-Pound266",
              "text": "Yeah there's a part of me that thinks whether data engineering now is like being in the pick and shovel business during this AI gold rush where everybody wants to dig gold.",
              "score": 1,
              "created_utc": "2026-02-19 16:16:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69acwh",
          "author": "MovieSaint",
          "text": "I'm a data engineer or atleast I was hired as one. I work on devops, analysis, front end apps using streamlit, database administrator, and at times basic ML and stuff too. And despite all this i also work on cloud infra related tasks including security. All this including my core data engineering job. So data engineer isnt just one branch. The overlaps are crazy. And this has been the case in all 3 companies I've worked in. The pay is good tho, so cant complain.",
          "score": 2,
          "created_utc": "2026-02-19 15:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69nty9",
          "author": "DataObserver282",
          "text": "A few reasons, that are almost true in every career \n\n- businesses  donâ€™t understand the function/value \n- AI hype \n- general burnout",
          "score": 2,
          "created_utc": "2026-02-19 16:49:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o637scn",
          "author": "denM_chickN",
          "text": "Well you can make more money in engineering, more easily, I think.\n\n\nBut I'm not on call in data science and I make enough money.\n\n\nI theoretically want more money, but practically I want less fucking work so I'm posted.",
          "score": 1,
          "created_utc": "2026-02-18 17:33:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63oc7q",
          "author": "Tushar4fun",
          "text": "Data Engineers should understand that they are now software developers.\n\nEvery app is data centric.\n\nThey neet to understand that they have to process the data and at the same time they should know how tech communicate.\n\nBasically, Data processing and integration both.\n\nAnd lastly, CI/CD. I believe every developer whether he/she is in any tech should know this.",
          "score": 1,
          "created_utc": "2026-02-18 18:46:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63onfy",
              "author": "Tushar4fun",
              "text": "Plus, product knowledge that develops from day 1.",
              "score": 1,
              "created_utc": "2026-02-18 18:47:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o64avw9",
          "author": "here_n_dere",
          "text": "DE roles across industry are essentially widely OLAP infra and data ownership, which tends to deal with transactional data at varied velocity, all cooked into digestible format for humans to drive business decisions and as such has a bottleneck. This bottleneck at the end tends to leave lot of wasted opportunity explorable if the intermediary decide not to ROT. But as is human tendency, we can only cater to our nature, we sulk and laze at the comfort the job brings at our doors, minds railing still but elsewhere.. \n\nBottomline, there are a lot of similar stuff around the industry, just different Legos, built up already to be managed and jailed into working... Part of the self contempt.\n\nBut someone said once and it stuck, do not run away from stuff, run towards stuff, that should be the way of life. That motto if driving us, can take us from this position of comfort to opportunities we explore and dream to capture. \n\nKnow your strength in terms of what you can handle, volume, architecture, insight.. and explore the depth to it, and if it takes you away from the title of a DE be it.. it will be a part of you always, and for good ðŸ˜‡",
          "score": 1,
          "created_utc": "2026-02-18 20:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64dywj",
          "author": "kbisland",
          "text": "I love the technical part but hate remembering business logic!!",
          "score": 1,
          "created_utc": "2026-02-18 20:44:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64i0ot",
          "author": "80hz",
          "text": "We're sold this lie that the goals to make data data driven decisions but the c-suite continually shows us that they don't care they only use the numbers when it backs up what they already want to do.",
          "score": 1,
          "created_utc": "2026-02-18 21:03:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64raq6",
          "author": "MikeDoesEverything",
          "text": "On top of all of the answers here, a lot of \"accidental DEs\" don't really know what it's like in other fields, thus assume it's \"shit\".\n\nYes, working from home earning a great salary is really quite awful.  I wrote a long winded [post](https://www.reddit.com/r/dataengineering/comments/1qr1ah1/comment/o2kvrao/?context=3) about why DE really isn't that bad compared to my old job.  Experience and perception how good your life is is all relative was the point I was trying to make.",
          "score": 1,
          "created_utc": "2026-02-18 21:45:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o650gqi",
          "author": "Atticus_Taintwater",
          "text": "Ironically I'm not sure I trust your data collection.\n\n\nI bet if you go on a front end dev forum you'll see as many people wanting to switch to back end. Vice versa.\n\n\nPeople and jobs aren't monoliths, I don't think de has any more discontents than other fields.\n\n\nedit: Specifically at my org data science has a better org structure. Non jr data scientists tend to report to avp's and have more autonomy over their projects.",
          "score": 1,
          "created_utc": "2026-02-18 22:28:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o650wdp",
              "author": "Illustrious-Pound266",
              "text": "I disagree. I don't see back-end people wanting to switch into front-end. Or data scientists / ML engineers wanting to switch into data engineering. If your logic was true, we would about similar proportion of folks wanting to switch out of these fields as well. But we don't.",
              "score": 1,
              "created_utc": "2026-02-18 22:30:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o656m2p",
                  "author": "SchemeSimilar4074",
                  "text": "Dude. Your sample size is \"people you see\". Nobody knows how many you see and what your background is. There's no logic whatsoever in this entire thread, just conjecture.Â ",
                  "score": 0,
                  "created_utc": "2026-02-18 22:58:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o655dms",
          "author": "Garcon_sauvage",
          "text": "My current job I am a slave to our data analysts while client and backend engineers are free to undermine and fuck me over without consequence. Get them to agree to a data contract and if they are feeling rushed they'll just break it, analysts then flip shit that they're not getting the data they need, guess who's fault it is? Literally just a punching bag.",
          "score": 1,
          "created_utc": "2026-02-18 22:52:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o659s4a",
          "author": "goeb04",
          "text": "It can be exhausting at times. For instance, I do some of the following:\n\nManage projects\nDevelop\nDebug\nResearch new tech\nPlan sprints for some contractors in Jira\nTry to keep up with whatever AI tool management salivates over\nOverlook DevOps\nGet requirements\nCreate wikis\nCreate roadmap\nKnowledge Transfer\nHelp out and mentor junior devs\n\n\n....and no, I am not a principal or Manager.\n\nI also never seem to get enough done either, which can be demoralizing. Love working with my business partners though, they keep me sane.",
          "score": 1,
          "created_utc": "2026-02-18 23:15:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66ikwp",
          "author": "MrNoSouls",
          "text": "They have no clue on a promotion track. Even though you make solutions to CAPX or OPX problems you don't get much in the way of compensation or prospects. The entire AI/ML will replace you also doesn't help.",
          "score": 1,
          "created_utc": "2026-02-19 03:32:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66xom8",
          "author": "neo_droid",
          "text": "too many Engineers. Its over crowded and lack of opportunities. Covid engineers ",
          "score": 1,
          "created_utc": "2026-02-19 05:13:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o687lf3",
          "author": "sporty_outlook",
          "text": "The field is saturated , and very generic. AI can already do most of the workÂ ",
          "score": 1,
          "created_utc": "2026-02-19 12:00:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o688b7v",
          "author": "dillanthumous",
          "text": "People who are happy in their jobs don't post about it online, would be my best guess.",
          "score": 1,
          "created_utc": "2026-02-19 12:05:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68f6xc",
          "author": "socratic_weeb",
          "text": "I've gotten bored. It's always the same thing: moving data around. It's also a tool hell, I don't want to learn a thousand different vendor lock-in tools for doing exactly the same stuff. You also have to deal with the suits more often, ugh.",
          "score": 1,
          "created_utc": "2026-02-19 12:53:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68p2kq",
              "author": "Illustrious-Pound266",
              "text": "Are you looking to switch out of data engineering into ML/AI? And wouldn't that also get boring once you settled into a new job?Â ",
              "score": 1,
              "created_utc": "2026-02-19 13:52:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o68q7yr",
                  "author": "socratic_weeb",
                  "text": "No, I've switched to full-stack development years ago. In principle, there aren't any limitations to the kind of work you can do as a software engineer, as long as it is computable, so you have more variety. Sure, in practice a lot of it is doing CRUDs, but let's say there is usually 30% of stuff that is different and really interesting. Specialization is valued and there isn't as much tool fragmentation, so the levels of tool hell are bearable.",
                  "score": 1,
                  "created_utc": "2026-02-19 13:59:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o69ipip",
          "author": "SnooSquirrels2420",
          "text": "I think it has been changing quite a bit with AI to be honest.",
          "score": 1,
          "created_utc": "2026-02-19 16:24:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69p3xu",
          "author": "Aggressive-Log7654",
          "text": "DE is extremely formulaic/linear and prone to total AI replacement sooner than other disciplines, in my experience of 12 years as a DE. I've partly jumped ship to SE which often requires more creative solutions and still needs a lot of handholding to have AI execute at higher complexity/abstraction levels. I still keep a DE role part of the time, but it's almost 100% AI agent driven set-and-forget kinda stuff now, for your typical non-global-scale startup or mid sized company, and it wouldn't be unfeasible for me to fully automate it into a strictly supervisory role if I invested the time and energy.\n\nAlso, as a pure DE, I felt no job satisfaction at all as my end users were always internal and companies largely pretend you don't exist until something is broken, then it's your fault. It's a nice feeling to ship features real field customers will use at scale. Whatever beautiful infrastructure or pipelines you build, the consuming analyst or DS will always get the glory/satisfaction of the discovery. There was also always a sense of being a \"fake software engineer\" whose \"code\" is mostly configs and baby scripts for various tools. And don't get me started on the endless tedious SQL some analyst half baked 5 years ago and now it's your responsibility to babysit for eternity in production.",
          "score": 1,
          "created_utc": "2026-02-19 16:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6djeg9",
          "author": "grounded-truth",
          "text": "I noticed after finishing my masters in data science that itâ€™s just DA, DE, DS and even ML all wrapped into one",
          "score": 1,
          "created_utc": "2026-02-20 05:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e1fns",
          "author": "EdmondVDantes",
          "text": "I'm a DevOps with data science masters who can't get into data science or data engineering for some reason. We will never be happy I guessÂ ",
          "score": 1,
          "created_utc": "2026-02-20 08:29:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64b4n9",
          "author": "Ashcliffe",
          "text": "For me itâ€™s the money. Transitioning to something like ML engineer will bring you at least a 30k pay increase with higher salary ceiling later on.Â \n\nItâ€™s also a good way to gain experience of similar roles to ensure you have a robust career.",
          "score": 1,
          "created_utc": "2026-02-18 20:31:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64bym4",
              "author": "Illustrious-Pound266",
              "text": "I feel like ML engineering is way more competitive though. I feel like that's the trade off.",
              "score": 2,
              "created_utc": "2026-02-18 20:35:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o64ouh5",
                  "author": "Ashcliffe",
                  "text": "Itâ€™s more about having your options open.\n\nIf you can do ML engineer you can do data engineer. But not the other way around.\n",
                  "score": 1,
                  "created_utc": "2026-02-18 21:34:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r69f91",
      "title": "What is the maximum incremental load you have witnessed?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r69f91/what_is_the_maximum_incremental_load_you_have/",
      "author": "kaapapaa",
      "created_utc": "2026-02-16 13:19:40",
      "score": 74,
      "num_comments": 48,
      "upvote_ratio": 0.97,
      "text": "I have been a Data Engineer for 7 years and have worked in the BFSI and Pharma domains. So far, I have only seen 1â€“15 GB of data ingested incrementally. Whenever I look at other profiles, I see people mentioning that they have handled terabytes of data. Iâ€™m just curiousâ€”how large incremental data volumes have you witnessed so far?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r69f91/what_is_the_maximum_incremental_load_you_have/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5ogav0",
          "author": "Sad_Monk_",
          "text": "smsc project @ a large indian telco\n\nevery 10 min ~100 gb mini batch mode from raw log files to oracle\niâ€™ve worked in insurance telcos and now banking \n\nno one does huge loads like telcos",
          "score": 78,
          "created_utc": "2026-02-16 13:25:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qo064",
              "author": "billy_greenbeans",
              "text": "Why do telcos have such large loads? Just sheer volume of calls being placed?",
              "score": 9,
              "created_utc": "2026-02-16 19:52:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5red6w",
                  "author": "mow12",
                  "text": "telco companies usually have tens of millions of user actively making transactions every day. it could be call or sms or data,mostly.",
                  "score": 8,
                  "created_utc": "2026-02-16 22:01:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5ogqbp",
              "author": "kaapapaa",
              "text": "interesting. looks domain plays a large role.",
              "score": 9,
              "created_utc": "2026-02-16 13:28:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5olg64",
          "author": "lieber_augustin",
          "text": "Iâ€™ve worked with very large telemetry datasets â€” up to 1â€“2 Pb of scanner data offloaded from autonomous test drives.\n\n\nRegarding 15Gb/day of new data -  it is already quite reasonable amount of data. If not treated properly it can \nbecome unusable very quickly. \n\nLast year I had a client who was struggling with 118 Gb of total data. \n\n\nSo Data Architecture is not about the size, itâ€™s about how you treat it :)",
          "score": 45,
          "created_utc": "2026-02-16 13:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5olzui",
              "author": "kaapapaa",
              "text": ">So Data Architecture is not about the size, itâ€™s about how you treat it :)\n\nðŸ’¯ \n\nUnfortunately recruiters aren't aware of it.",
              "score": 14,
              "created_utc": "2026-02-16 13:57:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5pkh5a",
                  "author": "TheOverzealousEngie",
                  "text": "It's a comment born of experience, so the true statement is Data Architecture is not about size, it's about experience. ",
                  "score": 5,
                  "created_utc": "2026-02-16 16:47:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5q54r7",
              "author": "Cpt_Jauche",
              "text": "Can you elaborate what you mean by â€žtreatmentâ€œ, like give an example?",
              "score": 4,
              "created_utc": "2026-02-16 18:23:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5p6x0g",
          "author": "crorella",
          "text": "In Facebook, it was common to work with tables that had 1 or 2 pb per day partition, specially in feed or ads.Â \n\nThe warehouse was around 5 exabytes in 2022.Â ",
          "score": 42,
          "created_utc": "2026-02-16 15:45:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5poykv",
              "author": "dvanha",
              "text": "holy fuckeronies",
              "score": 18,
              "created_utc": "2026-02-16 17:08:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5rmm6s",
              "author": "puripy",
              "text": "I believe it would've tripped by now?",
              "score": 3,
              "created_utc": "2026-02-16 22:43:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5scsgk",
                  "author": "crorella",
                  "text": "no idea, but it is not unusual, Netflix was at 4.5 exabytes last year.",
                  "score": 5,
                  "created_utc": "2026-02-17 01:11:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5paln2",
              "author": "kaapapaa",
              "text": "Amazing.",
              "score": 2,
              "created_utc": "2026-02-16 16:02:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5rjkf2",
              "author": "Dark_Force",
              "text": "That's awesome",
              "score": 2,
              "created_utc": "2026-02-16 22:27:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pamn4",
          "author": "Lanky-Fun-2795",
          "text": "Ppl donâ€™t judge data warehouse sizes anymore. Anyone who asks that is trying to hear keywords like partitioning/indexing for optimization. Logging/snapshots can easily double or triple your typical warehouse unless you are dealing with webforms",
          "score": 10,
          "created_utc": "2026-02-16 16:02:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pjxg6",
              "author": "kaapapaa",
              "text": "I understand. Yet wanted to check how much data being processed in reality.",
              "score": 5,
              "created_utc": "2026-02-16 16:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5psv1d",
                  "author": "Lanky-Fun-2795",
                  "text": "If they care that much just say petabytes. As long as you understand the repercussions of saying so.",
                  "score": 4,
                  "created_utc": "2026-02-16 17:26:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5q9xqp",
              "author": "THBLD",
              "text": "You forgot sharding.",
              "score": 1,
              "created_utc": "2026-02-16 18:45:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rb382",
                  "author": "Lanky-Fun-2795",
                  "text": "Thatâ€™s a relatively archiac concept with modern data warehouses tbh. I have taken tens of interviews in the past few weeks and I never got a single question about it.",
                  "score": 4,
                  "created_utc": "2026-02-16 21:45:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5okltr",
          "author": "LelouchYagami_",
          "text": "Last year I worked on data which had 200 million records per day. \n\nThis year I worked on data which has 600+ million records per hour!! So what seemed like big data last year is now not so big. ~1TB per hour\n\nDomain is e-commerce data",
          "score": 16,
          "created_utc": "2026-02-16 13:50:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ol2wv",
              "author": "kaapapaa",
              "text": "Nice. My profile is being judged for the low volume metrics .",
              "score": 4,
              "created_utc": "2026-02-16 13:52:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5opajx",
              "author": "selfmotivator",
              "text": "Damn! What kind of data is this?",
              "score": 1,
              "created_utc": "2026-02-16 14:15:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5p2p9h",
                  "author": "LelouchYagami_",
                  "text": "It's transformed data from API call logs. These APIs mainly take care of what customers see on the e-commerce website.",
                  "score": 2,
                  "created_utc": "2026-02-16 15:24:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5qogqw",
              "author": "billy_greenbeans",
              "text": "So, broadly, what is holding all of this data? How is it accessible?",
              "score": 1,
              "created_utc": "2026-02-16 19:54:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5t2nk6",
                  "author": "LelouchYagami_",
                  "text": "It's stored on S3 data lake and is made accessible through glue catalog. Mostly people use EMR to query it given the size of the data",
                  "score": 2,
                  "created_utc": "2026-02-17 03:49:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ofra2",
          "author": "liprais",
          "text": "i am running 100 + flink jobs and writing 1b rows into iceberg tables every day,qps is 30K + now,works smooth,took me a while,but it is easy, trust me ,loading data is always the easiest work to do.",
          "score": 7,
          "created_utc": "2026-02-16 13:22:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oivxv",
              "author": "jupacaluba",
              "text": "I wonder how much a select * would cost",
              "score": 4,
              "created_utc": "2026-02-16 13:40:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5olpvs",
                  "author": "ThePizar",
                  "text": "Depends on a lot. A system that large probably wonâ€™t let you return everything. And nor would you want to. However returning an arbitrary set of say 10 rows should be cheap",
                  "score": 2,
                  "created_utc": "2026-02-16 13:56:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5q3rjh",
                  "author": "skatastic57",
                  "text": "Limit 1",
                  "score": 1,
                  "created_utc": "2026-02-16 18:17:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5oimpk",
              "author": "Glokta_FourTeeth",
              "text": "What's your domain/industry?",
              "score": 2,
              "created_utc": "2026-02-16 13:39:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ok2om",
              "author": "taker223",
              "text": "Are those stage tables with no indexes?",
              "score": 1,
              "created_utc": "2026-02-16 13:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5okyer",
          "author": "chmod-77",
          "text": "AT&T messed with our plans and several months of data came in off \\~800 machines all at once. Everything scaled and handled it well, but it was a lot for me. 200-300 million records? The size is debatable due to the way its packaged, but it might have been 100 gbs.\n\nI realize this is a drop in the bucket for some of you.",
          "score": 5,
          "created_utc": "2026-02-16 13:52:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oln6g",
              "author": "kaapapaa",
              "text": "Seems like a Heavy Lifter.\n\nFor me, The volume of data is not problem, but the quality is.",
              "score": 3,
              "created_utc": "2026-02-16 13:55:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pikwr",
          "author": "ihatebeinganonymous",
          "text": "50 terabytes per day.\n\n\nOne million Kafka messages per second.",
          "score": 5,
          "created_utc": "2026-02-16 16:39:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pj3gm",
              "author": "kaapapaa",
              "text": "Social Media/ ecommerce domain?",
              "score": 1,
              "created_utc": "2026-02-16 16:41:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5pj7dx",
                  "author": "ihatebeinganonymous",
                  "text": "No. Industry.",
                  "score": 2,
                  "created_utc": "2026-02-16 16:42:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pxb1f",
          "author": "bythenumbers10",
          "text": "Once worked for a cybersec outfit that recorded spam web traffic. Whatever pinged their sensors, good, garbage, hack, anything, it got recorded and catalogued. Quite a bit of data, just continuously rolling & getting stored, gradually getting phased into \"cold storage\" in compressed formats.",
          "score": 4,
          "created_utc": "2026-02-16 17:47:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q60z7",
          "author": "Beny1995",
          "text": "Working in a large e comm provider our clickstream data is around 7PB at time of writing. Believe its back to 2015 so I guess thats roughly 1.7TB per day? Presumably partitioned further though.",
          "score": 4,
          "created_utc": "2026-02-16 18:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t36ee",
          "author": "its4thecatlol",
          "text": "1TB an hour across 500mm records",
          "score": 3,
          "created_utc": "2026-02-17 03:53:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5okraw",
          "author": "Hagwart",
          "text": "Same amounts ... 25 GB per bi monthly cycle added.",
          "score": 2,
          "created_utc": "2026-02-16 13:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pooo9",
          "author": "speedisntfree",
          "text": "Peter North's",
          "score": 1,
          "created_utc": "2026-02-16 17:07:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7bk2u",
      "title": "Is the Data Engineering market actually good right now?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r7bk2u/is_the_data_engineering_market_actually_good/",
      "author": "Tricky_Tart_8217",
      "created_utc": "2026-02-17 16:53:58",
      "score": 65,
      "num_comments": 57,
      "upvote_ratio": 0.88,
      "text": "I am just speaking from the perspective of a data engineer in the US, with 4 years of experience. I've noticed a lot of outreach for new data engineer positions in 2026, like 2-3 linkedin messages or emails per week. And I have not even set my profile as \"Open To Work\" or anything.\n\nHas anyone else noticed this? Past threads on this subreddit say that the market is terrible but it seems to be changing.\n\nThis is my skillset for reference, not sure if this has something to do with it. Python, SQL, AI model implementation, Kafka, Spark, Databricks, Snowflake, Data Warehousing, Airflow, AWS, Kubernetes and some Azure. All production experience",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r7bk2u/is_the_data_engineering_market_actually_good/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5wtn0k",
          "author": "SoggyGrayDuck",
          "text": "If your profile looks senior or you have the right experience you're a hit commodity. Seems every company is looking to bring in that top tier engineer to fix everything, migrate to the cloud, help the jr engineers. They realized they have the upper hand right now and hopefully just redesigning before bringing in more mid level/senior devs. \n\nAlthough looking at some of these job descriptions I don't think I'd even want the job. The list of requirements is insane. Or you specialize in a particular software",
          "score": 41,
          "created_utc": "2026-02-17 18:46:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yr5qu",
              "author": "Wojtkie",
              "text": "A lot Iâ€™ve seen fall into this bucket of â€œwe donâ€™t know how this works but we paid too much to a contract team 4 years ago when everyone was growing but now we need to hire someone to fix itâ€",
              "score": 15,
              "created_utc": "2026-02-18 00:31:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o61d5r6",
                  "author": "SoggyGrayDuck",
                  "text": "Yeah they lean heavily on SaaS tools (kickbacks) and it seems we need to learn this lesson every 10 years. I worry AI will make it work though",
                  "score": 1,
                  "created_utc": "2026-02-18 11:48:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5x37z0",
          "author": "JohnPaulDavyJones",
          "text": "Bunch of interest in the last few weeks from younger firms. I'm on the more junior end of the senior engineer world, so I think u/SoggyGrayDuck nailed it: the firms are looking for someone to come in and fix things without actually *paying* for a senior enough engineer who could do the job right with limited support.\n\nMost of these jobs look like they blow, though. $130k-$140k to lead a couple of very junior engineers/contractors, manage the MSP relationships, and handle all prod support as well? Pass.\n\nAlso got a couple recruiter pokes from the firms that are notable for the churn in their DE orgs, like CapOne, so that's also a hard pass.",
          "score": 20,
          "created_utc": "2026-02-17 19:31:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5y80bd",
              "author": "the_fresh_cucumber",
              "text": "I think you hit the nail on the head here.\n\nThere are *always* job offers for senior engineers that are willing to work for below market.",
              "score": 5,
              "created_utc": "2026-02-17 22:46:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5zup70",
              "author": "turboDividend",
              "text": "yes. this is whats out there 120k-130k is a experiened midlevel person. a senior should be at 170K+",
              "score": 5,
              "created_utc": "2026-02-18 04:11:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5yumlm",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-18 00:50:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5z3o5q",
                  "author": "JohnPaulDavyJones",
                  "text": "Maybe itâ€™s local to their Dallas office, but theyâ€™ve got a serious reputation around here for burning out their DEs and having crazy churn.",
                  "score": 1,
                  "created_utc": "2026-02-18 01:38:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5x3p4j",
              "author": "Tricky_Tart_8217",
              "text": "That's mostly what I have experienced. They don't seem to offer much of a raise from what I'm currently making. Unless I wanna gamble my job security with C1 ðŸ˜‚",
              "score": 1,
              "created_utc": "2026-02-17 19:33:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5x00hl",
          "author": "maxbranor",
          "text": "I live in Norway, I recently started in my company, and I still get contacted by recruiters / ceos / ctos at least once per week via linkedin/email.  Got some tempting offers, even though I'm well employed.\n\nAt the same time, we were hiring a DE for my team and it was quite challenging to find senior-ish people.\n\nIt seems that the market for senior DE is really good here: high demand, few prospects.\n\nEDIT: Sorry for the potential confusion. We already hired someone, the position is not open anymore - but good luck to those on the hunt!",
          "score": 31,
          "created_utc": "2026-02-17 19:16:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65dmq1",
              "author": "TotalBother9212",
              "text": "Just out of curiosity, whatâ€™s the realistic pay-range over there for mid to senior?",
              "score": 1,
              "created_utc": "2026-02-18 23:36:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o691a4z",
                  "author": "maxbranor",
                  "text": "according to my union's statistics, the numbers for data/it in the private sector are:\n\nAverage:  \n5-9 YoE: 940,000 nok (circa 84,000 Euro / year)  \n10-14 YoE: 1,145,000 nok (circa 102,000 Euro / year)  \n  \nUpper quartile:  \n5-9 YoE: 1,040,000 nok (circa 93,000 Euro / year)  \n10-14 YoE: 1,230,000 nok (circa 109,000 Euro / year)\n\nMy salary is bit over the upper quartile on the 10-14 YoE\n\nIt is a good salary for norwegian standards, but it wont get me rich lol",
                  "score": 2,
                  "created_utc": "2026-02-19 14:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5xdr58",
              "author": "the_mg_",
              "text": "Do you still need :) ? What stack do you use ?",
              "score": -2,
              "created_utc": "2026-02-17 20:20:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60gon5",
                  "author": "maxbranor",
                  "text": "We hired someone. Thanks, though  \nand good luck!",
                  "score": 2,
                  "created_utc": "2026-02-18 06:59:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5xh65t",
              "author": "Kaiserx0",
              "text": "Iâ€™d love to join the European workforce , even at minimum wage Iâ€™d love to contribute , I can send you over my resume.",
              "score": -22,
              "created_utc": "2026-02-17 20:37:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5wuhct",
          "author": "ppsaoda",
          "text": "I think yes, but seasonally. Its difficult for me to apply in 3rd and 4th quarter. But now I only applied to 4 jobs, got 3 interviews with verbal offers now. 30% jump.",
          "score": 42,
          "created_utc": "2026-02-17 18:50:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5x53z2",
              "author": "EricMichaelHarris99",
              "text": "Where are you based? 75% success sounds insane where I live!",
              "score": 12,
              "created_utc": "2026-02-17 19:40:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5yjop8",
                  "author": "ckal09",
                  "text": "They are in Malaysia based on their comment history",
                  "score": 4,
                  "created_utc": "2026-02-17 23:50:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5yewrv",
              "author": "isuckatpiano",
              "text": "I looked at the linked in where I live in the Midwest and senior jobs were at 100k? Seems low for a senior developer. Are they higher in yours?",
              "score": 1,
              "created_utc": "2026-02-17 23:23:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5zukuf",
                  "author": "turboDividend",
                  "text": "there has been wage compression.",
                  "score": 1,
                  "created_utc": "2026-02-18 04:11:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5xsrc6",
              "author": "Live-Duck1369",
              "text": "I donâ€™t understand? How ? How many years of experience if you donâ€™t mind me asking?",
              "score": 0,
              "created_utc": "2026-02-17 21:31:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xt2qh",
                  "author": "Treemosher",
                  "text": "I think the industry you're trying to work in should be part of these conversations.  \n\nI don't know where you or the person you're replying to works, but probably worth bringing up.",
                  "score": 2,
                  "created_utc": "2026-02-17 21:33:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o68bcdn",
                  "author": "ppsaoda",
                  "text": "I have 5 years, and in between senior position to lead/manager.  More towards IC role.",
                  "score": 1,
                  "created_utc": "2026-02-19 12:27:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5x9pr5",
          "author": "WilhelmB12",
          "text": "For mid to seniors yes, for jr's not so much.",
          "score": 7,
          "created_utc": "2026-02-17 20:01:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xtmlo",
              "author": "techinpanko",
              "text": "This. Like many other disciplines, AI is allowing folks to do more with less, so the more senior end of the spectrum gets picked up and is expected to do both his domain and the domain of a junior for maybe 10-25% more of what their salary was pre-AI. \n\nI also see in the next five years most of the seniors getting snatched up, leaving nothing but juniors in the talent pool, forcing firms to pick up junior talent.",
              "score": 3,
              "created_utc": "2026-02-17 21:36:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xwk6q",
                  "author": "WilhelmB12",
                  "text": "Tbh, DE has never been an entry level career",
                  "score": 6,
                  "created_utc": "2026-02-17 21:49:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5wz4cz",
          "author": "empireofadhd",
          "text": "I think itâ€™s normal, which is amazing in a ai software apocalypse.",
          "score": 5,
          "created_utc": "2026-02-17 19:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yks8o",
              "author": "EdwardMitchell",
              "text": "Iâ€™m actually wondering how many data engineers have moved to AI. That certainly leads to the demand for traditional engineers. The ai initiatives Iâ€™ve seen are not replacing people because the AI is harder to maintain than the automations that they were replacing",
              "score": 2,
              "created_utc": "2026-02-17 23:56:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5x6ha5",
          "author": "SQLofFortune",
          "text": "If youâ€™re a senior and willing to work in an office, yes. Also if youâ€™re willing to do senior-level work for junior-level pay.",
          "score": 5,
          "created_utc": "2026-02-17 19:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xkt5q",
          "author": "adgjl12",
          "text": "Yes and no. I do get recruiters reaching out but none of them are better than my current job. I have 6YOE now.\n\nIf you hit all or most of the below I will gladly interview:\n\n- fully remote\n- more than 160k TC\n- 15 or more days of PTO (youâ€™d be surprised how some jobs checked all boxes but only gave 5-10 days pto)\n- no industries like crypto, gambling, etc\n\nI have not had a single recruiter bring me a job with all of them so I stay put. So the market is okay as in I could find a job but hard to find an upgrade than what I have already",
          "score": 5,
          "created_utc": "2026-02-17 20:54:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5y6lne",
              "author": "Admirable_Bed7398",
              "text": "Everytime I see PTO days in US, I feel super lucky to live in the Europe with my 32 days of vacation and 14 days for any medical appointment. ",
              "score": 10,
              "created_utc": "2026-02-17 22:39:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5x4wat",
          "author": "Amar_K1",
          "text": "People realising data engineer is required for AI and it is also taking over to what level reporting was 5 years back.",
          "score": 7,
          "created_utc": "2026-02-17 19:39:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61x799",
              "author": "ludflu",
              "text": "this is my read of the situation too! AI without ground truth data is just pure hallucination, and the clued-in business people do seem to understand this.",
              "score": 1,
              "created_utc": "2026-02-18 13:53:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o63clgd",
              "author": "slayerzerg",
              "text": "Pretty much. Itâ€™s the least ai doable work (hence the burnout as ai has made this work harder)",
              "score": 1,
              "created_utc": "2026-02-18 17:54:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5wx2of",
          "author": "ianitic",
          "text": "Yup, I've been noticing the same. I've also been getting popular profile alerts even though I haven't made an update in like 3 years.",
          "score": 2,
          "created_utc": "2026-02-17 19:02:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67m5dd",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-02-19 08:44:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o68sr7v",
                  "author": "ianitic",
                  "text": "It's been 150-175K and I'm in a lcol area. So not horrible I suppose for the area.\n\nI'm a big fish in a small pond though. If I move companies I want it be to a tech industry company. I'm just tired of not having many peers anymore or anyone I can sharpen my skills with.",
                  "score": 1,
                  "created_utc": "2026-02-19 14:13:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5x11wh",
          "author": "LoudSphinx517",
          "text": "What skills do you have on your profile to get reached out to ?\n\n",
          "score": 2,
          "created_utc": "2026-02-17 19:21:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5x42q0",
              "author": "Tricky_Tart_8217",
              "text": "Python, SQL, AI model implementation, Data Warehousing, Kafka, Spark, Databricks, Snowflake, Airflow, AWS, Kubernetes and some Azure. All production experience",
              "score": 5,
              "created_utc": "2026-02-17 19:35:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60z7ql",
                  "author": "Illustrious_Role_304",
                  "text": "what exactly in AI model implementation",
                  "score": 1,
                  "created_utc": "2026-02-18 09:50:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xang2",
          "author": "DudeYourBedsaCar",
          "text": "Senior DE here and yes, anecdotally, I've noticed an uptick in recruiter messages for both hybrid and remote in the last 6 months.\n\nI'm still getting interest even though the market seems to be shit for everything else, and I'm not particularly visible on job platforms or blogs or anything like that. Seems to be purely organic.",
          "score": 2,
          "created_utc": "2026-02-17 20:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xdoh3",
          "author": "goblueioe42",
          "text": "Itâ€™s better than other fields within engineering, but still softer than a few years ago!",
          "score": 2,
          "created_utc": "2026-02-17 20:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ykz6g",
          "author": "typodewww",
          "text": "Idk Iâ€™m a fresh grad Data Engineer with like 2 month experience at my job. I just got hit up today for a Data Engineer position in person in Indiana which I wonâ€™t take.",
          "score": 2,
          "created_utc": "2026-02-17 23:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yoibq",
          "author": "Scared_Student7099",
          "text": "Unfortunately my latest roles have had limited software exposure, so my toolset isn't quite as wide despite my academic experience in a master's program with said tools (many companies seem to think such experience doesn't count since it isn't in production ðŸ˜®â€ðŸ’¨). Do you (or anyone else) have any tips on convincing my non-technical team to branch out into more modern data tools? We're currently mostly using bash, PostgreSQL and a drag and drop ETL tool. Because of my particular role, I'm also exposed to Databricks.",
          "score": 2,
          "created_utc": "2026-02-18 00:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63b8lg",
          "author": "slayerzerg",
          "text": "Itâ€™s good for seniors because most DEs in this industry have no idea what they are doing or are underqualified. Honestly I went from full stack, to backend swe with a focus in data, to platform & infra to ML & DE and itâ€™s a culmination of all of that that is why most companies are having trouble finding the right hires.",
          "score": 2,
          "created_utc": "2026-02-18 17:49:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xvwua",
          "author": "SgtSlice",
          "text": "Market is starting to pick up again.",
          "score": 3,
          "created_utc": "2026-02-17 21:46:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5x7mwb",
          "author": "Slggyqo",
          "text": "4 YoE \n\nSeems pretty good to me. \n\nNot as good as 2-5 years ago, but thereâ€™s no shortage of recruiter outreach and the salaries are decent, if a bit lower across the board unless itâ€™s a role for an AI company.",
          "score": 1,
          "created_utc": "2026-02-17 19:52:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5x8k88",
          "author": "marcelorojas56",
          "text": "How much $$$ are we talking about?",
          "score": 1,
          "created_utc": "2026-02-17 19:56:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xlp5x",
          "author": "starrorange",
          "text": "Which major city are you close to? I agree but Iâ€™m also getting them for nyc based",
          "score": 1,
          "created_utc": "2026-02-17 20:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y4s1o",
          "author": "Ok-Obligation-7998",
          "text": "No.",
          "score": 1,
          "created_utc": "2026-02-17 22:29:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zuhcx",
          "author": "turboDividend",
          "text": "i got laid off end of january. have 2 2nd round interviews already ;\\\n\n\n\nwas kinda hoping to take some time off but it looks like that might not happen",
          "score": 1,
          "created_utc": "2026-02-18 04:10:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61s9a0",
          "author": "NefariousnessSea5101",
          "text": "Man I just have 2.5 YoE, applying aggressively got great referrals, getting rejected because I miss the mark of 3+ YoE which most recruiters are looking for.",
          "score": 1,
          "created_utc": "2026-02-18 13:26:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61wt27",
          "author": "ludflu",
          "text": "I think AI has something to do with it. The hiring managers who have a clue realize that AI is in fact changing the business environment - but that AI doesn't work without data.",
          "score": 1,
          "created_utc": "2026-02-18 13:51:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68a2hl",
          "author": "Traditional_Ad_5878",
          "text": "I didnâ€™t even started my junior data engineer career and Iâ€™m already helping the recruiter to find someone else to get into the team.",
          "score": 1,
          "created_utc": "2026-02-19 12:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a15o4",
          "author": "Pristine-Gur-3363",
          "text": "I graduate this year how do I become wanted for hire do data engineering.",
          "score": 1,
          "created_utc": "2026-02-19 17:53:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7u6sz",
      "title": "Starting my first Data Engineering role soon. Any advice?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r7u6sz/starting_my_first_data_engineering_role_soon_any/",
      "author": "xahyms10",
      "created_utc": "2026-02-18 05:13:17",
      "score": 64,
      "num_comments": 27,
      "upvote_ratio": 0.94,
      "text": "Iâ€™m starting my first Data Engineer role in about a month. What habits, skills, or ways of working helped you ramp up quickly and perform at a higher level early on? Any practical tips are appreciated",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r7u6sz/starting_my_first_data_engineering_role_soon_any/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o60szyx",
          "author": "___ml_n",
          "text": "I've been in 3 different roles as a Data Engineer, and they've all been so wildly different to me and without knowing more specifics without your role, I can't give too specific advice. But here are some general pointers from when I first started that might help.\n\n\\- Learn general data engineering practices / lingo. You're going to hear things like: Data Governance, Data Catalogs, Data Lineage, Data Warehouse, ETL, ELT, Data Lake, OLAP, OLTP, Data Mesh, etc. You don't have to learn everything all at once, or even fully understand everything the first time. Start with who / what you'll work with, expand from there.\n\n\\- Learn SQL VERY well. Two sides to this: learn a dialect VERY well and learn a database implementation well.  \nThe former will help you with your day to day job as a junior. Learning how to solve common patterns, use common functions, solve common SQL problems, etc will help you for your whole career. For the latter, you would want to really be able to explain things like indexes (which ones to use, why), data storage internals, how to read execution plans and optimize, etc. This is something you should be picking up gradually throughout your career, and I would only expect more mid level / senior engineers to know more and more about these things. For a junior, just begin learning it slowly, but don't stress out too much. \n\n\\- Lots of companies are now on the cloud (AWS/Azure/GCP). If your company is one of them, you should learn the stack. Learn the services that your company is using, what role / problem it solves, and how to configure/work with it. Whatever your company uses, be it Azure Synapse/AWS Redshift for data warehousing, ADLS / AWS S3 for object storage, learn that tech deeply, learn how authorization/authentication works on your cloud platform, and those two alone will carry forth across cloud providers. Once you learn what you work with, you can slowly expand outwards if you so desire. \n\n\\- Additional point to the above, lots of companies also use Databricks / Snowflake. If applicable, learn what each of those companies provide in terms of offerings or services. IMHO learning either of these opens the door for more data engineering roles in the future.\n\n\\- Maybe a controversial tip, but as a software engineer turned data engineer, I personally still apply software engineering principals just through a data engineering lens. That means following best practices when writing clean code, working with things like CI/CD, git, code review, etc. This may seem like a no brainer, but not every shop hires data engineers from the software engineer / CS grad pipeline. Lots of DEs I knew came from data analyst or scientist positions, and had no clue of the SWE fundamentals. I think treating this job as a specialized SWE position will help you a LOT with the menial stuff, and it'll allow you to pivot if you ever want to.\n\nI omitted a lot, but I think this is good to start, and I think these are general enough to help you no matter what kind of DE position you're put into. ",
          "score": 79,
          "created_utc": "2026-02-18 08:52:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61i7ae",
              "author": "HOFredditor",
              "text": "can I DM you for some questions ?",
              "score": 2,
              "created_utc": "2026-02-18 12:24:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63b9qg",
                  "author": "___ml_n",
                  "text": "Sure",
                  "score": 2,
                  "created_utc": "2026-02-18 17:49:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o673ahy",
              "author": "onyxharbinger",
              "text": "Interesting since most DEs Iâ€™ve come across implement SWE practices. I suppose they can come from DS but usually those turn into more SWEs.",
              "score": 1,
              "created_utc": "2026-02-19 05:56:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6045em",
          "author": "Egao4",
          "text": "Same, gonna be a new grad data engineer in July but have little to no data engineering experience and feel like I rely on AI too much. Following this post!",
          "score": 14,
          "created_utc": "2026-02-18 05:17:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62dwvo",
              "author": "typodewww",
              "text": "Iâ€™m a current new grad Data Engineer graduated May 2025 been with my company 2 months you donâ€™t have to be a all or spake expert just try your best to keep up with projects and ask questions and itâ€™s ok not to be a master of everything.",
              "score": 4,
              "created_utc": "2026-02-18 15:17:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o613937",
              "author": "Dark_Sotard",
              "text": "This basically sums up my situation",
              "score": 3,
              "created_utc": "2026-02-18 10:26:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62806u",
          "author": "inglocines",
          "text": "SQL and Python are going to be your best friends in this career. I am not sure about your proficiency in either, but try to solve some difficult problems in both without using AI (or may be ask AI to generate questions for you to solve).   \n  \nIn SQL, try to build common patterns in data engineering with some sample data - MERGE INTO, SCD Type 2, some small star schema design.  \n  \nIn python, know common patterns used with data structures - list, dict, set and iterators. \n\nThese will help you in first few months. You can slowly move towards understanding the bigger data engineering architecture - SQL Optimization techniques, ETL, Data Vault modelling. I recommend you get 'Fundamentals of Data Engineering' book and read it once in a while. Re-read the concepts again once every few months as it will add new perspectives as you gain experience.  \n\nOnce you master SQL and python, tools are not going to be difficult for you. You will get to see that irrespective of tool - Spark or Snowflake, Airflow or ADF (or any GUI based orchestration) - the build patterns and outcomes are almost exactly same. \n\nWhile you master technical things, also try to be curious about the business problem you are solving. It doesn't matter if you know 4 different tools, if you cannot answer what business problem you solved. For this, AI would be immensely helpful. Let's say someone wants to build a CRM dashboard for which you are building data model - You might hear terms like Sales Funnel or Conversion rate - Try to ask AI and get an overall perspective of the problem you are trying to solve. You will work with lot of business analysts who will be more than happy if you talk their language. \n\nThese should be enough for now. ",
          "score": 6,
          "created_utc": "2026-02-18 14:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o608qlz",
          "author": "al_coper",
          "text": "I encourage you to try to understand deeply the business; How does they work? Process, customers, the reason behind the task you are performing, etc.",
          "score": 13,
          "created_utc": "2026-02-18 05:52:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60rvpg",
          "author": "Online_Matter",
          "text": "Do things as simple as possible and plan for changes. What's the data use and scale of data? What's the simplest way to handle that which will benefit the company for the next two or so years? Don't spin up a hadoop cluster for something that can be done in python.Â ",
          "score": 5,
          "created_utc": "2026-02-18 08:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o614y1g",
          "author": "redditreader2020",
          "text": "Take notes and/or journal as much as possible. This will help in so many ways. Reinforces what you are learning. Reference for when you forget or your manager asks what have you accomplished. You can mentally relax on the weekends.\n\nI recommend markdown files but find what works for you.",
          "score": 4,
          "created_utc": "2026-02-18 10:41:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60eckq",
          "author": "No_Distribution_7987",
          "text": "Congratulations! \nTry to understand the business. Itâ€™ll help you in long way to translate data to match the business use case. Always try and understand the complete picture.",
          "score": 5,
          "created_utc": "2026-02-18 06:39:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60wi2u",
          "author": "breadncheesetheking1",
          "text": "Do you have any previous experience in data?",
          "score": 2,
          "created_utc": "2026-02-18 09:25:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o651lui",
          "author": "Mercureece",
          "text": "Be a sponge, learn from everyone you can around you, learn how to solve the business problem before throwing tech at something so your solution will actually be used and youâ€™ll go far ðŸ¤",
          "score": 2,
          "created_utc": "2026-02-18 22:33:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c1xsb",
          "author": "perfectthrow",
          "text": "This is non-technical advice. Whoever you report to, ask them a lot of questions about what the teamâ€™s strategic direction is, what the business objectives are, where the gaps are, whatâ€™s the entire reason for the teamâ€™s existence (lol maybe not that bluntly).\n\nIn my experience, success in this field comes from aligning your technical work with what the business wants. Everything else cascades down from there. And if you have an awesome director or manager who communicates these needs/requirements to the team effectively and has you guys working on high value stuff, congrats!\n\nTechnical advice would be just make sure to program defensively. Assume things could go wrong at any step in any pipelines and know what state everything would be at when those things do go wrong. Itâ€™s not if, itâ€™s when. Good luck and congrats on the new gig!",
          "score": 2,
          "created_utc": "2026-02-19 23:59:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o612rpb",
          "author": "Key_Card7466",
          "text": "FollowingÂ ",
          "score": 1,
          "created_utc": "2026-02-18 10:22:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62d1t7",
          "author": "aquabryo",
          "text": "There's no best way to do anything, it's all just tradeoffs.",
          "score": 1,
          "created_utc": "2026-02-18 15:13:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62zhmp",
          "author": "mathproblemsolving",
          "text": "Congratulations on getting first DE role! I would check with the teammates/manager about the tech stacks they are using and a head start on those. ",
          "score": 1,
          "created_utc": "2026-02-18 16:55:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63715b",
          "author": "PuzzleheadedText5182",
          "text": "!remindme 3 days",
          "score": 1,
          "created_utc": "2026-02-18 17:30:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6377oe",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 3 days on [**2026-02-21 17:30:07 UTC**](http://www.wolframalpha.com/input/?i=2026-02-21%2017:30:07%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1r7u6sz/starting_my_first_data_engineering_role_soon_any/o63715b/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1r7u6sz%2Fstarting_my_first_data_engineering_role_soon_any%2Fo63715b%2F%5D%0A%0ARemindMe%21%202026-02-21%2017%3A30%3A07%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r7u6sz)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-18 17:30:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o639uk0",
          "author": "MakeoutPoint",
          "text": "Whatever you do, realize that you're a baby in the field. Don't come in thinking you're hot shit, and look to change the way things are done or tell someone else how to do their job. It's a great way to get on a shitlist.\n\n\nLearn everything you can from people who have been doing this for a lot longer, because what you were taught in school was a brief exploration of the idea of DE, and more importantly learn ***why*** things are done the way they are.",
          "score": 1,
          "created_utc": "2026-02-18 17:42:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64q36d",
          "author": "brucesheikh",
          "text": "Following",
          "score": 1,
          "created_utc": "2026-02-18 21:40:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65uzow",
          "author": "Own-You1124",
          "text": "!remindme 3 days",
          "score": 1,
          "created_utc": "2026-02-19 01:13:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68b2dn",
          "author": "RangaAnna",
          "text": "good luck brother",
          "score": 1,
          "created_utc": "2026-02-19 12:25:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6em0e6",
          "author": "Signal-Card",
          "text": "Congrats, thatâ€™s awesome.\n\nStuff that helped me early on:\n\nFocus on understanding the business first. Ask â€œwhat decisions does this data support?â€ every time. It makes all your technical work way more valuable and helps you prioritize.\n\nRead the existing pipelines like youâ€™re a detective. Trace one important data set from source to final table/dashboard. Take notes. Build yourself a little internal wiki or scratch doc with â€œthis table is used for X, comes from Y.â€\n\nGet very comfortable with SQL and debugging. Learn to quickly answer â€œwhy is this number wrong?â€ Thatâ€™s 70% of the job at a lot of places.\n\nOvercommunicate at the start. Before you build something, repeat back what you think they want and how youâ€™ll do it. Saves a ton of rework.\n\nAlso, donâ€™t try to overhaul everything in month one. Fix small, annoying problems, document stuff, and ask â€œis there already a standard way we do this?â€ a lot. That alone will make you look senior faster than flexing some fancy tool.",
          "score": 1,
          "created_utc": "2026-02-20 11:36:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7l43c",
      "title": "just took my gcp data engineer exam and even though i studied for almost a year, I failed it.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r7l43c/just_took_my_gcp_data_engineer_exam_and_even/",
      "author": "Historical_Donut6758",
      "created_utc": "2026-02-17 22:34:40",
      "score": 57,
      "num_comments": 23,
      "upvote_ratio": 0.96,
      "text": "I am familar with the gcp environment, studied practice exams and , read the books designing data intensive applications and the fundamentals of engineering and even have some projects. \n\n\nDespite that i still failed.\n\n\nI dont know what else to say.",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r7l43c/just_took_my_gcp_data_engineer_exam_and_even/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5y6wra",
          "author": "No-Satisfaction1395",
          "text": "If the exam motivated you to read DDIA and absorb its teachings, you already gained more value than the certification, which is more about specific GCP tooling, would ever have.",
          "score": 93,
          "created_utc": "2026-02-17 22:40:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5y795e",
              "author": "paxmlank",
              "text": "This is how I see it for 95% of the time; however, if they're trying to market themselves in freelance or whatever, having a GCP cert would likely help immensely compared to not having any.\n\nBut at least take solace in the fact that you read some very important literature, OP.",
              "score": 16,
              "created_utc": "2026-02-17 22:42:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yplln",
          "author": "cortrev",
          "text": "I would use GCP Study Hub if you haven't. That's what I used to pass and I couldn't recommend it enough",
          "score": 26,
          "created_utc": "2026-02-18 00:22:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zw1ql",
              "author": "legendarybyson",
              "text": "I second this.",
              "score": 4,
              "created_utc": "2026-02-18 04:20:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yqbh4",
          "author": "ironmagnesiumzinc",
          "text": "I took one of the gcp exams several years ago and failed. Since then, Iâ€™ve taken the aws solutions architect, databricks spark, databricks data engineer, and sec+ and passed them all. Havenâ€™t failed another one yet. Idk if gcp is just stupid hard or back then I didnâ€™t know how to study for these things. I developed a very specific way of studying now that works for me. Anyways just wanted to tell u that so u donâ€™t lose motivation",
          "score": 10,
          "created_utc": "2026-02-18 00:26:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zqt75",
              "author": "RustyEyeballs",
              "text": "Do you mind sharing your process for studying?",
              "score": 1,
              "created_utc": "2026-02-18 03:47:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5zzrkv",
                  "author": "ironmagnesiumzinc",
                  "text": "First I create a google doc with each topic and % of the exam it represents. Then, I go over several recent exam dumps, try to understand ever question/answer, and add any info I donâ€™t know to the correct section of my study guide. If thereâ€™s a specific topic I donâ€™t know much about, Iâ€™ll ask Claude more about it and really fill out that section of the guide. I reorganize every so often, reread it, and keep adding until thereâ€™s enough",
                  "score": 9,
                  "created_utc": "2026-02-18 04:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61swbo",
          "author": "Cyphor-o",
          "text": "Tbh most of the questions are BS. They're catch 22's of not what a Data Engineer would do but what would a GCP Data Engineering Consultant suggest to increase cloud spending. \n\nYou'll have great knowledge, use it to build a POC put it into a public repo and use it for a portfolio, shows better than a digital cert.",
          "score": 3,
          "created_utc": "2026-02-18 13:30:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y7vb3",
          "author": "i_hate_budget_tyres",
          "text": "Can you get on googles get certified program?  Getting guidance as a first timer is well worth while.  They give exam tips and tricks, constantly testing your knowledge and clarifying ideas as you learn with the exam in mind.  You really should use Googles training materials.  Videos, labs etc.\n\nAlso a year is too long, you end up forgetting stuff.  The get certified program pushes people to finish in 10 to 12 weeks.  I think that is optimal, given the scope of the qualifications, and its a short enough timeframe to retain information.  Give up evenings and social life for a while and keep pushing.",
          "score": 2,
          "created_utc": "2026-02-17 22:45:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yq2ku",
          "author": "AnimaLepton",
          "text": "There's not a year's worth of material to study for it. If you want to take it seriously, focus on a more structured 6 or 12 week approach",
          "score": 2,
          "created_utc": "2026-02-18 00:25:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62li4x",
          "author": "sdrawkcabineter",
          "text": "\"It is possible to commit no mistakes, and still lose.\"\n\n>Google Cloud Uniform Route Identification Value of the Present Instanced Commit Fabric?\n\n>\"Uh, 127.0.0.1?\"\n\n>\"Correct!\"\n\n>\"So it's localhost!\"\n\n>\"... No...\"",
          "score": 2,
          "created_utc": "2026-02-18 15:52:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y7r74",
          "author": "empireofadhd",
          "text": "Have you tried using an ai agent as a teacher? \n\nAlso sometimes you need 2-3 real world projects to really integrate the teachings.",
          "score": 5,
          "created_utc": "2026-02-17 22:45:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yicfg",
              "author": "Historical_Donut6758",
              "text": "i use chatgpt and i got most of the questions right...i guess they were easy questions.\n\n\ndid ai help you",
              "score": 1,
              "created_utc": "2026-02-17 23:42:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yhp3h",
          "author": "EffectiveClient5080",
          "text": "Exams donâ€™t always reflect real skills. With DDIA, projects, and a year of prep, youâ€™re clearly capable. Just tweak your approach-retake and crush it.",
          "score": 1,
          "created_utc": "2026-02-17 23:39:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z0anb",
          "author": "DenselyRanked",
          "text": "Did you feel that the books were helpful for the test? Did you find the training on [skills.google](http://skills.google) useful?",
          "score": 1,
          "created_utc": "2026-02-18 01:21:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z8auy",
          "author": "Thisisinthebag",
          "text": "I failed dbt 3 times, feels like questions are made to trick you to fail. Every exam I have noted down weak points and re-read chapters, sometimes had to absorb whole article for 1 question that might or might not be given. Gemini has very good ui for test questions, and if you can find leaked questions it will help you to focus on weak points",
          "score": 1,
          "created_utc": "2026-02-18 02:01:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61q5wm",
          "author": "LimitedInfo",
          "text": "Thatâ€™s because the exam is about Google tooling not data engineering in general. You just need to re-study based on what the exam is actually about.",
          "score": 1,
          "created_utc": "2026-02-18 13:14:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61thf3",
              "author": "Cyphor-o",
              "text": "Thats it, its about being the best GCP Data Engineering Consulant on the best approach to maximise cloud spending. \n\nI'm not a fan of certs in general. They're all like this.",
              "score": 1,
              "created_utc": "2026-02-18 13:33:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o651e56",
          "author": "bah_nah_nah",
          "text": "Like most academic achievements - You need to study for the exam not practical application (as much as they claim otherwise)",
          "score": 1,
          "created_utc": "2026-02-18 22:32:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66rvw1",
          "author": "dubnobasshead",
          "text": "[https://www.examprepper.co/](https://www.examprepper.co/)\n\nThis is the only resource I use to study for these exams, Certified Data Engineer, Professional Cloud Architect, and since yesterday certified DevOps Engineer. \n\nLook for key words, they will often just use things like \"High Availability\" to suggest the tool they want you to use. Check the Docs for the summary they give there, it will include those words. \n\nOften times, 2 of the answers will be quite similar, its usually one of those 2!\n\nThe books will be of no help to you in the exam, its all just about knowing how google position their products through common key words, thats it.",
          "score": 1,
          "created_utc": "2026-02-19 04:32:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69zqlv",
          "author": "Ok-Sentence-8542",
          "text": "Why did you fail?",
          "score": 1,
          "created_utc": "2026-02-19 17:46:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5w346",
      "title": "Spent last quarter evaluating enterprise ETL tools",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r5w346/spent_last_quarter_evaluating_enterprise_etl_tools/",
      "author": "Justin_3486",
      "created_utc": "2026-02-16 01:24:54",
      "score": 52,
      "num_comments": 33,
      "upvote_ratio": 0.96,
      "text": "Went through a formal evaluation process for data integration tools last quarter and thought I'd share since most comparisons online feel like marketing dressed up as content. For context, mid sized company, around 50 saas data sources, snowflake as primary destination though we're also testing databricks for some ml workflows and have legacy stuff in redshift we're migrating away from.\n\nFivetran connectors are solid and reliable but the cost at scale gets uncomfortable fast, especially once you're pulling significant volume. Airbyte was interesting because of the open source angle and we liked having control, but self hosting added a whole new category of things to maintain which defeated part of the purpose for a small team. Matillion felt more oriented toward transformation than data ingestion which wasn't quite our primary use case.\n\nPrecog had more reasonable pricing and less operational overhead, though their documentation could use work and the UI takes some getting used to if you're coming from fivetran's polish. \nEach has tradeoffs depending on your scale, team size, and needs. Happy to answer questions about specifics.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r5w346/spent_last_quarter_evaluating_enterprise_etl_tools/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5m308q",
          "author": "wytesmurf",
          "text": "Do you need realtime? Realtime is expensive. Anything that does realtime gets expensive. Airflow probably has most of the connectors youâ€™re looking for. You could do a micro ETL, that would be much less cost wise. Flink or Beam pipelines are really good if you need performance \n\nFor true realtime on a budget. Look at each solution and figure out an architecture. Are there hooks, queues, api limits, query costs, etc. Do a true realtime and a micro batch solution based on how often the data changes. You will never find a tool that does everything. You can spend 3 more months looking at tools or define tools for different use case and start chipping away at",
          "score": 13,
          "created_utc": "2026-02-16 02:04:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pvgv7",
              "author": "soundboyselecta",
              "text": "Every one needs realtime till they get their cloud bill. Takes management to sit down stakeholders, rub them on their head like a little child and say easy there buddy, you need to calm down. ",
              "score": 5,
              "created_utc": "2026-02-16 17:39:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5pwlbm",
                  "author": "wytesmurf",
                  "text": "Your right there, they tried that, I told them to wait for the bill. Then they got a 60k confluent bill and they came back to the table. Ended up with a 5 minute micro batch in airflow. It costs dollars not tens of thousands",
                  "score": 3,
                  "created_utc": "2026-02-16 17:44:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5m42wp",
          "author": "HC-Klown",
          "text": "We have a small team of 2 data engineers. We self host airbyte and also airflow. I must say we handle it pretty well. Airbyte does not give any issue whatsoever wrt hosting. \n\nWe create connections declaratively using terraform and orchestrate them with airflow. We barely touch the UI, only for logs and maybe the occasional manual sync. The open source and number of different connectors are worth it. \n\nOnly con for airbyte is that in our opinion the normalization step from having the data in json blob to a RDBMS table takes unnecessarily long. It stupid. \n\nTherefore, we are pivoting our RDBMS sources to ingest them with Trino. Where we use dbt to write models that serve as ingestion with no transformation. So, Trino + dbt = ingestion. With dbt incremental models you can handle all sorts of ingestion patterns.  \n\nFor our other sources such as sftp, API, sharepoint etc., we keep using airbyte. Around 90% of our sources are RDMS though.\n\nAdditionally Trino can handle reverse etl easily to another database. Moreover, we can also write them as dbt models maintaining full lineage from ingestion all the way to Reverse ETL and other exposures.",
          "score": 9,
          "created_utc": "2026-02-16 02:11:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mte5c",
              "author": "iamspoilt",
              "text": "Since you mentioned self-hosting Airflow and Airbyte, I am wondering have you folks tried self-hosting Apache Spark clusters for distributed computing as well? How has that experience been?",
              "score": 1,
              "created_utc": "2026-02-16 05:05:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rypo6",
                  "author": "HC-Klown",
                  "text": "We haven't tried that. We have an on-prem k8s cluster and we host a multi node Trino setup there. We still haven't migrated to it so it's not operating with prod data/pipelines",
                  "score": 1,
                  "created_utc": "2026-02-16 23:50:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5o55ji",
              "author": "Voxnihil",
              "text": "I used Meltano and noticed the same issue you did with Airbyte, incredibly slow due to the intermediate conversions to and from jsonl.\n\nAnd that was a side project with low data volume, I can't imagine it at scale.",
              "score": 1,
              "created_utc": "2026-02-16 12:09:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ma5nd",
          "author": "GreyHairedDWGuy",
          "text": "There are many roads to Rome.  What works for you may not work for others.  What are you spending on Fivetran today?  I disagree with your assessment of Matillion.  It can certainly ingest data from SaaS solutions as well as on-prem.  It's not as nice/easy to use for ingestion as Fivetran but it does work.   Fivetran can get expensive (high MAR usage) when you have cases of large datasets (SaaS or on-prem) that need to get ingested each month but also have low number of updates (meaning you cannot save MAR if rows change may times per month). \n\nI had never heard of 'Precog' before but it seems to only have been around since 2020.  Not sure I would want to partner with a company this new.\n\nHope it works out for you.",
          "score": 3,
          "created_utc": "2026-02-16 02:50:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mli8f",
          "author": "geoheil",
          "text": "For connectors consider dlt - [https://dlthub.com/](https://dlthub.com/)  see here for a more fully fledged example [https://github.com/l-mds/local-data-stack/](https://github.com/l-mds/local-data-stack/) and docs dedicated on the integration dlt + dagster here [https://docs.dagster.io/integrations/libraries/embedded-elt](https://docs.dagster.io/integrations/libraries/embedded-elt)\n\n  \nthis is a bit more involved - gives you much more power and flexibility though - and better pricing via dlt (if you want oss)",
          "score": 6,
          "created_utc": "2026-02-16 04:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v0ouv",
          "author": "nocomm_07",
          "text": "\nThis is current day ELT tax. Hahah. Pay Fivetran for convenience or pay Airbyte with engineering hours. At 50 SaaS sources on a small team, self hosting anything that needs Terraform, Airflow and K8s is never truly free â€œfree.â€ And once Snowflake volume grows, row based pricing gets HUGEE. If you want a middle path, look at Integrate etl or Estuary. Fully managed but without pure volume based pricing. For most mid sized orgs a micro batch ELT approach into Snowflake every 5 to 15 minutes is enough. Real time streaming is going to cost way more than you would like.",
          "score": 2,
          "created_utc": "2026-02-17 13:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m1uuv",
          "author": "MgmtmgM",
          "text": "Did you consider snowflakeâ€™s openflow?",
          "score": 2,
          "created_utc": "2026-02-16 01:57:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lyx6l",
          "author": "pungaaisme",
          "text": "1. Is it possible to list the datasources by priority or volume? In case of databased to distinguish if these are log based datasource reader or using simple queries?  \n2. do you have reverse ETL use case from snowflake back to our operational systems?  \n3. What do you use for transformation/modeeling (dbt?) is it on Prem or dbt cloud or using snowflakes dbt capabilities ?",
          "score": 1,
          "created_utc": "2026-02-16 01:38:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m4z9p",
          "author": "Bstylee",
          "text": "Which one can handle huge volume with tons of thrash?",
          "score": 1,
          "created_utc": "2026-02-16 02:17:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o3xxw",
          "author": "Traditional_Gap4163",
          "text": "Commenting to follow",
          "score": 1,
          "created_utc": "2026-02-16 12:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wonu9",
          "author": "eb0373284",
          "text": "Do some research about NiFi with DFM.",
          "score": 1,
          "created_utc": "2026-02-17 18:23:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yzqkq",
          "author": "Hot_Map_7868",
          "text": "OSS is not free when you consider the platform maintenance as you rightly said. Thereâ€™s always a trade off. What did you end up selecting?",
          "score": 1,
          "created_utc": "2026-02-18 01:18:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dmvf9",
          "author": "Which_Roof5176",
          "text": "Appreciate you sharing this. Weâ€™ve seen similar tradeoffs around cost at scale and self hosting overhead.\n\nIf you're still evaluating, Estuary might be worth a look. Happy to answer anything specific.",
          "score": 1,
          "created_utc": "2026-02-20 06:16:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m0aes",
          "author": "Leading-Inspector544",
          "text": "You might consider dbx lakeflow connectors as well. Generally cheaper at scale than fivetran, as it's pay for compute rather than pay for volume of data.",
          "score": 1,
          "created_utc": "2026-02-16 01:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o8mt0",
          "author": "Technical_Depth2382",
          "text": "Hevo",
          "score": 0,
          "created_utc": "2026-02-16 12:35:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ucldn",
          "author": "jonas-weld",
          "text": "You might want to take a look at **Weld,** we typically see teams in your exact situation switch when Fivetran costs start climbing.\n\nWe offer significantly better pricing while keeping connectors stable and fully managed, so thereâ€™s essentially no maintenance needed on the ingestion side. After a short trial you can clearly estimate what your bill would look like based on the data youâ€™re syncing, which makes planning a lot easier.\n\nTransformation, orchestration, and reverse ETL are built into the platform as well, but getting data in is intentionally very simple. Feel free to reach out if you ever decide to test it.",
          "score": 0,
          "created_utc": "2026-02-17 10:18:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7kl2",
          "author": "Nekobul",
          "text": "Have you consider using SSIS for your needs? The platform itself is powerful enterprise-level and there is a broad third-party extensions ecosystem with more than 300 connectors available.",
          "score": -3,
          "created_utc": "2026-02-16 12:27:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5p7e22",
              "author": "Pancakeman123000",
              "text": "Fyi for anyone reading, this guy freaking loves SSIS - just look at his comment history. Whenever I see his name crop up here, I think- 'its the SSIS guy!' ðŸ˜…",
              "score": 4,
              "created_utc": "2026-02-16 15:47:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5q7y7s",
                  "author": "Nekobul",
                  "text": "Thank you for the positive vibes!",
                  "score": 0,
                  "created_utc": "2026-02-16 18:36:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5om3cx",
              "author": "reddit_time_waster",
              "text": "I personally agree SSIS is still good under the following conditions:\n1) You already have SQL Server for other reasons, so SSIS is \"free\"\n2) You follow the CI/CD devops practice with the catalog and something like Azure Devops\n3) Your scaling needs are limited. Most companies actually fit in this category and just need etl between some systems or exports of less than 1m rows.\n3a) You have scaling needs, and you have a team with a good Azure practice able to run SSIS packages in Azure Data Factory.",
              "score": 2,
              "created_utc": "2026-02-16 13:58:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5q7ttn",
                  "author": "Nekobul",
                  "text": "You can process more than 1m rows with SSIS. You can process hundreds of millions.",
                  "score": 3,
                  "created_utc": "2026-02-16 18:35:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r5p40y",
      "title": "Started a new DE job and a little overwhelmed with the amount of networking knowledge it requires",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r5p40y/started_a_new_de_job_and_a_little_overwhelmed/",
      "author": "starrorange",
      "created_utc": "2026-02-15 20:29:15",
      "score": 46,
      "num_comments": 47,
      "upvote_ratio": 0.91,
      "text": "Maybe I was naive to think it was mainly pipelining on top of a platform like azure or databricks but Iâ€™m in the middle of figuring out how to ping and turn on servers etc. Iâ€™m going to read up on Linux and some other recommended textbooks but just overwhelmed I guess. I did math in undergrad and did cs for my masters so I opted out of the networking classes thinking I would never need it. ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r5p40y/started_a_new_de_job_and_a_little_overwhelmed/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5l2r2z",
          "author": "masapadre",
          "text": "DE means a different thing in each company.\nI had to learn too a lot of networking for my current DE position. Vnets, peerings, private endpoints, dns resolution and so on but what my company calls data engineer to me is more like a software & platform engineer",
          "score": 47,
          "created_utc": "2026-02-15 22:27:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5lnlf7",
              "author": "IAMHideoKojimaAMA",
              "text": "So what data are you actually engineering ðŸ˜‚",
              "score": 6,
              "created_utc": "2026-02-16 00:28:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5oharx",
                  "author": "masapadre",
                  "text": "I extract data from text logs and then I save to MongoDB. We can call that ETL and I did a little bit of data modeling (how am I saving this to mongo, how are we going to query this data, and so on). Nothing fancy.\nI look forward to start doing things with Databrick, have a proper lakehouse, work with tables, that kind of thing. We have that in the roadmap",
                  "score": 4,
                  "created_utc": "2026-02-16 13:31:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5os6n2",
              "author": "king_booker",
              "text": "Any good resources for this? \n\n",
              "score": 1,
              "created_utc": "2026-02-16 14:30:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5pfbq7",
                  "author": "masapadre",
                  "text": "I followed â€˜Getting Started with Azure Networking Servicesâ€™ by Houssem Dellai. Recommended if you work with Azure.",
                  "score": 3,
                  "created_utc": "2026-02-16 16:24:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5kgjl9",
          "author": "UhhSamuel",
          "text": "Any entry into DE right now is a good opportunity, but in my 7.5 years as a DE I've never pinged or turned on a server.",
          "score": 97,
          "created_utc": "2026-02-15 20:33:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5l1aer",
              "author": "Mindless_Let1",
              "text": "You've never set up an ec2 instance or nothing? Wild",
              "score": 38,
              "created_utc": "2026-02-15 22:20:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ljphy",
                  "author": "Typical_Priority3319",
                  "text": "Just copy that one value with the command and paste it into the terminalâ€¦ no not that one the other one",
                  "score": 16,
                  "created_utc": "2026-02-16 00:05:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5oe300",
                  "author": "Inner-Block8845",
                  "text": "I think you can do that through Terraform or Cloud Functions so I am pretty sure all is programming and reading documentation and stakeholders requirements.",
                  "score": 2,
                  "created_utc": "2026-02-16 13:12:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5lt8ah",
              "author": "SalamanderPop",
              "text": "7.5 years and you've never done any infrastructure work? That's crazy in this day and age.",
              "score": 11,
              "created_utc": "2026-02-16 01:02:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5m0vor",
                  "author": "UhhSamuel",
                  "text": "I've done plenty of infra as code, if that helps. But networking is almost completely a black box to me. ",
                  "score": 6,
                  "created_utc": "2026-02-16 01:51:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5m6azb",
              "author": "No_Airline_8073",
              "text": "We own a Kubernetes cluster, minus the networking part",
              "score": 5,
              "created_utc": "2026-02-16 02:25:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5l68rs",
          "author": "DenselyRanked",
          "text": "Are you working with a cloud provider? If so, then refer to their training modules. If not, then take this as an opportunity to create a run book for your team.",
          "score": 11,
          "created_utc": "2026-02-15 22:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kgnjo",
          "author": "xean333",
          "text": "Hmm networking is usually out of scope for a data engineer. Sounds like youâ€™ve got yourself a fuzzy role my friend. Make the best of it. You studied math - networking isnâ€™t harder than abstract algebra or complex analysis. Good luck",
          "score": 33,
          "created_utc": "2026-02-15 20:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mylgu",
              "author": "Fit_Highway5925",
              "text": "If you're a data engineer who's focused mainly on platform engineering & infrastructure, then I don't think it's out of scope. You have to really know how networks work. \n\nThe thing about DE is that it's so broad and has many flavors that what one DE is doing may be totally different from another. \n\nI've experienced this firsthand. In my previous DE role, I did mostly ETL development and I never dealt with networks. Now I'm working mostly in data infra & platform engineering, and networks are suddenly everywhere. Good thing I have somewhat of a background from my college degree so it came in handy.",
              "score": 6,
              "created_utc": "2026-02-16 05:46:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5kkuqt",
              "author": "VEMODMASKINEN",
              "text": "Err, networking is never out of scope for anyone working in IT.Â \n\n\nIt's basically one of the few things everyone should know at least the basics of because whatever you do will involve transmitting data over networks.Â ",
              "score": 45,
              "created_utc": "2026-02-15 20:55:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5njn0g",
                  "author": "sib_n",
                  "text": "You can say this about a lot of things in IT. IT professions have a core and then depending on companies and projects you may explore different things: streaming, ML, CICD, frontend, security etc. It's common to have an infrastructure team that abstract networking for you so you can focus on the data instead, so it's normal to not have experience with it as a DE.",
                  "score": 7,
                  "created_utc": "2026-02-16 08:56:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5kqpir",
                  "author": "xean333",
                  "text": "I agree we should all know the basics of networking. I suspect OP is being held to higher expectations than day 1 networking. Maybe Iâ€™m wrong!",
                  "score": 6,
                  "created_utc": "2026-02-15 21:25:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5knjir",
                  "author": "Plus-Willingness-324",
                  "text": "This.",
                  "score": 9,
                  "created_utc": "2026-02-15 21:09:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5n7xxa",
                  "author": "zangler",
                  "text": "This",
                  "score": 1,
                  "created_utc": "2026-02-16 07:06:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5l5q0m",
                  "author": "Dry_Philosophy7927",
                  "text": "I'm a data scientist doing research and contemplating a future move to.... somewhere else. I'm scared for exactly this reason. Where/how should i plug my knowledge? Just a starter for 10 pls",
                  "score": 1,
                  "created_utc": "2026-02-15 22:44:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5l7edv",
              "author": "greenestgreen",
              "text": "what? Is very much involved. How would you set up a spark cluster if it was needed on premise?\nCollecting data from system in different networks, crossing firewalls, etc.",
              "score": 5,
              "created_utc": "2026-02-15 22:53:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5lkjqt",
                  "author": "xean333",
                  "text": "Iâ€™ve always had admin/infra guys that are responsible for setting me up with what I need",
                  "score": 9,
                  "created_utc": "2026-02-16 00:10:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5lcwsd",
                  "author": "BobBarkerIsTheKey",
                  "text": "I've only worked with spark in AWS glue jobs. I've set up small spark clusters at home with maybe 3 machines before but it would be incredibly easy to not know anything about it  because it's been abstracted away for me. ",
                  "score": 2,
                  "created_utc": "2026-02-15 23:24:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5kinvv",
              "author": "PhraatesIV",
              "text": "Some of the math guys I know would certainly disagree with your last sentence :)",
              "score": 1,
              "created_utc": "2026-02-15 20:44:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5l98g7",
          "author": "peterxsyd",
          "text": "Time to get the books out",
          "score": 3,
          "created_utc": "2026-02-15 23:03:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5letzx",
          "author": "Only-Succotash-8829",
          "text": "Having worked across all clouds, I've found Databricks and Azure to be one with the most convoluted networking, LZ architecture and RBAC setup.Â \n\n\nThat said, what kind of servers are you maintaining?Â \n\n\nTry to speak with your IT department as they may already have ownership of this. Often times theres duplication of effort happening in orgs and there may already be processes in place, just not readily triggered by the teams needing them - and instead we end up doing it ourselves as we feel capable enough, even at our own detriment long term.",
          "score": 2,
          "created_utc": "2026-02-15 23:36:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oajry",
          "author": "Ok-Sentence-8542",
          "text": "Well you skipped networking thats on you. It all comes back to basics but its pretty easy to learn all about networking on the internet. Just do it.",
          "score": 2,
          "created_utc": "2026-02-16 12:48:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5krrtw",
          "author": "reditandfirgetit",
          "text": "Ping as in check if it's up or ping as in the network pinging an IP address?\n\nAlso what exactly do you mean turn on a server? Do you mean setup/standup a server?",
          "score": 3,
          "created_utc": "2026-02-15 21:30:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kpxag",
          "author": "confusing-world",
          "text": "How many years of experience do you have?",
          "score": 2,
          "created_utc": "2026-02-15 21:21:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69gh1p",
          "author": "Certain_Leader9946",
          "text": "Every data engineer should know how to do networking, not just SQL plumbing. We call those analysts. How else do you deploy secure systems or handle questions about data governance? You don't need to be a full blown network engineer for this, but you have got to know the basics of subsetting and route tables.",
          "score": 1,
          "created_utc": "2026-02-19 16:14:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ks7j3",
          "author": "Mefsha5",
          "text": "Some networking is required at the DE level, enough to build and test connections and through-put, and knowing how to expose your systems to others.\n\nMostly, its about understanding the existing network design and working within them.",
          "score": 0,
          "created_utc": "2026-02-15 21:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5n877t",
          "author": "zangler",
          "text": "Some people need to understand that NOTHING you do matters without network... fucking learn some basics...like out of pure intellectual curiosity",
          "score": 0,
          "created_utc": "2026-02-16 07:09:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oal34",
              "author": "mcgrst",
              "text": "Yeah... I work in a very large Corp, I have people who set that up. A DE in my company wouldn't be allowed anywhere near networking, we're given APIs or database locations all the underlying stuff is managed for us.Â ",
              "score": 3,
              "created_utc": "2026-02-16 12:49:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5od6sq",
                  "author": "zangler",
                  "text": "All the more reason to understand it. It will help",
                  "score": -1,
                  "created_utc": "2026-02-16 13:06:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r3vgbd",
      "title": "How MinIO went from open source darling to cautionary tale",
      "subreddit": "dataengineering",
      "url": "https://news.reading.sh/2026/02/14/how-minio-went-from-open-source-darling-to-cautionary-tale/",
      "author": "jpcaparas",
      "created_utc": "2026-02-13 17:31:12",
      "score": 45,
      "num_comments": 4,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r3vgbd/how_minio_went_from_open_source_darling_to/",
      "domain": "news.reading.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o58hbde",
          "author": "VEMODMASKINEN",
          "text": "Replaced it with Garage in my homelab. Was easy to setup in my K8s cluster and I haven't really had any issues one month in so far.\n\n\nhttps://garagehq.deuxfleurs.fr/",
          "score": 12,
          "created_utc": "2026-02-13 21:27:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59jas6",
              "author": "PencilBoy99",
              "text": "does garage let you create/setup s3 storage on an on premises box? that's what minio did think ",
              "score": 3,
              "created_utc": "2026-02-14 00:58:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5boktq",
              "author": "current_thread",
              "text": "I've been using Rook/Ceph for the last year and had no issues whatsoever.",
              "score": 1,
              "created_utc": "2026-02-14 11:24:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b4i20",
          "author": "every_other_freackle",
          "text": "We migrated to SeaweedFS and it is perfect!",
          "score": 5,
          "created_utc": "2026-02-14 08:08:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5xqqt",
      "title": "How often do you make webhooks and APIs as a data engineer?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r5xqqt/how_often_do_you_make_webhooks_and_apis_as_a_data/",
      "author": "ketopraktanjungduren",
      "created_utc": "2026-02-16 02:43:09",
      "score": 43,
      "num_comments": 31,
      "upvote_ratio": 0.96,
      "text": "Hey,\n\nI work primarily with dbt and Snowflake but now have to wrestle with Flask (and possibly Django) which makes my life a lot harder (as for now)\n\nWe use a CRM that can integrate with WhatsApp Business but we can only get the historical chat data with webhooks. The platform requires us to have a webhook URL(s) to receive a set of data so I look for a free webhook URL service.\n\nThe next step is to make endpoints and automate all of these. I realize that I need some kind of an app and fortunately Python has Flask and Django. So build one to satisfy my user (automate lead collection etc).\n\nBut the concepts involved in building the app is rather unfamiliar to me: tunneling, TCP, content-type, etc I rarely heard any of them. I suspect they are not common in data engineering work thus the app I build is not DE at all; this seems to be the work for backend engineers.\n\nHow often do you make webhook at work? Is it true that this work is for backend engineer?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r5xqqt/how_often_do_you_make_webhooks_and_apis_as_a_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5mbwpp",
          "author": "redditreader2020",
          "text": "A well rounded data engineer is a software engineer that likes working with data.\n\nLearn all you can about backend software engineering.",
          "score": 93,
          "created_utc": "2026-02-16 03:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mh4c5",
              "author": "ketopraktanjungduren",
              "text": "I'm learning backend engineering btw. Do you think BE with focus on Python is good or should I try Typescript/Go?",
              "score": 5,
              "created_utc": "2026-02-16 03:37:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5mi0s5",
                  "author": "redditreader2020",
                  "text": "Python is fine. Just learning the concept is key, after more experience switching languages is easy.",
                  "score": 10,
                  "created_utc": "2026-02-16 03:43:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5nbf8j",
                  "author": "Online_Matter",
                  "text": "Python is fine for small backends. I find it's lack of first-class type safety becomes an issue as the code becomes more complex.\n\n\nGo is quite a nice language but still a bit niche (at least in my area). I'd also take a look at C# which has really nice frameworks for APIs.Â ",
                  "score": 3,
                  "created_utc": "2026-02-16 07:38:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5mo7py",
                  "author": "bass_bungalow",
                  "text": "Python works. If youâ€™ve never worked with a compiled language, it might be worth learning some basic go/c++/rust/java but definitely not required",
                  "score": 1,
                  "created_utc": "2026-02-16 04:26:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5myhrk",
                  "author": "Shadilan",
                  "text": "Typescript is not good choice for de imho. Go is better but have questions too. Python, Java/Scala/Kotlin more familiar to data world. And Rust for high load may be.",
                  "score": 1,
                  "created_utc": "2026-02-16 05:45:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5mcfky",
          "author": "calimovetips",
          "text": "pretty common if your team owns ingestion, but usually itâ€™s â€œbuild a thin receiverâ€ and hand off to the warehouse, not a full backend app. if you just need to catch webhooks, a tiny flask endpoint plus queue or object storage is enough, you donâ€™t need to learn django for that. it can be DE work, but if it grows into auth, retries, complex business logic, and uptime guarantees, thatâ€™s when backend usually takes it. how much volume are you expecting and do they require a public https endpoint with signature verification?",
          "score": 10,
          "created_utc": "2026-02-16 03:05:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mi37q",
              "author": "ketopraktanjungduren",
              "text": "It's tiny but I have to figure out how to secure the connection. I'm trying url token parameter ('?token=...') then compare it with the SECRET variable but the platform sometimes posts without token so I have to find other ways to authenticate the connection.\n\n\nThe volume is maybe around 3-5 posts per hour, and yes I think it requires signature verification. Could you please give me advice to this problem?",
              "score": 1,
              "created_utc": "2026-02-16 03:43:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5mvi6k",
                  "author": "Odhdbdyebsksbx",
                  "text": "Commenting because I also want to know what's a good solution for this.",
                  "score": 1,
                  "created_utc": "2026-02-16 05:21:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5mce08",
          "author": "MonochromeDinosaur",
          "text": "This is why people always say data engineering is a specialization of software engineering. \n\nYou need skills from backend, frontend, devops, data analysis, MLE/data science to be well rounded. Even systems might be helpful depending on your performance requirements.\n\nI did web development, data analysis, and data science/MLE before becoming a data engineer so I am familiar with all these concepts and every team Iâ€™ve worked on has been a software engineering first team. Everyone is expert at SQL but can just as easily switch to writing application code.",
          "score": 14,
          "created_utc": "2026-02-16 03:05:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mj83u",
              "author": "ketopraktanjungduren",
              "text": "Yeah, I can grasp what you said. I learnt the ML requires a lot of SWE skills other than statistics and ML\n\n\nThanks for reminding me",
              "score": 3,
              "created_utc": "2026-02-16 03:51:37",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o60qhiu",
              "author": "TodayEasy949",
              "text": "How was your transition from frontend to data analysis? Was it an internal shift or you upskilled in that domain and changed the org?",
              "score": 1,
              "created_utc": "2026-02-18 08:28:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5maxto",
          "author": "SmallAd3697",
          "text": "do data engineers ever think of themselves as software developers?  it is a pet peeve when data engineers limit themselves to learning to use/ configure someone's software, and they aren't able to write any code themselves.\n\nweb api's are about as simple as it gets when it comes to software development.  the only thing that may be simpler is writing a hello world console app.  challenge yourself.",
          "score": 10,
          "created_utc": "2026-02-16 02:55:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mgur5",
              "author": "drunkenboy_",
              "text": "90% of people here forgets that Data Engineering is just Software Engineering applied to data.\n\nit makes sense when you see that most is used to work with already built tools, such as dbt and such.\n\nthat's why we also see that huge gap in infrastructure and architecture knowledge in many posts on this forum.",
              "score": 11,
              "created_utc": "2026-02-16 03:35:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5n8iv4",
              "author": "IAMHideoKojimaAMA",
              "text": "I dont seem myself as a swe as I also work a lot with business units. there's only so much I can do",
              "score": -1,
              "created_utc": "2026-02-16 07:12:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5mg24z",
              "author": "ketopraktanjungduren",
              "text": "Thanks a lot!",
              "score": 0,
              "created_utc": "2026-02-16 03:29:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ml1kk",
          "author": "JohnPaulDavyJones",
          "text": "APIs? Couple of times in the last few years, but I bet dollars to donuts that Iâ€™m the only one on my current team who has done that.\n\nWebhooks? Literally never.",
          "score": 2,
          "created_utc": "2026-02-16 04:04:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mxcm9",
          "author": "empireofadhd",
          "text": "Itâ€™s great for utility and monitoring. Like cicd and other forms of â€glue codeâ€. It can also be a consumption interface thatâ€™s more suitable then direct database access etc.",
          "score": 1,
          "created_utc": "2026-02-16 05:36:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mywgy",
          "author": "Shadilan",
          "text": "You can use apache nifi as less code tool, but it's rather heavy. But you can make http endpoint with no code in it.",
          "score": 1,
          "created_utc": "2026-02-16 05:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nyd7e",
          "author": "Bananaramaaaaa",
          "text": "I would say it depends a bit on the scale of data, how often you work with these. But agree with the other posters that this can be expected as it is fairly basic software engineering.\n\nAnd if you really only need a webhook endpoint to process some data, maybe AWS Lamda could be a good fit.\n\nAmd otherwise I'd always say FastAPI over Flask nowadays, it is just the cleaner, more modern version of it. If you use Django, you get user management and a nice ORM, but boilerplate or async processing can become headaches.",
          "score": 1,
          "created_utc": "2026-02-16 11:13:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5omyhv",
          "author": "drag8800",
          "text": "yeah this comes up a lot. the line between DE and backend is fuzzy and honestly depends more on the team structure than any official boundary. i work primarily with snowflake and dbt too and ended up building internal APIs a few times when nobody else was going to do it.\n\nthe tcp/tunneling stuff you're mentioning is real. webhooks touch networking concepts that don't come up much when you're writing sql all day. but it's learnable, and honestly flask is pretty minimal once you get past the initial wtf of understanding how routes work.\n\nthe bigger question is whether this should be your problem at all. if this is a one-off integration that marketing needs yesterday, sometimes you just build the thing. if you're going to be maintaining multiple webhooks indefinitely, that's closer to a backend service and someone should probably be thinking about ownership and on-call.\n\nfor the immediate problem you could look at something like ngrok for local testing instead of figuring out tunneling yourself. makes the development loop way less painful when you're trying to debug what the webhook is actually sending you.",
          "score": 1,
          "created_utc": "2026-02-16 14:03:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5p4lm8",
          "author": "Oxford89",
          "text": "If you really want to make this is easy and you have a budget for tools, you could use Zapier to catch and route the hooks.",
          "score": 1,
          "created_utc": "2026-02-16 15:34:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r05m1",
          "author": "Glass-Tomorrow-2442",
          "text": "A server with flask or Django app launched with docker and deployed with ansible. Everything is code and a joy to use.Â ",
          "score": 1,
          "created_utc": "2026-02-16 20:52:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v41c9",
          "author": "Idiot_LevMyskin",
          "text": "FastAPI is comparatively easier than Flask or Django for APIs. Most of our analytical models are deployed as an API using FastAPI. For a DE, a good understanding of API and basic knowledge of web frameworks are a must. It really helps when your source is an API or when you have the requirements to do web scraping.",
          "score": 1,
          "created_utc": "2026-02-17 13:40:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mwlui",
          "author": "Thinker_Assignment",
          "text": "We basically see 2 camps\n- g cloud function/aws gateway+lambda webhook\n- self hosted app (less scalable more management slightly cheaper)",
          "score": 1,
          "created_utc": "2026-02-16 05:30:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5miaac",
          "author": "Sweaty_Cartoonist703",
          "text": "If even flask makes your life harder, i think its time to look into another profession.",
          "score": -8,
          "created_utc": "2026-02-16 03:45:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mike1",
              "author": "ketopraktanjungduren",
              "text": "It's hard because I'm not familiar with the concept\n\n\nWhat makes you think it's a good profession for you?",
              "score": 1,
              "created_utc": "2026-02-16 03:47:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5n4y1k",
                  "author": "ALonelyPlatypus",
                  "text": "Yep. I'm a DE who maintains a flask web app fairly regularly but it's definitely not my favourite code style and I just kind of hack stuff into it.",
                  "score": 1,
                  "created_utc": "2026-02-16 06:40:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r4kugz",
      "title": "â€œWhat are the best resources to learn Docker from scratch?â€",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r4kugz/what_are_the_best_resources_to_learn_docker_from/",
      "author": "Effective_Bluebird19",
      "created_utc": "2026-02-14 13:38:31",
      "score": 42,
      "num_comments": 20,
      "upvote_ratio": 0.94,
      "text": "Iâ€™m a Data Engineer with around 2 years of experience and Iâ€™m trying to properly learn Docker so I can use it in real-world data pipelines.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r4kugz/what_are_the_best_resources_to_learn_docker_from/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5c5ttz",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-14 13:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cfnfb",
          "author": "ThroughTheWire",
          "text": "learning docker from scratch is pretty pointless imo. learn what you need to know as you have to deal with it. in practice for most data engineers this would be running your own airflow instance locally or perhaps running a tool like Airbyte locally. both situations have tutorials that you can follow along that will essentially teach you how docker is working with a practical use case in mind. I wouldn't waste time learning how docker otherwise works.",
          "score": 31,
          "created_utc": "2026-02-14 14:37:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e5xds",
              "author": "VEMODMASKINEN",
              "text": "It's hardly a waste knowing how container internals work with namespaces and cgroups along with security and modern building best practices... We're Data *Engineers* after all.Â \n\n\nAnyone can follow a tutorial that spells out how to set something up, it won't teach you much about the tool itself though...\nÂ \n\nAnyways, here OP:\n\n\nhttps://courses.mooc.fi/org/uh-cs/courses/devops-with-docker\n\n\nAnd:\n\n\nhttps://m.youtube.com/watch?v=Utf-A4rODH8",
              "score": 12,
              "created_utc": "2026-02-14 19:57:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5dqi71",
          "author": "Cloudskipper92",
          "text": "Since you (and a couple others) seem to be more or less asking for some structure to learn against, here's what I use or have used in my day-to-day.\n\n- How to install docker, and the follow-ups needed, on your Distro/OS. Windows/Mac are pretty straight-forward. Linux has some steps after install that you need to do.\n\n- Get used to navigating dockerhub, finding official image builds, and how to pull specific versions. Much like Python version pinning, you _certainly_ want to pin versions of infra.\n\n- Read the docs on the most important docker cli commands. Non-exhaustive: `docker build`, `docker run`, `docker pull`, `docker exec`, `docker container cp`.\n\n- Learn and practice making [Dockerfiles](https://docs.docker.com/reference/dockerfile/). Learn the subtle differences between `ADD` and `COPY`. How Layering works. Learn the differences between `CMD` and `ENTRYPOINT`, `ARG` and `ENV`. Learn how to expose a port on a container to the host. HINT: it isn't with the `EXPOSE` instruction and if you made it this far without being able to ping your container from your host you should go back one step ;) . Make a `.dockerignore` so you don't put anything you don't want in the container. You can ignore these instructions for now: `HEALTHCHECK`, `LABEL`, `MAINTAINER`, `ONBUILD`, `SHELL`, `STOPSIGNAL`.\n\n- Learn how networking works for Docker. Networking generally is a weak point for most SWEs, and seems to often be doubly so for DEs. In the same vein, read the docs on how Docker Volumes work and how to attach them.\n\nNow, you came to the DE Subreddit to ask this and mention you have 2 YOE already, so I'm going to also mention a couple of more specific things.\n\n1. [Running Airflow in Docker](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html) is D E N S E but obfuscated heavily. As in, it has a lot of levers and knobs, but it mostly assumes the defaults are good enough for this. It also assumes you know docker-compose which I _did_ leave out of the top. The justification I'll give for that is that Docker Compose is great... but you should be using the dockerized airflow mentioned here as a TESTING system ONLY. Thus, get it going following thier instructions, do what you need to do, but don't assume it matches production-grade Airflow deployments.\n\n2. You could (and perhaps should) use [Astronomer's CLI](https://www.astronomer.io/docs/astro/cli/overview). I don't work for them or anything, but I have used their managed service in the past. The fact that the CLI exists for free is great and should be taken advantage of for local testing.\n\n3. Now that you've seen those two and understand how docker works and have played with the ins and outs, contrary to what others may say, I would then _AND ONLY THEN_ look into Kubernetes. No matter the system, managed or self-hosted, Airflow and it's pipelines ALWAYS run on Kubernetes behind the scenes. The way you build the image for [Airflow will change](https://gist.github.com/wesh92/4ce0634e61949a1679e2ae5a1788cb18) and, thus, how you manage dependancies and the way you need to understand how Kubernetes sees Containers versus how you've seen them thus far at this point. I cannot stress this enough though, DO NOT jump straight to this point. Everything above here should be _weeks_ of testing, toiling, and troubleshooting at a minimum before you try to introduce K8s. When you do, start with a local manager like `k3s`. I would recommend not using `minikube` or `kind` as those are \"k8s in docker\" which is a whole extra layer you don't need. The justification I'll give for including this: I like my local testing env for pipelines to be as close, if not exact, to what I will deploy. For me this means _in kubernetes using exactly what I will deploy_ with as much of the kubernetes weirdness as I can account for. If this doesn't feel important to you, please feel free to ignore!\n\nHope this helps! But please, just start with the Docker basics. You can search up a youtube if your more visually-inclined. Read through the docs and try implementing things if you're more of the experiential kind. Nothing is going to be a cheat code because these are kind of foundational tools for SWE and DE.\n\nEDIT: formatting. reddit pls",
          "score": 5,
          "created_utc": "2026-02-14 18:37:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f7qct",
              "author": "wetnmoist",
              "text": "I learned how to use it for a home server / networking. \n\nImo youâ€™re on point - the only thing Iâ€™d add is finding a project where itâ€™s actually necessary to use it rather than playing around with everything it can do.",
              "score": 2,
              "created_utc": "2026-02-14 23:29:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5c77q2",
          "author": "Outside-Storage-1523",
          "text": "I think finding a use case in your personal project is useful.",
          "score": 12,
          "created_utc": "2026-02-14 13:47:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cj7g0",
          "author": "gn-musa",
          "text": "Ship one thing,not tutorials.",
          "score": 3,
          "created_utc": "2026-02-14 14:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5caa8q",
          "author": "Prestigious_Radio582",
          "text": "+1 I also want to learn docker from a structured resource.",
          "score": 3,
          "created_utc": "2026-02-14 14:05:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5choaf",
          "author": "xean333",
          "text": "What do you mean learn it from scratch? Are you just saying you donâ€™t currently know anything about docker? Start with a super high level overview of the problem(s) docker solves. Then run airflow locally with it. Start now and youâ€™ll be done by the afternoon. If you want to learn it deeper, this is probably the wrong sub to ask",
          "score": 2,
          "created_utc": "2026-02-14 14:49:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d25t0",
          "author": "meiousei2",
          "text": "All you need to understand is how containerized networking works and basic syntax to be able to audit AI generated Dockerfiles, they're not that complex",
          "score": 1,
          "created_utc": "2026-02-14 16:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dti1w",
          "author": "ludflu",
          "text": "If you want to make it specific to data engineering: \n\n1. run airflow using `docker compose` to get a sense for docker. (https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)\n2. Then create a DAG that does its work by running a docker image using the DockerOperator\n3. In production, its very similar, but you'll likely run your DAG task in ECS on AWS or Cloud Run on GCP",
          "score": 1,
          "created_utc": "2026-02-14 18:52:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5duvjt",
          "author": "dumb_user_404",
          "text": "there is a course on docker by javascript mastery, its a pretty new course and will teach you about docker from basics up. \n\nWatch half of that video and then move on to video teaching you about running your own airflow or spark or what ever you need. \n\nwith the foundational knowledge from the first video, everything will fall in place. \n\nyoutube : [https://youtu.be/GFgJkfScVNU?si=8jdbZsjlI4axyuzg](https://youtu.be/GFgJkfScVNU?si=8jdbZsjlI4axyuzg)\n\n",
          "score": 1,
          "created_utc": "2026-02-14 18:59:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ekxzk",
          "author": "JBalloonist",
          "text": "I'm just good enough to be dangerous with Docker, and frankly that was all I needed. I was using it to create containers running in AWS ECS (Elastic Container Service) and Lambda. If I ran into trouble enough searching or AI questions would usually give me the answer. Occasionally I'd reach out to a coworker who had more experience with builds (but not much Python experience). ",
          "score": 1,
          "created_utc": "2026-02-14 21:19:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ey0va",
          "author": "Dawido090",
          "text": "Book \"Learn Docker in a Month of Lunches\" it's great as whole series, its bit outdated but it's great.",
          "score": 1,
          "created_utc": "2026-02-14 22:31:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gqrk4",
          "author": "tbot888",
          "text": "YouTube and A.I. when you need to solve a problem.\n\nReview it.\n\nAsk someone else to have a look at it too.\n\nHow Iâ€™m learning most of my stuff now.\n\nAnd the blog /youtube/stackechange etc back to the world about it.\n\nI mean thatâ€™s what computer science is all about. Â Helping a brother out working on each others stuff.\n\nThen hiring each other.",
          "score": 1,
          "created_utc": "2026-02-15 05:52:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cvd92",
          "author": "DoomsdayMcDoom",
          "text": "Better off learning K8/Kubernettes since thatâ€™s whatâ€™s replacing docker in every company with a hybrid or cloud infrastructure.",
          "score": -3,
          "created_utc": "2026-02-14 16:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dao2a",
              "author": "Black_Magic100",
              "text": "Kubernetes does not replace Docker. \n\nRecommending somebody jump straight to orchestration when they want to learn containerization is also a crazy idea.",
              "score": 8,
              "created_utc": "2026-02-14 17:19:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5eesh4",
                  "author": "DoomsdayMcDoom",
                  "text": "Docker never kept up and unfortunately thatâ€™s their fault.  It could of been a better platform but technology advanced and they stayed stagnant.\n\ncontainerd is what Docker uses under the hood to manage containers. Kubernetes was like, â€œwhy not just talk to that directly?â€",
                  "score": 0,
                  "created_utc": "2026-02-14 20:45:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r49mr4",
      "title": "Is my ETL project at work using Python + SQL well designed? Or am I just being nitpicky",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r49mr4/is_my_etl_project_at_work_using_python_sql_well/",
      "author": "masterhoovy",
      "created_utc": "2026-02-14 03:15:59",
      "score": 38,
      "num_comments": 30,
      "upvote_ratio": 0.84,
      "text": "Hey all,\n\nI'm a fairly new software engineer who's graduated school recently. I have about \\~2.5YOE including internships and a year at my current job. I've been working on an ETL project at work that involves moving data from one platform via an API to a SQL database using Python. I work on this project with a senior dev with 10+YOE.\n\nA lot of my work on this project feels like I'm reinventing the wheel. My senior dev strives for minimizing dependencies to not be tied to any package which makes sense to some extent, but we are only really using a standard API library and pyodbc. I don't really deal with any business logic and have been basically recreating an ORM from the ground up. And at times I feel like I'm writing C code, like checking for return codes and validating errors at the start of every single method and not utilizing exceptions. \n\nI don't mean to knock this senior dev in any way, he has a ton of experience and I have learned a lot about writing clean code, but there are some things that throw me off from what I read online about Python best practices. From what I read, it seems like SQLAlchemy, Pydantic, and Prefect are popular frameworks for creating ETL solutions in Python. \n\nFrom experienced Python developers: is this approach â€” sticking to vanilla Python, minimizing dependencies, and using very defensive coding patterns â€” considered reasonable for ETL work? Or would adopting some standard frameworks be more typical in professional projects?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r49mr4/is_my_etl_project_at_work_using_python_sql_well/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5a5utd",
          "author": "reditandfirgetit",
          "text": "Rewriting things that are already written is insane. The packages exist, and the ones you'll need are well maintained. It also becomes a maintenance nightmare. I suspect the sr dev does this for some kind of idiotic job security",
          "score": 79,
          "created_utc": "2026-02-14 03:23:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5btu3u",
              "author": "SoggyGrayDuck",
              "text": "I've made this mistake. Shit like that is miserable",
              "score": 8,
              "created_utc": "2026-02-14 12:10:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5a62cy",
              "author": "masterhoovy",
              "text": "I get the impression he's concerned with performance and wants a small footprint. It seems he has a strong background in low-level and C programming. But yeah it's fairly strange to me",
              "score": 8,
              "created_utc": "2026-02-14 03:25:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5au524",
                  "author": "VipeholmsCola",
                  "text": "he should write in c++ then or rust. Python way is to use whatever tools you need to ship stuff.",
                  "score": 30,
                  "created_utc": "2026-02-14 06:32:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5btkju",
                  "author": "reditandfirgetit",
                  "text": "Then you find a package and run a timing test, you don't assume you can write cleaner more optimal code. That's not a senior mentality.\n\nIf the package is way slower than you want you can roll your own or get into the package code and optimize there.",
                  "score": 10,
                  "created_utc": "2026-02-14 12:08:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5e5fbz",
                  "author": "runawayasfastasucan",
                  "text": "Doesn't matter, he wont make it more performant.",
                  "score": 1,
                  "created_utc": "2026-02-14 19:54:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5a5iem",
          "author": "Peppper",
          "text": "Yeah, seems like a bad idea. Whatâ€™s the value add for not using libraries. Are SQLAlchemy or Polars going away anytime soon? Better value add work would be to concentrate resources on delivering analytics and data products.",
          "score": 15,
          "created_utc": "2026-02-14 03:21:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ae6ng",
              "author": "Thadrea",
              "text": "Using off the shelf libraries, yes, no good reason not to.\n\nThere is definite value to avoiding unnecessary internal dependencies on stuff managed by other teams if the application is business or mission critical.",
              "score": 8,
              "created_utc": "2026-02-14 04:22:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5af4hx",
                  "author": "Peppper",
                  "text": "Totally fair. Itâ€™s definitely a balance, but seems like OPâ€™s dev is too dogmatic.",
                  "score": 2,
                  "created_utc": "2026-02-14 04:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5abq3d",
          "author": "cmcclu5",
          "text": "Iâ€™ve done it. Youâ€™ll learn a lot of excellent Python mechanics, but youâ€™re taking the first step to the next level by being aware of other packages that can take the place of your â€œlow-levelâ€ work. SQLAlchemy has limitations, so a lot of groups default back to pyodbc or psycopg2 anyway. Polars is excellent, but still locks you into a core set of functions (pandas is even worse). Sometimes, itâ€™s best to start at the standard library, depending on your use case. Your senior is giving you a ton of experience a lot of seniors Iâ€™ve met donâ€™t have. Just be aware that it wonâ€™t always be applicable.",
          "score": 6,
          "created_utc": "2026-02-14 04:04:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b4ofe",
          "author": "drag8800",
          "text": "Both approaches have their place but the context matters a lot. I've built ETL pipelines both ways over 12+ years.\n\nMinimizing dependencies makes sense when you're building something simple and stable that won't need much maintenance. We had a batch job that ran for 8 years with zero external packages beyond requests and psycopg2. Worked great.\n\nBut rebuilding ORM patterns from scratch is different from just not using one. If you're writing your own query builders, connection pooling, retry logic, and type coercion, you're now maintaining all that code forever. Every bug fix, edge case, and security patch is on you. SQLAlchemy has had hundreds of contributors finding problems you'll never think of.\n\nThe return code pattern concerns me more than the dependency choice honestly. Python's exception model exists for a reason and fighting it creates code that's harder to read and debug. If your senior prefers explicit error handling, that's fine, but there are Pythonic ways to do it without making every function look like C.\n\nThe real question is what's the maintenance horizon here. If this is a one time data migration that runs and gets archived, vanilla Python is fine. If this is production infrastructure your team will maintain for years, the cost of rolling your own ORM will compound. Every new team member has to learn your custom patterns instead of reaching for documentation.\n\nWorth having a direct conversation about it. Ask what specific concern drives the no dependencies stance. Sometimes it's a bad experience with a package breaking, which is valid but solvable with pinned versions and testing.",
          "score": 9,
          "created_utc": "2026-02-14 08:10:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cydbo",
              "author": "masterhoovy",
              "text": ">The return code pattern concerns me more than the dependency choice honestly. Python's exception model exists for a reason and fighting it creates code that's harder to read and debug. If your senior prefers explicit error handling, that's fine, but there are Pythonic ways to do it without making every function look like C.\n\nYeah I'm still trying to wrap my head around using return codes in Python. Could you provide some examples of how this can be done in a pythonic way? I feel like it would be way easier to just log exceptions but he is pretty adamantly opposed to exceptions and stack traces and would rather log all our messages manually.",
              "score": 1,
              "created_utc": "2026-02-14 16:17:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5g440c",
                  "author": "drag8800",
                  "text": "Few patterns that work without going full C:\n\nSimple tuple returns:\n```python\ndef fetch_user(id):\n    if not id:\n        return None, \"missing id\"\n    user = db.get(id)\n    if not user:\n        return None, \"not found\"\n    return user, None\n\nuser, err = fetch_user(123)\nif err:\n    logger.error(err)\n    return\n```\n\nDataclass Result type:\n```python\n@dataclass\nclass Result:\n    value: Any = None\n    error: str = None\n    \n    @property\n    def ok(self):\n        return self.error is None\n```\n\nThen your code reads `if not result.ok: handle_error()` which is cleaner than tuple unpacking everywhere.\n\nThe `returns` library does this more formally if you want railway-oriented programming, but that might be overkill for ETL.\n\nHonestly though - the real question is why stack traces are the enemy. They're the single best debugging tool when something breaks in prod. Manual logging means you're recreating what the runtime gives you for free, except worse. Might be worth understanding what burned him before. Sometimes it's \"stack traces leaked to users\" which is a presentation problem, not an exception problem.",
                  "score": 2,
                  "created_utc": "2026-02-15 02:59:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5a80sj",
          "author": "Treemosher",
          "text": "I wish I had a senior dev to work under.  I basically did what you're doing but flying solo.  Had to teach myself everything.  It was pretty rough.\n\nI doubt any of this will be useful, all I really have is color commentary here.\n\nI did use SQLAlchemy.  I had nobody telling me no, I just communicated to IT what I was doing and got their blessing in email to cover my ass.\n\nAside from that, I think I was also pretty strict about choosing libraries.  I try to stick to stuff that's in the Anaconda suite since it seems to get a buttload of community and support.\n\nIf a vendor has their own libraries that they actively maintain, I'll use those.  \n\nIf it's a real niche thing by some dude and I can't find a way to feel good about it, hell no.  I've never had anything bad happen, but it only takes one time.  \n\nI don't think my situation is a very good comparison.  Nobody was really supporting me or looking at my work.  I just packaged code where I could reference a config file like a control table.  Send queries, save them as flat files, do the things like package them into this or that or upload them here or there.\n\nI was never given the greenlight for an actual database, but it got us by in the interim as we grew.  \n\nAgain, my situation was very specific with weird constraints.\n\nIf your senior dev dude is having you basically write your own stuff instead of using a library, take that is a chance to reverse engineer a process that many might take for granted.  A few years from now you'll be that much more versed in things I guess?  \n\nLike, I had nobody to review my code.  If anyone had to go back and look at it, it was me.  So that forced me to write in a way that didn't force me to curse my own name.  What feels like a setback can sometimes make you stronger in the end.",
          "score": 7,
          "created_utc": "2026-02-14 03:38:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bczyd",
          "author": "Outside-Storage-1523",
          "text": "My understanding is that you pull data from API to a DB so most likely you donâ€™t need to do much, if any SQL transformation. Maybe SQLAlchemy is a bit overkill? Do you insert the rows one by one? I think as long as you can insert them in batch that should be fine.",
          "score": 3,
          "created_utc": "2026-02-14 09:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ago78",
          "author": "calimovetips",
          "text": "keeping deps light is fine for simple pipelines, but rebuilding orm logic and avoiding exceptions is usually unnecessary overhead.\n\niâ€™d ask what real constraint justifies it, long term maintainability usually favors proven libraries.",
          "score": 2,
          "created_utc": "2026-02-14 04:41:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bbd32",
          "author": "Sensitive-Sugar-3894",
          "text": "Detach your SQL from the code. I don't use ORMs for ETL. System Engineering, maybe. Data Engineering, no.\n\nAre you using Windows for the DB? Why?",
          "score": 2,
          "created_utc": "2026-02-14 09:15:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68to9t",
          "author": "CiaraF135",
          "text": "You aren't being nitpicky. Rebuilding an ORM from scratch in 2026 is exactly the kind of 'resume-driven development' that becomes a maintenance nightmare the moment that senior dev leaves.  \n  \nThe bigger question is: why are you writing custom Python for standard API-to-SQL ingestion at all? Unless the API is incredibly niche or the transformation logic is wild, this is usually a solved problem.  \n  \nMost teams moved away from writing custom extractors (whether with SQLAlchemy or vanilla Python) because maintaining them when APIs change is a full-time job. We use Fivetran for the 'boring' API ingestion part so we don't have to debate ORM patterns, we just get the data in the warehouse and do the fun logic there.",
          "score": 2,
          "created_utc": "2026-02-19 14:18:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bhdo9",
          "author": "LookAtTheHat",
          "text": "Is there any company regulations stating you cannot use 3rd party libraries unless they have been approved?",
          "score": 1,
          "created_utc": "2026-02-14 10:15:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5btok5",
          "author": "AcanthisittaEarly983",
          "text": "To maintain or not to maintain.Â ",
          "score": 1,
          "created_utc": "2026-02-14 12:09:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5caypy",
          "author": "PeterDowdy",
          "text": "You should probably not homebrew these tools if at all possible. Have you considered a framework like dbt?",
          "score": 1,
          "created_utc": "2026-02-14 14:10:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f2v9b",
          "author": "prehensilemullet",
          "text": "I donâ€™t know that much about python orms, but how good are they at doing bulk inserts with associations efficiently? Â Because Iâ€™ve seen Typescript orms do bulk inserts in Postgres in really sub-par ways compared to the queries i can write by hand",
          "score": 1,
          "created_utc": "2026-02-14 22:59:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g4pty",
          "author": "WhiteWillow132",
          "text": "The only reason you do what this dev is doing is for security concerns or because he wants the installed package to be size constrained, likely due to where itâ€™s being deployed. Otherwise itâ€™s pointless. \n\nPulling data from an API is also to obscure of a comment. Is it batch, transactional, is there latency, is it paginated? Too many unknowns for anyone here to give you real advice.",
          "score": 1,
          "created_utc": "2026-02-15 03:03:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gkbjo",
          "author": "FORCEUPDATEALL",
          "text": "You are leaving a lot of context unclear. How big is your company and what is the data volume? Any data confidentiality? How important is data quality (this might justify expanding the work on the return codes). \n\nIâ€™ve been doing ETL, data integrations, and API extractions for a while now, and one thing thatâ€™s universally true is this: APIs are not designed to be persistent or cheap. You want to hit them as few times as possible, and you want to do it quickly and predictably. That alone can justify a more defensive, dependencyâ€‘light approach depending on the environment. What i am saying is you generally donâ€™t want your transform step or load step to depend on live API calls. Itâ€™s better to extract once, stage the raw data, and transform or load from the staged files.",
          "score": 1,
          "created_utc": "2026-02-15 04:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h0bug",
          "author": "acana95",
          "text": "Your senior is making up work so both of you wont be fired haha. Cleaning tech debts is only worth doing whenever it they slow down the data products otherwise as long as they meet sla and dont have critical bugs or security issues, its better for you to learn new tech or work on developing pipelines for business cases. In the end, a best pipeline isnt the best pipeline for a business if it is not generating money",
          "score": 1,
          "created_utc": "2026-02-15 07:19:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lbi7c",
          "author": "Certain_Leader9946",
          "text": "No he's not insane but doing this in a language like python is orthogonal to the reason why it exists. If you're doing that at least use Go and SQLC. Which is broadly what all my stuff (Databricks included) is based on.",
          "score": 1,
          "created_utc": "2026-02-15 23:16:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c5mxq",
          "author": "Nekobul",
          "text": "If you are using SQL Server, it is crazy not to take advantage of the SSIS and the available third-party extensions. You will save tons of time and have a more stable solution.",
          "score": 1,
          "created_utc": "2026-02-14 13:37:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hqk2i",
              "author": "NoleMercy05",
              "text": "While true, this crowd doesn't want to hear it.",
              "score": 2,
              "created_utc": "2026-02-15 11:31:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b5pt7",
          "author": "i_make_maps_0",
          "text": "Getting requirements, reading API docs and usage rules, setting up python process (25 lines max) with exception-handling, logging, monitoring, alerting, and auto-restart-on-death, creating indexed raw/staging tables, should take no more than 10-20 minutes. Will you be onboarding dozens of disparate sources API/scraping? Or is this a one-off for which you need data refreshed constantly for the one source?",
          "score": 0,
          "created_utc": "2026-02-14 08:20:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7855s",
      "title": "DuckLake data lakehouse on Hetzner for under â‚¬10/month.",
      "subreddit": "dataengineering",
      "url": "https://github.com/berndsen-io/ducklake-hetzner",
      "author": "MeepsByDre",
      "created_utc": "2026-02-17 14:55:33",
      "score": 35,
      "num_comments": 1,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Open Source",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r7855s/ducklake_data_lakehouse_on_hetzner_for_under/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o67smwu",
          "author": "Upper-Team",
          "text": "Nice, this is exactly the kind of thing people keep asking about in r/dataengineering but never actually benchmark for cheap providers.\n\nHetzner + lakehouse under 10â‚¬ is super tempting for small teams or side projects where Snowflake/Databricks is way overkill. The S3 permission thing is a pretty big red flag though, especially if you ever want to expose access to other tools or less trusted users.\n\nOne possible improvement: add a â€œparanoid modeâ€ section in the repo that documents workarounds for the S3 perms (eg. proxy service, perâ€‘project buckets, or using a separate object store if someone really needs granular ACLs). Also some rough cost sizing examples for different instance sizes would be gold.",
          "score": 1,
          "created_utc": "2026-02-19 09:49:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5d92s",
      "title": "Looking for book reccomendations",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r5d92s/looking_for_book_reccomendations/",
      "author": "a-s-clark",
      "created_utc": "2026-02-15 12:18:05",
      "score": 35,
      "num_comments": 9,
      "upvote_ratio": 0.91,
      "text": "Hi all,\n\nI've been a SQL Server developer for over twenty years, generally doing warehouse design and building, a lot of ETL work, and query performance tuning (TSQL,  .Net, Powershell and SSIS)\n\nI've been in my current role for over a decade, and the shift to cloud solutions has pretty much passed me by.\n\nFor a bunch of reasons i'm thinking its probably time to move on to somewhere else this year, but I'm aware that the job market isnt really there for my specific combination of skills anymore, so im looking at what I need to learn to upskill sufficiently.\n\nI know I need to learn python, but there seems to be a massive amount of other tools, technologies and approaches out there now.\n\nI've always studied best with books rather than videos, which seem to be where a lot of training is these days.\n\nSo, can anyone reccomended some good books/training (preferably not video heavy) for getting up to speed with \"modern\" data engineering?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r5d92s/looking_for_book_reccomendations/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5hwoph",
          "author": "imperialka",
          "text": "Fundamentals of Data Engineering by Joe Reis & Matt Housley. \n\nAlso, youâ€™re right you will need to learn Python. I recommend learning that first and then working on cloud. Python is like 80% of what I do on a daily basis so itâ€™d best to get comfortable with it asap especially for interviews. \n\nCloud tools are important, but I learned that on the job. Once you learn one cloud platform, youâ€™ve basically learned them all. Python is harder to learn and master. \n\nFor Python, assuming youâ€™re a beginner, I recommend Harvardâ€™s CS50 free online course and the this book called Python Crash Course (whatever latest edition) by Eric Matthes.",
          "score": 25,
          "created_utc": "2026-02-15 12:24:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ifixe",
              "author": "a-s-clark",
              "text": "Thanks, I'll check those out.",
              "score": 1,
              "created_utc": "2026-02-15 14:29:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ic9mw",
          "author": "Jazzlike_Drawing_139",
          "text": "Iâ€™m in a similar position. The previous reply is good - Iâ€™d also recommend Data Pipelines Pocket Reference by James Densmore.\nIâ€™ve recently started it, but finding it a helpful way to get to grips with using Python and basic cloud infrastructure for data engineering rather than just analysis/ creating charts which a lot of online training seems to focus on.\n\nIâ€™ve used some AI support when my output or options in cloud interface donâ€™t quite match whatâ€™s in the book, and have started to successfully apply some basic pipeline steps in a modern setup. \n\nYour fundamental knowledge from work with databases/ ETLs will really help - many of the core concepts are the same.",
          "score": 10,
          "created_utc": "2026-02-15 14:10:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ijqh6",
              "author": "a-s-clark",
              "text": "Thanks, I'll check that out.",
              "score": 1,
              "created_utc": "2026-02-15 14:52:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5igo4r",
          "author": "Dependent_Two_618",
          "text": "I think all the suggestions here are great so far. Iâ€™ll add â€œDesigning Data-Intensive Applicationsâ€ by Martin Kleppmann as a resource for how orgs design their stack with multiple data stores. Thereâ€™s a 2nd edition about to come out IIRC.\n\nI started in a similar boat about 3 years ago (albeit less experience). If you were hands on with managing the Windows side (Always On cluster mgmt, OS settings, etc), youâ€™ll want to get thinking in containers too, at least thatâ€™s been my experience so far.",
          "score": 10,
          "created_utc": "2026-02-15 14:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5js3r6",
          "author": "jeffhlewis",
          "text": "As someone mentioned above - once you learn a single public cloud platform, theyâ€™re pretty much all the same with nuances. The skills are 100% transferable. The most important part is to just pick one and start learning/tinkering.\n\nIf you go the azure or AWS route, both of them have introductory certifications (Azure Foundations and AWS Cloud Practitioner, respectively) that are worth taking as theyâ€™ll introduce you to the breadth of services available. Theres lots of courses and study guides available online for those.\n\nGood luck!",
          "score": 4,
          "created_utc": "2026-02-15 18:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ns4oc",
          "author": "Upper-Team",
          "text": "Youâ€™re in a great spot honestly, your background maps really well to modern data engineering, itâ€™s just new names and clouds on top.\n\nA few solid, bookâ€‘ish things:\n\nData engineering / modern stack:  \n- Designing Data-Intensive Applications â€“ Kleppmann  \n- Fundamentals of Data Engineering â€“ Joe Reis & Matt Housley  \n\nCloud + warehouse-y:  \n- The Data Warehouse Toolkit (Kimball) still matters, then pair it with docs for Snowflake / BigQuery / Synapse  \n- Azure Data Engineering (DP-203) study guides if you want to stay in the MS world\n\nPython:  \n- Python for Data Analysis â€“ Wes McKinney  \n\nWith your ETL + performance tuning experience, youâ€™ll pick this stuff up faster than you think.",
          "score": 4,
          "created_utc": "2026-02-16 10:16:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jv9sk",
          "author": "mycocomelon",
          "text": "Not a book, but Iâ€™d recommend dagster university.",
          "score": 2,
          "created_utc": "2026-02-15 18:46:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7vzqb",
      "title": "Data Engineer to ML",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r7vzqb/data_engineer_to_ml/",
      "author": "Comfortable-Bar-9983",
      "created_utc": "2026-02-18 06:54:24",
      "score": 33,
      "num_comments": 8,
      "upvote_ratio": 0.94,
      "text": "Hi Everyone \nGood Day!!\n\nI am writing to ask how difficult it's to switch from Data Engineering to Data Science/ML profile. The ideal profile I would want is to continue working as DE with regular exposure to industry level Ai.\n\nJust wanted to understand what should I know before I can get some exposure. Will DE continue to have a scope in the market, which it was having 4-5 years ago? Is switching to AI profile really worth it? (Worried that I might not remain a good DE and also not become a good Data Scientist)\n\nI have understanding of fundamentals of ML (some coding in sklearn), but if it's worth to start transitioning, where should I begin with to gain ML industry level knowledge?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r7vzqb/data_engineer_to_ml/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o60g5ef",
          "author": "AutoModerator",
          "text": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-18 06:54:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60hd7v",
          "author": "tehwhimsicalwhale",
          "text": "I was a DE for 5 years, did my masters in Data Science and transitioned into DS/ML. Been doing it for also 5 years now. Iâ€™d say DS is a different type of skill but having DE fundamentals has been very beneficial for me. A lot of the problems youâ€™ll be solving in DS/ML wonâ€™t be AI related. To me the coding side is never the problem, itâ€™s always been the statistics side. I encourage you to have strong understanding of stats if you want to succeed. Good luck!",
          "score": 26,
          "created_utc": "2026-02-18 07:05:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60nuhg",
              "author": "Lanky-Magician-5877",
              "text": "From where did you do masters ? I am also thinking of doing it along with job",
              "score": 3,
              "created_utc": "2026-02-18 08:03:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60jfxd",
          "author": "ActionConnect5973",
          "text": "I wish you the best of luck. I am thinking of the same. My background is in applied math heavy on stochastics, so my probability theory knowledge is pretty strong (everything from measure theory to Ito calculus), but since I never finished my PhD (have MSc.) it feels like I am stuck. Not a bad place to be stuck, but it would be fun to do something else for a change, or at least a job that doesn't have you plugged in 24/7.\n\nI miss not having to worry about SLAs, having weekends to myself almost surely, feeling good after a productive day. Getting my European 30 days of vacation on top of it all.... sorry for derailing.\n\nAll that having been said, I can keep up theoretically with a DS, but convincing HR/companies with no knowledge of advanced math about your knowledge can seem daunting at times.",
          "score": 5,
          "created_utc": "2026-02-18 07:23:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60oobk",
              "author": "iamnikaa",
              "text": "I feel your pain..",
              "score": 1,
              "created_utc": "2026-02-18 08:11:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60lers",
          "author": "Thinker_Assignment",
          "text": "You don't need ML to get into AI. As with engineering you can work backwards from what you wanna build and learn that. The field is so fast moving but also constrained, you'll learn the theory through whatever zeitgeist is doing.\n\nWe are preparing to teach modeling for AI as a relevant link",
          "score": 2,
          "created_utc": "2026-02-18 07:41:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o643lza",
          "author": "lbranco93",
          "text": "What you describe is basically an MLE or MLOps profile. I think it would be easier to switch to being an MLOps if you have some understanding of stats and ML.",
          "score": 2,
          "created_utc": "2026-02-18 19:55:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o677n5e",
          "author": "StephenODea",
          "text": "Well first off do you have a master's degree?",
          "score": 1,
          "created_utc": "2026-02-19 06:32:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4r12t",
      "title": "Data engineering vs AI engineering",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1r4r12t/data_engineering_vs_ai_engineering/",
      "author": "BeeLive9842",
      "created_utc": "2026-02-14 17:49:59",
      "score": 31,
      "num_comments": 10,
      "upvote_ratio": 0.88,
      "text": ". I am senior data engineer focused in Databricks & azure and I have been working in consulting companies ever since I started my career 13 years ago. My goal is get into product/tech native companies. However I have a confusion navigating my career decisions. Should I internally find an assignment within my organization and work on a project with AI focus (gen AI, building agentic workflows etc, but not machine learning) and eventually apply in my target companies, probably in a year? \n\nOr should I just start leet coding and apply in those target companies in data engineering now? I am 35 years old right now.\n\nIn my current job, I have an option to build some poc or personal projects and get into AI assignment which may not be possible after I step out. I am looking to develop AI skills that will complement my Data engineering expertise and not looking to completely move away from data engineering. How should I approach this? \n\nI love my data engineering job but also have FOMO in terms of AI",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1r4r12t/data_engineering_vs_ai_engineering/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5dgsbd",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-14 17:49:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dpwm2",
          "author": "Active_Lemon_8260",
          "text": "If you are an AI engineer, but arenâ€™t touching your own companyâ€™s in house model or doing actual machine learning work, then imo you are in danger. \n\nâ€œAI engineerâ€ as you describe, workflows, agents working for your system, is a space that outside of work is moving incredibly fast. So fast that it outpaces the slog it takes to get things implemented at an enterprise company. \n\nYour best bet is to find a data engineer or developer role you enjoy, and start using the AI tools to do that job better. \n\nBetter put, focus on the role and supplement it with AI, donâ€™t focus on a role that only exists to promote some x AI tool for your company. \n\nSorry this is long but one more example: my company has â€œAI engineersâ€ that spend a lot of time and energy making AI agents specific to certain areas - AI agent for M365, an AI document agent, email agent.. you get the idea. Then a few months later the outside world AI space comes out with agents that essentially work in any space, making a lot of their work extremely outdated in a matter of week/months. \n\nI canâ€™t overstate how fast AI is progressing in comparison to how slow companies implement changes.",
          "score": 34,
          "created_utc": "2026-02-14 18:34:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g2rx4",
          "author": "Ok_Yesterday_3449",
          "text": "Both.\n\nData engineering and AI engineering is close enough for applying for jobs at tech companies. The market is terrible right now so it'll probably take a while. In the mean time, since you have the opportunity, build the skills you want to have at your current company.",
          "score": 11,
          "created_utc": "2026-02-15 02:50:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iy9ma",
          "author": "Intrepid-Cat4462",
          "text": "I have been thinking about it lately. \nImo the positions Manager/SM [data and ai], Director[data and ai] are better match for us. This role requires moderate knowledge on ai tools and it's implementation across de space.",
          "score": 2,
          "created_utc": "2026-02-15 16:06:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hnh0l",
          "author": "Eric-Uzumaki",
          "text": "Currently on same boat. I am learning adk and lang graph. The challenge i feel in pet projects is the availability of proper validation phase + observability which are critical for ai engineers if not in data engineering.",
          "score": 1,
          "created_utc": "2026-02-15 11:03:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5j8zcy",
          "author": "x-mor",
          "text": ">My goal is get into product/tech native companies.\n\nThere are still companies still looking for data engineer. You don't need AI and AI need data engineering. The way data engineering is done will probably change but fundamental needs are not changing.\n\nMoreover, regarding your FOMO, my advice would be to focus on what will not change in the next 10 years in the data engineering field. IMO this could be semantic layers or any way to provide documentation to agents. ",
          "score": 1,
          "created_utc": "2026-02-15 16:57:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oj06d",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-16 13:41:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5orpf8",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment was removed because it violated rule #6 (No recruiting, solicitation, or networking posts).\n\nWe do not intend for this space to be a place where people ask for, or advertise:\n\n* Job postings - Please use r/dataengineeringjobs instead.\n* Study groups\n* Referrals\n* Requests to fill in surveys\n* Market research\n* Beta testers wanted\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-02-16 14:28:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5dnod5",
          "author": "msshaik",
          "text": "F",
          "score": -4,
          "created_utc": "2026-02-14 18:24:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5emdvi",
              "author": "greatsmapdireturns",
              "text": "Come on, you gotta admit this one made you chuckle...",
              "score": 3,
              "created_utc": "2026-02-14 21:27:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}