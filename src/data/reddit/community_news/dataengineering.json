{
  "metadata": {
    "last_updated": "2026-01-19 02:39:57",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 393,
    "file_size_bytes": 426633
  },
  "items": [
    {
      "id": "1qaoqlz",
      "title": "Caught the candidate using AI for screening",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qaoqlz/caught_the_candidate_using_ai_for_screening/",
      "author": "Hercules1408",
      "created_utc": "2026-01-12 07:36:49",
      "score": 288,
      "num_comments": 92,
      "upvote_ratio": 0.93,
      "text": "Guy was not able to explain facts and dimensions in theory but said he know in practical when asked him to write code for trimming the values he wrote regular expression immediately, even daily users do not remember syntax easily. When asked him to explain each letter of expression he started choking said he remembered it as it is because he used it earlier . Nowadays its very tough to find genuine working people because these kind of people mess up the project pretty badly ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qaoqlz/caught_the_candidate_using_ai_for_screening/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nz4ox54",
          "author": "painteroftheword",
          "text": "This is the problem with AI.\n\nGives people a false sense of competence because they can get it to do their work for them, up to a point.\n\nIt also has the effect of making non-technical people who've used AI think those with actual skills/knowledgeable aren't necessary.\n\nRecruitment is only going to get worse.",
          "score": 197,
          "created_utc": "2026-01-12 08:26:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz64p24",
              "author": "Rodrack",
              "text": "yes. this is why I hate when people insist that \"LLMs are just one more tool in the box\".\n\nsure they can be a tool if you're smart and disciplined enough, but the sad reality is that a very large amount of people are just, as you said, getting them to do their work for them.\n\nas someone on LinkedIn said, that's not a tool, it's a service; when you order pizza through Uber Eats you don't pretend you cooked the pizza. likewise, no one copy-pasting a ChatGPT output should be saying they created said output \"with the help of a tool\"",
              "score": 36,
              "created_utc": "2026-01-12 14:50:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz97tqm",
                  "author": "Rich-Beyond-9585",
                  "text": "I feel the same way, even with myself. LLM‚Äôs force a sort of reliance and makes competent people become incompetent, without themselves even noticing. \nWith me personally, I feel that my reliance on LLM‚Äôs in developing is reaching an unsustainable point. Like I‚Äôm only 18, and not a developer by trade, and was very much into programming before the emergence of AI Coding, but now I feel a dumbing down of myself in a sense. It‚Äôs also meant that I‚Äôm building things now that are kinda over my head üò≠\nMy New Year‚Äôs Resolution is to start using my own brain a bit more, and actually learn the skills that are required, to the extent of not having to use AI. Wish me luck ü§û",
                  "score": 7,
                  "created_utc": "2026-01-12 23:32:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6ewbv",
                  "author": "painteroftheword",
                  "text": "And it often does it quite badly and/or inefficiently.\n\nI really hate people using LLM's to rewrite their emails.",
                  "score": 5,
                  "created_utc": "2026-01-12 15:41:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz7nqre",
                  "author": "Sad-Guava-5968",
                  "text": "That's a dumb analogy, I'm sorry. I don't consider a hammer not a tool when I use it to saw down a tree.",
                  "score": 0,
                  "created_utc": "2026-01-12 19:04:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzpk9bu",
              "author": "BorderKeeper",
              "text": "We had those people in the past too, it was just a bit rarer as cheating was harder. I remember candidates who pivoted from business to IT and had a good looking resume only to absolutely choke in the interview. I remember being flabbergasted at how someone can go into a senior technical interview with a straight face and won't know what database indexes are and their types in T-SQL for a C#/SQL fintech position.",
              "score": 1,
              "created_utc": "2026-01-15 11:16:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzplix2",
                  "author": "painteroftheword",
                  "text": "I transitioned from business to IT but the hiring manager knew me and was aware I had limited scripting/tech knowledge and trusted I would learn on the job which I did. \n\nI certainly wouldn't have applied an IT job and tried to deceive the hiring manager.",
                  "score": 1,
                  "created_utc": "2026-01-15 11:27:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4ma41",
          "author": "pekingducksoup",
          "text": "I couldn't regex to save my life, it's something I also have to use a tool for.\nI've been using it since before there were tools, I remember flicking through a huge reference book to write a solution for reference.\n\n\nIf you can't explain facts and dims you're in trouble.\n\n\nFinding good candidates has always been hard.",
          "score": 151,
          "created_utc": "2026-01-12 08:01:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4mvun",
              "author": "Informal_Pace9237",
              "text": "Finding good candidates is not hard. But finding candidates who can do the work of  few departments which were laid off recently is hard.\n\nThese days JD are so greedily complex, they aren't even practical.\n\n Most of my interviewers wouldn't pass my interview.",
              "score": 48,
              "created_utc": "2026-01-12 08:07:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz505jq",
                  "author": "financialthrowaw2020",
                  "text": "This is a cop out. DE is a large field with a ton of knowledge required to do the work and most teams cannot survive if a bad hire doesn't pick up the work immediately and start taking ownership. If you as the candidate can't discern whether or not the role is \"multiple departments of work\" and  whether or not you're replacing multiple people, then you're bad at interviewing, these are very basic questions to ask.",
                  "score": -19,
                  "created_utc": "2026-01-12 10:14:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4q89c",
              "author": "ZirePhiinix",
              "text": "Using RegEx you don't understand is pretty dangerous. You will easily match things that you did not intend.",
              "score": 44,
              "created_utc": "2026-01-12 08:38:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4uv94",
                  "author": "pekingducksoup",
                  "text": "Ha, ask me how I know¬†",
                  "score": 42,
                  "created_utc": "2026-01-12 09:23:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz58kup",
                  "author": "big_chung3413",
                  "text": "I don‚Äôt see the issue as long as you test it.  I can never remember the regex syntax but know the edge cases to test so it works out.  \n\nI realize I am ‚Äòdoth has protest too much‚Äô it just seems like the ideal thing to google/ai for.",
                  "score": 24,
                  "created_utc": "2026-01-12 11:29:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5o91t",
                  "author": "Odd-String29",
                  "text": "That is why you test. Even if you understand it you can still miss cases. For example regex for catching emails addresses is extremely complex if you want to do it well. The joke that if you have a problem that requires regex to solve you have two problems holds some truth.\n\nAnyway, I can do some basic regex but when it gets complex I have to resort to tools, documentation and now LLMs.",
                  "score": 8,
                  "created_utc": "2026-01-12 13:20:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7ks4o",
              "author": "j2thebees",
              "text": "I remember doing a Perl project and parsing a huge DHCP leases file. With a cheat sheet in front of me and over a decade pro programming, it wasn‚Äôt a cake walk. It‚Äôs when they get nested that stuff goes sideways in my brain. üòÇ \n\nThat said, I do it infrequently (by hand) when I need it. No way I‚Äôd build that in AI (and trust output). Snatching back 90% of matches would get me fired. (If I was my boss)",
              "score": 1,
              "created_utc": "2026-01-12 18:51:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4k170",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 85,
          "created_utc": "2026-01-12 07:40:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4lccm",
              "author": "umognog",
              "text": "Fact: things I say.\nDim: the intelligence level of the people that use my facts.....",
              "score": 31,
              "created_utc": "2026-01-12 07:52:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4k3xw",
              "author": "Hercules1408",
              "text": "Regex was very simple one 0+ he could not even explain any letter",
              "score": 14,
              "created_utc": "2026-01-12 07:41:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4to4v",
                  "author": "squirrel_crosswalk",
                  "text": "Was the correct answer \"we don't use regex as then we would have two problems\"?",
                  "score": 20,
                  "created_utc": "2026-01-12 09:11:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4pn7t",
          "author": "speedisntfree",
          "text": "This has been very prevalent in our remote interviews, to the point of being nearly ubiquitous from a certain subcontinent.",
          "score": 78,
          "created_utc": "2026-01-12 08:32:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5f12e",
              "author": "3n91n33r",
              "text": "Did they kindly do the needful?",
              "score": 50,
              "created_utc": "2026-01-12 12:19:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6au3r",
                  "author": "TH_Rocks",
                  "text": "Please advice them to not use AI advise.",
                  "score": 12,
                  "created_utc": "2026-01-12 15:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5s0gw",
              "author": "CdnGuy",
              "text": "We‚Äôve been seeing a good bit of this too, combined with people sending surrogates to take the tech screen for them. Like we‚Äôre not going to notice it isn‚Äôt the same person? Even had one candidate get to the final interview which is just conversational, and just read gen ai output to us the whole time. Even used it for the fun brain teaser question.",
              "score": 14,
              "created_utc": "2026-01-12 13:42:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4n0bz",
          "author": "giantZorg",
          "text": "We have a coding interview in our process that tests rather basic python and SQL knowledge, so we generally expect people to be able to solve them without AI or searching. Had a crashout of someone recently that completely refused to code without an AI assistant. I don't know how you can work without understanding what you are supposed to be working with.",
          "score": 25,
          "created_utc": "2026-01-12 08:08:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz81ym9",
              "author": "sl00k",
              "text": "As someone who's been working almost entirely agentically for a year I'm dreading job hunting again for exactly this reason. I wouldn't crash out but I do think it's pretty dumb.\n\nI think companies should allow an AI based coding assessment that's a much more complex problem and you can judge based on that agentically or not.",
              "score": 6,
              "created_utc": "2026-01-12 20:10:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4wwjf",
              "author": "zubinajmera",
              "text": "hmmmm true..but then if you're going to allow them to use AI at their job, why not in interviews? and just watch HOW they used AI?",
              "score": -21,
              "created_utc": "2026-01-12 09:43:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz51d3h",
                  "author": "MikeDoesEverything",
                  "text": "The mental gymnastics people use to justify their lack of knowledge is astounding.\n\nImagine if this was any other job, you'd have the same problem.  If anybody applied to be a translator but they could only translate with the help of an AI assistant.  When asked to translate without one, they lose their shit and say, \"I'll be using one on the job anyway!\".\n\nJust because somebody can use an LLM, it doesn't mean they know how to program.  Anybody who needs, in the literal sense of \"can't do without\", an AI assistant to do any particular task can't do the task and anybody who says they can is LARPing.",
                  "score": 22,
                  "created_utc": "2026-01-12 10:25:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz9mnq0",
                  "author": "Rodrack",
                  "text": "I used to peddle this \"interviews should be reflective of the actual work\" narrative even long before GenAI.\n\nBut one day someone said the quiet part out loud to me: \"those interviews aren't designed to see if you can do the work. they're designed to see if you're intelligent\"\n\ndebateable, I know, but if you're selecting for abstract reasoning rather than simple experience, leetcode-style interviews used to be at least somewhat predictive of that.",
                  "score": 2,
                  "created_utc": "2026-01-13 00:52:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5co32",
                  "author": "giantZorg",
                  "text": "What we ask to do is really basic, to the point of where I asked the person who put it together initially what he would do if he got someone like myself who writes down everything asked in 5 minutes. So what we really ask is whether a person can understand what they read and know the basics of the tools they will work with. If they can't do that, then I wouldn't trust any of their MRs.\n\nIf the problems we had were at a level where I can simply take a ticket, pass it to the LLM and then get a working solution from the AI agent (which is basically what you need if you want someone with no understanding of what they do or work with), then I don't need an additional person at all.",
                  "score": 3,
                  "created_utc": "2026-01-12 12:01:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4pyk1",
          "author": "Hercules1408",
          "text": "And sorry to say this point but interviewed around 50 candidates and most of them were around bangalore and Hyderabad . The common pattern in their resume was they worked in some small company for 5 yrs and now they are in mnc don‚Äôt know how they got in and when you ask anything most of them are caught cheating . When you google their past company it will show some dummy website and no location for company or either some incorrect location pointed as company office.\n\nThis is not external hiring this is scenario in internal project interview of mnc big one like infy tcs ‚Ä¶",
          "score": 32,
          "created_utc": "2026-01-12 08:35:58",
          "is_submitter": true,
          "replies": [
            {
              "id": "nz4uco8",
              "author": "Psychological-Fly307",
              "text": "Yeah we saw the same thing, we had to implement a secondary screening process after hr and recruitment sent us applicants, it's effectively detective work. We also see a pattern of Nigerians 'working' at dummy UK companies ( I think it's a visa scam), a quick check of companies house usually shows it as an inactive or not making enough revenue to support a single worker. \n\nIf a candidate repeats your question out verbatim every time before answering and the answer never covers a specific scenario that relates to the job history you can usually end the interview early as they will be using AI.",
              "score": 15,
              "created_utc": "2026-01-12 09:18:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzpxi0t",
              "author": "the-great-pussy-rub",
              "text": "This is exactly what happens in Australia.",
              "score": 2,
              "created_utc": "2026-01-15 12:54:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5a22x",
          "author": "redvers76",
          "text": "Had a similar experience late last year. Some candidates tried inviting an AI \"note taker\" to the Teams call, that was denied access and was an immediate red flag (not one of them \\*asked\\* if they could do so).\n\nWe then had people who seemed to hesitate before answering any question. Once or twice, nerves, every single question? It's pointing the way of stalling before waiting to see the text appear for them to regurgitate! There's also the tell of the eye darting off screen to read something... could be notes, but... given what they then said, it just gave the impression of reading from either someone else googling on their behalf, or AI LLM output.\n\nBut every single one was derailed by this one simple trick... as hiring manager, I was interviewing the person for them, not their technical skills. There was some of that, but more in approach and mentality, rather than specific abilities, that would come in the next round. So I would just say to the candidate \"You have listed these ETL tools on your CV, which is your favourite and why?\"\n\nEvery single time, the ones reading AI output would turn into a marketing bot, sounding like an advert for the tools, bullet point after bullet point. Not one of them highlighted a favourite without being asked again, and then couldn't actually answer definitively as to why they chose that above another, almost as if they'd just picked one at random. The humans answering that question would do so in a conversational manner, often immediately blurting out their favourite and then going through the pros and cons as to why.\n\nI can see the appeal of using AI to help, to act as a pointer to guide your answers, especially in areas of theory where you're rusty because you've been at the coalface for a while. But don't rely on it 100% to the point where you cannot actually hold a conversation with the person you're talking to.",
          "score": 17,
          "created_utc": "2026-01-12 11:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5su1o",
              "author": "idodatamodels",
              "text": "Yep, I do the same for data modeler interviews. I ask what don't you like about erwin? Anyone who's worked with the tool should have a rant or two. If you don't, you haven't used the tool.",
              "score": 5,
              "created_utc": "2026-01-12 13:46:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz81syl",
              "author": "VipeholmsCola",
              "text": "Consider being from a third world country and faking your way into a tech company in US. If you just fake your way to one salary that would probably be 1-2 years of their income. It makes perfect sense for some poor desperate doing the needful.",
              "score": 5,
              "created_utc": "2026-01-12 20:09:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz9eiyn",
                  "author": "Dawido090",
                  "text": "They are going to kill market for themself.",
                  "score": 3,
                  "created_utc": "2026-01-13 00:08:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz8azig",
              "author": "tashibum",
              "text": "Your assessment of someone using ai is just my nervous habits already üò≠",
              "score": 1,
              "created_utc": "2026-01-12 20:52:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6dwnx",
          "author": "BackgammonEspresso",
          "text": "I interview people frequently, almost all Indian contractors. Nearly all of them are using AI.",
          "score": 7,
          "created_utc": "2026-01-12 15:36:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6m8jj",
          "author": "Sequoyah",
          "text": "Every DE job listing gets like a thousand applicants these days. This necessitates heavy automated screening, which only allows a tiny fraction of the most \"perfect\" resumes to even reach a human being at all. Real applicants don't have \"perfect\" resumes, so in effect this system rewards those who are the most willing to lie about their experience. The more shameless the liar, the more perfect the resume.¬†",
          "score": 8,
          "created_utc": "2026-01-12 16:15:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5labk",
          "author": "Counter-Business",
          "text": "Seen this too many times. Am considering that for future interviews, telling the candidates \n\n‚ÄúWe have seen too many people cheating with AI so we will need you to share your screen, and also, put your hands where I can see them.‚Äù",
          "score": 6,
          "created_utc": "2026-01-12 13:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz65plc",
              "author": "ccesta",
              "text": "Might as well white board in person",
              "score": 8,
              "created_utc": "2026-01-12 14:55:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz664a6",
                  "author": "Counter-Business",
                  "text": "Too much work for first few rounds of interviews.",
                  "score": 3,
                  "created_utc": "2026-01-12 14:57:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5ly03",
              "author": "Xman0142",
              "text": "Share my screen during an interview is a bit much. I wouldn‚Äôt want to be with a company that sends these kind of signals during the interview. Would make me think they are micromanagers.",
              "score": 1,
              "created_utc": "2026-01-12 13:06:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5wks2",
                  "author": "Counter-Business",
                  "text": "It‚Äôs pretty obvious that many people cheat now-a-days and hard to tell sometimes with how good AI has gotten. \n\nBetter to have these kinds of precautions than to pick the wrong candidate",
                  "score": 4,
                  "created_utc": "2026-01-12 14:07:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz770w7",
          "author": "linos100",
          "text": "Would it have been okay if the candidate had said \"I'll use regex. Usually I ask copilot to make the statement and test it this way\"? I know they probably had chatgpt make the whole script, but I am just wondering, as regex is one of the cases where AI is the right tool imo",
          "score": 6,
          "created_utc": "2026-01-12 17:49:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9pdzx",
              "author": "Rodrack",
              "text": "i agree. for me the line would be whether they're using AI as a \"cheat sheet\" (no different to, say, how we used StackOverflow back in the day) or to \"think\" for them.\n\nassuming it's a case-study question, I would be satisfied if the interviewee reached the conclusion that they need a regex, as long as they can explain what, why, and how. no need to write it from memory.\n\nwhat would be concerning is if they needed the AI to tell them to use regex.",
              "score": 2,
              "created_utc": "2026-01-13 01:07:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz79qg0",
          "author": "redditdotcrypto",
          "text": "the problem is that people doing the interviews have not evolved and doing the same interview style as 5 years ago. They need to find ways to ask things differently and basically the whole structure needs to change. Almost nobody is typing code nowadays. Just because someone memorized some syntax means nothing. You need to ask questions about understanding, design, architecture etc not write some code or solve a leetcode problem in 3 minutes.",
          "score": 6,
          "created_utc": "2026-01-12 18:02:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz61oyw",
          "author": "No_Airline_8073",
          "text": "Way too many candidates are cheating now. They will ask the question again and pretend to think while waiting for LLMs to generate answers. Then after speaking non sense for 10-20 seconds, they will give the perfect answer",
          "score": 3,
          "created_utc": "2026-01-12 14:35:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8uh8s",
          "author": "DiabloSpear",
          "text": "lol. literally me: I don't care if you use AI. You will have it when you are working. Just make sure that you can read the code it produced and tell me how it works though.",
          "score": 3,
          "created_utc": "2026-01-12 22:24:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9ssg9",
          "author": "Rodrack",
          "text": "I think those debating whereas regex (or anything else) is an OK use case for AI are missing the point.\n\nthe point is that not knowing facts/dims + writing regex immediately from scratch + not being able to even explain the letters = high likelihood of cheating with AI",
          "score": 3,
          "created_utc": "2026-01-13 01:26:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5oof8",
          "author": "WhipsAndMarkovChains",
          "text": "I could definitely write regex from memory but unlike this candidate I‚Äôd be able to explain the pattern I‚Äôd written.",
          "score": 2,
          "created_utc": "2026-01-12 13:23:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7b2sh",
          "author": "randomusicjunkie",
          "text": "It‚Äôs more common, interviewed hundreds of candidates this year, it‚Äôs crazy how many use AI. I don‚Äôt get upset anymore, it‚Äôs the world today and it‚Äôs no longer cheating to be frank - they will use AI at work too, so you better ask better questions or do good assignments.",
          "score": 2,
          "created_utc": "2026-01-12 18:08:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz81i34",
          "author": "Additional-Maize3980",
          "text": "If they can't explain facts and dims, I'd stop there",
          "score": 2,
          "created_utc": "2026-01-12 20:08:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz88s0m",
          "author": "fenrirbatdorf",
          "text": "It's very disappointing that I have been taking great pains to learn all these principles of data engineering through my soon-to-be completed college education and cannot find a interview because of the slog submitting applications.",
          "score": 2,
          "created_utc": "2026-01-12 20:42:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdbeoa",
          "author": "RandomChance",
          "text": "I recently had an interview where the interviewer welcomed me to use AI, just asked that we share the screen where I was using it.\n\nUsing AI at work is a given now.  The question is how you use it, if you use it responsibly, if you use it/trust it blindly.  Using it to avoid banging your head against something for hours? Smart.  But you don't copy and paste that output - you use it to understand what was wrong and what to improve.\n\nSo part of what they were looking at was not \"do you AI\" but how.",
          "score": 2,
          "created_utc": "2026-01-13 15:47:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmvx0z",
          "author": "Immediate-Pair-4290",
          "text": "I‚Äôve interviewed many candidates now cheating with AI. My experience interviewing is just horrible since LLMs.",
          "score": 2,
          "created_utc": "2026-01-14 23:40:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4wrp3",
          "author": "zubinajmera",
          "text": "agree...just curious, instead of asking them such questions which now can be easily gamed, why not give them an actual on-the-job task in a live production environment and then evaluate their shipped work?",
          "score": 4,
          "created_utc": "2026-01-12 09:42:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4uj3m",
          "author": "andymaclean19",
          "text": "This type of thing is not a strong long-term plan though is it?  If the AI is better at interviewing than the candidate then how long will it be before it's better at the job than they are?  And what would they expect to happen to their job then?",
          "score": 3,
          "created_utc": "2026-01-12 09:20:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4uqs3",
          "author": "ColdStorage256",
          "text": "I much prefer knowing the theory and asking AI for the application.\n\n  \nIn other industries, it's why builders often can't design homes - because they don't know structural engineering; but if you gave an architect a robot that could fulfill the builders' tasks, the architect could build the home.\n\n  \nTheory and understanding tradeoffs and how they apply to your set of needs is becoming much more important.",
          "score": 3,
          "created_utc": "2026-01-12 09:22:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz56qdg",
              "author": "TonkaTonk",
              "text": "All of my anecdotal experience says your analogy fails on several levels, but I see where you are going with it.\n\nSource: architects blowing out budgets and going with overly bespoke design choices.",
              "score": 5,
              "created_utc": "2026-01-12 11:13:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5730y",
          "author": "Bmaxtubby1",
          "text": "As a beginner, I totally get not remembering regex syntax - I look it up constantly. Even experienced people say they rely on references. That part alone doesn't feel like a red flag.\n\nNot being able to explain core concepts like facts and dimensions feels different though. Those are ideas you use to reason about data, not just code you copy-paste.",
          "score": 2,
          "created_utc": "2026-01-12 11:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4rbps",
          "author": "codykonior",
          "text": "Lol",
          "score": 1,
          "created_utc": "2026-01-12 08:49:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5kryi",
          "author": "uvaavu",
          "text": "The worst I've had is interviewing consultants that I caught using AI during informal fit interviews.",
          "score": 1,
          "created_utc": "2026-01-12 12:58:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziassf",
          "author": "snigherfardimungus",
          "text": "We had so many people trying so many silly ways to cheat (even before the AI boom) that we just went back to in-person interviews. I had one guy who had a buddy sitting just off-camera trying to whisper answers. I had another who was clearly using his earbuds to have a friend on the phone during the zoom interview and wasn't even bright enough to mask it. (He told the other guy to \"slow down\" at one point.... when I wasn't talking, so he wasn't addressing me. etc.) That's not even the worst of it.\n\nMost of our candidates were happy with the change when we explained our motivation; that it eliminated unfair competition in the process. It was more expensive for us per candidate, but it took far fewer candidates to get strong positive responses from our interviewing staff.\n\nThe work was on-site, so candidates who were considering moving for the position liked the fact that we were giving them several days of hotel/car/food stipend so they could check out the area and see if they were really wanting to move there. I had too many experiences when I was younger where I had to make that call based upon experiencing the city between the airport and the office.",
          "score": 1,
          "created_utc": "2026-01-14 08:43:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzppfkh",
          "author": "Dogentic_Data",
          "text": "This feels like a symptom of how hiring has shifted, not just people using AI. Memorizing syntax or definitions has always been a weak signal, now it‚Äôs just more obvious. What I‚Äôve found more telling is asking candidates to reason through tradeoffs or explain why they‚Äôd design something a certain way. AI can generate code, but it‚Äôs much harder to fake understanding of constraints and consequences.",
          "score": 1,
          "created_utc": "2026-01-15 11:58:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqqemh",
          "author": "Standard-Ant874",
          "text": "How much experience the candidate has in this role?",
          "score": 1,
          "created_utc": "2026-01-15 15:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz69fxu",
          "author": "connmt12",
          "text": "It sounds like you‚Äôre looking for the wrong thing. You should consider what skills actually translate to success in the job. Memorizing syntax was once a useful skill and it is likely hard to let go of the ego boost related to knowing more code than other people, but in the long term getting the job done is much more important than memorizing syntax for an interview",
          "score": 1,
          "created_utc": "2026-01-12 15:14:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6b5md",
              "author": "lazyear",
              "text": "Most programming languages have very little syntax you need to know.\nIf you don't know it, you don't know how to program and it's clear that you haven't really written much code.\n\nThis is like claiming to know English without knowing any English syntax.",
              "score": 2,
              "created_utc": "2026-01-12 15:23:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5wb48",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -1,
          "created_utc": "2026-01-12 14:06:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7driy",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment violated rule #1 (Don't be a jerk). \n\nWe welcome constructive criticism here and if it isn't constructive we ask that you remember folks here come from all walks of life and all over the world. If you're feeling angry, step away from the situation and come back when you can think clearly and logically again.\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-01-12 18:20:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5kn5o",
          "author": "Gold-Pomelo-2143",
          "text": "bro dont know abt facts and dimensions, if i were the interviewer i have already failed that guy in round 1",
          "score": 0,
          "created_utc": "2026-01-12 12:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5r9ce",
          "author": "Responsible_Act4032",
          "text": "I had an interview where I caught the person reading from an AI on his screen while we were talking. \n\nThe tell was, as he moved in his seat, his eyes stayed exactly focused on the same spot, not moving around as folks sometimes do when they are thinking. \n\nHarder to spot these days, which is why I believe we're seeing the return of some element of in person interviews.",
          "score": 0,
          "created_utc": "2026-01-12 13:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz70mb7",
              "author": "Icyywinds",
              "text": "I've done this but I have notes and when I get nervous I tend to look where my salvation is. How do you tell the difference between that and AI?",
              "score": 6,
              "created_utc": "2026-01-12 17:20:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz741p7",
                  "author": "Responsible_Act4032",
                  "text": "I could see their eyes scanning, and the text was moving, but their hands weren't scrolling the mouse in a doc to get to another section of notes. \n\nIf you are using notes, tell the interviewer that you are using notes on some of the tech you prepared for the interview.",
                  "score": 0,
                  "created_utc": "2026-01-12 17:36:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qes5tx",
      "title": "Anyone else losing their touch?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qes5tx/anyone_else_losing_their_touch/",
      "author": "The-CAPtainn",
      "created_utc": "2026-01-16 21:04:22",
      "score": 224,
      "num_comments": 119,
      "upvote_ratio": 0.91,
      "text": "I‚Äôve been working at my company for 3+ years and can‚Äôt really remember the last time I didn‚Äôt use AI to power through my work. \n\nIf I were to go elsewhere, I have no idea if I could answer some SQL and Python questions to even break into another company. \n\nIt doesn‚Äôt even feel worth practicing regularly since AI can help me do everything I need regarding code changes and I understand how all the systems tie together. \n\nDo companies still ask raw problems without letting you use AI? \n\nI guess after writing this post out, I can already tell it‚Äôs just going to take raw willpower and discipline to keep myself sharp. But I‚Äôd like to hear how everyone is battling this feeling. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qes5tx/anyone_else_losing_their_touch/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzzr90c",
          "author": "soricellia",
          "text": "my job is to solve business problems by typing them into the ai.",
          "score": 309,
          "created_utc": "2026-01-16 21:06:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzrot7",
              "author": "Informal_Pace9237",
              "text": "That job WILL be replaced by some one with lot less brain power till the product is doomed and the company goes under.",
              "score": 71,
              "created_utc": "2026-01-16 21:08:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzw6tx",
                  "author": "girlgonevegan",
                  "text": "The inbalance in cognitive work loads is so wild. ü§™ I‚Äôve been cycling burn out in MOps for what feels like the last 5 years. Everyone thinks IT + Consultant + Offshore is somehow going to solve years of enterprise tech debt because there‚Äôs now AI.\n\nETA - Thanks for the upvotes üëçüèº \nI feel like I‚Äôve been screaming into the void about this. I just want to stop the madness.",
                  "score": 70,
                  "created_utc": "2026-01-16 21:29:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00s9mj",
                  "author": "ScottFujitaDiarrhea",
                  "text": "Couldn‚Äôt you make the same argument for like every white collar job?",
                  "score": 3,
                  "created_utc": "2026-01-17 00:16:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzzuho1",
                  "author": "Aggravating_Sand352",
                  "text": "#capitalism",
                  "score": 8,
                  "created_utc": "2026-01-16 21:21:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o01doe2",
              "author": "Sad-Guava-5968",
              "text": "In Soviet Russia, AI type you",
              "score": 10,
              "created_utc": "2026-01-17 02:29:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o070k7h",
              "author": "longbreaddinosaur",
              "text": "Glorious. Absolutely glorious.\n\nI had AI read all of my meeting notes and draft my year end review.  Better than anything I could have done.",
              "score": 1,
              "created_utc": "2026-01-17 23:26:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o008aaq",
              "author": "Philosiphizor",
              "text": "My job is to also solve business problems by typing them into the ai.",
              "score": 1,
              "created_utc": "2026-01-16 22:28:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzskqs",
          "author": "Leilatha",
          "text": "AI makes me more productive at work, at the cost of losing a bit of intelligence every day...",
          "score": 164,
          "created_utc": "2026-01-16 21:12:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzztki3",
          "author": "recursive_regret",
          "text": "I was a huge AI skeptic when all the LLMs started to drop, but since then they have become really good. I use AI every day to help me through my work. I ask chatGPT to write scripts, read logs, research solutions, etc. THIS is the new iteration of software engineering and by extension data engineering. If you‚Äôre not using AI at your job, you‚Äôre falling behind.  \n  \nHaving said that, I‚Äôm still up to date on technology, I still read documentation, and I review every single line of code chatGPT writes without exception. If I don‚Äôt understand what it‚Äôs doing, I research it. If I‚Äôm skeptical on what the script does, it does not make it into prod. No exceptions.  \n  \nA word of caution, we had someone on our team write a script with AI and run it without reviewing. They deleted a bunch of data from the database without knowing. We had back ups, but there was data that went missing. When asked about the obviously ChatGPT written script they could not explain what it did or why.",
          "score": 149,
          "created_utc": "2026-01-16 21:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzxp5a",
              "author": "Otherwise_Movie5142",
              "text": "Same, I don't let a single line of code pass by without understanding what it's doing first to make sure it's the right solution but I can save a lot of time on what may as well be boiler plate by using AI.\n\nMy work hasn't dropped in quality and I'm more productive, but that does come at the cost of not having to think through certain problems in the same way. Understanding a solution vs solving the problem are two completely different skills imo and AI robs you of the latter if you use it as your first point of call every time.",
              "score": 34,
              "created_utc": "2026-01-16 21:36:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o01vfxz",
              "author": "pinkpepr",
              "text": "100% regarding the word of caution. I once asked chatGPT to generate me a command to revert a commit where I deleted a Git branch I thought I didn't need. I pasted the command into terminal, hit enter, and watched as it was queuing all of the commits from the entire repo. I googled the command it gave me and it was for deleting every commit in the entire repo. Fastest keyboard interrupt I've ever done. I literally came within seconds of deleting all of me and my colleague's work (hundreds of commits). Moral of the story, understand everything the AI generates for you before actioning it/implementing it.",
              "score": 7,
              "created_utc": "2026-01-17 04:25:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04n2q1",
                  "author": "Desperate_Cod_4153",
                  "text": "Lol, same thing happened to me.",
                  "score": 2,
                  "created_utc": "2026-01-17 16:30:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o025weu",
              "author": "Chowder1054",
              "text": "This is how it should be used. An aide and complement. But you had to have the base knowledge to make sure it‚Äôs spitting out proper material.",
              "score": 4,
              "created_utc": "2026-01-17 05:42:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o03s1xr",
              "author": "reelznfeelz",
              "text": "This is basically where I‚Äôm at too.  AI accelerates my work heavily.  But expert human in the loop is still pretty critical.  So being an expert who knows how to use AI well is actually a skill now IMO.",
              "score": 2,
              "created_utc": "2026-01-17 13:52:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0212wa",
              "author": "muhmeinchut69",
              "text": ">  If I don‚Äôt understand what it‚Äôs doing, I research it.\n\nEven now I don't trust AI to do something I don't understand. Any research you need to do should come first and should be done by you. If you ask AI to both identify the problem AND suggest the solution, you're basically begging for it to hallucinate, which it does quite frequently.",
              "score": 2,
              "created_utc": "2026-01-17 05:05:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04xpt6",
              "author": "littlerchef",
              "text": "Having an AI-written script delete data without knowing is the major alarm bell that should be going off. Competent employees should be reviewing and learning from the AI productivity boost not turning into prompt monkeys.",
              "score": 1,
              "created_utc": "2026-01-17 17:19:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0028a0",
          "author": "IamAdrummerAMA",
          "text": "Back in the StackOverflow days (which I still use today, but sad to see others no longer do) I‚Äôd always use it to research a problem and apply it to my own thinking.\n\nWhat I keep is a learning log on my GitHub, my own collection of code snippets and solutions to problems I‚Äôve had over the years, which I always go to first over an AI tool. This collection is my own, sure I may have learnt some of the technique from Stack or documentation, but the code in the log is applied to my own circumstance so the knowledge is retained better. I can also trust it more so than the AI tool.\n\nWhen I do use an AI, I always ask it to provide me with the citations it used to formulate the response so I can go there to back up the outcome. Gemini is particularly good at this.",
          "score": 25,
          "created_utc": "2026-01-16 21:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00stw3",
              "author": "ScottFujitaDiarrhea",
              "text": "Yep, I basically use AI as a more robust SO. And I write bits and pieces of code and test iteratively like I did in the SO days.",
              "score": 3,
              "created_utc": "2026-01-17 00:20:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o03lots",
              "author": "gonetribal",
              "text": "I use Brave Search AI responses for this reason. It gives you a source for almost every line in the response, so it's really easy to fact check the source, i.e.was it the official docs or some random blog from 10 years ago.",
              "score": 2,
              "created_utc": "2026-01-17 13:14:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o053t4f",
              "author": "typodewww",
              "text": "What I usually do I copy and paste code scripts Microsoft one note to reference later and put a data on the code so if I‚Äôm in like Databricks and delete some of my old scripts I‚Äôm not panicking",
              "score": 1,
              "created_utc": "2026-01-17 17:48:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzx4kl",
          "author": "living_direction_27",
          "text": "I‚Äôm in the same spot! I realize I probably forgot how to code. The other day I had to start a script from scratch, and was literally staring at the screen unable to remember what to do. I think this is a serious problem.\n\nTo be honest, what we have learned before AI stays in our brains. All we learned after, it doesn‚Äôt. At least, this is the case for me. \n\nAnd yes, company do coding test, but it is way too easy to cheat that you end up doing it. I believe everyone use AI at work nowadays",
          "score": 36,
          "created_utc": "2026-01-16 21:34:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o002uny",
              "author": "Odd_Lab_7244",
              "text": "It's like when you use satnav for a drive, you can't remember afterwards how you got there, but if you don't use satnav you almost certainly get lost, but next time you drive know the way better. Don't know what the moral of the story isüòÜ",
              "score": 8,
              "created_utc": "2026-01-16 22:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o005iju",
                  "author": "living_direction_27",
                  "text": "I think the moral of the story is that, if you want to learn something, you got to do it. If you outsource it, it will feel you are learning/moving forward faster, but in reality, you aren‚Äôt",
                  "score": 8,
                  "created_utc": "2026-01-16 22:14:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03vtun",
                  "author": "anti_humor",
                  "text": "You get better at what you do often, and skills you aren't using often start to atrophy. Our brains are super adaptive and won't waste resources that aren't being used for long, to a degree.",
                  "score": 1,
                  "created_utc": "2026-01-17 14:13:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o015v9t",
              "author": "Skullclownlol",
              "text": "> To be honest, what we have learned before AI stays in our brains. \n\nThis is not how knowledge retention works. Unless knowledge is frequently/consistently applied, it gets lost.",
              "score": 3,
              "created_utc": "2026-01-17 01:39:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzug6q",
          "author": "Tee_hops",
          "text": "Everyone else please keep relying on AI to do everything.",
          "score": 61,
          "created_utc": "2026-01-16 21:21:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o004d74",
          "author": "tashibum",
          "text": "Same, with a big BUT:\n\nI try REALLY HARD  to understand the context and use case for keeping in my pocket later, because you still have to understand why you choose to do one thing over the other.  I always make my LLM justify the action.  Lots of times,  I've asked \"why not do it x way?\" and it'll be like \"oh yes,  that's much more simple\". It can get over complicated fast if you don't pay attention.  \n\nI have definitely learned a lot of new things.  But you're right about interview questions man. I just don't allocate my brain power to recalling an exact name of a command anymore because the only reason to do that is for an interview now üòÖ",
          "score": 8,
          "created_utc": "2026-01-16 22:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00l19k",
          "author": "Orcasun",
          "text": "You could try going into management? Seriously, this is basically what management is, telling somebody to do something and supervising their output.",
          "score": 8,
          "created_utc": "2026-01-16 23:35:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzt0fi",
          "author": "69odysseus",
          "text": "I use AI but still have to do lot of work based on my understanding of the domain and internals of the data. AI still heavily relies on what I feed to it and still can't figure out the core of what's being asked.",
          "score": 11,
          "created_utc": "2026-01-16 21:14:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00by27",
          "author": "i_hate_budget_tyres",
          "text": "I‚Äôm surprised AI is so useful to so many on this thread.   I find I use it like a glorified google search.   Agentic modes utterly balls up code, and I spend more time fixing mistakes, ie,  its a hinderance more than a help.  As yes, I have done prompt engineering courses.\n\nThe only area it‚Äôs come in really useful is creating pipelined bash commands.  Like a command I might have spent 10 mins, building 1 function at a time takes seconds with a natural language prompt now.",
          "score": 19,
          "created_utc": "2026-01-16 22:46:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00up1f",
              "author": "ScottFujitaDiarrhea",
              "text": "Yeah, not to mention it‚Äôs very difficult to vibecode an entire application that‚Äôs specific to your company/domain. You have to either code it yourself or be very specific and break it down into smaller chunks of functionality, which at that point you have to understand it to some extent.",
              "score": 9,
              "created_utc": "2026-01-17 00:30:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o01pgmf",
                  "author": "i_hate_budget_tyres",
                  "text": "I tried vibe coding, it made me slower.  I work in a multicloud, multivendor environment, across different code repositories and different CI CD platforms.  AI from one vendor can‚Äôt see across all that holistically.  I‚Äôm guessing some of the people who are finding it useful here, are working in much simpler environments and tech stacks.",
                  "score": 6,
                  "created_utc": "2026-01-17 03:44:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o01y6kj",
              "author": "ramoslucas_",
              "text": "I agree. Agentic mode only works for me if I describe every detail of what i want to code, so I'm better off coding myself. They can handle simple tasks, but don't handle context and nuance very well. \n\nUsually what I do is ask cursor to review, comment and format the code.",
              "score": 4,
              "created_utc": "2026-01-17 04:44:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o03k4sr",
              "author": "azirale",
              "text": "I keep getting blocked on using it because it eventually wanders off and I keep having to correct it. Eventually it gets to a point that I may as well just be doing things myself. I mix in prompts for small sections where I can get it to quickly spin up something like boilerplate, which I then include and fix/tweak.\n\nBut so much of the issues I'm grappling with just can't be handled by AI at all. Adding integrations with third party processors for new products, and the spec says to copy an existing implementation but actually the need a bunch of changes. Lining up time zones, currencies, scheduling, file naming conventions between provider and receiver for data. Or team based things like code and test standards, evaluating which tech to apply to solutions we need.",
              "score": 1,
              "created_utc": "2026-01-17 13:03:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o08zhh5",
              "author": "thro0away12",
              "text": "I am the same. I asked AI the other day to give me a solution specific to aws redshift and it gave me a function that doesn't exist there. I told it you gave me a function that doesn't exist and it was like \"Oh yes....<proceeds to give something else lol>\". At best, I feel like it's good at giving me the answers I used to have to sift through bunch of stack overflow threads for, but it doesn't always work for me.",
              "score": 1,
              "created_utc": "2026-01-18 06:26:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzztbge",
          "author": "BoinkDoinkKoink",
          "text": "AI is a tool that helps you power through your work, which is similar to stackexchange, a resource that helped people look for a solution. It's like asking if companies let you use stackexchange to give interviews.",
          "score": 11,
          "created_utc": "2026-01-16 21:16:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02fqz8",
          "author": "Lastrevio",
          "text": "I don't understand something about OP and most of the people in the comments: is all you're doing as a data engineer 'writing code'? 90-95% of my time at work is spend reading code other people wrote, not writing something myself, since I have to maintain legacy systems. I don't see how AI can help me with that if I have to explain to the client how a certain column is computed by reverse engineering a pipeline to figure out how it works.",
          "score": 3,
          "created_utc": "2026-01-17 07:05:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05covi",
              "author": "The-CAPtainn",
              "text": "I write code more often than not because we‚Äôre building a new system, but I am also on app support for another system that we left 2.5 years ago. I have provided ZERO support to that app though because AI isn‚Äôt able to help explain things for a massive legacy system. I‚Äôve piggybacked two other developers on this every time an issue came up. I guess this is one area I should raise my bar for since I can be of use without AI here.",
              "score": 1,
              "created_utc": "2026-01-17 18:29:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o007skq",
          "author": "TyrusX",
          "text": "lol. Yeah. It is brutal  I feel so much dumber now",
          "score": 3,
          "created_utc": "2026-01-16 22:25:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00ghxg",
          "author": "winnieham",
          "text": "It depends if the company is an AI first company then the interview process is more abt broad problem solving rather than coding.",
          "score": 3,
          "created_utc": "2026-01-16 23:10:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00hih0",
          "author": "Last0dyssey",
          "text": "Don't use it as a crutch and you'll be fine. I use it mainly for brainstorming and vetting my thoughts. It can write code for sure but it can be ass. Just because it runs doesn't mean it's good. I have had to debug AI code my peers have implemented and it can be horrifically bad. Oddly enough everyone that has abused it to that point were pretty subpar analysts to begin with so there's that",
          "score": 3,
          "created_utc": "2026-01-16 23:15:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00nr4l",
          "author": "adgjl12",
          "text": "Syntax and quirks sure. But not the fundamentals.\n\nIf a company wants me to remember some random spark function I probably won‚Äôt know off the top of my head since I haven‚Äôt worked with it in years. So if the interview is trivia based I probably won‚Äôt do well, but those types of companies that did ask those didn‚Äôt seem so promising anyways. Generally people are happy to test my fundamentals.",
          "score": 3,
          "created_utc": "2026-01-16 23:50:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o011hin",
          "author": "AnimaLepton",
          "text": "Sure. My goal is to hold on to my job, try to build some transferable and soft skills, and continue to make money until I become a multimillionaire and can retire comfortably. But yeah, there's definitely a subset of my technical, troubleshooting, and communication skills where I'm offloading it to AI. That's potentially to my own detriment, but it allows me to save time or move quickly. The more important thing is that I spend time on important things.",
          "score": 3,
          "created_utc": "2026-01-17 01:11:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01l9ph",
          "author": "Alternative_Car4265",
          "text": "i been doing leetcode problems on company time to not lose my brain. An apple a day. Honestly useless though",
          "score": 3,
          "created_utc": "2026-01-17 03:16:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06j0q0",
          "author": "Acceptable-Sense4601",
          "text": "I feel the same. I was recruited by the data department because of some work undid for a higher level manager. I did it all with ChatGPT. Full stack web app for a data dashboard. Flask, node, react, typescript, mongo, oracle sql, ldap login with role based access controls. Tokens. All that. Nobody asked me a single coding question when i did the interview. I just answered the usual questions and then showed them how my application works. That was great because they already knew me and wanted me. If i had to leave for another data role, I‚Äôd be screwed. I have no idea how to write code without Ai.",
          "score": 3,
          "created_utc": "2026-01-17 21:58:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06mm3q",
              "author": "The-CAPtainn",
              "text": "That‚Äôs so fascinating to hear haha, you made something that was actually useful and they wanted you. That‚Äôs wholesome. Relieved to hear I‚Äôm not the only one screwed in that department haha",
              "score": 2,
              "created_utc": "2026-01-17 22:16:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o06r1u9",
                  "author": "Acceptable-Sense4601",
                  "text": "lol indeed.",
                  "score": 1,
                  "created_utc": "2026-01-17 22:38:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0aisvy",
              "author": "Wierd-Ass-Engineer",
              "text": "Happy to see someone in the same boat as me lol. Shit scared if I would be able to clear interviews when I go for a switch",
              "score": 2,
              "created_utc": "2026-01-18 14:07:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0akbm3",
                  "author": "Acceptable-Sense4601",
                  "text": "I‚Äôm just glad i do t have to look for a switch. I work in nyc government so im not going anywhere, thankfully and my salary is very nice with pension. If i went anywhere it would still be in my agency, just for more money and mostly everyone knows me so interviews are easy.",
                  "score": 1,
                  "created_utc": "2026-01-18 14:16:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzzsh7o",
          "author": "chlor8",
          "text": "I get what you mean. Honestly, I've thought about doing a few SQL and python challenges per week just to see different data problems. That's partially bc I think I get pigeonholed by my own work: same problems, same schemas, etc.",
          "score": 4,
          "created_utc": "2026-01-16 21:12:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzuvau",
          "author": "Prijent_Smogonk",
          "text": "For me, I think of AI as a tool.  I still start my research with plain old Google, because it‚Äôs fun to research and learn new things on my own.  If and only if I start getting pissed off at the thing I‚Äôm working on and am about to break it to pieces, I give in to my buddy, ChatGPT.\n\n It my be weird, but I look at Chat as a co-worker or colleague that can (and did) get me out of a lot of messes.  However, I still do refer to Google and YouTube as a first resort to try to tackle things on my own, only because when you end up figuring out a difficult problem on your own, it‚Äôs a satisfying dopamine rush.",
          "score": 4,
          "created_utc": "2026-01-16 21:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0110dr",
          "author": "KarmaIssues",
          "text": "I stopped using AI in work for this reason. \n\nI'm not degrading my skills so that I can be 5% more preoductive in a company where most of the work is non value add and I don't capture those profits anyway.",
          "score": 5,
          "created_utc": "2026-01-17 01:08:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o023mz4",
              "author": "Not-Inevitable79",
              "text": "Exactly. There's something about analyzing the problem and coming up with a solution, then doing it yourself. With AI, we're all going to be dumb in 5-10 years. I don't feel accomplished by prompt engineering. I feel accomplished by writing actual code and seeing it work.",
              "score": 2,
              "created_utc": "2026-01-17 05:24:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzshwa",
          "author": "Inevitable_Zebra_0",
          "text": "\\> Do companies still ask raw problems without letting you use AI?\n\nWe do, in our case for Databricks/Spark engineering, googling is allowed. Though, having restrictions doesn't do much - people still try to cheat by having a second monitor, you can easily tell by their eyes switching between them when typing code. So, the focus is on a candidate being able to explain their train of thought, not solve the tasks like it's a test. The first 5-10 minutes of the interview is usually enough for me to understand if the candidate has the claimed experience or not, and the remainder of the time is for digging to the boundaries of their knowledge, by asking them more and more questions.",
          "score": 4,
          "created_utc": "2026-01-16 21:12:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o007tr2",
              "author": "exjackly",
              "text": "You are the kind of person I want when I am the interviewee.  I don't claim experience I don't have, but I've switched around tools and languages at different clients enough that I do google syntax regularly (or take a stab at it and ask AI to point out the problems so I can fix them).\n\nNearly everything comes back to the same thought patterns in breaking down problems, solving each component and bringing it back together so it functions as a whole.",
              "score": 3,
              "created_utc": "2026-01-16 22:25:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00p56g",
                  "author": "Inevitable_Zebra_0",
                  "text": "\\> I don't claim experience I don't have,\n\nThis is a bigger problem now, by the way. Nowadays everyone can use AI to create perfect resumes, as a result, when picking applications, HRs can't differentiate between the liars and really capable candidates. A significant portion of the candidates I've interviewed for the last year weren't capable of being even juniors, though their resumes said they were practically seniors - 5+ years of experience in all/most tech tools listed for the job, certificates, accomplishments, etc. Imagine having a person stating they've had 5 years of experience designing SQL databases, writing procedures etc., and at the interview they don't know how to write a query to count the number of rows in a table. This takes up a lot of our time, and the experienced real candidates get drowned in this pool of fraudsters. We haven't solved this problem yet, and I'm not sure if it's even solvable.",
                  "score": 2,
                  "created_utc": "2026-01-16 23:58:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzzreaz",
          "author": "bastante_pendejeria",
          "text": "Is this a shitpost?",
          "score": 11,
          "created_utc": "2026-01-16 21:07:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzruno",
              "author": "The-CAPtainn",
              "text": "Nah üò≠",
              "score": 18,
              "created_utc": "2026-01-16 21:09:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o003f7n",
          "author": "Odd_Lab_7244",
          "text": "I am fairly new in this career ~3y but i often worry that I'm not providing enough value at work - using AI helps me produce more faster\n\nI think",
          "score": 2,
          "created_utc": "2026-01-16 22:04:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01i2ar",
          "author": "MonochromeDinosaur",
          "text": "Yes I am an AI QA developer now. That said I have a lot longer to verify the code is correct now. Which means less excuses for bugs. I used to take 80% times implementing and 20% testing now it‚Äôs 20% implementing 80% testing. \n\nI used to miss small logic bugs trying to rush work out the door that would eventually months later end in a missed edge case in a test or a bug ticket. \n\nNow I have all the time in the world to do verification it has been months since a bug came up. \n\nI do think it‚Äôs a force multiplier in the right hands. You still need subject matter experts for the time being.",
          "score": 2,
          "created_utc": "2026-01-17 02:56:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03vcl5",
          "author": "anti_humor",
          "text": "I think it depends on how you use it. Just out of habit I still do a lot of stuff myself, but I am a pretty shit coder (outside of SQL) to be honest so I do let LLMs write a lot of syntax for me and explain snippets I don't understand well enough.\n\nI think the way I'd characterize its impact on me is that I'm just as good at SQL as I've ever been, maybe a bit better, but I'm not making the progress in application coding skills that I thought I would. I'm still progressing, just not as quickly as if I had to get in reps without LLMs like in the past. I suppose if it's going to be automated anyway, as long as I keep trying to understand the business logic and what the code is doing (and whether there's a more efficient way), I should be alright.",
          "score": 2,
          "created_utc": "2026-01-17 14:11:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08tkvc",
          "author": "PickRare6751",
          "text": "We have scraped all white board coding tests in the interview process, now all questions are based on candidates‚Äô past experiences such as choice of design, the most difficult problem and solutions",
          "score": 2,
          "created_utc": "2026-01-18 05:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ai69s",
          "author": "Wierd-Ass-Engineer",
          "text": "I feel the same way. As many people suggested, I am new to coding with around 3yoe and don't blindly copy paste AI responses or snippets I rather use it like a non-judgemental colleague. I try to understand what the solution is and ask for explanations when I don't or even brainstorm with AI on what my thought process is on the solution. Even then I still feel myself getting blanked out when trying to code from scratch. I can create the approach but get confused on implementation without AI. Even though I can do my job, this makes me really anxious as to whether I will be able to clear interviews",
          "score": 2,
          "created_utc": "2026-01-18 14:04:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e0x9m",
              "author": "The-CAPtainn",
              "text": "Yeah clearing interviews is the main thing. Endeavoring to add a whole new attribute to my identity (solving problems with memorized syntax) is just the cost of the job hunting game, which I guess is totally different from actual work life.",
              "score": 1,
              "created_utc": "2026-01-19 00:32:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzumdu",
          "author": "Smart_Department6303",
          "text": "i have written the cloud infrastructure for 2 startups valued at millions of dollars. I have not written a single line of code for the last 6 months. It was all Claude Code with me reviewing it and telling it to rewrite and test a bunch of times. It's actually crazy. I look at code all day but did not write any of it. Sometimes it writes truly horrible code like having imports inside of functions and I course correct it.",
          "score": 3,
          "created_utc": "2026-01-16 21:22:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzz79u",
              "author": "Braxuss_eu",
              "text": "Are you sure it would take you longer to actually write the code only asking for help when you need it? I feel that sometimes AI helps me a lot and other times it takes me a long time to find all the bug it created and make it fix the bad practices and spaguetti code and it would have taken me less time to code it myself. But I don't know what will happen until it's already happening and my time is already wasted. I think I have to be better at deciding what to do myself and what to delegate to AI. I think the best way to use it \"give me an example of how to do this\" and then adapt it myself, so I don't lose track of the code and there are not bugs that are not my own.",
              "score": 3,
              "created_utc": "2026-01-16 21:43:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00lphy",
                  "author": "Smart_Department6303",
                  "text": "Yes 100% but I think I use it differently to most people. I usually spend an hour drafting a super detailed plan and a detailed testing plan before even proceeding and obviously I have my CI/CD testing pipelines all set up. Git workflow that sort of a thing. When Claude Code (I have the most expensive subscription whatever that is) executes the plan it probably does 3 weeks of work in a few days, deploys it, tests it, etc. It's actually ridiculous because I'm working on cutting edge stuff. Large scale data pipelines, site to site vpn connections between on premise and cloud accounts, etc. I'm also running multiple agents at the same time. Like I said it's been 6 months of this and I took a startup from nothing to MVP to 25 corporate customers like it was nothing.",
                  "score": 5,
                  "created_utc": "2026-01-16 23:39:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o003xc4",
                  "author": "Odd_Lab_7244",
                  "text": "I think you could be right. Started using agentic mode in last 2 months - couldn't say for 100% sure that I'm moving faster with it",
                  "score": 3,
                  "created_utc": "2026-01-16 22:06:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzzvx44",
          "author": "dorkyitguy",
          "text": "Nope. I won‚Äôt use AI for coding. You lose your skills when you don‚Äôt use them. This applies to anything and I see it frequently with people who use AI a lot. All of a sudden people can‚Äôt handle simple problems they used to be able to do in their head or on the back of a napkin.¬†\n\nThe rest of you can use AI. I‚Äôll be here when you need someone who knows how your systems actually work.¬†",
          "score": 7,
          "created_utc": "2026-01-16 21:28:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzxaqj",
              "author": "living_direction_27",
              "text": "I rely a lot on AI, and you are absolutely right!",
              "score": 7,
              "created_utc": "2026-01-16 21:34:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzxyyj",
              "author": "Pale_Squash_4263",
              "text": "Same here, I‚Äôve seen a lot of posts like these and I‚Äôm not interested in my skills atrophying over time",
              "score": 6,
              "created_utc": "2026-01-16 21:37:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0071ab",
              "author": "exjackly",
              "text": "I absolutely use AI for coding, but under strict direction.  I don't give it a big general idea to solve.  Vibe coding isn't the answer except for long term employment.\n\nBut, I will give it specifics and let it generate the tedious part - field lists, generating a skeleton API call and other boilerplate.  \n\nAnd I review every line of code as if I wrote it when I first graduated from college.  I still know my systems inside and out.  But I only write about 1/3 of what I used to, including the amount I have to type for my prompts.",
              "score": 3,
              "created_utc": "2026-01-16 22:21:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00t89l",
                  "author": "ScottFujitaDiarrhea",
                  "text": "Same. I‚Äôm very specific and iterative when I use AI that a lot of times I feel like I‚Äôm almost pseudo-coding lol",
                  "score": 1,
                  "created_utc": "2026-01-17 00:22:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0043bp",
              "author": "kthejoker",
              "text": "Typing in and remembering syntax is the least valuable part of our job.",
              "score": 2,
              "created_utc": "2026-01-16 22:07:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o00zxzc",
              "author": "earlandir",
              "text": "Exactly! I still don't use a calculator for the same reason. Once you rely on it you start getting super rusty whenever you need to do any sort of computation by hand.",
              "score": 1,
              "created_utc": "2026-01-17 01:01:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzrwsm",
          "author": "Senior_Plastic_95",
          "text": "ya a lot of things are out hte window using AI now. It's just about asking the right questions, understanding the process and it does everything for you. I'm a DevOps wizard now.",
          "score": 2,
          "created_utc": "2026-01-16 21:09:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzvirc",
          "author": "zazzersmel",
          "text": "Yes but not like that. Have a 3 year old son and my wife's chronic health problems have progressed over the last few years. Life is a constant struggle and it seems employers are less and less sympathetic. The world kinda sucks.",
          "score": 2,
          "created_utc": "2026-01-16 21:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzxunv",
          "author": "SQLofFortune",
          "text": "Personally I hate AI lol so I just do most things myself. I‚Äôll ask it for advice on how to approach a problem but that‚Äôs about it.",
          "score": 2,
          "created_utc": "2026-01-16 21:37:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o001kjt",
          "author": "Odd_Lab_7244",
          "text": "This question is bugging me too",
          "score": 1,
          "created_utc": "2026-01-16 21:55:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00e2zx",
          "author": "Certain_Leader9946",
          "text": "I think the future of development is to use AI to power the creation of independent tools",
          "score": 1,
          "created_utc": "2026-01-16 22:57:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00l1cl",
          "author": "alien_icecream",
          "text": "A single prompt can generate a week‚Äôs worth of AI slop. I wonder how anyone who wants to review the code (intending to learn) can do so in a realistic time frame.",
          "score": 1,
          "created_utc": "2026-01-16 23:35:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00utqw",
          "author": "wildthought",
          "text": "There is definitely a tradeoff.  Our species is defined by our ability to make and use tools. This is just the latest tool. I do feel more productive in terms of my output.  I reason we must be going through a similar experience to losing the muscle memory of calculating math in your head, once the world relied on calculators.",
          "score": 1,
          "created_utc": "2026-01-17 00:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0137ev",
          "author": "IAMHideoKojimaAMA",
          "text": "Yea but you can cheat with AI during interviews. Well remote jobs anyways. And yes I still get grilled all the time on stuff. I mean I guess it makes sense but if I can solve their questions in seconds with ai then maybe their questions are useless. But it's the game you play....",
          "score": 1,
          "created_utc": "2026-01-17 01:22:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01kleb",
          "author": "YaBoiAIML",
          "text": "Your skills will atrophy into uselessness until you get wholly replaced by Grok",
          "score": 1,
          "created_utc": "2026-01-17 03:12:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01lzou",
          "author": "pottedPlant_64",
          "text": "Idk, I spent time learning something new and making it happen. When I needed python glue, AI knocked it out for me.",
          "score": 1,
          "created_utc": "2026-01-17 03:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o027kqc",
          "author": "Schtick_",
          "text": "I mean you need to know the fundamentals to use the ai well, but if you don‚Äôt know how to use ai for data engineering then I‚Äôm not hiring you.",
          "score": 1,
          "created_utc": "2026-01-17 05:55:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0281px",
          "author": "Wojtkie",
          "text": "I was feeling this way, so I ended up just doing some leet code in my spare time to combat it.",
          "score": 1,
          "created_utc": "2026-01-17 05:59:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ihle",
          "author": "Kilnor65",
          "text": "I use it mostly for syntax such as date manipulations, as there is a lot of switching between SQL Server and Oracle. Its a faster way of googling, as Google has become useless the last few years.\n\nI might ask it \"Hey, how can I do this specific thing\", but I never ask it to build anything from the ground up. I can see a LOT of future issues if this becomes the norm.",
          "score": 1,
          "created_utc": "2026-01-17 07:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02lmkb",
          "author": "ComprehensiveRide946",
          "text": "Yes! It‚Äôs starting to concern me if I‚Äôm honest. I‚Äôve been a dev for 15 years so I know what to do, but now I use AI to power through tickets faster. I always review the output and change it where necessary to ensure its production grade. I think the key thing is I know what to ask the model and even if it gives me a working solution, I still know what it needs to be more robust and of production quality. I know what it should look like, but I worry I‚Äôd struggle to do it on my own without AI now? Plus I think as well, the extra effort and time it would take to do it on my own and to cover all edge cases when when I know AI can probably smash out 80% of it in minutes rather than taking me a day or so.",
          "score": 1,
          "created_utc": "2026-01-17 07:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02olei",
          "author": "Emergency_Egg_4547",
          "text": "I felt the same way and that is why I actively reduce my use of AI. I only try to use it for repetitive shallow tasks like fixing downstream DBT models after a column change or updating documentation.",
          "score": 1,
          "created_utc": "2026-01-17 08:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02orag",
          "author": "Think3r_reddit",
          "text": "Studies with children show that they can learn faster with AI, but ONLY if it is used correctly. \n\nFor this reason, I try not to let AI solve problems for me. First, I devise an approach myself. Then, I use AI as a tutor who asks questions. A tutor guides me toward a solution. A tutor wants me to solve the problem on my own, as this significantly increases memory retention. All while working more efficiently! \n\nNow, if I'm wrong about my approach, I learn even more thanks to the neuroplasticity-facilitating neurotransmitters released when I'm wrong!\n\nDon't ask AI to solve your problems.  \nAsk AI to GUIDE you in solving your problems.",
          "score": 1,
          "created_utc": "2026-01-17 08:27:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02w987",
          "author": "Ok_Tough3104",
          "text": "use ai.\n\nread a book at home, or at work, while ai is doing the work.\nyou won't lose shit.\n\nyour ai is just solving boring shit for you or repetitive tasks. As long as you're guiding it in solving the problem then u're doing well.",
          "score": 1,
          "created_utc": "2026-01-17 09:38:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o030iij",
          "author": "armyknife-tools",
          "text": "AI is like a drug. It makes you feel like you can do anything. Your brain actually turns to mush. Soon nobody will be able to do tech work. I‚Äôm trying to solve this problem. Reach out if you want to test something truly innovative.",
          "score": 1,
          "created_utc": "2026-01-17 10:19:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03jyx7",
          "author": "Expensive_Culture_46",
          "text": "Sort of related. I think AI is helpful as a really good search terminal. I use it to help get potential solutions such as how to unpivot like 13 columns without just doing ‚Äúunpivot‚Äù over and over and over. It had some terrible suggestions and then a good one. \n\nWhat is really creeping me out is seeing companies use AI to fully write contracts for engineering work without actually looking at what it said. So now I am having to argue with the CEO that it is not reasonable to promise 30 pipelines into a data lake and into gold tables in 3 weeks with 0.5 engineers. Sure AI can reduce the manpower needed or hours but it doesn‚Äôt remove the dependencies that inevitably screw everything up. \n\nI‚Äôm about to bounce this place because this man is going to get us into a lawsuit for breach of contract real fucking fast. He‚Äôs having Claude make manpower estimates as well‚Ä¶. Then he was confused that it showed 1.5 for the number of engineers\n\nI think a lot of engineering teams are about to experience this more broadly. Who needs a senior manager when you can just use AI to spit out insane timelines and estimates?",
          "score": 1,
          "created_utc": "2026-01-17 13:02:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o044ca5",
          "author": "reditandfirgetit",
          "text": "I only use AI as an acceleration tool, not for every task. I would be bored if I did that. Just because you can doesn't mean you should\n\nYou need to know what you're talking about in an interview, no AI",
          "score": 1,
          "created_utc": "2026-01-17 14:59:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04e961",
          "author": "Icy_Clench",
          "text": "I find AI useful to summarize information but I have to argue with it when trying to actually code because of constant hallucinations, outdated information, or just bad brittle approaches to code.  It literally told me SQL doesn‚Äôt have transaction control yesterday.\n\nThe AI does what you ask it and that is part of the issue. You can give it context like ‚ÄúI‚Äôm trying to ingest data for an SCD2 pattern‚Äù but it‚Äôs not going to back up and ask why SCD2. It won‚Äôt ask you what the project is, goals are, requirements, your other tools in the platform, your team, and so on. If CDC was actually needed you‚Äôd have no idea because it would never guide you to that discussion.",
          "score": 1,
          "created_utc": "2026-01-17 15:48:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06jaef",
              "author": "Acceptable-Sense4601",
              "text": "I think prompting is the issue. When i approach a coding issue i will tell it what i want to do then asking if there is a better way. Then we get to coding.",
              "score": 0,
              "created_utc": "2026-01-17 21:59:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0651nc",
          "author": "23_jordan23",
          "text": "My suggestion is there is no harm in using AI but to keep up with the trends, always attempt to solve the problem on your own the first time.\n\nTyping, drawing diagrams and doing dry runs.\n\nYou can take that to AI to structure it for you but this will be better way and you would actually build on top of what you know.",
          "score": 1,
          "created_utc": "2026-01-17 20:47:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06r1vq",
          "author": "trappedinab0x285",
          "text": "Do you think the first \"computers\" (people who were doing the calculations) were thinking the same when they started to get substituted by the first machines?\n\nPersonally, I find it more empowering rather than belittling, I use AI every day and try to understand and assess the solution it gives me. I have started to learn a bit of prompt engineering to use natural language to guide it programmatically...\n\nThe tests for jobs will just evolve, you need to evolve as well and stop being crystallized in your old ways of doing things, specific tools or languages\n\nWhat counts is more your sense of logic and abstraction and your care for your job and your colleagues. Perhaps use your free time acquired via AI to attend a course in maths or philosophy or something that engages your brain directly. Keep yourself sharp and you will be able to tackle future challenges and perhaps reinvent yourself.\n\nNo reason for being scared of change, it is just inevitable.",
          "score": 1,
          "created_utc": "2026-01-17 22:38:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09nii1",
              "author": "Skualys",
              "text": "Well I agree on the fact we need to evolve around new possibilities and elaborate new methods.\n\nBut two things :\n- I see it in education where students have difficulties to concentrate and progress due to the use of AI as a substitute to thinking. Understand a book, what is written between the lines, use your imagination is just replaced by \"write me a summary like a B- student would do it\".\n- I'm not sure we will get more free time. During a transition time there will be more unemployment, and people with a job asked to produce more than before.",
              "score": 1,
              "created_utc": "2026-01-18 10:03:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o080ebk",
          "author": "Useful-Goose-1656",
          "text": "I'm actually more curious on your workflow because it seems you have it automated already.",
          "score": 1,
          "created_utc": "2026-01-18 02:36:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09ilvk",
          "author": "dataflow_mapper",
          "text": "You are definitely not alone in feeling this. I think a lot of people are quietly shifting from memorizing syntax to being good at framing problems and spotting bad solutions. Interviews are still mixed though. Some places absolutely still ask raw SQL or Python on a whiteboard, others care more about how you reason and explain tradeoffs. What helps me is occasionally doing something small without AI on purpose, like writing a query or script from scratch just to prove I still can. Using AI daily does not erase skill, but it can dull recall if you never exercise it. The upside is you probably understand systems and intent better than you realize, which is harder to fake than syntax.",
          "score": 1,
          "created_utc": "2026-01-18 09:18:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09jnql",
          "author": "Skualys",
          "text": "We are a SQL (dbt) shop and I'm still looking for the use or AI. For sure to easily get some syntax, convert between formats, all silly tasks, it's useful.\n\nBut still 80% of my work is to understand business needs and understand how to get it from the source (which is a old ERP with customised tables usually without enforced PK). And I don't know how AI can help here (I have a basic data dictionary which give hints but the true meaning of fields is in the head of people).\n\nWriting SQL is so easy that I would lose time to ask AI to write it for me / review it (it already took me more time to write the Jira than to do it). And when I used it for complex tasks (like writing a macro that generate SQL query to join   SCD2 tables together with possible hierarchy structures, it failed, and I ended writing a recursive macro). \n\nA field where I find it really useful is to build simple tooling (VS code expansion for dbt, CRUD applications on top of Snowflake...) where I can build things I wouldn't be able to before.",
          "score": 1,
          "created_utc": "2026-01-18 09:28:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o001epc",
          "author": "Maiden_666",
          "text": "OP I‚Äôm with you, I feel the same way. I am using Cursor to solve all my tickets. I‚Äôm able to accomplish a lot more now but I‚Äôm scared to give interviewed because my I‚Äôm barely writing SQL queries or Python code anymore.",
          "score": 1,
          "created_utc": "2026-01-16 21:54:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o002erx",
          "author": "Uncle_Snake43",
          "text": "I use AI for literally everything and there is no putting the toothpaste back in that tube lol",
          "score": 1,
          "created_utc": "2026-01-16 21:59:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o000mxi",
          "author": "FlowOfAir",
          "text": "Impossible. If I don't know what the AI is doing and I'm unable to debug the query or the code, then I'm worthless as an engineer.",
          "score": 0,
          "created_utc": "2026-01-16 21:50:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0013io",
          "author": "AppleAreUnderRated",
          "text": "Uhh nope lol",
          "score": -1,
          "created_utc": "2026-01-16 21:52:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbrhgn",
      "title": "Im Burnt Out",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qbrhgn/im_burnt_out/",
      "author": "shittyfuckdick",
      "created_utc": "2026-01-13 13:36:33",
      "score": 120,
      "num_comments": 91,
      "upvote_ratio": 0.96,
      "text": "My company had a huge amount of layoffs last year. My team went from 4 DEs to 2. Right now the other DE is on leave and its just me. \n\nThe amount of work hasnt changed and theres a ton of tribal business logic I never even learned. Every request is high priority. We also merged with another company and the new cto put their data person in charge. This guy only works with SSIS and we are a python shop. He also hates python.\n\nIm completely burnt out and have been job hunting for months. The market is ass and I do 2-3 rounds of interviews just to get ghosted by so no name company. Anyone else in a similar boat? Im ready to just quit and chillax ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qbrhgn/im_burnt_out/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzd0yp0",
          "author": "MikeDoesEverything",
          "text": ">This guy only works with SSIS and we are a python shop. He also hates python.\n\nMost people who love SSIS absolutely hate Python.  It's a really sad trend.",
          "score": 78,
          "created_utc": "2026-01-13 14:57:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd1hrm",
              "author": "shittyfuckdick",
              "text": "I come from SSIS and i hated it so much i learned python",
              "score": 62,
              "created_utc": "2026-01-13 15:00:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzdqyuh",
                  "author": "intrepidbuttrelease",
                  "text": "Christ SSIS is miserable when youre figuring out what broke in some 10 year old operational process. We're fortunately moving into the Py world where I am now however our stack is a data swamp of all sorts of shit, its been a mortal 6 months here since the guy who architected most of these systems left. I feel your post to my core.",
                  "score": 11,
                  "created_utc": "2026-01-13 17:09:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzd21so",
                  "author": "MikeDoesEverything",
                  "text": "I'm not surprised.  I started with Python and whilst I get SSIS has it's place, it's not really for me.  Very finicky overall and, unfortunately, pretty much part of the furniture in some companies so quite literally irreplaceable.",
                  "score": 17,
                  "created_utc": "2026-01-13 15:03:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzd476r",
                  "author": "Nekobul",
                  "text": "Can you elaborate why so much hate for SSIS?",
                  "score": 0,
                  "created_utc": "2026-01-13 15:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzd2nac",
              "author": "JBalloonist",
              "text": "Never heard anything good about SSIS except from people that have worked exclusively with Microsoft products their entire career.",
              "score": 11,
              "created_utc": "2026-01-13 15:06:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzd31rt",
                  "author": "MikeDoesEverything",
                  "text": "With this level of SSIS slander, we are one SSIS package away from summoning the wrath of u/Nekobul.",
                  "score": 10,
                  "created_utc": "2026-01-13 15:08:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzd5196",
                  "author": "Nekobul",
                  "text": "The reality is SSIS is still the best ETL platform on the market. There is nothing remotely close that can compete with it.",
                  "score": -6,
                  "created_utc": "2026-01-13 15:17:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzd4w4g",
              "author": "Nekobul",
              "text": "No hate with me. However, I definitely believe there is a paid trend to try to move as many people as possible to coded solutions which is not exactly the future of the data engineering, but more \"cry of the past\" approach.",
              "score": 0,
              "created_utc": "2026-01-13 15:17:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzdgtsd",
                  "author": "yorkshireSpud12",
                  "text": "Why would there be a paid trend towards coded solutions? Surely the trend would be the opposite to attempt to vendor lock your solutions and make migrations very difficult and therefore not worth it (i.e. SSIS and other GUI based tools).",
                  "score": 12,
                  "created_utc": "2026-01-13 16:12:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzcz70r",
          "author": "codykonior",
          "text": "Condolences. How old are you?\n\nOne of two things are going to happen. You burn out / fall ill from stress / purposefully injure or kill yourself, and they fire you because you're now worthless to them.\n\nOr you purposefully choose to recognise your limits, say a hard no to any work outside your capacity, knowledge, or schedule, and what happens happens. Maybe they'll ease up. Maybe they won't care and will still burden you and blame you and fire you after. But you'll be working 9-5, have your dignity, they'll suffer the consequences of their bad management (which is satisfying), you won't end up sick or dead, plus they would have fired you anyway. \n\nYoung people typically fall into that first category. Older workers have been through that before and live according to the second category.",
          "score": 54,
          "created_utc": "2026-01-13 14:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd09k1",
              "author": "shittyfuckdick",
              "text": "Dude i would just quit before i ever thought of harming myself over a 9 to 5. i log off at 5 everyday and tell my company the solution isnt to work me harder i need a team. however that doesnt mean they dont try to give me an insane workload still",
              "score": 39,
              "created_utc": "2026-01-13 14:54:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzd3yxl",
                  "author": "sephraes",
                  "text": "If you have your limits and are already working an 8 or 9 hour day and they aren't doing anything substantial (i.e. threatening firing), then it sounds like you already have the solution.¬†\n\n\nCare about the stuff you can do. Don't care about the stuff you don't have time for after the day is over. Pick up next day. Set actual priorities with your management. And not the \"everything is a priority' type. It's not your fault they mismanaged the team down to effectively one person. Keep looking for another job, but control your controllables and everything can kick rocks.",
                  "score": 14,
                  "created_utc": "2026-01-13 15:12:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzq93nb",
              "author": "Tiny_Studio_3699",
              "text": "Great advice",
              "score": 3,
              "created_utc": "2026-01-15 14:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqi8z6",
                  "author": "codykonior",
                  "text": "I think so. I've seen quite a few people burn out and hurt themselves. When I was young I wondered why my seniors were so guarded and slow moving. Now I know - and if anything treatment of workers has gotten even worse than in their time!",
                  "score": 2,
                  "created_utc": "2026-01-15 14:48:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzd2ho2",
          "author": "T3quilaSuns3t",
          "text": "SSIS people hate python. \n\nPython people hate SSIS.\n\nUI vs code \n\nLol classic",
          "score": 22,
          "created_utc": "2026-01-13 15:05:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzem8zm",
              "author": "po1k",
              "text": "IMHO, ssis is abomination from day 1. Can be handy in the right hands though. Although it's obsolete many years already. Python is a general purpose.  These are different things, and must not be compared.",
              "score": 4,
              "created_utc": "2026-01-13 19:31:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzd4k5q",
              "author": "Nekobul",
              "text": "I don't hate Python just like I didn't hate Perl which was the language Python did in fact replace for doing data processing and reporting in the past. I just think using a visual development technology is more appropriate for the task at hand. Not mindless coding.",
              "score": 6,
              "created_utc": "2026-01-13 15:15:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzdbpyd",
                  "author": "shittyfuckdick",
                  "text": "Its not mindless it gives you finer control of the logic. GUIs just obfuscate that logic which is fine when your pipelines arent that complex.¬†",
                  "score": 13,
                  "created_utc": "2026-01-13 15:49:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzd2kog",
          "author": "venky_LM",
          "text": "Apparently it‚Äôs more common than you think these days. It‚Äôs really bad management from your boss and upper management. Sadly you don‚Äôt have much option here, either jump ship or bring this up in every 1:1 I guess. If possible name drop your company or at least a hint so fellow engineers can stay away. ‚úåÔ∏è",
          "score": 6,
          "created_utc": "2026-01-13 15:05:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd5h3s",
          "author": "Material-General5640",
          "text": "If your financial situation is not dire, my recommendation would be to enforce boundaries and deliver at a pace that‚Äôs reasonable for you. If it is dire, then you might have to weigh mental health vs financial health. That varies from person to person. If it were me, I‚Äôd enforce boundaries regardless.\n\nIn the meantime, try to apply for jobs elsewhere. The market is bad, but it‚Äôs not totally hopeless for mid to senior DEs.",
          "score": 5,
          "created_utc": "2026-01-13 15:19:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcpqgm",
          "author": "ActEfficient5022",
          "text": "Does sound like quite a flashing alarm situation. Good for you to be searching. I say keep it up. At least you have a job right now so just use this time to stay on top of things, learn some of that tribal knowledge and focus the most of your energy on the job search. Could take several months more but that's ok.",
          "score": 5,
          "created_utc": "2026-01-13 13:59:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfk52s",
          "author": "DiabolicallyRandom",
          "text": "I mean, most people don't love their jobs. This is a factual statement.  At some point, you learn that unless you are a lucky one, you're never going to be truly satisfied in this society.\n\nI clock in. I do some work. I clock out. The moment I lock my computer, work is no longer close to my mind.\n\nWork-life separation is the biggest thing you can do for yourself.\n\nBy all means look for a better job, but the job is just a means to an end. You need money to live life, so you sell some time to someone to get money, and that time is used.\n\nUnless you're being emotionally, physically, or ethically abused, turning off work and just not caring about the company or what happens should be the focus.\n\nThey don't care about you. Not really. Individual people might, but the company doesn't.",
          "score": 4,
          "created_utc": "2026-01-13 22:08:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcmc1o",
          "author": "joins_and_coffee",
          "text": "im sorry to hear that man, hope your situation with that gets better though, im sure your talented and can find something new soon if you wanted to",
          "score": 8,
          "created_utc": "2026-01-13 13:40:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd8a5v",
          "author": "AppleAreUnderRated",
          "text": "You‚Äôll find something new just takes time sometimes",
          "score": 3,
          "created_utc": "2026-01-13 15:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzczdl7",
          "author": "haseeb1431",
          "text": "Since you are about to quit, I would give one try to communicate the same with the leadership that how are you feeling about the work environment and you cannot sustain this long term and we need to fix it before I am forced to give up.",
          "score": 5,
          "created_utc": "2026-01-13 14:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd0flq",
              "author": "shittyfuckdick",
              "text": "i make it very well known how i feel",
              "score": 3,
              "created_utc": "2026-01-13 14:54:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzd092n",
          "author": "MissingSnail",
          "text": "You had an offer on your other thread, why don‚Äôt you go?",
          "score": 4,
          "created_utc": "2026-01-13 14:53:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd0kmm",
              "author": "shittyfuckdick",
              "text": "No offer yet just in the final stages. Wanted to make sure Im taking something good and not trying to just jump ship.¬†",
              "score": 4,
              "created_utc": "2026-01-13 14:55:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzctjdx",
          "author": "Atticus_Taintwater",
          "text": "Good luck man, good that you are actively looking\n\n\nThat situation is not going to get better",
          "score": 2,
          "created_utc": "2026-01-13 14:19:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd2vlf",
          "author": "HD_VE",
          "text": "Was in the same boat some months ago, though I was the only DE in the team, only solution was to move and even after that I asked for a week off in my new role to let the burnout leave",
          "score": 1,
          "created_utc": "2026-01-13 15:07:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgnmzk",
          "author": "Immediate-Pair-4290",
          "text": "If there is one thing I have learned it is to reject unpaid overtime. As long as you do your best with the 8 hours you are required to work push back on their unreasonable expectations. You are literally the only data engineer on payroll. They cannot afford to have no team. Offer to convert to a contractor so you can work 10-12 hours and get paid for the extra need. But do not do it for free.",
          "score": 1,
          "created_utc": "2026-01-14 01:39:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn220d",
          "author": "Outrageous-Owl1617",
          "text": "Take help from models ,",
          "score": 1,
          "created_utc": "2026-01-15 00:13:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp0lx3",
          "author": "PickRare6751",
          "text": "Same, my manager offshored all data analysts to India, they sit in a different time zone and rely on very explicit instructions, while I have to wear the hat of pm, ba and de",
          "score": 1,
          "created_utc": "2026-01-15 08:10:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpsxb8",
              "author": "shittyfuckdick",
              "text": "Dude that sucks. When ever i have to work with Indians theyre extremely incompetent and hard to communicate with.¬†",
              "score": 0,
              "created_utc": "2026-01-15 12:23:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp3chp",
          "author": "96TaberNater96",
          "text": "Then there is people like me who volunteer to work for free and still can't even get an email back.",
          "score": 1,
          "created_utc": "2026-01-15 08:37:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpszss",
              "author": "shittyfuckdick",
              "text": "Send me your resume if you want to work at this shit hole for free¬†",
              "score": 2,
              "created_utc": "2026-01-15 12:24:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsguoy",
          "author": "Difficult_Paint3162",
          "text": "Old saying, \"When everything is a priority, then nothing is a priority\"   When you are assigned a bunch of high priorities tasks, give them a reasonable estimate as to which ones you can accomplish in a X hour day.  (Say I can complete 3 of these 6, which ones should I focus on).   This should help them better plan than simply dumping on you to pressure you to complete them all.    After all, if just you, what would the company do if you leave?",
          "score": 1,
          "created_utc": "2026-01-15 20:08:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzco32z",
          "author": "EmotionalSupportDoll",
          "text": "At least you have 2",
          "score": -6,
          "created_utc": "2026-01-13 13:50:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcowvy",
              "author": "shittyfuckdick",
              "text": "Maybe reread¬†",
              "score": 0,
              "created_utc": "2026-01-13 13:54:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzctdbl",
          "author": "NoleMercy05",
          "text": "Standard OPs",
          "score": -4,
          "created_utc": "2026-01-13 14:18:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcthes",
              "author": "shittyfuckdick",
              "text": "What does this mean?",
              "score": 5,
              "created_utc": "2026-01-13 14:19:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdh5me",
      "title": "Data team size at your company",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qdh5me/data_team_size_at_your_company/",
      "author": "molkke",
      "created_utc": "2026-01-15 11:32:40",
      "score": 92,
      "num_comments": 83,
      "upvote_ratio": 0.97,
      "text": "How big is the data/analytics/ML team at your company? I'll go first.\n\nCompany size: *\\~*1800 employees  \n  \nData and analytics team size: 7.   \n3 internals and 4 externals with the following roles:  \n1 Team lead (me)  \n2 Data engineers  \n1 Data scientist.  \n3 Analytics engineers (+me when i have some extra time)\n\nMy gut feeling is that we are way understaffed compared to other companies.\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qdh5me/data_team_size_at_your_company/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzpot7m",
          "author": "Odd-String29",
          "text": "250 employees\n\nTeam size: me",
          "score": 103,
          "created_utc": "2026-01-15 11:53:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuzwfr",
              "author": "SparkOrigin",
              "text": "![gif](giphy|l5s71uAp3CzKwxwkoZ|downsized)",
              "score": 5,
              "created_utc": "2026-01-16 04:05:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o05sr3e",
              "author": "JBalloonist",
              "text": "Same\n\nEdit: there are some people learning Power BI for the visualization  side, but it‚Äôs going to be a while before they are completely independent",
              "score": 1,
              "created_utc": "2026-01-17 19:44:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpmqjs",
          "author": "Eightstream",
          "text": "My feeling is that analytics staffing has more to do with the type of business than the number of employees",
          "score": 95,
          "created_utc": "2026-01-15 11:36:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzptxc9",
              "author": "molkke",
              "text": "Good point. Should have included that in the question... In our case both manufacturing and global sales",
              "score": 9,
              "created_utc": "2026-01-15 12:30:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpmxcz",
          "author": "Sensitive-Sugar-3894",
          "text": "It depends on the demand and how stable is the system. I joined my current company 1y ago and we were 4 DE + 4 DA, besides BAs, Tech Lead, and PM. We progressed and the systems are much more stable, lost 2 DE and 1 DA and doing alright.",
          "score": 23,
          "created_utc": "2026-01-15 11:38:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpu17t",
              "author": "molkke",
              "text": "And how big is your company?",
              "score": 3,
              "created_utc": "2026-01-15 12:31:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzq72ao",
                  "author": "Sensitive-Sugar-3894",
                  "text": "Between 2 and 3k people. 10% engineers.",
                  "score": 4,
                  "created_utc": "2026-01-15 13:50:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzppf3h",
              "author": "Tape56",
              "text": "So you didn‚Äôt end up finding more new development  / value creation related work for those engineers that got freed up since the system became more stable?",
              "score": 5,
              "created_utc": "2026-01-15 11:57:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzq6uip",
                  "author": "Sensitive-Sugar-3894",
                  "text": "Actually we are refactoring the legacy piplines (gradually replacing old). The new demands are under control.",
                  "score": 3,
                  "created_utc": "2026-01-15 13:49:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpnxal",
          "author": "Froozieee",
          "text": "That‚Äôs crazy. At my current org of ~300 I am the data team in its entirety, but at my previous job (gov agency of ~4000) there was a core DE team of 5, and then about 60-70 other dedicated analytics staff distributed throughout different business units in the agency, not counting our GIS teams which comprised another 3 engineers and about 30 analysts/DS staff. \n\nThis ratio of analytics staff to core DE staff definitely was not ideal - DE bandwidth ended up constantly being a blocker for analytics.",
          "score": 19,
          "created_utc": "2026-01-15 11:46:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpvb5s",
              "author": "Soggy_Data7710",
              "text": "Ugh... I feel your pain with your current role. At least with a small team you can maintain morale a bit but when you are alone the responsibility can be brutal",
              "score": 6,
              "created_utc": "2026-01-15 12:40:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs8mc6",
              "author": "psuku",
              "text": "Hmm, this could also mean that your org is not data driven",
              "score": 3,
              "created_utc": "2026-01-15 19:31:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzqkl1b",
              "author": "vikster1",
              "text": "say what. please elaborate on 60-70 analytics staff. what industry?",
              "score": 2,
              "created_utc": "2026-01-15 14:59:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsuspb",
                  "author": "Froozieee",
                  "text": "Primary sector. The agency as a whole was very science-driven which was quite unusual and cool, and meant that there were a lot of fairly highly data-literate staff. There are a lot of analytics/modelling use cases when you‚Äôre responsible for cross-sector policy and/or ops for forestry, fisheries, agriculture, food safety, biosecurity, and a bunch of other stuff.",
                  "score": 3,
                  "created_utc": "2026-01-15 21:13:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpvkls",
          "author": "Lurch1400",
          "text": "150 employees, 5-person data team.\nHard to say who has what role, we all do a bit of everything",
          "score": 11,
          "created_utc": "2026-01-15 12:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpti57",
          "author": "Edd037",
          "text": "Org of 10,000 people.\n\nCentral data team of 10 engineers, 30 analysts, 5 scientists, 20 data managers/admins/cleaners. \n\nA number of analysts also embedded in business teams.",
          "score": 10,
          "created_utc": "2026-01-15 12:27:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpnmlp",
          "author": "thnd23x",
          "text": "Currently, two data engineers and one team lead. It is a mixed role when you work on everything. It is the smallest team I have ever worked for.",
          "score": 7,
          "created_utc": "2026-01-15 11:44:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpu4q7",
              "author": "molkke",
              "text": "And how big is the company you work for?",
              "score": 2,
              "created_utc": "2026-01-15 12:32:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzqvt2d",
                  "author": "thnd23x",
                  "text": "~300 people B2B fintech",
                  "score": 2,
                  "created_utc": "2026-01-15 15:52:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpu7gi",
          "author": "erdmkbcc",
          "text": "If you have a good data architecture, good semantic and metric layer, i think that size enough for your company, most company's data teams has a huge tech debts bad practices decentrilized garbage lakehouses, and they have huge data team for paying the tech debts which created by bad managers, and that teams manages like dashboard factories without any data infra/arch conceptual design",
          "score": 8,
          "created_utc": "2026-01-15 12:32:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqyciy",
              "author": "molkke",
              "text": "We are working on reducing the amount of platforms and thereby also the tech debt. Ditching redundant Qlik in favor for Power BI and ditching ADF+SQL to consolidate with the rest of our pipelines in Azure Databricks. \n\nManagement hates it because they cant get their new reports while we are occupied with this but they seem to trust my decision.",
              "score": 3,
              "created_utc": "2026-01-15 16:03:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpvrtq",
          "author": "FX-126",
          "text": "Nearly everyone at my company does data eng or data science because that's what the company does.\n\nAs for my team, it used to be me and 5 other data engineers spread out across the US but they all got laid off and no I have 4 offshore replacements.\n\nI need a new job.",
          "score": 6,
          "created_utc": "2026-01-15 12:43:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzprfs5",
          "author": "dragonnfr",
          "text": "7.3 internals? That's brutal. Automate what you can - your team's stretched too thin.",
          "score": 4,
          "created_utc": "2026-01-15 12:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpsqy6",
          "author": "Latter-Corner8977",
          "text": "~3000 employees\n7 squads each with up to two data engineers attached who fill data and analytics engineering. Supported by cloud/software engineers and a few floating data architects and test resource.\n\nThat‚Äôs just engineering. Science and analytics is its own beast.\n\nEmployee size doesn‚Äôt matter though, smaller companies can have bigger needs around data.\n\nE: previously worked for a company which employed ~50. 4 data engineers, 2 data analysts.",
          "score": 5,
          "created_utc": "2026-01-15 12:22:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpoif0",
          "author": "TatsiRedditor1337",
          "text": "Joined my current company about 2 years ago as junior DE. Current team size is a team lead (DA), 2 DE and AE. Current projects are database migration to the gcp and migration from legacy system to salesforce. Pretty hectic experience without previous knowledge about dataengineering.",
          "score": 3,
          "created_utc": "2026-01-15 11:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpuayj",
              "author": "molkke",
              "text": "And how big is the company?",
              "score": 2,
              "created_utc": "2026-01-15 12:33:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzq6x36",
                  "author": "TatsiRedditor1337",
                  "text": "Little bit over 200 employees.",
                  "score": 3,
                  "created_utc": "2026-01-15 13:49:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpta71",
          "author": "Mr_Nicotine",
          "text": "290 employees\n\n1 DE (used to be 2 + the lead)\n3 DS\n5 Analysts",
          "score": 3,
          "created_utc": "2026-01-15 12:26:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpvtwd",
          "author": "Truth-and-Power",
          "text": "F500, 10 internal 30 contract. 4 intergration, 16 modeling and analytics.¬† Rest requirements, pm, managers. No data scientists.¬† Couple other temporary teams for projects.",
          "score": 3,
          "created_utc": "2026-01-15 12:43:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq5ldy",
          "author": "big_data_mike",
          "text": "I‚Äôm at a global manufacturing company of 10,000 employees and my particular data team is 1 manager, 3 internals, 3 externals. There are other data teams in other departments. \n\nOur scope covers about 300-400 other employees. We are understaffed for what upper management wants us to do.",
          "score": 3,
          "created_utc": "2026-01-15 13:42:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq9hq4",
          "author": "SupoSxx",
          "text": "Company size: 400k+ around the world, 10k+ in my country\n\n\nData department: around 500 people",
          "score": 3,
          "created_utc": "2026-01-15 14:03:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrtpj2",
          "author": "Life_Finger5132",
          "text": "I guess my team is way better off than I thought -\n\nCompany size is roughly 70\n\nDE Team is 4 + Our Boss who is highly competent at BI tools + 3 Analysts",
          "score": 3,
          "created_utc": "2026-01-15 18:24:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzttmw6",
          "author": "pun_krock",
          "text": "2500 and 4. It's hell.",
          "score": 3,
          "created_utc": "2026-01-16 00:07:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpy2rj",
          "author": "dark_dagger99",
          "text": "Company size 150:\n\nMe (manager)\n2 data engineers \n1 data analyst \n1 junior data engineer",
          "score": 2,
          "created_utc": "2026-01-15 12:58:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpysg2",
          "author": "psgpyc",
          "text": "I work for a survey analytics company, its just 3 of us. One DA, i am analytics engineer and then a data analyst. \nWe work with many local NGOs and handle survey data from as small as 1000 responses to nation wide.\n\nWe have field coordinators who are not considered data team but they do help with data definitions, questionnaire design",
          "score": 2,
          "created_utc": "2026-01-15 13:02:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpz2x3",
          "author": "deanremix",
          "text": "1300 employees. \n\n2 Engineers. 2 dedicated Analysts. \n\nCompany refuses to hire more so we implemented Sigma Computing to reduce the need for analysts and push our semantic/gold layer to non technical users. We have around 70 active users in that platform.",
          "score": 2,
          "created_utc": "2026-01-15 13:04:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpzggd",
          "author": "silentlegacyfalls",
          "text": "400 people. Total data and tech staff:¬† 1.",
          "score": 2,
          "created_utc": "2026-01-15 13:07:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq3bzg",
          "author": "Alternative-Guava392",
          "text": "Depends on what the team does.\n\nIf your team manages the infrastructure and the analytics and also business-facing data products, maybe understaffed. \n\nIf only analytics, maybe you have a strong team. \nAs a rule of thumb, I like one product per person per quarter. \nUnless there is a huge project, in that case 2 people for the huge project per quarter.",
          "score": 2,
          "created_utc": "2026-01-15 13:29:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqwrei",
              "author": "molkke",
              "text": "We are currently streamlining our setup. Our goal is to manage Azure Databricks and Power BI only. We are currently sunsetting Qlik and ADF+Azure SQL.",
              "score": 1,
              "created_utc": "2026-01-15 15:56:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzq6y1x",
          "author": "ghostydog",
          "text": "Company size 100ish, I'm the only data-focused guy (broad data management/analysis/reporting duties, business side) with 1-2 non-dedicated devs that I can tap for help when I run into tech-side issues and they have some time to spare. I know some other teams also collect various data and run reports but as far as I'm aware those duties are spread out more widely to different people.",
          "score": 2,
          "created_utc": "2026-01-15 13:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq7j2s",
          "author": "typodewww",
          "text": "In the only jr DE out of 5 other senior engineers (2 are contractors), are BI teams are much more bigger, we only have a two person DS team I believe",
          "score": 2,
          "created_utc": "2026-01-15 13:52:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqc656",
          "author": "ToothEffective",
          "text": "I work for a bank with around 4000 back office people.\n\nThere are roughly 500 of us DA, DS, DE, MLEs and middle managers.",
          "score": 2,
          "created_utc": "2026-01-15 14:17:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqme7q",
          "author": "petandoquintos",
          "text": "260 -> 6",
          "score": 2,
          "created_utc": "2026-01-15 15:08:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqozfv",
          "author": "XXXYinSe",
          "text": "~200 people in biotech. Team size: 3 people",
          "score": 2,
          "created_utc": "2026-01-15 15:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr88j3",
          "author": "babygrenade",
          "text": "Company size: 40,000+ employees\n\nData and analytics team: ~100",
          "score": 2,
          "created_utc": "2026-01-15 16:48:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrb204",
          "author": "dodonerd",
          "text": "I think Bilbo Baggins said it best... \"I feel thin. Like butter scraped over too much bread\". Thats your team. \n\nWe're a team of 250-300 and we have 7 people in data... and even then we promote self serve. \n\nNo way you're serving that many people? What's your total addressable stakeholder volume?",
          "score": 2,
          "created_utc": "2026-01-15 17:00:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzruux5",
              "author": "molkke",
              "text": "We currently have roughly 600 BI users, capped mainly due to licensing. That cap will be removed in March, after which we expect to reach ~800 users as frontline sales gain access. Databricks users around 20 but expecting this to grow as well due to \"AI this and AI that\"\n\nHistorically, stakeholder management has frankly been chaotic, largely due to missing data ownership. The ones shouting the most got their stuff done...We are planning to channel requests via our recently assigned data domain owners instead, but this is not fully in place yet.\n\nOur main report domains today are Finance, SalesOps, Order-delivery, Service and Product Management With additional domains starting to request stuff..\n\nAnd yes, I fully agree with the Bilbo quote...",
              "score": 2,
              "created_utc": "2026-01-15 18:29:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nztz53h",
                  "author": "SmallAd3697",
                  "text": "How do you get to 20 databricks users?   Are these DE's or analysts or data scientists?  Are they in non-IT departments?\n\nDatabricks would like their product to have more visibility, and accessibility to low-code end-users.  But they are not another Fabric, by a long stretch.  Fabric is taking territory from Databricks a lot faster than Databricks is taking from Fabric.  I'm quite surprised their partnership hasn't fallen over yet",
                  "score": 1,
                  "created_utc": "2026-01-16 00:37:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzsndvb",
          "author": "haonon",
          "text": "5k employees and 100 or so in data fragmented across the business.",
          "score": 2,
          "created_utc": "2026-01-15 20:39:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt3i0g",
          "author": "dessmond",
          "text": "data heavy company w/ 7000 staff and data & analytics team of about 300 people. it's still a mess.",
          "score": 2,
          "created_utc": "2026-01-15 21:53:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt8stq",
          "author": "Ancient_Ad_916",
          "text": "200 people; \nData science; just me",
          "score": 2,
          "created_utc": "2026-01-15 22:18:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzthnbu",
          "author": "NerdasticPerformer",
          "text": "Size ~1000 employees\n\nTeam: 2\n\n1 Data Analytics Engineer (me)\n\n1 System Specialist and Staff Educator\n\nI manage the data warehouse, analytics, dashboards, AI development, predictive analytics, etc\n\nYes, technically the system specialist isn‚Äôt a data role, but our company looped us together under the Data dept, so yipee",
          "score": 2,
          "created_utc": "2026-01-15 23:03:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu1adr",
          "author": "dev_lvl80",
          "text": "Depends on how business depends on data, is not it ?\n\nFirst case: 450 engineers, 800 total employees. DE team \\~20 persons.\n\nSecond case 350 engineers, 1500+ total employees. few DE teams: 30+",
          "score": 2,
          "created_utc": "2026-01-16 00:48:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu1sd6",
          "author": "Ztino34",
          "text": "Manufacturing,~250. director of IT, 1 BA, 1 DA/DE/BA(me).",
          "score": 2,
          "created_utc": "2026-01-16 00:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu2jno",
          "author": "TimmmmehGMC",
          "text": "55k employees\n7 analyst/report specialist/DBA/pipeline developers",
          "score": 2,
          "created_utc": "2026-01-16 00:55:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu4ubk",
          "author": "Icy_Clench",
          "text": "400 employees, 3 analysts, 3 engineers and 1 manager that‚Äôs also an analyst. The other 2 engineers honestly slow everything down.\n\nWe haven‚Äôt made anything new in a year because one of the engineers is an absolute control freak wanting to custom code everything (no dlt, dbt, or sqlmesh) while simultaneously producing absolute dog water that doesn‚Äôt even work on a basic level. I found and fixed 4 of his bugs today. Dude needs to be straight up fired but the manager is afraid of hurting peoples‚Äô feelings and won‚Äôt even mention there is a problem.\n\nSo, I can‚Äôt build new stuff that actually works because he whines about being dependent on some software, and the manager refuses to let me build it because he won‚Äôt take sides and we don‚Äôt have consensus on how to proceed.",
          "score": 2,
          "created_utc": "2026-01-16 01:08:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxe3jw",
              "author": "Thinker_Assignment",
              "text": "stop i'm getting flashbacks\n\nI was on that team once. Raised to the manager, they pressed it and the engineer got offended and quit. We replaced the mess and moved on.",
              "score": 1,
              "created_utc": "2026-01-16 14:40:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvnkgg",
          "author": "siaisinthepan",
          "text": "We are an organisation of 3k people and have approximately 230 data + AI professionals",
          "score": 2,
          "created_utc": "2026-01-16 06:55:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwyird",
          "author": "headdertz",
          "text": "Employees: 16 000  \nDWH: 5 people  \nLogistics: 5 people  \nMy team: 3 people\n\n<3",
          "score": 2,
          "created_utc": "2026-01-16 13:19:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx9spi",
          "author": "NovelSine5874",
          "text": "~450 employees.¬†\n¬†Team Size: 4\n\n\n3 Data Engineers part time Analytics Engineers\n1 Full time Analytics Engineer\n\n\nBunch of people creating reports and stuff.¬†",
          "score": 2,
          "created_utc": "2026-01-16 14:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxi1e8",
          "author": "Evening_Chemist_2367",
          "text": "13,000 and your technical team is bigger than mine.  \\*whimper\\*",
          "score": 2,
          "created_utc": "2026-01-16 15:00:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy6mjy",
          "author": "dillanthumous",
          "text": "200 people 2FT and 1PT.",
          "score": 2,
          "created_utc": "2026-01-16 16:50:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzptacl",
          "author": "Turbulent_Egg_6292",
          "text": "Curious, do you thing diff stacks need diff team sizes? We are 7, and 3 of us work as data leads jointly. Mixed stacks, postgres, clickhouse, bigquery, dbt...",
          "score": 1,
          "created_utc": "2026-01-15 12:26:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqtjia",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-15 15:42:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqztin",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment was removed because it violated rule #6 (No recruiting, solicitation, or networking posts).\n\nWe do not intend for this space to be a place where people ask for, or advertise:\n\n* Job postings - Please use r/dataengineeringjobs instead.\n* Study groups\n* Referrals\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-01-15 16:10:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrckdt",
          "author": "PrestigiousAnt3766",
          "text": "6.5k\n40ish in bi\nX frontenders (no idea)\n40+ ds.",
          "score": 1,
          "created_utc": "2026-01-15 17:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrgu1d",
          "author": "Raph16",
          "text": "22k employees\nTeam size : 1 (me)",
          "score": 1,
          "created_utc": "2026-01-15 17:26:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs3ugw",
              "author": "Yabakebi",
              "text": "Tell me that's a joke? ‚Äã",
              "score": 1,
              "created_utc": "2026-01-15 19:09:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzswko5",
          "author": "Erikoopter",
          "text": "18k employees, 40 internal team, 150 external",
          "score": 1,
          "created_utc": "2026-01-15 21:22:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsxg2m",
          "author": "Uncle_Snake43",
          "text": "Company of 200ish.  We have 3 Data Engineers, a couple Analysts and a Director.",
          "score": 1,
          "created_utc": "2026-01-15 21:26:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzts82o",
          "author": "HungryRefrigerator24",
          "text": "Company of around 50 employees,\n\nTeam size:\n\n1 Tech lead (me)  \n1 PM\n\n2 juniors Engineers (+me in free time)  \n2 BI (senior and junior)  \n2 AI Engineer (1 being hired, other is myself)  \n1 Full Stack (being hired)\n\nIt's an M&A boutique firm with a digital branch that offers AI automation to other finance firms and companies",
          "score": 1,
          "created_utc": "2026-01-15 23:59:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzudhb6",
          "author": "Healthy_Put_389",
          "text": "4500 employees \nTeam size : me and my girlfriend",
          "score": 1,
          "created_utc": "2026-01-16 01:57:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzqv1j",
          "author": "soricellia",
          "text": "about 500 people, team of 1 (me)",
          "score": 1,
          "created_utc": "2026-01-16 21:04:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01f2z3",
          "author": "PlantRulx",
          "text": "120 person company, 1 person full time data team. Sometimes contracted help/intern.",
          "score": 1,
          "created_utc": "2026-01-17 02:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05gd2v",
          "author": "Green-Yesterday2505",
          "text": "2000ish employees.  55 folks on the data team.",
          "score": 1,
          "created_utc": "2026-01-17 18:46:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdv3wh",
      "title": "Getting off of Fabric.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qdv3wh/getting_off_of_fabric/",
      "author": "FirefighterFormal638",
      "created_utc": "2026-01-15 20:39:42",
      "score": 90,
      "num_comments": 105,
      "upvote_ratio": 0.96,
      "text": "Just as the title says. Fabric has been a pretty rough experience.\n\nI am a team of one in a company that has little data problems. Like, less than 1 TB of data that will be used for processing/analytics in the future with < 200 people with maybe \\~20 utilizing data from Fabric. Most data sources (like 90 %) are from on-prem SQL server. The rest is CSVs, some APIs.\n\nA little about my skillset - I came from a software engineering background (SQLite, SQL Server, C#, WinForms/Avalonia). I‚Äôm intermediate with Python and SQL now. The problem. Fabric hasn‚Äôt been great, but I‚Äôve learned it well enough to understand the business and their actual data needs.\n\nThe core issues:\n\n* Random pipeline failures or hangs with very little actionable error output\n* Ingestion from SQL Server relies heavily on Copy Data Activity, which is slow and compute-heavy\n* ETL, refreshes, and BI all share the same capacity\n* When a pipeline hangs or spikes usage, capacity shoots up and Power BI visuals become unusable\n* Debugging is painful and opaque due to UI-driven workflows and preview features\n\nThe main priority right now is stable, reliable BI. I'm open to feedback on more things I need to learn. For instance, better data modeling.\n\nComing from SWE, I miss the control and being granular with execution and being able to reason about failures via logs and code.\n\nI'm looking at Databricks and Snowflake as options (per the Architect that originally adopted Fabric) but I think since we are still in early phases of data, we may not need the price heavy SaaS.\n\nDE royalty (lords, ladies, and everyone else), let me know your opinions.\n\n  \nEDITED: Because there was too much details and colleagues.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qdv3wh/getting_off_of_fabric/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzso4io",
          "author": "TCubedGaming",
          "text": "Looking for the guys that told me fabric is the future",
          "score": 133,
          "created_utc": "2026-01-15 20:42:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsow64",
              "author": "No_Lifeguard_64",
              "text": "I have a friend that is all eggs in the Fabric basket and to him Fabric is the best thing since Jesus.",
              "score": 27,
              "created_utc": "2026-01-15 20:46:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzspr37",
                  "author": "FirefighterFormal638",
                  "text": "He got lost in the sauce of the msft eco-system.",
                  "score": 28,
                  "created_utc": "2026-01-15 20:50:26",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nzsq7cr",
                  "author": "TCubedGaming",
                  "text": "Even when our org tested it out, the pipelines would stall out all the time. We have system critical pipelines that run on ADF and have never failed for a \"hang up\"\n\nI would never feel comfortable about putting those pipelines on \"PowerBi.com\" rather than a dedicated engine whose only purpose is to ship data",
                  "score": 4,
                  "created_utc": "2026-01-15 20:52:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztz42t",
                  "author": "SOLID_STATE_DlCK",
                  "text": "Maybe he's making an omelette.  In that case, Fabric is the solution.",
                  "score": 3,
                  "created_utc": "2026-01-16 00:37:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztnfvv",
                  "author": "ab624",
                  "text": "but even Jesus the DE consultant won't recommend fabric",
                  "score": -1,
                  "created_utc": "2026-01-15 23:34:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzvdeuy",
              "author": "VarietyOk7120",
              "text": "Fabric is fine, not perfect but not what this thread says either. \nThis guy wants a code heavy ETL by the sounds of it, for his preference of debugging. \n1) If you look at Snowflake , people are also using ADF and the Copy Activity as a pattern \n2) The issue here is the on Prem source , there isn't a way to connect - perhaps a shortcut would work and then a notebook on that to do transformations in his language of choice ?",
              "score": 0,
              "created_utc": "2026-01-16 05:35:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzveaza",
                  "author": "TCubedGaming",
                  "text": "Why not just use ADF for a fraction of the cost?",
                  "score": 5,
                  "created_utc": "2026-01-16 05:42:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzssr7a",
          "author": "silentlegacyfalls",
          "text": "Fabric is fine for the right use case, but it sure as hell isn't low-code / no-code if you want good, cost-conscious, efficient performance.",
          "score": 33,
          "created_utc": "2026-01-15 21:04:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzstcj6",
              "author": "FirefighterFormal638",
              "text": "Agreed. A huge limitation is connecting to the on-prem SQL servers. Being forced to use their copy data activity for it eats up CUs. Wishing I could just use python scripts for the ingestion into the warehouse.",
              "score": 6,
              "created_utc": "2026-01-15 21:07:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsx1ex",
                  "author": "sjcuthbertson",
                  "text": "Have you explored mirroring the DBs into Fabric first (standalone workspace and capacity _solely_ for mirror objects) and then ingesting further if needed into your standard medallion or equivalent process?\n\nRe your capacity woes - you _could_ address that by just running two smaller capacities instead of one big one; one for all the DE stuff, the other for end user BI. Then the BI experience is insulated from any spikes upstream. If you are still doing import mode for BI reports then you could even just have them in Pro workspaces, based on your user count.\n\nUltimately if you don't like Fabric and want to move to something different, you do you - but those small wins _might_ make it less painful and less necessary to rebuild on a different stack.\n\nFwiw we've not had any \"random\" pipeline failures that we couldn't debug and understand the reason for. There have been a few (very few) examples of python notebooks misbehaving for _odd_ reasons - what feels like problems happening on the level of the underlying Azure infrastructure running Fabric. But for us, those are a fair trade-off for the benefits we're getting. YMMV of course. Not trying to convince you, just offering my experience.",
                  "score": 12,
                  "created_utc": "2026-01-15 21:24:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsu0is",
                  "author": "silentlegacyfalls",
                  "text": "I use python scripts to consume 3rd party data into my Fabric SQL Database.  Haven't had to integrate with on-prem yet.  Are you seriously stuck with Copy?",
                  "score": 2,
                  "created_utc": "2026-01-15 21:10:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o05umzy",
                  "author": "JBalloonist",
                  "text": "How big are your tables? How many tables? \n\nI copy just the tables I need (about 60) daily (some hourly) from an on-premise SQL server and rarely have problems. I‚Äôm only using one F4 capacity for everything (not best practice I know but trying to manage cost). The copy activity is definitely the highest usage but it is consistently below 50 percent capacity. \n\nI haven‚Äôt tried using a pure Warehouse; my entire architecture is on Lakehouses. That might where the difference is. Every time I spin up a Warehouse it seems to use a lot of capacity, even if there is little to no data.",
                  "score": 1,
                  "created_utc": "2026-01-17 19:54:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztaxs5",
          "author": "technojoe99",
          "text": "My company uses ADF to load data into Fabric. From there, we transform the data as needed via Notebooks written in Python and SQL. It works very well, and is stable unless there's an update that borks the self-hosted integrated runtime. \n\nI think moving your ingestion from Fabric to ADF while keeping fabric for everything else would get you the most bang for your buck. Databricks provides similar functionality with their notebooks, but it would be a larger effort to move to them.",
          "score": 7,
          "created_utc": "2026-01-15 22:29:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztuydv",
              "author": "TCubedGaming",
              "text": "Why put fabric in between adf and databricks? What value is added?",
              "score": 1,
              "created_utc": "2026-01-16 00:14:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvxrnv",
                  "author": "technojoe99",
                  "text": "I don't have databricks at all. I was merely speaking to him considering switching to Databricks, by saying Databricks provides comparable functionality.",
                  "score": 2,
                  "created_utc": "2026-01-16 08:24:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzueth1",
          "author": "babygrenade",
          "text": ">Ingestion from SQL Server relies heavily on Copy Data Activity\n\nIf most of the data is from on prem SQL Server (I'm assuming this is your transaction database) why aren't you mirroring the SQL server database into fabric (or into an Azure SQL database)?\n\n\n>I'm looking at Databricks and Snowflake as options\n\nIf you have small to medium data, why are you looking at big data platforms?",
          "score": 6,
          "created_utc": "2026-01-16 02:04:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxnb11",
              "author": "wubalubadubdub55",
              "text": "This OP guy just wants to hate on fabric and suffers from severe skill issue.",
              "score": -3,
              "created_utc": "2026-01-16 15:24:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuwtyi",
          "author": "Weekly_Activity4278",
          "text": "Another one of these. \n\nYou know you can put your ETL items like notebooks and pipelines in a separate capacity right? So it doesn‚Äôt affect your BI items like reports and semantic models. Feels like more of an implementation issue rather than the product itself. \n\nAlso have looked into mirroring which is free for upto 5TB of storage? \n\nI get it‚Äôs cool to hate on Fabric or whatever and I am ok with criticism of Microsoft but this just screams lazy to me.",
          "score": 6,
          "created_utc": "2026-01-16 03:46:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt118p",
          "author": "AtypiclAvngr",
          "text": "OP, reading your context was like looking in a mirror. I'm basically in the same situation across the board regarding history and experience. However, I've had a totally different Fabric experience. Never had anything fail, been working super efficiently, and easy to debug. Granted, coming from a 3rd party tool with zero visibility. \n\nMy data complexity, scale, and user base is a little higher than what you listed, but my entire backend fits easily on an F4.\n\nFor my approach, I only used Spark (pyspark or spark sql) and a medallion approach. All the cdc pipelines work great, and I haven't had any issues.\n\nI have to ask, how come you can't use mirroring for your on-prem sql? Or at least spark if not mirroring.\n\nFor the front end, I just approached it via segmentation of capacity. So, each business domain only throttles themselves. But that doesn't happen much since nobody uses paginated reports, and the data models are pretty clean.\n\nHonestly, I'd still rather use Databricks, but my problem is I can't justify it to my organization since I made the Fabric site work too well on its own...",
          "score": 8,
          "created_utc": "2026-01-15 21:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt3bti",
              "author": "FirefighterFormal638",
              "text": "Last I researched, it was not possible to route directly from a Spark Notebook to an on-prem SQL Server. I have the medallion approach implemented and it did teach me a lot stepping into the role.\n\nI believe the last time that I looked into it, mirroring had it's limitations as well.",
              "score": 1,
              "created_utc": "2026-01-15 21:52:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzt7ls0",
                  "author": "AtypiclAvngr",
                  "text": "Not out of the box. I have spark environments with jdbc drivers to different systems set up. Used that for sql server to start, but mirroring with an on prem sqp server gateway just worked way better and had even less capacity usage. Someone else on my infrastructure team set that up though, so I don't know what it entails, but it made the ELT much easier",
                  "score": 7,
                  "created_utc": "2026-01-15 22:13:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzth4zp",
          "author": "Nekobul",
          "text": "Why not use SSIS to push your data from on-premises? In this way you will use your local server computing capacity.",
          "score": 4,
          "created_utc": "2026-01-15 23:00:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztz9js",
          "author": "Vw-Bee5498",
          "text": "I used to build data warehouse on Fabric and agree debugging was cumbersome. The Data Factory within Fabric portal didn't have the same features as DF on standalone Azure. But I find the UI better than Databricks though.¬†",
          "score": 3,
          "created_utc": "2026-01-16 00:38:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsxloy",
          "author": "vikster1",
          "text": "my heart jumps for joy each time i read about fabric being bad. third year now and i cherish every post. thank you and i hope microslop tanks 50% in value over the next 2 years.",
          "score": 20,
          "created_utc": "2026-01-15 21:26:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt9s5l",
              "author": "RemarkableCompote517",
              "text": "I read that fabric lost 4% of a cloud market last year (32 -> 27%), so your dreams come true",
              "score": 6,
              "created_utc": "2026-01-15 22:23:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzubt9x",
                  "author": "EcoEng",
                  "text": "Source?",
                  "score": 2,
                  "created_utc": "2026-01-16 01:48:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzu2sug",
                  "author": "splynta",
                  "text": "Is that size of pie or size of slice in terms of market share? Like did the pie get bigger but their slice stayed the same or they lost?",
                  "score": 1,
                  "created_utc": "2026-01-16 00:57:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzxo1wt",
              "author": "wubalubadubdub55",
              "text": "It‚Äôs interesting how Redditors think everything out of Microsoft is inherently bad and anything else is inherently good. \n\nI mean aren‚Äôt the developers at Microsoft just like you and I trying to build and ship something great? \n\nAs a fellow dev, I can‚Äôt put other developers down like that just because they work at Microsoft. \n\nJudge a product based on its features not where it comes from.",
              "score": 2,
              "created_utc": "2026-01-16 15:28:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzu1485",
              "author": "TowerOutrageous5939",
              "text": "It‚Äôs makes zero sense to pick fabric. You are locking yourself into microslops road map. Yah f that noise.",
              "score": 2,
              "created_utc": "2026-01-16 00:48:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzva04n",
          "author": "ActionOrganic4617",
          "text": "I found the copy activity, especially for high frequency jobs more expensive than ADF. To make the best of the platform, I‚Äôd recommend mirroring for SQL tables.",
          "score": 3,
          "created_utc": "2026-01-16 05:11:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsrlw8",
          "author": "mark2347",
          "text": "We load data into Snowflake using ADF and our PBI datasets are imports from Snowflake. We're a small company, but it works well for us and is much simpler orchestration than the AWS DMS/DAG mess it used to be.",
          "score": 5,
          "created_utc": "2026-01-15 20:59:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzstn6l",
              "author": "aMare83",
              "text": "And do you implement much DAX, data transformations im PBI or you pretty much try to prepare everything in SQL and mostly just visualize in PBI? My experience says that PBI can struggle with performance when working with high data volume.",
              "score": 2,
              "created_utc": "2026-01-15 21:08:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzstzxm",
                  "author": "mark2347",
                  "text": "We create views in Snowflake for much of the translation when we can. I'm much more familiar with sql than DAX so this allows Snowflake to do most of the heavy lifting.",
                  "score": 8,
                  "created_utc": "2026-01-15 21:10:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztbr6j",
                  "author": "frozengrandmatetris",
                  "text": "how is DAX not just bad practice being sold as a feature? I prefer to prepare the data as much as I can before the reporting layer even sees it, for the best performance. I want my reporting layer doing as little work as possible.",
                  "score": 1,
                  "created_utc": "2026-01-15 22:33:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwdc4g",
          "author": "Alternative_Aioli_72",
          "text": "Your instincts are right, you don't need Databricks or Snowflake for <1TB with 20 users. That's using a sledgehammer to hang a picture frame.\n\nThe issue you're describing is the classic Fabric trap for small teams. Everything competing for the same CU pool means your ETL spikes tank your dashboards.\n\nAn alternative is keeping Fabric for Power BI only (it's actually decent there), but moving your ingestion/transformation outside. Azure Functions + DuckDB can handle your SQL Server extracts for few bucks at your scale. You get actual logs, version control, and the debugging experience you're missing from your SWE days.\n\nOr go simpler, depending on your refresh requirements, a straightforward SQL Server -> Parquet -> Power BI pattern with scheduled Python scripts might be all you need. No platform lock-in, easy to reason about, easy to hand off to future team members.",
          "score": 2,
          "created_utc": "2026-01-16 10:47:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztmisb",
          "author": "HansProleman",
          "text": "Fabric was so obviously always bad and going to be bad. Like Synapse (remember that?), it's just Microsoft's response to Databricks nibbling their lunch. Sloppy, thrown together crap to snare the people who'll always prefer to select MSFT, or think synergies (e.g. with PBI) make up for it.\n\nI've always wanted to run a FOSS Spark setup, but I mostly work for enterprises and Databricks handles/integrates *so much* enterprise-required stuff (IAM, access controls/governance, dictionaries etc.) that it's a pragmatic choice. You could put together all those things from FOSS, but it probably adds up to a lot of components and thus a higher complexity burden. An all-in-one solution is pretty appealing.\n\n>since we are still in early phases of data, we may not need the price heavy SaaS\n\nIt's pretty affordable if you manage costs appropriately? Like, you pay for what you use. If you want a support agreement, of course that'll cost, but it's not mandatory.",
          "score": 3,
          "created_utc": "2026-01-15 23:29:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzssyht",
          "author": "WhoIsJohnSalt",
          "text": "For less than a terabyte couldn‚Äôt you just load this into the PBI instance and miss out the fabric stuff? (Ok yes, fabric/PBI are kind of blending together)",
          "score": 1,
          "created_utc": "2026-01-15 21:05:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzstn15",
              "author": "FirefighterFormal638",
              "text": "Yes, and it was being done before they adopted Fabric however, with newer projects on the horizon, they are wanting to adopt better DE practices.",
              "score": 1,
              "created_utc": "2026-01-15 21:08:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsu9fy",
                  "author": "WhoIsJohnSalt",
                  "text": "Yeah, though unless your data is going to get a lot bigger I‚Äôd keep it simple. \n\nIf you fancy some fun, create some pipelines into DuckDB and start doing a low cost code first data stack. \n\nProbably plays nicer with your on prem world.",
                  "score": 1,
                  "created_utc": "2026-01-15 21:11:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt5i88",
          "author": "Winterlimon",
          "text": "also on fabric and in OMSA, are you me?",
          "score": 1,
          "created_utc": "2026-01-15 22:03:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt5q7v",
              "author": "FirefighterFormal638",
              "text": "Hello, self.",
              "score": 2,
              "created_utc": "2026-01-15 22:04:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztt13e",
          "author": "Careful_Reality5531",
          "text": "Would highly recommending checking out LakeSail.",
          "score": 1,
          "created_utc": "2026-01-16 00:04:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0fhb",
          "author": "mr_PayTel",
          "text": "I‚Äôm tasked with figuring out if we should implement fabric or any other analytics tool. The thing is we don‚Äôt need any of these but someone outside of our department keep hyping up fabric and being pain in the butt.\n\nWe lost few people in our department and no one is data engineering/architecture level. We‚Äôre BI analysts with SQL in our belt.\n\nWe use excel base reporting by doing markup language and it‚Äôs been working amazing so I‚Äôm not sure what benefits fabric provides for someone who just do pipeline snapshots once a week and at monthly level. Am i missing something?",
          "score": 1,
          "created_utc": "2026-01-16 00:44:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu1kt7",
          "author": "Efficient_Novel1769",
          "text": "We starting using Dremio Cloud - it is like a 1/3 of the price for us as we came off Snowflake and it is Iceberg based.  We use dbt with it and it has worked well for us - good price/perf option.",
          "score": 1,
          "created_utc": "2026-01-16 00:50:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu2iih",
          "author": "BeesSkis",
          "text": "Databricks for DE and Fabric for Reporting (PBI) is always an option.",
          "score": 1,
          "created_utc": "2026-01-16 00:55:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzunqt5",
          "author": "Immediate-Pair-4290",
          "text": "If you like SWE run DuckDB in docker containers and write to ducklake in native or iceberg format. You‚Äôre welcome.",
          "score": 1,
          "created_utc": "2026-01-16 02:54:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvg0ss",
          "author": "randomuser1231234",
          "text": "How DIY and SWE-style-programming do you want to get here?\n\nBecause hosting your own Airflow (as opposed to using a SaaS like Astronomer or Databricks for orchestration) will provide the options for logging and you can have the heavier duckdb jobs in Kubernetes pods.\n\nAnd if you want to go REALLY away from Fabric, Apache has their own reporting tool as well.",
          "score": 1,
          "created_utc": "2026-01-16 05:54:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvjskg",
          "author": "Left_Offer",
          "text": "Are you no able to just mirror data from SQL db? Also, you can spin a separate capacity for DE and for BI (based on your description cheap F2 should do), therefore eliminateing risk of BI throttling during other processes.",
          "score": 1,
          "created_utc": "2026-01-16 06:24:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvorqc",
          "author": "freedumz",
          "text": "Once you get the hang of Fabric, it is quite easy to use. \n\nA few optimization tips:\nReporting: Use a small capacity just for consumption.\nStorage Mode: If you aren't using Direct Lake (Import only), stick to a Pro workspace.\nOn-Prem Data: Avoid Copy activities for big tables; use Mirroring instead.\n\nLet's make sure we really understand the tool (or ask someone who does) before we critique it\n\nI deployed it at a few customers and after a few optimizations people are pretty happy with this solution and it continues to evolve",
          "score": 1,
          "created_utc": "2026-01-16 07:05:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvwm5c",
          "author": "Ok-Sentence-8542",
          "text": "So switching from Snowflake to Fabric is a bad Idea right? Also for a large firm leaning into Microsoft especially for AI and having a heterogeneous stack with lots of different data sources and types?",
          "score": 1,
          "created_utc": "2026-01-16 08:13:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05wb8s",
              "author": "JBalloonist",
              "text": "If you are already on Snowflake there is definitely no reason to switch.",
              "score": 1,
              "created_utc": "2026-01-17 20:02:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw5zra",
          "author": "Waldchiller",
          "text": "You ca also run your PBI reports on non fabric workspaces with import mode so you are not affected by other fabric objects in terms of speed. Depends on model size but power BI can compress heavily.\n\nWhen you do transformations use python / pyspark notebooks.",
          "score": 1,
          "created_utc": "2026-01-16 09:41:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwd3zy",
          "author": "WishfulAgenda",
          "text": "Have a look at clickhouse cloud or on premise. I‚Äôve found the cloud version very reasonable (1TB storage is something like $22 per month) and on premise is open source. Also has a neat option where cloud service ‚Äúsleep‚Äù and reduces costs.\n\nBroad integration and accessible with python through  clickhouse-connect and powerbi through a standard connector. \n\nGood luck",
          "score": 1,
          "created_utc": "2026-01-16 10:45:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwoi24",
          "author": "DefinitelyNotMeee",
          "text": "Perfect example of Dunning-Kruger.",
          "score": 1,
          "created_utc": "2026-01-16 12:15:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy7w0x",
          "author": "dillanthumous",
          "text": "It's a bit of a car crash. We use it tactically where it is useful (API calls, Python scripts etc.) and avoid it for our core ELT (using Synapse and Azure SQL).",
          "score": 1,
          "created_utc": "2026-01-16 16:55:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsqs8u",
          "author": "Dry_Professional8254",
          "text": "Just Microsoft doing what it does best.",
          "score": 1,
          "created_utc": "2026-01-15 20:55:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0tmv",
          "author": "TowerOutrageous5939",
          "text": "Everything you said is correct",
          "score": 1,
          "created_utc": "2026-01-16 00:46:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzstqhr",
          "author": "Arnechos",
          "text": "Primary SQL workloads -> Snowflake  \nMixed structured/un-structured/maybe ML -> Databricks (Ray on Spark)\n\nOr duckdb/motherduck.",
          "score": 1,
          "created_utc": "2026-01-15 21:08:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsx2gi",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2026-01-15 21:24:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsyleo",
              "author": "FirefighterFormal638",
              "text": "8 Years??",
              "score": 6,
              "created_utc": "2026-01-15 21:31:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzt0eyy",
                  "author": "Seebaer1986",
                  "text": "Bot...",
                  "score": 3,
                  "created_utc": "2026-01-15 21:39:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt1ixn",
                  "author": "ATL_we_ready",
                  "text": "lol",
                  "score": 1,
                  "created_utc": "2026-01-15 21:44:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzszm60",
                  "author": "Astherol",
                  "text": "More or less with early PBI, SSAS, SSRS, you know all this Microsoft stuff that makes you go loco",
                  "score": 1,
                  "created_utc": "2026-01-15 21:36:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu1pki",
              "author": "RobCarrol75",
              "text": "Fabric was launched 2 years ago...",
              "score": 1,
              "created_utc": "2026-01-16 00:51:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzujan8",
              "author": "VarietyOk7120",
              "text": "So much BS here ‚òùÔ∏è",
              "score": 1,
              "created_utc": "2026-01-16 02:29:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzst3pv",
          "author": "Babs12123",
          "text": "I'm working with a very similar setup - greenfield opportunity with an org with no formal data infrastructure outside of systems like a CRM, where the near term use cases are BI and process automation. Fortunately they brought me in before buying Fabric (though they have talked about it a lot!) and my plan for the initial data infrastructure is literally just Python on a VM and ADLS. That might not be suitable for you but I found it helpful to be reminded to keep it really simple until I can't anymore!\n\nWe don't have the scale or complexity yet to warrant a platform like Fabric or even a SQL database, so I'm planning to keep it very simple and only make it more complex when there is a tangible need for it. Then when we have actually matured a little I am thinking of moving onto probably Databricks (I'll do a proper assessment but I am suspicious about Fabric and I know a lot of people who work at DB so it's handy!).",
          "score": 0,
          "created_utc": "2026-01-15 21:05:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsudtb",
              "author": "FirefighterFormal638",
              "text": "This is exactly the mindset that I have. Because we are still new with our analytics and still navigating what we want to see, why do we need the heavy cost of Fabric or another SaaS? 90% of our data is already coming in as structured and reporting is essentially just basic charts and aggregations right now.",
              "score": 1,
              "created_utc": "2026-01-15 21:11:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsw9sv",
                  "author": "Truth-and-Power",
                  "text": "You could also just use a sql server.¬† The sql can transport to snowflake or databricks later if the modeling is done right.¬†",
                  "score": 1,
                  "created_utc": "2026-01-15 21:20:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsuswb",
                  "author": "Babs12123",
                  "text": "Best of luck - I would hope you are able to convince your company to drop Fabric based on cost and time savings alone from the sound of it!!",
                  "score": -1,
                  "created_utc": "2026-01-15 21:13:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzt2a2q",
              "author": "Seebaer1986",
              "text": "I am curious, how much does running the VM cost you? \n\nYou can have such a simple setup as well in fabric. Use pure python notebooks and store everything in a lake house on OneLake - which is in the end just ADLS Gen2.\n\nWhen you have small data running through an F2 will definitely be sufficient and you can cut down the cost even more by starting and stopping the capacity when needed.",
              "score": 1,
              "created_utc": "2026-01-15 21:48:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsxzfq",
          "author": "slowboater",
          "text": "If you have the on prem compute space, rancher for orch, mysql, and python microservices for anything thats too heavy for mysql. All free. Bonus points if small k8s cluster is in 5-10 year plan. Only subscription fee id recommend is a Tableau or similar for your DSs",
          "score": 0,
          "created_utc": "2026-01-15 21:28:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztaxvy",
          "author": "Hagwart",
          "text": "Take a look at Qlik Cloud and Qlik Sense Enterprise (on prem). I am a swiss army knife myself with this for 15+ years in different companies ranging from small to large.",
          "score": 0,
          "created_utc": "2026-01-15 22:29:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxm928",
          "author": "wubalubadubdub55",
          "text": "Buddy,\nYou have skill issue.",
          "score": 0,
          "created_utc": "2026-01-16 15:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztwqmc",
          "author": "fckmstrflx",
          "text": "Exasol. It's a German OLAP with the best price/performance ratio I've seen, and on similar hardware it's light years faster.",
          "score": -2,
          "created_utc": "2026-01-16 00:24:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu7s8x",
          "author": "ugamarkj",
          "text": "I‚Äôd highly recommend Exasol. Very low overhead / very fast platform that you could spin up on your laptop for free as a POC.",
          "score": -2,
          "created_utc": "2026-01-16 01:25:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbjqex",
      "title": "I spent 8 months fighting kafka and just decided to replace the whole thing",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qbjqex/i_spent_8_months_fighting_kafka_and_just_decided/",
      "author": "seizethemeans4535345",
      "created_utc": "2026-01-13 06:08:19",
      "score": 82,
      "num_comments": 36,
      "upvote_ratio": 0.91,
      "text": "I know I‚Äôm gonna get hate for this but kafka is overengineered for most. We ran it for our event pipeline, 50k events per second, which sounds like a lot but isn't really, zookeeper randomly failing, consumer rebalancing in the middle of critical processing, exactly once delivery that definitely wasn't exactly once and brokers filling up disk space the partition decisions we made in month one haunting us. I just said screw it and rebuilt everything on synadia with nats, performance is actually better, haven't touched the infrastructure in four months.\n\nkafka makes sense if you're linkedin processing billions of events, for us it was like using a semi truck to deliver a single pizza, overkill has a cost and that cost is your sanity.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qbjqex/i_spent_8_months_fighting_kafka_and_just_decided/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzb4sd7",
          "author": "wbrd",
          "text": "Throughput isn't what you use to determine if you should use Kafka or not. Most MQ implementations will trounce Kafka in that. You only use Kafka if you want to be able to go back in the messages or if you are lazy and don't want to write to the DB at each step.\n\nIf you just want fast pub/sub, Kafka shouldn't even make the list.",
          "score": 54,
          "created_utc": "2026-01-13 06:15:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbmcll",
              "author": "sib_n",
              "text": "> You only use Kafka if you want to be able to go back in the messages or if you are lazy and don't want to write to the DB at each step.\n\nAnd you have enough data to justify the added complexity of a distributed system.",
              "score": 5,
              "created_utc": "2026-01-13 08:54:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzbtsiu",
                  "author": "_predator_",
                  "text": "The DistSys argument is moot.\n\nEvery component is a distributed system once you run it with multiple nodes. Postgres, RabbitMQ, NATS, MySQL, ValKey, even your own application.\n\nYou can run Kafka just fine on a single node and avoid a lot of problems that way.",
                  "score": 13,
                  "created_utc": "2026-01-13 10:06:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb5gd9",
          "author": "IllustratorWitty5104",
          "text": "No, you are right. There is no, one size fit all solution for everything.\n\nEvery company have different context and situations which require different solution. Hence, I find myself always arguing with theory monsters who insist on using their so called \\*best\\* tool for a particular problem",
          "score": 13,
          "created_utc": "2026-01-13 06:20:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzc2yg4",
              "author": "Vegetable_Bowl_8962",
              "text": "yup. Every company has a different solution and monitoring system and data observability solution or pipeline structuring based on their needs and business goals.",
              "score": 1,
              "created_utc": "2026-01-13 11:28:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzbll6s",
          "author": "Feisty_Following9720",
          "text": "Is this an ad?",
          "score": 19,
          "created_utc": "2026-01-13 08:46:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcgvkv",
              "author": "West_Good_5961",
              "text": "Seems like an ad for whatever synadia is",
              "score": 17,
              "created_utc": "2026-01-13 13:08:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzbmfj6",
              "author": "sib_n",
              "text": "Good point, clickbait subject, random username and hidden history.",
              "score": 14,
              "created_utc": "2026-01-13 08:54:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzbnwor",
                  "author": "Feisty_Following9720",
                  "text": "I have 2 of those things tbh. But yeah doesn't help the case.",
                  "score": 2,
                  "created_utc": "2026-01-13 09:09:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzcko8v",
                  "author": "NoleMercy05",
                  "text": "Wierd.",
                  "score": 1,
                  "created_utc": "2026-01-13 13:31:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznqjbs",
              "author": "col0rcutclarity",
              "text": "Yes these guys been actively advertising",
              "score": 1,
              "created_utc": "2026-01-15 02:32:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb8haj",
          "author": "redderage",
          "text": "Did you use multi node cluster? What was the requirement and settings?",
          "score": 2,
          "created_utc": "2026-01-13 06:46:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbacnw",
          "author": "DataObserver282",
          "text": "What compelled you to use Kafka to begin with? At a heavy Kafka org and convinced we could move 80% some of our pipelines that don‚Äôt need to be real time",
          "score": 2,
          "created_utc": "2026-01-13 07:02:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbalcr",
          "author": "Yabakebi",
          "text": "Where you not using a managed solution?",
          "score": 2,
          "created_utc": "2026-01-13 07:04:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdcg3y",
          "author": "dev_lvl80",
          "text": "We do distancing from kafka too. Too complex¬†and not reliable (confluent). If real time is not must - os school methods works better and simply.",
          "score": 2,
          "created_utc": "2026-01-13 15:52:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzeilsg",
          "author": "peterxsyd",
          "text": "Out of interest was your use case live data capture or live data processing? Obviously many cases have both, but in the event you are pulling data off a websocket or need to pipe live app events somewhere else for processing i‚Äòd be interested.",
          "score": 2,
          "created_utc": "2026-01-13 19:14:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfnrso",
          "author": "slayerzerg",
          "text": "There‚Äôs smaller scale options rather than using Kafka",
          "score": 2,
          "created_utc": "2026-01-13 22:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbfr39",
          "author": "unreasonablystuck",
          "text": "Honestly Kafka is meant for at-least-once delivery. Even if they advertise exactly-once, the CAP theorem is just a basic fact of mathematics: you are trading consistency over availability. Not to mention how hard it is to tune the various timeouts and parameters both server and client side and when transactions get stuck, it's an absolute hell to debug. Every single actor and library involved has to be aware of this transactional mode or else you will see duplicates. It's not worth it.\n\nAnd even in at-least-once, you need to discuss beforehand the need for timeouts, heartbeat adjustments, the need for an idempotency/deduplication ID and event_time parameter... Applications tend to just be set up with default parameters without discussing any of that which is a recipe for headaches. Hell, I've seen deployments without as much as a group ID set up saying \"hey it worked without it\". And specially the thundering herd (?) problem in case of rebalancing is quite tricky to explain to people, it seems. Your apps and pipelines need to be able to handle these, and that's an architectural decision, it's not just plug and play.\n\nAnd that's me mostly just using it client side as a developer/engineer, having to help Ops debug server side issues occasionally. You need a lot of observability over Linux data syscalls and disks, and it seems to me that the default dashboards only have CPU, memory, at most disk usage.\n\n~~But I would be even warier of building custom stuff on NAS storage, but hey, that's why I don't work at Ops~~ EDIT: sorry, misread it as NAS storage for some reason. BTW, just to make sure, you weren't trying to use them as persistence for Kafka, were you? I've had to discourage people from doing it, very few databases would handle being persisted to network storage well",
          "score": 3,
          "created_utc": "2026-01-13 07:51:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbgz5s",
          "author": "starless-io",
          "text": "FYI, since version 3 Kafka doesn't need Zookeeper anymore, it's possible to run without it and skip some of complexity üôÇ\n\nNATS is faster if you don't use persistence layer (Jetstream). And when you have a need for persistance, NATS has it's quirks as well... Don't get me wrong, I do love NATS and use it for few projects\n\nBy the sound of it, you don't really need persitence and Kafka was not needed to start with.\n\nBy the way, there's a feature in NATS which I found very useful: you can have topic and you can have subtopic, and you can listen to subtopics by wildcard. We have a case of replicating over 400 tables from bunch of teams. In Kafka you should just create 400 topics, listen them one by one. Good luck maintaining that... In NATS that can be a single topic üôÇ",
          "score": 3,
          "created_utc": "2026-01-13 08:02:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbzllj",
          "author": "amanbolat",
          "text": "Kafka just works.\n\nIf you spent that much time fixing your Kafka setup in production, it means you don‚Äôt make enough preparation in advance.\n\nIn case you don‚Äôt want to manage everything there are managed services, e.g. AWS MSK or Aiven.",
          "score": 5,
          "created_utc": "2026-01-13 10:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbpwuh",
          "author": "xmBQWugdxjaA",
          "text": "It's only worth it if you're regularly reprocessing past events.\n\nIf you don't need the time travel stuff, then just use RabbitMQ etc.",
          "score": 2,
          "created_utc": "2026-01-13 09:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb9114",
          "author": "t3hWarrior",
          "text": "give pulsar a shot",
          "score": 2,
          "created_utc": "2026-01-13 06:50:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbetdx",
              "author": "kabinja",
              "text": "Doesn't pulsar use zookeeper and even add complexity with book keeper or something like that?",
              "score": 3,
              "created_utc": "2026-01-13 07:42:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzbfgei",
                  "author": "t3hWarrior",
                  "text": "i mean, yeah, but from my experience, once it's up, it stays up. no partition or disk issues at all. \nbesides, it can be configured to use other types of metadata storage other than ZK (etcd, oxia, etc..)",
                  "score": 3,
                  "created_utc": "2026-01-13 07:48:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzclgf8",
          "author": "NoleMercy05",
          "text": "Kafka is a C-Suite requirement. \n\nThey need to get a checkbox on the Kafka line item. Helps being acquired.",
          "score": 1,
          "created_utc": "2026-01-13 13:35:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzf493l",
              "author": "GoodLyfe42",
              "text": "Not just c-suite, data engineers want it on their resume. And if you tell them it is over kill or we can‚Äôt implement something we can‚Äôt adequately support they get bent out of shape.",
              "score": 1,
              "created_utc": "2026-01-13 20:55:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhl8cz",
          "author": "Sagar_N",
          "text": "We are also using kafka in our org for data transfer from one team to another with single server, single topic, with 3 partitions with 3 days retention policy. But I don't get what is the actual use case of Apache kafka why would someone choose kafka over something else? The use we are doing in our org can be replaced by may be writting to some storage like GCS or S3 right? Can please someone well aware of topic help and guide others please reply or point to resources.",
          "score": 1,
          "created_utc": "2026-01-14 05:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznqgmr",
          "author": "col0rcutclarity",
          "text": "Advertisement. Flagged",
          "score": 1,
          "created_utc": "2026-01-15 02:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzosru7",
          "author": "Justin_3486",
          "text": "this'll be controversial but you're right, we calculated kafka costs us way too much in engineer time, managing it, debugging weird issues, training new people, that's expensive for a messaging system.",
          "score": 1,
          "created_utc": "2026-01-15 06:59:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp09y9",
          "author": "BalanceOk6316",
          "text": "Anyone interrupting to the devops or the devsecops bootcamp by tech with nana ?",
          "score": 1,
          "created_utc": "2026-01-15 08:07:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbb88o",
          "author": "FooBarBazQux123",
          "text": "You‚Äôre right, I used Kafka in multiple complex projects, and all the times was over engineered. Fine tuning of parameters everywhere, odd behavior of Kafka Streams, odd rebalancing issues, etc\n\nKinesis, PubSub, or just RabbitMQ would do the job with way less hidden behaviors.",
          "score": 1,
          "created_utc": "2026-01-13 07:09:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb6wkv",
          "author": "ImaginaryEconomist",
          "text": "What did you switch to then? Few more details about the nature of workload & use case would be helpful.",
          "score": 0,
          "created_utc": "2026-01-13 06:32:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbpoh1",
      "title": "Relational DBMS systems are GOATed",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qbpoh1/relational_dbms_systems_are_goated/",
      "author": "sexyman213",
      "created_utc": "2026-01-13 12:10:02",
      "score": 81,
      "num_comments": 36,
      "upvote_ratio": 0.88,
      "text": "I'm currently doing a master's degree in CS and I have taken a few database related courses. In a course I delved deep into the theory of relational algebra, transactions, serializability, ACID compliancy, paging, memory handling, locks etc., it was fascinating to see how decades of research had perfected the relational databases. Not to diss any modern cloud based batch processing big data platforms, but they seem to throw away a lot of clever stuff from RDBMSs as trade-off for bandwidth, which is fine, they do what they are supposed but it feels like boring transactional databases like Postgres, MySQL or Oracle don't get talked about often especially in the 'big data' sphere and 'data driven' world.\n\nPS: I don't have much experience in the industry and feel free to counter my opinions",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qbpoh1/relational_dbms_systems_are_goated/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzc87hr",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-13 12:10:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzca34c",
          "author": "equipmentmobbingthro",
          "text": "Start watching some of Hannes M√ºhleisen's talks on DuckDB and DuckLake. His inaugural lecture on the history of DBMS is also really nice.",
          "score": 71,
          "created_utc": "2026-01-13 12:23:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy7pqe",
              "author": "sexyman213",
              "text": "Hey I watched that video. It was great! thank you for the suggestion. Relational models swallow everything eventually",
              "score": 2,
              "created_utc": "2026-01-16 16:54:51",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzdnt75",
              "author": "ColdStorage256",
              "text": "Sorry to be that guy who can't do anything for himself but I'm multi-screening while in a meeting... got a link for later please?",
              "score": 7,
              "created_utc": "2026-01-13 16:44:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzy7w0e",
                  "author": "sexyman213",
                  "text": "[https://youtu.be/-wCzn9gKoUk?si=oNuZ\\_RNLg42mQx9\\_](https://youtu.be/-wCzn9gKoUk?si=oNuZ_RNLg42mQx9_)",
                  "score": 1,
                  "created_utc": "2026-01-16 16:55:37",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzdl84w",
          "author": "SirLagsABot",
          "text": "SQL Server and Postgres, my dynamic duo. RDBMS‚Äôs are some of the most powerful, battle-tested, reliable pieces of software ever produced by the entirety of mankind. Look at sql lite, they have orders of magnitude more tests for sql lite than actual source code to run the db - and freaking public domain/free, too.\n\nI‚Äôve never been a fan of nosql dbs like mongo. Eventually when someone builds an app or whatever that gets enough users or data, they will want engineering to extract it and analyze it. SQL is just too good for this stuff.",
          "score": 26,
          "created_utc": "2026-01-13 16:32:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdsvmh",
              "author": "THBLD",
              "text": "![gif](giphy|iGpdSizVSdPJfiVG9O)",
              "score": 7,
              "created_utc": "2026-01-13 17:19:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nziyjfd",
              "author": "HoushouCoder",
              "text": "The second point rings true. I find that it's commonly used by teams when starting out, who didn't have the time or bandwidth to employ a proper data workflow and just wanted to hit the ground running.",
              "score": 4,
              "created_utc": "2026-01-14 12:13:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcx9hn",
          "author": "MaverickGuardian",
          "text": "Postgres is actually so great that it works even when most teams abuse it really badly.",
          "score": 13,
          "created_utc": "2026-01-13 14:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdrxcw",
              "author": "_predator_",
              "text": "I'm willing to bet most teams never even update the default config. Which is so conservative it allows Postgres to run on a tiny old Raspberry Pi.",
              "score": 3,
              "created_utc": "2026-01-13 17:14:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzc8zse",
          "author": "Sensitive-Sugar-3894",
          "text": "There are the cloud-only DBs and they are good to do stuff. But Postgres is everywhere. Even in cloud. And the older the company, the higher the possibility to find MySQL.",
          "score": 23,
          "created_utc": "2026-01-13 12:15:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcbhdn",
              "author": "j0holo",
              "text": "I have yet to work for a company that did not use MySQL or still had some legacy software running on MySQL. Postgres gets all the hype these days for a good reason by MySQL knowledge is damn useful and roles/authorization a PITA in postgres.",
              "score": 10,
              "created_utc": "2026-01-13 12:33:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzd9rqe",
                  "author": "Sensitive-Sugar-3894",
                  "text": "It's true. And it's kind of interesting. In one hand, we want to modernise stuff and are aware of limitations on older versions, even in MySQL. On the other hand, usually these legacy envs provide stability and support growth.",
                  "score": 3,
                  "created_utc": "2026-01-13 15:40:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzcbcmm",
          "author": "SirGreybush",
          "text": "What differs? One big difference. \n\nPK / FK management with enforcement of constraints. Mono-server or server clustering that essentially works like a single server, constraints are enforceable. This can be on-prem or in the cloud as a VM or equivalent, like a DB service that can scale but isn‚Äôt distributed, so you cannot break a constraint. \n\nVery different to distributed cloud DB computing where PK/FK constraints cannot be enforced, which is why we need to have a landing area for new data, staging, then Medallion. To not import dupes, and then have Cartesian product with Join.",
          "score": 16,
          "created_utc": "2026-01-13 12:32:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzlc3r7",
              "author": "Hulainn",
              "text": "Long time MySQL user here, at large data scales.  FK constraints in your schema will murder performance, and make online schema migration a nightmare once you are at the point where blocking writes for ALTER TABLE is not an option.\n\nThe phrase I liked to use was that we avoided using \"scale limiting features\".  FK constraints are a huge one; triggers (non-trivial ones anyway) and stored functions are some others.  It is shocking how fast MySQL stays if you are mainly using it for indexing, and stick to basic feature usage.  Millisecond lookup on random data keys is the killer feature that no cloud DB gets you, combined with a full SQL engine that can leverage that for join performance as well.\n\nThe thing that often kills you in cloud db land is read amplification, for lookups or joins.  You might have to read MB's or TB's of data to get the same handful of records that MySQL or Postgres could find in a few KB of I/O.",
              "score": 2,
              "created_utc": "2026-01-14 19:17:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzljxhp",
                  "author": "SirGreybush",
                  "text": "Great insights. I agree - my point is more that this is a PK/FK constraints are a \"gotcha\" that just because Snowflake allows in the syntax PK and FK, they are simply a visual reference, a way to document your tables.\n\nBack in the 90's we'd actually future allocate empty rows in binary tables on disk and the code would find a blank and update it, this was faster than locking the table, adding a physical row, unlocking the table. Multiple users accessing the same data row on update, semantic locking. Basically doing what early MSSQL 2000 did with it's paging engine.\n\nSo we were able to achieve crazy efficient speeds, span many disks volumes. This was in Unix of course. The early days of Informix or previously Universe. Our biggest issue was that the OS was 32 bits, so this limited file sizes.",
                  "score": 1,
                  "created_utc": "2026-01-14 19:53:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzddzhc",
          "author": "ZeppelinJ0",
          "text": "I'm an RDBMS glazer and will be for life",
          "score": 7,
          "created_utc": "2026-01-13 15:59:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzckoc4",
          "author": "dessmond",
          "text": "OP preaching to the choir. üôè",
          "score": 5,
          "created_utc": "2026-01-13 13:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzclomj",
              "author": "sexyman213",
              "text": "im new here",
              "score": 1,
              "created_utc": "2026-01-13 13:37:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzcmo02",
                  "author": "dessmond",
                  "text": "For years I dreaded the overhead of the locking mechanisms which come standard with the RDBMSs. We were totally able to roll back transactions per batch. It‚Äôs been a small paradigm shift.",
                  "score": 1,
                  "created_utc": "2026-01-13 13:42:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzdg98h",
          "author": "michaelisnotginger",
          "text": "Managed Postgres is a multi-billion dollar industry...",
          "score": 3,
          "created_utc": "2026-01-13 16:10:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzf1uwn",
          "author": "astrick",
          "text": "This industry is constantly reinventing the same things",
          "score": 3,
          "created_utc": "2026-01-13 20:44:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc9e2c",
          "author": "Wh00ster",
          "text": "Wat",
          "score": 7,
          "created_utc": "2026-01-13 12:18:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd8628",
              "author": "wyx167",
              "text": "Topkek wat indeed",
              "score": 1,
              "created_utc": "2026-01-13 15:32:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcbk5d",
          "author": "hoodncsu",
          "text": "Different tools for different jobs",
          "score": 4,
          "created_utc": "2026-01-13 12:33:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nze4lae",
          "author": "mertertrern",
          "text": "I used to be a DBA, and would also write database code packages in Oracle PL/SQL that fed back-end web services. I fell in love with data-first development (as opposed to code-first) styles that were popular in back-end development at the time.\n\nI came to understand that there are two types of back-end developers: those who know SQL and relational DB internals, and those who don't but end up trying to come up with their own equivalent of it (and usually failing). You can go a long way when you properly leverage the capabilities of a database like Postgres. It's just that many devs seem to find relational databases and SQL to be too esoteric for their liking. Usually when they see how much less back-end code they have to maintain if they let the database do the work it was intended for, they come around.",
          "score": 2,
          "created_utc": "2026-01-13 18:12:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdlk2k",
          "author": "tiny-violin-",
          "text": "Wait till you delve into Oracle ecosystem, it‚Äôs incredible how much effort was put into perfecting every bit of rdbms, including optimized dedicated hardware. They are expensive as hell, also hard to master, but that‚Äôs what I would call a mature technology. Mssql is not far behind too",
          "score": 1,
          "created_utc": "2026-01-13 16:34:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdmpif",
              "author": "sexyman213",
              "text": "I have worked with Oracle in the past. The ecosystem was sophisticated and my firm had built all of their processes around them. License cost was the only problem¬†",
              "score": 2,
              "created_utc": "2026-01-13 16:39:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcepbq",
          "author": "RunOrdinary8000",
          "text": "Maybe it is not that often talked about  because IMHO that is the default. So usually a dwh resides within a Database. \n\nI would say there are 2 base logic I see often in DB driven systems.\nThere is the business logic in the Database approach. You use views and Stored processes to transform data by business logic. Or you have a tool like Matt Lion or DBT to orga use your logic.\n\nThe other one is to keep the data base stupid and use a different tool, like Ab initio, Sas, Informatica or python scripts.\n( I mean if you use Ms fabric that would be similar category.)\n\nActually I am not sure where Apache Spark would belong to.\n\nA third I have not often seen in production is the use of hadoop or Apache Iceberg. Which is more file based. That changes a lot of strategies you use in opposition of a DB based approach. You start thinking in files, which is more natural to a data warehouse then the row based thoughts.\n\nMessaging system are even further away from data warehousing with different requirements. More set in the message logic then in an holistic portfolio view.",
          "score": 1,
          "created_utc": "2026-01-13 12:54:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcjwr5",
              "author": "sexyman213",
              "text": "too many jargons for my inexperienced brain. i will try read about them later",
              "score": 1,
              "created_utc": "2026-01-13 13:27:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzczl9j",
          "author": "Responsible_Act4032",
          "text": "Whoa there Les (UK reference), hold your horses. It's literally horses for courses. PG will do most stuff, but it's not great for scale or analytics. Where great here is high toil to get it working, more than anything else. \n\nI work for [firebolt.io](http://firebolt.io), we have customers combining OLAP and OLTP workloads and we're PostgreSQL compliant and ACID compliant. \n\nCan download it for free too and run it where you want, Core.",
          "score": 1,
          "created_utc": "2026-01-13 14:50:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdcsao",
              "author": "sexyman213",
              "text": "Cool! any chance you have a thesis position in Germany ü•∫?",
              "score": 2,
              "created_utc": "2026-01-13 15:54:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzdov6u",
                  "author": "Responsible_Act4032",
                  "text": "We did recently have an intern who came and worked with us, I'll check with our engineering leadership.",
                  "score": 2,
                  "created_utc": "2026-01-13 16:49:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nze5iz3",
          "author": "sjcuthbertson",
          "text": "I'm deeply hurt and offended that you didn't mention MSSQL, the GOAT of the GOATs in my most humble opinion.\n\nNo this is not satire, yes you can all downvote me now.",
          "score": -2,
          "created_utc": "2026-01-13 18:17:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdk0i0",
      "title": "AI this AI that",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qdk0i0/ai_this_ai_that/",
      "author": "FuzzyCraft68",
      "created_utc": "2026-01-15 13:49:51",
      "score": 79,
      "num_comments": 37,
      "upvote_ratio": 0.93,
      "text": "I am honestly tired of hearing the word AI, my company has decided to be AI-First company and has been losing trade for a year now, having invested AI and built a copilot for the customers to work with, we have a forum for our customers and they absolutely hate it. \n\nYou know why they hate it? Because it was built with zero analysis, built by software engineering team. While the data team was left stranded with SSRS reports. \n\nNow after full release, they want us to make reports about how good it‚Äôs doing, while it‚Äôs doing shite. \n\nI am under a group who wants to make AI as a big thing inside the company but all these corporate people talk about is I need something to be automated. How dumb are people? People considering automation as AI! These are the people who are sometimes making decisions for the company. \n\nThankfully my team head has forcefully taken all the AI Modelling work under us, so actually subject matter experts can build the models.\n\nSorry I just had to rant about this shit which is pissing the fuck out of me. ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qdk0i0/ai_this_ai_that/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzq9124",
          "author": "smolhouse",
          "text": "I work for a large aerospace company known for lousy leadership.\n\nIt's so frustrating listening to the company \"leaders\" talk about AI.  They are throwing huge sums of money at it with little understanding of it's practical uses and no plan on how to effectively apply it, but I guess they get to say AI during earnings calls and board meetings.\n\nI can't wait for this bubble to pop.",
          "score": 62,
          "created_utc": "2026-01-15 14:00:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqam4l",
              "author": "West_Good_5961",
              "text": "Maybe AI will keep the doors from falling off.",
              "score": 14,
              "created_utc": "2026-01-15 14:09:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrs1d4",
                  "author": "smolhouse",
                  "text": "Probably just hallucinate data showing that doors are designed to fall off.",
                  "score": 9,
                  "created_utc": "2026-01-15 18:17:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvbi1k",
                  "author": "NDHoosier",
                  "text": "Engineer:  \"How do I keep airplane doors from falling off?\"\n\nBubbaAI:  \"Use more duct tape.\"",
                  "score": 3,
                  "created_utc": "2026-01-16 05:21:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzqm5bk",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 2,
              "created_utc": "2026-01-15 15:07:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs1yys",
                  "author": "AntDracula",
                  "text": "I doubt they want to answer, or they would have named them. Too private to let out on reddit.",
                  "score": 2,
                  "created_utc": "2026-01-15 19:00:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzqhzna",
          "author": "codykonior",
          "text": "Imagine what you could do if they took all that money they pumped into AI and just ... paid their staff.",
          "score": 34,
          "created_utc": "2026-01-15 14:47:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqo86i",
              "author": "FuzzyCraft68",
              "text": "Oh no that would lead to good tested software to be built rather than sloppy code",
              "score": 21,
              "created_utc": "2026-01-15 15:17:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzre6xx",
              "author": "LoaderD",
              "text": "No, that makes no sense, these AI companies will always be cheap. There‚Äôs no way they are just hooking companies in then 100-1000x their make revenue actually justify their valuation /s",
              "score": 6,
              "created_utc": "2026-01-15 17:14:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03m6oa",
                  "author": "Expensive_Culture_46",
                  "text": "Thank you.",
                  "score": 2,
                  "created_utc": "2026-01-17 13:17:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzqle7a",
          "author": "chamomile-crumbs",
          "text": "Idk if you‚Äôve seen this but you will love it \n\nhttps://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/",
          "score": 16,
          "created_utc": "2026-01-15 15:03:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrmuep",
              "author": "thecoller",
              "text": "It‚Äôs been a full year and reads just as relevant",
              "score": 7,
              "created_utc": "2026-01-15 17:53:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrjhvk",
              "author": "Thrillhousez",
              "text": "This was great. My org started an AI projects team. We are basically doing automation work and calling it AI. There is only some small amount of experimental machine learning .",
              "score": 3,
              "created_utc": "2026-01-15 17:38:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03mz25",
                  "author": "Expensive_Culture_46",
                  "text": "My favorite part is they spend insane amounts of money because all they really wanted was a a way to query their dashboards. \n\nWorking on a project where they want a custom LLM to generate SQL and query a data base and return reports. Do they want it to make custom reports? NO, just reports from this list of 10 queries. They spending 6 figures worth of cash to add more time to their day having to type ‚Äúshow me the blah blah report‚Äù rather than click a god damn button. \n\nOh. And they loose the ability to actually interact with said data because it‚Äôs just static tables for excel.",
                  "score": 1,
                  "created_utc": "2026-01-17 13:22:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztepdj",
              "author": "reviverevival",
              "text": "I think an underrated and prescient point is that 99% of companies need to do literally nothing to capture the value of AI. We actually have a fairly competent in-house AI team that managed to build a value-add product with some level of sophistication. But I tried Claude code and it's like wow! Who is going to be using our (comparatively) shitty homebrew framework in 24 months, when every user (internally and externally) is just going to be rolling with Claude Cowork 2.0 installed on their desktop? It would be as if every company was trying to build an in-house spreadsheet software the second after windows 3.0 landed.",
              "score": 2,
              "created_utc": "2026-01-15 22:48:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztv0eh",
          "author": "umognog",
          "text": "One of the best things we can do with AI, is replace leadership teams with it. The line of work is right up AI alley; spout some waffle then hazard a guess at what to do.",
          "score": 7,
          "created_utc": "2026-01-16 00:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvaj5q",
              "author": "NDHoosier",
              "text": "Would that system be ChatPHB?",
              "score": 1,
              "created_utc": "2026-01-16 05:15:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsxmuo",
          "author": "WhoIsJohnSalt",
          "text": "Look. \n\nForget AI\n\nIt‚Äôs Agentic. \n\nBut wait! Agent can mean anything from an LLM to a SLM, to an AI/ML model, to some python. \n\nWith some orchestration. \n\nThink of them as Orchestration DAGs with objects of varying capabilities. \n\nTake the hype money, deploy meaningful code, just like we all did in the GDPR panic of 2016",
          "score": 6,
          "created_utc": "2026-01-15 21:26:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuyly4",
              "author": "Weekly_Activity4278",
              "text": "This the way",
              "score": 2,
              "created_utc": "2026-01-16 03:57:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzszlh3",
          "author": "speedisntfree",
          "text": "I get triggered by AI because I'm still half a bioinformatician where I'm actually building and training deep learning models, not shovelling prompts via API to pre-trained LLMs which is basically web dev.\n\nOur management took the AI bait hard last year but the failing PoCs have actually been very beneficial. People were lobbing a transactional DB designed by academics into Databricks and getting LLMs to write SQL. What was became obvious (and what is very obvious to anyone here) is that is you don't have decent clean data, accessible and well organised, the LLMs don't do so well. \n\nSince senior people staked their career advancement on this, it has redirected focus hard onto DE. Recruitment and also stopping every project doing its own thing YOLOing blob storage and Databricks. We are finally producing a cohesive approach to data I've been pushing for when no one ever cared previously.",
          "score": 5,
          "created_utc": "2026-01-15 21:35:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzf73o",
              "author": "shougaze",
              "text": "It can‚Äôt deal with the context. They spent all this money for recommended queries and tables that don‚Äôt make sense. Like the code runs, but it‚Äôs meaningless. It doesn‚Äôt understand when something doesn‚Äôt make sense and it can‚Äôt keep track of really complex data needs, it gets distracted and derailed and overwrites what it was originally trying to do",
              "score": 2,
              "created_utc": "2026-01-16 20:09:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03nsff",
                  "author": "Expensive_Culture_46",
                  "text": "It‚Äôs like managing a child. But if these idiots got their way they would hire children in a second and pay them in ‚Äòlove‚Äô",
                  "score": 1,
                  "created_utc": "2026-01-17 13:27:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03nm1w",
              "author": "Expensive_Culture_46",
              "text": "‚ÄúSir we are busy building the future. We don‚Äôt have time for data governance. Also do you know which of these 5 columns called ‚Äòmeasurement‚Äô are actually the one we need‚Äù",
              "score": 1,
              "created_utc": "2026-01-17 13:26:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw0hj9",
          "author": "davatosmysl",
          "text": "I know. The moment I see AI on a website or in a video I'm closing the tab.",
          "score": 3,
          "created_utc": "2026-01-16 08:49:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00ouaj",
              "author": "GlueSniffingEnabler",
              "text": "I‚Äôm being a dick, but I just can‚Äôt help pointing out that you didn‚Äôt close this one¬†",
              "score": 1,
              "created_utc": "2026-01-16 23:57:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzry8pb",
          "author": "AntDracula",
          "text": "I'm so burned out on AI you can't imagine.",
          "score": 2,
          "created_utc": "2026-01-15 18:44:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzunepn",
          "author": "billysacco",
          "text": "Man if this AI bubble bursts it‚Äôs going to be bad",
          "score": 1,
          "created_utc": "2026-01-16 02:52:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvadxh",
          "author": "NDHoosier",
          "text": "Company executives are chasing AI for one reason and one reason only.  They hope to replace nearly all their employees with it.  They are licking their chops at finally laying hands on the unholy grail:  a nearly infinite profit margin (revenues with nearly zero costs).  All other reasons given are just commentary or, more likely, obfuscation.\n\nSnake-oil salesmen like Sam Altman should, when they die, be buried face-down so they can see where they are going.\n\nAdd: I am hoping that AI and its evil disciples meet a fate similar to the Tower of Babel and its builders.",
          "score": 1,
          "created_utc": "2026-01-16 05:14:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwqfoc",
          "author": "New-Addendum-6209",
          "text": "Lots of talk about AI in my place but developers and analysts are only officially allowed to access LLMs through a single out of data corporate chat interface or Copilot through MS products.",
          "score": 1,
          "created_utc": "2026-01-16 12:28:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o031t4g",
          "author": "Typhon_Vex",
          "text": "we live in era of the triumph of stupidity.\n\nstupid people win in global and local poitics, elected by stupids,\n\nand companies ar erun by incompetent and stupid managers and directors, with no knowledge of what they ar managing and directing",
          "score": 1,
          "created_utc": "2026-01-17 10:31:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03mjvq",
          "author": "okenowwhat",
          "text": "While talking to recruiters i realised a thing:\n* data analysis is now called AI\n* machine learning is now called AI\n* using AI to help with coding is called AI engineer\n\nIs it something computer related an non-technical person doesn't understand? It's called AI now.\n\nAI is just another bullshit marketing buzzword.",
          "score": 1,
          "created_utc": "2026-01-17 13:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bzqdf",
          "author": "varwave",
          "text": "I‚Äôm thankfully at a role with a statistics background, in a smaller department, where I can say ‚Äúyeah, we‚Äôre not doing that‚Äù‚Ä¶basic CRUD software development still stuns business people if delivered correctly to meet needs \n\nThe same people rushing to AI think Excel is a great place to store important data üòÇ",
          "score": 1,
          "created_utc": "2026-01-18 18:27:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzufxg8",
          "author": "SRMPDX",
          "text": "You have to decide if you're going to embrace it or be left behind by it. Everyone wants AI, so either profit off of that need or move over for the guy who will.",
          "score": -1,
          "created_utc": "2026-01-16 02:11:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03ouae",
              "author": "Expensive_Culture_46",
              "text": "![gif](giphy|8J5ttmATzHeEw)\n\nAnyone here ever watch mars attacks. ‚ÄúOh they must just hate doves‚Äù\n\nI am working with one of these self-proclaimed AI leaders. Absolutely charlatan who says shit like ‚Äúdown to the silicon‚Äù. I will continue to let him get to the front of the line so he falls flat on his face because when he fails I can come in and ask for 3x the money and half to work to fix the half garbled mess he has left behind.",
              "score": 0,
              "created_utc": "2026-01-17 13:33:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qcw5qe",
      "title": "Data modeling is far from dead. It‚Äôs more relevant than ever",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qcw5qe/data_modeling_is_far_from_dead_its_more_relevant/",
      "author": "eczachly",
      "created_utc": "2026-01-14 19:04:52",
      "score": 78,
      "num_comments": 41,
      "upvote_ratio": 0.91,
      "text": "There‚Äôs been an interesting shift in the seas with AI. Some people saying we don‚Äôt need to do facts and dimensions anymore. This is a wild take because product analytics don‚Äôt suddenly disappear because LLM has arrived. \n\nIt seems like to me that multi-modal LLM is bringing together the three types of data:\n\n\\- structured \n\n\\- semi-structured\n\n\\- unstructured \n\nDimensional modeling is still very relevant but will need to be augmented to include semi-structured outputs from the parsing of text and image data. \n\nThe necessity for complex types like VARIANT and STRUCT seems to be rising. Which is increasing the need for data modeling not decreasing it. \n\nIt feels like some company leaders now believe you can just point an LLM at a Kafka queue and have a perfect data warehouse which is still SO far from the actual reality of where data engineering sits today \n\nAm I missing something or is the hype train just really loud right now? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qcw5qe/data_modeling_is_far_from_dead_its_more_relevant/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzle6ig",
          "author": "Ok-Recover977",
          "text": "i feel like people who say we dont need facts and dimensions anymore are engagement baiting",
          "score": 105,
          "created_utc": "2026-01-14 19:27:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmf26z",
              "author": "tophmcmasterson",
              "text": "I‚Äôve encountered many and I think it‚Äôs more just people who are happy to produce whatever ad-hoc slop they‚Äôre asked for and never learned to do things the right way. \n\nSo because they don‚Äôt understand dimensional modeling, they don‚Äôt understand the point of it, and try to write it off as ‚Äúsomething people used to do to save space‚Äù even when the reasons to implement a dimensional model have much more to do with usability and flexibility in reporting.",
              "score": 21,
              "created_utc": "2026-01-14 22:14:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzpafrm",
                  "author": "Ulfrauga",
                  "text": "The answer I've been given to my question of that nature has been along the lines of \"data is small\", \"only a few tables\".\n\nYep.  True.  But I don't think that's the point.  Go ahead and chuck it in to Power BI as it is....copy paste your \"bronze\" code into a \"gold\" version and call it done..... have fun battling mixed up grains and transactional tables with a bunch of custom columns and shit.\n\nStuck a nerve methinks.  But someone who says \"I know about dims and facts\"...should know about dims and facts...unless that statement doesn't actually extend to overall data modelling concepts.\n\n\\*Edit my kneejerk half-baked post.  This theme has been a broken record at work..\n\n\n\nI mean to say I agree that data modelling - in whatever form, be it Kimball or Data Vault or whatever else - *shouldn't* be pronounced dead just because \"storage is cheap\" and we can scale compute.  That's only part of the point of it, IMO.  I also agree that strict modelling like Kimball dims and facts *aren't* always the right form of output.  Some semblance of processing and curation remains necessary, even if the resulting structures start to be different.",
                  "score": 2,
                  "created_utc": "2026-01-15 09:46:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo21rs",
              "author": "Key-Alternative5387",
              "text": "I'm not so sure. In over 10 years, I've never used facts and dimensions in big data applications and it's gone extremely well for everyone involved.\n\nJust throw related data together. Depending on the usecase -- wide tables can be okay.\n\nIt's certainly not useful in terms of performance and would be an enormous detriment for most of the projects I've worked on due to scale issues.",
              "score": 4,
              "created_utc": "2026-01-15 03:41:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzlfti5",
              "author": "Sex4Vespene",
              "text": "I think it 100% depends on the type of data you are working with. For example, I work in healthcare data, that‚Äôs large sourced from a heavily normalized application database. The majority of what is needed for us to prepare that in the analytics layer is to denormalize it and make some marts/facts from that. Dimensions largely don‚Äôt add much value to us, as most of the relationships are just defined as primary to primary or primary to foreign key joins between those tables, and all the columns we need are directly from those tables being joined. However I will readily admit that dimensions have their uses, just saying in our case they provide basically nothing.",
              "score": 5,
              "created_utc": "2026-01-14 19:34:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmc43t",
                  "author": "Choice_Figure6893",
                  "text": "All you're saying is it's someone else's job",
                  "score": 12,
                  "created_utc": "2026-01-14 22:00:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzmfqwv",
                  "author": "Beautiful-Hotel-3094",
                  "text": "Isn‚Äôt the whole point of it the fact that u can easily get from the dwh whatever u needed? In a world where u didn‚Äôt have a well defined relational dwh, you would have had to maintain some spaghetti pipelines and probs redo a lot of logic in multiple places to achieve what u already have now? Correct me if I am wrong, I do not know the details ofc.",
                  "score": 4,
                  "created_utc": "2026-01-14 22:17:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzndbuu",
                  "author": "lugiamax3000",
                  "text": "It does depend on your definition of dimensional modelling. In a strictly traditional Kimball sense, maybe yes it‚Äôs not useful to have everything live as strictly dims and facts - but in the broader sense, the idea of creating easy to access distinct business entities is not outdated at all - and in your case, your marts are created from these normalised entities directly - whereas majority of companies require them to be modeled in the DWH.\n\nTo me, what you‚Äôre saying is that, since your source data is already modeled in a dim/fact friendly way, dim/fact data modeling is useless - tbh this is a really bizarre take for a ‚Äúprinciple data engineer‚Äù",
                  "score": 3,
                  "created_utc": "2026-01-15 01:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o015vuq",
              "author": "jayzfanacc",
              "text": ">‚ÄùYour company no longer needs data modelers. Our custom-built AI model will solve all your problems. Just blindly feed your propriety data into it‚Äù\n\n>costs $20,000/mo and sells your customer and vendor list on eBay",
              "score": 1,
              "created_utc": "2026-01-17 01:39:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzlecgg",
              "author": "eczachly",
              "text": "100%. Counting things still matters and the context window of an LLM isn‚Äôt a billion rows of data",
              "score": 1,
              "created_utc": "2026-01-14 19:28:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzlecbd",
          "author": "69odysseus",
          "text": "I work as a data modeler and can say this, data models are more needed now than ever.¬†\n\nMost of the companies build pipelines without models, now they're all facing issues and they don't have backward traceability. Everyone rushed pushing pipelines into production without proper models, processes, conventions and standards in place. Data Modeling is not easy skill to obtain and requires lot of effort, time and multitude skills.¬†\n\nMy current teams uses data vault and dimensional modeling frameworks, it takes time to get to final data marts and views on top but we rarely have pipeline issues (DBT, Snowflake). We spend lot of time upfront, which saves lot of money and reduce development time and effort down the line, which is the right way of doing things.¬†\n\nWhen we face any ELT issues, then we go back to the data model and analyze on how to de-couple, optimize the model without breaking the grain at times. It saves lot of load times in some of those big fact tables. ¬†The issues I also noticed and I made those mistakes as well, shove tons of metrics into a fact table and calculate them at the fact table level. Instead those metrics should be calculated at one layer up (business vault or raw vault) layer and just load them as is into fact table. Fact table should be a simple select * from xyz tables.¬†\n\nThere's so many things that can go wrong in a pipeline and data model can solve many of those. We normally do a hands off to our DE's of our data models and mapping docs, it makes their life whole lot easier and efficient at times.¬†",
          "score": 36,
          "created_utc": "2026-01-14 19:28:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzleiqk",
              "author": "eczachly",
              "text": "Investing in repeatable truth access is never a bad investment. I love this strategy",
              "score": 5,
              "created_utc": "2026-01-14 19:28:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzpsi20",
                  "author": "69odysseus",
                  "text": "Oh crap, I didn't realize till now (Friday 5:20am mst) that it was you Zack, who posted it.üòÜüòÜ¬†\nI enrolled into Karan's cybersecurity bootcamp and we just completed the first week.",
                  "score": 2,
                  "created_utc": "2026-01-15 12:20:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzlfryg",
              "author": "randomName77777777",
              "text": "I've been working on building a data model from the ground up using a star schema and trying to follow the Kimball methodology but I feel like I'm really struggling because I can't find any good resources online. Unfortunately we don't have any data modelers and it falls on my shoulders. \n\nDo you have any recommendations for good resources online?",
              "score": 2,
              "created_utc": "2026-01-14 19:34:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlj1yr",
                  "author": "LargeSale8354",
                  "text": "The Kimball university site remains online, preserved for posterity.  Kimball's DataWarehousing Toolkit book is still in print.",
                  "score": 8,
                  "created_utc": "2026-01-14 19:49:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzljxyo",
                  "author": "69odysseus",
                  "text": "Every online course only focuses on Databricks and Snowflake but not a single course out there that teaches data modeling because it's hard subject to teach. I haven't come across any good modeling course myself and can't point you in wrong direction.¬†\n\nData Model design is primarily based on \"cardinality\", then comes the de-coupling aspect of breaking into smaller objects rather than big tables, then follows the scalability aspect of the object.\n\n1) This is how I do data modeling at my current team: I data profile for a day or two, meaning I first collect column level stats of a table(s). I look at no# of distinct, nulls, pk/fk, total count of table, etc.¬†\n\n2) Then I take few ID's and review data at row level to understand what type of data am I looking at. I look at timestamps, Boolean fields, status fields.¬†\n\n3) Then I'll use functions like QUALIFY to look at records in a table, see what's changing at row level and what's causing that change for a new row.¬†\n\n4) If I don't understand data at that point, then I'll get my SME's into a meeting and get lot more clarification. By this time, I'll have pretty good idea about the data domain in order to start my modeling at stage layer.¬†\n\n5) First I start with stage layer, followed by raw vault, if needed business vault and dimensional layer model.¬†",
                  "score": 10,
                  "created_utc": "2026-01-14 19:53:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzlwas1",
          "author": "SoggyGrayDuck",
          "text": "It's going to have to make a major comeback. As these companies realize NONE of their metrics (maybe the core metrics are ok) across departments line up. It's like a 10 year cycle, numbers are bad, spend 3-5 years moving towards strict data models and standards. As the business grows and no longer remembers those problems points the finger at slow development, leaders get replaced and the silo/tech debt starts over. \n\nI'm in the middle of one thats blowing my mind. Working on core metrics that all source from 5-6 dates, calculating the time between timestamps. Instead of defining those 5-6 dates with proper labels we expect the devs to get that same date whenever it's needed for a metric.... This isn't clean data and I could calculate these data points several different ways using different columns to filter. Sure they'll be close but those minor differences have cost companies millions when it distracts from the actual conversation.",
          "score": 14,
          "created_utc": "2026-01-14 20:49:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0063dk",
              "author": "girlgonevegan",
              "text": "They need to read the 4-digit zip codes on the wall. üò≠",
              "score": 1,
              "created_utc": "2026-01-16 22:17:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmhzf6",
          "author": "evlpuppetmaster",
          "text": "Totes. The idea that we don‚Äôt need modelling anymore could only be pushed by people who have no clue what they are on about, or grifters trying to sell you bullshit snake oil. Unfortunately CTOs will lap it up because data modelling takes time and expertise, and therefore money. AI produces superficially easy results that appear reasonable enough on first glance. But AIs don‚Äôt actually know anything about your business so they will confidently tell you things that are completely wrong, or which are true but not the correct answer to your question.¬†\n\nData modelling is not primarily a technical discipline, it is about extracting human-understandable meaning from what is otherwise just a bunch of ones and zeroes. It requires understanding your business deeply, and understanding what the business cares about and needs to measure. ¬†This meaning is often not directly available in your raw data. You have to translate it for a business user.\n\nNow this is where the AI grifters will tell you ‚Äúoh sure the AI isn‚Äôt great at that now but it‚Äôs going to get better with better models‚Äù. And sure, it will. But even when you have better models that can more accurately translate the user‚Äôs intent into a correct answer, you will still have the problem that each individual user is having a separate conversation with an AI. Bob might ask for revenue figures for last month, the AI asks him how to define revenue and gives him a correct answer based on his definition. Jenny has a separate conversation with the AI and gives a slightly different definition and the AI gives her a correct but DIFFERENT answer.¬†\n\nSo how do you fix this situation and ensure that Bob and Jenny get the exact same answer for revenue? You have to make sure there is a source that has the correctly calculated and verified definition of revenue ready for the AI to use. And what do we call this process? Data modelling!\n\nIf anything, data modelling only gets more important in the age of AI. Since in the past when you had highly technical data and BI analysts answering the questions for you, you could rely on them having enough knowledge and expertise to work around the complexities and problems of the data. But in a world where every Bob, Jenny, and Harry with no technical knowledge expects to be able to ask the AI for answers themselves, you better be damn sure that it is working off a highly curated and verified source.¬†",
          "score": 7,
          "created_utc": "2026-01-14 22:28:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlna8h",
          "author": "Unhappy_Commercial_7",
          "text": "I agree with your point, LLMs actually demand more modeling complexity, especially when you are now adding structured data along with parsed documents and metadata. Maybe also coupled with a feature store for model inputs/outputs\n\n\nIt would actually increases the surface area for data modeling. Someone needs to decide how to represent extracted entities, where embeddings live, how to join LLM outputs back to source records, and maintain consistency across all of it.\n\nOn a side note, LLM on a kafka queue for analytics sounds like a classic ‚Äúthis type its gonna be different because AI‚Äù kind of a take, cannot even imagine how bad its gonna be",
          "score": 5,
          "created_utc": "2026-01-14 20:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm6w33",
          "author": "fauxmosexual",
          "text": "The data hype train seems to be intent on forgetting and reinventing each and every wheel it has. That's because the people on the train want to get somewhere, but the train is owned by a wheel-selling company. This metaphor got away from me, kind of like a runaway train. \n\nThe best use of off-the-shelf AI products is pointing them at really good semantic models. It's dashboarding that's dying, if you haven't fired your dashboarders yet it's time to start teaching them a little Kimball.",
          "score": 4,
          "created_utc": "2026-01-14 21:37:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn8281",
          "author": "Soldierducky",
          "text": "Facts and dims is really more UX first then for whatever engineering reasons (even though less joins are a performance boost)¬†\n\nPeople forget this. In kimball, he always talks about how the models should really cater for the end user and the qns asked\n\nIn the advent of AI, this is no different. If you really model well, the AI can easily write queries for common metrics because the base table is well name and understood. Then the rest of the refinement are really a bunch of where clauses¬†",
          "score": 3,
          "created_utc": "2026-01-15 00:46:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn85x3",
          "author": "Gators1992",
          "text": "Data modeling always has been and always will be important.  It's not just one pattern though, it's sticking with whatever pattern makes sense for your company and ensuring it doesn't end up in a pile of irreconcilable shit.  I don't see a huge reason to do dimensional modeling anymore other than your downstream tools may  like it and it's useful if you have a lot of cross-subject rate calculations that benefit from conformed dimensions.  A lot of businesses don't need that though and are fine with stuff like OBTs and master data and those help them move faster.\n\nI am also skeptical that we are going to see a lot of usefulness with LLMs and data any time soon.  I think AI is very useful as a tool to help build pipelines and tools, but not as much for accessing data right now.  Data models can be massive with lots of tables, columns and semantic descriptions for the content, so you end up flooding the context window and confusing the model (most of which is irrelevant context to the problem).  A lot of the definitions are weird so don't align well with the model's training and people also ask the same question 20 different ways, which can lead to inconsistent answers.  \n\nThe way I have seen people trying to make AI systems that work is by slowly building up the model and keeping it small (i.e. not the enterprise model you are used to).  So in the end it can only answer simple questions like \"tell me how much revenue we earned from product X in the last three months\".  Given how much time you spend building and tuning the model until you feel like it works most of the time, isn't it faster to just give them a dashboard with the same capability and better accuracy?  Also the user community is thinking that they will be able to prompt the model to do a deep dive that an analyst would spend a week on and that's just not reality.",
          "score": 3,
          "created_utc": "2026-01-15 00:46:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp2npt",
          "author": "Crazy-Sir5935",
          "text": "Lol! \n\nI came from being a controller to being a data analist/scientist to being a n00b data engineer but i can tell you one thing from my domain expertise, data modelling is key for success in any organization that leans heavily on data. \n\nBiggest issue i see with people just rushing the data from A to B is that they basically construct jungles in where employees end up defining their own version of the truth and thereby undermining a core principle of why you had that warehouse/lakehouse in the first place. Departments will build their own vision on top of the mess you supply them with. I had a discussion lately with a professor ranting how multiple versions of the truth can coexist but believe me, companies just want 1 version. In the end, you don't want to have senior level management have a discussion in a meeting about what a cost center is, what data is correct, on what date FTE stats are calculated for reports and what the source is of all of this (that, in effect, will surge your indirect costs, drop the trust in your solution and eventually have management question why in gods name they hired those engineers).",
          "score": 3,
          "created_utc": "2026-01-15 08:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp4ijj",
          "author": "One_Citron_4350",
          "text": "Great topic to bring up. I share the same feeling that there is this hard push to avoid the problem altogether. \n\nYes, let's jump on the datalakehouses, as medallion architecture is the one-size fits all solution. Forget about DWH, analytics, we'll leave the business logic to the visualization anyway. Only later they find out the dashboard slow and useless, metrics are useless but by then it's too late...\n\n  \nEvery two weeks there is a new tool or concept that is rebranded that the community hypes about, LinkedIn is a primary example of this. Then it dies and people forget about it as something else comes up.",
          "score": 3,
          "created_utc": "2026-01-15 08:48:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzof0ti",
          "author": "pvtbobble",
          "text": "25+ years ago during dot com, every dev had a mysql db and enterprise data models were pushed aside. Sensitive data - HR, GL accounts, etc - were being copied from app to app. Downstream apps no longer pointed to the source of truth. Data governance fell away.\n\nThe rush to AI has a similar feel but in my experience orgs are realising to higher entry cost is not offset if data structures are not understood. After all, an enterprise data model is the language of the organisation. It's an ideal input to an LLM.\n\nAnd the age of data breaches and leaks has made sure orgs are more likely to ensure data stewardship is in place before launching data at AI.\n\n*About 10% of this actually happens but it's a good start :)",
          "score": 2,
          "created_utc": "2026-01-15 05:09:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzow20d",
          "author": "CognatixCoach",
          "text": "Most of the replies here are actually saying the same thing in different ways.\n\nWhether people call it *semantic layers*, *metrics stores*, *data products*, or *business models*, the underlying idea hasn‚Äôt changed - data only becomes valuable when it‚Äôs **understood, shaped, and aligned to an outcome**.\n\nThat‚Äôs data modelling.\n\nGood models aren‚Äôt about rigid schemas for their own sake. They‚Äôre about:\n\n* expressing how the business thinks,\n* anchoring data in decisions and outcomes,\n* and making meaning explicit rather than inferred.\n\nAnd if anything, AI makes this **more**, not less, important.\n\nAI doesn‚Äôt magically ‚Äúunderstand‚Äù raw data. It relies on well-defined structures, relationships, and semantics to reason, generalise, and produce trustworthy results. Poorly modelled data just scales confusion faster.\n\nWhat‚Äôs fading is *modeling for its own sake.* What‚Äôs emerging is **outcome-led, human-centred modelling** ‚Äî and that‚Äôs exactly what modern data platforms *and* AI depend on.",
          "score": 2,
          "created_utc": "2026-01-15 07:28:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzppta5",
          "author": "Dogentic_Data",
          "text": "The idea that LLMs somehow replace modeling feels like confusing interface with foundation. You can query messy data with an LLM, but you still can‚Äôt reason about it reliably without structure underneath. In practice it feels like modeling is expanding, not disappearing. You still need strong cores, plus layers that can handle semi-structured and derived outputs. Pointing an LLM at a stream doesn‚Äôt magically solve lineage, quality or consistency.",
          "score": 2,
          "created_utc": "2026-01-15 12:00:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpwxn3",
          "author": "His0kx",
          "text": "Agree. LLMs are a powerful tool/technology but they need curated and clean data to work at their real potential (hello good sh*t in sh*t out) and in an appropriate context window. My guesses :\n\n- The comeback of a real semantic layer and cubes backed by proper dim/fct tables (for BI)\n\n- Proper RAG to access documents and other ressources\n\n- Unstructured data (json) for ¬´¬†persistent¬†¬ª memory for long workflow/tasks ie how to properly chain the information trough multiple agents\n\n \nWhat I found funny/ironic is that we are coming back to old school BI problematics : how to optimize data to fit on a limited system (ie token window of a LLM). A lot of people are all doom with IA/LLM while I think our job (as a data engineer) has a lot of new interesting challenges in the next 5-10 years, just different that we are used to.",
          "score": 2,
          "created_utc": "2026-01-15 12:50:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznzex4",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-15 03:25:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp9yjx",
          "author": "Sharp_Conclusion9207",
          "text": "Just an open ended question to tag this thread as soming with more of an analytica engineering backgrounds what are some of the attributes and qualities a good data model should exhibit? Naming consistency, reusable patterns? Appropriate natural keys? Table indexes etc.",
          "score": 1,
          "created_utc": "2026-01-15 09:41:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwamjr",
          "author": "CriticalJackfruit404",
          "text": "Zach, can you offer a standalone data modeling module on your site, instead of only selling the full data engineering course?",
          "score": 1,
          "created_utc": "2026-01-16 10:23:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxltfz",
          "author": "Thinker_Assignment",
          "text": "with code being commoditized by autofill, architecture and management become more and more important, and we have a little more time for them too",
          "score": 1,
          "created_utc": "2026-01-16 15:18:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbx8ay",
      "title": "Data engineer with 4 years what do I need to work on",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qbx8ay/data_engineer_with_4_years_what_do_i_need_to_work/",
      "author": "Fantastic_Bed_6378",
      "created_utc": "2026-01-13 17:24:54",
      "score": 77,
      "num_comments": 40,
      "upvote_ratio": 0.93,
      "text": "Hi all,\n\nI‚Äôm a data engineer with 4 years experience , currently earning ¬£55k in London at a mid sized company.\n\nMy career has been a bit rocky so far and I feel like for various reasons I don‚Äôt have the level of skills that I should have for a mid level engineer , I honestly read threads on this sub Reddit and sometimes haven‚Äôt even got a clue what people are talking about which feels embarrassing given my experience level.\n\nSince I‚Äôm the only data engineer at my company or atleast in my team it‚Äôs hard to know how good I am or what I need to work on.\n\n\nHere‚Äôs what I can and can‚Äôt do so far\n\nI can:\n-Do basic Python without help from AI, including setting up and API call\n\n-Do I would say mid level SQL without help from AI\n\n-Write python code according to good conventions like logging, parameters etc\n\n-Can understand pretty much all SQL scripts upon reading them and most Python scripts\n\n-Set up and schedule and airflow DAG (only just learnt this though)\n\n-Use the major tools in the GCP suite mostly bigquery and cloud storage\n\n-Set up scheduled queries\n\n-Use views in bigquery and set them up to sit on a looker dashboard\n\n-have some basic visualisation experience with power bi and looker too\n\n-Produce clear documentation\n\n\n\nI don‚Äôt know how to:\n\n-Set up virtual machines\n\n-Use a lot of the more niche GCP tools (again I don‚Äôt even really know what I don‚Äôt know here)\n\n-do any machine learning or data science \n\n-Do mid level Python problems list list \ncomprehensions etc without help from AI\n\n-Do advanced SQL problems without help from AI.\n\n-Use AWS or azure\n\n-Use databricks \n\n-Use Kafka\n\n-Use dbt \n\n-Use pyspark\n\nAnd probably more stuff I don‚Äôt even know I don‚Äôt know\n\nI feel like my experience is honestly more around the 2 years sort of level,  I have been a little lazy in terms of upskilling but also had a couple of major life events that disrupted my career I won‚Äôt go into here\n\nWhere can I get the best bang for my buck so to speak upskill I f over the next year or so the trying to pivot for a higher salary somewhere else, right now I have no problem getting interviews and pass the cultural fit phase mostly as I‚Äôm well spoken and likeable but always fail the technical assesment  (0/6 is my record lol)",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qbx8ay/data_engineer_with_4_years_what_do_i_need_to_work/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzdu1k4",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-13 17:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdwiy9",
          "author": "AverageGradientBoost",
          "text": "You do not need to know how to do everything without AI. What matters more is knowing which tools solve which problems. Using AI is completely fine as long as you understand the code it produces and could reason about it yourself.\n\nSame idea with tooling. A GCP or AWS cert is useful, not because you will be an expert in every service, but because it expands your mental map of what tools exist and what they are good at. You can always go deep and learn them properly when you actually need them.",
          "score": 28,
          "created_utc": "2026-01-13 17:36:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nze8gxk",
          "author": "Certain_Leader9946",
          "text": "You need to work on your salary negotiation skills. You're lacking that mercantalist attitude and, without realising that the market is pretty solid right now letting organisations pay you a junior level salary (yes, a junior salary for companies with a strong tech culture) with 4 YOE.\n\nThis isn't always a hard skills problem. This is also a softskills problem. Sorry to break it to you but markets do not operate on merit alone. It's also who you know, who you get to know, and timing. I was working a junior salary for the longest time (40k a year junior dev) and then I went right up to 170k/year as of today. I was lucky to have the Elixir slack group back in the day sit me down and have this talk with me and make me realise I'm letting myself get hustled (or fleeced if you're a northerner like me :) ) because I lack the self confidence to apply for positions that pay a respectable income, in the UK, above what a copywriter makes. \n\nI think you need to work more towards becoming a software enigneer and less of a tooling engineer. But even with your experience I'd estimate you should be able to pull at least 30k more in more of a devops role. There are a LOT of companies with broken data pipelines. Your job is to get street wise.",
          "score": 35,
          "created_utc": "2026-01-13 18:29:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzeazh7",
              "author": "Fantastic_Bed_6378",
              "text": "Well this attitude is kind of a result of me persistently failing technical interviews which makes me feel like my hard skills are the issue.   I have passed 1st stage interviews for a variety of roles between ¬£60-75k (which is probably market rate for my experience level and location )",
              "score": 8,
              "created_utc": "2026-01-13 18:40:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzgg51y",
                  "author": "CJDrew",
                  "text": "What types of questions are you failing? Seems like you should focus on that",
                  "score": 2,
                  "created_utc": "2026-01-14 00:56:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgfdbt",
                  "author": "Certain_Leader9946",
                  "text": "market rate means you're batting average. shoot for exceptional. every time.",
                  "score": 1,
                  "created_utc": "2026-01-14 00:52:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzdvj2y",
          "author": "Level-Gap-1398",
          "text": "!RemindMe 7 days \"Check this thread\"",
          "score": 11,
          "created_utc": "2026-01-13 17:31:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze4qsg",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 7 days on [**2026-01-20 17:31:53 UTC**](http://www.wolframalpha.com/input/?i=2026-01-20%2017:31:53%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1qbx8ay/data_engineer_with_4_years_what_do_i_need_to_work/nzdvj2y/?context=3)\n\n[**4 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1qbx8ay%2Fdata_engineer_with_4_years_what_do_i_need_to_work%2Fnzdvj2y%2F%5D%0A%0ARemindMe%21%202026-01-20%2017%3A31%3A53%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qbx8ay)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 2,
              "created_utc": "2026-01-13 18:13:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfq30w",
          "author": "No_Rhubarb7903",
          "text": "After 4 years of experience I would say the skill that will level you up the most is ProductSense. ProductSense means that you have the ability to work backwards from the product to the data pipelines. Understanding what needs to be measured, how to measure it, and then building the pipelines.\n\nSome core skills that you need to be really good at in todays modern data tech stack world are these:\n\n- Strong SQL, i.e. its like reading and writing english\n- DBT, don‚Äôt let a new tool intermediate you, it‚Äôs just SQL queries orchestrated in an autogenerated DAG. \n- Data QA, building pipelines where data quality tests are first class citizens. The moment your dashboard shows one wrong number people instantly loose trust in your data assets. Better to delay data availability then delivering and redacting later.\n\nSome tools to look into:\n- Airbyte for data ingestion\n- Superset and Metabase for BI tools\n- Duckdb",
          "score": 5,
          "created_utc": "2026-01-13 22:37:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjwz6z",
              "author": "PowerUserBI",
              "text": "100% this",
              "score": 3,
              "created_utc": "2026-01-14 15:27:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzgcxpp",
          "author": "WanderingGunslinger",
          "text": "Dude you literally got the basics right.\n\nYou know enough python and sql to make things work and you already work with one of the 3 big cloud providers (gcp). \n\nThe big issue you've got is that of confidence. Unless you want to be in the top 1 percent of data engineers working for a faang like company, your skillset should be good enough to solve a company's problems from a data engineering perspective.\n\nYou could study a bit of data modelling (Ralph Kimball is the OG in this field, so I recommend studying his approach) but otherwise stop selling yourself short...\n\nAnother alternate career path is to look up Analytical / BI engineering and see if you are a good fit there...",
          "score": 3,
          "created_utc": "2026-01-14 00:39:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzesgkw",
          "author": "PowerbandSpaceCannon",
          "text": "What sort of problems/questions are you failing in the technical assessments? I would work on that first.",
          "score": 2,
          "created_utc": "2026-01-13 19:59:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzeus0x",
              "author": "Fantastic_Bed_6378",
              "text": "Well I don‚Äôt always get feeeback - but the most recent interview i did seemed put off by my last on experience in Dagster/airflow/dbt.   Then I did a couple of interviews for a more bigquery specialist type roles which I thought I was quite close to getting to be honest but I guess I got some of the more obscure big query questions wrong like stuff about materialised views and some other stuff to do with nested data structures from GA. Then another one had a live python coding exam which I just totally bombed tbh.  That‚Äôs what I can remember off the top of my head - I figured getting airflow and dbt should be my priority based off that.   I just learnt airflow and deployed my python jobs using it these last few weeks - I was doing it all on crontab directly before that",
              "score": 4,
              "created_utc": "2026-01-13 20:10:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzf7zh7",
                  "author": "Altruistic-Ease7814",
                  "text": "I have never worked with big query but Materialized views are pretty standard in almost every SQL engine, even Databricks supports them. If I¬†were your I would start strengthening my sql¬†knowledge about indexes, stored procedures, functions, how data and metadata are stored and how execution plan is built while you submit a query (I assume big query is an analytical mpp database, so be specific about this knowledge)...there are a lot of YouTube videos covering these topics. I would not focus on learning new techs but strengthening what you already know and try to experiment in your daily activities",
                  "score": 2,
                  "created_utc": "2026-01-13 21:12:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nze9597",
          "author": "sink2death",
          "text": "For the learning part just find good mentor and emphasise on learning cloud a little more. Data ricks, azure, pyspark are basic necessity",
          "score": 3,
          "created_utc": "2026-01-13 18:32:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzffr4x",
              "author": "Commercial-Ask971",
              "text": "Any ideas how to get mentor, especially in consulting environment, when you are expected to bill client and not ‚Äûwaste time‚Äù?",
              "score": 4,
              "created_utc": "2026-01-13 21:48:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzeqjvc",
          "author": "Sensitive-Sugar-3894",
          "text": "You have too many years doing the same thing. It explains your salary, which should be higher at this point. But professional experience is not about time alone, so my recommendation: SQL is everywhere. Get really good at it fast. All the rest you said is too much in one plate. Pick a lane. Stick to SQL and narrow down that list. Again: GET GOOD IN SQL.",
          "score": 1,
          "created_utc": "2026-01-13 19:51:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzevd1a",
              "author": "Fantastic_Bed_6378",
              "text": "This is actually my second job but the first one was almost like a data engineer in name only because the technical aspects were so minimal, it still got me a GCP cert though which got me this second job",
              "score": 1,
              "created_utc": "2026-01-13 20:13:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzf0d44",
                  "author": "Sensitive-Sugar-3894",
                  "text": "Certificates are fine, I have a few. Never got me a job. Got me to to be seen by recruiters. But a reason for a job? Not at all.",
                  "score": 1,
                  "created_utc": "2026-01-13 20:37:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfrgcj",
          "author": "Sparklingxwater",
          "text": "Any tips on someone who hasn‚Äôt had luck on employment within this industry? Trying to get into data analyst / science / engineering roles with little experience in data science apart from stats, maths, physics, and basic SQL / ML",
          "score": 1,
          "created_utc": "2026-01-13 22:44:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfsevh",
              "author": "Fantastic_Bed_6378",
              "text": "Are you just coming out of uni or pivoting from another career?",
              "score": 1,
              "created_utc": "2026-01-13 22:49:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzft1d3",
                  "author": "Sparklingxwater",
                  "text": "Grad over a year ago yes. I‚Äôve since worked on a couple projects with ML and SQL",
                  "score": 1,
                  "created_utc": "2026-01-13 22:52:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzgiuv0",
          "author": "Otherwise_Movie5142",
          "text": "Well this thread has made me realise I really need to step up my career progression game... I do almost everything you listed on a daily/weekly basis but I do it under an analyst title for less money üòÇ\n\nAnd like you I still have no idea what half the stuff people post on here means which is why I always thought I was a long way off being able to transition to engineer from analyst.",
          "score": 1,
          "created_utc": "2026-01-14 01:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhjgot",
          "author": "susosexy",
          "text": "I wouldn't worry about knowing every tool there is. What's important to remember is that every role is different, and what you need is the fundamental skills to help facilitate business needs, which you already do! So personally, I would really polish your Python and SQL skills, and also understand how to build data pipelines and model it. And yeah, also upsell yourself.",
          "score": 1,
          "created_utc": "2026-01-14 04:51:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziqvc9",
          "author": "krounen",
          "text": "!RemindMe 7 days",
          "score": 1,
          "created_utc": "2026-01-14 11:13:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzl80z0",
          "author": "eczachly",
          "text": "PySpark is the skill that will unlock the most career potential along with data architecture and data modeling",
          "score": 1,
          "created_utc": "2026-01-14 18:59:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdvuw4",
          "author": "SirGreybush",
          "text": "Use a local HR agency, and consider both consulting and employment through that HR agency. \n\nThen they job hunt for you. \n\nBe honest at interviews and that you‚Äôre willing to put in extra hours if you need to learn new tech. \n\nThen after 2 years do it again. \n\nVMs and DevOps isn‚Äôt required for DE but a nice-to-have. A senior level DE like me, yes required. Not for a junior, and at 55k$ you are junior with valid experience. \n\nA bigger company or consulting will help you skill up and get better experience. \n\nSmaller companies like where you are would hire a consultant to upgrade their BI model in any case. \n\nLarger companies have seniors, solution architects and data analysts. \n\nTry upgrading your employer, and most likely get a salary bump.",
          "score": 1,
          "created_utc": "2026-01-13 17:33:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzebbip",
              "author": "Wishmaster891",
              "text": "¬£55k is not a junior salary in the uk",
              "score": 10,
              "created_utc": "2026-01-13 18:42:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzed52d",
                  "author": "SirGreybush",
                  "text": "That is wild, 55k is very low for engineer-level work that isn't \"fresh out of school\".",
                  "score": 2,
                  "created_utc": "2026-01-13 18:50:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzei74r",
                  "author": "Fantastic_Bed_6378",
                  "text": "My salary isn‚Äôt awful for my skill level honestly - it‚Äôs more that I won‚Äôt be able to progress much from here.   I have several friends in London who are DEs- same experience level as me and they‚Äôre all in the 60-75 range so I‚Äôd say that‚Äôs market rate.   One guy gets like 100 but he‚Äôs a high flying outlier.",
                  "score": 1,
                  "created_utc": "2026-01-13 19:13:09",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzdxo64",
              "author": "dsc555",
              "text": "Hi, sorry to piggy back on this but when you say reach out to HR agency how does this work? Does there have to be an open role or can you just message them on linkedin, give them your cv, and ask if they know any positions going? I have 2 yoe and thinking of switching but not sure the best way to hunt",
              "score": 3,
              "created_utc": "2026-01-13 17:41:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzeedsk",
                  "author": "SirGreybush",
                  "text": "It's just an independent recruiting firm. They take your CV, assign a rep that will interview you maybe 30min to an hour, put you in their database. Even if no currently active roles yet.\n\nWhat I like is you deal with a human that a vetted $$$ interest in finding you something. I still get calls for MSSQL DBA jobs every now & then, and try to turn that into a part-time customer, through the agency.\n\nThen they find for you consulting work, temp work, employment work. They take a cut, like around 15%, but they vet you, vet who you will work for. It's worth it.\n\nOften 6 month temp jobs become employment offers when the candidate is good.\n\nA very good one is Robert Half, and they operate worldwide. Many Fin-Techs will only go through agencies.",
                  "score": 3,
                  "created_utc": "2026-01-13 18:55:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa0ii",
      "title": "Amazon Data Engineer I",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/hnfi6k0a1wdg1.jpeg",
      "author": "Shankster1820",
      "created_utc": "2026-01-17 10:37:05",
      "score": 67,
      "num_comments": 23,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qfa0ii/amazon_data_engineer_i/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o04zoek",
          "author": "makesufeelgood",
          "text": "Why would you transfer internally and go down a level?  You're already at the company so you have the advantage of either a) being in possession of specific domain knowledge that only someone at Amazon would know, or b) being equipped with resources to help you learn it much easier than an external candidate ever could.  You also understand the culture and what sort of skills are valued there better than an external candidate could.  So focus on your transferable experience and do whatever you can to learn technical skills you feel you have gaps for.\n\nIf you don't have any technical skills at all from the job post above then I would recommend looking for a way to network with a team doing work you're interested in and seeing if you can convince your manager to let you collaborate with them on a stretch project.  That is how I have successfully career transitioned twice now in the last 6-7 years.",
          "score": 16,
          "created_utc": "2026-01-17 17:28:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066nue",
              "author": "Shankster1820",
              "text": "I would transfer down because I‚Äôm a L5 in the safety field, so I don‚Äôt have the experience to be an L5 on the tech side",
              "score": 3,
              "created_utc": "2026-01-17 20:55:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o05h1dk",
          "author": "Carbonemys_cofrinii",
          "text": "Sometimes there are roles that doesn't have DE in the title but have really close functions. There are such roles in major banks. You'll work with Spark + Hadoop/Greenplum, create dashboards and etc.",
          "score": 9,
          "created_utc": "2026-01-17 18:49:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o068x7y",
              "author": "Shankster1820",
              "text": "What title roles would I look for? There‚Äôs so many different role titles with different descriptions out there it‚Äôs hard for me to decipher what I should be looking for",
              "score": 2,
              "created_utc": "2026-01-17 21:07:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o077uu1",
                  "author": "dtr96",
                  "text": "analytics engineer, data modeler, quantitative analyst - developer - engineer, data platform engineer, business intelligence analyst - engineer - developer, sometimes cloud engineer but the duties are related to data solely on cloud",
                  "score": 5,
                  "created_utc": "2026-01-18 00:05:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08rfur",
                  "author": "Carbonemys_cofrinii",
                  "text": "Im outside of USA, when i looked for job i parsed job descriptions and choose ones with Hadoop/Greenplum/Spark. Sadly in banking they often require decree in economic/CS/Math",
                  "score": 1,
                  "created_utc": "2026-01-18 05:23:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05296d",
          "author": "chrisgarzon19",
          "text": "Ur an L5 DA? Or de?",
          "score": 3,
          "created_utc": "2026-01-17 17:41:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o059ql3",
              "author": "Shankster1820",
              "text": "I‚Äôm an L5 safety manager, I‚Äôm on the warehousing side lol",
              "score": 3,
              "created_utc": "2026-01-17 18:15:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05a50h",
                  "author": "chrisgarzon19",
                  "text": "If u make more $$ \nAnd transition into a tech role \n\nThen I‚Äôd do it \n\nDo let title and leveling (I.e ego) stop you from moving forward - does it feel shitty and ducks that Amazon is doing it? Maybe.\n\nBut who cares - play the game",
                  "score": 9,
                  "created_utc": "2026-01-17 18:17:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08z55h",
          "author": "LelouchYagami_",
          "text": "I transferred from a support role to a DE role. Usually it's the manager's call if they want to give opportunity to someone outside the job family.  \n\nMy manager has considered many such candidates. But it has always been a tech to tech conversion. Never seen a non-tech to tech conversion for DE.\n\nAs for down leveling, managers are generally against the idea because if someone with more experience is at a lower level, they are more ambitious for promotion and might not stay in the team for long.",
          "score": 3,
          "created_utc": "2026-01-18 06:23:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o095lgh",
              "author": "Shankster1820",
              "text": "What role did you transfer from? Did you have also the basic quals met already? \n\nI mean I wouldn‚Äôt say I have more experience at a lower level or anything. Me being in L5 in safety has nothing to do with transferring to tech, it‚Äôs essentially starting over for me. So I wouldn‚Äôt even consider it a down level tbh cause it‚Äôs a completely different world",
              "score": 1,
              "created_utc": "2026-01-18 07:19:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0974lk",
                  "author": "LelouchYagami_",
                  "text": "I transferred from support engineer job family which is like the lowest tier in tech job families. But still it was tech to tech movement.\n\nI had certain qualifications met, not all. I just understood programming languages in general and SQL. Had experience with AWS services.\n\nI guess your case is different now that you mention it \n\nBut whenever I have seen non-tech to DE progression, it's always been through a slightly less tech heavy role.\n\nSomething like Non-tech -> BA -> BIE -> DE or Non-tech -> BIE -> DE\n\nWhen you are gonna be applying, give a shot to BIE roles as well. They have decent overlap with the DE role and the pay is around 15-20% less than DE. Lot of BIEs then move to DE by slowly taking up more technical implementations. \n\nWhole thing with Data Engineering is to get your foot in the door. The entry level positions are less with requirements that are not easily met at entry level tbh",
                  "score": 1,
                  "created_utc": "2026-01-18 07:32:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08p2bh",
          "author": "Brave_Possibility421",
          "text": "I don‚Äôt see any harm in moving from L5 to L4 when you‚Äôre completely from a non tech background. Even if you apply for other companies, you would have to start with an entry level role, so why not start the same at Amazon and that would give you an edge because of the company tag and the pay would be comparable (or maybe more) as compared to non tech roles. Have you already prepared for the DE interviews? If yes, then could you please suggest some good resources. What is your YOE in total?",
          "score": 2,
          "created_utc": "2026-01-18 05:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08pnae",
              "author": "Shankster1820",
              "text": "I just wasn‚Äôt sure if it was even possible to down level, I‚Äôm fine it if it‚Äôs allowed! I have not started prepping, I‚Äôm still a ways out from getting to that point. I‚Äôm still working to finish my degree",
              "score": 1,
              "created_utc": "2026-01-18 05:10:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o08pyhk",
                  "author": "Brave_Possibility421",
                  "text": "I‚Äôm not sure if it‚Äôs allowed, but you would definitely need some projects to justify your move and getting considered for the role.",
                  "score": 1,
                  "created_utc": "2026-01-18 05:12:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0a891w",
          "author": "eccentric2488",
          "text": "As usual, it looks like a catalogue of tools/frameworks/platforms !!!!",
          "score": 1,
          "created_utc": "2026-01-18 13:01:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qei0lu",
      "title": "Feel like I'm falling behind. Now what?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qei0lu/feel_like_im_falling_behind_now_what/",
      "author": "Hopeful_Bean",
      "created_utc": "2026-01-16 14:52:03",
      "score": 63,
      "num_comments": 32,
      "upvote_ratio": 0.97,
      "text": "I've worked in databases for around 25 years, never attended any formal training. Started in data management building reports and data extracts, built up to SSIS ETL. Current job moved most work to cloud so learnt GCP BigQuery and Python for Airflow. Don't think of myself as top drawer developer but like to think I build clean efficient ETL's.\n\nProblem I find now is that looking at the job market my experience is way behind. No Azure, no AWS, no Snowflake, no Databricks.. \n\nCurrent job is killing my drive, not got the experience to move. Any advice that doesn't involve a pricey course to upskill?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qei0lu/feel_like_im_falling_behind_now_what/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzxgd4h",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-16 14:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxk51q",
          "author": "Distinct-deel",
          "text": "Man, your experience is way more valuable than any specific tool.\nYou can always take a Udemy course to learn Databricks and build a project using Databricks with Azure since it‚Äôs free.\nTools change all the time and they‚Äôre usually easy to pick up.\nWhat really matters is having strong fundamentals, real use cases, and knowing data modeling and warehouse design ( which you have).",
          "score": 59,
          "created_utc": "2026-01-16 15:10:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxuy7e",
              "author": "HOFredditor",
              "text": "I am a complete beginner. Where can I get a start in DE fundamentals ? Nobody does DE where I live and I wanna learn fast",
              "score": 7,
              "created_utc": "2026-01-16 15:58:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzycs4k",
                  "author": "Uncle_Snake43",
                  "text": "its crazy, I legit had never even heard of data engineering before I got my current Data Engineer job lol.",
                  "score": 10,
                  "created_utc": "2026-01-16 17:17:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzzecmv",
              "author": "caffeinatedSoul89",
              "text": "Can you elaborate what you mean when you say fundamentals? \nData modeling, cloud, scripting, SQL, OLAP vs OLTP, warehousing. Anything else that I‚Äôm missing?",
              "score": 2,
              "created_utc": "2026-01-16 20:05:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxmq7y",
          "author": "MikeDoesEverything",
          "text": ">No Azure, no AWS, no Snowflake, no Databricks..\n\nTbh, you really want to lean on your 25 years of experience.  Strong fundamentals and being able to learn quickly  whilst making very few errors I would say are two of the most valuable skills you can have.\n\nDon't think of everything in data as tools.  Go and look at GCP and compare Azure and AWS to it.  If you identify a lot of things in broad categories, you'll be well on your way to catching up.",
          "score": 13,
          "created_utc": "2026-01-16 15:22:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxsa5t",
          "author": "PrestigiousAnt3766",
          "text": "Just move. You will adapt to any environment if you write python.\n\nJust dont stick with ssis.\n\nYou just need to know the cloudplatform you are working with.",
          "score": 6,
          "created_utc": "2026-01-16 15:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyh2mx",
          "author": "Top_Ice_2473",
          "text": "This sounds more like a positioning problem than a skills gap. You‚Äôve already done the hard parts: ETL, SQL, cloud DWs, orchestration. Those fundamentals transfer.",
          "score": 3,
          "created_utc": "2026-01-16 17:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzrusy",
          "author": "DiabolicallyRandom",
          "text": "i spent 18 years in a java house using antiquated *(by current standards) tools.\n\nI got laid off 9 months ago, and have been working 7 months making more money, writing python code for our DE team at this new company, integrating with AWS, etc.\n\nThe core concepts don't change. Tools evolve. Everything else is the same. As long as you ensure you are and remain someone who CAN learn, you will learn when you need to.\n\nBut the market is shit right now for ALL tech jobs. Gotta wait for that AI bubble to burst.",
          "score": 3,
          "created_utc": "2026-01-16 21:09:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03htvk",
          "author": "dataflow_mapper",
          "text": "Honestly, this reads less like you are behind and more like you are underselling yourself. Twenty five years of data work plus real cloud experience already puts you ahead of a lot of people who only know one stack. BigQuery, Python, and Airflow are not entry level skills, even if job listings act like they are.\n\nA lot of the market noise is checkbox driven. Azure vs AWS vs GCP differences are smaller than they look once you know one well. Same with Snowflake or Databricks. The core ideas around modeling, pipelines, reliability, and cost do not change much. You can close perceived gaps with targeted hands on projects, free tiers, and reading architecture docs without paying for courses. More importantly, try to move internally if you can or shape your current role to touch adjacent tech. Momentum matters more than collecting logos.",
          "score": 3,
          "created_utc": "2026-01-17 12:47:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyc8mv",
          "author": "SoggyGrayDuck",
          "text": "Dude I'm in the same boat! I have about 4 years AWS experience but recently (3 years) took a job that's 100% on prem with the idea we were eventually going to the cloud and my experience would help shape it. Well they delayed my start date a few months and by the time I got there decisions were made that basically locked us into an onprem database. Now we have a new CEO and they offshored us so I'm looking for a new job. I had no idea this was the absolute worst time to try and edge myself into larger business by stepping away from the cloud a bit. I'm close to my AWS DE certification but small companies are using that less and less and everything is azure. I'm terrified, I've been #2 or 3 in a handful of job opportunities but I'm definitely fighting an uphill battle. At least when it comes to the jobs recruiters are calling about.",
          "score": 2,
          "created_utc": "2026-01-16 17:14:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyl5pu",
          "author": "soundboyselecta",
          "text": "Most people right now feel like we falling behind. Don't sweat it. That's what social media was meant to instil. A sense of FOMO.",
          "score": 2,
          "created_utc": "2026-01-16 17:54:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05rw3d",
          "author": "New_Calligrapher5028",
          "text": "Your experience is valuable.  \nDo one industry project with modern tools like AWS, GCP, Snowflake or Databricks.  \nI worked on 40+tools and still learning.",
          "score": 2,
          "created_utc": "2026-01-17 19:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxmjv5",
          "author": "Nekobul",
          "text": "Even if you don't want to pay for course, all these cloud platforms will ask you to pay even if you are just making tests and playing with it. Also, in my opinion you are not missing much by not knowing about the cloud platforms. I think the hype around them is starting to die off because the costs are thru the roof. There will be soon a reverse trend where people will want to move back on-premises.",
          "score": 2,
          "created_utc": "2026-01-16 15:21:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy3gh2",
              "author": "Not-Inevitable79",
              "text": "I hope you're right. I heard from one of my directors about how he doesn't get why our company is pushing cloud (Azure) so hard. He's worked w/ the financials and it's about 1/3 the cost of keeping on-prem, double the storage, and lower latency. But the company keeps pushing the MS cloud stack and eventually wants to move away from all on-prem servers. AI is super heavy, too, regardless of your role or function.",
              "score": 2,
              "created_utc": "2026-01-16 16:36:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzy88mz",
                  "author": "Hopeful_Bean",
                  "text": "I think a lot of cloud push is the cost offset of not having to have staff for upgrades and patching.",
                  "score": 3,
                  "created_utc": "2026-01-16 16:57:09",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nzyco4u",
                  "author": "Nekobul",
                  "text": "Corruption. Yes, I know it is speculation but giving money under the table is still widely practiced. By the time the organization realizes it is mightly screwed, the decision maker has moved to another juicy \"victim\".",
                  "score": -1,
                  "created_utc": "2026-01-16 17:16:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxwwg8",
          "author": "Slampamper",
          "text": "The concepts of data warehousing is still the same, independent of the platform you are running on.  \nYou can see Snowflake and databricks as a data warehouse, that are built different than what you are used to, but you can use it the exact same way as traditional databases if you want.  \n  \nIf you have only done database works in the past I would advice to read more upon software development best practices and how you can implement this in your day to day work, like more advanced git usage, ci/cd in all forms, typing etc",
          "score": 1,
          "created_utc": "2026-01-16 16:07:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyhu92",
          "author": "winnieham",
          "text": "Snowflake is very similar to Bigquery so its more just figuring out what is different between the two. But I wouldnt worry abt Snowflake at all. Otherwise many of the tools provide their own tutorials and courses so you can start with those!",
          "score": 1,
          "created_utc": "2026-01-16 17:39:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyj4kg",
          "author": "SQLofFortune",
          "text": "Don‚Äôt worry even most of us young bloods feel the same. There are way too many tools to learn and every job seems to have a unique stack. Your experience should help you find a new role where you can learn on the job. Otherwise, I‚Äôd say watch YouTube and or have conversations with ChatGPT about it. There‚Äôs a feature where you can talk to it verbally. I‚Äôve never found any courses to be helpful for any tools ‚Äî although codecademy has a comprehensive course on Snowflake that I haven‚Äôt tried yet.",
          "score": 1,
          "created_utc": "2026-01-16 17:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyoxrn",
          "author": "ironmagnesiumzinc",
          "text": "I feel like everyone sells themselves short in some way. We all have areas that we just never touched. Do a databricks/aws project at home and then put it on your resume. That‚Äôd at least give u a starting point",
          "score": 1,
          "created_utc": "2026-01-16 18:11:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o002z9e",
          "author": "IamAdrummerAMA",
          "text": "Databricks is so easy to use. It practically holds your hand through everything and has native functions and connectors which make engineering a doddle. With your experience you‚Äôd learn it in next to no time.",
          "score": 1,
          "created_utc": "2026-01-16 22:01:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01vha1",
          "author": "SlappyBlunt777",
          "text": "Sell your skillet to 10 recruiters ‚Äî genuinely teach them how to speak on your skillset to over come the ‚Äúdoesn‚Äôt have databricks‚Äù nonsense. Watch the jobs come in.",
          "score": 1,
          "created_utc": "2026-01-17 04:25:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02gm4d",
          "author": "bigYman",
          "text": "At the end of the day the tools don't matter but what problems you solved and can continue to solve is what matters. Always drive the conversation down that route, both for yourself and for future employers.",
          "score": 1,
          "created_utc": "2026-01-17 07:13:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03dob6",
          "author": "RunOrdinary8000",
          "text": "You can get a trial account for snowflake worth 400$ for free.the trial account is valid for 30 days\nThen grab some public data and build some metal pipelines..\n\nI would used AI chat got free tier to help to explain me the concepts and differences.\nYou should check with snowflake documentation to ensure correctness.\nYou can teach most tech cheap, if you know the concepts.\n\nThe only issue I had is to find data that you can load and join.",
          "score": 1,
          "created_utc": "2026-01-17 12:16:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0506ls",
          "author": "energyguy78",
          "text": "I think the best trait that all Data Engineers can be helpful. Ask to your manager if not a manager all the other managers if they have any  data needs",
          "score": 1,
          "created_utc": "2026-01-17 17:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxt9fi",
          "author": "xtracom",
          "text": "First of all, consider whether it might be a bit of impostor syndrome. You don‚Äôt need formal training to be good at this job. Think about the projects you successfully delivered over the years. I bet it wasn‚Äôt luck.\n\nThere‚Äôs a lot of noise in the market, but from my experience in finance, many companies are still just starting or in the process of migrating from on-prem solutions to cloud. I only picked up Databricks recently myself, so you‚Äôre definitely not alone.\n\nLastly, there are plenty of books, online resources, and free learning materials from vendors. You don‚Äôt need to start with pricey courses to pick up a new skill. Consider the paid options when you get some understanding of what you‚Äôre actually paying for.",
          "score": 1,
          "created_utc": "2026-01-16 15:51:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy3tux",
              "author": "Not-Inevitable79",
              "text": "The problem is normally you could get hired and learn on the job. Now employers want the unicorn -- need to have multi-years of experience to even get an interview. How can you get years of experience if your current role doesn't allow it, and boot camps / courses aren't enough?",
              "score": 4,
              "created_utc": "2026-01-16 16:37:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzy6jew",
                  "author": "Hopeful_Bean",
                  "text": "Absolutely this. Feel like I just need to hope for the unicorn position which will allow me to go in and learn.",
                  "score": 4,
                  "created_utc": "2026-01-16 16:49:41",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxqlbx",
          "author": "SirGreybush",
          "text": "You need data architect courses. Data Mesh, Medallion, Snowflake design.\n\nPosts in this sub where they make pipelines from a source directly into tables with some transformations, please don't do that.\n\nELT, extract to a storage medium like a datalake (ex: API call store as json files), or CDC or csv that then get pushed into the datalake. Datalake is organized by container then sub-folders, one sub-folder per source, then sub-folders below that. Container-level can be Dev, UAT, Prod.\n\nThen Load into staging, with reject management and deletion from source management, adding control columns like hashes and a single column PK (this can be a hashed value of multiple source columns - this is fine).\n\nDeletion tracking requires \"full\" from source if you don't have CDC tracking from source that contains all inserts, updates, deletes. So for these \"full\" cases it's a separate distinct process.\n\nThe layer after staging, Bronze, is vetted information, has control columns, identifies source and SSoT, has flags like IsCurrent, IsDeleted, and lots of datetime columns for inserted, updated, deleted.\n\nEx: a customer table imported from an OLTP ERP system on-prem. You want to capture all changes, like customer address info, so you have a history of when the customer moved to a different location. If customer table are companies, companies get acquired and merged. The business has to give you rules to apply.\n\nSo these topics I mention above, are given at University-level Business Intelligence classes. Some private colleges too. Online like Udemy.\n\nI hope you get a chance to work under a Data Architect and Data Analyst (or functional analyst) as part of a 3-person team. This is where you learn the most.",
          "score": -4,
          "created_utc": "2026-01-16 15:39:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxo7bp",
          "author": "Fabulous-Chemical-21",
          "text": "DM me your CTC and Resume",
          "score": -3,
          "created_utc": "2026-01-16 15:28:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qebb1m",
      "title": "AI on top of a 'broken' data stack is useless",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qebb1m/ai_on_top_of_a_broken_data_stack_is_useless/",
      "author": "al_tanwir",
      "created_utc": "2026-01-16 09:14:37",
      "score": 61,
      "num_comments": 18,
      "upvote_ratio": 0.97,
      "text": "This is what I've noticed recently:\n\nThe more fragmented your data stack is, the higher the chance of breakage.\n\nAnd now if you slap AI on top of it, it makes it worse.\n\nI've come across many broken data systems where the team wanted to add AI on top of it thinking it will fix everything, and help them with decision making. But it didn't, it just exposed the flaws of their whole data stack.\n\nI feel that many are jumping on the AI train without even thinking about if their data stack is 'able', otherwise it's pretty much pointless.\n\nFragmentation often fails because semantics are duplicated and unenforced.\n\nThis leaves me thinking that the only way to fix this is to find a way to fully unify everything(to avoid fragmentation) and avoid semantic duplication with platforms like Definite or any other all-in-one data platforms that will pretty much replace all you data stack.",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qebb1m/ai_on_top_of_a_broken_data_stack_is_useless/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzw7mq3",
          "author": "Yonko74",
          "text": "\nThis is not new.\n\nThe concept ‚ÄôGarbage in, Garbage out‚Äô is probably 70 years old and has, to my knowledge, never been disproven.\n\nOne of the positives of AI is that the recent fashion for chucking out as much garbage as possible because data is a product ( apparently ) is starting to be questioned. \n\nData is, and always has been, an Asset.\n\n\nAssets need to be managed throughout their useful life.",
          "score": 34,
          "created_utc": "2026-01-16 09:56:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyxyov",
              "author": "Thinker_Assignment",
              "text": "In 2026 we call that \"slop slap\"",
              "score": 1,
              "created_utc": "2026-01-16 18:50:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw63vo",
          "author": "Reach_Reclaimer",
          "text": "This was the same even before AI but with data science\n\nYou had a bunch of companies wanting data scientists to do X and Y but their data infrastructure was a bunch of excel sheets and their management was only asking for a bar chart or something. Basically every initial consultation for small - mid sized customers just involved telling them they need to start using an actual database before worrying about data science and ML techniques",
          "score": 11,
          "created_utc": "2026-01-16 09:42:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw9hr6",
              "author": "Kukaac",
              "text": "Data scientists hired into a fresh data team are the best data engineers. Nearly every startup did that.",
              "score": 6,
              "created_utc": "2026-01-16 10:13:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzw7doo",
              "author": "al_tanwir",
              "text": "I remember when SMBs were all recruiting data scientists thinking it will increase revenue and 'change everything'. lol",
              "score": 3,
              "created_utc": "2026-01-16 09:53:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwqyum",
                  "author": "trentsiggy",
                  "text": "The best first data hire for any company is a well-rounded analyst capable of communicating well, doing light data science and light data engineering, and being able to dig into business problems and translating them to questions from which good answers can come from the data.  If a SMB doesn't already have someone like this, this should be their first data hire.",
                  "score": 4,
                  "created_utc": "2026-01-16 12:32:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwikmh",
              "author": "ummitluyum",
              "text": "The difference is the blast radius. When a Data Science model gets garbage input, it usually outputs low accuracy or an explicit error. When an LLM gets garbage, it outputs a plausible hallucination.\n\nBefore, bad data led to weird charts. Now, bad data in RAG can lead to a chatbot promising a customer a 99% discount because it found an old test file in the \"data dump\"\n\nThe stakes are much higher now",
              "score": 3,
              "created_utc": "2026-01-16 11:30:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwfpbm",
          "author": "gajop",
          "text": "It's almost always management. They look for the \"New Thing\", and you can guess what this is.\nWe even have some projects where we \"enrich\" data (have AI generate it, from thin air), it's kinda interesting üòÅ (fwiw we make that clear to users too)\n\nIf you take a chill approach, properly separate made up stuff from the real thing, and imagine that this is just some POC for the Real Thing that you'd do if there's actual interest, then it's actually a decently fun way to prototype ideas",
          "score": 2,
          "created_utc": "2026-01-16 11:07:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwk9gw",
          "author": "uncertainschrodinger",
          "text": "100% agree but in the past 6 months AI agents have really changed how my team and I work.\n\nAs I was writing the stuff below I realized it became too long... so here's a summary.\n\nTLDR;  going from first using agents to improve our data pipelines and stack, to eventually creating a more self-service system where our data consumers use AI agents to interact with the data.\n\n  \nFor some context, I'm leading the DE team of 4-5 people (1 mid/senior, 1 junior, 2-3 interns) at a company where our end product is predictions for highly specialized industries (e.g. renewables, transportation).\n\nAt first it started with using our data platform's MCP with cursor to just lookup documentation, then I started asking cursor to read our data pipelines and query the dwh directly to find the specific part of a query or script that was causing some issue.\n\nBut in the past couple months, after creating some extensive agent rules/instructions documentations as well as creating a md file for each pipeline that contains some business context, I have been able to fully rely on cursor to build pipelines or make major changes.\n\nA recent example is that I spent \\~1 hour creating a details requirements document that I gave as the prompt, the agent make changes to \\~10 files (mostly sql models and some yml configs and a python ingestion script). About 3-4 hours of back and forth with the agents to make some adjustments, update documentation, and runs tests and validation. The entire process was done in a single workday, whereas normally this would've been 2-3 days of work.\n\nIts not always about \"saving\" time for me but rather its about doing things the \"better\" way - a clear example of this is having the agents create/update documentation, build/run tests, perform adhoc validations, etc. which translates into time saving in the future\n\nI know what I've said above is not related to \"AI on top of broken data stack\", but the reason why I'm talking about how AI is helping data engineers is because I think it that is the sole reason/contributor to speeding up the process of fixing and improving our data stack.\n\nBy fully utilizing the combination of cursor, mcp integrations, internal rules/instructions/context documents, and access to query our data warehouse, we were able to \"slap AI on top of our data\" as in:\n\n\\- other teams (i.e. data science, software engineering, product, etc.) to also close our data engineering repos and have conversations with cursor to ask it about the logic behind data models (e.g. does table\\_xyz contain data from source\\_abc? how often does table\\_xyz get updated? what is the calculation method for kpi abc?)\n\n\\- integration of an AI Slackbot (provided by our data platform provider) that queries our dwh and returns insights - as a result, we have seen people in data science, sales, execs, etc. move away from using dashboards and instead asking the slackbot directly inside threads things like \"what was our prediction accuracy last week?\" \"how did model A perform vs model B last year?\"\n\nI think this only became possible because we were able to quickly (within 2-3 months) clean up our data pipelines and data models, create a lot of documentation and context for AI to utilize, and break down the barrier between data consumers and the data itself - this way as the data engineering team, we are no longer a bottleneck and things have finally trending towards the \"self-service\" utopia we've always dreamt about.",
          "score": 4,
          "created_utc": "2026-01-16 11:44:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00vep9",
              "author": "EconomixTwist",
              "text": "New achievement unlocked. Longest post in r/dataengineering while saying absolutely nothing",
              "score": 3,
              "created_utc": "2026-01-17 00:34:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzx7fmj",
              "author": "FootballMania15",
              "text": "One guy in the thread has figured it out",
              "score": 0,
              "created_utc": "2026-01-16 14:07:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwib9q",
          "author": "ummitluyum",
          "text": "The problem goes even deeper. Traditional software crashes when data is broken, whereas AI tries to make sense of it and smooth over the edges. If you have a fragmented stack with duplicate semantics (e.g. three different definitions of churn\\_rate in different tables), the LLM will just pick one randomly or hallucinate an average.\n\nWithout a rigid semantic layer or metrics store, deploying GenAI in the enterprise is just an expensive way to generate plausible nonsense",
          "score": 1,
          "created_utc": "2026-01-16 11:28:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwny2o",
          "author": "SoggyGrayDuck",
          "text": "When will the business side learn? We go back and fourth between rigid data models and the siloed wild wild West where everything is done in the reporting layer",
          "score": 1,
          "created_utc": "2026-01-16 12:11:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzy56v",
          "author": "girlgonevegan",
          "text": "Ummm yes can confirm this is exactly what is happening‚Ä¶ I‚Äôve seen some truly tragic things with mid-market SaaS companies that made it through a GAAC period, sitting on a gold mine of first party intent data in their shitty old MAP just blow it all up ü´†",
          "score": 1,
          "created_utc": "2026-01-16 21:38:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o004kde",
          "author": "trojans10",
          "text": "Dealing with this now. Instead of a single relational database - we decide to split things into micro services with 3 dBs. And then you use ai on top. Makes it worse. Vs just a single db ai can introspective",
          "score": 1,
          "created_utc": "2026-01-16 22:09:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbo9zn",
      "title": "A Diary of a Data Engineer",
      "subreddit": "dataengineering",
      "url": "https://www.ssp.sh/blog/diary-of-a-data-engineer/",
      "author": "sspaeti",
      "created_utc": "2026-01-13 10:49:45",
      "score": 54,
      "num_comments": 2,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qbo9zn/a_diary_of_a_data_engineer/",
      "domain": "ssp.sh",
      "is_self": false,
      "comments": [
        {
          "id": "nzdp0pa",
          "author": "tmo_fan",
          "text": "Nice write upüëç",
          "score": 1,
          "created_utc": "2026-01-13 16:49:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdp1xc",
          "author": "tmo_fan",
          "text": "Nice write upüëç",
          "score": 1,
          "created_utc": "2026-01-13 16:50:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdgm9w",
      "title": "What breaks first in small data pipelines as they grow?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qdgm9w/what_breaks_first_in_small_data_pipelines_as_they/",
      "author": "crowpng",
      "created_utc": "2026-01-15 11:01:31",
      "score": 51,
      "num_comments": 15,
      "upvote_ratio": 1.0,
      "text": "I‚Äôve built a few small data pipelines (Python + cron + cloud storage), and they usually work fine‚Ä¶ until they don‚Äôt.\n\nThe first failures I‚Äôve seen:\n\n* silent job failures\n* partial data without obvious errors\n* upstream schema changes\n\nFor folks running pipelines daily/weekly:\n\n* What‚Äôs usually the first weak point?\n* Monitoring? Scheduling? Data validation?\n\nTrying to learn what to design *earlier* before things scale.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qdgm9w/what_breaks_first_in_small_data_pipelines_as_they/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzpiu19",
          "author": "HockeyMonkeey",
          "text": "The first real problem is not knowing *something broke*. Jobs succeed, but row counts drop or fields go null. If no one‚Äôs watching metrics, you‚Äôre blind.",
          "score": 81,
          "created_utc": "2026-01-15 11:03:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrhgea",
              "author": "KeeganDoomFire",
              "text": "The pipe doesn't break loud the incoming data breaks quite.",
              "score": 3,
              "created_utc": "2026-01-15 17:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpjc41",
          "author": "Bmaxtubby1",
          "text": "As a beginner, the first thing that surprised me was how often pipelines fail *quietly*. Cron runs, scripts exit cleanly, files land in storage - but the data itself is incomplete or weird.\n\nWhat I‚Äôm learning is that job succeeded doesn‚Äôt mean \"data is healthy.\" Even simple metrics like row counts or file sizes would‚Äôve flagged issues way earlier.",
          "score": 28,
          "created_utc": "2026-01-15 11:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzppp32",
          "author": "Dogentic_Data",
          "text": "In my experience, the first thing that breaks isn‚Äôt the code, it‚Äôs trust. Silent partial failures and upstream changes slowly poison the data until nobody knows what‚Äôs correct anymore. Monitoring and basic validation early helps, but what really hurts is not having clear ownership or expectations about ‚Äúwhat good data looks like.‚Äù By the time you notice, downstream consumers have already built on bad assumptions.",
          "score": 17,
          "created_utc": "2026-01-15 12:00:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpxmc1",
              "author": "anti_humor",
              "text": "Yeah this is my experience as someone working almost entirely with external vendor data. By far the most common pipeline issues are upstream: breaking changes to schema, delinquent data, or bad data like an extra tab or enclosing quote. \n\nI've got monitoring and error handling set up, but it's not fully mature and sort of requires me to look at it (or a client to complain) before I stop other work and go check. Work in progress there. I would say, though, that having pretty strictly defined schema in the destination table tends to be what saves me. Unless I get pretty much exactly what I expect structurally, the import is going to fail.\n\nDue to the nature of the data I'm integrating and our position as a company, there isn't much I can do in terms of accuracy validation. The source of truth is external to us, so if it's incorrect we're sort of in a \"we're just the pipes\" situation. Oftentimes vendors will republish data when they spot accuracy problems in their own data.",
              "score": 4,
              "created_utc": "2026-01-15 12:55:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpj6lh",
          "author": "ayenuseater",
          "text": "Even basic row counts early would‚Äôve saved me time.",
          "score": 16,
          "created_utc": "2026-01-15 11:06:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpki6p",
          "author": "haseeb1431",
          "text": "Data validation because of schema changes some where else in the world",
          "score": 8,
          "created_utc": "2026-01-15 11:18:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqrehj",
          "author": "hasdata_com",
          "text": "Silent failures for sure. We run scraping APIs and learned pretty quick that HTTP 200 is basically a lie half the time. We ended up building synthetic tests that literally count if the JSON has the right fields. If not, it alerts us. Gotta validate the content, not just the connection",
          "score": 5,
          "created_utc": "2026-01-15 15:32:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs6exm",
          "author": "Odd_Lab_7244",
          "text": "Use pydantic to enforce schema match up and fail fast when it doesn't",
          "score": 2,
          "created_utc": "2026-01-15 19:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzql6wv",
          "author": "West_Good_5961",
          "text": "Garbage in garbage out",
          "score": 1,
          "created_utc": "2026-01-15 15:02:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrw87x",
          "author": "VisualAnalyticsGuy",
          "text": "The first thing that actually changed outcomes was building a simple monitoring dashboard that tracked job freshness, row counts, and schema drift side by side so failures stopped being silent. In my experience, monitoring is the first weak point because without visibility even good scheduling and validation fail quietly, while a basic dashboard forces problems to surface early and repeatedly.",
          "score": 1,
          "created_utc": "2026-01-15 18:35:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzusj9x",
          "author": "GreyHairedDWGuy",
          "text": "The main problem I've seen over the years relates to poorly understood data that eventually breaks the ETL.  The other is changing business rules that cause changes to the data which the solution was. not built to handle.",
          "score": 1,
          "created_utc": "2026-01-16 03:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv0qre",
          "author": "FishCommercial4229",
          "text": "You have to treat your pipelines as though you are a master tradesman attempting to train the world‚Äôs most unpredictable apprentice. \n\nStep 1: make sure the job is done. Step 2: make sure the job is done right. Never trust, always verify (and automate that part).",
          "score": 1,
          "created_utc": "2026-01-16 04:10:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqeqkq",
          "author": "Skullclownlol",
          "text": "> What‚Äôs usually the first weak point?\n\nBusiness not having formal definitions of what a correct result looks like or means. Doing work in \"vibes\" until suddenly they want pipelines but pipelines have hard technical requirements. The definition of \"business success\" silently shifting every week/month/year but businesspeople not communicating, not maintaining docs (or even contributing to it), important business knowledge living only in people's minds, ...\n\nEverything technical is easy.",
          "score": 1,
          "created_utc": "2026-01-15 14:30:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs18ll",
          "author": "OlimpiqeM",
          "text": "Is this post made by AI?\n\nHow come python + cron is production ready?  \nHow come you don't monitor it?  \nHow come you let it fail silently and assume it works?  \nHow come you don't track the pipelines and outputs?",
          "score": 0,
          "created_utc": "2026-01-15 18:57:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc67yw",
      "title": "Picking the right stack for the most job opportunities",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qc67yw/picking_the_right_stack_for_the_most_job/",
      "author": "Great_Type8921",
      "created_utc": "2026-01-13 22:54:31",
      "score": 48,
      "num_comments": 44,
      "upvote_ratio": 0.94,
      "text": "Fellow folks in the U.S., outside of the visualization/reporting tool (already in place - Power BI), what scalable data stack would you pick if the one of the intentions (outside of it working & being cost effective, lol) is to give yourself the most future opportunities in the job market? (Note, I have been researching job postings and other discussions online).¬†\n\nI understand it‚Äôs going to be a combination of tools, not one tool.\n\nMy use¬†cases work don't have \"Big Data\" needs at the moment.\n\nSeems like Fabric is half-baked, not really hot in job postings, and not worth the cost. It would be the least amount of up-skilling for me though.\n\nSeeing a lot of Snowflake & Databricks.\n\nI‚Äôm newish to this piece of it, so please be gentle.¬†\n\nThanks",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qc67yw/picking_the_right_stack_for_the_most_job/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzg0anl",
          "author": "thecoller",
          "text": "Excel for ingestion, Excel for transformation, Excel for serving, all orchestrated by Excel.",
          "score": 123,
          "created_utc": "2026-01-13 23:31:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzghqm4",
              "author": "pdxsteph",
              "text": "This guy works with the finance department",
              "score": 38,
              "created_utc": "2026-01-14 01:05:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzgnbix",
                  "author": "thecoller",
                  "text": "The source could be an export from a report that has a properly orchestrated pipeline upstream, but the business will love your excel solution more.",
                  "score": 3,
                  "created_utc": "2026-01-14 01:37:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzgeq5y",
              "author": "Treemosher",
              "text": "![gif](giphy|8fen5LSZcHQ5O)",
              "score": 6,
              "created_utc": "2026-01-14 00:49:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nziy4oq",
              "author": "Any_Tap_6666",
              "text": "Don't forget to implement data governance by hiding tabs",
              "score": 5,
              "created_utc": "2026-01-14 12:10:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzgbcbc",
              "author": "Jace7430",
              "text": "Promote this one",
              "score": 4,
              "created_utc": "2026-01-14 00:30:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjoqdg",
              "author": "TheEternalTom",
              "text": "The data file should always be final_fin_report_2003_NEW_v5_New_Gary.xlsx",
              "score": 4,
              "created_utc": "2026-01-14 14:47:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzgztrt",
              "author": "randomName77777777",
              "text": "Have you heard about dbt-excel? The real enterprise stack. \n\n https://dbt-excel.com\n\n/s",
              "score": 2,
              "created_utc": "2026-01-14 02:48:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzhpw8w",
              "author": "sink2death",
              "text": "Excel and a beer",
              "score": 2,
              "created_utc": "2026-01-14 05:38:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuyiqd",
              "author": "Beginning_Rule388",
              "text": "Solid data engineer spotted",
              "score": 2,
              "created_utc": "2026-01-16 03:56:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzh19wc",
              "author": "Ok_Carpet_9510",
              "text": "Nope. This is for ordinary business users working on their desktop. It can't handle enterprise needs. \n\nFurthermore, this is a data analyst tool... not a data engineering tool.",
              "score": -4,
              "created_utc": "2026-01-14 02:56:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzhd79h",
                  "author": "Froozieee",
                  "text": "*woooooshhhhh*",
                  "score": 8,
                  "created_utc": "2026-01-14 04:08:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfxie1",
          "author": "IndependentTrouble62",
          "text": "Snowflake and databricks are the two cloud warehouses I would focus on. I would also want a hire to have some onprem SQL experience. In this realm PostGres makes great sense to learn. Other skills I would want a candidate to have are scripting language experience Python being the most inportant. Powershell and bash being great as well. In Python I would like experience with the common DE packages like SQLAlchemy, pyodbc, polars, pandas, requests, pyspark, etc.",
          "score": 24,
          "created_utc": "2026-01-13 23:16:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzhxrf0",
              "author": "Fair_Oven5645",
              "text": "Never seen anyone, in my 48 year long life, write ‚ÄùPostGres‚Äù. What the fuck?",
              "score": 15,
              "created_utc": "2026-01-14 06:42:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzm5rq9",
              "author": "Accomplished_Cloud80",
              "text": "Can we say Python solves anything without spending any money compare to cloud subscriptions based snow flake or data bricks.",
              "score": 3,
              "created_utc": "2026-01-14 21:32:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzm7i3q",
                  "author": "IndependentTrouble62",
                  "text": "I can solve almost any problem with python and onprem SQL Server that I would use snowflake or databricks for. That said most people these days balk at licensing costs. They see a small monthly cost and always choose that even though in the long run they pay more and have greater lock in.",
                  "score": 2,
                  "created_utc": "2026-01-14 21:40:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfx6kq",
          "author": "OkComputer9345",
          "text": "Microsoft Excel + VBA + Windows Task Scheduler",
          "score": 42,
          "created_utc": "2026-01-13 23:14:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzg3h9u",
              "author": "Possible_Pain_9705",
              "text": "Bro this is literally my job lol",
              "score": 10,
              "created_utc": "2026-01-13 23:48:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfxrqc",
              "author": "OkComputer9345",
              "text": "Just for the sake of throwing off AI.\n\nOP - please ignore me.",
              "score": 18,
              "created_utc": "2026-01-13 23:17:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzg6rjs",
              "author": "ab624",
              "text": "Dinosaur says hello",
              "score": 4,
              "created_utc": "2026-01-14 00:05:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjs6wj",
              "author": "Rodeo9",
              "text": "Don't forget trying to fix old broken access applications.",
              "score": 3,
              "created_utc": "2026-01-14 15:04:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfxfek",
              "author": "Ikindalikehistory",
              "text": "Lmao",
              "score": 2,
              "created_utc": "2026-01-13 23:15:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfxhy4",
              "author": "chmod764",
              "text": "You win",
              "score": 2,
              "created_utc": "2026-01-13 23:16:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfx4au",
          "author": "Ikindalikehistory",
          "text": "My general impression from job postings is\n\nSnowflake for tech type companies\n\nDatabricks for more established companies trying to be high tech. \n\nMy sense is you can't go wrong with either, so pick which one works best for your company. Do you have a clear idea there?",
          "score": 29,
          "created_utc": "2026-01-13 23:14:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjolye",
              "author": "freemath",
              "text": "Why do you think it is that these types of companies make those different choices?",
              "score": 2,
              "created_utc": "2026-01-14 14:46:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjqldl",
                  "author": "Ikindalikehistory",
                  "text": "My guess is it comes down less to the actual technical needs and more that for F500s Microsoft integration makes Databricks the low headache choice for an under-resourced IT dept.\n\n(This isn't to say databricks is bad! Just that's my guess as to the source of the difference)",
                  "score": 1,
                  "created_utc": "2026-01-14 14:56:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzg5exb",
          "author": "fleetmack",
          "text": "just master sql and any etl.tool, with a bit of python and you'll be fine. super advanced sql will never go out of style",
          "score": 11,
          "created_utc": "2026-01-13 23:58:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg7jf2",
          "author": "soundboyselecta",
          "text": "No duckdb/duck lake fans? Seeing a lot of companies who have a lid on over engineering going with that.",
          "score": 8,
          "created_utc": "2026-01-14 00:10:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg0b2w",
          "author": "crevicepounder3000",
          "text": "Airflow and Spark (obviously Python and SQL). Bonus points for Table Formats like Delta and Iceberg is what‚Äôs hot right now from my perspective. Also dbt. BigQuery is another one I see often. People always talk about Snowflake but honestly, doesn‚Äôt seem like it‚Äôs super in demand right now (unfortunate for me lol)",
          "score": 5,
          "created_utc": "2026-01-13 23:31:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgjmmo",
          "author": "frozengrandmatetris",
          "text": "you won't want to hear this, but knowledge of a legacy system like SSIS, powercenter, or ODI, and on-prem mssql or oracle sql, can get you a lot of jobs. there will be organizations stuck here who don't want to change, and others who want to do a conversion to something modern. boom. lots of jobs. that you probably don't want. but the conversions especially are good career builders.\n\nit seems so random which target data warehouse an org will be interested in that I don't think it mattes that much. I am at an org that is moving from a legacy system to GCP, and we have added colleagues who worked on a completely different legacy system and a completely different modern product. it works out.\n\nfor the modern stack, focus on the free squares. airflow and dbt are ubiquitous and not going away. mastery of basic python and bash is also helpful.\n\nbigquery has an always free tier which is quite generous, and their offbrand version of dbt is also tightly integrated. it's an easy way to learn for free. they charge money for composer, so you'll have to use a trial or local docker if you want to experience airflow. I do have a lot of colleagues who previously worked with snowflake and loved it, and I haven't met a soul who ever worked on databricks or is interested in having it at my current org.",
          "score": 4,
          "created_utc": "2026-01-14 01:16:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfw9f5",
          "author": "chmod764",
          "text": "To optimize for the *number* of available job applications, I'm thinking:\n\n- data ingestion: Fivetran or Airbyte or maybe even Meltano (which is probably a bit more rare, but good for very cost sensitive companies)\n- orchestration: Airflow\n- warehouse logic: dbt\n- warehouse engine: Snowflake or Databricks, I do see a lot about BigQuery and GCP, but I don't have enough knowledge about how prevalent it really is.\n- cloud platform: AWS\n- transactional db knowledge (not always required for DE): I still think PostgreSQL is king here\n\n\nI think most companies don't truly need streaming, but it you're interested in it from a resume-driven-development perspective, then perhaps RabbitMQ Streams or Kafka or Flink",
          "score": 3,
          "created_utc": "2026-01-13 23:09:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg5zrp",
          "author": "leogodin217",
          "text": "Dbt and Airflow. May not be great for the future, but good for now",
          "score": 3,
          "created_utc": "2026-01-14 00:01:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgzgtl",
          "author": "DataObserver282",
          "text": "Been messing around with DuckDB. This is the way",
          "score": 2,
          "created_utc": "2026-01-14 02:46:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzic9yb",
              "author": "valentin-orlovs2c99",
              "text": "DuckDB is super fun‚Äîfast, lightweight, and surprisingly powerful for analytics use cases. It definitely has a cult following among data folks, and I can see why. That said, if you're thinking about job marketability, you might want to balance tinkering with emerging tools (like DuckDB) with learning the bigger names like Snowflake and Databricks since they show up so often in job posts. Still, knowing your way around DuckDB could make you stand out when someone needs a nimble, local analytics solution. Plus, it‚Äôs just plain satisfying to run complex queries on your laptop without spinning up a fleet of cloud services.",
              "score": 1,
              "created_utc": "2026-01-14 08:57:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkxa41",
                  "author": "tommeh5491",
                  "text": "Thanks for the AI answer",
                  "score": 2,
                  "created_utc": "2026-01-14 18:12:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzicfo2",
          "author": "xmBQWugdxjaA",
          "text": "In my experience just Python, Scala and Java - then you might end up using just Polars, or Spark or Flink, etc.\n\nFAANG doesn't use Snowflake or Databricks.",
          "score": 2,
          "created_utc": "2026-01-14 08:59:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjvvo5",
              "author": "Great_Type8921",
              "text": "What do they use?",
              "score": 1,
              "created_utc": "2026-01-14 15:22:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhkwkf",
          "author": "GlasnostBusters",
          "text": "notepad",
          "score": 1,
          "created_utc": "2026-01-14 05:01:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhtws3",
          "author": "MayaKirkby_",
          "text": "Given you‚Äôre already on Power BI, I‚Äôd optimise for skills that show up everywhere, not chase every shiny thing.\n\nIf I were you in the US, I‚Äôd pick one big cloud and go reasonably deep: Azure (nice fit with Power BI, very common in enterprises) or AWS (huge overall market). On top of that, I‚Äôd add one ‚Äúheadline‚Äù warehouse/lakehouse that‚Äôs all over job posts, Snowflake is the safest bet right now, Databricks is a close second if you like more engineering-heavy work.\n\nLayer that on top of strong SQL and some Python and you‚Äôll be in a good spot for most roles. Fabric is worth keeping an eye on because of the Microsoft story, but I wouldn‚Äôt make it my main bet just yet.",
          "score": 1,
          "created_utc": "2026-01-14 06:10:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi6j4i",
          "author": "Odd-String29",
          "text": "Just learn SQL",
          "score": 1,
          "created_utc": "2026-01-14 08:02:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzidwxm",
          "author": "West_Good_5961",
          "text": "Ingest: Excel spreadsheets\nData Warehouse: MS Access\nTransformations: VBA",
          "score": 1,
          "created_utc": "2026-01-14 09:13:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzja9rd",
          "author": "ObjetoQuaseNulo",
          "text": "I'm thinking the same thing OP, my case is that I'm going back to the job market and the analysis paralysis is hitting hard (for context I'm not U.S based).\n\nSo to solve that, I was wondering whether I should collect as many job postings in my region/state and extract the most common tech keywords to have a base of current demands.\n\nJust so I'm not re-doing work, are there any platforms that collect that kind of data and provide it for free/low cost?",
          "score": 1,
          "created_utc": "2026-01-14 13:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzphj1t",
          "author": "szrotowyprogramista",
          "text": "I may be talking from a different context (in EU not the US), so IDK how entirely applicable the advice is.  \n\nBut I would say that if LLMs have done anything to the job market - it's that they've decreased the relevance of specific technologies, and brought forward the emphasis on higher-level theory - architecture patterns, data modelling, knowledge of the tooling landscape, etc. Sure, if you're already a pro, certified, many YoE in a specific technology it will be a factor in recruiting, but if you're just starting to study something, I'm not sure how much of a factor it will be that you've taken a course or two - as opposed to your abstract DE knowledge. (Then again, IDK how brutal the market is where you are. Maybe you really do need to optimize down to specific technologies.)\n\nIf I really had to name some technologies, I'd say yes, knowing Databricks and Snowflake helps, they hold a lot of mindshare. Knowledge of DBT and EL connectors still seems very relevant to ELT-focused places. Kafka is relevant in real-time contexts. Airflow is not \"cool\", but still relevant, although knowing more modern alternatives like Prefect, Dagster, etc would not hurt. \n\nI would also say that knowing cloud solutions from hyperscaler vendors is relevant - I mean, those besides the DE domain. A DE that is not afraid of HCL and can write or read and make sense of a Terraform module, and knows different AWS solutions (we're an AWS shop), would be valuable in the org where I currently work.",
          "score": 1,
          "created_utc": "2026-01-15 10:52:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj8rw8",
          "author": "RunnyYolkEgg",
          "text": "So no GCP? Why?",
          "score": 1,
          "created_utc": "2026-01-14 13:20:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcs226",
      "title": "Data retention sounds simple till backups and logs enter the chat",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qcs226/data_retention_sounds_simple_till_backups_and/",
      "author": "Initial-Possible9050",
      "created_utc": "2026-01-14 16:37:22",
      "score": 44,
      "num_comments": 4,
      "upvote_ratio": 0.89,
      "text": "We‚Äôve been getting more privacy and compliance questions lately and the part that keeps tripping us up is retention. Not the obv stuff like delete a user record, but everything around backups/logs/analytics events and archived data.\n\n  \nThe answers are there but they‚Äôre spread across systems and sometimes the retention story changes from person to person.\n\n\n\n  \nAnything that can help us prevent this is appreciated",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qcs226/data_retention_sounds_simple_till_backups_and/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzkh2nq",
          "author": "Playful-Dress-2287",
          "text": "Retention is one of those things that looks easy on paper then becomes messy in real systems. What helped us was documenting retention by system type and sticking to one approved narrative, even if the answer is this is our current constraint. Consistency matters more than having a perfect retention story",
          "score": 6,
          "created_utc": "2026-01-14 16:59:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkp800",
              "author": "Salty-Translator5060",
              "text": "For us the biggest improvement was just centralizing the retention evidence and responses so it didn‚Äôt drift between teams. Once we pulled it into Delve, we didn't have to re explain it from scratch every time",
              "score": 2,
              "created_utc": "2026-01-14 17:36:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzkm1h5",
          "author": "exjackly",
          "text": "The only way to prevent it is to have it be a focus.\n\nWhat I mean, is that the retention and destruction rules are collected in one place, and there is assigned responsibility for seeing that they are applied correctly.  This can be a specific person/team or it can be one of the checklist items (if your company is small enough) that every system owner is required to certify for acceptance.\n\nAnd it has to include backups, logs and analytics.  It is a lot of work up front, identifying the rules and what that needs to look like, but the maintenance part of that is generally straightforward.\n\nHonestly, in my experience the hardest part is getting the requirements clearly defined, as business users seldom want to give up old data; which is exactly what this is about.",
          "score": 4,
          "created_utc": "2026-01-14 17:21:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs8zqr",
          "author": "Muted_Jellyfish_6784",
          "text": "retention gets messy fast once backups, logs, analytics events, and archives are involved different systems, different people giving different answers one solid fix I've seen work treat retention as part of your core data model early on add explicit retention fields usse domain driven boundaries to group data by policy apply agile evolutionary modeling so changes are easy to iterate his cuts down on the inconsistency and makes audits way less painful check out r/agiledatamodeling small community but focused on practical patterns and war sttories",
          "score": 1,
          "created_utc": "2026-01-15 19:32:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qaut4d",
      "title": "Data Engineer by title, not by work. Feeling stuck and unsure what to do next.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qaut4d/data_engineer_by_title_not_by_work_feeling_stuck/",
      "author": "mindwrapper13",
      "created_utc": "2026-01-12 13:25:40",
      "score": 41,
      "num_comments": 19,
      "upvote_ratio": 0.92,
      "text": "Hi everyone,\n\nI have a little over five years of experience. I started my career as a Software Engineer working on Python-based full stack applications for 2 years and later moved into a Data Engineer role at a new company because there were very few Python backend opportunities at the time.\n\nOver the last three and a half years, I‚Äôve realised that I never really got to work as a ‚Äúproper‚Äù data engineer. Most of my work involved data administration, Python automation, some cloud services, cloud data warehouses, basic data modelling, and a few simple Airflow pipelines that pulled data from APIs and loaded it using pandas. I never worked with Spark or large-scale data pipelines.\n\nNow that I‚Äôm trying to switch jobs, I‚Äôm in a confusing spot. Based on my experience, companies expect me to be a Senior Data Engineer, but I don‚Äôt have hands-on experience with many of the tools they expect at that level. At the same time, when I get considered for junior  roles, the pay is around 50 percent lower than what I make today. It‚Äôs also hard not to compare myself to people with fewer years of experience who seem to have worked on far more complex data systems.\n\nI‚Äôm willing to start now, learn Spark seriously, build strong projects, and put in the effort. I‚Äôm just unsure if it‚Äôs too late at this stage or if taking a pay cut is the only way to reset my career. Is there a smarter way to transition into real data engineering without completely derailing things?\n\nAny honest advice would really help.\n\nTL;DR: 5+ YOE with a Data Engineer title but limited real DE experience. Now expected to be senior without Spark or large-scale pipeline work. Junior roles mean a big pay cut. Looking for guidance.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qaut4d/data_engineer_by_title_not_by_work_feeling_stuck/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "nz5p4a3",
          "author": "AutoModerator",
          "text": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-12 13:25:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz61lrt",
          "author": "Uncle_Snake43",
          "text": "Not all companies with DEs use Spark or do the kind of things you're thinking.  I am a Data Engineer at a data broker, and 90% of my job is setting up Airflow orchestration, automation, and moving and loading files between SQL Server and Google Cloud.",
          "score": 23,
          "created_utc": "2026-01-12 14:34:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz64m91",
              "author": "No_Song_4222",
              "text": "This is true. Your skillset and tool stack largely depend on the organization tech stack. Especially this is your first job or something like that. \n\nYou can't uproot tech stack overnight and replace it when critical business workflows are already setup. \n\nI do something similar i.e use airflow + SQL+ gcp and I am just learning spark on the side in the local cluster and yes no way on paper I can match someone who is working on a spark in production. \n\nBut can I solve it and work independently ? Absolutely yes :)",
              "score": 7,
              "created_utc": "2026-01-12 14:50:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz66hp1",
                  "author": "mindwrapper13",
                  "text": "Oh, what is your YOE? In my case the salary that I have here is competent so if I need a decent hike on that, I would have to target big companies where they need crazy experience with big and real time data. Other option that I was thinking is to maybe get a similar pay or a small pay cut to get some good experience in the field.",
                  "score": 1,
                  "created_utc": "2026-01-12 14:59:49",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz66259",
              "author": "mindwrapper13",
              "text": "Yes, but most of the jobs that I‚Äôm applying for requires you to have Spark hands on in production. I can def study all this yes, but others who have been working on such stuff since the beginning have an edge over me. Anyway I‚Äôll just study and add some projects to my resume. That‚Äôs all I can do.",
              "score": 1,
              "created_utc": "2026-01-12 14:57:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6ats3",
                  "author": "Krampus_noXmas4u",
                  "text": "Don't forget, companies often list all skills across their DEs in job descriptions, where their current DEs do not all have these skills.  Candidates often are not going to be able to check all boxes off for skills needed in a job description. Recruiters and managers know this (unless it's a skill that is listed as a must have, but even then, still worth applying for the practice and experience).\n\nThat said, have you applied to any jobs that list Spark as a skill? If not, I would suggest applying even if you lack a specific skill.  In those areas you are lacking, focus on how you are willing to grow and learn and provide a past example of how you closed a skills gap if you land an interview.",
                  "score": 2,
                  "created_utc": "2026-01-12 15:21:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz61pp8",
          "author": "DataObserver282",
          "text": "Lean into what you can do well, and try and teach yourself the rest. Not saying this is your experience , but I had a team member come from a more antiquated company once that definetly wasn‚Äôt leaning into the  MDS - ended up working harder than others and leapfrogged to sr in 1 year",
          "score": 3,
          "created_utc": "2026-01-12 14:35:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz88wam",
          "author": "psypous",
          "text": "\nYou have a massive advantage that you might be overlooking: your foundation as a Software Engineer.\n\nIt is absolutely not too late. In fact, the industry is currently shifting back toward wanting Data Engineers who think like Software Engineers. Your background is exactly what the Modern Data Stack needs.\n\nMany Senior Data Engineers are actually great at SQL but terrible at software patterns, your 2 years of Full Stack experience is your advantage.\n\nMy suggestion is to build one solid project using PySpark on a local cluster or a free Databricks Community Edition account.\n\nAlso since you know Airflow Databricks won‚Äôt be difficult!",
          "score": 2,
          "created_utc": "2026-01-12 20:43:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzafncy",
              "author": "mindwrapper13",
              "text": "Yes, but getting interview calls is becoming hard.",
              "score": 0,
              "created_utc": "2026-01-13 03:29:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz8r76w",
          "author": "Waldchiller",
          "text": "Spark is such an obsession right now. I use it but I am not an expert by any means.  When I‚Äôm using spark I still think SQL. Any complex join logic I‚Äôll use spark SQL. I do the same I used to on SQL server DWH just with spark now. Combined with delta lake it‚Äôs kinda nice though especially the Change data feed capabilities. We don‚Äôt have huge data we don‚Äôt need spark but it integrates nicely with fabric so we use it. \n\nAll these jobs with big data require you to be good at spark /dbx but it‚Äôs just hard to get that experience out of nowhere especially coming from smaller orgs. With the bad job market right now it will be hard to land such a job. I think you have to fake it a little bit exaggerate the amount of data you worked with etc.",
          "score": 2,
          "created_utc": "2026-01-12 22:08:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzafjqt",
              "author": "mindwrapper13",
              "text": "Yeah, that‚Äôs why I feel stuck currently.",
              "score": 1,
              "created_utc": "2026-01-13 03:28:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5purh",
          "author": "[deleted]",
          "text": "Sounds like you're using air flow wrong. Use the correct tool for etl.",
          "score": -8,
          "created_utc": "2026-01-12 13:29:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfmrd6",
      "title": "Clickhouse launches managed PostgreSQL",
      "subreddit": "dataengineering",
      "url": "https://clickhouse.com/cloud/postgres",
      "author": "vaibeslop",
      "created_utc": "2026-01-17 19:42:24",
      "score": 40,
      "num_comments": 10,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qfmrd6/clickhouse_launches_managed_postgresql/",
      "domain": "clickhouse.com",
      "is_self": false,
      "comments": [
        {
          "id": "o07g90j",
          "author": "TripleBogeyBandit",
          "text": "But why? Isn‚Äôt their whole product pitch ‚ÄúOLAP at the speed of OLTP‚Äù? Curious what use cases this aids.",
          "score": 16,
          "created_utc": "2026-01-18 00:49:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08yxaz",
              "author": "noswag15",
              "text": "I think this caters to both olap and oltp. Seems like it automatically replicates the data from postgres to clickhouse and any anayltical queries fired on the postgres db gets routed to the clickhouse instance so you get the best of both worlds. Atleast that's what I gleaned from a cursory look at the link in OP.",
              "score": 11,
              "created_utc": "2026-01-18 06:21:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a6b2w",
                  "author": "LemmyUserOnReddit",
                  "text": "Worth mentioning that none of this is new, except for them hosting the PG instance",
                  "score": 2,
                  "created_utc": "2026-01-18 12:46:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bud2t",
                  "author": "saipeerdb",
                  "text": "Thanks for chiming in. This captures the overall vision  well. You are spot on. It caters to both OLTP and OLAP, bringing together the best-in class OSS databases for each (Postgres and ClickHouse) and offering them in the most integrated way. We‚Äôve seen many thousands of companies use Postgres and ClickHouse to build their data stacks, and the adoption is growing very fast. The idea behind this Postgres offering is to bring them even closer together and make that integration as effortless as possible for developers. :)\n\nWith regard to integration, the vision behind our CDC capabilities is to offer a much more native experience, something you can‚Äôt get from other services and addresses problems around standard CDC. Additionally, the `pg_clickhouse` extension will be native to this service and maintained by ClickHouse, and will act as a unified query layer for both transactional and analytical workloads. We plan to invest heavily in this area to make application migration as seamless as possible.\n\nApart from all of this, the Postgres we are offering is NVMe-backed, which is very fast and comes enterprise-grade guarantees. We are building this in partnership with a world-class Postgres team at Ubicloud who were ex-Citus, Heroku, Microsoft Postgres.\n\nThis launch was a primer, stay tuned for a more very soon! :)",
                  "score": 2,
                  "created_utc": "2026-01-18 18:02:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09guk1",
              "author": "Competitive_Layer_71",
              "text": "I don't think the replication is at all that interesting: you can set that up with any provider. \n\nThe killer feature is if the cross-querying is easy: joining a Postgres dataset with a ClickHouse dataset *without* CDC.\n\nIt should be noted that even if pg_clickhouse exists you'd basically have to self host Postgres to get at it. But very few *want* to self host Postgres.",
              "score": 5,
              "created_utc": "2026-01-18 09:01:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09qex4",
              "author": "Creative-Skin9554",
              "text": "Their pitch is being the fastest OLAP database. It still doesn't do OLTP. Speed is irrelevant to that, OLTP and OLAP are different things. Most people still end up with Postgres and ClickHouse inside their business to handle both sides, and now you can buy both from the same vendor.\n\nIf ClickHouse sees that most of their customers are also buying Postgres, why wouldn't they want to be the one selling it to you?",
              "score": 2,
              "created_utc": "2026-01-18 10:30:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o07ssc6",
              "author": "RemoteLifeguard8208",
              "text": "Pretty sure snowflake did a similar thing and I wondered the same thing",
              "score": 1,
              "created_utc": "2026-01-18 01:55:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o084kxu",
                  "author": "TripleBogeyBandit",
                  "text": "Snowflake and databricks, but it makes more sense to server faster workloads in these environments.",
                  "score": 1,
                  "created_utc": "2026-01-18 02:59:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07xu78",
          "author": "BarfingOnMyFace",
          "text": "Nice",
          "score": 1,
          "created_utc": "2026-01-18 02:22:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08mpqb",
          "author": "McNemarra",
          "text": "only makes sense when you see\n\n1. NVMe performance\n\n2. Availability guarantees",
          "score": 1,
          "created_utc": "2026-01-18 04:49:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf7eoh",
      "title": "How big of an issue is \"AI slop\" in data engineering currently?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qf7eoh/how_big_of_an_issue_is_ai_slop_in_data/",
      "author": "Kilnor65",
      "created_utc": "2026-01-17 07:56:45",
      "score": 36,
      "num_comments": 42,
      "upvote_ratio": 0.87,
      "text": "I know many industries are having issues now with AI generated slop, but data engineering should in *theory* consist of people who are a bit more critical and at least question the AI results to some extent before implementing. How is it at your work? Do people actually vet the information given and critically assess it, or do they just plug it into whatever pipeline that exists and call it a day?\n\nI have seen a lot of questionable DAX queries from people I assume have very little to no clue as to why they have made it like that. The complexity of the queries are often worrying as it displays a very high level of trust in the result that has been given to them. Stuff that \"works\" in the moment, but can easily break in the future.\n\nWhat are your experiences? Have you seen anything in production that made you go \"oh, this is BAD!\"?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qf7eoh/how_big_of_an_issue_is_ai_slop_in_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o02vpew",
          "author": "West_Good_5961",
          "text": "I have a coworker who suggested using LLMs to do the actual transformations in a data warehouse. They also use it to generate all code and responds to all questions by sending us LLM outputs instead of researching anything themselves. This is a senior person.",
          "score": 100,
          "created_utc": "2026-01-17 09:33:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02w2vj",
              "author": "Reach_Reclaimer",
              "text": "Senior doesn't always mean good unfortunately",
              "score": 46,
              "created_utc": "2026-01-17 09:37:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o05d46j",
              "author": "SaW120",
              "text": "Same here, senior pydev/data scientist switched to dbt data warehouse development. We do every new pipeline with llm agents. We worked around 2 weeks and we were 2 persons (both new to dbt). Without llms I think you would have needed a full team > 2 months easily.",
              "score": 13,
              "created_utc": "2026-01-17 18:31:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cv3kl",
                  "author": "Firm-Albatros",
                  "text": "Idk if this is concerning or impressive but im here for it",
                  "score": 1,
                  "created_utc": "2026-01-18 20:58:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03gndk",
          "author": "ppsaoda",
          "text": "We have terabytes of data on average daily coming in. Hired a contractor to fix a small bug on batching logic. He's the type of guy that always reply with \"chatgpt said...\". And his codes are full of the typical obvious GenAI slops. I kept raising this issue to the management that he's fully reliant on AI on decision making. Gave more chances. \n\nUntil one day he slopped, causing infinite loop of same batch being loaded repeatedly over and over thru the weekend. Costed us a year of cost in just 2 days.... Fired by next week.",
          "score": 58,
          "created_utc": "2026-01-17 12:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03jsa5",
              "author": "Kilnor65",
              "text": ">Until one day he slopped, causing infinite loop of same batch being loaded repeatedly over and over thru the weekend. **Costed us a year of cost in just 2 days....** Fired by next week.\n\nBrutal",
              "score": 27,
              "created_utc": "2026-01-17 13:01:32",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03rkz6",
              "author": "_predator_",
              "text": "So if he's working on stuff that directly impacts billing, why is no one reviewing his changes before they're applied? This sounds more like an organizational failure than a technical one.",
              "score": 26,
              "created_utc": "2026-01-17 13:50:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03s9u0",
                  "author": "ppsaoda",
                  "text": "We give a bit of autonomy for testing purposes. And yeah, we improved the process after that. Those who are in probation aren't allowed to mess with infra repo.",
                  "score": 5,
                  "created_utc": "2026-01-17 13:54:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04jzqy",
                  "author": "Kilnor65",
                  "text": "There is a practical limit of how much you can baby people. You absolutely **could** have 15 sign off steps at every turn, but that would bog down your entire org and skyrocket costs elsewhere.",
                  "score": 3,
                  "created_utc": "2026-01-17 16:15:43",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o084f5e",
                  "author": "Spunelli",
                  "text": "For real, why doesn't his account have a budget limit. Lmfao.",
                  "score": 1,
                  "created_utc": "2026-01-18 02:58:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03x4py",
              "author": "Able_Ad813",
              "text": "That‚Äôs you on you guys for not having safe guards against that",
              "score": -1,
              "created_utc": "2026-01-17 14:21:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03irnl",
          "author": "dataflow_mapper",
          "text": "It is definitely showing up, mostly in the form of overcomplicated logic that nobody can explain anymore. You can tell when something was pasted in because it technically works but has zero consideration for edge cases, performance, or future changes. The scary part is not bad code, that has always existed, but the confidence people have in it because an AI produced it. The teams that avoid real damage are the ones that still do reviews focused on intent and data correctness, not just whether tests pass. I have seen pipelines where one small schema change would silently corrupt metrics, and nobody knew why the logic looked the way it did. That is usually the moment people get a lot more skeptical of blind copy paste.",
          "score": 17,
          "created_utc": "2026-01-17 12:54:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03qj5v",
              "author": "Kilnor65",
              "text": ">You can tell when something was pasted in because it technically works but has zero consideration for edge cases, performance, or future changes.\n\nYeah I have seen that as well. As long as stuff works now, it gets a pass. Just imagine in a few years when/if the AI market has collapsed and corporations are stuck with millions upon millions of lines of buggy, unmaintainable code but no people who knows how to actually fix it and no ChatGPT to ask.",
              "score": 4,
              "created_utc": "2026-01-17 13:44:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0bvyav",
                  "author": "jesusrambo",
                  "text": "When that happens we‚Äôll probably just ask GPT 9 to clean it up, and it‚Äôll probably do quite well",
                  "score": 1,
                  "created_utc": "2026-01-18 18:10:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02uoqk",
          "author": "Reach_Reclaimer",
          "text": "It's quite a big issue I think. All the AI produced code some of the team I'm in has used and tried to implement has been absolutely crap. It gets a job done but not the job done and it also doesn't fit well within our systems\n\nEvery other ai/vibe coder I've come across has been wank as well. Those that are decent are ones who use it for quick 1 liners when syntax is forgotten or they're exploring something new but never implement the ai code into prod",
          "score": 27,
          "created_utc": "2026-01-17 09:23:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02vs81",
              "author": "Kilnor65",
              "text": ">It's quite a big issue I think. All the AI produced code some of the team I'm in has used and tried to implement has been absolutely crap. **It gets a job done but not the job done and it also doesn't fit well within our systems**\n\nYeah, I have seen it make stuff that is \"good enough\" for the moment when you have 1000 rows of data, but completely breaks when it reaches +100k and beyond. Iterations over full tables etc. \n\n>Every other ai/vibe coder I've come across has been wank as well. Those that are decent are ones who use it for quick 1 liners when syntax is forgotten or they're exploring something new but never implement the ai code into prod\n\n> \n\nYeah, I many use it for syntax or just trying to figure out a possible entry point, then google to understand it better if the solution provided is not straight forward enough.\n\nNow that Stack Overflow is going away, I wonder what future models will get their data from. Using GitHub repos will probably not work as a majority of them now uses AI generated data that will mess up the training.",
              "score": 3,
              "created_utc": "2026-01-17 09:34:15",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03s5lf",
              "author": "forserial",
              "text": "What are your guys using? Claude code is surprisingly good now, but it's expensive we can easily hit like $100+ a day per developer. It writes great code that aligns with existing style, but unfortunately every prompt / step in thinking chain is 5-10k tokens especially if it has to read context and scan surrounding code before doing anything.",
              "score": 1,
              "created_utc": "2026-01-17 13:53:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03f6it",
          "author": "NoleMercy05",
          "text": "Much much Less of an issue than offshoring 85%+ of a companies tech staff.",
          "score": 24,
          "created_utc": "2026-01-17 12:28:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03ufeq",
              "author": "TA_poly_sci",
              "text": "I just in general poor decision making by humans. That has had decades to build up, LLMs have had 3",
              "score": 1,
              "created_utc": "2026-01-17 14:06:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o04been",
          "author": "WhileTrueTrueIsTrue",
          "text": "On my team, it's a serious issue. We laid off most of our team and immediately turned around and offshored those position to India. Now, our new Indian coworkers are copying text from Jira tickets, pasting it into Claude, copying whatever Claude generates, and opening PRs without testing the code. The code usually doesn't run, and these people are completely closed off to constructive criticism, so nothing has improved for weeks. They do like to bitch about us, though. \n\nMy manager came to me yesterday to tell me I needed to be more patient and to train one of these guys more. There is no training taking place, because they're not actually attempting to do what is asked of them. Copying and pasting things into and put of an LLM is not learning or trying, it's just creating slop. Ive gone over the changes that need made to a file three times now and have shown them the exact lines where changes need to be made. Something that I've told them is only a 3 line update turns into a 600+ line diff.\n\nLast week, I got on a call with my tech lead and one of these guys and went through every single line he had updated in a PR and asked him to explain his design decisions. He literally couldn't explain what the code did at all. \n\nSo, at least on my team, it's a huge issue. We are hiring people that aren't competent because our leadership assumes that any idiot can generate code via an LLM, so they're hiring the cheapest idiots they can find. We have guardrails on everything, so no one has brought down dev, let alone prod, but jfc it's an exhausting, neverending mess around here.",
          "score": 12,
          "created_utc": "2026-01-17 15:34:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04fht6",
              "author": "Kilnor65",
              "text": "How is it even sustainable?\n\nAt some point, there will be no original crew left who even has a basic understanding of what does what and why. AI slop will generate upon already AI generated slop, by people who have no understanding of the underlying system and don't care either for that matter.\n\nI know from experience of just working on smaller personal solutions just how quickly \"ah, I'll take this shortcut\" can bite you in the ass once the scale grows or you have to make changes. I cant even imagine the damage a team of vibe coders in India can cause...",
              "score": 3,
              "created_utc": "2026-01-17 15:54:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04x6v7",
                  "author": "WhileTrueTrueIsTrue",
                  "text": "It isn't. The remaining US devs that built our platform are all looking for new jobs. I dread going to work now, so I'm leaving.",
                  "score": 5,
                  "created_utc": "2026-01-17 17:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ei2oj",
              "author": "bubzyafk",
              "text": "Haa‚Ä¶ I guess many management likes this crap.. fresh grad from the best uni in my country is the same price as 8YOE in India/vietnam.. from Opex point of view this is makes sense, but from quality it‚Äôs questionable.. especially when they make the internal dev-team is just few people while the contractors are many.\n\nWait till you‚Äôve done any interview to them. Some done 1-2 projects of data pipeline within 2-3 years and abit of databricks then call themselves an Architect. Some people have same coding test answer 1 another (GPT copy paste), etc.\n\nBut again, not everyone is bad.. I got people that don‚Äôt even know how to write sql agg and sometimes just copy paste code from gpt without even think.. and 1 guy that damn good in many stacks. Stream, batch, api, coding, sql, etc.. \n\nBottom line is, 1st: there‚Äôs chance to find gold in contractors, our task to find one‚Ä¶ 2nd: we both know we should run away from this company because they might not know how to appreciate engineering. Wish both of us luck in 2026.. lol",
              "score": 1,
              "created_utc": "2026-01-19 02:06:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o08xape",
          "author": "LelouchYagami_",
          "text": "Gosh. I was ranting about it yesterday. One my coworker has gotten addicted to AI usage. Their role is a bit on the lowcode side(Dashboards mainly) so it's not as much of AI slop code, but everything else.\n\n\nHe was supposed to document a certain onboarding process for a new product and dude made a fuckin 30 page doc. Obviously AI. It has like 40 different steps in 5 phases. Then he set up a 2 hour call with the team to review the doc. Manager postponed the meeting to 3 days later cuz no one had the time to read that. \n\nIn the end, maybe only the manager read the doc. Not even sure of that.\nRest of us just gave a go ahead without reading the whole shit. And the dude is so proud that he has contributed to documentation in extreme detail. 100% no one is going to follow through that shit.\n\nNow when you slack the guy, he'll reply with obviously AI generated messages. The meeting invites have AI slop agenda with üëâ‚ùå‚úÖüìÖüìçüöÄ emojis \n\nOther teammates have started to use AI to summarise his messages and emails into human readable summaries",
          "score": 4,
          "created_utc": "2026-01-18 06:08:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02mpo9",
          "author": "EntertainmentOne7897",
          "text": "DAX in data engineering? What?\n\n\nBut bad data quality lack of governance lack of documentation is a much bigger issue for me than a sql query written by AI.\nAI wont solve my people problem and data illiteracy",
          "score": 9,
          "created_utc": "2026-01-17 08:08:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0388dz",
              "author": "Kilnor65",
              "text": "It mostly falls on us when the reports starts to fail.\n\nIt is in 99% of the cases that they are doing SELECT \\* FROM some massive table and then writing bonkers DAX that takes **minutes** to run.",
              "score": 5,
              "created_utc": "2026-01-17 11:30:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o031eft",
              "author": "Data_cruncher",
              "text": "It‚Äôs common for DAX expressions to be moved/converted upstream by DEs for performance reasons - Roche‚Äôs Maxim.",
              "score": 3,
              "created_utc": "2026-01-17 10:27:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03ciea",
          "author": "BufferUnderpants",
          "text": "My former team lead generated a copious amount of slop for a system that's meant to replace something running on a mainframe. But no worries, he's since plopped the project on one of the teammates with more time on the company and he'll be taking over now, with minimal coordination.\n\nHe did create a voluminous, but ultimately insufficient, test suite for the contraption. But he did try, there. The code itself is atrocious and the pipeline flounders when ran against data outside the test suite.\n\nAnyway, I'll probably look for a new job by mid year, I'd switch now but I started three months ago and I can't be assed to go through interviews for weeks on end again just now, the silver lining is that I'm seeing that I can do whatever I want amidst all this chaos, and my overtime is regulated so what gives.\n\nEdit: also this is one of the largest and better known multinational corporations of its type of financial services lmao",
          "score": 3,
          "created_utc": "2026-01-17 12:06:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03s6r8",
          "author": "Leather-Replacement7",
          "text": "Humans make slop too. I‚Äôve seen tons of ‚Äúdata platforms‚Äù fail as they‚Äôre just a collection of disparate pipelines with poor docs and no tests. If there are standards and conventions in place, a tool which outputs pretty robust code after a few iterations can 10x a team. I don‚Äôt think AI is the problem, it‚Äôs teams happily letting the tail wag the dog.",
          "score": 6,
          "created_utc": "2026-01-17 13:53:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o040eoa",
              "author": "ldhe_shsieon",
              "text": "Yep. I‚Äôve spent the last year pushing my team to standardize pipelines so everything that can (80% probably) follows the same patterns. The humans have come up with the patterns and we‚Äôve validated them together instead of each person building their own shit, and now AI can easily follow it within Cursor or Claude Code.\n\nIMO being a staff is all about creating good standards and guard rails so that you can 10X the team around you who are less skilled than you. AI is not different than a junior team member.",
              "score": 2,
              "created_utc": "2026-01-17 14:38:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05oyxg",
          "author": "His0kx",
          "text": "It makes me laugh when I see DEs talking about AI slop while I have spent my entire working life on Human slop : garbage code, totally stupid data modeling and bad optimised queries (¬´¬†we are in the cloud now so we can just add more compute power¬†¬ª). \n\nMy hot take is that AI/LLMs will put data modeling at the number one skill but problem is that a lot of DEs are really bad at it and are scared because they can‚Äôt rely on just producing and shipping (often bad/average) code/pipelines because they will be slower than LLMs.\n\nIf your datawarehouse, datamarts and semantic layer have strong foundations and follow the same patterns, LLMs will provide a real time gain allowing DEs to focus on architecture/data modeling (the fun part of the job imp).",
          "score": 4,
          "created_utc": "2026-01-17 19:26:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04joth",
          "author": "wstwrdxpnsn",
          "text": "We are using LLMs for call transcript summarizations and are looking at using snowflake cortex as a tool for folks to find answers to common questions. I personally use GitHub copilot to help scaffold ideas for things I‚Äôm unsure of but it‚Äôs very iterative and tbh probably would make the process take longer for someone with more experience than just doing it themselves. I feel it just helps give me context for a lot of ‚Äúwhy‚Äù questions I have when doing new development involving tools or systems I‚Äôm unfamiliar with.",
          "score": 2,
          "created_utc": "2026-01-17 16:14:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05fqry",
          "author": "Little_Kitty",
          "text": "Those who made crap PRs before now make more and there's more to read. Their understanding of basic concepts is still wrong so the whole thing still needs to be redone, but it takes longer. I can at least ask an LLM to tone down my review so they get less offended.\n\nThose who can't even be bothered to ask for a bug check get told off, it's good for cutting that out of PRs and letting me focus on the logic and coverage.",
          "score": 2,
          "created_utc": "2026-01-17 18:43:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04kdh3",
          "author": "PuckGoodfellow",
          "text": "I'm a DE student. I have a very strict instructor for an intense data warehousing class. Current homework includes creating an ER model diagram. I was struggling a little bit on how to determine the tables and consulted 3 different AI to help give me some direction (ChatGPT, Gemini, Copilot). They were all different and wrong. Missing attributes, weird relationships, tables that weren't needed... but it did help me work through the challenge I was having so I could DIY.",
          "score": 1,
          "created_utc": "2026-01-17 16:17:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04vcfu",
          "author": "Walk_in_the_Shadows",
          "text": "I‚Äôm all for AI augmenting engineers existing skillsets by reducing repetitive tasks and boilerplating pipelines. It can save a huge number of man hours, without the slop\n\nHowever, all PRs are reviewed properly. If you used AI and can‚Äôt explain what it‚Äôs doing and why, the PR gets rejected. It‚Äôs a good way to weed out engineers who do nothing but copy code generated by ChatGPT",
          "score": 1,
          "created_utc": "2026-01-17 17:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05i9gz",
          "author": "Immediate-Pair-4290",
          "text": "I‚Äôve been asked to come fix bad design. So it‚Äôs definitely an issue.",
          "score": 1,
          "created_utc": "2026-01-17 18:54:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04mq54",
          "author": "LargeSale8354",
          "text": "AI Slop == Always India Slop?\n\nSeriously,  this could be just my perception but the DE stuff that was published felt like stuff worth publishing and Reading. These days, it feels like the \"worth reading\" proportion is low",
          "score": 0,
          "created_utc": "2026-01-17 16:28:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}