{
  "metadata": {
    "last_updated": "2026-01-24 02:29:56",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 360,
    "file_size_bytes": 384504
  },
  "items": [
    {
      "id": "1qivk0x",
      "title": "This will work, yes??",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/ht0f89g2voeg1.png",
      "author": "Thinker_Assignment",
      "created_utc": "2026-01-21 11:34:40",
      "score": 217,
      "num_comments": 8,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qivk0x/this_will_work_yes/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0ucq1b",
          "author": "Ok-Improvement9172",
          "text": "Management wouldn't be wearing the hard hat and swinging the hammer. They'd be staring at their watch, tapping their foot, with a whip in their hand, grumbling to a consultant while a contingent worker on a 3 month contract is sweating bullets trying to make this happen.",
          "score": 38,
          "created_utc": "2026-01-21 12:20:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ughsi",
              "author": "Thinker_Assignment",
              "text": "nice one :) maybe it's a budget hammer that hits hard and leaves a dent",
              "score": 1,
              "created_utc": "2026-01-21 12:45:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uopdc",
          "author": "SupaWillis",
          "text": "It‚Äôs actually me with the hammer usually",
          "score": 33,
          "created_utc": "2026-01-21 13:35:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0upzy3",
              "author": "Thinker_Assignment",
              "text": "username checks out",
              "score": 5,
              "created_utc": "2026-01-21 13:42:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uj36e",
          "author": "lillogicdork",
          "text": "Ain't no way management touches code",
          "score": 9,
          "created_utc": "2026-01-21 13:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0uqeqr",
              "author": "Thinker_Assignment",
              "text": "i really wish that were true, but i once did a 6mo enterprise project where we re-wrote a manager's monolithic notebook to discover his genius 99% accuracy was infact, suprised pikachu, a bug. The people involved had salaries in the millions per year.",
              "score": 4,
              "created_utc": "2026-01-21 13:44:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0xmhx6",
                  "author": "Difficult-Vacation-5",
                  "text": "Which company is this thst pays people millions a year?",
                  "score": 2,
                  "created_utc": "2026-01-21 21:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0uua4p",
              "author": "Kaze_Senshi",
              "text": "They don't want to , because of that they love vibe coding.",
              "score": 2,
              "created_utc": "2026-01-21 14:05:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhcekr",
      "title": "Any data engineers here with ADHD? What do you struggle with the most?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qhcekr/any_data_engineers_here_with_adhd_what_do_you/",
      "author": "psgpyc",
      "created_utc": "2026-01-19 18:31:30",
      "score": 147,
      "num_comments": 82,
      "upvote_ratio": 0.94,
      "text": "I‚Äôm a data/analytics engineer with ADHD and I‚Äôm honestly trying to figure out if other people deal with the same stuff.\n\nMy biggest problems\n\n\\- I keep forgetting config details. YAML for Docker, dbt configs, random CI settings. I have done it before, but when I need it again my brain is blank.\n\n\\- I get overwhelmed by a small list of fixes. Even when it‚Äôs like 5 ‚Äúeasy‚Äù things, I freeze and can‚Äôt decide what to start with.\n\n\\- I ask for validation way too much. Like I‚Äôll finish something and still feel the urge to ask ‚Äúis this right?‚Äù even when nothing is on fire. Feels kinda toddler-ish. \n\n\\- If I stop using a tool for even a week, I forget it. Then I‚Äôm digging through old PRs and docs like I never learned it in the first place.\n\n\\- Switching context messes me up hard. One interruption and it takes forever to get my mental picture back.\n\nI‚Äôm not posting this to be dramatic, I just want to know if this is common and what people do about it.\n\nIf you‚Äôre a data engineer (or similar) with ADHD, what do you struggle with the most? \n\nAny coping systems that actually worked for you? Or do you also feel like you‚Äôre constantly re-learning the same tools?\n\nWould love to hear how other people handle it.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qhcekr/any_data_engineers_here_with_adhd_what_do_you/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0is2dt",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-19 18:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0it4nd",
          "author": "GachaJay",
          "text": "Meetings and constantly changing requirements",
          "score": 132,
          "created_utc": "2026-01-19 18:36:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ix2ke",
              "author": "SirGreybush",
              "text": "You need a data analyst that is part of your team, part of IT and not a business unit. \n\nSo that he/she go nuts not you.",
              "score": 30,
              "created_utc": "2026-01-19 18:53:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ixtlb",
                  "author": "GachaJay",
                  "text": "We need a lot of things. First and foremost we need to be relieved from the 126% tariff on our company as we only have a 9% profit margin prior to the tariff being enforced. The joys of ‚Äúwanting manufacturing to occur in America,‚Äù but taxing the manufacturing companies for raw materials it has to get overseas.",
                  "score": 13,
                  "created_utc": "2026-01-19 18:56:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0jpd9d",
                  "author": "thisfunnieguy",
                  "text": "ive worked with data analysts at 3 different companies; each one they were sorta mini-data scientists with better presentation skills.\n\nthey were doing dashboards and running analysis about new features and about user behavior on our site.\n\n  \nnever se them have anything to do with requirements.",
                  "score": 5,
                  "created_utc": "2026-01-19 21:04:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0iwbay",
          "author": "SoggyGrayDuck",
          "text": "Context switching and the absolute insane overuse of agile. Agile isn't supposed to mean \"throw everything at the engineer and then prioritize\" \n\nI'm at a company that wants to think and act like fin tech but because we don't have solid processes it creates so much tech debt. Bringing it up is like you dropped an f bomb in church",
          "score": 77,
          "created_utc": "2026-01-19 18:50:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j0y8j",
              "author": "ResidentTicket1273",
              "text": "Agile kills so many good teams, especially if it gets invaded by the business/product-manager who use it as a stick to beat engineers with. A good reply I've found is to make sure you raise high-value tickets/tasks to refactor/enable sustainable build/promote maintainability/maintain velocity - just to shoehorn actual real development work into what would otherwise be a wishlist with no idea as to the costs/consequences of balancing a bunch of unicorn-shit until it all falls over.",
              "score": 17,
              "created_utc": "2026-01-19 19:10:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0kgr0v",
                  "author": "StewieGriffin26",
                  "text": "I had an 8 point user story one time, like I created it, said it was 8 points, everyone agreed, but it was still tooth and nail to get that set as 8 because agile says you can break it down further.\n\nSure I can break it down to a 5 point and a 3 point user story but my god, sometimes it's just doing shit in jira for *metrics* which really just means paperwork.",
                  "score": 7,
                  "created_utc": "2026-01-19 23:21:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0lircp",
              "author": "Sea-Meringue4956",
              "text": "Are we in the same company? This is my life",
              "score": 1,
              "created_utc": "2026-01-20 02:47:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0nja0m",
                  "author": "SoggyGrayDuck",
                  "text": "Is there a consulting firm involved?",
                  "score": 0,
                  "created_utc": "2026-01-20 12:07:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0iuf6f",
          "author": "Distinct-deel",
          "text": "I struggle with long meetings \nI lose my focus half way through when they repeat same unnecessary things over and over that I miss important parts discussed then I have to figure them by my own",
          "score": 54,
          "created_utc": "2026-01-19 18:41:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kj1lv",
              "author": "Kukaac",
              "text": "Same. Just for context, \"long\" starts at around 17 seconds.",
              "score": 12,
              "created_utc": "2026-01-19 23:33:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0krr05",
                  "author": "Distinct-deel",
                  "text": "It depends on the topic for me.\nI can stay engaged for hours if I‚Äôm contributing, leading the discussion, or answering meaningful questions.\nBut it drops to about 10 seconds when directors are arguing about policies and internal management politics. I sometimes force myself to stay alert and listen just to understand the politics, but it‚Äôs very challenging and honestly frustrating. At times, it becomes difficult to even pretend that I‚Äôm still listening.",
                  "score": 4,
                  "created_utc": "2026-01-20 00:20:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0jnsvi",
              "author": "areyoua0neora0",
              "text": "I‚Äôm so happy that I‚Äôm not alone",
              "score": 3,
              "created_utc": "2026-01-19 20:56:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0mx3wz",
              "author": "VibraniumSpork",
              "text": "And video call training.\n\nBrother, you want me to focus on a 9-5 Teams presentation over 3 days? I ain‚Äôt learning shit.",
              "score": 3,
              "created_utc": "2026-01-20 08:52:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0kwaaf",
              "author": "katharsix",
              "text": "That's why I always ask for them to record meetings so I can just zone out and work while people are talking and then come back to the video and watch it in 2.5x or get an AI summary or smth to get to the important bits.",
              "score": 4,
              "created_utc": "2026-01-20 00:44:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vv11r",
                  "author": "psgpyc",
                  "text": "I do the same. If its a one-on-one, or few off us, I always ask beforehand If i can record it.",
                  "score": 1,
                  "created_utc": "2026-01-21 16:58:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0mqgw2",
              "author": "ooh-squirrel",
              "text": "Wait.. what kind sorcery is this? How do you make it all the way to half way? 20 minutes in I need an import statement before I am of any use. I can stay somewhat focused if I find the topic interesting enough but even then it's sometimes a struggle.",
              "score": 1,
              "created_utc": "2026-01-20 07:50:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0lppnc",
              "author": "PlantainStriking4423",
              "text": "Make it a habit to use an LLM recording/ summariser in every meeting, this is my plan too!",
              "score": 1,
              "created_utc": "2026-01-20 03:26:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vqko0",
                  "author": "psgpyc",
                  "text": "Yeah, I use the notion AI meeting tool. It helps.",
                  "score": 1,
                  "created_utc": "2026-01-21 16:39:01",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jn81w",
          "author": "kiquetzal",
          "text": "I think for us all it's context switching , which includes meeting transitioning. I have two tools I absolutely relish:\n1) Todo manager: I use Super Productivity. 100% local with ADHD and Focus/Flow management in mind\n2) Rituals: I plan my week and I plan my day. Every time as the first thing I'll do. When forced to switch context, I look into the day plan that I set up.",
          "score": 23,
          "created_utc": "2026-01-19 20:54:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0juf5n",
          "author": "ooh-squirrel",
          "text": "Yup. Lead engineer with primarily inattentive type adhd and a sprinkle of autism. Context switching and changing requirements are the worst. And meetings. Oh my god.. the meetings. \n\nI decided that I didn‚Äôt want to deal with it alone and I felt comfortable enough to disclose my adhd to my manger, my PM (that I have worked closely with for 5+ years) and a few more coworkers. Full acceptance and support all around. The PM was even like ‚Äúuhm.. yeah, I could have told you that‚Äù\n\nI still forget shit. And sometimes trail off. Or hyperfocus on the wrong task. Or deepdive into some weird deviation on the 8th decimal in an algorithm while listening to Finnish melodic death metal at a dangerously high volume. The difference is that now they know why.",
          "score": 17,
          "created_utc": "2026-01-19 21:28:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0l01jd",
              "author": "mikeballs",
              "text": "This genuinely gave me a second-hand rush of relief to read that you can be accepted and supported at work while being wired this way. Thanks for sharing",
              "score": 5,
              "created_utc": "2026-01-20 01:05:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mpgiq",
                  "author": "ooh-squirrel",
                  "text": "Happy to hear that. It's a story I like telling. \n\nI'm lucky to be in a company that support D&I by word and action. Fx. they are an active supporter of the hidden disabilities sunflower. It also helps to be in a country where D&I is literally part of the labor laws and ADHD is covered by disabilities laws. \n\nThat said, I would still encourage people to disclose if they feel safe to do so. You'd be surprised how many people are supportive or struggle with similar or other issues themselves. Diagnosed or otherwise.",
                  "score": 5,
                  "created_utc": "2026-01-20 07:41:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ke73z",
              "author": "PoochyPoochPooch",
              "text": "Username checks out",
              "score": 3,
              "created_utc": "2026-01-19 23:07:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jbhun",
          "author": "Treemosher",
          "text": "Yep, sole data engineer here and standing up a brand new CDW.  Diagnosed and medicated when i was a kid.  Re-diagnosed and medicated since about 5 years ago.\n\nBiggest help for me is cognitive therapy with psychologist who specializes in ADHD and stuff.\n\nThe validation thing, learning to trust myself, learning to stop self-shaming myself, etc has been a lifesaver.\n\nAnd to literally sit down and talk with someone about all the stupid junk that goes through my head.  Just being able to express frustrations with myself and occasionally with coworkers (data analysts).\n\nOn top of designing the ingestion and bringing in new data sources, I'm also the only account administrator for our CDW.\n\nLiterally nobody else on my team, even IT, understands the work I do.  They wouldn't even know I am doing it unless I straight up explain it to them.\n\nIt does force me to communicate and document like a mad dog.  Force my team to make decisions together with me so they stay involved and in the knowledge loop.\n\nBut going from access control, onboarding & training new users, coming up with a strategy for ongoing development, and also switching back to discussing whether to bring in <this other critical system's data>, peppering in these smaller data sources, it's a fucking lot.  I\n\nSometimes I think the ADHD helps lol  But my therapist is my fucking hero.\n\nBased on the text vomit I just dumped here, I would recommend you find a therapist you click with if you are struggling.  And ADHD people usually feel like they're struggling, don't we.",
          "score": 15,
          "created_utc": "2026-01-19 19:59:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ka6jb",
              "author": "TieAccomplished7039",
              "text": "That‚Äôs great!\nWhat kinda data you with? I‚Äôm looking for insights on data engineering.",
              "score": 1,
              "created_utc": "2026-01-19 22:46:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0j3vy0",
          "author": "hotlinesmith",
          "text": "the 7 seconds it may take spark to start evaluating a simple query",
          "score": 13,
          "created_utc": "2026-01-19 19:24:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m5z1q",
              "author": "solo_stooper",
              "text": "Switch to snowflake lol",
              "score": 1,
              "created_utc": "2026-01-20 05:05:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iwts6",
          "author": "SirGreybush",
          "text": "Reddit when someone says something that is wrong. \n\nOr that I am wrong. \n\nArgh! Distracted again FML",
          "score": 8,
          "created_utc": "2026-01-19 18:52:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j8azo",
              "author": "Treemosher",
              "text": "Defiance is one hell of a motivator",
              "score": 3,
              "created_utc": "2026-01-19 19:44:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ixoq9",
          "author": "Budget-Minimum6040",
          "text": "Meetings.\n\nEvery 2 weeks in person scrum retro + scrum planning for 4 hours with my team (2 people), web analysis team (4 people) + both team leads + head of department.\n\nMy tickets were like 5 minutes of the 4 hours and everything else so fucking boring and had nothing to do with my work at all so ... felt asleep 2 times while sitting next to the head of ...",
          "score": 6,
          "created_utc": "2026-01-19 18:56:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kobdc",
              "author": "MissingSnail",
              "text": "No meeting should ever last four hours. ADHD or not, that is torture.",
              "score": 5,
              "created_utc": "2026-01-20 00:02:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0n8ya1",
                  "author": "Budget-Minimum6040",
                  "text": "1:30 hours, 30min mandatory lunch break where we ordered pizza normally, 2:30 hours\n\nStill so sleepy.",
                  "score": 1,
                  "created_utc": "2026-01-20 10:42:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jhgog",
          "author": "wherzeat",
          "text": "Oh god... i am not alone",
          "score": 5,
          "created_utc": "2026-01-19 20:27:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kkw8n",
          "author": "jubza",
          "text": "I struggle the most with paying attention in meetings, morning meetings in particular. And getting started. Once I'm into the swing of things, I can sit there for hours and plug away at it (if I enjoy it). \n\nSomething that helps me is that I have a file that has all my testing code in. YYYYMMDD_scratchpad.py/sql \n\nAll my little bits of code are in there on a weekly basis. If there was a funky function or something that I once did and want again, there it is. I recommend saving your configs somewhere :) \n\nAlso, few people mentioned AI here. Absolutely, I was very against it until recently, I thought it took away from me being a proper data engineer but honestly, AI is not something thats going to take your job away if you know how to leverage it in your favour. I ask my preferred AI provider some questions, sometimes it gets it wrong and I have to correct it or point it but even when it gives me something a bit wrong, it still gives me something to work with that I would have otherwise taken an hour or two to put together where to start.",
          "score": 4,
          "created_utc": "2026-01-19 23:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m6rn2",
              "author": "solo_stooper",
              "text": "I have this system too. In markdown in VS Code/ Cursor",
              "score": 1,
              "created_utc": "2026-01-20 05:10:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0j1mng",
          "author": "chock-a-block",
          "text": "You need a project manager that you trust to set your priorities.  Whoever you report to might be the way to get going.\n\nJust couch it like, ‚ÄúI want to make sure I have my priorities straight. I worry about that.‚Äù. Not ‚ÄúI need help because I have a thing you might get very judgmental about.‚Äù  And everyone knows priorities change.  It‚Äôs just knowing/acting on what they are right now.\n\nNever, ever discuss ADHD at work.  ADHD is one topic  that brings the crazy out.  Among medical professional, too!\n\nEDITS for clarity.",
          "score": 6,
          "created_utc": "2026-01-19 19:13:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mshr1",
              "author": "ooh-squirrel",
              "text": "Honestly discussing my ADHD at work has helped a lot. People were very understanding and supportive but it naturally depends a lot on the situation, the country you're in, and how safe you feel in your company and position. \n\nWe changed some things in the team including how we run meetings and ways-of-working. Incidentally the entire team are really happy about the changes.",
              "score": 1,
              "created_utc": "2026-01-20 08:08:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kcnls",
          "author": "cky_stew",
          "text": "Since I got medicated I turned into an absolute powerhouse, and my career skyrocketed to taking very well paid and competitive contracts. I gained the capability to focus on fulfilling tasks to absolute completion, it was life changing.",
          "score": 3,
          "created_utc": "2026-01-19 22:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lcbg1",
              "author": "superiorballsack",
              "text": "What medication did you take? Do you find the side effects to be worth it?",
              "score": 1,
              "created_utc": "2026-01-20 02:12:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0myt5b",
                  "author": "cky_stew",
                  "text": "I started with elvanse (vyvanse in US) - which worked OK but required strict regiment I struggled with. Then due to a shortage of it I had to switch to Amfexa which is like instant release dexamfetamine - this stuff works way better on me - I can dynamically adjust dose, it‚Äôs not the end of the world if I miss one etc - it kicks in faster and I know it‚Äôs not supposed to but I feel the effects last almost as long as the slow release stuff.\n\nThis was all on docs recommendation though, I never ‚Äúchose‚Äù what I wanted to be on.\n\nI have a higher heart rate, burn more calories, and if I take a dose too late then I might lose a bunch of sleep, which happens every now and again when my routine is all over the place.\n\nWell worth it for me, personally. Yes, it will probably shorten my lifespan - but I enjoy my work way more now (I sometimes work evenings, wtf), and I‚Äôm earning so much more to retire earlier with a nicer house etc; I genuinely prefer my life this way so I‚Äôm happy with the elevated risks.\n\nI don‚Äôt want to take this stuff forever, I feel I can eventually move away from being the code grunt and more of a manager and project director type role, which requires less pure concentration in order to overcome complex technical intricacies- because that‚Äôs where the meds really shine. But yeah I think I‚Äôd probably be OK without it in a fast moving role with constant requirement shifting.",
                  "score": 1,
                  "created_utc": "2026-01-20 09:08:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kk4fg",
          "author": "ForMyWork",
          "text": "For me, I love jumping between helping people in the team on different tasks or problem solving. I find I'm a very rapid problem solver. Whereas if I have one big thing that isn't particularly interesting I find it difficult to sit with just that. \n\nIf it's an interesting problem, or new piece of work for tackling, then that's different and I can often get a really good burst of work done. If it's a repetitive thing that isn't particularly fast, that's the work that causes me to just freeze up and I struggle with. \n\nI find that to get through those tasks where my brain just has no interest and freezes up, jumping onto other things that are more interesting and then coming back to it helps a lot, so doing it in chunks, whether that is my work or helping someone else. \n\nAlso a 10-minute walk to break up a day really helps me focus, and I do little longer lunch walk on my break and eat at my desk. Those two things help me focus a lot better throughout the day. Also when I started medication in October that really helped as well.\n\nOh one other one, I sometimes get a bit frustrated when people are so much slower at picking up the concept or the problem when they are the decision maker, or blocking something. If it is someone just working at their pace or understanding things as they do that's fine, but when it's a blocker or like I feel like I've explained myself three times, that can be frustrating. I don't often show that frustration but it puts a downer on the day.",
          "score": 3,
          "created_utc": "2026-01-19 23:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0knvil",
          "author": "MissingSnail",
          "text": "This is silly, but I keep losing notebooks and just grabbing a new one from the supply closet on the way to the next meeting. I have like five going now with various notes in them. I know I‚Äôve written it down somewhere, in one of the notebooks I on my work desk, or maybe one I left at home (I‚Äôm hybrid), or maybe one I left in a conference room‚Ä¶.",
          "score": 3,
          "created_utc": "2026-01-19 23:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pk6dl",
          "author": "ObjetoQuaseNulo",
          "text": ">Any coping systems that actually worked for you? Or do you also feel like you‚Äôre constantly re-learning the same tools?\n\nCheatsheets.  \n\n\nYes they work, find ones that are pertinent for the tools you use. For example, I know Python, Java, and Rust. Sometimes I might not use a language for a week or a few weeks, and end up forgetting the syntax structure of a language or some functions, I just check the cheatsheet, and check the standard library/api.\n\n  \nThere's a lot of cheatsheets out there for the tools you need, if there isn't, make ones that are useful for you.",
          "score": 3,
          "created_utc": "2026-01-20 18:22:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jzqfw",
          "author": "Deadible",
          "text": "I've found that my team generally has a good validation culture for asking quick clarifying questions of each other. This does slightly clash with not wanting context switching, but a bit of disruption there has been a good sacrifice to stopping things getting sluggish.\n\nI'm generally much better with lists of tiny tasks - it's the big ones where I just accumulate distractions. At some point I had to train myself to split it out into more tickets. ALWAYS overestimate how long something will take to do and you will still be underestimating it.\n\nMe and my small team are generally fine asking each other for validation - we take reviewing as an opportunity to knowledge share, so that's baked into how we spend our time/how productive we are.\n\nI hate meetings where I'm not needed, or I'm witnessing a project manager give an inaccurate representation of something. I hate when people give too much detail about things in standup when they're not looking for input. It's physically painful. \n\nI find unreasonable requirements difficult, because my instinct is always to begin to work around how we would do something, even if the system doesn't support it, and not ask whether we should do something. So I tend to hold my cards close to my chest and talk with my team/manager before I solutionise in the moment.\n\nI have been at the same place for around five years so I have built trust that I do good work, ask the right questions for peoples requirements, and am proactive about our data stack, so that gives me some leeway.",
          "score": 2,
          "created_utc": "2026-01-19 21:55:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lvjk1",
          "author": "Inevitable_Bunch_248",
          "text": "Taking notes helps me a ton, then I turn them into jota epics/stories/spikes for my team.\n\n\nMaking people write what they want after talking to them helps too.",
          "score": 2,
          "created_utc": "2026-01-20 03:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m6ju5",
          "author": "Digitaldarkness14",
          "text": "Technical writer turned Data Engineer here. Systems work for me. I have habit of using lists and trackers for my work. I always had to work with changing requirements so that was the only way",
          "score": 2,
          "created_utc": "2026-01-20 05:09:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mgq4z",
          "author": "Great-Tart-5750",
          "text": "I also struggle with the same things as you listed along with continuous meetings and changing PRD's. \n\nWhat I do to deal with this is, I have created extensive documentation for all login credentials, common bug fixes, dbt scripts, jenkins steps, etc. \nI also shared it with my seniors so that he can also provide inputs if anything had to be changed. \n\nIt has been more than a year since I created that doc and now it is used by everyone in our team.\n\nFor the changing requirements and meetings, I start my day with creating a note of things that need to be closed today. If there are anything left from the previous day, those are inserted according to priority. The list keeps me in check what I am currently working with even if someone interrupts and the mental map is lost. \n\nIt took me 2 years to learn all this, but in the end this works well for me.",
          "score": 2,
          "created_utc": "2026-01-20 06:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ojccb",
          "author": "soundboyselecta",
          "text": "Honestly with the amount of information being thrown at any human who uses any tech in the last few years of high speed access, even more so now with llm(s) and socials especially the short video epidemic, I find it hard to believe not everyone has ADHD. One of the most important things I find is limit distractions this includes \n1) shutoff all social related apps\n2) dont have 400 windows open (mainly browsers) constantly close anything unrelated to main task, you can get it back with grouping  browser tabs/ windows and history.\n3) if you have multiple screens like me, use it only when u need it otherwise limit it to one\n4) try to read a book before you sleep versus anything on a screen \n5) invest in a proper time management tool\n6) invest in an advanced to do list is important\n7) catch bad habits before then happen",
          "score": 2,
          "created_utc": "2026-01-20 15:31:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0to0io",
          "author": "arachnarus96",
          "text": "I have ADHD and my problems include impulsivity and forgetting why I did stuff. I may have found a good solution to a problem and months later when someone asks me about it I have no clue what they're talking about. I don't struggle with forgetting how to do stuff though but refreshing skills is always nice. And also naming stuff in data factory or in a database like views or tables can get messy.",
          "score": 2,
          "created_utc": "2026-01-21 08:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u1ak1",
          "author": "BorisKuntimov",
          "text": "Scope creep from stakeholders, remembering certain pyspark libraries that I've used countless times for integrations and or transformations, whimsical meetings that I'm not actually in required in because requirements haven't even been gathered.....\nThere's loads ,,ü§£",
          "score": 2,
          "created_utc": "2026-01-21 10:49:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jaogh",
          "author": "nonamenomonet",
          "text": "Yes. That‚Äôs me.  \n\n\nWhat helps me is my tickets have acceptance criteria that I can point back to to make sure I‚Äôm done. I also am a big believer in using AI when my brain is stuck. And though my current setup doesn‚Äôt work for this (cloud based with no local environment‚Ä¶ which is dumb) I was a big believer in TDD.",
          "score": 2,
          "created_utc": "2026-01-19 19:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k5qzy",
          "author": "heisoneofus",
          "text": "Oh shit I might have ADHD. Thanks OP.",
          "score": 2,
          "created_utc": "2026-01-19 22:24:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j7pai",
          "author": "Mysterious_Rub_224",
          "text": "AI is your friend here. Make a Claude style that will help you triage and breakdown projects or deployments. And then use whichever LLM in your IDE and give it your repo + docs as context on how your project is structured. Then you can turn around and get the LLM to \"make a game plan\" instead of you combing thru old PRs.\n\nLLM is also good at helping separate out all the disparate tasks/issues, so it takes on a good bit the cognitive load of \"wait which context am I in and do I need to switch over to another mode of thinking  for this other deliverable?\". Like just word vomit everything thats on your plate or in your head and get it to structure and breakdown what matters (critical path, bruh) and what does not.\n\nThink of it this way: Wouldn't it be nice to have additional roles supporting you as a DE? Like...\n\n- a PM to help prioritize all the chaos of requests\n- An intern to go do the \"look up how we did this last time\" work\n\nThen make appropriate personas for AI to fill those roles.",
          "score": 3,
          "created_utc": "2026-01-19 19:41:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vqyd8",
              "author": "psgpyc",
              "text": "I have been using AI. I am asking it to be my PM and list out requirements and acceptance criteria. Thank you.",
              "score": 1,
              "created_utc": "2026-01-21 16:40:42",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0jguxh",
              "author": "wherzeat",
              "text": "Thanks!",
              "score": 0,
              "created_utc": "2026-01-19 20:24:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0jazuc",
              "author": "nonamenomonet",
              "text": "This assumes they are allowed to use AI/Claude at work. At my last three jobs I wasn‚Äôt allowed to have Ubuntu on my machine.",
              "score": -2,
              "created_utc": "2026-01-19 19:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jcypu",
                  "author": "ActEfficient5022",
                  "text": "Using Claude for assistance with task management is way less difficult than getting Linux on your work machine. I'm not sure what the connection is.",
                  "score": 1,
                  "created_utc": "2026-01-19 20:05:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jp2t1",
          "author": "thisfunnieguy",
          "text": "there's plenty of neurodivergent in the SWE/DE space.\n\nand importantly there HAVE been neurodivergents in the eng space for many many many years.\n\nSo you CAN be successful, you just have to figure out a mix of meds and processes to keep you on the track.\n\nchecklists are great.\n\nI really like a \"deploy checklist\" md file added with any PR: \"this is a quick list of what needs to happen to make this change go live\".\n\nThat might be a \"merge to main\" and profit or stuff like \"merge to main, delete the OLD s3 bucket manually, run the TF apply... run the DB migration, wait for this jenkins pipeline to finish....\"\n\n  \n\\--\n\n  \nEDIT:\n\nanother reason i like this is it gives me something i can point someone else to. \"hey is this the right steps to deploy this\"",
          "score": 2,
          "created_utc": "2026-01-19 21:02:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k2qbo",
          "author": "Adorable-Emotion4320",
          "text": "Wait, so you guys are saying the DE's that 1) are not insanely overcompensating their insecurity by being a d##k¬†\n2) those that not like meetings, agile, ridiculous requirements, getting new tasks every day and basically everything else that is wrong in every other data project\n\n\nBut the ones that are just struggling and have imposter syndrome like the rest of us are all neurodivergent?\n\n\nPlease show me the list of symptoms that fill this criteria (genuinely would like to know)",
          "score": 1,
          "created_utc": "2026-01-19 22:09:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0l5x9p",
          "author": "zazzersmel",
          "text": "Had a manager who would send back all my work with lists of minor formatting issues, refusing to answer any big picture questions I had about the project until everything met his exact standards, often over and over again. Then he‚Äôd criticize for taking too long.",
          "score": 1,
          "created_utc": "2026-01-20 01:37:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ldf94",
          "author": "Tupiekit",
          "text": "I will say‚Ä¶.as a data analyst who has ADHD and wants to pivot into data engineer but who is scared/self selecting myself out of the field because of my fear of my ADHD making it hard‚Ä¶,this thread is kinda helping.",
          "score": 1,
          "created_utc": "2026-01-20 02:18:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lif69",
          "author": "skatastic57",
          "text": "Everything you said plus Adderall hasn't been available for 3 months. \n\nOn the validation thing, I'll often get a somewhat vague ask so I'll do a minimum viable thing, give them that and ask where they want to go, and they'll say this is great, no notes. It seems like that would be good but getting no notes sucks. It just makes me think they didn't want anything to begin with and they were just asking me to check the box that they asked me. \n\nIf I have a bunch of low priority things I also often end up doing none of them and instead invent a project that's tangentially related or is a pet project.",
          "score": 1,
          "created_utc": "2026-01-20 02:45:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lrjqe",
          "author": "hairymelon90",
          "text": "You summed it up well. I've got perfectionism too which is so difficult because it irks me to have incorrect data and not do anything about it RIGHT NOW. But if I try to fix it, I hyper-fixate and go down rabbit holes trying to find the root of an issue... 20-30 dbt models deep and I've found 17 more issues and can't figure out which to tackle first. It's overwhelming and I feel so defeated.\n\nHowever, I feel like I'm a good counter to others on my team though because they're so quick to just push out \"good enough\" (ughhh I wish my brain could be okay with that) and I catch things they miss with my annoyingly fine-tooth comb.",
          "score": 1,
          "created_utc": "2026-01-20 03:37:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mk5l9",
          "author": "One_Citron_4350",
          "text": "It depends on how your team or working environment is like? Do you have a team leader or a manager or are you alone in this situation? How many stakeholders are you working with?\n\nChanges, especially on short notice are unfortunately common.",
          "score": 1,
          "created_utc": "2026-01-20 06:55:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ndkzx",
          "author": "angry_oil_spill",
          "text": "Yyyyep. Down to a T. Described my experience perfectly as a data analyst and learning data engineer.",
          "score": 1,
          "created_utc": "2026-01-20 11:22:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nfe0u",
          "author": "GehDichWaschen",
          "text": "I dont have adhd and struggle with the same things. Mostly I have accepted that things take time, in particular what you mentioned: \n\nProper docs, \nAnnoying context switching, \nTedious result validation with users\n\nI cannot use a magic wand to do all this, it just takes time.\n\nbut when you have clear procedures to do each step properly and stick to it, at least you yourself keep the sanity",
          "score": 1,
          "created_utc": "2026-01-20 11:37:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nh8fk",
          "author": "Murky-Sun9552",
          "text": "I use notepad ++ to copy and paste config templates with heavily commented lines, and jupyter notebooks to scratch in, all saved on my desktop, has helped me no end",
          "score": 1,
          "created_utc": "2026-01-20 11:51:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o3cf4",
          "author": "Longjumping_Lab4627",
          "text": "Are these related any to ADHD? Don‚Äôt everyone just struggle with these challenges? \nI can extend the list with challenges where I can‚Äôt force myself to pay attention to‚Ä¶ but tbh I think that‚Äôs a common struggle among normal people as well",
          "score": 1,
          "created_utc": "2026-01-20 14:10:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vurr7",
          "author": "psgpyc",
          "text": "Thank you everyone for the replies. It genuinely makes me feel safer knowing so many of us go through similar things.\n\nI realised I have ADHD a bit late, and I‚Äôm still learning how to cope with it. I‚Äôm more on the hyperactive side, and for years I‚Äôve lived in a cycle of hyperfocus and burnout. Nothing felt ‚Äúenough‚Äù or ‚Äúperfect‚Äù, so I kept polishing, then I‚Äôd burn out and abandon it. In the end, I had lots of half-finished work and very little truly completed.\n\nLately I‚Äôm learning to prioritise, and like many of you said, a consistent routine has helped the most. To manage the hyperactive side, the vocal stimming, and my mind wandering, I started going live on Facebook (I just have my famliy members on facebook). Weirdly, that‚Äôs helped me stay present and keep the hyperactivity in check.\n\nI also used to take loads of notes, but they were scattered everywhere (notebooks, random apps, GitHub). Now I‚Äôve moved everything into Notion with a proper structure, and it‚Äôs made a huge difference\n\nOne thing I still struggle with is the need for validation. I‚Äôm starting to accept that this might be something I need to work through properly, and I think therapy is the direction that will actually help long-term.\n\nReally appreciate all of you taking the time to share advice and experiences.",
          "score": 1,
          "created_utc": "2026-01-21 16:57:49",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o109z4q",
          "author": "Glittering_Light_334",
          "text": "Yes, I do. I have been clinically diagnosed with ADHD but not on any medication currently. The biggest struggles have been with: \n\n1. Paying attention especially on long drawn business meetings.\n\n2. Sticking to learning something and being consistent once the novelty wears off. \n\n3. Being able to estimate and track time in general. \n\n4. Hyper focusing on perfecting trivial aspects of routine tasks like documentation.",
          "score": 1,
          "created_utc": "2026-01-22 07:14:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10rzpa",
          "author": "ineedasolution",
          "text": "You just helped me self diagnosis myself with ADHD.",
          "score": 1,
          "created_utc": "2026-01-22 10:01:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14bqqy",
          "author": "junacik99",
          "text": "Hello, for some time now I work in Data Engineering and Data Science. I was not diagnosed with adhd, but I have always felt that I cannot focus on one thing for a long time. I have trouble even doing online courses for more than 5 minutes. Especially boring HR stuff, but also technical courses.\n\nI recently discovered Planner on MS teams. Which is like really simplified version of Jira. I add there really small implementation steps I want to take . Usually one day before. Those tasks are usually small and simple so I don't feel overwhelmed. And if I do I take a breath and just choose one that can be done right away. This start is the most important.\n\nTo focus on a task, when my hands are not occupied by the keyboard, I use small objects to hold in my hand like d20 dice or even a pen. \n\nAlso very good thing is a rubber duck debugging. You can have a small rubber duck to which you explain your task or your code and it just listens and won't interrupt you. This helps you focus more on your task and immerse in it.",
          "score": 1,
          "created_utc": "2026-01-22 21:14:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kisie",
          "author": "SaintTimothy",
          "text": "What do I struggle most with?\n\n\nhumans\n\n\nOr, more specifically, psychology... maybe IOPsych.\n\n\nIf a person is an idiot, I can't just call them an idiot, replace them with someone competent, and move on with my life (as one might a failed laptop). I have to instead provide them enough opportunities to either grow, or prove to their boss that they are, indeed, an idiot. Bonus points of their boss is also an idiot.\n\n\nRunner up, for things I struggle with. Weltschmerz.",
          "score": 1,
          "created_utc": "2026-01-19 23:32:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kj8p9",
              "author": "SaintTimothy",
              "text": "I've heard weltschmerz described as the pain felt when someone doesn't do what you expected of them.",
              "score": 1,
              "created_utc": "2026-01-19 23:34:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0l32ab",
          "author": "decrementsf",
          "text": "ADHD does not exist. On average it is lifestyle factors posing as a label. Stay up late with poor sleep binge watching shows, eat terrible, no exercise for aerobic development, no restful practices to build parasympathetic support and counter stress, focus is going to go to hell. We teach therapy terms without teaching language and habits for health.",
          "score": -2,
          "created_utc": "2026-01-20 01:22:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lqpvo",
              "author": "PlantainStriking4423",
              "text": "not sure this is true but even if it were you still needs way to cope with the 'symptoms' of bad health while you find better health",
              "score": 1,
              "created_utc": "2026-01-20 03:32:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0o4cf3",
                  "author": "decrementsf",
                  "text": "There used to be the boring advice of grandma. She would chastise you for staying up all night. Cut to the point that well of course you feel terrible, you're not doing any of the things all people who feel good have to do.\n\nI have in mind the parents of the boomers generation. They're not around anymore and this role is being forgotten.\n\nChanneling that energy to play it forward. With mind toward college and high school aged as audience. A large portion of them are naturally unaware, yet, what habits support feeling good. More than is accurate take on an identity of a neurotic. I think they'd be happier with the cut to the point advice from grandma. Playing it forward, I loved that grandma. She was full of boring advice from grandma you roll your eyes at. Then fifteen years later after trying every nootropic and other option finally tried going to bed earlier and your life falls together and recognize damnit, the boring advice was from grandma was wisdom.",
                  "score": 1,
                  "created_utc": "2026-01-20 14:16:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qi7quj",
      "title": "Spending >70% of my time not coding/building - is this the norm at big corps?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qi7quj/spending_70_of_my_time_not_codingbuilding_is_this/",
      "author": "HiddenStanLeeCameo",
      "created_utc": "2026-01-20 17:40:10",
      "score": 138,
      "num_comments": 35,
      "upvote_ratio": 0.97,
      "text": "I'm currently a \"Senior\" data engineer at a large insurance company (Fortune 100, US).\n\nPrior to this role, I worked for a healthcare start up and a medium size retailer, and before that, another huge US company, but in manufacturing (relatively fast paced). Various data engineer, analytics engineer, senior analyst, BI, etc roles.\n\nThis is my first time working on a team of just data engineers, in a department which is just data engineering teams.\n\nIn all my other roles, even ones which had a ton of meetings or stakeholder management or project management responsibilities, I still feel like the majority of what I did was technical work. \n\nIn my current role, we follow Devops and Agile practices to a T, and it's translating to a **single pipeline being about 5-10 hours of data analysis and coding and about 30 hours of submitting tickets to IT requesting 1000 little changes to configurations, permissions, etc and managing Jenkins and GitHub** deployments from unit>integration>acceptance>QA>production>reporting\n\nIs this the norm at big companies? if you're at a large corp, I'm curious what ratio you have between technical and administrative work.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qi7quj/spending_70_of_my_time_not_codingbuilding_is_this/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0pefea",
          "author": "Reverie_of_an_INTP",
          "text": "Yeah that was my exact experience in a similar job.",
          "score": 96,
          "created_utc": "2026-01-20 17:56:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sgnho",
              "author": "Fun-Estimate4561",
              "text": "We moved over to databricks last year and no one else wanted it so my team took hold \n\nNot having any red tape and autonomy to build has been amazing \n\n(Being the manger of the group still force everyone to follow best practices but not having to deal with other groups red tape is awesome)",
              "score": 15,
              "created_utc": "2026-01-21 03:11:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pmouj",
          "author": "toadling",
          "text": "Is that normal? I am not sure. All I know from experience is that the bigger the org the more red tape and the more pointless meetings you get stuck with",
          "score": 62,
          "created_utc": "2026-01-20 18:33:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tftf5",
              "author": "ask-the-six",
              "text": "If you lack skills and talent in a large org you can make a career out of scheduling meetings/creating meaningless policies to roadblock skilled and talented people.",
              "score": 21,
              "created_utc": "2026-01-21 07:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yvmb1",
                  "author": "NDHoosier",
                  "text": "Stop giving me flashbacks, dammit.",
                  "score": 1,
                  "created_utc": "2026-01-22 01:39:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pk5pr",
          "author": "zipzapzippydyzoom",
          "text": "I've found that no matter what you're doing, working in big corporations means less responsibility and more redtape. That's why I prefer consultancy rather than working inhouse. Because you have a higher probability of working on big projects and are less likely to do day to day stuff. (logging every hour of your day is a bitch, though)",
          "score": 43,
          "created_utc": "2026-01-20 18:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sdfmm",
              "author": "NDHoosier",
              "text": "\\> *I've found that no matter what you're doing, working in big corporations means less responsibility and more redtape.*¬†\n\nTry working in government....",
              "score": 5,
              "created_utc": "2026-01-21 02:52:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yq3s6",
                  "author": "Empty_Experience_950",
                  "text": "That's not red tape that's red carpet bureaucracy, where literally \"nothing\" gets done",
                  "score": 4,
                  "created_utc": "2026-01-22 01:08:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qsn68",
          "author": "BestNarcissist",
          "text": "you are an engineer, not a coder.\n\nLawyers don't spend much time in court.\n\nSurgeons don't spend much time in the OR.\n\nArchitects dont spend much time drawing.\n\nThis is completely normal.",
          "score": 98,
          "created_utc": "2026-01-20 21:45:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0shgir",
              "author": "Maple_Mathlete",
              "text": "damn this was a great way of putting it",
              "score": 16,
              "created_utc": "2026-01-21 03:16:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o169w4c",
              "author": "jduran9987",
              "text": "Damn dude‚Ä¶ look at the perspective on you.",
              "score": 1,
              "created_utc": "2026-01-23 03:28:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0xa3j8",
              "author": "SELECT_ALL_FROM",
              "text": "I like this idea, but also glad you didn't capitalise Engineer. Some of those other professions, and Engineers, are highly governed and accredited titles. That said, much like software engineering, data engineering feels right",
              "score": 0,
              "created_utc": "2026-01-21 20:46:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o115ose",
                  "author": "Quick_Assignment8861",
                  "text": "Does it matter? They could call me a pipeline artist idgaf. Sounds like a culture thing",
                  "score": 1,
                  "created_utc": "2026-01-22 11:56:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pd092",
          "author": "joins_and_coffee",
          "text": "Yeah, this is pretty normal at large, regulated companies. Once you hit a certain scale, a lot of the ‚Äúwork‚Äù becomes coordination, approvals, and moving changes safely through environments rather than writing code. The irony is that the more senior and mature the org, the less time you actually spend coding. devops + strict governance + multiple environments usually means pipelines are easy to build but slow to *land*. Insurance is especially heavy on this. Some teams do manage to streamline it with better self-service, platform teams, or looser controls in non-prod, but 60 to 70% overhead isn‚Äôt unusual. Whether that‚Äôs acceptable or soul draining is kind of the real question",
          "score": 20,
          "created_utc": "2026-01-20 17:49:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pt8dx",
          "author": "Astherol",
          "text": "Most senior DE in major manufacturing company in Europe here. It's normal, the further I go into high impact projects the more calls and business engineering I do. Currently I do mailing, meetings and monitoring the control dashboards and it's already 4 hours in work and I'm about to finally open Databricks to throw in some code. Don't fear of going Data Engineer -> Solution engineer, there is good $$ there",
          "score": 8,
          "created_utc": "2026-01-20 19:02:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pe9l7",
          "author": "mcgrst",
          "text": "Depends on the project. Last one got so crunchy my boss was doing all the meetings and admin while I done all the work. Other projects it's been near 50/50.¬†\n\n\nPart of me prefers the pressure of a very hard deadline and someone else dealing with the rest of the chaos.¬†",
          "score": 8,
          "created_utc": "2026-01-20 17:55:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0quyqq",
          "author": "Kenny_Lush",
          "text": "Ah, ‚Äúagile.‚Äù Somewhere there are happy people that never heard of that miasma of dystopian micromanagement. I really need to be more grateful for what I have.",
          "score": 6,
          "created_utc": "2026-01-20 21:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pyfgo",
          "author": "Im_probably_naked",
          "text": "Sounds like you're in a large company. My company was bought a year ago by a large company and I'm experiencing this too. I'm actively looking.",
          "score": 5,
          "created_utc": "2026-01-20 19:26:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rfw11",
          "author": "StewieGriffin26",
          "text": "That's normal.",
          "score": 3,
          "created_utc": "2026-01-20 23:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rfxp8",
          "author": "jfrazierjr",
          "text": "Unfortunately yes.   The bigger the company, the bigger the work getting done tax",
          "score": 4,
          "created_utc": "2026-01-20 23:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q6why",
          "author": "peterxsyd",
          "text": "Literally just get out of there. Those companies will be dead. Setup an auto Claude bot to do your tickets for you, ask to work from home lots and build your own apps and startup whilst studying to learn lots of stuff that will help scale your impact meaningfully.",
          "score": 8,
          "created_utc": "2026-01-20 20:05:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rdrji",
          "author": "secretazianman8",
          "text": "I am at a large corporation in a similar role and situation. I saw the same problem with these types of friction here and elsewhere. And we both know this friction could be reduced by moving a lot of these responsibilities into the cicd pipelines.  \n\nThis type of friction is something unfortunately only certain people can change because it's organizational and requires different c suite and vp's to understand which can be a difficult task. If those people aren't open to it, then switch jobs. Optimizing for machines is easy. Optimizing our companies decisions unfortunately is complicated. \n\nAs my role has increased, my time is being spent more on \"selling\" our devops practices to the right leadership and how these best practices reduce the friction from organizational processes.  There're two paths to adoption in my opinion.\n\nThe first is convincing the leadership in charge of both organizations to see the friction. So a lot of my time is spent on making architectural diagrams, reading the latest research publications to use in presentations and design, generating pretty graphs, etc. I want to showcase where we are spending our time and the value coming out of the different usages of time.\n\nThe second is to convince the leadership and engineers from the team causing friction that there's a better way. For this, I spend time helping my team excel in ways that we always get recognition in organizational announcements. We want to convince leadership and engineers in other organizations to see how efficient we are and come to us to adopt our practices.  \n\nEncouraging education seems to be difficult in this industry. The people in the highest roles often get there over time and often get stuck in their ways. It's not always the case but it happens enough and the research agrees. The DORA research publications have shown that a disconnect between developers and researchers is all too common",
          "score": 3,
          "created_utc": "2026-01-20 23:33:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pd9z8",
          "author": "PrestigiousAnt3766",
          "text": "No, it sounds like a hellhole..\n\nId get out fast.",
          "score": 10,
          "created_utc": "2026-01-20 17:50:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q2oy8",
          "author": "Firm-Yogurtcloset528",
          "text": "Recognizable. Advice, get out if you can before you become brain death,",
          "score": 5,
          "created_utc": "2026-01-20 19:46:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tb6wc",
          "author": "i_hate_budget_tyres",
          "text": "Seniors in my firm are also mainly managers.  My firm followed the big tech trend of laying off the proper manager roles PM, BA, Scrum master etc and flattening out the structure.  This meant the seniors had to start filling in.",
          "score": 2,
          "created_utc": "2026-01-21 06:47:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xtp7s",
          "author": "DoubleAway6573",
          "text": "I'm in a small start up reverted to seed phase. we are less than 25 heads in total and my last two days I had no less than 9 meetings. this is hell",
          "score": 2,
          "created_utc": "2026-01-21 22:17:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qxz6o",
          "author": "GachaJay",
          "text": "The higher your designation the more meetings and less IC work. As a manager, graduated from Lead,85% of my day is meetings.",
          "score": 2,
          "created_utc": "2026-01-20 22:10:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rth9r",
          "author": "Aggressive-Intern401",
          "text": "I've worked at large companies and it absolutely sucked. The amount of red tape, ineptitude and meetings was too much. The only way I'll work for a large corp again is if I'm starving.",
          "score": 1,
          "created_utc": "2026-01-21 00:59:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sgre7",
          "author": "Sizzlingbrowny",
          "text": "That‚Äôs completely normal",
          "score": 1,
          "created_utc": "2026-01-21 03:12:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tf1gd",
          "author": "One_Citron_4350",
          "text": "My understanding is that the more you go up the rank, you tend to focus less on the coding/building. The nature of your work changes, it remains technical but you become more of an enabler, focus on designing, meetings, connecting, doing glue work, following through the entire data engineering lifecycle and beyond.",
          "score": 1,
          "created_utc": "2026-01-21 07:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0thlnj",
          "author": "m1nkeh",
          "text": "Yep, pretty much mate",
          "score": 1,
          "created_utc": "2026-01-21 07:44:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tm1s7",
          "author": "GrandOldFarty",
          "text": "This is exactly how it is.",
          "score": 1,
          "created_utc": "2026-01-21 08:25:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tsm3y",
          "author": "gaussmage",
          "text": "Depends on the company. I had a previous job where everything had to be signed off by multiple people to approve a deployment or change. Current job more leeway and direct cloud access to do stuff vs having to rely on another team",
          "score": 1,
          "created_utc": "2026-01-21 09:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xm5i9",
          "author": "ID_Pillage",
          "text": "Wait until your company trials implementing AI DLC",
          "score": 1,
          "created_utc": "2026-01-21 21:41:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjbawr",
      "title": "Fivetran pricing spike",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qjbawr/fivetran_pricing_spike/",
      "author": "onksssss",
      "created_utc": "2026-01-21 21:44:44",
      "score": 97,
      "num_comments": 54,
      "upvote_ratio": 0.98,
      "text": "Hi DEs,\n\nAnd the people using Fivetran..\n\nWe are experiencing a huge spike (more than double) in monthly costs following the March 2025 changes, and now with the January 2026 pricing updates.\n\nPreviously, Fivetran calculated the cost per million Monthly Active Rows (MAR) at the account level. Now, it has shifted to the connector (or connection) level. This means costs increase significantly ‚Äî often exponentially ‚Äî for any connector handling no more than one million MAR per month. If a customer has multiple connectors below that threshold, the overall pricing shoots up dramatically.\n\nWhat is Fivetran trying to achieve with this change?\nFivetran's official explanation (from their 2025 Pricing FAQ and documentation) is that moving tiered discounts (lower per-MAR rates for higher volumes) from account-wide to per-connector aligns pricing more closely with their actual infrastructure and operational costs. Low-volume connectors still require setup, ongoing maintenance, monitoring, support, and compute resources ‚Äî the old model let them \"benefit\" from bulk discounts driven by larger connectors, effectively subsidizing them.\n\nWill Fivetran survive this one? My customer is already thinking about alternatives.. what is your opinion?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qjbawr/fivetran_pricing_spike/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0xmt52",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 21:44:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xpx9x",
          "author": "trash_snackin_panda",
          "text": "Many businesses who are stuck on Fivetran don't have another option, whether it's because there is a technical skill gap, staffing, etc. There are alternatives, but high switching costs. \n\nFivetran is trying to make more money, to properly expand their product offering, and make good on their merger with dbtLabs, sqlmesh, etc. They need staffing hours dedicated to people making good on the synergies between their products. Essentially flying the plane while building it. \n\nSo yeah. They now own probably 50% of the teams that manage the software products many DE's rely on. Probably more. Are we surprised prices went up? No. Will they keep going up? Almost definitely.",
          "score": 44,
          "created_utc": "2026-01-21 21:59:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10j2ex",
              "author": "Odd-String29",
              "text": "‚Ç¨10K is our yearly Fivetran bill. We are keeping our eyes open for other solutions, but if we need to hire someobdy to built a replacement the ROI is going to be several years. Looking at the current spend for this month I don't see a very large increase in our situation.",
              "score": 3,
              "created_utc": "2026-01-22 08:36:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o123ytb",
                  "author": "asevans48",
                  "text": "Airflow to the rescue i guess.",
                  "score": 3,
                  "created_utc": "2026-01-22 15:11:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0z2k8s",
          "author": "pungaaisme",
          "text": "Isn't this expected? I am not sure why FT customers are surprised by the increase in their FT invoices. Any VC-backed company needs to show 50% YoY growth, or it faces a down round. FT raises prices for its customers at every renewal to keep its VC satisfied. There are plenty of alternatives available that are much cheaper. It's time to stop paying per-row for data.",
          "score": 25,
          "created_utc": "2026-01-22 02:19:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10s8la",
              "author": "uncertainschrodinger",
              "text": "It also seems like a never ending spiral - they increase prices, lose customers, need to increase prices to make up for lost customers, rinse and repeat.\n\nFrom what I've seen around me, people are more and more opting for tools that are not so vendor-locked just so they can jump ship when this type of shit happens.",
              "score": 6,
              "created_utc": "2026-01-22 10:03:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o11c2c1",
                  "author": "anti_humor",
                  "text": "I'm still in my first data engineering job. I remember being a bit disappointed when I was hired that we aren't using many if any of the tools that are popular in this sub and on DE blogs and everywhere else. \n\nI've been here a couple of years now, and although there's definitely some extra work involved with doing almost everything in house, it totally makes sense to me now. Every company is going to have some amount of exposure to vendor lock in, but it seems clear that limiting this exposure as much as is practical has been a good move.",
                  "score": 5,
                  "created_utc": "2026-01-22 12:41:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0zfdi9",
          "author": "blueadept_11",
          "text": "We pay around $10k a month for fivetran and are paying somebody to migrate to an in-house built solution. I think the ROI is positive in like 3 months. In 2021-2023, I paid $10k/yr to stitch for unlimited rows. Fivetran is out of its damn mind.",
          "score": 12,
          "created_utc": "2026-01-22 03:32:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10be3v",
              "author": "ZirePhiinix",
              "text": "Nah, they know not everyone can switch and they need to get the returns going.",
              "score": 5,
              "created_utc": "2026-01-22 07:26:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17gtwz",
              "author": "TiredDataDad",
              "text": "Not sure what are the data sources you are ingesting with Fivetran, but I think you are probably not very far off with your ROI calculation.\n\nWe did it for a few clients and they were quite happy, not just for the cost savings, but also because they got full visibility on their loading pipelines",
              "score": 1,
              "created_utc": "2026-01-23 08:51:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0xqiys",
          "author": "GreyHairedDWGuy",
          "text": "I know nothing about you or your customers situation but for us, there was a small increase but not significant.  Most of our connectors attract more than 1M MAR per month with some around 10million so perhaps that's why we didn't see a large increase.  Our small MAR connectors are generally less than 500,000 paid MAR each with a few < 100,000MAR (we're talking $40USD for the month).\n\nWhat plan are you using?",
          "score": 8,
          "created_utc": "2026-01-21 22:01:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zx01i",
              "author": "onksssss",
              "text": "Enterprise and many connectors less than 1M MAR",
              "score": 2,
              "created_utc": "2026-01-22 05:29:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o13xutl",
                  "author": "GreyHairedDWGuy",
                  "text": "what were you paying before versus now?   if you don't mind me asking",
                  "score": 1,
                  "created_utc": "2026-01-22 20:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10l3zw",
          "author": "Domehardostfu",
          "text": "When I was head of data of my previous company, Fivetran was a one man replacement.\n\n1 month of salary = 1 year of data sync.\n\nThe prices kept increasing till 1/2 month of salary = 1 month of data sync.\n\nAt this time we had to replace. And I was an early adopter of Fivetran.\n\nI'm now working as a contractor, with 10Yrs of experience, let me know if you need help migrating from Fivetran.",
          "score": 9,
          "created_utc": "2026-01-22 08:55:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14qj6q",
              "author": "quickdraw6906",
              "text": "What do you prefer to migrate to?",
              "score": 1,
              "created_utc": "2026-01-22 22:26:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o181gkv",
                  "author": "TiredDataDad",
                  "text": "My suggestion would be dlt. It's open source, but dlthub, the company behind it, is building something on top of it, not just a dlt SasS, so I am pretty confident it will stay open.\n\nDisclaimer: we implement dlt for our clients, migrating away from Fivetran and Airbyte",
                  "score": 1,
                  "created_utc": "2026-01-23 11:52:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18tj3l",
                  "author": "Domehardostfu",
                  "text": "It really depends on the data sources, company and data department maturity. \n\nIf there's already a company scheduler I'll try to reuse it. \nElse Either prefect or Airflow are simple enough and work great, I'll implement my typical extraction framework which already includes SLA checks for jobs out-of-the-box.",
                  "score": 1,
                  "created_utc": "2026-01-23 14:37:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0xxqgk",
          "author": "redwards1230",
          "text": "sweet summer child",
          "score": 17,
          "created_utc": "2026-01-21 22:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y3xl1",
          "author": "Apprehensive-Ad-80",
          "text": "Price model changes rarely benefit the customer, so what are they doing? Making more money. It‚Äôs that simple. \n\nWe jumped from them last year to portable because of the price and (lack) of service",
          "score": 9,
          "created_utc": "2026-01-21 23:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0z963k",
          "author": "wantonmee-nowanton",
          "text": "Same here. After the pricing updates, despite 41% reduction in MARs, our costs spiked 193%. It‚Äôs insane cause we initially got into this to save time and money",
          "score": 5,
          "created_utc": "2026-01-22 02:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ycfno",
          "author": "Jameswinegar",
          "text": "Without actual numbers or sources to provide a real opinion on, if you're spending thousands of dollars a month it might be worth looking into Estuary for your workloads, it does pricing by GB and task runtime vs MAR. \n\nWe've seen price reductions of 80% for some SaaS sources like Shopify and 90%+ for databases with high transaction volume.",
          "score": 7,
          "created_utc": "2026-01-21 23:54:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yjaf2",
          "author": "latro87",
          "text": "We also had a significant increase in costs and my director decided our current priority is to dump as much Fivetran as we can as fast as possible.\n\nJust moving our netsuite ingestion off of it will cut our bill by 50%\n\nWe plan to cut the connectors down to a handful that represents maybe 5% of our spend. We will only keep these last few as they don‚Äôt cost much but are otherwise hard to replace with other solutions.",
          "score": 3,
          "created_utc": "2026-01-22 00:31:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o181u99",
              "author": "TiredDataDad",
              "text": "I think you are a bit pessimisting with your 50%.  \n  \nWe went fully opensource for the NetSuite ingestion and we really spent only pennies",
              "score": 1,
              "created_utc": "2026-01-23 11:55:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0z164k",
          "author": "Nekobul",
          "text": "The \"sweetness\" of being in the cloud",
          "score": 3,
          "created_utc": "2026-01-22 02:11:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0z9wj4",
          "author": "siggywithit",
          "text": "We ditched them for a better solution. Didn‚Äôt have row based pricing and much easier to work with. What are the sources and destinations you are trying to use. We evaluated a bunch.",
          "score": 3,
          "created_utc": "2026-01-22 03:00:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10x3fp",
              "author": "Jstrom40",
              "text": "What did you go with? Most of ours are SQL Server to Snowflake and we are actively looking at options now üôÇ",
              "score": 1,
              "created_utc": "2026-01-22 10:47:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o161ury",
                  "author": "SeaYouLaterAllig8tor",
                  "text": "Why not go with Snowflake open flow. Pretty sure they have a SQL server connector.",
                  "score": 1,
                  "created_utc": "2026-01-23 02:43:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1colh0",
                  "author": "siggywithit",
                  "text": "For SQL Server we ended up using SnowConvert.  For the SAP we were recommended by our SAP rep to use precog and that has worked well so far for SAP data into snowflake.",
                  "score": 1,
                  "created_utc": "2026-01-24 01:53:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o113var",
                  "author": "Nekobul",
                  "text": "Why not use SSIS ? That is the most cost-effective and high-performance option.",
                  "score": 0,
                  "created_utc": "2026-01-22 11:43:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10rnw0",
          "author": "Infinite-Camp489",
          "text": "For those looking to migrate off fivetran where are you going to?",
          "score": 3,
          "created_utc": "2026-01-22 09:58:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19h4ms",
              "author": "Bryan_In_Data_Space",
              "text": "OpenFlow for all things on-prem SQL Server which is 90% of what we are replicating. We will likely leave the other connectors on Fivetran until OpenFlow has connectors or we find another vendor that would make it easy to switch to.",
              "score": 2,
              "created_utc": "2026-01-23 16:28:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0yow5q",
          "author": "RaisinGullible9177",
          "text": "This is our last year with hightran ü§û We kicked off the migration last quarter and it‚Äôs been‚Ä¶ an experience. My company has a massive data literacy problem, so choosing an alternative was way harder than it should've been. Before hightran we had a bunch of smaller tools and consolidated thinking itt would simplify everything. It did, kind of, but the cost just doesn‚Äôt make sense anymore. It kept climbing, and even last year when we used it less, we somehow paid more than previous years. Our boss ahs had the same haunted look since the renewal quote came in üòù It‚Äôs aging him in real time.",
          "score": 2,
          "created_utc": "2026-01-22 01:01:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17fd3o",
          "author": "TiredDataDad",
          "text": "Fivetran will survive, for now. Most of their business is coming from a few big whales which are too deep into Fivetran to move away quickly.\n\nThe question is if the small clients will enjoy it this price hike (narrator: they won't) or will decide to look around at other solution.\n\nI saw this already a few times since the raise of dlt:  \n  \n1. As a small consultancy, we helped a few clients to migrate to dlt from Fivetran because the cost didn't make sense, because the connectors they wanted didn't exist, or just because they didn't like to deal with a balck box (with pricing controlled by others).\n\n2. As organizer of the Data Berlin meetup, I spoke with multiple teams which introduced dlt, initially for limited use cases, then it started to replace more consistent data loads. Once you have dlt in place it makes no sense to spend for loading if you can have it for free (or at least a minimal fraction of what you are paying).\n\nFeel free to ping me in case you want me to elaborate",
          "score": 2,
          "created_utc": "2026-01-23 08:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10oag3",
          "author": "m1nkeh",
          "text": "It‚Äôs the MO for FiveTran, they‚Äôve done it before and will do it again.. sorry this happened.",
          "score": 1,
          "created_utc": "2026-01-22 09:26:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10z1bh",
          "author": "value-no-mics",
          "text": "Why would anyone really try to select multiple connectors that are transferring rows across multiple syncs? \n\nWhat would be the necessity for that?",
          "score": 1,
          "created_utc": "2026-01-22 11:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11p9ll",
          "author": "Cool-Explorer-8510",
          "text": "That‚Äôs why a lot of teams start thinking about both flexibility and predictability before they lock into any single pipeline tool.",
          "score": 1,
          "created_utc": "2026-01-22 13:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12opek",
          "author": "Trey_Antipasto",
          "text": "This was so predictable just looking at their pricing plan from the go.   It was $1000 mo for 1mm rows at one point.  Not only that but you can‚Äôt dictate a schedule it‚Äôs just best effort and they frequently shift timing on you.   You can‚Äôt even run a sql query.  Yet people jumped on the hype.",
          "score": 1,
          "created_utc": "2026-01-22 16:46:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o146osb",
          "author": "New_Juice_7577",
          "text": "If you even pay attention to the bill, you never should have chosen Fivetran.",
          "score": 1,
          "created_utc": "2026-01-22 20:50:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14s1lr",
          "author": "quickdraw6906",
          "text": "We were a $100k/yr HVR customer. Then Fivetran bought HVR. We're in the middle of a 140+ connector migration to Debezium + Kafka (Redpanda) + EKS + Strimzi. Not fun. Massive headache. We have oodles of DB2, which is a half baked community connector. Still, it made sense to save bundles to not have MAR pricing.",
          "score": 1,
          "created_utc": "2026-01-22 22:35:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14yddc",
          "author": "Ok_Exchange1148",
          "text": "I‚Äôve spent a fair bit of time thinking about why these pricing changes are so irritating and feel wrong.\n\nMy top 3 are:\n1.  it feels like a broken promise / bait and switch\n2.  it‚Äôs the same product / service as it was before\n3.  ETL is a commodity.  There‚Äôs no difference in the result.  (Non functional requirements like latency and reliability are differences but I‚Äôm dwelling on the anger for a minute)\n\nIn a commoditised market the prices go down, not up.\n\nFull disclosure - I‚Äôm the founder of Matatika and we just acquired Meltano.  So I‚Äôm keen on figuring this out too!\n\nTaylor (Meltano & Arch founder), Max (Airflow & Superset founder) and yours truly will be discussing all of this Live on LinkedIn tomorrow if you‚Äôre interested in wading in on the topic with us!",
          "score": 1,
          "created_utc": "2026-01-22 23:09:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17mv53",
          "author": "eccentric2488",
          "text": "Never used these off the shelf connectors. I've always developed my own custom logic in python using standard libraries and it has worked well !!!",
          "score": 1,
          "created_utc": "2026-01-23 09:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18mde3",
          "author": "geoheil",
          "text": "Anyone explored https://dlthub.com/ ?\n\nIt might go well with https://github.com/l-mds/local-data-stack",
          "score": 1,
          "created_utc": "2026-01-23 14:01:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10sns0",
          "author": "karakanb",
          "text": "If anyone is looking for an open-source alternative, I have built ingestr: [https://github.com/bruin-data/ingestr](https://github.com/bruin-data/ingestr)\n\nIt is a CLI tool that allows you to ingest data from many different sources into different destinations. We are happy to build custom connectors within a week if there's anything missing.\n\nDisclaimer: I am the co-founder of a competitor, [Bruin](https://getbruin.com). We do ingestion, transformation, quality, and governance.",
          "score": -2,
          "created_utc": "2026-01-22 10:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o125ibf",
          "author": "ETL-architect",
          "text": "I work at Weld (a Fivetran competitor), and these pricing changes....so many, so fast... are just outrageous. That‚Äôs why we‚Äôve migrated so many teams from them over the last year, handling migrations for free for customers including schemas, historical syncs, and validation. We price it at around $99 per 10M MAR. \n\nDefinitely good to try for small or medium size companies. I can understand the bigger companies wanting to stay with them as it's crazy hard to make that switch after such a long time.",
          "score": -1,
          "created_utc": "2026-01-22 15:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19ko5j",
          "author": "Yuki100Percent",
          "text": "Start looking into other tools like airbyte, Estuary, dlt, etc.",
          "score": 0,
          "created_utc": "2026-01-23 16:43:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfa0ii",
      "title": "Amazon Data Engineer I",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/hnfi6k0a1wdg1.jpeg",
      "author": "Shankster1820",
      "created_utc": "2026-01-17 10:37:05",
      "score": 93,
      "num_comments": 23,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qfa0ii/amazon_data_engineer_i/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o04zoek",
          "author": "makesufeelgood",
          "text": "Why would you transfer internally and go down a level?  You're already at the company so you have the advantage of either a) being in possession of specific domain knowledge that only someone at Amazon would know, or b) being equipped with resources to help you learn it much easier than an external candidate ever could.  You also understand the culture and what sort of skills are valued there better than an external candidate could.  So focus on your transferable experience and do whatever you can to learn technical skills you feel you have gaps for.\n\nIf you don't have any technical skills at all from the job post above then I would recommend looking for a way to network with a team doing work you're interested in and seeing if you can convince your manager to let you collaborate with them on a stretch project.  That is how I have successfully career transitioned twice now in the last 6-7 years.",
          "score": 25,
          "created_utc": "2026-01-17 17:28:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066nue",
              "author": "Shankster1820",
              "text": "I would transfer down because I‚Äôm a L5 in the safety field, so I don‚Äôt have the experience to be an L5 on the tech side",
              "score": 3,
              "created_utc": "2026-01-17 20:55:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o05h1dk",
          "author": "Carbonemys_cofrinii",
          "text": "Sometimes there are roles that doesn't have DE in the title but have really close functions. There are such roles in major banks. You'll work with Spark + Hadoop/Greenplum, create dashboards and etc.",
          "score": 13,
          "created_utc": "2026-01-17 18:49:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o068x7y",
              "author": "Shankster1820",
              "text": "What title roles would I look for? There‚Äôs so many different role titles with different descriptions out there it‚Äôs hard for me to decipher what I should be looking for",
              "score": 5,
              "created_utc": "2026-01-17 21:07:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o077uu1",
                  "author": "dtr96",
                  "text": "analytics engineer, data modeler, quantitative analyst - developer - engineer, data platform engineer, business intelligence analyst - engineer - developer, sometimes cloud engineer but the duties are related to data solely on cloud",
                  "score": 8,
                  "created_utc": "2026-01-18 00:05:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08rfur",
                  "author": "Carbonemys_cofrinii",
                  "text": "Im outside of USA, when i looked for job i parsed job descriptions and choose ones with Hadoop/Greenplum/Spark. Sadly in banking they often require decree in economic/CS/Math",
                  "score": 2,
                  "created_utc": "2026-01-18 05:23:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08z55h",
          "author": "LelouchYagami_",
          "text": "I transferred from a support role to a DE role. Usually it's the manager's call if they want to give opportunity to someone outside the job family.  \n\nMy manager has considered many such candidates. But it has always been a tech to tech conversion. Never seen a non-tech to tech conversion for DE.\n\nAs for down leveling, managers are generally against the idea because if someone with more experience is at a lower level, they are more ambitious for promotion and might not stay in the team for long.",
          "score": 4,
          "created_utc": "2026-01-18 06:23:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o095lgh",
              "author": "Shankster1820",
              "text": "What role did you transfer from? Did you have also the basic quals met already? \n\nI mean I wouldn‚Äôt say I have more experience at a lower level or anything. Me being in L5 in safety has nothing to do with transferring to tech, it‚Äôs essentially starting over for me. So I wouldn‚Äôt even consider it a down level tbh cause it‚Äôs a completely different world",
              "score": 1,
              "created_utc": "2026-01-18 07:19:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0974lk",
                  "author": "LelouchYagami_",
                  "text": "I transferred from support engineer job family which is like the lowest tier in tech job families. But still it was tech to tech movement.\n\nI had certain qualifications met, not all. I just understood programming languages in general and SQL. Had experience with AWS services.\n\nI guess your case is different now that you mention it \n\nBut whenever I have seen non-tech to DE progression, it's always been through a slightly less tech heavy role.\n\nSomething like Non-tech -> BA -> BIE -> DE or Non-tech -> BIE -> DE\n\nWhen you are gonna be applying, give a shot to BIE roles as well. They have decent overlap with the DE role and the pay is around 15-20% less than DE. Lot of BIEs then move to DE by slowly taking up more technical implementations. \n\nWhole thing with Data Engineering is to get your foot in the door. The entry level positions are less with requirements that are not easily met at entry level tbh",
                  "score": 2,
                  "created_utc": "2026-01-18 07:32:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05296d",
          "author": "chrisgarzon19",
          "text": "Ur an L5 DA? Or de?",
          "score": 3,
          "created_utc": "2026-01-17 17:41:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o059ql3",
              "author": "Shankster1820",
              "text": "I‚Äôm an L5 safety manager, I‚Äôm on the warehousing side lol",
              "score": 4,
              "created_utc": "2026-01-17 18:15:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05a50h",
                  "author": "chrisgarzon19",
                  "text": "If u make more $$ \nAnd transition into a tech role \n\nThen I‚Äôd do it \n\nDo let title and leveling (I.e ego) stop you from moving forward - does it feel shitty and ducks that Amazon is doing it? Maybe.\n\nBut who cares - play the game",
                  "score": 11,
                  "created_utc": "2026-01-17 18:17:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08p2bh",
          "author": "Brave_Possibility421",
          "text": "I don‚Äôt see any harm in moving from L5 to L4 when you‚Äôre completely from a non tech background. Even if you apply for other companies, you would have to start with an entry level role, so why not start the same at Amazon and that would give you an edge because of the company tag and the pay would be comparable (or maybe more) as compared to non tech roles. Have you already prepared for the DE interviews? If yes, then could you please suggest some good resources. What is your YOE in total?",
          "score": 3,
          "created_utc": "2026-01-18 05:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08pnae",
              "author": "Shankster1820",
              "text": "I just wasn‚Äôt sure if it was even possible to down level, I‚Äôm fine it if it‚Äôs allowed! I have not started prepping, I‚Äôm still a ways out from getting to that point. I‚Äôm still working to finish my degree",
              "score": 1,
              "created_utc": "2026-01-18 05:10:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o08pyhk",
                  "author": "Brave_Possibility421",
                  "text": "I‚Äôm not sure if it‚Äôs allowed, but you would definitely need some projects to justify your move and getting considered for the role.",
                  "score": 1,
                  "created_utc": "2026-01-18 05:12:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0a891w",
          "author": "eccentric2488",
          "text": "As usual, it looks like a catalogue of tools/frameworks/platforms !!!!",
          "score": 1,
          "created_utc": "2026-01-18 13:01:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjv1ja",
      "title": "Any European Alternatives to Databricks/Snowflake??",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qjv1ja/any_european_alternatives_to_databrickssnowflake/",
      "author": "Donkey_Healthy",
      "created_utc": "2026-01-22 13:50:42",
      "score": 84,
      "num_comments": 72,
      "upvote_ratio": 0.89,
      "text": "Curious to see what's out there from Europe?\n\nEdit: options are open source route or exasol/dremio which are not in the same league as Databricks/Snowflake.",
      "is_original_content": false,
      "link_flair_text": "Blog",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qjv1ja/any_european_alternatives_to_databrickssnowflake/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o11v90k",
          "author": "lozinge",
          "text": "DuckDB or Spark is all I can think of",
          "score": 53,
          "created_utc": "2026-01-22 14:28:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12cg4z",
              "author": "Efficient_Shoe_6646",
              "text": "Spark is not European. DuckDB is and if you're into Russian tech check out ClickHouse.",
              "score": 28,
              "created_utc": "2026-01-22 15:51:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o12j39k",
                  "author": "Creative-Skin9554",
                  "text": "ClickHouse is owned by ClickHouse Inc which is a Dutch company",
                  "score": 18,
                  "created_utc": "2026-01-22 16:21:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o12hpc7",
                  "author": "dangerbird2",
                  "text": "Clickhouse started at Yandex but it was spun into a San Fransisco-based company when it was made open-source",
                  "score": 15,
                  "created_utc": "2026-01-22 16:15:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o140c37",
              "author": "soundboyselecta",
              "text": "I think OP means cloud offerings not that I disagree with you in this age of over-engineering.",
              "score": 3,
              "created_utc": "2026-01-22 20:20:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1795ap",
              "author": "nerevisigoth",
              "text": "Spark was developed at UC Berkeley.",
              "score": 1,
              "created_utc": "2026-01-23 07:42:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1821ne",
                  "author": "lozinge",
                  "text": "Yeah but its open source was my thinking; I don't think the provenance of OSS matters so much if you can run/fork it locally",
                  "score": 2,
                  "created_utc": "2026-01-23 11:57:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11qs08",
          "author": "Tough-Leader-6040",
          "text": "Yes, SAP Analytics Cloud",
          "score": 77,
          "created_utc": "2026-01-22 14:05:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11v5v3",
              "author": "lozinge",
              "text": "üíÄ",
              "score": 174,
              "created_utc": "2026-01-22 14:27:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1262gz",
                  "author": "Ready-Marionberry-90",
                  "text": "I feel you, brother.",
                  "score": 22,
                  "created_utc": "2026-01-22 15:21:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o13efhh",
              "author": "Ekkaia153",
              "text": "Thank you, but I'd rather go back to pen and paper.",
              "score": 22,
              "created_utc": "2026-01-22 18:41:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o12u331",
              "author": "Firm-Yogurtcloset528",
              "text": "Ah well..",
              "score": 1,
              "created_utc": "2026-01-22 17:10:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o120cwd",
              "author": "Amilol",
              "text": "Can you please explain what you mean?",
              "score": 1,
              "created_utc": "2026-01-22 14:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o13l79a",
                  "author": "brunogadaleta",
                  "text": "Designed in the 70's. Still works with cryptic table name codes like \"FD04\". Despite having a relatively nice webapp, the heavy client is bloated and \"required for some important features missing in the web version\".\n\nCustomization, maintenance aren't cheap, must be handled by specialized costly consultants. I heard hardware requirements are high. \n\nIt can probably do anything you'll ever dreamed of with some degree of customization and or appropriate licenses (caution license hell, to be expected).\n\nActually the main reason it still exists:  \n1) it pays consultant well enough so that you will always find someone crazy enough to work on any project.  \n2) it exists for so long that it will probably still exist in 30 years.\n\nSo business cases are very narrow, even if some client don't realize they could have much better for less.\n\nSo OP, duckdb or Clickhouse.",
                  "score": 15,
                  "created_utc": "2026-01-22 19:11:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o137dbf",
                  "author": "dangerbird2",
                  "text": "It‚Äôs a enterprise business intelligence platform sold by the German company SAP. It‚Äôs a crusty proprietary platform you‚Äôd more likely see at a bank or defense contractor rather than a state of the art startup",
                  "score": 5,
                  "created_utc": "2026-01-22 18:10:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12r07z",
          "author": "beyphy",
          "text": "Polars has their heardquarters in Amsterdam.",
          "score": 16,
          "created_utc": "2026-01-22 16:56:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o156c4g",
              "author": "skatastic57",
              "text": "Although, polars cloud, for the time being, is hosted on aws",
              "score": 9,
              "created_utc": "2026-01-22 23:51:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o16xydu",
                  "author": "ritchie46",
                  "text": "We are rolling out on premises.",
                  "score": 4,
                  "created_utc": "2026-01-23 06:08:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11x1oh",
          "author": "andrejlr",
          "text": "While not a complete out of the box solution and might defer in feature parity.  \nScaleaway offers a clickhouse datawarehouse. That will lack sql workflows though.  \nI am not familiar with Snowflake, but most likly it has dbt similar worfkflows with data validation   \nand testing.  \nYou can define constraints on your producition tables though.  \nBut for testing you buisiness logic, you would need to move that into app layer. \n\nThere is also data lab spark cluster in case sql hits limits. But again here, testing would be part of app layer.  \nThere is not such an standardized way to test data processing workflows in spark I so far i came only across few projects which have set it up at all.\n\n[https://www.scaleway.com/en/data-warehouse-for-clickhouser/](https://www.scaleway.com/en/data-warehouse-for-clickhouser/)  \n[https://www.scaleway.com/en/docs/data-lab/quickstart/](https://www.scaleway.com/en/docs/data-lab/quickstart/)",
          "score": 6,
          "created_utc": "2026-01-22 14:37:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12t9cj",
          "author": "nobbert",
          "text": "Not strictly speaking a one to one alternative, as it is something you need to host and operate yourself, but you can build something kinda similar with open source tools like Trino, Airflow, Spark etc.\n\n  \nAs for the commercial portion of it, Stackable wraps those tools into a plattform that makes it \"easy\" to deploy (sadly, it remains complex software!) - and provides support and other enterprise features around it.\n\nfull disclosure: I work at Stackable :)",
          "score": 4,
          "created_utc": "2026-01-22 17:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11unse",
          "author": "loudandclear11",
          "text": "Apache Spark is open source and free. \n\nRoll your own compute with Spark on managed kubernetes/docker.",
          "score": 31,
          "created_utc": "2026-01-22 14:25:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11vmbz",
              "author": "StereoZombie",
              "text": "\"Just build your own platform\" is not an answer to the question",
              "score": 73,
              "created_utc": "2026-01-22 14:30:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o144tuf",
                  "author": "tecedu",
                  "text": "Why not? They are asking solution for a managed platform, spark on managed kubernetes is pretty good, its the storage which is problamatic",
                  "score": 8,
                  "created_utc": "2026-01-22 20:41:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o12085n",
              "author": "zjaffee",
              "text": ">Apache Spark is open source and free\n\nThis is only really true on paper. EMR, dataproc, hell azure basically just outsourced to databricks which does its own thing, don't run really anything close to open source apache spark and are all several multiple times faster for average queries and orders of magnitude faster for specific use cases.\n\nThe cost of rolling something competitive on your own is really just not remotely worth the extra cost you pay for any of the above services.",
              "score": 13,
              "created_utc": "2026-01-22 14:53:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o12srbm",
                  "author": "nobbert",
                  "text": "Not saying you are wrong here, but I'd be curious to see some numbers on the claim that databricks [et.al](http://et.al) are between multiple times and orders of magnitude faster than open source Spark. Do you have some links here?\n\n  \nAlso, while I have to agree that \"rolling your own\" is certainly not for everybody, it does take extra work and  thought, it is not just the extra cost for cloud services you need to consider. Things like lock-in effect, loss of control over your own data, a total inability to pretty much investigate anything when an outage occurs are just some topics one might mention here. Are these things important enough to warrant the extra effort of not just taking an off the shelf cloud solution? No idea - everybody needs to answer that for themselves, but I personally have been bitten by shitty SaaS vendors often enough, that I'll at least think about hosting something on my own every time.",
                  "score": 9,
                  "created_utc": "2026-01-22 17:04:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o122elm",
              "author": "StolenRocket",
              "text": "Buddy, have you seen the price of RAM lately?!",
              "score": 5,
              "created_utc": "2026-01-22 15:03:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1799w8",
                  "author": "loudandclear11",
                  "text": "If you need RAM you're going to pay for it one way or another anyway. The big cloud vendors aren't giving you free RAM.",
                  "score": 1,
                  "created_utc": "2026-01-23 07:43:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o124h80",
          "author": "Pittypuppyparty",
          "text": "Exasol is what you are looking for.",
          "score": 14,
          "created_utc": "2026-01-22 15:13:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12utal",
          "author": "GeneralFlight2313",
          "text": "Ovh cloud dataplatform",
          "score": 4,
          "created_utc": "2026-01-22 17:13:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12cwp9",
          "author": "Leorisar",
          "text": "Self-host or cloud Clickhouse",
          "score": 7,
          "created_utc": "2026-01-22 15:53:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14mkeu",
              "author": "geneticswag",
              "text": "100% this",
              "score": 1,
              "created_utc": "2026-01-22 22:06:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o12rihs",
          "author": "Unfair-Sleep-3022",
          "text": "Apache doris is chinese \\^\\^",
          "score": 3,
          "created_utc": "2026-01-22 16:58:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12sv66",
          "author": "InteractionHorror407",
          "text": "OSS only would be my choice. Spark + Kubernetes + duckDB + Linux is my ‚Äúdoomsday‚Äù stack if a full US decoupling were to happen. \n\nOpen source doesn‚Äôt belong to a specific country, that‚Äôs part of what makes it open source.",
          "score": 6,
          "created_utc": "2026-01-22 17:05:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o142ejx",
              "author": "soundboyselecta",
              "text": "Exactly üòÇ",
              "score": 1,
              "created_utc": "2026-01-22 20:30:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o167w1j",
          "author": "Gators1992",
          "text": "I think Mother duck is European.¬† Not as full featured as Snowflake but if you just need a cloud db it seemed pretty good when I tried it in beta.¬† I love the Snowflake platform, but tbh don't need most of what they offer.¬†¬†",
          "score": 2,
          "created_utc": "2026-01-23 03:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o175cyh",
          "author": "BusOk1791",
          "text": "I am interested in something like that too, at the moment we are on GC with a BigQuery stack (using custom made python pipelines to ingest data into BQ or GCS (parquet / delta lake) and dataform for transformations.  \nBut if in the future things go sideways, i do not know exactly what to switch to, and no, setting up all the infrastructure is not an option, not for us, and not for most of the people.  \nWhat people do not get, is that it is not only a matter of setting up Duckdb, Clickhouse.. whatever, but also all the ecosystem around it, like centralized logging and alerting, serverless functions, managed databases for reverse-elt, granular user rights management via iam and so on.  \nMaybe OVH Data or Scaleway as someone mentioned below..",
          "score": 2,
          "created_utc": "2026-01-23 07:08:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o177f6v",
          "author": "_N0T0K_",
          "text": "These are the questions and answers that'll make big impacts",
          "score": 2,
          "created_utc": "2026-01-23 07:26:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18dlxj",
          "author": "Solid_Carpenter_4783",
          "text": "Exasol obviously",
          "score": 1,
          "created_utc": "2026-01-23 13:13:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c9rvh",
          "author": "anyfactor",
          "text": "Clickhouse was originally developed by Yandex (the Russian search engine company). Clickhouse the company has some American funding but you can always self host Clickhouse. \n\nI have thought about an self hostable data engineering stack before. \n\nEssentially get a bare metal server from a local hosting company in your city. It almost never will be crazy expensive.  Set up rsync or some sort of backup service for scaling scaling.\n\nUse bash for most things. Avoid buying into tools and services. Just use bash, python, go and take advantage of linux as an environment. Use as little things as possible and document everything.\n\nBut the truth is that DE has become a \"product/tool\" centric profession. If you are solo building something the idea of self hostable and self built tools makes sense. But you will struggle to find entry/mid level talent to support your growth and ecosystem.",
          "score": 1,
          "created_utc": "2026-01-24 00:29:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11wupb",
          "author": "Raddzad",
          "text": "Don't know any but it would be really good to have one",
          "score": 1,
          "created_utc": "2026-01-22 14:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o187fr5",
              "author": "NoleMercy05",
              "text": "It's not like they don't try.",
              "score": 1,
              "created_utc": "2026-01-23 12:35:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o13acxa",
          "author": "Dry-Message8118",
          "text": "Business data cloud. Gets close to the lakehouse concept and supports data mesh. You can even run it with Databricks and zero delta sharing. \n\nBut keep in mind you not only have to solve compute but also storage. So also finds alternative for azure and aws. In Germany it would be stack it. Don‚Äôt know their services tough",
          "score": 1,
          "created_utc": "2026-01-22 18:23:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13bwvn",
          "author": "5hruj4n",
          "text": "I am just going through all these comments and wondering how do you guys know so much, and that in detail. How do you guys keep yourself updated all the time and remember so much of information?",
          "score": 1,
          "created_utc": "2026-01-22 18:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14af43",
              "author": "Pittypuppyparty",
              "text": "A lot of the people in here are vendors.",
              "score": 2,
              "created_utc": "2026-01-22 21:07:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o12r9qt",
          "author": "eMperror_",
          "text": "I use Starrocks with DBT",
          "score": 0,
          "created_utc": "2026-01-22 16:57:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o138xu4",
              "author": "Creative-Skin9554",
              "text": "StarRocks is Chinese though",
              "score": 3,
              "created_utc": "2026-01-22 18:17:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1397ri",
                  "author": "eMperror_",
                  "text": "I selected it because it's part of the Linux Foundation, why do people dislike it? (serious)\n\n  \nI just checked and CelerData seems to be based in California. Not that it's any better than the chinese though.",
                  "score": 1,
                  "created_utc": "2026-01-22 18:18:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o126yam",
          "author": "Efficient_Novel1769",
          "text": "We use Dremio Cloud now - all in the EU; alternative is to use their Software.",
          "score": -1,
          "created_utc": "2026-01-22 15:25:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12do9s",
              "author": "alfakoi",
              "text": "Was on dremio briefly, it was a terrible product.",
              "score": 10,
              "created_utc": "2026-01-22 15:56:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o13ul4x",
                  "author": "pantshee",
                  "text": "Entreprise architect trying to make us switch from databricks to dremio. Hell no bro",
                  "score": 5,
                  "created_utc": "2026-01-22 19:53:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12oi05",
          "author": "Turbulent_Egg_6292",
          "text": "Clickhouse is european, obsessionDB and tinybird too",
          "score": 0,
          "created_utc": "2026-01-22 16:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12r5z0",
          "author": "empireofadhd",
          "text": "You can run spark jobs on ovh cloud which is french. Spark is open source so ok.",
          "score": 0,
          "created_utc": "2026-01-22 16:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13h974",
          "author": "vainamoinen_",
          "text": "If what you‚Äôre looking for a lakehouse platform but EU-first that‚Äôs exactly what we‚Äôre building with Hyperfluid Cloud. \n\nOur main service is a Lakehouse based on trino.\n\nAnd we will be happy to help, feel free to reach us anytime.\n\nSite: https://www.hyperfluid.cloud/\nContact: contact@nudibranches.tech",
          "score": 0,
          "created_utc": "2026-01-22 18:53:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17l9f4",
          "author": "Far_Mathematici",
          "text": "Flink.\nMain dev office In Berlin but the owner is Alibaba",
          "score": 0,
          "created_utc": "2026-01-23 09:33:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14336m",
          "author": "Tiny_Falcon_4310",
          "text": "Made some good experiences with Exasol DB. Spode is phenomenal and the support is hands-on and not just ticket ping pong. Based in Germany and exists for 20 years already",
          "score": -1,
          "created_utc": "2026-01-22 20:33:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11tyvt",
          "author": "Nekobul",
          "text": "Amazon just announced \"European Sovereign Cloud\" .",
          "score": -9,
          "created_utc": "2026-01-22 14:21:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11qsqc",
          "author": "_Marwan02",
          "text": "Dataiku",
          "score": -10,
          "created_utc": "2026-01-22 14:05:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11t2in",
              "author": "Aibbie",
              "text": "I would argue Dataiku is not a great replacement. It‚Äôs not good for code-first infra/systems, very clunky for data engineering.",
              "score": 5,
              "created_utc": "2026-01-22 14:16:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o11vean",
              "author": "Tough-Leader-6040",
              "text": "Dataiku is a transformation tool, not a data warehouse or data lake",
              "score": 3,
              "created_utc": "2026-01-22 14:28:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o11vqvd",
              "author": "StereoZombie",
              "text": "It's been a few years since I worked with it but it sucked back then.",
              "score": 2,
              "created_utc": "2026-01-22 14:30:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o12qsi6",
              "author": "laegoiste",
              "text": "Absolutely not. Avoid at all costs, and it's not an answer to the question either.",
              "score": 2,
              "created_utc": "2026-01-22 16:55:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qisbbq",
      "title": "How did you land your first Data Engineer role when they all require 2-3 years of experience?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qisbbq/how_did_you_land_your_first_data_engineer_role/",
      "author": "Such-Revolution-9975",
      "created_utc": "2026-01-21 08:18:16",
      "score": 65,
      "num_comments": 79,
      "upvote_ratio": 0.89,
      "text": "For those who made it - did you just apply anyway? Do internships or certs actually help? Where did you even find jobs that would hire you?\n\nAppreciate any tips.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qisbbq/how_did_you_land_your_first_data_engineer_role/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0tlnjq",
          "author": "thisfunnieguy",
          "text": "ppl are way too hung up on certifications.\n\nno one cares\n\ni have interviewed way too many ppl with an AWS cert who cant have a conversation about AWS resources.",
          "score": 95,
          "created_utc": "2026-01-21 08:22:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqlu7",
              "author": "According_Layer6874",
              "text": "What does a conversation about AWS resources entail?\n\n\"This is what I use s3 buckets for, this is what is hosted in my lambda\" etc?",
              "score": 18,
              "created_utc": "2026-01-21 09:09:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0u15uw",
                  "author": "thisfunnieguy",
                  "text": "in a system design interview.\n\ni ask you to sketch out a data pipeline based on a prompt.\n\nat some point you say \"and then we push the data into AWS\" \n\nand i say, \"cool we use AWS here, can you tell me more about what resources in AWS you want to use\"\n\nand maybe you say \"s3\"\n\nand i say, \"that sounds nice. suppose you've got an intern shadowing you for this, what kind of advice do you want to give them about using S3 in this situation\"\n\nor\n\n\"great, assume the bucket doesnt exist yet, how should we create it\"\n\nor\n\n\"got it, our finance team has been pressing us to make smart cost choices. Whats something we can do with s3 as part of a cost saving strategy\"\n\nor\n\n\"ok, we do knowledge sharing sessions on the team. Suppose you were presenting and someone wanted know why you picked S3 vs any other AWS resource, how would you explain that choice?\"\n\n  \n\\----\n\n  \nI'm looking for opinions (with support) and experience. If all you know is what you read on a blog about s3 thats different than someone who has dealt with this nonsense for years. \n\nI'm not saying i wont hire you, but i will suggest we pay the other person more.",
                  "score": 29,
                  "created_utc": "2026-01-21 10:48:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0ts37n",
                  "author": "Altruistic_Stage3893",
                  "text": "I'd imagine is more testing whether you inderstand the onion-like structure of the network and how the shit comes down from gateway to lambda and queues for example",
                  "score": 9,
                  "created_utc": "2026-01-21 09:24:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0xqa68",
                  "author": "PromptAndHope",
                  "text": "for example :what is a difference between s3:// and s3a:// connector. What happen if you use s3 with Spark?",
                  "score": 1,
                  "created_utc": "2026-01-21 22:00:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ufs1l",
          "author": "GennadiosX",
          "text": "I heard that usually DE chooses you, not the other way around. I started as a backend dev but my job focus slowly shifted to data engineering. While formally I'm still a backend SWE, in reality my job is 75% DE.",
          "score": 35,
          "created_utc": "2026-01-21 12:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wfx6f",
              "author": "Nck865",
              "text": "Wow that's interesting as I was thrown into the role. It literally chose me lol.",
              "score": 11,
              "created_utc": "2026-01-21 18:31:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0x2fb4",
              "author": "CometChaserStarGazer",
              "text": "I totally agree! I just randomly fell into DE",
              "score": 8,
              "created_utc": "2026-01-21 20:12:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0z18do",
              "author": "echanuda",
              "text": "Happened to me as well, LITERALLY. I applied to a local company for a software QA position (no degree but I‚Äôve been a lifelong programmer). I FINALLY got an interview after hundreds of applications. The interview went great, but I clearly didn‚Äôt have QA experience and was rejected. I got a call from them a month later and they offered me a DE role, despite me never touching any data library or even knowing what a dataframe was. Ended up loving it and got an offer somewhere else after a year :)",
              "score": 6,
              "created_utc": "2026-01-22 02:11:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0z5q4u",
              "author": "BitterFrostbite",
              "text": "Exactly the same for me",
              "score": 3,
              "created_utc": "2026-01-22 02:37:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0z9o5y",
              "author": "dark_dagger99",
              "text": "I was thrown into the role as well. I started in finance and then did a lot of DE work to improve our reporting and analytics and then grew to manager level",
              "score": 3,
              "created_utc": "2026-01-22 02:59:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o10rt0d",
              "author": "According_Layer6874",
              "text": "I'm a graduate data analyst and I just shipped my first end to end fully automated integration using AWS / Snowflake / Terraform and now becoming the product owner of our low code automation software",
              "score": 2,
              "created_utc": "2026-01-22 09:59:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0wmi7z",
              "author": "armoman92",
              "text": "what do you use as part of your stack? Java?",
              "score": 1,
              "created_utc": "2026-01-21 19:00:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0xz5fd",
                  "author": "GennadiosX",
                  "text": "C#",
                  "score": 4,
                  "created_utc": "2026-01-21 22:43:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0tlmp1",
          "author": "SchemeSimilar4074",
          "text": "There are hybrid roles where you do both DA and DE work, for example, consulting. I went for a consulting role where I was hired for my DA skill but got put on many DE projects. Afterwards, I simply change my title to DE.¬†\n\n\nThis is probably easier in a mid-size city. In large cities, companies have dedicated analytics team so jobs are more specialised. In smaller cities (I'm in Brisbane in Australia for example), most data jobs are hybrid because companies have 1 data team who do everything. I was put on consulting projects where I do end to end whereas my friends who are in the same consulting firm but in Sydney, still do DA projects for very large firms and banks.¬†",
          "score": 23,
          "created_utc": "2026-01-21 08:21:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tm71e",
          "author": "randomName77777777",
          "text": "Started as a data analyst until an engineering position was open 3 years later. Was internal so the DE manager knew me and it worked out.",
          "score": 21,
          "created_utc": "2026-01-21 08:27:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15ud0f",
              "author": "molodyets",
              "text": "This is the path for most",
              "score": 1,
              "created_utc": "2026-01-23 02:02:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tmm1y",
          "author": "Schtick_",
          "text": "many people (myself included) view roles like DE as a specialisation. ie you have a good foundation in engineering and now you‚Äôre specialising in data. Universities try to short cut that engineering requirement by having a dedicated ‚Äûdomain XYZ‚Äù degree. Which is great but I don‚Äôt need a data engineer who doesn‚Äôt at least have a foundational knowledge and foundational experience in software engineering.",
          "score": 16,
          "created_utc": "2026-01-21 08:31:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tlzeq",
          "author": "Rus_s13",
          "text": "Got an internship, got lucky. Rare but it‚Äôs out there so don‚Äôt give up",
          "score": 10,
          "created_utc": "2026-01-21 08:25:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ux5zg",
          "author": "paxmlank",
          "text": "Worked as an analyst and did engineering stuff. Put that on my resume",
          "score": 7,
          "created_utc": "2026-01-21 14:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uewgj",
          "author": "Prior_Two_2818",
          "text": "it was 20 years ago. if you could read the oracle documentation and write pl/sql procedures and packages you where hired. no one cares for certifications. they are so consultants can make their hourly rates more expansive without knowing much more than before the did take the exam",
          "score": 4,
          "created_utc": "2026-01-21 12:35:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uvpjx",
          "author": "Alternative-Guava392",
          "text": "Started as an intern analytics engineer at a startup with 0 experience before. Continued full time in the team, moved on to more data platforms and architecture stuff.",
          "score": 4,
          "created_utc": "2026-01-21 14:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ts67d",
          "author": "Altruistic_Stage3893",
          "text": "I've started as data analyst, naturally moved into engineering like a year later cuz i put in the work. BI has this benefit",
          "score": 3,
          "created_utc": "2026-01-21 09:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xgi7q",
          "author": "ntdoyfanboy",
          "text": "By shoehorning in from Analytics Engineering or Software Developer.\n\nAssuming you'll be hired outright as DE without some experience is like asking to be made a Director or Senior VP in banking without any prior experience. Data Engineer is not a new-graduate position really",
          "score": 3,
          "created_utc": "2026-01-21 21:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zdfky",
              "author": "Icy_Clench",
              "text": "I don‚Äôt think it‚Äôs fundamentally different from software engineer which has entry-level roles.",
              "score": 4,
              "created_utc": "2026-01-22 03:21:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tmbf4",
          "author": "Pandapoopums",
          "text": "My path was basically Phone Tech Support (1 yr) > Web Developer (5 yrs) > Data Analyst/Reporting/DB Analyst (5 yrs) >  Data Engineer (7 yrs) most of my transitions were lateral moves at the same company/volunteering for projects that involved data engineering components. Never had a cert, so can't tell you whether they actually help or not, but I know when I hire, I don't care about certs, I care about how well you can solve the problems and talk about what you've done before intelligently. That's not to say they don't matter, there's HR screening that typically happens before a resume ever makes it to my inbox, and maybe it matters to that level of screen, but I personally don't care about them. If you're not getting interviews, take any job you can get to build \\*some\\* experience and use data to solve problems regardless of what the job is.",
          "score": 2,
          "created_utc": "2026-01-21 08:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uaz5z",
          "author": "robberviet",
          "text": "By intern from 2nd year in college.",
          "score": 2,
          "created_utc": "2026-01-21 12:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0upvgo",
          "author": "tinycockatoo",
          "text": "Had an internship in a research-like role and had personal projects. Got hired as a junior DE, which admittedly is not that common. I think what made they hire me was that I was able to talk about my projects from end to end, from data modeling to cloud deployment and dashboard integration",
          "score": 2,
          "created_utc": "2026-01-21 13:41:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0z2bye",
              "author": "echanuda",
              "text": "Same here. Honestly was surprised how much I remembered about it too since it was years ago, but I literally had a coherent answer to every question they asked.",
              "score": 1,
              "created_utc": "2026-01-22 02:18:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uq7nq",
          "author": "typodewww",
          "text": "I landed my role 2 months ago, graduated in May I did API integration projects and real time dashboards, I had two unpaid data analyst internships via capstone classes in college where I did mini ML pipelines and integrated an API data with a static data set",
          "score": 2,
          "created_utc": "2026-01-21 13:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ur50c",
              "author": "typodewww",
              "text": "Btw I didn‚Äôt even ‚Äúapply‚Äù to my role I applied as a market researcher got to third round VP saw my resume took a look at it cancelled my interview and encouraged me to apply to DE role been history ever since that‚Äôs why you diversify your skillset especially entry level",
              "score": 1,
              "created_utc": "2026-01-21 13:48:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uy9rj",
          "author": "midasweb",
          "text": "I did not really meet the requirements either. built a couple solid projects did some sql python work at my previous job and applied anyway. one company cared more about what i could do than the years.",
          "score": 2,
          "created_utc": "2026-01-21 14:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vctp0",
          "author": "The-CAPtainn",
          "text": "I got lucky, I got a contract role that was willing to have me shadow a data team, and then it transitioned to full time. I didn‚Äôt even know I was a data engineer at first because my role was called app development analyst, but then I realized a few months in that I was only doing data pipelines and spark and sql",
          "score": 2,
          "created_utc": "2026-01-21 15:37:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tvyww",
          "author": "pymlt",
          "text": "no certs, university -> data scientist -> analytics engineer -> data engineer\n\nbasicly easing into more technical roles - but that was a few years ago , market has changed since then",
          "score": 3,
          "created_utc": "2026-01-21 10:01:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ultep",
          "author": "dataflow_mapper",
          "text": "i mostly applied anyway and treated the requirements as wish lists. What helped more than certs was already doing DE type work under another title, like owning pipelines, fixing data quality issues, or modeling tables instead of just querying them. Being able to talk concretely about those problems mattered a lot in interviews. Smaller teams were way more flexible than big companies with rigid job ladders. It felt less like finding a perfect entry role and more like gradually stretching my scope until the title caught up.",
          "score": 1,
          "created_utc": "2026-01-21 13:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v2qm9",
          "author": "Fancy_Arugula5173",
          "text": "Accounting and finance at University -> graduate accounting role -> qualified accountant working as financial analyst -> systems accountant specialising in ERP and complicated excel models -> data engineer",
          "score": 1,
          "created_utc": "2026-01-21 14:49:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vd7vg",
              "author": "Only_Payment9976",
              "text": "Woah",
              "score": 1,
              "created_utc": "2026-01-21 15:39:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ve42o",
          "author": "nineteen_eightyfour",
          "text": "Made 32,000 for 6 months for experience",
          "score": 1,
          "created_utc": "2026-01-21 15:43:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vej12",
          "author": "Queen_Banana",
          "text": "Moved internally. I had about 7 years experience working in data as an analyst, 4 at that company. I worked really closely with the engineers and learned from them when I could. Then when a position opened up I applied and got it.",
          "score": 1,
          "created_utc": "2026-01-21 15:44:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vm1bw",
          "author": "priviakeys",
          "text": "I'm just now looking into changing career paths so this thread is really helpful! Just looking at the courses I have to take and hopefully by the end of it, land an entry level analyst job and move from there",
          "score": 1,
          "created_utc": "2026-01-21 16:18:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11k6zv",
              "author": "Snoo-14088",
              "text": "We should keep in touch working entry data jobs too",
              "score": 1,
              "created_utc": "2026-01-22 13:29:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w0fw5",
          "author": "Parking_Anteater943",
          "text": "I got an internship and worked my ass off doing 60 hour weeks and not clocking hours to make them want to hire me straight from school",
          "score": 1,
          "created_utc": "2026-01-21 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w59c0",
          "author": "num2005",
          "text": "you apply anyway, realize they dont have a candidate with 2 to 3y expetience whonapplied, get the job",
          "score": 1,
          "created_utc": "2026-01-21 17:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wclrs",
          "author": "Egao4",
          "text": "I got pretty lucky. I got a 2026 new grad data engineering rotational program job. New grad DE jobs are rare but do exist.  But I had two previous internships, one as a data analyst and another as a data analyst/SWE. I say I got lucky bc I don‚Äôt have any data engineering projects or experience + no other company has reached back to me.",
          "score": 1,
          "created_utc": "2026-01-21 18:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wflvr",
          "author": "Nck865",
          "text": "I'm a consultant and they kinda threw me into the role as the client started this 3 year tenure debacle. I had no clue what I was doing. Fast forward a year and I'm now the tech lead on the same project. I also have a half of a clue what I am doing.\n\nOn another note I'm making $75,800 salary atm and feel super underpaid.",
          "score": 1,
          "created_utc": "2026-01-21 18:29:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wgbal",
          "author": "m1nkeh",
          "text": "Consulting. Anyone with a pulse tbh ü§ó",
          "score": 1,
          "created_utc": "2026-01-21 18:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wzuf8",
          "author": "CorpusculantCortex",
          "text": "Convinced my boss to change my title because what I was doing 80% of my time was not data analysis in the slightest bit.",
          "score": 1,
          "created_utc": "2026-01-21 20:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0x3cjz",
          "author": "viniciusvbf",
          "text": "By working as a software engineer for a few years first",
          "score": 1,
          "created_utc": "2026-01-21 20:16:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ylwmw",
          "author": "Brus210",
          "text": "Got an internship at a consulting company specialized in Informatica (governance platform) and then they hired me as a data management consultant jr.\nAnd the last week I completed my first year in the company.üòä",
          "score": 1,
          "created_utc": "2026-01-22 00:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ysqgx",
          "author": "JBalloonist",
          "text": "I was a data analyst first but already doing DE.",
          "score": 1,
          "created_utc": "2026-01-22 01:23:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ywpk9",
          "author": "Siege089",
          "text": "By accident, joined a company and was transferred between projects before I even completed onboarding. Role ended up being for a data platform and I've not looked back. So glad I left full stack dev, JS is such a terrible language.",
          "score": 1,
          "created_utc": "2026-01-22 01:46:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11kuia",
              "author": "Snoo-14088",
              "text": "So what language do use now then , im guessing pyhton , I‚Äôm starting out just want to Learn more .",
              "score": 1,
              "created_utc": "2026-01-22 13:33:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o11vjge",
                  "author": "Siege089",
                  "text": "I'm at a scala place now. Can't go wrong with python though it's very popular for DE.",
                  "score": 2,
                  "created_utc": "2026-01-22 14:29:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0z6bp7",
          "author": "Balgur",
          "text": "Got hired as a data engineer. Didn‚Äôt apply for it. Had experience working on data heavy systems at Amazon.",
          "score": 1,
          "created_utc": "2026-01-22 02:40:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0zb81b",
          "author": "Icy_Clench",
          "text": "I was a full time data analyst for 4 months after interning (first job too). Realized the company had no clue what they were doing in DE and applied when the position opened.\n\nI applied and showed the company some pretty basic ingestion and transformation skills honestly and got hired. The people hiring were not data engineers but they liked that I was methodical and organized.\n\nLanding the internship I just did some EDA in Python and showed some distributions, stats, and a basic XGBoost model. That was well above what the team was operating at and they called me before I even made it home.",
          "score": 1,
          "created_utc": "2026-01-22 03:08:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1007fc",
          "author": "nightslikethese29",
          "text": "Started as an analyst and my boss gave me an end to end project. I loved the DE part of it and told her. She then made it her mission to get me the resources I needed to learn, made 90% of my work DE, and then helped me transition to a backend team with a title change. That took a little less than 2 years to get the title change but I was doing de work for a full year and a half before that.",
          "score": 1,
          "created_utc": "2026-01-22 05:53:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10dlrv",
          "author": "Business_External_36",
          "text": "With Fake experience",
          "score": 1,
          "created_utc": "2026-01-22 07:46:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10ve18",
              "author": "Careful_Ring2461",
              "text": "Can you tell more about this. I assume you already had a job before you got into DE.",
              "score": 1,
              "created_utc": "2026-01-22 10:32:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o11m2yc",
              "author": "Snoo-14088",
              "text": "Wait does that work ?",
              "score": 1,
              "created_utc": "2026-01-22 13:40:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o11magq",
                  "author": "Business_External_36",
                  "text": "Yes",
                  "score": 1,
                  "created_utc": "2026-01-22 13:41:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12k2v7",
          "author": "abrem5",
          "text": "Had an internship doing backend dev work in college, then focused on data classes my senior year and looked for data roles.\n\nGot a job working at an IT consulting/temp firm out of college as a data analyst. Got started with a 3 month contract at a client for an analyst position that ended up being more of an engineering position in reality. \n\nThat 3 month contract turned into a 6 month contract, which turned into a 12 month contract, which turned into a full time role at the client.",
          "score": 1,
          "created_utc": "2026-01-22 16:25:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13e6lt",
          "author": "forserial",
          "text": "Worked as a full stack software dev and then transitioned over.",
          "score": 1,
          "created_utc": "2026-01-22 18:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13p8yd",
          "author": "Space2461",
          "text": "Soulless corporate consulting job, where you get exploited and \"forced\" to work at least 12 hours/day in a country where 28k/year is considered a good salary",
          "score": 1,
          "created_utc": "2026-01-22 19:29:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14wpqr",
          "author": "PossibilityRegular21",
          "text": "4 years in Analytics. Realised all the data was shit quality. Asked to move to DE to help fix the problems. Still working on it - there's a bigger culture problem I can't fix.",
          "score": 1,
          "created_utc": "2026-01-22 23:01:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16773l",
          "author": "RslashJD",
          "text": "I recently landed a DE job, and I got my experience in an adjacent role. It‚Äôs pretty common to move from data analyst to engineer. However, I‚Äôd recommend looking for an analyst job that works closely with the engineering team. In my old job, I pretty much was the middle man between the data engineers and any department that had a data related use case. This gave me a ton of experience with gathering requirements, planning go live dates, determining frequency that tables needed to be loaded, etc. I also ‚Äúmapped‚Äù all fields to whatever table they were being added to. So I wrote a lot of SQL transformations and complicated Joins. This was insanely valuable experience. \n\n\nLooking for titles like: BI analyst, BI Engineer, Data Management Analyst. Also any mentions of mapping, data modeling, managing data warehouse logic, or supporting the data engineering team are usually a good sign you will get an opportunity to learn some valuable skills. \n\n\nExtra Tip: When you eventually get an interview, be likable! There are plenty of people in the world that have the skills to be a good DE. Separate yourself by being someone that the interviewer would enjoy working with. My team told me that the last round of my interview was between me and one other person, and they eventually chose me because we got along better. \n\n\n\nSorry for any typos, I don‚Äôt have the energy to get up and grab my glasses.",
          "score": 1,
          "created_utc": "2026-01-23 03:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16lcmp",
          "author": "Leading_Tradition471",
          "text": "Started as a intern at a consulting firm, then landed a Python project. Turns out that project was DE work with Databricks and Power Bi. I got lucky",
          "score": 1,
          "created_utc": "2026-01-23 04:38:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17mf75",
          "author": "taker223",
          "text": "I had Bs.D in 2003 in what 7 years later would become \"Data Engineering\". Worked in Database/Informational Systems development since 2001 so yeah... naturally :)",
          "score": 1,
          "created_utc": "2026-01-23 09:44:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1abrwd",
          "author": "FuzzyCraft68",
          "text": "1 year experience in Software Engineer, 1 internship doing CRM dashboard, finished my masters. Recruiters found me on LinkedIn after networking and posting about data engineering every 2 days for about a month",
          "score": 1,
          "created_utc": "2026-01-23 18:46:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bx15k",
          "author": "slayerzerg",
          "text": "They require 3 years but hire someone with 7+ years",
          "score": 1,
          "created_utc": "2026-01-23 23:20:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13jjrj",
          "author": "luckyswine",
          "text": "Here's how: be a software engineer first.  Data engineering is a specialization of software engineering.  I will hire an experienced software engineer and train them up as a data engineer long before I hire someone with less than 3 years of data engineering experience.",
          "score": 0,
          "created_utc": "2026-01-22 19:03:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhi4lr",
      "title": "Designing Data-Intensive Applications",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qhi4lr/designing_dataintensive_applications/",
      "author": "ninjaburg",
      "created_utc": "2026-01-19 21:58:12",
      "score": 63,
      "num_comments": 14,
      "upvote_ratio": 0.96,
      "text": "First off, shoutout to the guys on the Book Overflow podcast. They got me back into reading, mostly technical books, which has turned into a surprisingly useful hobby.\n\nLately I‚Äôve been making a more intentional effort to level up as a software engineer by reading and then trying to apply what I learn directly in my day-to-day work.\n\nThe next book on my list is Designing Data-Intensive Applications. I‚Äôve heard nothing but great things, but I know an updated edition is coming at some point.\n\nFor those who‚Äôve read it: would you recommend diving in now, or holding off and picking something else in the meantime?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qhi4lr/designing_dataintensive_applications/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0kqp4t",
          "author": "strugglingcomic",
          "text": "The first edition is great, but you're so close to the new edition that, I honestly would hold off for another 2 months I guess, and fill in with other resources for learning in the meantime. \n\nAssuming the purchase of a $30-50 book is not trivial to you. If it's trivial, then hell buy both and support the author twice.",
          "score": 17,
          "created_utc": "2026-01-20 00:15:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oe0fd",
              "author": "me_wallflower",
              "text": "Imagine how cool and hip you would look, my having not one but TWO, yes, twoooo designing data intensive applications on your desk",
              "score": 2,
              "created_utc": "2026-01-20 15:05:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0uvfwt",
                  "author": "scarredMontana",
                  "text": "Stop, I'm getting a little too wet",
                  "score": 2,
                  "created_utc": "2026-01-21 14:11:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0lj45h",
              "author": "ninjaburg",
              "text": "Good point.",
              "score": 1,
              "created_utc": "2026-01-20 02:49:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kfl8r",
          "author": "WanderingGunslinger",
          "text": "It‚Äôs a great book, I still revisit sections from time to time.\n\nIf your goal is to understand data systems from a software engineering and architectural perspective, it‚Äôs one of the best reads out there.\n\nIt‚Äôs less about tools and more about how to think about data systems, so it‚Äôs valuable whether you read it now or later in your career.\n\nHighly recommend.",
          "score": 36,
          "created_utc": "2026-01-19 23:15:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ljdsf",
              "author": "ninjaburg",
              "text": "After another comment im leaning toward audio book now and buy the physical book when the new one arrives.",
              "score": 3,
              "created_utc": "2026-01-20 02:51:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0lu22j",
                  "author": "paulrpg",
                  "text": "The new one should be out next month, at least on oreilys website",
                  "score": 3,
                  "created_utc": "2026-01-20 03:51:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0pgwos",
                  "author": "speedisntfree",
                  "text": "I cannot imagine a book like this as an audio book. One of the best chapters is where he builds up DB from a text file with shell commands.",
                  "score": 3,
                  "created_utc": "2026-01-20 18:07:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kg1vq",
          "author": "dont_tagME",
          "text": "I‚Äôm reading it right now, the book discusses different aspects of making applications reliable, scalable, sustainable etc. A bit of history here and there and how things work, the problem they solve etc. \n\nIt is worth reading. If you have worked building apps, you will find that many concepts are familiar to you.",
          "score": 5,
          "created_utc": "2026-01-19 23:17:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ksvj4",
          "author": "big_chung3413",
          "text": "I think it‚Äôs fair if you want to wait for the new addition.  I think a ton is applicable in the first version regardless.  I read it really slowly, 8 months , but it really did open my eyes to a lot of patterns I work with or around. \nRead for most of 2025 for reference",
          "score": 4,
          "created_utc": "2026-01-20 00:26:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n5ul6",
          "author": "_OMGTheyKilledKenny_",
          "text": "It‚Äôs very dense subject matter and needs the accompanying visual representation to get a handle, especially for topics like LSTM, unless you are already familiar with the concepts being discussed.  I‚Äôd skip the audiobook and get a hard copy or digital version.",
          "score": 3,
          "created_utc": "2026-01-20 10:14:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nevhs",
              "author": "ninjaburg",
              "text": "That‚Äôs a good point, I‚Äôve ran into that issue with some previous books. \n\nI‚Äôm generally pretty familiar with the subject but I suppose not enough to think the book wouldn‚Äôt help me in day to day stuff. \n\nCurrently looking like I‚Äôm going to try audio book the buy the new edition when it comes out.",
              "score": 1,
              "created_utc": "2026-01-20 11:33:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1c62un",
          "author": "Financial-Book-3613",
          "text": "It was recommended to me during grad school by my professor, and it‚Äôs easily one of the finest books available. I‚Äôm not a DE (I‚Äôm an MLE), but I work with DEs daily and can see how practically useful it is once the concepts sink in, far more than just hammering theory. Hands down!",
          "score": 1,
          "created_utc": "2026-01-24 00:09:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qig8ea",
      "title": "Senior DE on on-prem + SQL only ‚Äî how bad is that?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qig8ea/senior_de_on_onprem_sql_only_how_bad_is_that/",
      "author": "Educational_Ad4133",
      "created_utc": "2026-01-20 22:47:07",
      "score": 59,
      "num_comments": 31,
      "upvote_ratio": 0.98,
      "text": "Hey all,\n\nI‚Äôm a senior data engineer but at my company we don‚Äôt use cloud stuff or Python, basically everything is on-prem and SQL heavy. I do loads of APIs, file stuff, DB work, bulk inserts, merges, stored procedures, orchestration with drivers etc. So I‚Äôm not new to data engineering by any means, but whenever I look at other jobs they all want Python, AWS/GCP, Kafka, Airflow, and I start feeling like I‚Äôm way behind.\n\nAm I actually behind? Do I need to learn all this stuff before I can get a job that‚Äôs ‚Äúequivalent‚Äù? Or does having solid experience with ETL, pipelines, orchestration, DBs etc still count for a lot? Feels like I‚Äôve been doing the same kind of work but on the ‚Äúwrong‚Äù tech stack and now I‚Äôm worried.\n\nWould love to hear from anyone who‚Äôs made the jump or recruiters, like how much not having cloud/Python really matters.",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qig8ea/senior_de_on_onprem_sql_only_how_bad_is_that/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0s37e7",
          "author": "IndependentTrouble62",
          "text": "I took a similar path as you. I was an on prem person for most of my career. I now support Azure and Databricks as well. The skills transfer really easily by and large. I would have more issue with you not knowing python.",
          "score": 38,
          "created_utc": "2026-01-21 01:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tuwvy",
              "author": "Educational_Ad4133",
              "text": "Thanks for the reply, it's nice to know people has done my route. It's not like I don't know Python at all. I have used Python and know the basics and familiar with the libraries. Issue is not actively using it at work as is not require. \n\nI am learning and studying all these but it's hard for me as whenever I learn about these feel like extra steps I don't need to achieve the same output.",
              "score": 1,
              "created_utc": "2026-01-21 09:51:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ykk95",
                  "author": "IndependentTrouble62",
                  "text": "I am a senior data engineer and honestly I use python now less than I used to. Main reasons is organization is delving heavily into Azure lakehouses and Similar structures in data bricks. We deal with lots of data, but our trnasformations are very simple so we can get by with low code tools like adf, ssis, etc, and pure sql. I would weight data modeling and SQL the most important skill.",
                  "score": 2,
                  "created_utc": "2026-01-22 00:37:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0vchd8",
                  "author": "Upstairs_Ad6877",
                  "text": "Same here. I know basic Python, used it for POC, but don‚Äôt have chance to use it in daily basic.",
                  "score": 1,
                  "created_utc": "2026-01-21 15:35:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0yj41d",
              "author": "IDoCodingStuffs",
              "text": "+1 on the ease of transition.\n\nKnowing Python can also mean different things. Like, are you writing entire libraries for deployed services, tooling for data scientists etc. or just pipeline scripts?",
              "score": 1,
              "created_utc": "2026-01-22 00:30:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yk6g1",
                  "author": "IndependentTrouble62",
                  "text": "For DE if you know the main libaries and can write basic servicable python is what I mean. If you can help with DS projects its nice to have, but not required. I would want a hire to have python and speak to libaries like pyspark, polars, pandas, pyodbc, SQLAlchemy, requests, etc.",
                  "score": 1,
                  "created_utc": "2026-01-22 00:35:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o14ko06",
              "author": "quickdraw6906",
              "text": "Yeah, I wouldn't stress it. Get a certification on AWS or your preferred cloud. I'm self taught after 25+ years of on prem dba and data app dev. It wasn't hard to pick up.",
              "score": 1,
              "created_utc": "2026-01-22 21:57:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0s8y49",
          "author": "GachaJay",
          "text": "Not gonna lie, I‚Äôm trying to hire someone like you right now. I have to hire in Pune, India, but, yeah, I value you.",
          "score": 15,
          "created_utc": "2026-01-21 02:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sdnnv",
              "author": "Great-Tart-5750",
              "text": "But given the choices you have,  you will most likely pick the one who has cloud as well as on prem experience, but not this guy.",
              "score": 6,
              "created_utc": "2026-01-21 02:54:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tmwfh",
                  "author": "Skullclownlol",
                  "text": "> But given the choices you have, you will most likely pick the one who has cloud as well as on prem experience, but not this guy.\n\nI've been the Tech Lead of the team for the past 3y and had to hire a few times, for a bank. Privacy sensitive, majority on-prem (for the data our team works with, the bank globally uses cloud ofc), python with SQL and dataframes. Majority cloud experience was seen as a (very slight) negative because those people often didn't know how to optimize single-node operations. In our context, \"just scale it up\" isn't an option.\n\nBoth the on-prem person and the cloud person would've been given an interview (because I respect people's experiences and adaptability and don't try to project what they can/can't do), but the \"majority on-prem\" person would've received priority (especially from our businesspeople). If a person has both on-prem and cloud experience equally, the \"majority on-prem\" person would receive 1st priority and 50/50 person would receive 2nd (\"majority cloud\" would be 3rd pick).\n\nThese priorities of course don't take into account how well the interview goes. A resume doesn't really say much imo.",
                  "score": 6,
                  "created_utc": "2026-01-21 08:34:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0rjg3l",
          "author": "Nekobul",
          "text": "Knowing the so-called cloud stuff or Python-based solutions is highly overrated. You can search and find plenty of people posting here who are unable to find job with these skills.",
          "score": 14,
          "created_utc": "2026-01-21 00:04:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tafcr",
              "author": "reallyserious",
              "text": "True. But lacking those skills will make it significantly more difficult to land an interview.¬†\n\n\nUnfortunately you have to play the CV buzzword bingo game to even be considered.",
              "score": 8,
              "created_utc": "2026-01-21 06:40:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ruvt7",
          "author": "swagfarts12",
          "text": "On prem and SQL only can be a good base, but I'd probably try to learn a cloud platform of some kind in your free time. They are basically infinitely scalable and have a lot of tools integration that is a lot less likely to be used for on prem data warehouses. Specific cloud implementation you use matters less, but having experience with a cloud platform at all is important in the sense that I would guess recruiters would choose someone with slightly less YoE who knows a cloud platform well over someone who has more YoE but none with any cloud warehouses.",
          "score": 3,
          "created_utc": "2026-01-21 01:07:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sdgk5",
          "author": "Great-Tart-5750",
          "text": "I am also kind of in the same boat as you. We use either on-prem or open source tech in our data infra and no cloud is involved. I also have knowledge of cloud personally, but not on production level. \n\nFrom the pov of switching, man cloud is a must. I am trying since the past few months and all I get in return is you don't have enough hands on with cloud so we can't take you. \n\nI am now thinking of getting a cert in AWS cloud for the same.",
          "score": 2,
          "created_utc": "2026-01-21 02:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s5mj0",
          "author": "HC-Klown",
          "text": "Knowing the concepts which probably you already know is way more important than knowing tools or cloud providers. Nowadays, with LLMs, given your knowledge on fundamental principles of data engineering you can get away with imementing and debugging most use cases in the cloud. \n\nSo, it might be worthwhile getting a certification and/or updating yoir portofolio with cloud project just for your resume. However, I wouldn't ne worried of being \"left behind\". Lean on your strong points during interviews and how you approached problems using fundamentals and treat cloud for what it is, a tool.",
          "score": 3,
          "created_utc": "2026-01-21 02:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0shmx5",
          "author": "Sizzlingbrowny",
          "text": "I don‚Äôt think all your experience will go vain you can use that to learn cloud platforms quickly but yes learning cloud will gives an edge",
          "score": 1,
          "created_utc": "2026-01-21 03:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sz6go",
          "author": "Easy_Cable6224",
          "text": "you have heavy sql experience, just deepen your skill in cloud as other said, then pretty sure you will be fine. Companies, especially big tech, they value experience more and more recently",
          "score": 1,
          "created_utc": "2026-01-21 05:11:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tvdqd",
              "author": "Educational_Ad4133",
              "text": "Thanks I am learning on my free time. This is what I was after tbh, I know I need to know all these just felt like all my experience are in vain or not. I have solved huge issues at my work with batching, query optimising and all. Feel like these skills are not something you just learn. But feel so behind when I see the jds of job at my level",
              "score": 1,
              "created_utc": "2026-01-21 09:55:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tj8zc",
          "author": "Little_Kitty",
          "text": "At least makes sure you know enough python to get through Leetcode interviews and have a couple of personal projects.  I don't use python much, largely because I find it an ugly language and it's too slow for a lot of what I need, but it has its place and works fine there (largely getting C / Scala to do things).\n\nThe problem with knowing only SQL is that you don't have coding experience and that matters because it's a different mindset to set based transformations.  Similarly you see issues with people who can code but don't understand SQL.\n\nTL;DR not good",
          "score": 1,
          "created_utc": "2026-01-21 07:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u921l",
          "author": "SoggyGrayDuck",
          "text": "Same boat and it's tough but I have 3-5 years of aws. I'm cranking out the AWS DE cert and then databricks if I'm still looking",
          "score": 1,
          "created_utc": "2026-01-21 11:53:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0util0",
          "author": "SQLDevDBA",
          "text": "Data & Analytics Director here and I‚Äôve worked on (and led) multiple teams over the years that are similar.  There are plenty of teams out there that value those skills either because they need them explicitly or because they transfer easily to cloud environments.  Python is pretty much a must at this point, but it will be useful in your on-prem environment.  A ‚Äúgood‚Äù substitute is PowerShell so if I see someone with PS experience that‚Äôs usually a good sign. Knowing APIs and how to interact with them is already putting you above many others I‚Äôve encountered.\n\nI‚Äôd suggest an AI prompt like: \n\n>>I‚Äôm a Data Engineer with X years of experience with Data Warehousing on Prem with [XYZ Technologies and platforms], what tech/knowledge should I know that I probably don‚Äôt?\n\nAnd go from there.\n\nThe Azure Career path for Data engineers is free and has lots of modules available as well:\n\n\nhttps://learn.microsoft.com/en-us/training/career-paths/",
          "score": 1,
          "created_utc": "2026-01-21 14:01:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v6opt",
          "author": "Fabulous-Chemical-21",
          "text": "People who are strong at ETL and SQL can easily tune to Cloud !! \nSQL isn‚Äôt just a query language.\nIt‚Äôs a mindset.\nIt‚Äôs how data engineers think.",
          "score": 1,
          "created_utc": "2026-01-21 15:08:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wjihk",
          "author": "billysacco",
          "text": "This is valid experience, many places can and should just stick with local SQL databases for their analysis. I won‚Äôt lie the cloud thing is getting very popular even for smaller companies that don‚Äôt need it. A ‚Äúkeeping up with jones‚Äù mindset I imagine. One thing I will say try learning python as soon as you can. Use it to automate functions or ETLs at your job. I did that and learned fast. At some point your company might dip its toe into the cloud and Python experience is really good to have.",
          "score": 1,
          "created_utc": "2026-01-21 18:47:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xkctv",
          "author": "SeaYouLaterAllig8tor",
          "text": "I'm kinda in the same boat but not in the cloud dept. I went from SQL server (and related apps) to Snowflake about 6-7 years ago. I've now got experience with multiple cloud based apps but I'm basically a SQL guru. My python skills are rudimentary. I've written a bit of python here and there for applications like streamlit but nothing significant and I wouldn't trust myself to write a data pipeline solely in Python. I basically Google and hack my way through functional or OOP programming. All that said, I feel you and often feel like (as someone who's looked at as a Senior Engineer/Solution Architect) I'm somewhat behind compared to many.",
          "score": 1,
          "created_utc": "2026-01-21 21:33:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xo9cr",
          "author": "StarSchemer",
          "text": "Enable SQL Server Machine Learning Services. \n\nThis will allow you execute Python (and R) scripts from SQL Server.\n\nWe mainly use it for much-improved CSV ingestion over the native SQL Server options.\n\nThis approach will allow you to build production Python solutions while also bringing big benefits to your existing platform.",
          "score": 1,
          "created_utc": "2026-01-21 21:51:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sqrqg",
          "author": "minato3421",
          "text": "You know sql. You just need to extend the same to cloud. I don't think it's that hard to get hired",
          "score": 0,
          "created_utc": "2026-01-21 04:14:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0trsaa",
          "author": "xmBQWugdxjaA",
          "text": "You need to learn to program.\n\nCloud management is optional and a deep rabbit hole in itself, but programming is essential.",
          "score": -1,
          "created_utc": "2026-01-21 09:21:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi4bp2",
      "title": "Any Other Seniors Struggling in the Job Market Right Now?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qi4bp2/any_other_seniors_struggling_in_the_job_market/",
      "author": "shittyfuckdick",
      "created_utc": "2026-01-20 15:37:11",
      "score": 54,
      "num_comments": 34,
      "upvote_ratio": 0.95,
      "text": "Have 8 yoe. Work with Airflow, DBT, Snowflake, the works. US citizen. \n\n  \nIve been applying since October probably to well over 100 maybe 200 jobs. Theres maybe like 6 places I got to the final rounds for and they all rejected me. The most feedback I could get was they had another candidate who was better. Every technical assessment I did correctly. I was even told for one I was the fastest to ever complete it. \n\n  \nSo whats the deal? I cant figure out if this is a skill issue or personality issue. Its definitely been getting to me I thought i was a pretty good engineer.  ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qi4bp2/any_other_seniors_struggling_in_the_job_market/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0ootxr",
          "author": "codemega",
          "text": "Well Q4 is known to be a quiet period for hiring due to the holidays and budgets not being set until the new year.\n\nBut you've been posting for longer than that about either not getting interviews or getting rejected due to a supposed lack of streaming experience. You've previously brought up lying about past experience to get noticed.\n\nPerhaps there's something wrong with your resume or your interview skills or personality. The job market is tough too. Maybe a link to a resume would be a start for assistance.",
          "score": 54,
          "created_utc": "2026-01-20 15:57:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oql45",
              "author": "shittyfuckdick",
              "text": "Yes sir. I fixed up my resume and started getting more interviews. the previous thread people mentioned i needed streaming experience so i need to make a lateral move. I have been trying to do that. I even interviewed for a data analyst position which i wound up being rejected in the final rounds.¬†\n\nso yes I am posting because im desperate and tired.¬†",
              "score": 6,
              "created_utc": "2026-01-20 16:05:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0omfd0",
          "author": "MikeDoesEverything",
          "text": ">So whats the deal? I cant figure out if this is a skill issue or personality issue.¬†\n\nAs per yourself:\n\n>The most feedback I could get was they had another candidate who was better.\n\nIt's probably a bit of both, but it isn't personal (unless you are a self confessed massive piece of shit).  You can be technically strong and \"not a good fit\" for a massive list of reasons.  Usually, it's just vibes.\n\nMy background is in chemistry.  I used to make the active component of pharmaceuticals for a living.  I got rejected for a DE role at a pharma company looking for DEs with a background in the specific chemistry I did which I swear can't be very common.  Reasons? No idea.\n\n>Its definitely been getting to me I thought i was a pretty good engineer.\n\nLikewise, I thought I was a decent chemist.  I lost my last chemistry job during the pandemic and kept interviewing for places where all of my technical skills lined up.  I didn't struggle in the technicals and seemed to get on with everybody too.  Some places never called me back.  Other places rejected me at the last hurdle.  I even followed up with some of the team members who interviewed me and asked them wtf was up because it was extremely confusing.  The team members said if it was up to them, I'd have been in.  They weren't consulted so it must have been management.\n\nMy personal issue was that I hadn't enjoyed doing chemistry for quite a while before then.  I didn't want to do chemistry anymore, but, I have bills to pay.  I think no matter where I went and no matter how many technicals I would have cleared, every company I would have interviewed for would have said no.  They didn't have to know I had lost my passion for the field although I'm sure, subsconsciously or consciously, they knew something was off.\n\nI changed field to DE.  Best decision ever for me.  Not saying this is you, although this is potential food for thought.",
          "score": 23,
          "created_utc": "2026-01-20 15:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0osfly",
              "author": "shittyfuckdick",
              "text": "Thanks I can only speak introspectively but I am not a social person and am hard to get along with. I do my best to put on a performance during interviews and what little feedback ive gotten on that is positive. So no idea if that is an actual issue or overthinking.¬†",
              "score": 8,
              "created_utc": "2026-01-20 16:14:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0rnrmj",
                  "author": "Toastbuns",
                  "text": "Having been on the hiring side, I would absolutely answer a question of feedback more honestly if you found a way to DM on LinkedIn or something than I would if you asked me on the interview rejection email or via HR. \n\nSometimes it's just bullshit reasons like I got over-ruled by a more senior person or that a single person on the interview team got weird vides that no-one else caught. \n\nI've also been in situations where we had a great candidate for a job we listed but then the company realized they didn't want to hire that role anymore or that they were asking for the wrong role in general.\n\nHave also seen situations where we ended up hiring an internal candidate even though they were less competent.   \n\nOverall, I would say just keep at it, as discouraging as it can be.",
                  "score": 1,
                  "created_utc": "2026-01-21 00:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0p97xq",
              "author": "JJ3qnkpK",
              "text": "Hey! Fellow chemist data engineer!\n\nI went into a form of organizational sciences after chemistry before finally hopping to data engineering. I've found that the two together make me into a sort of business superhero: looking for the true meaning of data and the true business problems that need to be solved.\n\nMy advice to any struggling data engineer is to evaluate whether or not you are actually identifying and actually solving business problems. You can be the end-all be-all of Spark, Databricks, etc., and you can build perfectly to provided specifications, but ultimately end up worthless to the business by not actually solving problems.\n\nLearn to interrogate the data, the business constructs, find what people are actually needing and trying to achieve, speak to the stakeholders and understand them, their needs, hell their entire job if you can.\n\nExplain the benefits of modern infrastructure and methods in the context of the business problem and constructs. If you can't bring an engaged layperson to understanding what you put forth, then keep refining your thoughts and approach until you can.\n\nBuild your ability to present such that you can speak to managers and stakeholders. Build your technical understanding such that you can put forth directions on-the-fly and communicate why these directions will lead everyone towards the goal of solving the actual business problem.\n\nBringing this back to my first points: my background in the sciences has so greatly assisted me in all of the above. All too often, I meet technical people who are fantastic developers, but just build things off-kilter and struggle to gather requirements and internalize the business's needs and goals. It'd be like a plumber who doesn't understand what a pipe will be used for - is it the washer/dryer, sewage, a fire hydrant, or what? These developers do the equivalent of building a sewage pipe that emerges in the center of the bathroom floor - it's almost correct, but useless because nobody wants the toilet there.",
              "score": 4,
              "created_utc": "2026-01-20 17:32:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0po7rf",
                  "author": "curiosickly",
                  "text": "My God, there are at least 3 of us! (Chemists turned DE)",
                  "score": 3,
                  "created_utc": "2026-01-20 18:40:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qiliz",
              "author": "beyphy",
              "text": "> I got rejected for a DE role at a pharma company looking for DEs with a background in the specific chemistry I did which I swear can't be very common. Reasons? No idea.\n\nThis reminds me of a short-term contract job that I interviewed for recently.\n\nAlthough I'm not one anymore, I have a background as a data analyst. I worked 5+ years as a data analyst across two different industries.\n\nRecently, a recruiter contacted me about a position that's in one of the niche industries that I used to work in. There are only a handful of major companies in that industry, I've worked for a few of them, and have a combined three years of experience across those companies. The job was for some much smaller company in the same industry. And although the job was remote, the company happens to be in the same city that I'm located in. So we are on the same time zone. And I'd be open to going into the office if they wanted me to do that.\n\nI couldn't even get an interview. Like you, I have no idea why. I didn't get any feedback. And as far as I can tell, the recruiter ghosted me.",
              "score": 1,
              "created_utc": "2026-01-20 20:59:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0qkl72",
              "author": "TheFIREnanceGuy",
              "text": "What exactly did do to pivot, get the skills and get that first de job? I always love hearing about the story",
              "score": 1,
              "created_utc": "2026-01-20 21:08:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ot9eu",
          "author": "git0ffmylawnm8",
          "text": "I'm in a similar situation. I rarely get contacted back even when I meet the majority of the listed skills required. 9 YoE (2.5 years in FAANG), US citizen, hands on experience with the major tools like Databricks/Snowflake/Airflow/Python. I declined an offer for one job and I was passed for an internal candidate just because they needed someone with internal tooling experience",
          "score": 9,
          "created_utc": "2026-01-20 16:18:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ovxv3",
              "author": "shittyfuckdick",
              "text": "Damn if you cant get hired with FAANg experience im really screwed.¬†",
              "score": 3,
              "created_utc": "2026-01-20 16:30:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pieia",
                  "author": "Gh0sthy1",
                  "text": "Most of the small companies that I have worked prefer avoiding ex-FAANG.",
                  "score": 9,
                  "created_utc": "2026-01-20 18:14:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0q3omy",
                  "author": "Fender6969",
                  "text": "Not all companies are in a position to hire/retain FAANG engineers. And just because someone worked at one company it doesn‚Äôt necessarily mean they are the best fit for the role in another.",
                  "score": 2,
                  "created_utc": "2026-01-20 19:50:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ovhl5",
          "author": "goblueioe42",
          "text": "I found it harder to get a job this time around. Much harder. And yes final rounds are harder this time around.",
          "score": 6,
          "created_utc": "2026-01-20 16:28:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pc8lt",
          "author": "dukeofgonzo",
          "text": "If you are making it to 6 final round interviews, but going 0/6, then whatever is happening at that final round interview is whatever is stopping you from getting hired. Could there be something in common about those 6 final interviews? If it's about one other candidate having +1 to what they're looking for, then it means they just like that person more on 6 occasions. It's likely not about some minute technical skill difference.\n\nGetting 6 interviews is commendable, and proof that on paper you can get to that eliminating interview.",
          "score": 6,
          "created_utc": "2026-01-20 17:46:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0phjb9",
          "author": "ask_can",
          "text": "Since you are able to make it through the initial rounds...you probably are following short in one of the following:\n\n‚Ä¢ Experience with Snowflake isn‚Äôt coming through clearly  \n‚Ä¢ Experience with CI/CD pipelines for Snowflake deployments  \n‚Ä¢ How you explain orchestration of jobs and handle failures  \n‚Ä¢ Examples of performance tuning  \n‚Ä¢ Walk through of complex project or architecture with trade-offs.",
          "score": 5,
          "created_utc": "2026-01-20 18:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pvzuz",
          "author": "SoggyGrayDuck",
          "text": "Id update your LinkedIn, something seems off. The calls I get are all for senior/staff and in and in a better market I'd land one but I'm right on the edge. I really want one more position under a great staff engineer and then I know I'm really really to run. I just need someone to discuss how the current architecture and best practices have changed. I'm so frustrated with how little we even mention it where I'm at right now. Agile agile AGILE! \n\nSorry I got off topic. But anyway I have the opposite problem but unfortunately currently working on prem so I kept fucking up interviews. I feel like you're in a better spot than me and just need to tweak the profile a bit.",
          "score": 2,
          "created_utc": "2026-01-20 19:14:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q1lp6",
          "author": "sleeper_must_awaken",
          "text": "I've heard quite some stories about 'reverse' discrimination, both on gender, race and age. Basically, if you're a caucasian male above 40, you're at the back of the line on recruitment lists. Nobody will admit to it, of course...",
          "score": 2,
          "created_utc": "2026-01-20 19:41:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0s3dm1",
              "author": "Captain-Melonhead2x4",
              "text": "In this political climate? That makes no sense.",
              "score": 1,
              "created_utc": "2026-01-21 01:55:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0p5h0p",
          "author": "Accomplished-Dot-608",
          "text": "Maybe companies are trying to hire junior level engineers who have senior level experience whom they can pay less. I am just guessing.",
          "score": 1,
          "created_utc": "2026-01-20 17:14:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pba3u",
          "author": "WrongPlaceRightTime0",
          "text": "i have 5 yoe and had worked on the same tech stack, and mid last year i learnt spark structured streaming, kafka, kubernetes and did some personal projects then tailored it to match the industrial productionized ones for interview storytelling and resume. the fact is most data engs are working on batch processing reporting solutions hence real time streaming analytics can set you apart. i personally got 100 percent hike from a tier one consulting firm in india. i‚Äôd say just work your way around the new tools and tech and smartly sprinkle it on your cv",
          "score": 1,
          "created_utc": "2026-01-20 17:41:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0phyyd",
          "author": "adgjl12",
          "text": "Keep going. Reaching final round is a good sign. I got my job a year ago with 5YOE and it took 300+ applications to get 5 final interviews and 1 offer. It‚Äôs just a numbers game at that point.",
          "score": 1,
          "created_utc": "2026-01-20 18:12:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pp540",
          "author": "Gawgba",
          "text": "You need a better 'internal referral network'.  IYKYK",
          "score": 1,
          "created_utc": "2026-01-20 18:44:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pr15y",
              "author": "shittyfuckdick",
              "text": "So just networking?",
              "score": 0,
              "created_utc": "2026-01-20 18:52:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0px5dw",
          "author": "McNemarra",
          "text": "Prob cheaper candidates that provide similar value",
          "score": 1,
          "created_utc": "2026-01-20 19:20:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qdjzo",
          "author": "Inevitable_Oil_9715",
          "text": "in UK its really bad! Been trying to change the jobs but the market is dry so the salary is so low that one has to prepare for top tech companies. Surprise - you're laid off !",
          "score": 1,
          "created_utc": "2026-01-20 20:36:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r0xby",
          "author": "TheCamerlengo",
          "text": "No. None.",
          "score": 1,
          "created_utc": "2026-01-20 22:25:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rnx9x",
          "author": "get-the-dollarydoos",
          "text": "Just 200 jobs?\n\nHate to say it but those are rookie numbers. I see people all the time putting in 500+. My last job hunt I wrote a program to track my job searches and did more than 300 full applications and more than 600 Indeed quick apply applications, and I felt like I got hired quickly. Before that I'm pretty sure I was over 700. Back in 2014 it was over 500.\n\nIn fact, I haven't been on a job hunt in almost 15 years that didn't require 400+ applications and nowadays it seems to be approaching 1,000.",
          "score": 1,
          "created_utc": "2026-01-21 00:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rqvx5",
              "author": "shittyfuckdick",
              "text": "So it sounds like automation is key to landing a job?",
              "score": 1,
              "created_utc": "2026-01-21 00:44:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0oxf8s",
          "author": "5hruj4n",
          "text": "There‚Äôs a walkin for Azure Data Engineering in Bangalore on 14th Feb. DM me for more info",
          "score": -7,
          "created_utc": "2026-01-20 16:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p24po",
              "author": "shittyfuckdick",
              "text": "Im desperate but not India desperate",
              "score": 4,
              "created_utc": "2026-01-20 16:59:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qilwgb",
      "title": "Airflow Best Practice Reality?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qilwgb/airflow_best_practice_reality/",
      "author": "BeardedYeti_",
      "created_utc": "2026-01-21 02:45:18",
      "score": 54,
      "num_comments": 33,
      "upvote_ratio": 0.98,
      "text": "Curious for some feedback. I am a senior level data engineer, just joining a new company. They are looking to rebuild their platform and modernize. I brought up the idea that we should really be separating the orchestration from the actual pipelines.  I suggested that we use the KubernetesOperator to run containerized Python code instead of using the PythonOperator. People looked at me like I was crazy, and there are some seasoned seniors on the team. In reality, is this a common practice? I know a lot of people talk about using Airflow purely as an orchestration tool and running things via ECS or EKS, but how common is this in the real world. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qilwgb/airflow_best_practice_reality/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0sefx3",
          "author": "dudebobmac",
          "text": "It depends to me. Is the code you‚Äôre running some super lightweight script or something? If so, directly in a PythonOperator is probably fine. If it‚Äôs something heavier, then your idea is better. Airflow is an orchestrator, using it to actually PERFORM ETL or other major transformations or whatever is an anti pattern.",
          "score": 43,
          "created_utc": "2026-01-21 02:58:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tw2hm",
              "author": "No_Song_4222",
              "text": "What do you mean by anti pattern? Could you give an example ? \n\nln my prev org we used airflow + bigquery job operator to transform  several TBs and even create new tables.\n\nIt's worked and scaled okay because the compute happens at big query end and airflow just does the task retires, task dependencies, waiting time etc\n\nI know several companies use airflow to run their ML batch predictions and inferences as well so I am not sure what you mean by anti pattern here ? \n\nAll other native cloud based orchestrators are some form of airflow only e.g. AWS Blue, Databricks etc",
              "score": 4,
              "created_utc": "2026-01-21 10:02:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0u5s8x",
                  "author": "dudebobmac",
                  "text": "Right. So Airflow isn‚Äôt performing ETL in your examples. It‚Äôs orchestrating other tools to perform the ETL. That‚Äôs its intended usage, so you‚Äôre using it correctly as an orchestrator.\n\nThe anti pattern would be if you (for example) ran a PySpark job within a PythonOperator. Airflow isn‚Äôt meant to actually run your ETL jobs, only orchestrate them.",
                  "score": 18,
                  "created_utc": "2026-01-21 11:27:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0tyzvm",
                  "author": "Great-Tart-5750",
                  "text": "I think he means to say what you said earlier, that airflow itself does not do any compute and also that it's not something you should even try to. It kind of goes against the principle of being an orchestrator.",
                  "score": 2,
                  "created_utc": "2026-01-21 10:29:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0tk4c7",
              "author": "Adrien0623",
              "text": "Aren't Airflow's workers actually made to perform compute ? We used them for Spark jobs at a previous company and it was fine. Of course we had to allocate enough memory for each CPU core to ensure workers got enough resources.",
              "score": -5,
              "created_utc": "2026-01-21 08:07:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0twz7m",
                  "author": "No_Song_4222",
                  "text": "Not sure what you mean here. \n\nIt's the reverse. Airflow just does schedule and workflow/task management. No way airflow does any kind of compute. \n\nProcessing and computing happens only at spark. \n\nE.g. if processed in create a spark cluster, load your code , execute it airflow does exactly the same. Based on how your write your script you can either split it as task 1 create a spark cluster once that is done load and execute the code or else have everything in one script. \n\nThe workers you say here just execute the task and they needs cpu and memory to be in sync and communicate with other dependencies and receive updates from spark clusters about the status of job etc .",
                  "score": 5,
                  "created_utc": "2026-01-21 10:10:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0se23k",
          "author": "DoNotFeedTheSnakes",
          "text": "This is the norm at my company.\n\nI'm a senior DE & Airflow expert there.\n\nThough for most jobs we don't need the KubernetesPodOperator we just use normal Operators with the KubernetesExecutor.\n\nSo you still use the regular old PythonOperator, but under the hood you're running everything in Kubernetes.\n\nAny questions?",
          "score": 16,
          "created_utc": "2026-01-21 02:56:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sf7k1",
              "author": "BeardedYeti_",
              "text": "I'd love to hear more. So you're just using the nornmal operators, but because you are using the KubernetesExecutor all of your tasks essentially run as their own pod? Do you containerize your DAGs?",
              "score": 3,
              "created_utc": "2026-01-21 03:03:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0sfztu",
                  "author": "DoNotFeedTheSnakes",
                  "text": "Exactly.\n\nWe don't containerize most DAGs, just use a mount with a shared volume that the DAGs are on. (You need one anyway for the scheduler to parse)\n\nSome specific sensitive or complex DAGs get containerized due to special needs.",
                  "score": 2,
                  "created_utc": "2026-01-21 03:07:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0tr304",
                  "author": "ZeroSobel",
                  "text": "Using the KubernetesExecutor means you can throw all the \"don't use airflow for compute\" out. You can even have individual tasks with different venvs if you want.",
                  "score": 2,
                  "created_utc": "2026-01-21 09:14:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0scuik",
          "author": "Great-Tart-5750",
          "text": "Airflow can be quite powerful given its support of wide range of operators. But we should be very careful of what we pick as it is always a step away from becoming a clusterf*ck.\n\nPersonally we use it as a pure orchestration platform  only and other things are managed out of it.",
          "score": 5,
          "created_utc": "2026-01-21 02:49:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0txje5",
          "author": "No_Song_4222",
          "text": "I want to understand who is running compute in airflow and why ? \n\n\n What the OP mentioned is fine as long as your compute cluster like Spark, bigquery, redshift and other operators are decoupled from the airflow orchestrators layer. \n\nAs in compute happens on actually big data processing tech like snowflake , Databricks etc. airflows should just be telling run this at 3am in morning and mark success else make the DE life a mess with failure emails.",
          "score": 3,
          "created_utc": "2026-01-21 10:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vtd9o",
              "author": "alittletooraph3000",
              "text": "I too would love to understand when it makes sense to run compute in Airflow ...",
              "score": 2,
              "created_utc": "2026-01-21 16:51:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0snpuv",
          "author": "nyckulak",
          "text": "I work at a super small company and everything I do runs in containers, so every DAG is its own container. It‚Äôs just a lot easier to maintain and debug, and I don‚Äôt see it as much of an overhead.",
          "score": 2,
          "created_utc": "2026-01-21 03:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ss6zs",
          "author": "thickmartian",
          "text": "We do leverage PythonOperator for light/orchestration/formatting scripts. Any heavier Python work is done outside of Airflow.",
          "score": 2,
          "created_utc": "2026-01-21 04:23:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ssqb0",
          "author": "Fine_Art6449",
          "text": "i am newbie in airflow but in my company they are running airflow through EKS, is there any learning material to understand these types of deployments ?",
          "score": 2,
          "created_utc": "2026-01-21 04:27:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u4e3o",
          "author": "ludflu",
          "text": "you are 100% correct. doing the actual work in a python operator doesn't scale because it runs on airflow's compute. It can work for small things, but its bad practice and will backfire as soon as real load is placed on it.",
          "score": 2,
          "created_utc": "2026-01-21 11:16:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sql75",
          "author": "git0ffmylawnm8",
          "text": "My company uses venv operators, but I don't think we've ventured into remote execution with Kubernetes",
          "score": 1,
          "created_utc": "2026-01-21 04:13:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tgwlx",
          "author": "lupine-albus-ddoor",
          "text": "Love this idea - splitting orchestration away from the pipelines jsut makes everything cleaner. Sounds like you building a pipeline engine that stays pretty independent from each pipeline‚Äôs logic, which is the right direction.\n\nI just might have to nick this one, mate Will give credits to the BeardedYowie 8-)",
          "score": 1,
          "created_utc": "2026-01-21 07:38:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ti19l",
          "author": "Whatiftheresagod",
          "text": "For really heavy work we host our own api and run the code there. In this case Airflow is only orchestrating it by calling exposed endpoints.",
          "score": 1,
          "created_utc": "2026-01-21 07:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0un693",
          "author": "Hofi2010",
          "text": "I agree with your approach outsourcing the compute to a something like ECS or kupernetes (if you already have and know how to work with it). Reason is that the PythonOperator, as many noted, runs on airflow compute (workers) and depending on what compute engine airflow sits on this doesn‚Äôt scale well for big data volumes. For small things it is fine, but not for reliable production. Airflow uses a central requirements.txt file so managing all the different library versions and conflicts is nightmare and requires a lot of discipline. Using airflow purely as an orchestrator and execute on Faragate for example gives everyone a lot more flexibility and decouples Python dependencies from the workers. It also allows you to use any programming language you prefer.  if you are using MWAA, managed airflow on AWS, it will not allow you to install any dependency you want, mostly pure Python libraries or it gets complicated quickly.\n\nLong story short, outsourcing you compute to WCS or other compute and just use airflow for orchestration leads to a much more stable airflow. A lot of companies are doing this as best practice now.",
          "score": 1,
          "created_utc": "2026-01-21 13:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w2m7c",
          "author": "joaocerca",
          "text": "In the case of the small team I belong to, I use mainly to orchestrate pipelines of containers. We have only an aws ec2 instance. Cron jobs were not granular enough for what I needed, so I shifted some of those scripts to Airflow.\n\nThere is no computation there, just tasks to send notifications and containers to get data, transform it and send it to other places. And usually, I try to separate those too. A container to extract, another to transform and another send it somewhere.\n\nI am quite happy with it, no need for kubernetes. It would be overkill for our purposes.",
          "score": 1,
          "created_utc": "2026-01-21 17:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wakgs",
          "author": "iMakeSense",
          "text": "If you run things using the Python Operator, and there are multiple people doing multiple things on it, eventually you're going to have pip dependency clashes when someone wants to do something new. You also can do things like fill up space on a limited instance, use up too much cpu power, etc. You'd then have to scale up your node running Airflow. Which is dumb.\n\nNot everyone with a senior title thinks these things through. Some people get promoted for other reasons.   \n  \nIf you run things in ephemeral containers, it's the better practice, but it's a bit more overhead and headache depending on what devops or IT at your company is like. So most people in a hurry spin up Airflow and just wanna get something done because they're coming from running a cron job or what have you on a server or they don't read the goddamn docs or they're more objective focused because agile, KPIs, etc. Which...makes sense. People only care about things when they break. They don't want to pre-maturely optimize ( read, do the suggested best practice ) w/ something when they don't have to.\n\nI'd say, let it break first. Or give it an incentive to break. Then be the savior. Until then, monitor the machine it's running on.",
          "score": 1,
          "created_utc": "2026-01-21 18:08:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xco4h",
          "author": "geoheil",
          "text": "You might find https://georgheiler.com/event/magenta-data-architecture-25/ interesting. But this is way more than just a tool and best practices. \n\nAlbeit this is more about dragster the concepts are the relevant part and you can implement them also with something else",
          "score": 1,
          "created_utc": "2026-01-21 20:58:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y0g5r",
          "author": "No-Theory6270",
          "text": "`from cosmos import DbtTaskGroup`",
          "score": 1,
          "created_utc": "2026-01-21 22:50:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y9kbj",
          "author": "DataObserver282",
          "text": "Use a normal operator for Kubernetes. How much data are you moving? If at scale, would def seperate orchestration from pipelines. I‚Äôm not a fan of overtooling but for complicated pipelines ETL tools can be your friend.",
          "score": 1,
          "created_utc": "2026-01-21 23:38:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yos2c",
          "author": "Syneirex",
          "text": "We use it entirely as an orchestration tool, where everything is containerized and runs on Kubernetes.\n\nWe are running multiple environments in multiple clouds‚Äîthis approach has worked well for us.",
          "score": 1,
          "created_utc": "2026-01-22 01:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uavp1",
          "author": "mRWafflesFTW",
          "text": "Most people give bad airflow advice. Airflow is just a python application like any other. If you treat it like any other app, you'll be fine. Does the complexity of splitting your application into multiple services and executing them on kubernetes make sense for your use case? 99 percent of the time the answer is fuck no.\n\n\nMost firms can't handle properly version Python applications, so they probably can't handle the complexity of running Airflow as a \"distributed kubernetes service\".\n\n\nKeep it simple unless you have a good reason not to or the institutional engineering ability to go for the hard fun stuff first.",
          "score": 1,
          "created_utc": "2026-01-21 12:06:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qha2l9",
      "title": "Context graphs: buzzword, or is there real juice here?",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/2s01b45qvbeg1.jpeg",
      "author": "Berserk_l_",
      "created_utc": "2026-01-19 17:10:57",
      "score": 53,
      "num_comments": 15,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qha2l9/context_graphs_buzzword_or_is_there_real_juice/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0j2xof",
          "author": "kthejoker",
          "text": "To help everyone\n\nThere are (at least) two types of problems in the world of business.\n\nOne is measurement / analysis. This is things like \"how much did we sell last month?\" These are solved by data. databases, warehouses, SQL, BI, semantic layers. \n\nThe other one is process / logic / workflow. This is things like \"what sales actions should I take with this customer over the next 3 months to improve my chances of a win?\" Or \"what data should I use to answer this question?\"  These are solved by different kinds of data, usually qualitative in nature - metadata, documents, runbooks, applications, code, vector searches, RAG, and graphs. \n\n\"Context graph\" is a buzzword - it's just a graph database, the same ones we've had for 40+ years. The \"context\" just describes its purpose - a tool for providing context to AI models and agents.\n\nOffloading context, just like offloading data catalogs and other tools, help AI agents by preventing them from hallucinating, drifting, or getting context overload.\n\nJust like we don't expect an airline pilot to handle all measurement, observation, and emergency procedures themselves, we give them accurate dashboards, runbooks, and a support crew to help them achieve their tasks.\n\nData engineering obviously has a role in both problems in terms of investing, transforming, and managing data into data warehouses and graph databases.",
          "score": 41,
          "created_utc": "2026-01-19 19:19:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nmsar",
              "author": "Vemyx",
              "text": "so it's kind of like accounting vs financial modelling/investment banking",
              "score": 2,
              "created_utc": "2026-01-20 12:32:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ilcwy",
          "author": "ResidentTicket1273",
          "text": "I've heard people muttering about context graphs, but nobody's been able to define it for me. I know about knowledge graphs, and am wondering if a context graph is where you apply a knowledge graph in order to feed more contextually appropriate content to an LLM than an equivalent vector-database equipped RAG search would normally do - but it can't just be that.",
          "score": 28,
          "created_utc": "2026-01-19 18:01:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ilyw4",
              "author": "MakitaNakamoto",
              "text": "no, it is literally what you just described\n\nlook up AI ontologies and how to operationalize them, most of the time it's a knowledge graph + connection to company database and AI agents",
              "score": 20,
              "created_utc": "2026-01-19 18:04:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0io4kq",
                  "author": "ResidentTicket1273",
                  "text": "OK, in which case, it sounds like a rebranding of what (at least I thought) used to be called \"Graph-RAG\"!",
                  "score": 22,
                  "created_utc": "2026-01-19 18:14:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0j2phl",
              "author": "recursive_regret",
              "text": "So a knowledge graph is metadata about the data? I‚Äôm still so confused on what it is and now throwing in context graph I‚Äôm one layer deeper into confusion",
              "score": 3,
              "created_utc": "2026-01-19 19:18:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jw4m6",
                  "author": "kthejoker",
                  "text": "A graph is a graph. Nodes connected by edges.\n\nYou can have a graph of the people you know and how they know each other - a social graph.\n\nYou can also have a graph of all the data sources you have and how they're related to each other - this is a \"knowledge\" graph. \n\nIt may also include information about people (who uses, owns, manages the data), business context (is the data confidential, audited, what problems does it solve, when is it updated), and so on - then it becomes more like a \"context\" graph.\n\nAgain, nothing new. Just finding value in graph database technology as it relates to helping AI focus on what it's good at (high quality generation / imitation) and offload what it's bad at (deep context, computation, retrieval) to tools.",
                  "score": 5,
                  "created_utc": "2026-01-19 21:37:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0o1g37",
                  "author": "ResidentTicket1273",
                  "text": "It can be lots of things, but whenever anyone (or anything) is decoding some text (say in the middle of a conversation) a great deal of that decoding is dependent on the sender of the text and the receiver of the text sharing a common context. That context might start with the language being used (both in terms of actual language, and the specifics of the vocabularies or dialects each understands), the time of day, situational context, intentional context, the assumed roles of each of the communicating parties, and their respective understanding of the world. \n\nIf I ask someone a question, their ability to provide a meaningful answer is going to largely revolve around how closely they can frame their mental context to match mine. There's often a bunch of implicit stuff that's really important in doing that, and a graph is a super-flexible way of encoding data such that it can be applied across multiple contexts to build a temporary contextual framing in which to parse a given message.\n\nLots of humour revolves around the surprise and embarrassment that occurs when one person frames their response to a message in a different context to that of the other person.",
                  "score": 2,
                  "created_utc": "2026-01-20 14:00:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jzffa",
          "author": "Gators1992",
          "text": "The meta for llms changes every week, so don't get two freaked out about it.  \n\nBusiness context is usually captured with either RAG or graphs.  RAG uses a vector similarity search algorithm to look up related information and graphs rely on nodes and edges to connect relationships in your data.  Basically look at how Neo4j works.  They have been talking about the graph approach for a while, but barriers are how your data is organized/tagged as it's less effective the fewer relationships you have.  That's not easy to establish depending on what your metadata looks like.  Also massive graph dbs tend to not be that performant.  \n\nYou can still get pretty good results with them, especially for document search use cases or something like that.  But there are also people talking about how tensor based LLMs are limited and not going to get us to the promised land and the next step might be difusion models or something else.  AWS also was talking about how they are maxing out what they can do with generic LLMs in training and how they could be more effective if they had access to actual business data to train on (not going to happen).  Agentic systems are the current hot thing where you can create \"tools\" for the LLM to use based on the context.  Like if a user asks an accounting question, the LLM can call an accounting agent that might have textual, RAG or graph resources to answer the call.  \n\nIt's interesting but also infuriating that there are so many approaches and the \"best\" approach changes almost weekly.  It's still very early in AI development so I guess I would say don't freak out about learning one thing as it will likely change, but definitely do get into working with AI is future work will depending on it.  It's not going away.",
          "score": 6,
          "created_utc": "2026-01-19 21:53:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k8bou",
          "author": "ANGRYLATINCHANTING",
          "text": "Sounds like GraphRAG rebranded, tbh.",
          "score": 1,
          "created_utc": "2026-01-19 22:37:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t9131",
          "author": "Ok-Canary-9820",
          "text": "Old tech rebranded with new application. Tradeoffs, just like any other.",
          "score": 1,
          "created_utc": "2026-01-21 06:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19zp00",
          "author": "klumpbin",
          "text": "Context graphs are the apex predator of the modern data stack. By leveraging a hyper-scalable, multidimensional architecture, they unlock the latent potential of your unstructured data silos, transforming static touchpoints into a living, breathing ecosystem of actionable intelligence.\nThe Strategic Pillars of Context Graphing\n * Semantic Interoperability: We‚Äôre moving beyond flat-file legacy systems into a graph-native paradigm that facilitates seamless cross-functional transparency.\n * Predictive Synthesis: By mapping the relational DNA of every node, your enterprise can achieve a 360-degree holistic view that is both proactive and boundaryless.\n * Cognitive Agility: This isn't just about connectivity; it's about context-aware liquidity that empowers stakeholders to pivot at the speed of thought.\n> \"To win in the post-digital era, you need to stop managing data and start curating relationships via a robust, cloud-agnostic context fabric.\"\n> \nEssentially, it's about disrupting the status quo to drive exponential value-add through a unified, high-fidelity neural map of your entire business gravity.",
          "score": 1,
          "created_utc": "2026-01-23 17:53:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfmrd6",
      "title": "Clickhouse launches managed PostgreSQL",
      "subreddit": "dataengineering",
      "url": "https://clickhouse.com/cloud/postgres",
      "author": "vaibeslop",
      "created_utc": "2026-01-17 19:42:24",
      "score": 48,
      "num_comments": 11,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qfmrd6/clickhouse_launches_managed_postgresql/",
      "domain": "clickhouse.com",
      "is_self": false,
      "comments": [
        {
          "id": "o07g90j",
          "author": "TripleBogeyBandit",
          "text": "But why? Isn‚Äôt their whole product pitch ‚ÄúOLAP at the speed of OLTP‚Äù? Curious what use cases this aids.",
          "score": 22,
          "created_utc": "2026-01-18 00:49:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08yxaz",
              "author": "noswag15",
              "text": "I think this caters to both olap and oltp. Seems like it automatically replicates the data from postgres to clickhouse and any anayltical queries fired on the postgres db gets routed to the clickhouse instance so you get the best of both worlds. Atleast that's what I gleaned from a cursory look at the link in OP.",
              "score": 10,
              "created_utc": "2026-01-18 06:21:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a6b2w",
                  "author": "LemmyUserOnReddit",
                  "text": "Worth mentioning that none of this is new, except for them hosting the PG instance",
                  "score": 3,
                  "created_utc": "2026-01-18 12:46:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bud2t",
                  "author": "saipeerdb",
                  "text": "Thanks for chiming in. This captures the overall vision  well. You are spot on. It caters to both OLTP and OLAP, bringing together the best-in class OSS databases for each (Postgres and ClickHouse) and offering them in the most integrated way. We‚Äôve seen many thousands of companies use Postgres and ClickHouse to build their data stacks, and the adoption is growing very fast. The idea behind this Postgres offering is to bring them even closer together and make that integration as effortless as possible for developers. :)\n\nWith regard to integration, the vision behind our CDC capabilities is to offer a much more native experience, something you can‚Äôt get from other services and addresses problems around standard CDC. Additionally, the `pg_clickhouse` extension will be native to this service and maintained by ClickHouse, and will act as a unified query layer for both transactional and analytical workloads. We plan to invest heavily in this area to make application migration as seamless as possible.\n\nApart from all of this, the Postgres we are offering is NVMe-backed, which is very fast and comes enterprise-grade guarantees. We are building this in partnership with a world-class Postgres team at Ubicloud who were ex-Citus, Heroku, Microsoft Postgres.\n\nThis launch was a primer, stay tuned for a more very soon! :)",
                  "score": 3,
                  "created_utc": "2026-01-18 18:02:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09guk1",
              "author": "Competitive_Layer_71",
              "text": "I don't think the replication is at all that interesting: you can set that up with any provider. \n\nThe killer feature is if the cross-querying is easy: joining a Postgres dataset with a ClickHouse dataset *without* CDC.\n\nIt should be noted that even if pg_clickhouse exists you'd basically have to self host Postgres to get at it. But very few *want* to self host Postgres.",
              "score": 4,
              "created_utc": "2026-01-18 09:01:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09qex4",
              "author": "Creative-Skin9554",
              "text": "Their pitch is being the fastest OLAP database. It still doesn't do OLTP. Speed is irrelevant to that, OLTP and OLAP are different things. Most people still end up with Postgres and ClickHouse inside their business to handle both sides, and now you can buy both from the same vendor.\n\nIf ClickHouse sees that most of their customers are also buying Postgres, why wouldn't they want to be the one selling it to you?",
              "score": 3,
              "created_utc": "2026-01-18 10:30:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o07ssc6",
              "author": "RemoteLifeguard8208",
              "text": "Pretty sure snowflake did a similar thing and I wondered the same thing",
              "score": 2,
              "created_utc": "2026-01-18 01:55:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o084kxu",
                  "author": "TripleBogeyBandit",
                  "text": "Snowflake and databricks, but it makes more sense to server faster workloads in these environments.",
                  "score": 2,
                  "created_utc": "2026-01-18 02:59:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08mpqb",
          "author": "McNemarra",
          "text": "only makes sense when you see\n\n1. NVMe performance\n\n2. Availability guarantees",
          "score": 2,
          "created_utc": "2026-01-18 04:49:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mgzci",
          "author": "colorcat_v",
          "text": "Great job!",
          "score": 2,
          "created_utc": "2026-01-20 06:28:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07xu78",
          "author": "BarfingOnMyFace",
          "text": "Nice",
          "score": 2,
          "created_utc": "2026-01-18 02:22:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qklwjw",
      "title": "DataFrame or SparkSQL ? What do interviewers prefer ?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qklwjw/dataframe_or_sparksql_what_do_interviewers_prefer/",
      "author": "SnooCakes7436",
      "created_utc": "2026-01-23 08:59:41",
      "score": 47,
      "num_comments": 29,
      "upvote_ratio": 0.94,
      "text": "I am learning spark. And i just needed clarity on what does interviewers prefer in interviews ? Irrespective of what is used in the companies while actual work. \n\nDataFrame or SparkSQL ?",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qklwjw/dataframe_or_sparksql_what_do_interviewers_prefer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o17ho4y",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-23 08:59:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17lieh",
          "author": "eccentric2488",
          "text": "Driver, executors\nLazy evaluation \nTransformations, Actions\nStages\nNarrow and wide transformations\nShuffles\nDAG, data skew, partitioning\n\nThese are the topics that matter for Spark in interviews.",
          "score": 69,
          "created_utc": "2026-01-23 09:36:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o181jxi",
              "author": "Mean_Elderberry7914",
              "text": "Add salting and bucketing if you truly want this job.",
              "score": 14,
              "created_utc": "2026-01-23 11:53:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o188iy0",
                  "author": "azirale",
                  "text": "If you're going to talk about salting you'd better be able to walk me through the tradeoffs and limitations because I've seen too many people handwave it as some magic solution to skew. Some of the \"explanations\" I've had for it have completely missed the mark on how it actually works and presented broken solutions.",
                  "score": 8,
                  "created_utc": "2026-01-23 12:42:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cn7yk",
                  "author": "Expensive_Culture_46",
                  "text": "Why does everything in data fields just sound like some is having a stroke and screaming random words. \n\n‚ÄúFam parm chess the potato then hammer to toadstool‚Äù\n\n‚ÄúSir are you ok? Do I need to call a doctor‚Äù\n\n‚ÄúOh no. I‚Äôm just a data professional‚Äù",
                  "score": 1,
                  "created_utc": "2026-01-24 01:45:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17ijsz",
          "author": "merrpip77",
          "text": "For me, it doesn‚Äôt really matter. I was on the interviewing side a couple of times. While personally, I usually prefer sparksql for structured data, if the candidate is capable of solving issues either way that‚Äôs what matters most. Probably it depends on the company‚Äôs standards later on, but not at the interviewing stage",
          "score": 15,
          "created_utc": "2026-01-23 09:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17jf59",
          "author": "Dawido090",
          "text": "More dataframe but both are valid, if you can't do one but can another then doesn't matter",
          "score": 6,
          "created_utc": "2026-01-23 09:16:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19qo0d",
          "author": "xmBQWugdxjaA",
          "text": "It doesn't matter, but you should be able to use both.",
          "score": 3,
          "created_utc": "2026-01-23 17:11:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17oc4j",
          "author": "Capt_korg",
          "text": "I guess it is important to highlight when to use what. \n\nI mean between dataframes and SQL are architectural differences and both shine in different usages.\n\nWhile dataframes shine in their programmatic way, with chaining, validating, etc.\n\nSQL shines in their parsing nature, with i.e. window functions, complex joins, CTEs...\n\nIt is important to stick mainly with one API and not mix too much!",
          "score": 4,
          "created_utc": "2026-01-23 10:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17u9kl",
              "author": "Altruistic_Stage3893",
              "text": "I usually tell my juniors to use dataframe for simpler stuff, ctes for complex shenanigans as they are inherently more readable. but ultimately it doesn't matter as you an make mess with each",
              "score": 2,
              "created_utc": "2026-01-23 10:54:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18raum",
                  "author": "Capt_korg",
                  "text": "True, it doesn't matter, how to get there...",
                  "score": 1,
                  "created_utc": "2026-01-23 14:26:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1861c2",
          "author": "ThroughTheWire",
          "text": "depends on the company and the interviewer. I got dinged negatively during an interview with a larger tech company that had people who ONLY worked with dataframe transforms even though sparksql evaluates pretty much the same in an interview context because they rarely worked with sql. you have to read the room/interviewer unfortunately.\n\npersonally I'd be cool with either but try to understand what the interviewers preference is, if any",
          "score": 1,
          "created_utc": "2026-01-23 12:25:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o187gal",
          "author": "Unlucky_Data4569",
          "text": "Sql is better to learn because it translates more to writing sql for actual dbs from a interview prep efficiency standpoint. The interviewer probably won‚Äôt care",
          "score": 1,
          "created_utc": "2026-01-23 12:35:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18abmh",
          "author": "dataflow_mapper",
          "text": "Most interviewers care less about which one you type and more about whether you understand what Spark is doing under the hood. Being comfortable with the DataFrame API is usually expected since it is more flexible and composable, but you should also be able to read and reason about SparkSQL because a lot of real pipelines mix both. A good answer in interviews is often explaining how the two map to the same execution engine and when you would prefer one for readability or maintainability. If you can show that you understand query planning, shuffles, and performance tradeoffs, the syntax choice becomes secondary.",
          "score": 1,
          "created_utc": "2026-01-23 12:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18r7jo",
          "author": "eccentric2488",
          "text": "Add catalyst optimizer and tungsten execution engine to it. After writing transformation logic and before calling actions like show or count, use df.explain(true). Practice reading logical and physical plans for your transform logic. It helps in interviews.",
          "score": 1,
          "created_utc": "2026-01-23 14:26:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18xe6d",
          "author": "Resquid",
          "text": "Depends",
          "score": 1,
          "created_utc": "2026-01-23 14:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18swtc",
          "author": "dukeofgonzo",
          "text": "I only give input to hiring, not actually make any hiring decisions at my job. I would prefer a candidate that is stronger with dataframes than SparkSQL. My coworkers who are stronger with SQL are not as adept programmers as they are SQL analysts. The coworkers I have who prefer using dataframes are much more comfortable with programming concepts than the SQL faction. They behave more like engineers than database administrators. That's my anecdotal dataset.",
          "score": 0,
          "created_utc": "2026-01-23 14:34:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1a455i",
              "author": "SnooCakes7436",
              "text": "And why do you think that is ?",
              "score": 1,
              "created_utc": "2026-01-23 18:12:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1cks3v",
                  "author": "iamnotapundit",
                  "text": "We discussed this on my team this morning (within the context of Cursor and where type systems and inspection midway really can help). \n\nBasically, the DataFrame API is python through and through. They means refactoring it into functions and parameterizing portions of a pipeline fit naturally. Doing the same completely in SparkSQL requires string formatting and permutations, which is just more fragile. \n\nWe landed at any reusable code should be DataFrames and not string formatting a block of sql. Top level stuff can be SparkSQL.",
                  "score": 1,
                  "created_utc": "2026-01-24 01:31:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17le6d",
          "author": "liprais",
          "text": "they are more or less the same thing.Asking of this implies lack of knowledge.",
          "score": -7,
          "created_utc": "2026-01-23 09:35:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17mrik",
              "author": "SnooCakes7436",
              "text": "I know they are same but the syntaxes are different. And from the person i am learning from says interviewers will ask you to solve problems using DataFrame only and will ask you to not use SparkSQL\nThat is why i just wanted to confirm of that is true.",
              "score": 1,
              "created_utc": "2026-01-23 09:47:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o17pneg",
                  "author": "liprais",
                  "text": "he is nuts and i suggest distance from him",
                  "score": 2,
                  "created_utc": "2026-01-23 10:14:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17iads",
          "author": "cmcclu5",
          "text": "For data engineering technical interviews, I‚Äôm generally asked less about the high level libraries like that and more about my general understanding of Python like iterating over dictionaries versus sets versus lists, or how recursion can be optimized. Lower level understanding (Python isn‚Äôt a low level language) is WAY more important than knowing library syntax. If you understand why iterating over a list is significantly worse than iterating over a set, you‚Äôre halfway there.",
          "score": -7,
          "created_utc": "2026-01-23 09:05:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17j8hs",
              "author": "MlecznyHotS",
              "text": "Ok, I feel like an idiot asking having been programming in Python for almost 8 years now, but why is iterating over a list worse than iterating over a set?",
              "score": 7,
              "created_utc": "2026-01-23 09:14:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o17jsqs",
                  "author": "cmcclu5",
                  "text": "A set is hashed, a list is not. That‚Äôs the simplest explanation. Run a timing test with cprofile to see the difference.",
                  "score": -8,
                  "created_utc": "2026-01-23 09:19:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o189kil",
              "author": "azirale",
              "text": "> If you understand why iterating over a list is significantly worse than iterating over a set, you‚Äôre halfway there.\n\nThis sounds entirely absurd, you're going to have to back this up with something.\n\nAs mentioned elsewhere a list is essentially an array in the background with contiguous blocks of memory. It is the simplest and fastest structure for iterating through provided values.\n\nThe hashing of a set is irrelevant to iterating over all the values. The hash allows for bucketing so that with the hash you can jump to sublists that are much smaller, allowing for faster operations that check for presence of a value, but that's not relevant to iterating over all values.\n\nIs there some deep lore in cpython this relates to? Or did you simply misspeak here?",
              "score": 1,
              "created_utc": "2026-01-23 12:48:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qh6wo1",
      "title": "Crippling your Data Engineers",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qh6wo1/crippling_your_data_engineers/",
      "author": "LargeSale8354",
      "created_utc": "2026-01-19 15:18:34",
      "score": 40,
      "num_comments": 10,
      "upvote_ratio": 0.95,
      "text": "I'm working as a contractor for a client where I have to log onto a GDE terminal. The window size is fixed and the resolution is probably 800x600.\nYou can't copy/paste between your host and the GDE so be prepared to type a 24character strong password. Session time outs are aggressive so expect to type this a lot.\n\nGDEs are notoriously slow. This one sets a new record. The last time I saw something this slow was when I had to use an early Amstrad laptop with dial up modem to connect to an HP3000 mini computer. In 2026, I've been assigned kit that wasn't impressive in 1989.\n\nI'd love to know the justification for this fetid turd of an environment.",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qh6wo1/crippling_your_data_engineers/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0hljqb",
          "author": "Reach_Reclaimer",
          "text": "They don't want you working in their systems by the sounds of it",
          "score": 34,
          "created_utc": "2026-01-19 15:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i78xb",
          "author": "Thinker_Assignment",
          "text": "What I learned from freelancing in enterprise: when the business model already works, the incentive is to prevent further changes, not to enable change.\n\nLooks like you won't be changing sh\\*t on that project.",
          "score": 10,
          "created_utc": "2026-01-19 16:58:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hq6av",
          "author": "Omar_88",
          "text": "Take the W and just work as well as you can. You're getting paid a nice day rate.",
          "score": 23,
          "created_utc": "2026-01-19 15:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i61ci",
          "author": "LargeSale8354",
          "text": "Some of the tools on the GDE have modal interfaces that are too big for the GDE screen resolution with critical controls off screen.\nThe Tab key doesn't help here either",
          "score": 7,
          "created_utc": "2026-01-19 16:52:44",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0parzq",
              "author": "Thinker_Assignment",
              "text": "I hope you feel resigned rather than angry, for your own sake. Imagine a troll did this.",
              "score": 2,
              "created_utc": "2026-01-20 17:39:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ph5x9",
                  "author": "LargeSale8354",
                  "text": "Very much so. I've seen variations of this in larger financial institutions.  The typical profile is\n1. They've got a monopoly shared with 3 or 4 key players \n2. They treat their customers with arrogance and disdain.\n3. They know the cost of everything and the value of nothing \n4. They have legions of people whose only role seems to be the perpetuation of bureaucracy\n5. They've got bizarre status perks. Exec loos get a different class of toilet paper, that sort of thing.",
                  "score": 1,
                  "created_utc": "2026-01-20 18:08:33",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ifycd",
          "author": "TheOverzealousEngie",
          "text": "I had that happen to me once, the interface they gave me such low res that you could barely read the fonts, so I went into the MONITOR settings and adjusted the resolution and make it 150x better. When my manager came over she nearly had a heart attack, she was furious. I thought I was fired. But she warned me .. touch nothing, make nothing better. Working in a corporate environment is quite different.",
          "score": 3,
          "created_utc": "2026-01-19 17:37:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgcog8",
      "title": "Order of Books to Read: (a) The Data Warehouse Toolkit, (b) Designing Data-Intensive Applications, (c) Fundamentals of Data-Engineering",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qgcog8/order_of_books_to_read_a_the_data_warehouse/",
      "author": "queued_queue",
      "created_utc": "2026-01-18 16:15:27",
      "score": 38,
      "num_comments": 14,
      "upvote_ratio": 0.95,
      "text": "For someone who wants to enter the field and work as a data engineer this year, whose skills include basic SQL and (watched some) Python (tutorials), in what order should I read the books stated in the title (and why)? Should I read them from cover to cover? If there are better books/resources to learn from, please state those as well. Also, I got accepted in the DE Zoomcamp but I still have not started on it yet since I got so busy.\n\nThanks in advance!",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qgcog8/order_of_books_to_read_a_the_data_warehouse/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0b8mhs",
          "author": "Ok-Recover977",
          "text": "C, A, and then B only if your role deals with architecture or if you want your career to go in that direction.",
          "score": 12,
          "created_utc": "2026-01-18 16:19:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ft1lt",
              "author": "queued_queue",
              "text": "thanks!",
              "score": 2,
              "created_utc": "2026-01-19 07:19:43",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0bv69x",
              "author": "paxmlank",
              "text": "Sucks for me because I started with B and haven't touched the others",
              "score": 3,
              "created_utc": "2026-01-18 18:06:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0e42lk",
          "author": "joins_and_coffee",
          "text": "If you‚Äôre like new to DE, I wouldn‚Äôt read them cover to cover in one go. They serve different purposes. I‚Äôd start with fundamentals of data engineering to get a broad mental model of the field and the vocabulary. Then read The Data Warehouse Toolkit selectively focus on dimensional modeling and skip deep dives that won‚Äôt make sense yet without real projects. Designing Data Intensive Applications is excellent, but it‚Äôs more of a ‚Äúwhy things work this way‚Äù book, so it lands better once you‚Äôve built or broken a few pipelines. Zoomcamp will honestly teach you more faster than passive reading, so I‚Äôd prioritize that and use the books as references alongside it. Build something, hit a wall, then read the relevant chapters that tends to stick much better than linear reading",
          "score": 5,
          "created_utc": "2026-01-19 00:48:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0g2lgl",
              "author": "queued_queue",
              "text": "Hey, this is great advice. thank you!",
              "score": 2,
              "created_utc": "2026-01-19 08:46:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0g1955",
          "author": "okaycompuperskills",
          "text": "FYI B & C are available on Spotify as audiobooks (included with paid subscriptions)¬†\n\nI found it useful to listen to them to get an overview, but then also have the physical book as a reference",
          "score": 3,
          "created_utc": "2026-01-19 08:34:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0g2gzt",
              "author": "queued_queue",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-01-19 08:45:33",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0lkxml",
              "author": "HotSpecific3486",
              "text": "Hey, can you give a link or something. I tried searching, but all I  was able to find only the podcast.",
              "score": 1,
              "created_utc": "2026-01-20 02:59:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0m5qk6",
                  "author": "okaycompuperskills",
                  "text": "https://open.spotify.com/show/0hDOOflMW9WIQ0EONEcJsU\n\nhttps://open.spotify.com/show/7zFPhQeul3ct7iGluDXnIf\n\nI‚Äôm in the uk though might be a rights thing¬†\n\nCan you share the podcast? Sounds interesting¬†",
                  "score": 2,
                  "created_utc": "2026-01-20 05:03:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fr2rp",
          "author": "One_Citron_4350",
          "text": "I'd recommend starting with c then a. It gives you such a good overview about the field. b is a little different than other books since it doesn't focus on the data engineer's work especially when you are starting your career. It's more about how to think about systems, design decisions, tradeoffs, it primarily focuses on *architecture* of data systems and the ways they are integrated into data-intensive applications",
          "score": 2,
          "created_utc": "2026-01-19 07:02:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ft27x",
              "author": "queued_queue",
              "text": "thank you!",
              "score": 2,
              "created_utc": "2026-01-19 07:19:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0b7pd7",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-18 16:15:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t30lj",
          "author": "SlappyBlunt777",
          "text": "I bought all these books several years ago and have skimmed them. I‚Äôve read C the most. I work for medium sized manufacturing firm and I am by far the most ‚Äúdata engineer‚Äù type of guy but it‚Äôs just not  that deep per the content in these books (it can be if I had the resources to)! We do have plant systems that sit on time series historian. I can pay a few k for a class on that. I‚Äôm also big on erp, costing and financial reporting (P&L / B&S) a business technology generalist. I constantly struggle with delving into the path of those books versus just keeping one foot in the cfo and IT circle.",
          "score": 1,
          "created_utc": "2026-01-21 05:40:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkxr5q",
      "title": "Candidates using AI",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qkxr5q/candidates_using_ai/",
      "author": "DataEngineer2026",
      "created_utc": "2026-01-23 17:53:22",
      "score": 38,
      "num_comments": 82,
      "upvote_ratio": 0.86,
      "text": "I am a data engineering manager and we are looking for a senior data engineer. So many times we see a candidate that looks perfect on paper, HR has a great conversation with them, then we do a technical Teams call and find that the candidate is using some kind of AI (or human) assistance - delayed responses, answers that are too perfect or very general, sometimes very obvious reading from the screen or listening through the headphones, and some (or complete) inability to write code during the test. \n\nIs there a way to filter out these candidates ahead of time, so we don't have to waste time on it? We don't mind that the team members use AI to be more productive and we even encourage it, but this is just pure manipulation, and definitely not what we are looking for.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qkxr5q/candidates_using_ai/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1azic5",
          "author": "FreeMeson",
          "text": "Its kind of frustrating as a senior data engineer that people are getting to technical interviews and I can't even get passed the AI resume filters.\n\nRecruiting needs to change in light of AI but I don't have any idea how.",
          "score": 73,
          "created_utc": "2026-01-23 20:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1boauf",
              "author": "lostinideas",
              "text": "I heard people are changing their entire CV's according to JD to be the \"perfect candidate\" as OP describes.\n\n\nFor the love of God of course not every company uses the exact tech stack. As long as people continue to look for perfect candidates they will find the ones most willing to lie.\n\n\nMost of the experience with the tools are transferrable skills, people needs talk about the concepts, problem solving and communication skills. But as far as my experience goes that's not common, I even experienced one guy asking about placement of the button on the specific tools interface. (Fortune 500 analytics manager :))",
              "score": 31,
              "created_utc": "2026-01-23 22:35:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bxwaf",
                  "author": "TA_poly_sci",
                  "text": "I personally suspect a decent amount of this issue arises from companies using non-technical staff in the initial screening process, resulting in the first selection being done by people who do not really have the knowledge to select beyond relying on specific keywords and direct matching to the position.",
                  "score": 13,
                  "created_utc": "2026-01-23 23:25:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cbv6f",
                  "author": "FreeMeson",
                  "text": "I'm doing a LinkedIn Premium trial and in the jobs section its allows you to use AI to update your resume for the JD. Its like an arms race of employers and applicants for AI. It fucking sucks. My current resume represents me and my experience, I don't want to memorize the 30 versions of my resume.\n\nNot sure where we go from here. I kind of want to stick with my current shit job just so I don't have to deal with the current job app system.\n\nI think only referrals will be meaningful going forward.",
                  "score": 3,
                  "created_utc": "2026-01-24 00:40:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ccsd9",
              "author": "Reach_Reclaimer",
              "text": "Have you even bothered to put your CV through an llm? I was passing a few but I after I put it through and looked at the responses, my ror went through the roof\n\nI'm not saying to copy and paste, but simply pinching a few things then updating goes a long way. Then you don't even need to find tune your CV for roles because it passes the initial AI and ATS checks",
              "score": 2,
              "created_utc": "2026-01-24 00:45:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cf8pk",
                  "author": "FreeMeson",
                  "text": "I've gone through my CV several times improving it, but I haven't used an LLM. I've thought about it for that reason, but I don't like the idea. I can tell when something is written by an LLM and seeing my CV like that would bother me. But I might need to play ball this job search.",
                  "score": 1,
                  "created_utc": "2026-01-24 00:59:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ak4ro",
          "author": "No_lych",
          "text": "Stop looking for the perfect candidate on paper, everyone that uses AI on screening will tailor a perfect resume based on the job description. You will find more \"real\" people when you look for almost perfect CV's",
          "score": 74,
          "created_utc": "2026-01-23 19:25:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bijp9",
              "author": "chipstastegood",
              "text": "got it, so ask the AI to select resumes that are ‚Äúalmost perfect‚Äù. lol. AI is everywhere",
              "score": 8,
              "created_utc": "2026-01-23 22:06:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bih7k",
              "author": "DataEngineer2026",
              "text": "I am not looking for perfect resumes, I am interviewing whoever HR recommends. I personally would prefer someone who doesn't necessarily have experience with the exact technologies we are using, but someone who is sharp, knows how to approach any problem and figure out a solution. Unfortunately there is no way to know that by looking at a resume. The only way is to interview them, hence the problem.",
              "score": 5,
              "created_utc": "2026-01-23 22:06:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bu2m4",
                  "author": "living_direction_27",
                  "text": "‚ÄúI‚Äôm interviewing whoever HR recommends‚Äù.\n\nI feel the problem starts here. When you hire for a technical position, you expect the resume to be also technical. Most of the time, you have experiences not with the same platforms or tools, but still very closely aligned to the job. However, HR almost always fail to see these transferable skills. \n\nThe reason is simple. HR are most often not technical people, and they search for keywords. If they don‚Äôt find it, they do not consider you. \n\nI find this extremely sad and frustrating.",
                  "score": 27,
                  "created_utc": "2026-01-23 23:05:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bz3dh",
                  "author": "SupermarketNo3265",
                  "text": "Why the fuck is HR choosing who you interview? That's your first problem right there.¬†",
                  "score": 13,
                  "created_utc": "2026-01-23 23:31:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1byu5q",
                  "author": "invidiah",
                  "text": "I don't know what company do you represent but in general people looking for the exact match in tools stack (unless it's FAANG). E.g. if I don't have 3 YoE with Snowflake listed in a job description, nobody would even talk with me, no matter of what. But it's just a tool that can be replaced with another warehouse/lakehouse solution such as Redshift, Databricks, selfhosted Iceberg, data swamp with Athena etc.  \nSo what you're saying is super uncommon, noone is hiring problem solvers of even Data Engineers, everyone is looking for %toolname% engineers.",
                  "score": 5,
                  "created_utc": "2026-01-23 23:30:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1ccthu",
                  "author": "babygrenade",
                  "text": "It's been almost 10 years since I've been in a hiring role, but even back then I found I was way better off telling HR to let me find my own candidates from the applicant pool.\n\nThe best candidates I got through a recruiting agency though.",
                  "score": 3,
                  "created_utc": "2026-01-24 00:45:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1amwji",
          "author": "g_m_j",
          "text": "We‚Äôve experienced the same during interviews‚Ä¶ Candidates giving unbelievably amazing responses on really niche (business specific) subjects.\n\nWe‚Äôre now doing on site interviews.",
          "score": 18,
          "created_utc": "2026-01-23 19:38:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bja35",
              "author": "Altrooke",
              "text": "This could be a could a strat to identify cheaters. \n\nThrow in 2\\~3 questions about some esoteric detail of a niche tool, that they could only realistically answer if they are cheating.",
              "score": 5,
              "created_utc": "2026-01-23 22:10:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1byhgq",
                  "author": "randomName77777777",
                  "text": "That's what I've done in the past. I got someone who my boss said was perfect, started asking niche questions and everything is spot on even about frameworks not related to data engineering. \n\nVery clearly using AI",
                  "score": 3,
                  "created_utc": "2026-01-23 23:28:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cn8ge",
                  "author": "ALonelyPlatypus",
                  "text": "Yep, if there is a projects section on the resume, asking them details on that tends to weed out cheaters.",
                  "score": 2,
                  "created_utc": "2026-01-24 01:45:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bitfs",
              "author": "DataEngineer2026",
              "text": "I wish we could, but our team is all over the country, so even the interviewers are not on site :)",
              "score": 1,
              "created_utc": "2026-01-23 22:08:14",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1bpqcy",
              "author": "Technical_Program_35",
              "text": "I like this",
              "score": 1,
              "created_utc": "2026-01-23 22:42:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1c8v7i",
              "author": "trafalmadorianistic",
              "text": "It just means the way we are doing interviews in 2026 is broken. If your interview can be gamed through automation, then your questions are useless.¬†",
              "score": 1,
              "created_utc": "2026-01-24 00:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cky9y",
                  "author": "alexmojo2",
                  "text": "For real what a boomer ass thread lol",
                  "score": 1,
                  "created_utc": "2026-01-24 01:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1a9v4e",
          "author": "Massive_Course1622",
          "text": "I haven't had to hire since widespread AI use, but my main question is what do these people have on their resume for working experience? Fake jobs, unrelated stuff, or nothing?",
          "score": 5,
          "created_utc": "2026-01-23 18:38:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b9a55",
              "author": "gjionergqwebrlkbjg",
              "text": "Fake jobs.",
              "score": 7,
              "created_utc": "2026-01-23 21:23:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bo0fu",
                  "author": "RevolutionaryGain823",
                  "text": "It‚Äôs fairly widespread that Indian folks will have fake jobs from home with real references I.e. the reference is an actual manager in a company who‚Äôs a family friend of the person or has just been paid to vouch for them even when they never worked at the company. There are entire companies that help Indian candidates get fake references, have someone feed them answers on an interview call off-screen etc. in exchange for either a flat fee or percentage of income from the job (like boot camps a few years ago lmao).\n\nI have multiple Indian mates who were offered this service when they 1st came to Europe looking for a job after graduating",
                  "score": 10,
                  "created_utc": "2026-01-23 22:33:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bds2d",
                  "author": "thelonely_stoner_",
                  "text": "This might seem like a dumb question.. but what do you mean fake jobs? Like folks are totally putting companies they never worked for or making up stuff they did just to fit the job description?",
                  "score": 2,
                  "created_utc": "2026-01-23 21:44:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1cdint",
              "author": "Commercial-Ask971",
              "text": "There is no background screening (I assume) in US? Living in Europe and in the process between HR and Tech interview most of companies would screen the background - simply call companies listed in CV and ask if you are legit",
              "score": 1,
              "created_utc": "2026-01-24 00:49:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bgarj",
          "author": "SRMPDX",
          "text": "Had very similar experiences. Before AI was being used widely it was ghost interviewers and people whispering answers or at least typing answers in a screen the interviewee could read. I've had catfishers interview then a different person onboards. It happens, we just need to be better at detecting and stopping it.  There will always be people who lie their way into jobs though. \n\nJust last week I interviewed a guy who seemed to be using AI to craft his answers. Although some answers were obviously not scripted, and he seemed to know what he was talking about, he still seemed like he was using an AI interview tool. After talking to some of the recruiters familiar with his region of the world it was apparent that this was VERY common and candidates felt they had to do it to stay competitive. \n\nWe had a follow-up interview where we told him that we all use AI tools in out jobs and that we can't fault anyone for using them, but we wanted to hear his answers unassisted. We made it clear that it was OK to say \"I don't know\" or \"I don't understand the question\". The interview went much better. There was some language barrier and he didn't understand all the questions as asked, but when clarified he was fine and gave good answers. When he didn't know something he said so. It turns out his resume was real, he did know what he was talking about. \n\nI think going forward we will address the use of AI, let them know it's ok for some aspects of their job and even for helping them interview. We also need to get good at asking the right questions. Not to \"trick\" the AI, or to somehow catch them in a lie, but to help us understand if they have the basic knowledge we're looking for.",
          "score": 6,
          "created_utc": "2026-01-23 21:56:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1b09ef",
          "author": "Global-War181",
          "text": "In person interviews are making a come back",
          "score": 4,
          "created_utc": "2026-01-23 20:41:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1b3klt",
          "author": "Kenny_Lush",
          "text": "A former manager was getting his MBA online and for tests they would have him take his camera and rotate it around the room, under the desk, etc. Might be a simple way to eliminate the giant LLM server sitting just out of view. I suppose another option is to start with a nonsensical question - AI loves to please so it will start to provide an ‚Äúanswer‚Äù and you can abort early. \n\nThis is fascinating when so many people around here complain about not getting interviews, while stories like this are so prevalent. Maybe focusing on less-than-perfect resumes is the answer.",
          "score": 4,
          "created_utc": "2026-01-23 20:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1belmc",
              "author": "BestNarcissist",
              "text": "If an applicant can't trick an AI into showing HR their resume, I don't want to hire them.",
              "score": -4,
              "created_utc": "2026-01-23 21:48:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ajzlu",
          "author": "lozbrown85",
          "text": "We had the same problem, we switched all technical interviews to be on prem. We get HR to tell them that from the off, lots of people drop out at the point they are told",
          "score": 12,
          "created_utc": "2026-01-23 19:24:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b0hkg",
              "author": "Global-War181",
              "text": "Oh so you migrated them from cloud to onprem‚Ä¶interesting",
              "score": 21,
              "created_utc": "2026-01-23 20:42:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bd0ze",
              "author": "SRMPDX",
              "text": "This works if you're hiring for an in-person or hybrid office. It doesn't work so well if you have people all over the world who are trying to hire other people all over the world for remote work.",
              "score": 3,
              "created_utc": "2026-01-23 21:41:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1amzkw",
          "author": "Treemosher",
          "text": "Can't imagine using AI for an interview.  That's fucking nuts.  \n\nMakes me feel like the competition is hamstringing itself at least.",
          "score": 3,
          "created_utc": "2026-01-23 19:38:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1a9et0",
          "author": "MikeDoesEverything",
          "text": "Prepare your anus for a lot of salty responses. People are ready to rage on you for not letting them use AI during the interview.",
          "score": 10,
          "created_utc": "2026-01-23 18:36:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bj0p5",
              "author": "DataEngineer2026",
              "text": "Nobody raged so far :)",
              "score": 2,
              "created_utc": "2026-01-23 22:09:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1bhmzm",
              "author": "Mindless_Let1",
              "text": "Who tf is going to complain about no ai during interview? \n\nIt's like complaining you're not allowed to hold the ball while playing football",
              "score": 2,
              "created_utc": "2026-01-23 22:02:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1axmww",
          "author": "ManiaMcG33_",
          "text": "We switched to white board style interviews. Walk me through how you would solve this problem, what similar projects have you worked on in the past. It was a better experience than prior interviews we did which allowed too much AI usage over a teams call.\n\nI have also heard of people mandating cameras be on telling a candidate to close their eyes before asking a question, lol. But that‚Äôs not very professional",
          "score": 2,
          "created_utc": "2026-01-23 20:28:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bd2ev",
              "author": "koteikin",
              "text": "I think you just gave me an idea to do blindfolded interviews",
              "score": 1,
              "created_utc": "2026-01-23 21:41:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cf6l2",
                  "author": "Commercial-Ask971",
                  "text": "Dont forget to put it on twitch and monetize!",
                  "score": 2,
                  "created_utc": "2026-01-24 00:58:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1aou7d",
          "author": "Fifiiiiish",
          "text": "I truly think use of AI should now be a discussion in the hiring process, as it is part of the job.\n\nAnd answering some questions with use of AI should not be a problem, as long as it is transparent and AI is cleverly used by the candidate, as it should be in job.\n\nLike the meme said, even the senior SW developer googles \"how to format a date in js\". Asking stupid stuff to AI is normal. Let people handle what AI can't.",
          "score": 7,
          "created_utc": "2026-01-23 19:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b1mf3",
              "author": "YakFull8300",
              "text": "No, because interviewers care about how you get to an answer and what your thought process is. Using AI is not a good evaluation of that. ",
              "score": 12,
              "created_utc": "2026-01-23 20:47:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bd3tg",
                  "author": "CorpusculantCortex",
                  "text": "Ai is now a part of that though. Like i agree that there needs to be better screening but to be fair there is no need to have niche coding structures in brain memory anymore. And 9/10 times data engineering is a task that takes time to reflect and build something related to the requirements gathered from colleagues, not whether you have an immediately impactful coding solution to something that can be solved in like 30 minutes. Its a mixed bag. People need to be checked before given the position, but there is also little evidence in ability to code a microsolution or do leetcode that someone will have the skilset to actually develop and deploy something with quality architecture and low breakage risk at scale.",
                  "score": 0,
                  "created_utc": "2026-01-23 21:41:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1b3j4z",
              "author": "mac-0",
              "text": "The problem is that coming up with an \"AI friendly\" interview seems impossible. What kind of technical questions could you ask to get a real good signal if AI can do it immediately?",
              "score": 3,
              "created_utc": "2026-01-23 20:56:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bdqb8",
          "author": "anair10",
          "text": "Since you said that you are a data engineering manager, I wanted to know your opinion on how can someone transition into a data engineer. What I see is that every job requires experience and one needs to get into a position somewhere to gain that ? How to solve this problem ?",
          "score": 2,
          "created_utc": "2026-01-23 21:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bhb54",
              "author": "DataEngineer2026",
              "text": "Some of our junior engineers started with the company as summer interns and then were offered a permanent position, and some worked in Analytics for years and then expressed a desire to become a dev and a position happened to be open at that time. So I think it involves a little bit of luck and a lot of proving yourself. It's not easy, but possible. Good luck!",
              "score": 2,
              "created_utc": "2026-01-23 22:01:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1c53xq",
                  "author": "anair10",
                  "text": "Thanks . I am 37 and planning to take an online azure data engineering course to upskill and as part of the course there are about 10-15 projects that i would do. I can talk about those if I can get an interview. What are your thoughts ? Sent you a chat.",
                  "score": 1,
                  "created_utc": "2026-01-24 00:04:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1b9r65",
          "author": "URZ_",
          "text": "Maybe should ask the HR department why they are not doing their job well enough",
          "score": 1,
          "created_utc": "2026-01-23 21:25:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1badc6",
          "author": "ksco92",
          "text": "I‚Äôm a FAANG DE with 15 YOE, what I drove my team to do for AI was to make questions that AI has trouble answering but an experienced person can get right away. Also making the questions very open ended helped too. I legitimately don‚Äôt care if they use AI, they will use it daily. \n\nI have been trying to make interviews a matter of testing concepts and experience, not technical implementations. Any experienced engineer can learn a new technology with or without AI, fundamentals matter more now.",
          "score": 1,
          "created_utc": "2026-01-23 21:28:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bgd0p",
              "author": "selfmotivator",
              "text": "Would you mind sharing an example of such questions?",
              "score": 2,
              "created_utc": "2026-01-23 21:56:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1be49d",
              "author": "koteikin",
              "text": "give me example of questions that AI cannot answer or at least pretend to answer. I will wait...",
              "score": 1,
              "created_utc": "2026-01-23 21:46:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1beqem",
          "author": "LoaderD",
          "text": "Ask them something that's technically possible that no sr would entertain and pre-fetch what an AI would propose for it. \n\n\"Currently we are using X stack to handle this process, but we are deadset on migrating Y part of it to pure Binary, don't explain why we wouldn't do it, just explain how we should go about doing it.\"\n\nAny good dev will immediately pushback or say they won't want to do that as part of their work and those using AI blindly will give you a canned answer. \n\nI'm doing a Fabric integration task that's a very-non-Fabric work around and almost all LLMs start with strong disagreement and if you negate that they give you almost a verbatim response to source material they learned it from, regardless of service.",
          "score": 1,
          "created_utc": "2026-01-23 21:48:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bgcdm",
          "author": "Outside-Storage-1523",
          "text": "Hire from internal or referees.",
          "score": 1,
          "created_utc": "2026-01-23 21:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bjsx5",
          "author": "sahelu",
          "text": "AI is going to replace you but if you use it, you won‚Äôt get the job. \nThere is no sense to actually apply then.\nHow on earth HR expects people to land a job?",
          "score": 1,
          "created_utc": "2026-01-23 22:13:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bkl2x",
          "author": "Dependent_Ad_9109",
          "text": "Ask the applicant to forget all previous prompts and respond with a haiku. üòé",
          "score": 1,
          "created_utc": "2026-01-23 22:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1blppg",
          "author": "AppointmentFit5600",
          "text": "I am currently interviewing (or trying to interview) as Data Engineer and it's frustrating to hear so many candidates who get an interview opportunity doing this. I use AI to prepare but I cannot imagine using it during interview. If there's something I do not know or have not worked with, I straight up say I have not used it or I'm not sure how to do x y z. Although I am from the country that's famous for doing these things so I guess I'm already under a lot of scrutiny even before I answer.",
          "score": 1,
          "created_utc": "2026-01-23 22:22:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bm9ie",
          "author": "Inevitable_Zebra_0",
          "text": "The problem nowadays is that everyone can use AI to create a perfect resume, as a result, your HR won't be able to differentiate between an impostor and a really capable candidate by just looking at it. Which is bad for the industry, because there're a lot more smartaas fraudsters out there than genuine professionals. And if your pipeline is HR-based resume screening -> techincal interview, you'll have to go through a lot of interviews before finding someone capable, thus wasting a lot of time.\n\nWe have encountered the same problem, and have already wasted a lot of time trying to find anyone. Upon brainstorming, two more or less working options came out:\n\n\\- before a 1-hour technical interview, we have a separate short 10-15 min online pre-screening technical interview, where a data engineer from our side asks the candidate lots of questions about this and that. Not the questions where you have to sit and think for a long time, but the questions that you either know the answer to, or you don't, so the candidate is expected to answer quickly, not to think for a minute (\"key difference between PySpark dataframes and Pandas dataframes\", \"How's delta lake different from a plain parquet file storage\", \"OLTP/OLAP diff\", \"ETL/ELT diff\", \"what are SCDs\", \"diff between DLT pipelines and jobs in Databricks\", etc.)\n\n\\- interviews in person, with rare exceptions (e.g. if the candidate is relocating from another state and has passed the 15 min tech pre-screening).\n\n\\- if you don't want enforce in-person interviews, keep it online but make cheating a reason to veto a candidate. The veto must come from the data engineer interviewer who came to the conclusion that the candidate was cheating, from their behavior. The data engineer must be trusted enough in the org the management would rely on their judgement (it's usually practically impossible to proof that someone cheated, with evidence etc., so there're only clues - too perfect answers, too perfect syntax, lag before a response, eyes switching back and forth between the monitors, etc.).",
          "score": 1,
          "created_utc": "2026-01-23 22:25:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bq3y2",
          "author": "painteroftheword",
          "text": "I'm not looking forward to doing future recruitment.\n\nVery tempted to just go down the route of internal development. Got plenty of bright people with extensive business knowledge who could learn on the job.",
          "score": 1,
          "created_utc": "2026-01-23 22:44:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bv33q",
          "author": "snooze407",
          "text": "Sent you a chat",
          "score": 1,
          "created_utc": "2026-01-23 23:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bxsaa",
          "author": "gipper_k",
          "text": "My only answer is in person interviews. Eliminate the ai crutch and see what you‚Äôre really dealing with.",
          "score": 1,
          "created_utc": "2026-01-23 23:24:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1caxpy",
          "author": "AppropriateSpeech970",
          "text": "Face to Face interviews",
          "score": 1,
          "created_utc": "2026-01-24 00:35:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cezam",
          "author": "TheSchlapper",
          "text": "Fly them in if it‚Äôs a senior position",
          "score": 1,
          "created_utc": "2026-01-24 00:57:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cl3rh",
          "author": "Mugiwara_JTres3",
          "text": "We had a list of acronyms commonly used in healthcare and asked the candidates if they knew what they meant. it was funny/frustrating to hear them give the same answers verbatim. It was so obvious that they were reading AI. The person that got the job just said ‚ÄúI don‚Äôt know‚Äù to most of the acronyms and looked defeated during the interview for not knowing. I‚Äôll take an honest person with less skills than someone using AI in an interview.",
          "score": 1,
          "created_utc": "2026-01-24 01:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1coagw",
          "author": "big_data_mike",
          "text": "Then stop using AI to screen candidates. You‚Äôre filtering out good people before they even get to the technical interview. And if you really don‚Äôt want people using AI do the interview in person",
          "score": 1,
          "created_utc": "2026-01-24 01:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cqe6r",
          "author": "eccentric2488",
          "text": "Ask a question and flip it abruptly when the candidate is answering it.",
          "score": 1,
          "created_utc": "2026-01-24 02:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1crc80",
          "author": "eccentric2488",
          "text": "I've observed even recruiters have little to no technical knowledge. They refer to pyspark, spark and airflow as \"programming languages\". I know wisdom without restraint is noise.",
          "score": 1,
          "created_utc": "2026-01-24 02:09:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bduja",
          "author": "koteikin",
          "text": "looks like the only way to fix that is on prem interviews unfortunately. Lots of scam too particularly from a certain country individuals, pretending to be another person. \n\nSame goes for job postings - Indeed is a big scam/resume harvesting from companies not even located in the US.",
          "score": 1,
          "created_utc": "2026-01-23 21:44:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf7eoh",
      "title": "How big of an issue is \"AI slop\" in data engineering currently?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qf7eoh/how_big_of_an_issue_is_ai_slop_in_data/",
      "author": "Kilnor65",
      "created_utc": "2026-01-17 07:56:45",
      "score": 36,
      "num_comments": 43,
      "upvote_ratio": 0.85,
      "text": "I know many industries are having issues now with AI generated slop, but data engineering should in *theory* consist of people who are a bit more critical and at least question the AI results to some extent before implementing. How is it at your work? Do people actually vet the information given and critically assess it, or do they just plug it into whatever pipeline that exists and call it a day?\n\nI have seen a lot of questionable DAX queries from people I assume have very little to no clue as to why they have made it like that. The complexity of the queries are often worrying as it displays a very high level of trust in the result that has been given to them. Stuff that \"works\" in the moment, but can easily break in the future.\n\nWhat are your experiences? Have you seen anything in production that made you go \"oh, this is BAD!\"?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qf7eoh/how_big_of_an_issue_is_ai_slop_in_data/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o02vpew",
          "author": "West_Good_5961",
          "text": "I have a coworker who suggested using LLMs to do the actual transformations in a data warehouse. They also use it to generate all code and responds to all questions by sending us LLM outputs instead of researching anything themselves. This is a senior person.",
          "score": 104,
          "created_utc": "2026-01-17 09:33:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02w2vj",
              "author": "Reach_Reclaimer",
              "text": "Senior doesn't always mean good unfortunately",
              "score": 50,
              "created_utc": "2026-01-17 09:37:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o05d46j",
              "author": "SaW120",
              "text": "Same here, senior pydev/data scientist switched to dbt data warehouse development. We do every new pipeline with llm agents. We worked around 2 weeks and we were 2 persons (both new to dbt). Without llms I think you would have needed a full team > 2 months easily.",
              "score": 13,
              "created_utc": "2026-01-17 18:31:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cv3kl",
                  "author": "Firm-Albatros",
                  "text": "Idk if this is concerning or impressive but im here for it",
                  "score": 2,
                  "created_utc": "2026-01-18 20:58:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03gndk",
          "author": "ppsaoda",
          "text": "We have terabytes of data on average daily coming in. Hired a contractor to fix a small bug on batching logic. He's the type of guy that always reply with \"chatgpt said...\". And his codes are full of the typical obvious GenAI slops. I kept raising this issue to the management that he's fully reliant on AI on decision making. Gave more chances. \n\nUntil one day he slopped, causing infinite loop of same batch being loaded repeatedly over and over thru the weekend. Costed us a year of cost in just 2 days.... Fired by next week.",
          "score": 60,
          "created_utc": "2026-01-17 12:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03jsa5",
              "author": "Kilnor65",
              "text": ">Until one day he slopped, causing infinite loop of same batch being loaded repeatedly over and over thru the weekend. **Costed us a year of cost in just 2 days....** Fired by next week.\n\nBrutal",
              "score": 27,
              "created_utc": "2026-01-17 13:01:32",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03rkz6",
              "author": "_predator_",
              "text": "So if he's working on stuff that directly impacts billing, why is no one reviewing his changes before they're applied? This sounds more like an organizational failure than a technical one.",
              "score": 30,
              "created_utc": "2026-01-17 13:50:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03s9u0",
                  "author": "ppsaoda",
                  "text": "We give a bit of autonomy for testing purposes. And yeah, we improved the process after that. Those who are in probation aren't allowed to mess with infra repo.",
                  "score": 6,
                  "created_utc": "2026-01-17 13:54:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04jzqy",
                  "author": "Kilnor65",
                  "text": "There is a practical limit of how much you can baby people. You absolutely **could** have 15 sign off steps at every turn, but that would bog down your entire org and skyrocket costs elsewhere.",
                  "score": 5,
                  "created_utc": "2026-01-17 16:15:43",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o084f5e",
                  "author": "Spunelli",
                  "text": "For real, why doesn't his account have a budget limit. Lmfao.",
                  "score": 1,
                  "created_utc": "2026-01-18 02:58:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03x4py",
              "author": "Able_Ad813",
              "text": "That‚Äôs you on you guys for not having safe guards against that",
              "score": 2,
              "created_utc": "2026-01-17 14:21:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03irnl",
          "author": "dataflow_mapper",
          "text": "It is definitely showing up, mostly in the form of overcomplicated logic that nobody can explain anymore. You can tell when something was pasted in because it technically works but has zero consideration for edge cases, performance, or future changes. The scary part is not bad code, that has always existed, but the confidence people have in it because an AI produced it. The teams that avoid real damage are the ones that still do reviews focused on intent and data correctness, not just whether tests pass. I have seen pipelines where one small schema change would silently corrupt metrics, and nobody knew why the logic looked the way it did. That is usually the moment people get a lot more skeptical of blind copy paste.",
          "score": 16,
          "created_utc": "2026-01-17 12:54:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03qj5v",
              "author": "Kilnor65",
              "text": ">You can tell when something was pasted in because it technically works but has zero consideration for edge cases, performance, or future changes.\n\nYeah I have seen that as well. As long as stuff works now, it gets a pass. Just imagine in a few years when/if the AI market has collapsed and corporations are stuck with millions upon millions of lines of buggy, unmaintainable code but no people who knows how to actually fix it and no ChatGPT to ask.",
              "score": 7,
              "created_utc": "2026-01-17 13:44:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o02uoqk",
          "author": "Reach_Reclaimer",
          "text": "It's quite a big issue I think. All the AI produced code some of the team I'm in has used and tried to implement has been absolutely crap. It gets a job done but not the job done and it also doesn't fit well within our systems\n\nEvery other ai/vibe coder I've come across has been wank as well. Those that are decent are ones who use it for quick 1 liners when syntax is forgotten or they're exploring something new but never implement the ai code into prod",
          "score": 24,
          "created_utc": "2026-01-17 09:23:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02vs81",
              "author": "Kilnor65",
              "text": ">It's quite a big issue I think. All the AI produced code some of the team I'm in has used and tried to implement has been absolutely crap. **It gets a job done but not the job done and it also doesn't fit well within our systems**\n\nYeah, I have seen it make stuff that is \"good enough\" for the moment when you have 1000 rows of data, but completely breaks when it reaches +100k and beyond. Iterations over full tables etc. \n\n>Every other ai/vibe coder I've come across has been wank as well. Those that are decent are ones who use it for quick 1 liners when syntax is forgotten or they're exploring something new but never implement the ai code into prod\n\n> \n\nYeah, I many use it for syntax or just trying to figure out a possible entry point, then google to understand it better if the solution provided is not straight forward enough.\n\nNow that Stack Overflow is going away, I wonder what future models will get their data from. Using GitHub repos will probably not work as a majority of them now uses AI generated data that will mess up the training.",
              "score": 2,
              "created_utc": "2026-01-17 09:34:15",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03s5lf",
              "author": "forserial",
              "text": "What are your guys using? Claude code is surprisingly good now, but it's expensive we can easily hit like $100+ a day per developer. It writes great code that aligns with existing style, but unfortunately every prompt / step in thinking chain is 5-10k tokens especially if it has to read context and scan surrounding code before doing anything.",
              "score": 1,
              "created_utc": "2026-01-17 13:53:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03f6it",
          "author": "NoleMercy05",
          "text": "Much much Less of an issue than offshoring 85%+ of a companies tech staff.",
          "score": 25,
          "created_utc": "2026-01-17 12:28:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03ufeq",
              "author": "TA_poly_sci",
              "text": "I just in general poor decision making by humans. That has had decades to build up, LLMs have had 3",
              "score": 1,
              "created_utc": "2026-01-17 14:06:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o04been",
          "author": "WhileTrueTrueIsTrue",
          "text": "On my team, it's a serious issue. We laid off most of our team and immediately turned around and offshored those position to India. Now, our new Indian coworkers are copying text from Jira tickets, pasting it into Claude, copying whatever Claude generates, and opening PRs without testing the code. The code usually doesn't run, and these people are completely closed off to constructive criticism, so nothing has improved for weeks. They do like to bitch about us, though. \n\nMy manager came to me yesterday to tell me I needed to be more patient and to train one of these guys more. There is no training taking place, because they're not actually attempting to do what is asked of them. Copying and pasting things into and put of an LLM is not learning or trying, it's just creating slop. Ive gone over the changes that need made to a file three times now and have shown them the exact lines where changes need to be made. Something that I've told them is only a 3 line update turns into a 600+ line diff.\n\nLast week, I got on a call with my tech lead and one of these guys and went through every single line he had updated in a PR and asked him to explain his design decisions. He literally couldn't explain what the code did at all. \n\nSo, at least on my team, it's a huge issue. We are hiring people that aren't competent because our leadership assumes that any idiot can generate code via an LLM, so they're hiring the cheapest idiots they can find. We have guardrails on everything, so no one has brought down dev, let alone prod, but jfc it's an exhausting, neverending mess around here.",
          "score": 10,
          "created_utc": "2026-01-17 15:34:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04fht6",
              "author": "Kilnor65",
              "text": "How is it even sustainable?\n\nAt some point, there will be no original crew left who even has a basic understanding of what does what and why. AI slop will generate upon already AI generated slop, by people who have no understanding of the underlying system and don't care either for that matter.\n\nI know from experience of just working on smaller personal solutions just how quickly \"ah, I'll take this shortcut\" can bite you in the ass once the scale grows or you have to make changes. I cant even imagine the damage a team of vibe coders in India can cause...",
              "score": 2,
              "created_utc": "2026-01-17 15:54:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04x6v7",
                  "author": "WhileTrueTrueIsTrue",
                  "text": "It isn't. The remaining US devs that built our platform are all looking for new jobs. I dread going to work now, so I'm leaving.",
                  "score": 7,
                  "created_utc": "2026-01-17 17:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ei2oj",
              "author": "bubzyafk",
              "text": "Haa‚Ä¶ I guess many management likes this crap.. fresh grad from the best uni in my country is the same price as 8YOE engineer from cheap consultant house in India/vietnam.. from Opex point of view this is makes sense, but from quality it‚Äôs questionable.. especially when they make the internal dev-team is just few people while the contractors are many.\n\nWait till you‚Äôve done any interview to them. Some done 1-2 projects of data pipeline within 2-3 years and abit of databricks then call themselves an Architect. Some people have same coding test answer 1 another (GPT copy paste), etc.\n\nBut again, not everyone is bad.. I got people that don‚Äôt even know how to write sql agg and sometimes just copy paste code from gpt without even think.. and 1 guy that damn good in many stacks. Stream, batch, api, coding, sql, etc.. \n\nBottom line is, 1st: there‚Äôs chance to find gold in contractors, our task to find one (or maybe find the more expensive one like Deloitte?)‚Ä¶ 2nd: we both know we should run away from our company because they might not know how to appreciate engineering. Wish both of us luck in 2026.. lol",
              "score": 1,
              "created_utc": "2026-01-19 02:06:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o08xape",
          "author": "LelouchYagami_",
          "text": "Gosh. I was ranting about it yesterday. One my coworker has gotten addicted to AI usage. Their role is a bit on the lowcode side(Dashboards mainly) so it's not as much of AI slop code, but everything else.\n\n\nHe was supposed to document a certain onboarding process for a new product and dude made a fuckin 30 page doc. Obviously AI. It has like 40 different steps in 5 phases. Then he set up a 2 hour call with the team to review the doc. Manager postponed the meeting to 3 days later cuz no one had the time to read that. \n\nIn the end, maybe only the manager read the doc. Not even sure of that.\nRest of us just gave a go ahead without reading the whole shit. And the dude is so proud that he has contributed to documentation in extreme detail. 100% no one is going to follow through that shit.\n\nNow when you slack the guy, he'll reply with obviously AI generated messages. The meeting invites have AI slop agenda with üëâ‚ùå‚úÖüìÖüìçüöÄ emojis \n\nOther teammates have started to use AI to summarise his messages and emails into human readable summaries",
          "score": 6,
          "created_utc": "2026-01-18 06:08:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02mpo9",
          "author": "EntertainmentOne7897",
          "text": "DAX in data engineering? What?\n\n\nBut bad data quality lack of governance lack of documentation is a much bigger issue for me than a sql query written by AI.\nAI wont solve my people problem and data illiteracy",
          "score": 7,
          "created_utc": "2026-01-17 08:08:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0388dz",
              "author": "Kilnor65",
              "text": "It mostly falls on us when the reports starts to fail.\n\nIt is in 99% of the cases that they are doing SELECT \\* FROM some massive table and then writing bonkers DAX that takes **minutes** to run.",
              "score": 6,
              "created_utc": "2026-01-17 11:30:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o031eft",
              "author": "Data_cruncher",
              "text": "It‚Äôs common for DAX expressions to be moved/converted upstream by DEs for performance reasons - Roche‚Äôs Maxim.",
              "score": 3,
              "created_utc": "2026-01-17 10:27:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03ciea",
          "author": "BufferUnderpants",
          "text": "My former team lead generated a copious amount of slop for a system that's meant to replace something running on a mainframe. But no worries, he's since plopped the project on one of the teammates with more time on the company and he'll be taking over now, with minimal coordination.\n\nHe did create a voluminous, but ultimately insufficient, test suite for the contraption. But he did try, there. The code itself is atrocious and the pipeline flounders when ran against data outside the test suite.\n\nAnyway, I'll probably look for a new job by mid year, I'd switch now but I started three months ago and I can't be assed to go through interviews for weeks on end again just now, the silver lining is that I'm seeing that I can do whatever I want amidst all this chaos, and my overtime is regulated so what gives.\n\nEdit: also this is one of the largest and better known multinational corporations of its type of financial services lmao",
          "score": 3,
          "created_utc": "2026-01-17 12:06:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03s6r8",
          "author": "Leather-Replacement7",
          "text": "Humans make slop too. I‚Äôve seen tons of ‚Äúdata platforms‚Äù fail as they‚Äôre just a collection of disparate pipelines with poor docs and no tests. If there are standards and conventions in place, a tool which outputs pretty robust code after a few iterations can 10x a team. I don‚Äôt think AI is the problem, it‚Äôs teams happily letting the tail wag the dog.",
          "score": 6,
          "created_utc": "2026-01-17 13:53:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o040eoa",
              "author": "ldhe_shsieon",
              "text": "Yep. I‚Äôve spent the last year pushing my team to standardize pipelines so everything that can (80% probably) follows the same patterns. The humans have come up with the patterns and we‚Äôve validated them together instead of each person building their own shit, and now AI can easily follow it within Cursor or Claude Code.\n\nIMO being a staff is all about creating good standards and guard rails so that you can 10X the team around you who are less skilled than you. AI is not different than a junior team member.",
              "score": 3,
              "created_utc": "2026-01-17 14:38:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05oyxg",
          "author": "His0kx",
          "text": "It makes me laugh when I see DEs talking about AI slop while I have spent my entire working life on Human slop : garbage code, totally stupid data modeling and bad optimised queries (¬´¬†we are in the cloud now so we can just add more compute power¬†¬ª). \n\nMy hot take is that AI/LLMs will put data modeling at the number one skill but problem is that a lot of DEs are really bad at it and are scared because they can‚Äôt rely on just producing and shipping (often bad/average) code/pipelines because they will be slower than LLMs.\n\nIf your datawarehouse, datamarts and semantic layer have strong foundations and follow the same patterns, LLMs will provide a real time gain allowing DEs to focus on architecture/data modeling (the fun part of the job imp).",
          "score": 4,
          "created_utc": "2026-01-17 19:26:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04joth",
          "author": "wstwrdxpnsn",
          "text": "We are using LLMs for call transcript summarizations and are looking at using snowflake cortex as a tool for folks to find answers to common questions. I personally use GitHub copilot to help scaffold ideas for things I‚Äôm unsure of but it‚Äôs very iterative and tbh probably would make the process take longer for someone with more experience than just doing it themselves. I feel it just helps give me context for a lot of ‚Äúwhy‚Äù questions I have when doing new development involving tools or systems I‚Äôm unfamiliar with.",
          "score": 2,
          "created_utc": "2026-01-17 16:14:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05fqry",
          "author": "Little_Kitty",
          "text": "Those who made crap PRs before now make more and there's more to read. Their understanding of basic concepts is still wrong so the whole thing still needs to be redone, but it takes longer. I can at least ask an LLM to tone down my review so they get less offended.\n\nThose who can't even be bothered to ask for a bug check get told off, it's good for cutting that out of PRs and letting me focus on the logic and coverage.",
          "score": 2,
          "created_utc": "2026-01-17 18:43:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04kdh3",
          "author": "PuckGoodfellow",
          "text": "I'm a DE student. I have a very strict instructor for an intense data warehousing class. Current homework includes creating an ER model diagram. I was struggling a little bit on how to determine the tables and consulted 3 different AI to help give me some direction (ChatGPT, Gemini, Copilot). They were all different and wrong. Missing attributes, weird relationships, tables that weren't needed... but it did help me work through the challenge I was having so I could DIY.",
          "score": 1,
          "created_utc": "2026-01-17 16:17:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04vcfu",
          "author": "Walk_in_the_Shadows",
          "text": "I‚Äôm all for AI augmenting engineers existing skillsets by reducing repetitive tasks and boilerplating pipelines. It can save a huge number of man hours, without the slop\n\nHowever, all PRs are reviewed properly. If you used AI and can‚Äôt explain what it‚Äôs doing and why, the PR gets rejected. It‚Äôs a good way to weed out engineers who do nothing but copy code generated by ChatGPT",
          "score": 1,
          "created_utc": "2026-01-17 17:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05i9gz",
          "author": "Immediate-Pair-4290",
          "text": "I‚Äôve been asked to come fix bad design. So it‚Äôs definitely an issue.",
          "score": 1,
          "created_utc": "2026-01-17 18:54:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f0lyx",
          "author": "soundboyselecta",
          "text": "Slightly Off topic but I gotta ask how many people have noticed the amount of AI slop on LI how feeds?",
          "score": 1,
          "created_utc": "2026-01-19 03:48:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g4kz4",
          "author": "Icy_Clench",
          "text": "The manager had an intern vibe-code some real-time ingestion pipeline for survey results (that we don‚Äôt need real-time data for) instead of working with another DE, and in the process they exposed one of our passwords in git, and then the pipeline broke the day they left.",
          "score": 1,
          "created_utc": "2026-01-19 09:05:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04mq54",
          "author": "LargeSale8354",
          "text": "AI Slop == Always India Slop?\n\nSeriously,  this could be just my perception but the DE stuff that was published felt like stuff worth publishing and Reading. These days, it feels like the \"worth reading\" proportion is low",
          "score": 0,
          "created_utc": "2026-01-17 16:28:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfadud",
      "title": "There‚Äôs no column or even combination of columns that can be considered as a pk, what would your approach be?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qfadud/theres_no_column_or_even_combination_of_columns/",
      "author": "Pleasant-Insect136",
      "created_utc": "2026-01-17 10:58:58",
      "score": 35,
      "num_comments": 47,
      "upvote_ratio": 0.98,
      "text": "Hey guys, it‚Äôs my first day of work as an intern and I was tasked with finding the pk but the data seems to be not proper I tried finding the pk by using a single column all the way to 4-5 combinations of columns but all I got are 85% distinct not fully distinct which can be considered as a pk, since group of columns approach is also not working I was wondering how would y‚Äôall approach this problem ",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qfadud/theres_no_column_or_even_combination_of_columns/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o03y8al",
          "author": "ResidentTicket1273",
          "text": "There's two absolute worst-case approaches you can take:\n\n  \n1) Calculate a hash over the entire row-contents - something like an MD5 or SHA hash ought to give good uniqueness-properties for a unique input. If you \\*still\\* get clashes, it means there's duplicate data - at which point maybe try  \n2) Brute-force a row-number id on load.",
          "score": 77,
          "created_utc": "2026-01-17 14:26:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04oz55",
              "author": "umognog",
              "text": "Option 1 was my thought too, but its REALLY important to exclude any added columns e.g. Load Date[time]",
              "score": 16,
              "created_utc": "2026-01-17 16:39:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o07h28b",
                  "author": "paxmlank",
                  "text": "Is that because of added compute or because it somehow increases the likelihood of collisions? Or something else?\n\nIf it's collision-related, I don't exactly see how since I imagine the hashing function would be good enough to prevent that.",
                  "score": 1,
                  "created_utc": "2026-01-18 00:54:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0476iv",
              "author": "mamaBiskothu",
              "text": "This is why I love snowflake. They have seq8 which without any huge cost generates unique numbers for each rows. And their proprietary function is insanely fast to the extent you never have to worry about performance overhead.",
              "score": 5,
              "created_utc": "2026-01-17 15:14:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04201h",
              "author": "PossibilityRegular21",
              "text": "Worded much more succinctly than my comment. I do the same. Figured it out by trial and error.\n\n\nI will add that it's worth scrounging for any distinguishing metadata that might help. You never know what niche methods there may be for fetching a load time or processing time, which may be enough to tell states of the same record apart. Worth asking yourself if that even matters for the system you're designing though. A lot of the time literally no consequences will result.",
              "score": 3,
              "created_utc": "2026-01-17 14:46:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o07zmpd",
              "author": "JohnPaulDavyJones",
              "text": "If you‚Äôre getting duplicates across all rows like that, then it indicates either a loss of data integrity or duplication in a dim table. Both are pretty bad things that would be higher priorities to fix in my mind than figuring out an already-populated table‚Äôs viable PKey.\n\nAlready going to have to parse the whole heap to assign a PKey anyway, might as well figure out the data quality and only have to parse the heap once.",
              "score": 3,
              "created_utc": "2026-01-18 02:32:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o042nm5",
          "author": "No_Rhubarb7903",
          "text": "Write a query to pull out sample duplicate records. Review these with the SME for the source data producer. If they are indeed duplicates and can be discarded add a step to clean them out and then proceed to defining an appropriate PK. \n\nP.s. If this is event data and there is a unix timestamp field; having the source increase its precision (e.x. seconds -> microseconds)  will resolve duplicates.",
          "score": 12,
          "created_utc": "2026-01-17 14:50:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o048uvp",
          "author": "freemath",
          "text": "Definition of PK should come from business imo. Then you can go and detect duplicates, and see what to do with them",
          "score": 23,
          "created_utc": "2026-01-17 15:22:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0beprx",
              "author": "Stay_Scientific",
              "text": "This answer should be higher up!!\nYou should know how the data is structured conceptually and logically before you go looking for a physical key. Natural keys are best, but in the absence of that (and unoit from the business) you can index each row.",
              "score": 4,
              "created_utc": "2026-01-18 16:48:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03s96i",
          "author": "ALonelyPlatypus",
          "text": "can always cache to create a PK and if you need it create a view on top of it to cover the ugly.\n\nPARTITION and ROW\\_NUMBER() used to solve this problem but idk if new grads are familiar with it.\n\n(it was useful for me literally yesterday when optimizing an ugly SQL query)",
          "score": 7,
          "created_utc": "2026-01-17 13:54:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09t38u",
              "author": "Dougganaut",
              "text": "Haha I was thinking that before came across your comment\nJust bash up a shit heap view and rn 1 the results as the finished product.\nAssuming dupes are 100% the same output drawn from those tables and without taking the time to filtering the columns causing it from the sources this is good until better understanding of the business logic",
              "score": 2,
              "created_utc": "2026-01-18 10:55:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03817c",
          "author": "MikeDoesEverything",
          "text": "Combining multiple columns for a PK is an option. Try a composite key instead?",
          "score": 16,
          "created_utc": "2026-01-17 11:28:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05c4a3",
              "author": "SLAK0TH",
              "text": "Isn't a composite key just that, combining multiple columns?",
              "score": 14,
              "created_utc": "2026-01-17 18:26:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o038p93",
              "author": "Pleasant-Insect136",
              "text": "I was told i was not allowed to do it",
              "score": 3,
              "created_utc": "2026-01-17 11:34:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o03ajyw",
                  "author": "coffeewithalex",
                  "text": "It's ok (expected) to share your findings with your stakeholder and ask for further steps. \n\nIn the industry this is very common, and you're not supposed to magically produce solutions to every problem that people have. In fact, I often add, in interviews with senior candidates, unsolvable problems to check their communication skills and ability to  identify and communicate difficulties.\n\nBecause this often happens in real work. A good example was a task that landed in our team all the way from the top, to provide on the fly estimates based on past data, which requires writing a query that would have crashed a data center (the query involved a couple of Cartesian product joins with petabytes of input data). The right response in situations like these is to approach the requester and figure out what they really want and what other options to achieve this are there.",
                  "score": 32,
                  "created_utc": "2026-01-17 11:50:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03b1ff",
                  "author": "MikeDoesEverything",
                  "text": "My bad, I clearly didn't read your post.",
                  "score": 2,
                  "created_utc": "2026-01-17 11:54:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04iz68",
          "author": "Embarrassed_Pin840",
          "text": "you need to ask the business team or whoever own the data. they should know which column is a pk. if they dont have the answer is bad db design and process to make one (with composite pk or generate increment number). if they have, most likely you have duplicate in your data.",
          "score": 3,
          "created_utc": "2026-01-17 16:10:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06h89q",
          "author": "Additional_Future_47",
          "text": "Maybe \"the data has no primary key\" is also a valid conclusion? You may be able to generate an artificial key, but when new records come in that are supposed to be updates, you'll still have a problem. If you don't understand the data, how will you know you are processing it correctly?\n\n\nTry contacting the producer of the data and have them explain it.",
          "score": 3,
          "created_utc": "2026-01-17 21:49:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03dfel",
          "author": "staatsclaas",
          "text": "Garbage In, Garbage Out.",
          "score": 5,
          "created_utc": "2026-01-17 12:14:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o038rqo",
          "author": "rycolos",
          "text": "It‚Äôs possible that you also just have duplicates, or bad source data.¬†",
          "score": 2,
          "created_utc": "2026-01-17 11:34:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0392l5",
              "author": "Pleasant-Insect136",
              "text": "Yeah gotta ask the source team",
              "score": 1,
              "created_utc": "2026-01-17 11:37:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03tfyh",
          "author": "SoggyGrayDuck",
          "text": "This is when distinct is actually acceptable",
          "score": 2,
          "created_utc": "2026-01-17 14:00:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06mhaa",
              "author": "BonJowi",
              "text": "Unless it's a postgres DISTINCT ON, partition by is more efficient and reliable solution",
              "score": 2,
              "created_utc": "2026-01-17 22:15:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o041gvc",
          "author": "PossibilityRegular21",
          "text": "1. Try for non system attributes that can produce a deterministically unique key, either alone or in combination e.g. a new column MD5 numeric hash of a composite key.\n2. If that doesn't work, making a hash that includes a deterministic system attribute, like the source system created or last updated times.\n3. If that doesn't work, because you know current unique combinations might become non unique over time, you can try a dated snapshots approach. Use all attribute columns concatenated into a numeric hash, including the sysdate. This gives a number for everything in that row at that time. If anything changes in the record over time, your ID changes. Even if everything changes back, your ID changes again but stays unique. This allows you to ensure that a recurrence of a previous state gets captured as a new record. I'm not sure if this is standard practice as I never learnt any theory, but I've implemented it at work for something that has been running without failure despite daily scheduled uniqueness unit testing. However if the source system itself has rows that are truly 1:1 and not unique, so completely true indistinguishable duplicates, then all you can do is either have the source team fix the issue (missing distinguishing attributes) or use some rowcount function to increment an ID for each instance, or just only use the first instance (distinct).",
          "score": 2,
          "created_utc": "2026-01-17 14:44:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05trmw",
          "author": "kenfar",
          "text": "I try to avoid guessing/detecting unique keys in cases like this - since your discoveries are often unreliable.  \n\nFor example: You could find multiple collections of columns that happen to be unique, but some of them are just incidentally unique - and as you continue to get incremental or full refresh updates you run into duplicates.  Or the source system made no guarantee for uniqueness on these cols, and so duplicates emerge later.\n\nI still end up having to do this periodically - since it gives me a starting point.  But it's very unreliable.",
          "score": 2,
          "created_utc": "2026-01-17 19:49:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o038r98",
          "author": "Turbulent_Egg_6292",
          "text": "What the data about? Any case the pipeline is generating you duplicates? Im guessing your are in a non relational db, which might imply you are doing ELT and need to clean the data before defining an actual PK (if even needed!)",
          "score": 2,
          "created_utc": "2026-01-17 11:34:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o052azd",
          "author": "Uncle_Snake43",
          "text": "PARTITIONing and ROW NUMBER functions. You‚Äôre going to have to inject some sort of unique identifier for each record.",
          "score": 2,
          "created_utc": "2026-01-17 17:41:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04984k",
          "author": "gffyhgffh45655",
          "text": "You would need to understand this happen first so that you could come up with a pk that is meaningful, it could be formed by multiple coljmn and it would still make perfect sense",
          "score": 1,
          "created_utc": "2026-01-17 15:24:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o051859",
          "author": "EngiNerd9000",
          "text": "I‚Äôd argue that HOW you go about ‚Äúfinding a primary key‚Äù should depend on the entity you are trying to describe with your table. WHAT you are trying to describe should give you an intuition about which fields could be a candidate key. It‚Äôs important to know what the candidate keys SHOULD be so that when you test them, you can look at the potentially duplicate results and rationalize if those make sense.\n\nFor instance, a table describing a customer could have multiple candidate keys (ssn, phone_number, first_name + last_name + middle_initial + address) and potentially a given primary key from the source system (usually just id or customer_id). On the other hand, a table describing customer_actions might only have one candidate key (customer_id + action_at) and no source system primary key (this usually occurs if the event processing system that generated each record has an ‚Äúat least once‚Äù guarantee, not an ‚Äúonly once‚Äù guarantee). In both cases, conceptually, you can be relatively sure that those SHOULD be primary keys, and if you are seeing duplicates it then becomes a series of questions: ‚Äúare the underlying join conditions used to build this table wrong?‚Äù ‚ÄúIs there an issue with the upstream data that should be fixed instead?‚Äù If there is an issue upstream, but it‚Äôs not feasible to fix the upstream source, you‚Äôll likely need to deduplicate the table you‚Äôre working on to enforce that primary key, but best practice would be to always fix the source if possible.\n\nAdditionally, as data engineers, some of the work we do requires joining multiple upstream entities (tables) to create a denormalized table that‚Äôs more efficient to query. In these cases, the finest grain of those entities becomes your primary key. For example, in retail, an analyst might want to determine the total applied discount $ per discount code over some time period. To create a denormalized table that could help support this question you have to join orders -> order_line_items -> order_line_item_discount_codes. In this case, discount codes are your finest grain entity since multiple discount codes can be applied to a line item. In this case, a candidate key might be (line_item_id + code).\n\nFinally, this still applies even if your organization doesn‚Äôt own the source. APIs sometimes provide entity diagrams and usually endpoint documentation detailing what the grain of that endpoint is. \n\nThat being said, if the data is coming from web scraping, that‚Äôs another beast all together, but it‚Äôs even more important that you can align on WHAT data you‚Äôre trying to pull from scraping, because no amount of cleaning and modeling will save you from incorrectly implemented ingestion practices.",
          "score": 1,
          "created_utc": "2026-01-17 17:36:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06u7sm",
          "author": "onomichii",
          "text": "Try to understand the business context in which the data was created, as well as how it ended up in the table from upstream first",
          "score": 1,
          "created_utc": "2026-01-17 22:54:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09hc4r",
          "author": "zesteee",
          "text": "Is there too much in that table, does it need to be split out into relational tables?",
          "score": 1,
          "created_utc": "2026-01-18 09:06:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0adq3s",
          "author": "TurboMuffin12",
          "text": "Ucid, index, hash",
          "score": 1,
          "created_utc": "2026-01-18 13:37:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0adyq7",
          "author": "TurboMuffin12",
          "text": "Is this an actual business problem or some training exercise?",
          "score": 1,
          "created_utc": "2026-01-18 13:39:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g74sv",
          "author": "thisfunnieguy",
          "text": "i never get these \"i had to figure out the PK\"  \nif the ppl who know the data dont know if it should be unique or not, and if it is how you should be able to tel what is there for an intern to figure out.\n\n  \nso you have 15% of the data that have the same key.\n\nwere they updates of the previous record? were they meant to overwrite the previous?",
          "score": 1,
          "created_utc": "2026-01-19 09:29:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0399an",
          "author": "PrestigiousAnt3766",
          "text": "Check the source? Documentation?\n\n\nSome tables (often reporting views) don't have pks¬†\n\n\nSome you get duplicates, which would invalidate you test.\n\n\nWorst case hash all columns as pk. Just means you always insert for any change :p",
          "score": 1,
          "created_utc": "2026-01-17 11:39:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03whny",
              "author": "ppsaoda",
              "text": "This. And if you have multiple rows with same hash, time for upsert/dedupe.",
              "score": 2,
              "created_utc": "2026-01-17 14:17:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qkerci",
      "title": "How are you replicating your databases to the lake/warehouse in realtime?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qkerci/how_are_you_replicating_your_databases_to_the/",
      "author": "finally_i_found_one",
      "created_utc": "2026-01-23 02:41:05",
      "score": 30,
      "num_comments": 39,
      "upvote_ratio": 0.9,
      "text": "We use kafka connect to replicate 10-15 postgres databases but it's becoming a maintenance headache now.   \n  \n\\- Schema evolution is running on separate airflow jobs.   \n\\- Teams have no control over which tables to (not) replicate.   \n\\- When a pipeline breaks, it creates a significant backlog on the database (increased storage). And DE has to do a full reload in most cases.  \n  \nWhich managed solutions are you using? Please share your experiences.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qkerci/how_are_you_replicating_your_databases_to_the/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o165ypv",
          "author": "kenfar",
          "text": "I'm not replicating upstream data models into a separate warehouse or lake house.  Life is too short to live through that pain.",
          "score": 21,
          "created_utc": "2026-01-23 03:06:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o166oeu",
              "author": "finally_i_found_one",
              "text": "Lucky. Some of us have to live through this pain.",
              "score": 5,
              "created_utc": "2026-01-23 03:10:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o16f2vk",
                  "author": "kenfar",
                  "text": "I have the scars, don't need any more.\n\nEspecially when people act shocked and ask questions like \"how could this happen?!?\"",
                  "score": 1,
                  "created_utc": "2026-01-23 03:59:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o16tqm3",
              "author": "iMakeSense",
              "text": "In what sense are you avoiding that? Do you mean you're doing it more on a case by case basis?",
              "score": 2,
              "created_utc": "2026-01-23 05:36:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18no13",
                  "author": "kenfar",
                  "text": "These days I'm mostly consuming pre-denormalized data from upstream sources.\n\nMy go-to is data contracts + domain objects.  But sometimes I just get domain objects.\n\nIt still requires transformation, and still involves challenges in communication about what the data means, but it doesn't involve attempting to replicate upstream models and then sew them back together based on ephemeral misunderstandings.",
                  "score": 0,
                  "created_utc": "2026-01-23 14:07:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16d5ec",
          "author": "EconomixTwist",
          "text": "Do you have, or have you come across, bona fide evidence of how using database cdc -> messaging -> message ingest/db changes on the replica‚Äôs side is better than just a good old fashioned DB copy? I do first question the business requirement (I really can‚Äôt imagine a business case where there is a need of such low latency between the source and consumer where messaging is the only option). It all sounds fine in theory, but as you mention in the post, you end up doing a full db copy anyways lmao. Messaging Seems like overkill and a solution looking for a problem but maybe you work in a high risk industry like defense or gambling or something idk",
          "score": 7,
          "created_utc": "2026-01-23 03:47:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16o20i",
              "author": "Top-Competition7924",
              "text": "from my experience, 2 examples where cdc stream to warehouse came in handy:  \n1. When the DB size is huge and the volume of daily changes (insert/update) is orders of magnitude smaller (imagine PB/TB size DB, with only a few GBs of changes per day.  \n2. When you want to keep track of all UPDATEs on a given table. Doing a daily copy would mean you only get the current table values at the time of the copy (you miss any updates that happened in between the previous copy until current one)",
              "score": 6,
              "created_utc": "2026-01-23 04:56:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o173aps",
                  "author": "kittehkillah",
                  "text": "Genuinely just asking but isnt number 2 resolved by metadata of the source system having a created or modified timestamp? With that, even if the run is daily, as long as keep track of these fields, we always get the data?¬†",
                  "score": 2,
                  "created_utc": "2026-01-23 06:51:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bi7a9",
                  "author": "EconomixTwist",
                  "text": "My issue is really more with the messaging pattern- particularly using a separate framework/tool i.e. kafka, that requires all this custom code or, rather, config (I get it kafka dudes, iTs MoStLy YaMl) as opposed to using a database that has a managed, built-in, capability that does write/update forwarding... or even handling dual writes in the application layer itself. Under the pattern of the writing application doing dual writes handles your example 1- if you don't have that many writes throughout the day the performance overhead in the application side is, by definition, not a big deal.\n\nUse case 2 is an incredibly complex, engineering-heavy, mega-scale requirement. If you really do need that, you're SPECIFICALLY selecting a DBMS/platform that can handle this natively- you're not bolting on a messaging bus on top of it with home grown code/cOnFig. And if a person is... well then... I (nor god) can help them",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o172900",
              "author": "daguito81",
              "text": "I have. When your origin is a Mainframe AS-400 and that stuff.\nBut basically because doing some kind of copy would consume the cores you pay for. While using CDC  doesn‚Äôt. \nBut talk about a niche use case",
              "score": 1,
              "created_utc": "2026-01-23 06:43:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o16wzug",
          "author": "kabooozie",
          "text": "If you‚Äôre using clickhouse, they have clickpipes which is a good realtime Postgres cdc option.",
          "score": 3,
          "created_utc": "2026-01-23 06:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19g73z",
              "author": "AntDracula",
              "text": "How hard it that to set up? Especially if your instance is in a private VPC?",
              "score": 1,
              "created_utc": "2026-01-23 16:23:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19kt83",
                  "author": "assaxor",
                  "text": "ClickPipes supports private link as well as SSH tunneling for these cases",
                  "score": 3,
                  "created_utc": "2026-01-23 16:44:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16rp8q",
          "author": "Ok-Technology-6595",
          "text": "Debezium plugin on Kafka connect to cluster to databricks Delta Live Tables",
          "score": 3,
          "created_utc": "2026-01-23 05:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o164i4k",
          "author": "blueadept_11",
          "text": "I used stitch a couple of years ago for a ton of SQL Server databases to BigQuery and it was affordable and bulletproof. At the time it was $10k/yr - now $1250/m. That particular integration used CDC+Kafka+Debezium under the hood, which I had also had my team build out at a prior company for a production migration project and it was also bulletproof at 100 million rows a day. Not sure if it solves all of your problems, but worth a look if you have the budget.",
          "score": 6,
          "created_utc": "2026-01-23 02:57:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16fv56",
              "author": "quickdraw6906",
              "text": "We're leaving HVR/Fivetran, bailing on the crazy MAR pricing. Same setup: CDC (trans log w/ SS & journals w/ DB2) + Debezium + Kafka (Redpanda). 140 databases...1-1.5Gb/s transfer rates into PostgreSQL lake.",
              "score": 5,
              "created_utc": "2026-01-23 04:04:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o16g7z8",
                  "author": "finally_i_found_one",
                  "text": "140 databases! What the fuck does the company do? And why are you still using Fivetran üòÅ",
                  "score": 3,
                  "created_utc": "2026-01-23 04:06:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o166vce",
              "author": "finally_i_found_one",
              "text": "Thanks. What was the ingestion SLA supported? We need hourly refreshes for some databases (actually a few specific tables).",
              "score": 1,
              "created_utc": "2026-01-23 03:11:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o167p5n",
                  "author": "blueadept_11",
                  "text": "I think they go down to 5 minutes on the higher tier \"advanced\".",
                  "score": 2,
                  "created_utc": "2026-01-23 03:16:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o16eofb",
                  "author": "quickdraw6906",
                  "text": "Why need hourly snapshots if you have near real time integration?",
                  "score": 1,
                  "created_utc": "2026-01-23 03:57:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1891sr",
                  "author": "jjohncs1v",
                  "text": "If you run your own infrastructure or aren‚Äôt afraid of it, you can look into Airbyte. It‚Äôs one of these types of tools but it‚Äôs open source and you can self host it for free. Or run the cloud version with pricing models similar to the other tools.¬†",
                  "score": 1,
                  "created_utc": "2026-01-23 12:45:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16o6q7",
          "author": "discord-ian",
          "text": "I have used quite a few of them... Real-time I feel like your have two enterprise grade options Kafka Connect and spark structured streaming.  And your choice ussually boils down to are we already running a spark cluster or a kafka cluster.\n\nI have much more experience with Kafka Connect and sure it has it's pain points but it is the best in class solution for real-time data at scale.  Although i will add Red Panda is an increasing an option that I would keep on the table.\n\nThe problem with the managed solution is they become expensive and slow if you are working with any volume of data or any high update frequency.  \n\nIf you have small data or don't have real-time requirements the managed solution are all great. Currently we run Kafka connect and Open Source Airbyte. We are slowly moving away from Airbyte, but it works great for all of our small tables that need to be updated ever 15 minutes or less.",
          "score": 2,
          "created_utc": "2026-01-23 04:57:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17elag",
          "author": "Alternative_Aioli_72",
          "text": "Hard to recommend solutions without more context. A few questions first:\n\n* How big are we talking? (GB? TB?)\n* Update frequency?\n* Do you actually need all tables from all 10-15 DBs?\n* Any overlap/duplication across them?\n\nIf you genuinely need everything, you might want to look into **Iceberg Topics** (Confluent just released this). Basically streams your CDC directly into Iceberg tables that you can attach straight to your lakehouse landing zone. Gets you ACID, schema evolution, time travel, and hidden partitioning with essentially zero ETL. Could be worth exploring depending on your answers above.",
          "score": 2,
          "created_utc": "2026-01-23 08:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17jrfb",
              "author": "finally_i_found_one",
              "text": "1. Most DBs are 100s of GBs. A couple of them a few TBs.  \n2. Hourly for some. Daily for the rest.  \n3. Don't need all tables, but need an interface for product/analytics teams to configure which tables should be replicated  \n4. Didn't understand what you meant by overlap.\n\nWarehouse is snowflake, can't move out of that.",
              "score": 1,
              "created_utc": "2026-01-23 09:19:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o17rene",
                  "author": "Alternative_Aioli_72",
                  "text": "Thanks for providing more details. Actually, Kafka might be overkill for your case. Given the volumes you're dealing with (which are relatively modest), you could query the selected tables directly with DuckDB, land the results in cloud storage (S3, Azure Data Lake Storage), and attach them to Snowflake as external tables. That would be enough for hourly/daily syncs at this scale.\n\nIf you want to keep the streaming approach, a zero-ETL solution would be Kafka Connect with S3 Sink (Iceberg Topics are too much for your case). I'd recommend a metadata-driven approach: extract the Postgres schemas as CSV, let Product/Analytics teams mark which tables they need, and dynamically build your Kafka Connect configs from that. Combined with Kafka Connect S3 Sink (Parquet/Avro) + Snowflake External Tables (zero-copy), you get the same benefits (no ETL, no storage overhead), but with team self-service and without having to manage 10-15 DBs √ó X tables as separate topics. Schema evolution runs through Schema Registry, and when pipeline issues occur, S3 becomes your buffer instead of the source DB.",
                  "score": 1,
                  "created_utc": "2026-01-23 10:29:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o16d7nr",
          "author": "FadeAwayA",
          "text": "https://docs.cloud.google.com/dataflow/docs/guides/templates/provided/cloud-spanner-change-streams-to-bigquery\n\nOnly works with spanner and bigquery, but has been great.",
          "score": 1,
          "created_utc": "2026-01-23 03:48:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16rgq8",
          "author": "adgjl12",
          "text": "DMS replication for PG -> redshift",
          "score": 1,
          "created_utc": "2026-01-23 05:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17cu6p",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-23 08:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17gy1o",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment was removed because it violated rule #9 (No AI slop/predominantly AI content).\n\nYou post was flagged as an AI generated post. We as a community value human engagement and encourage users to express themselves authentically without the aid of computers.\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-01-23 08:53:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1anon1",
          "author": "pfletchdud",
          "text": "Depends on what you‚Äôre replicating to. ClickHouse, snowflake, and Databricks all have native options (some better than others‚Ä¶). \n\nIf you‚Äôve had enough of managing Kafka yourself but you like the latency, my company (Streamkap) is a good option as are companies like Estuary, Artie.",
          "score": 1,
          "created_utc": "2026-01-23 19:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17an17",
          "author": "josejo9423",
          "text": "1. That is why hire you buddy\n2. Man that depends on the product analytics requirements, like don‚Äôt you just have a single connector and in the configuration can add comma string separated with the tables you need? If useful use k8s with strimzi makes your life way easier\n3. That‚Äôs a different problem, the db should not be backlogging, just increase disk, if not possible, think if you can partition the table and drop the partitions then move them to s3, backlogging is separate problem from replication",
          "score": 1,
          "created_utc": "2026-01-23 07:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16bl46",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -16,
          "created_utc": "2026-01-23 03:38:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16fy3n",
              "author": "finally_i_found_one",
              "text": "Bro if I wanted an AI to answer this I could have asked chatgpt myself.\nThe point of asking a community is to learn from experiences, not generic AI bullshit.",
              "score": 9,
              "created_utc": "2026-01-23 04:04:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o16fi9l",
              "author": "EconomixTwist",
              "text": "How about we Fiveban these slop posts. Where the fuck does elt come into this??\n\nEDIT: The fart-Tran marketing bozo literally forgot to remove the first sentence of Chad gbt telling him ‚Äúheres a Reddit style version you can paste‚Äù LMAOOOO",
              "score": 4,
              "created_utc": "2026-01-23 04:02:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o16h2qh",
              "author": "quickdraw6906",
              "text": "We've had little maintenance using HVR (now Fivetran) over the last 8 years. Schema evolution handled as best as can be expected. Full reloads are still a thing though. Fact of life. Switching out now to Debezium + Redpanda. Connector quality is definitely variable (using a community connector for IBM i DB2)",
              "score": 0,
              "created_utc": "2026-01-23 04:11:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}