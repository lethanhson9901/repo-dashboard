{
  "metadata": {
    "last_updated": "2026-02-05 17:09:59",
    "time_filter": "week",
    "subreddit": "dataengineering",
    "total_items": 20,
    "total_comments": 278,
    "file_size_bytes": 317530
  },
  "items": [
    {
      "id": "1qvizak",
      "title": "Data Engineering as an After Thought",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/pdqlix94tfhg1.png",
      "author": "uncertainschrodinger",
      "created_utc": "2026-02-04 08:20:10",
      "score": 440,
      "num_comments": 19,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qvizak/data_engineering_as_an_after_thought/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3igd75",
          "author": "meatmick",
          "text": "Yeah... Their tools are also sometimes python scripts, written with AI (nothing againstAI for code but not like this) and are unmaintainable pieces of garbage...\nAll that for the small price of hundreds of thousands of dollars if not millions. Ask me how I know lol",
          "score": 187,
          "created_utc": "2026-02-04 11:23:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3imfy3",
              "author": "TheFach",
              "text": "I probably know the same way as you but tell the story man",
              "score": 37,
              "created_utc": "2026-02-04 12:10:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3jach2",
                  "author": "meatmick",
                  "text": "One of those 3 companies was hired to find things to optimize in our processes. They clearly sold us the dream of saving millions, which so far doesn't look like it'll ever be the case. To do their dream stuff, we needed to provide a shit-load of data from all manners of business units in the company. Then this data gets normalized by them and fed in their \"tool\". The tool uses AI to find the \"things to optimize\". Now the department that paid for this crap is trying to pawn the maintenance off on us in IT. The company also doesn't provide help on how to normalize data to fit their tool, and guess who will probably also be in charge of doing it? So far, they have not found any significant savings and the ROI vs how much their cost (1+ million so far) will take years, if it ever pays back.\n\n  \nAs others have said, it's ok because our VPs can say we're AI enabled.",
                  "score": 41,
                  "created_utc": "2026-02-04 14:31:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ip8di",
              "author": "uncertainschrodinger",
              "text": "As long as the VP can tell execs \"we are AI enabled now\" in the next quarterly report, then it's worth every penny.",
              "score": 38,
              "created_utc": "2026-02-04 12:30:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3l4xoc",
                  "author": "TheFach",
                  "text": "I guess this is sadly the reality of the moment",
                  "score": 4,
                  "created_utc": "2026-02-04 19:40:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3k1zfs",
              "author": "mertertrern",
              "text": "This has been the game with these companies for a long time. Before AI, the term used was \"Machine Learning\", but the pitch was the same. Before that, it was \"Semantic Model\" or \"OLAP Cube\". It's always the same: \"give us your data and $1M, and we'll give you back a miracle\". It's always too good to be true though.",
              "score": 11,
              "created_utc": "2026-02-04 16:42:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3lc506",
                  "author": "South_Candle_5871",
                  "text": "Agreed with the sentiment, but semantic models are real and useful abstractions to non tech data consumers",
                  "score": 1,
                  "created_utc": "2026-02-04 20:15:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qdo86",
                  "author": "JJ3qnkpK",
                  "text": "Working with the resultant product of a major tech consultancy now. I've noticed that they absolutely *fixate* on using a particular suite of products even if they're horrendous solutions to the actual problem. It's like they're trying to farm case studies for how good said suite of products is rather than use the best tool for the job.\n\nIn this case: Microsoft stuff. I've got a Synapse instance with a freakish set of pipelines and notebooks to make it function even somewhat like Databricks. This was a clean slate start from only a few years, so they could have chosen any product, but instead they chose to go all-in on Microsoft.\n\nInstead, this client company paid that consultancy tons of money to custom build janky code on an old platform when they could have saved so much time and money by just using tools made for the job. Now they're digging deeper trying to make this weird stuff work. But hey, at least you got a cool PowerPoint with a bunch of tech product logos with arrows pointing between them (and no description about how said diagram represents an actual solution to the problems at hand).\n\nRabble rabble rabble..",
                  "score": 1,
                  "created_utc": "2026-02-05 15:40:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iuwg7",
          "author": "Rift-enjoyer",
          "text": "Well It was a 3 week project, and the IT said it will take 2 weeks to just get access to data. Also the exec only paid for a POC + a roadmap slides that can score him the next year's bonus.",
          "score": 41,
          "created_utc": "2026-02-04 13:06:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jciy0",
          "author": "decrementsf",
          "text": "Professional maturity is recognizing when to laugh when the consultant leaves the room. Does your boss need political cover for a decision that must be made? That is the only time to use the consultant. Nobody got fired when the consultants advice didn't work out. They're an insurance product.",
          "score": 42,
          "created_utc": "2026-02-04 14:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jgt7o",
              "author": "passing_marks",
              "text": "Yeah a consultant that worked with us said it openly! Blame it on us üòÇ I don't know if that makes me believe in them or not lol",
              "score": 15,
              "created_utc": "2026-02-04 15:04:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jgy7f",
          "author": "glubglublub",
          "text": "As a side question, does any of these companies do any good projects? I feel like they're a fraud at this point lol",
          "score": 14,
          "created_utc": "2026-02-04 15:04:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lbgu9",
          "author": "klubmo",
          "text": "I work for a medium size consulting firm that often gets contracts to come and fix the ‚Äúwork‚Äù that these big companies sold. Often that means completely needing to redo everything from scratch. C-suite loves these big companies, but the directors have to convince the VPs to use us constantly to fix the big firms screw ups.\n\nIt‚Äôs a very expensive way to run a business.",
          "score": 10,
          "created_utc": "2026-02-04 20:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lassb",
          "author": "engineer_of-sorts",
          "text": "Massive fuck you to all the consultants out there getting paid to literally churn out tech debt",
          "score": 10,
          "created_utc": "2026-02-04 20:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ip4tx",
          "author": "Morpheyz",
          "text": "Are you me?",
          "score": 6,
          "created_utc": "2026-02-04 12:29:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oecxn",
          "author": "redeyedbiker",
          "text": "Ugh, all my homies hate BCG",
          "score": 1,
          "created_utc": "2026-02-05 06:59:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv0iyl",
      "title": "DoorDash Sr Data Engineer",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qv0iyl/doordash_sr_data_engineer/",
      "author": "Outside_Reason6707",
      "created_utc": "2026-02-03 18:49:14",
      "score": 182,
      "num_comments": 50,
      "upvote_ratio": 0.95,
      "text": "Recently interviewed at DoorDash. \n\nOnsite had 4 rounds System Design, Data Modeling, Business Partner and Leadership \n\nThe recruiter who had reached out regarding the role had transferred my profile to other recruiter at onsite process. \n\nThis new recruiter , not friendly. In a cold email said that I should book time on her calendar for a prep call. Well there was not a single slot available for next 3 weeks. I kept checking for couple of days and finally found one. On the day of call she rescheduled for different time. On the call read the same pdf that she had shared with me over the email on what to expect. Not a great conversation. I‚Äôve  met really good recruiters who are friendly enough. \n\nSystem Design question - question was quite big 6-7 lines. I‚Äôll put it in simple words - Design DataBricks! Yes, you read it right! Interviewer was interested in knowing how will I write exact YAML code for this. I was able to answer all his questions.\n\nData Modeling - Design fitness app. But the interviewer wanted me to draw visualizations. Well never in my past 8 years of work experience I had to do any visualizations but looks like DE in DoorDash work on visualizations as well. It wasn‚Äôt a basic graph , some advanced trend graph. \n\nBusiness Partner - DoorDash expanding business how will you go about it etc. basic questions interviewer also seem to be onboarded on the approaches\n\nLeadership - Hiring Manager joined 2-3 minutes late. Didn‚Äôt bother to apologize. I ignored that and continued to talk with my positive energy. He said he will leave 10 minutes at the end for me to ask any questions. \n\nQuestions were normal tell me about the time kind. Situation based. I answered all. He had multiple follow up questions. Kept asking something from the list. It was almost 5 minutes to end the meeting and then he stopped and started sharing about the team. Even here he didn‚Äôt ask if I have any questions. I had to ask him when we were at time if I can ask couple of questions. I felt like I performed well.\n\nNext day morning Recruiter‚Äôs cold email came in that team has not decided to move forward. \n\nHappy to answer any questions anyone has. ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qv0iyl/doordash_sr_data_engineer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3e4xpf",
          "author": "DenselyRanked",
          "text": "Sorry that it didn't work out for you and thanks for sharing your experience. Some of these companies do not have a team selection process for DE and given how competitive the market is, you may have been second best to someone that they have already interviewed.\n\nFor the sys design, were they expecting a YAML or was that the agreed upon method to explain the design? How in-depth did you need to get into involving things that are not normally in the JD for data engineering like networking, security, shared resources, etc?",
          "score": 55,
          "created_utc": "2026-02-03 19:07:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ejycx",
              "author": "Outside_Reason6707",
              "text": "I totally agree, but sharing a feedback would really help candidates to understand their weaknesses when candidates actually answered everything they asked! \n\nFor system design- question was design declarative and interactive system that can connect multiple sources like OLTP to event stream and destination could also be multiple like dw, dashboard, etc. again it was a very long question so I don‚Äôt remember exact wording but this was the idea. \nWhen I tried to explain high level design using Medallion architecture interviewer redirected conversation to asking how will I declare it. Then I suggested YAML. Then he wanted to know how in YAML will I explicitly write for each source . Which IDID! Wrote a pseudo script. Then I moved to design again. He asked multiple questions about each component. Semantic layer was something I couldn‚Äôt answer well. I have no idea where thing went wrong , which interview",
              "score": 10,
              "created_utc": "2026-02-03 20:17:44",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3edp3i",
              "author": "Calm_Bodybuilder_335",
              "text": "Yes , can you elaborate on the system design round? What was the expectation?",
              "score": 8,
              "created_utc": "2026-02-03 19:48:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3f1z7z",
          "author": "Informal_Pace9237",
          "text": "They are looking for Unicorns.\nNot normal folks",
          "score": 20,
          "created_utc": "2026-02-03 21:41:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g0wqo",
              "author": "Outside_Reason6707",
              "text": "None of interviewer was anywhere close to unicorn! Not here to rant but just frustrated with so called policy to not share feedback",
              "score": 9,
              "created_utc": "2026-02-04 00:42:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fjyby",
          "author": "Commercial-Ask971",
          "text": "Design databricks in YAML was meant to be databricks asset bundle for running pipelines?",
          "score": 8,
          "created_utc": "2026-02-03 23:10:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gm50u",
              "author": "Outside_Reason6707",
              "text": "Yess",
              "score": 1,
              "created_utc": "2026-02-04 02:42:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eqrtd",
          "author": "epic-growth_",
          "text": "Design data bricks???? Bro I gotta switch out",
          "score": 7,
          "created_utc": "2026-02-03 20:49:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3erfaw",
              "author": "Outside_Reason6707",
              "text": "What do you mean ? Sorry didn‚Äôt understand",
              "score": 2,
              "created_utc": "2026-02-03 20:52:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3etx5w",
                  "author": "epic-growth_",
                  "text": "I‚Äôm a data engineer with much less experience. So doing something like writing YAML code for designing data bricks just seems like a lot to know in the future. And I‚Äôve been thinking of pivoting out of data engineering eventually.",
                  "score": 8,
                  "created_utc": "2026-02-03 21:04:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3e2q71",
          "author": "wiseyetbakchod",
          "text": "Even I had Doordash interview and I felt like I do good. At the end, I received a call saying I didn‚Äôt explain two points in data modelling round correctly.\n\nIn my few, designing exactly the same data model that interviewer have in his mind in one hour is not possible. \n\n\nAfter some permutations and combinations, i realised that they aren‚Äôt looking for someone who can perform. They are looking for perfect 10/10 candidate which seems fair given they are paying top buck.",
          "score": 13,
          "created_utc": "2026-02-03 18:56:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eibq0",
              "author": "Outside_Reason6707",
              "text": "Recruiter said she can‚Äôt share feedback due to company policy.",
              "score": 8,
              "created_utc": "2026-02-03 20:10:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3epbkd",
          "author": "Foreign_Yam3729",
          "text": "How was the technical screen went? I am about to have a call with recruiter ?",
          "score": 3,
          "created_utc": "2026-02-03 20:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3errbz",
              "author": "Outside_Reason6707",
              "text": "It was easy! I luckily got chill interviewer. He wasn‚Äôt concerned about the syntax errors. 4 SQL and one DSA",
              "score": 4,
              "created_utc": "2026-02-03 20:54:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3gbuj0",
          "author": "calimovetips",
          "text": "that sounds frustrating, especially the mismatch between what was tested and what the role likely does day to day. honestly feels like either the loop wasn‚Äôt well calibrated or they were already unsure what they wanted, which is rough but not a reflection of your performance.",
          "score": 3,
          "created_utc": "2026-02-04 01:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gjyld",
              "author": "Outside_Reason6707",
              "text": "I hope that was the case since I started questioning where am I lagging",
              "score": 1,
              "created_utc": "2026-02-04 02:29:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e9za5",
          "author": "Boy675te",
          "text": "India or us ?",
          "score": 8,
          "created_utc": "2026-02-03 19:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ekvfy",
              "author": "Outside_Reason6707",
              "text": "USA",
              "score": 6,
              "created_utc": "2026-02-03 20:22:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e7dqz",
          "author": "SaintTimothy",
          "text": "Run, dont walk. Did you see the whistle blower letter this past week? Who do you think designed the system that determines whether a contractor is \"desperate\"? Do you want to maintain that system, that helps the company further exploit its own staff?\n\nEdit - the story got debunked as fake, my bad",
          "score": 7,
          "created_utc": "2026-02-03 19:18:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e8vph",
              "author": "Intelligent_Series_4",
              "text": "Share link?",
              "score": 3,
              "created_utc": "2026-02-03 19:25:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ear67",
                  "author": "SaintTimothy",
                  "text": "Apparently it was made up :-(\n\nhttps://www.reddit.com/r/doordash_drivers/s/vuOwLwPlpX",
                  "score": 3,
                  "created_utc": "2026-02-03 19:34:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ekxuk",
              "author": "Outside_Reason6707",
              "text": "Sorry I didn‚Äôt get what you said",
              "score": 1,
              "created_utc": "2026-02-03 20:22:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e72xg",
          "author": "armoman92",
          "text": "Thank you for sharing.",
          "score": 2,
          "created_utc": "2026-02-03 19:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f17pq",
          "author": "BeeLive9842",
          "text": "Can you share the resources you follow for preparing system design and data modelling interviews?",
          "score": 2,
          "created_utc": "2026-02-03 21:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eehn5",
          "author": "PplAreStooopid",
          "text": "Could you pls elaborate on the system design \"Design Databricks\" question? What exactly did he want? Did they want a control plane vs compute/data plane architecture details? Also isnt YAML config for all of the resources would be too much right?",
          "score": 2,
          "created_utc": "2026-02-03 19:52:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3elgux",
              "author": "Outside_Reason6707",
              "text": "I answered above in the thread",
              "score": -2,
              "created_utc": "2026-02-03 20:24:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3edr32",
          "author": "Calm_Bodybuilder_335",
          "text": "Is this US based experience?",
          "score": 1,
          "created_utc": "2026-02-03 19:48:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eld3h",
              "author": "Outside_Reason6707",
              "text": "Yes USA",
              "score": 1,
              "created_utc": "2026-02-03 20:24:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fxf48",
          "author": "goeb04",
          "text": "I would be miserable if I put in the effort and quality responses you gave‚Ä¶.and got nothing in the end. Best of luck moving forward OP.",
          "score": 1,
          "created_utc": "2026-02-04 00:23:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g0l13",
              "author": "Outside_Reason6707",
              "text": "Thank you!!",
              "score": 1,
              "created_utc": "2026-02-04 00:40:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3gw3wa",
          "author": "busybeeatwork",
          "text": "Thanks for sharing your experience!",
          "score": 1,
          "created_utc": "2026-02-04 03:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h3sm1",
          "author": "Original_Fox_6278",
          "text": "Sorry to hear that. By any chance can you give like a good resource from where I can practice case studies for data modelling and system design",
          "score": 1,
          "created_utc": "2026-02-04 04:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hnces",
              "author": "Outside_Reason6707",
              "text": "Honestly even I‚Äôm looking for a good resource. So far all I‚Äôm doing is random YouTube videos especially from Exponent",
              "score": 4,
              "created_utc": "2026-02-04 06:58:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3hh7wt",
          "author": "NefariousnessSea5101",
          "text": "What‚Äôs your profile like if I may ask?",
          "score": 1,
          "created_utc": "2026-02-04 06:07:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hnh9d",
              "author": "Outside_Reason6707",
              "text": "Grad School - Top 10 Private Schools in USA 6 years of experience in big tech 2 years in start up",
              "score": 1,
              "created_utc": "2026-02-04 06:59:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ivzmb",
          "author": "Confident-Advice-390",
          "text": "Thanks for sharing your experience.",
          "score": 1,
          "created_utc": "2026-02-04 13:13:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j27i2",
          "author": "rudderstackdev",
          "text": "It is time to document your answers (for imp questions like databricks design) and put it out there on your personal blog. So that you get something out of the time you invested.",
          "score": 1,
          "created_utc": "2026-02-04 13:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l4m7x",
          "author": "agent_kowalski",
          "text": "For system design, were they evaluating tradeoffs (cost, scaling, failure) or more like tool specific expertise (Databricks internals, YAML, clusters, etc.)?",
          "score": 1,
          "created_utc": "2026-02-04 19:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lhn6w",
              "author": "Outside_Reason6707",
              "text": "It was none of that. Interviewer was pretty old school (25+ years of experience) He seemed to be interested in theoretical knowledge- what will you write in YAML, How spark works internally to give you few examples. \nEnlist functional and non functional requirements and when I try to do so he will interrupt and suggest more which I was anyway supposed to talk etc\nProbably not a helpful answer but he just seemed to be not satisfied with whatever I was talking.",
              "score": 1,
              "created_utc": "2026-02-04 20:41:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3gyrjf",
          "author": "No-Carob4234",
          "text": "Interested to hear your profile. Seems like outside of Meta's push a few months ago most FAANG or adjacent only looking for tier 1 schools or previous FAANG.",
          "score": 1,
          "created_utc": "2026-02-04 03:56:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hn7ry",
              "author": "Outside_Reason6707",
              "text": "Grad School - Top 10 Private Schools in USA\n6 years of experience in big tech\n2 years in start up",
              "score": 6,
              "created_utc": "2026-02-04 06:57:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e5xuu",
          "author": "Razzl",
          "text": "No DSA?",
          "score": 0,
          "created_utc": "2026-02-03 19:11:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3el3rn",
              "author": "Outside_Reason6707",
              "text": "That was during technical screen. Interviewer was great and very chill!",
              "score": 2,
              "created_utc": "2026-02-03 20:23:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eae2m",
          "author": "Boy675te",
          "text": "Op when exactly you interviewed ,?",
          "score": 0,
          "created_utc": "2026-02-03 19:32:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqm5vk",
      "title": "Being the \"data guy\", need career advice",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qqm5vk/being_the_data_guy_need_career_advice/",
      "author": "jonfromthenorth",
      "created_utc": "2026-01-29 21:47:36",
      "score": 149,
      "num_comments": 49,
      "upvote_ratio": 0.96,
      "text": "I started in the company around 7 months ago as a Junior Data Analyst, my first job. I am one of the 3 data analysts. However, I have become the \"data guy\". Marketing needs a full ETL pipeline and insights? I do it. Product team need to analyze sales data? I do it. Need to set up PowerBI dashboards, again, it's me.\n\n  \nI feel like I do data engineering, analytics engineering, and data analytics. Is this what the industry is now? I am not complaining, I love the end-to-end nature of my job, and I am learning a lot. But for long-term career growth and salary, I don't know what to do.\n\n  \nSalary: 60k",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qqm5vk/being_the_data_guy_need_career_advice/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2hm4gg",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-29 21:47:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hthcg",
          "author": "instamarq",
          "text": "Automate as much of your job as you can, then start actively seeking out people's pain points and solving them with data. Keyword is \"active\" here, i.e. talk to people, chat it up. Once you feel like you've established yourself as more of a problem solver who's an asset to the business and less of a \"data guy\", ask for a sizable raise and pull out your list of solved business problems.\n\nIf you don't get your way, start looking for somewhere else to go and take that big list of wins into an interview. Do that and you'll move in very much the right direction.",
          "score": 129,
          "created_utc": "2026-01-29 22:23:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2m9tdj",
              "author": "slayerzerg",
              "text": "This. Don‚Äôt be afraid to automate your job. Obviously this may automate other steps in the pipeline / jobs in that business but thats when upper management starts seeing your value as that is what data engineering is about tbh esp as you scale. If you get stuck just being the data guy and do a lot of stuck work it may actually be worse",
              "score": 4,
              "created_utc": "2026-01-30 15:32:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2olwpw",
              "author": "Illustrious_Fun1436",
              "text": "As a new junior in the field, how can one \"automate\" their job? What I work with are sql files and a new task comes in every week. I'm not sure how automation goes (may look like a naive question,¬† but I'm looking for others' experiences)",
              "score": 2,
              "created_utc": "2026-01-30 21:54:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2phpce",
                  "author": "lost_in_santa_carla",
                  "text": "Hmm, any patterns in the transforms / aggs that you do regularly? Could be an opportunity to refine the dataset into something easier to use. If not, would your org get any value from a semantic layer that they could access themselves with little or no input from you?\n\nSounds like automating yourself out of a job but in reality tends to be the opposite imo",
                  "score": 1,
                  "created_utc": "2026-01-31 00:42:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2yujbq",
                  "author": "instamarq",
                  "text": "You must have _some_ repetitive tasks? In my case, if there was a task that took me hours due to multiple steps, I would at the very least create a script of some sort that would consolidate that process into one step. Maybe you can't automate a whole ingestion pipeline yet because no one is asking you to do that, but look at your own process and see where you can replace manual work.\n\nMaybe you don't want to automate the writing of your SQL with AI, but you can perhaps automate how that SQL ends up in the final destination. **The main takeaway is to save yourself time and reinvest the savings in finding valuable problems to solve**.",
                  "score": 1,
                  "created_utc": "2026-02-01 13:37:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2qd1zb",
              "author": "dark_dagger99",
              "text": "100% agree, I got a 35k raise in my first year doing exactly this",
              "score": 2,
              "created_utc": "2026-01-31 03:49:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2sft6f",
              "author": "Internal-Address2279",
              "text": "Solving with data I love the phrase could you give me an example",
              "score": 1,
              "created_utc": "2026-01-31 13:58:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2u6nmx",
                  "author": "instamarq",
                  "text": "Let's say your business is trying to figure out how to keep revenue growth going, despite sales figures trending lower. If you don't already know, figure out why sales are trending lower with the data you have access to and find perhaps a missed opportunity. Maybe a particular product segment could use a small price increase. Maybe there's hidden waste in a product return policy.\n\nIt doesn't have to be this in depth, maybe you automate an alert for some issue that finance is having trouble with based on some check data. All kinds of ways to do this.",
                  "score": 1,
                  "created_utc": "2026-01-31 19:10:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hry4k",
          "author": "x1084",
          "text": ">I feel like I do data engineering, analytics engineering, and data analytics. Is this what the industry is now?\n\nYou wear more hats at smaller companies and on smaller teams. GenAI is also enabling a lot of people to attempt to expand their skillsets and take on tasks that would've previously been outside of their wheelhouse.\n\n>But for long-term career growth and salary, I don't know what to do.\n\nIn a vacuum, if you're strictly talking about growth and salary you probably want to consider pivoting into DE from DA. In fact if you search the subreddit you'll find a ton of posts from people trying to do the same. In some ways you're in an advantageous spot because you're already getting hands on with more technical tasks.",
          "score": 30,
          "created_utc": "2026-01-29 22:15:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ivr4q",
              "author": "LeonardMcWhoopass",
              "text": "I actually do the same now. I don‚Äôt expect I‚Äôll get any significant raises but they‚Äôre talking about grooming me for leadership. Something about potential. Already know it‚Äôs not a long term fit for me with the BS I don‚Äôt like putting up with but it‚Äôs fine",
              "score": 5,
              "created_utc": "2026-01-30 01:48:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2izu5p",
                  "author": "Useful-Bug9391",
                  "text": "I really wish to be in that situation to be honest. \n\nOnce you feel that you have scratched the limit of problem solving for that company and reached dilution... You should look for your way out as you will be packed with arsenal of multiple hat skills and that too on a senior profile. \n\nYou are getting exposure to those things ... It's really helpful.",
                  "score": 2,
                  "created_utc": "2026-01-30 02:10:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ho1mk",
          "author": "MikeDoesEverything",
          "text": ">60k\n\nCurrency and location really helps people.",
          "score": 14,
          "created_utc": "2026-01-29 21:56:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hp9jm",
              "author": "LoaderD",
              "text": "Canada , cad.\n\nIt‚Äôs sadly not horrible salary for jr DA, it‚Äôs dog shit for any DE (Data Developer in Canada)",
              "score": 6,
              "created_utc": "2026-01-29 22:02:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2izy61",
                  "author": "Useful-Bug9391",
                  "text": "What's data developer now??",
                  "score": 1,
                  "created_utc": "2026-01-30 02:11:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hndly",
          "author": "Repulsive-Beyond6877",
          "text": "When you say ETL pipes, what are you using to build, test, and deploy?",
          "score": 7,
          "created_utc": "2026-01-29 21:53:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hrqbf",
              "author": "jonfromthenorth",
              "text": "GCP, using python scripts to ingest data from various sources into BigQuery, testing is also python\n\njobs are containerized and run on Cloud Run\n\nFor the display and insights layer, it's Sheets of PowerBI, and R for statistical analysis",
              "score": 15,
              "created_utc": "2026-01-29 22:14:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2i8idf",
                  "author": "Repulsive-Beyond6877",
                  "text": "I‚Äôd say if DE is your desired path then go somewhere else to play with tools that are used in bigger companies. Spark, Beam, Airflow, etc. just showing you know how to deal with data at scale and how to orchestrate it and recover from disasters.\n\nPython is handy, although depends on how you‚Äôre using it.\n\nThe role you‚Äôre currently in is definitely exploiting you and you‚Äôre not being compensated correctly.",
                  "score": 3,
                  "created_utc": "2026-01-29 23:41:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2hvdkx",
                  "author": "bradcoles-dev",
                  "text": "How big is the company? This feels like shadow IT to me. This approach wouldn't be overly attractive to a DE hiring manager. If your org has its own enterprise data platform, e.g. established, governed, cloud tooling, you need to get involved in that. If they don't have that and you want a DE career, you're better off finding a new employer.",
                  "score": 6,
                  "created_utc": "2026-01-29 22:32:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2i70mw",
          "author": "Big-Touch-9293",
          "text": "I do everything you say for what it‚Äôs worth to you",
          "score": 5,
          "created_utc": "2026-01-29 23:33:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ifus0",
          "author": "Murder_1337",
          "text": "This all seems about right. They got you doing all the work cuz you‚Äôre the JR with talent. The better you are at your job the more work you will have to do. Keep this up so they see you as a all star and try to get to the point where you can be Sr. then you can slack off",
          "score": 3,
          "created_utc": "2026-01-30 00:21:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jzntj",
          "author": "Immediate-Pair-4290",
          "text": "Yes this is the industry now. They expect you to be a super hero while they follow garbage manual processes. Make sure you are being paid  handsomely for it or leave.",
          "score": 3,
          "created_utc": "2026-01-30 05:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hvy66",
          "author": "Sharp_Conclusion9207",
          "text": "If you're at a regular company, almost no one else at your business has done anything half as cognitively demanding as building out end to end business reporting. And you're getting paid peanuts.",
          "score": 2,
          "created_utc": "2026-01-29 22:35:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iijty",
          "author": "SaintTimothy",
          "text": "Sounds like youre up for a promotion. Here's the thing though, they'll never see you as the engineer once they paid you like an analyst.\n\n\nBest thing I've seen some folks do is hop to consulting for a year and then come back if they'll have you, at a properly market adjusted rate.",
          "score": 2,
          "created_utc": "2026-01-30 00:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2imkqv",
          "author": "1HunnidBaby",
          "text": "Unless you‚Äôre already working in a big tech company the best way to increase your pay is to switch jobs. I worked at a startup doing everything like you said and move to big tech and got paid 60% more",
          "score": 2,
          "created_utc": "2026-01-30 00:56:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2j6qnp",
          "author": "Sizzlingbrowny",
          "text": "I am a business intelligence analyst I also do the same in-fact more (python +sql+databricks +azure services+power bi) and I am also wearing business analyst hat too  for gathering requirements from SMES and ops guys . I am really in a confused state Whether I need to stay in the same role or move ?forward I am getting paid 85kUSD",
          "score": 2,
          "created_utc": "2026-01-30 02:48:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ir6cb",
          "author": "ZirePhiinix",
          "text": "You're on a team of three, what do the others do?",
          "score": 1,
          "created_utc": "2026-01-30 01:22:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2j7qgn",
          "author": "varwave",
          "text": "As someone who landed a similar role, but had an extensive background in programming and statistics‚Ä¶make friends with software engineers in your company. Try a lateral move. Use best practices. If you want to be treated like an software engineer, then act like one, then search for jobs. You‚Äôre not in a bad spot",
          "score": 1,
          "created_utc": "2026-01-30 02:54:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jg8sr",
          "author": "Spunelli",
          "text": "That's 100k work, for real. However, you still have to earn your stripes. Keep a record of what you do so you can sell yourself in the next interview. After 2 years here, start interviewing.\n\nBut yea, that's the gig. Especially for small companies and when you don't know what you don't know to effectively set boundaries.",
          "score": 1,
          "created_utc": "2026-01-30 03:43:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jgajn",
          "author": "TechnoGauss",
          "text": "This might be an unpopular opinion and counter-advice to some of the feedback you've already received but I would urge you to set up some boundaries. I'm not saying don't volunteer to take on some projects that might expand your skills but just be cautious with how much you take on because you can quickly and easily find yourself doing the job of 3 people. Sounds like this is already the case for you but not sure how far down this path you are at the moment hence why I mention this. Once you start doing this it becomes an expectation and more money isn't always on the horizon unless you have a good boss and great work place culture.",
          "score": 1,
          "created_utc": "2026-01-30 03:43:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jlrug",
          "author": "Cwlrs",
          "text": "I'm shocked 'analytics engineering' ever got given it's own dedicated title. It's so narrow in it's definition it's unrealistic at any company where you might need to help fix a variety of software problems.\n\nAs for your career... it sounds like you're doing all the typical things so... keep going?",
          "score": 1,
          "created_utc": "2026-01-30 04:16:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jmcmz",
          "author": "JBalloonist",
          "text": "For long-term career growth I would just keep doing what you‚Äôre doing and learn how you make things run more smoothly. I‚Äôm in the same boat as you but since I‚Äôve been doing it a long time I‚Äôve got a Director title and the salary to go with it.",
          "score": 1,
          "created_utc": "2026-01-30 04:20:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jsdbm",
          "author": "moshujsg",
          "text": "I see no problem, just a man doing everything and learnikg everything.",
          "score": 1,
          "created_utc": "2026-01-30 04:59:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kofcu",
          "author": "a-ha_partridge",
          "text": "I‚Äôm basically you from a decade or so in the future as a principal analyst which for me is hybrid data engineer/business analyst role. I spend my days building and maintaining pipelines in airflow, automating different tasks for people with python/sql, developing scripts to ingest data from external sources, writing ad hoc queries, making dashboards, and talking to the non technical folks about their needs. I almost never provide actual analytics these days, but If the word ‚Äúdata‚Äù comes up in any context it ends up on my desk somehow. That never goes away when you are ‚Äúthe data guy‚Äù. \n\nIf you enjoy it, embrace it because it eventually pays very well, and you‚Äôll usually be one of the last people that they‚Äôd ever want to get rid of. The job skills are incredibly transferable too, so long as you keep building on them. That‚Äôs helpful because the key to making more money is to change companies every few years - ideally around the same industry.\n\nBest wishes for your data guy career!",
          "score": 1,
          "created_utc": "2026-01-30 09:22:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kyk9b",
          "author": "Secret-Life-2192",
          "text": "Which industry and scale of company are you in?",
          "score": 1,
          "created_utc": "2026-01-30 10:53:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2q6ips",
          "author": "Greedy_Ad5722",
          "text": "Honestly, take on as many projects as you can, use it to upgrade your resume and dip. I was helpdesk tier2 until 7 month ago and was making 65K. You are definitely under paid lol",
          "score": 1,
          "created_utc": "2026-01-31 03:08:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rdrph",
          "author": "Annual_Expression185",
          "text": "Research with ai tools what the future roadmap is headed in your space, and start working on the skillset that is lacking , that you can add t your resume. It takes bit of forethought, but the experience you are gaining is great. Lastly, find a mentor, in your area, who can perhaps give you some sage advice. it is good, that you are asking for help. Gl, and best wishes. \"A fool learns from his mistake, but a wiseman learns from the mistake of others. \" -Source unknown.",
          "score": 1,
          "created_utc": "2026-01-31 08:46:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sbglz",
          "author": "Business-Crab-9301",
          "text": "Hello! I would just like to ask if you have any tips on how to start learning this kinds of skill. I am very interested in handling this kind of thing",
          "score": 1,
          "created_utc": "2026-01-31 13:32:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30kawb",
          "author": "Bodhisattva-Wannabe",
          "text": "Data engineering is a better prospect than data analysis in terms of career. So much so that the uk government has downgraded the data analyst role so it doesn‚Äôt qualify for a higher skilled worker visa and is now classified as a non graduate role. \n\nIt‚Äôs actually worth knowing both but data engineering experience will provide more leverage. \n\nPersonally having worked both sides I much prefer data engineering to analysis. \n\nIf you can, see if you can use the things you are learning to work towards some certifications. I always like to see CPD on a CV. \n\n(YMMV of course. )",
          "score": 1,
          "created_utc": "2026-02-01 18:37:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34h5yb",
          "author": "geoheil",
          "text": "You might find some of these ideas useful https://georgheiler.com/post/learning-data-engineering/",
          "score": 1,
          "created_utc": "2026-02-02 08:32:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b8zms",
          "author": "techjobmentor",
          "text": "seems to me that you are learning a lot, you're starting and getting to an expertise level that you'll be able to leverage later on, keep up the good work and you'll be landing more specific roles",
          "score": 1,
          "created_utc": "2026-02-03 08:56:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv5w7i",
      "title": "Fivetran cut off service without warning over a billing error",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qv5w7i/fivetran_cut_off_service_without_warning_over_a/",
      "author": "DigitalDelusion",
      "created_utc": "2026-02-03 22:07:31",
      "score": 148,
      "num_comments": 30,
      "upvote_ratio": 0.92,
      "text": "I need to vent and have a shoulder to cry on (ib4 \"I told you so\"). \n\nWe've been a Fivetran customer since the early days. Renewed in August and provided a new email address for billing. Our account rep confirmed IN WRITING that they would do that. They didn't. Sent the invoice to old contacts intead, we never saw it. \n\nNo past due notice.   \nNo grace period. \n\nThis morning 10;30 am services turned off. \n\nWe're a reverse-ELT shop: data warehouse feed *everything.* Salesforce to ERP. ERP to Salesforce, EAM to ERP, P2P to ERP, holy crap there's so much stuff I've built over the last few years. All down. I mean that's not even calling out the reporting! \n\nWired the payment, proof from the bank send. Know what they said? \n\n\"Reinstatement takes 24-48 hours\"\n\nBro. 31k to 45k in our renewal cycle and we moved connectors off. \n\nI know it's so hot right now to shit on Fivetran. I'm here now. I was a fan (was featured on a dev post too). \n\nI can't get anyone on the phone, big delays in emails. Horror. ",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qv5w7i/fivetran_cut_off_service_without_warning_over_a/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3g39f7",
          "author": "data4u",
          "text": "This is why customer support and customer success are crucial. Time to roll your own ELT.",
          "score": 41,
          "created_utc": "2026-02-04 00:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fecpu",
          "author": "No_Lifeguard_64",
          "text": "I empathize with you OP and while I think Fivetran sucks, all these tools in the \"connector\" space are varying degrees of bad so while I would recommend getting off of Fivetran because the amount you're paying is actually crazy, you will run into SOME issue with all of the tools.",
          "score": 42,
          "created_utc": "2026-02-03 22:41:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ff00c",
              "author": "DigitalDelusion",
              "text": "My leadership team is going to make me break contract. This is terrible. We've been down all day and I can't get anyone on the phone, just an email every few hours. \n\nThe value prop is I don't need as many devs here to maintain these pipelines and that I'd have someone to call when things went south. \n\nThat trust is being broken.",
              "score": 31,
              "created_utc": "2026-02-03 22:44:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3gc4wq",
                  "author": "Nottabird_Nottaplane",
                  "text": "This is a disaster on both sides. I‚Äôm shocked FiveTran would allow something like this; that your AEs/CSMs are MIA; that this is all happening. I can also only imagine you‚Äôre panicking a bit since you probably have customers to serve of your own and this is impacting that.\n\nHuman error + rules-lawyering & rigid policy + lazy response = apocalyptic scenarios, every time",
                  "score": 17,
                  "created_utc": "2026-02-04 01:45:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3hfzg0",
                  "author": "C2mind",
                  "text": "I chose airbyte after using fivetran at my last company. Very glad I did. It took a bit to get the infra in place for self hosting but has been smooth sailing ever since. I know you‚Äôre not asking for these kind of recs but just wanted to point out that there are alternatives that you can still manage with a lean team.",
                  "score": 2,
                  "created_utc": "2026-02-04 05:57:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3i31sf",
                  "author": "Thinker_Assignment",
                  "text": "you don't need many devs in this day and age to maintain pipelines if you use stuff with schema evolution, resllience and a little LLMs for maintenance. You can ask a LLM for fixes faster than you can get that out of Saas support.",
                  "score": 2,
                  "created_utc": "2026-02-04 09:22:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3juqgh",
                  "author": "No_Lifeguard_64",
                  "text": "I'm not affiliated with either of these tools but I would recommend looking at [integrate.io](http://integrate.io) or dlthub+. Both of these tools do integration and are based around the idea of very small teams. [Integrate.io](http://Integrate.io) is more tailored to your use-case from what I understand and would cut your Fivetran bill in half. We demoed both of these tools and found that while we liked them, they had shortcomings that made it no go for us but the teams were great.",
                  "score": 1,
                  "created_utc": "2026-02-04 16:09:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3g58w3",
          "author": "Choperello",
          "text": "Fivetran is predatory. The fact DBT sold to them made beyond sad.",
          "score": 28,
          "created_utc": "2026-02-04 01:06:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g7smz",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 16,
              "created_utc": "2026-02-04 01:21:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ikg7h",
                  "author": "StarWars_and_SNL",
                  "text": "Fivetran acquired SQLmesh in September then dbt in October. No months in between. It happened crazy fast.",
                  "score": 8,
                  "created_utc": "2026-02-04 11:55:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3fcygm",
          "author": "Murky_Extension2089",
          "text": "u/DigitalDelusion \\- I'm a PM at Fivetran. I'll DM you to get more details.",
          "score": 30,
          "created_utc": "2026-02-03 22:34:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gc18h",
          "author": "calimovetips",
          "text": "that‚Äôs brutal, especially with reverse-elt where everything is chained together. cutting service with no past due notice or grace period is an ops failure, not a billing one, and 24 to 48 hours is a long time when prod depends on it.",
          "score": 5,
          "created_utc": "2026-02-04 01:44:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gthpc",
          "author": "GreyHairedDWGuy",
          "text": "definitely sounds like some CSM somewhere messed up big time.  There should have been ways to reach someone at your company.  Shutting you off is bush league.\n\nPersonally I like Fivetran.  It allows us to focus on other DE tasks (and let them deal with changing API's...etc).   \n\nHowever, if this happen to us, I'd insist that they provide us at least 3 months free usage and if not.  Look at alternatives or roll your own.",
          "score": 5,
          "created_utc": "2026-02-04 03:24:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gae7t",
          "author": "mertertrern",
          "text": "No customer service? How about no customers then.",
          "score": 4,
          "created_utc": "2026-02-04 01:35:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g84rf",
          "author": "MandrillTech",
          "text": "the 24-48 hour reinstatement after they screwed up the billing is wild. that's basically saying 'we broke it but you get to eat the downtime.' at minimum i'd be documenting everything for contract renegotiation leverage, especially since they confirmed the billing change in writing.",
          "score": 3,
          "created_utc": "2026-02-04 01:22:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ht1pt",
          "author": "Kukaac",
          "text": "This is crazy, as customer support used the be a huge thing for Fivetran. If that's gone all will they have is high prices.",
          "score": 3,
          "created_utc": "2026-02-04 07:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3julfd",
          "author": "ClavLos",
          "text": "This is exactly where trust breaks. When your warehouse feeds everything, ‚Äú24‚Äì48 hour reinstatement‚Äù is unacceptable.\n\nI‚Äôm one of the founders at SupaFlow. We‚Äôre an alternative to Fivetran focused on pipeline reliability, sane pricing, and real humans when things go sideways.\n\nNot here to pile on ‚Äî just saying teams shouldn‚Äôt have to accept this as normal.",
          "score": 2,
          "created_utc": "2026-02-04 16:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3il50k",
          "author": "Therican85",
          "text": "Just got up tools like Matia. Screw fivetran, I'm sorry, thief-tran",
          "score": 1,
          "created_utc": "2026-02-04 12:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iw261",
          "author": "Used-Comfortable-726",
          "text": "If you‚Äôre considering switching to a more enterprise IPaaS, I recommend **MuleSoft**, especially for Salesforce<>ERP<>EAM<>P2P.  Real-time transactional bidirectional sync across all endpoints is way more efficient than multiple ETL/RETL jobs.  And if you‚Äôre company already has a Salesforce contract, the billing for MuleSoft will just rollup (and optionally co-terminate if you want) into your existing contract, so one less vendor to pay",
          "score": 1,
          "created_utc": "2026-02-04 13:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3j07gp",
              "author": "Nekobul",
              "text": "MuleSoft is dead at this point after the Informatica acquisition.",
              "score": 1,
              "created_utc": "2026-02-04 13:37:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3jnabk",
              "author": "rico_andrade",
              "text": "Celigo is a good option too.",
              "score": 1,
              "created_utc": "2026-02-04 15:35:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3i2qaz",
          "author": "Thinker_Assignment",
          "text": "# it's trival to replace them in this day and age\n\nNowadays you can replace them in about 1h per pipeline to get the code, and of course a little more to do the actual migration ops and any stitching or backfilling.\n\nI recently ran an experiment where I give an LLM the target model of a saas pipeline and ask it to fill the gap between my current OSS pipeline and the target state.\n\nIt works extremely well in cursor, getting your work done within the hour per pipeline - in my experience not only did claude make the SQL to do the migration, but it also extended the python ingestion side to call more endpoints",
          "score": -3,
          "created_utc": "2026-02-04 09:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ikl23",
              "author": "StarWars_and_SNL",
              "text": "Ok now do that work under the pressure of prod being down",
              "score": 5,
              "created_utc": "2026-02-04 11:56:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3j03v9",
                  "author": "Thinker_Assignment",
                  "text": "I'm not victim blaming and neither should you  \n  \nNothing you can do can bring your pipelines back, or within your control, except migrating away.\n\nPressure can only be released by vendor or by migration. The business is under pressure, why should you accept it, did you choose to give control to a 3rd party? nah it was your manager",
                  "score": 0,
                  "created_utc": "2026-02-04 13:36:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3j01yl",
              "author": "Nekobul",
              "text": "That is a bold-faced lie.",
              "score": 1,
              "created_utc": "2026-02-04 13:36:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3j3hcu",
                  "author": "Thinker_Assignment",
                  "text": "We are seeing 55-60% success rates per session (n=800) with python ingestion pipelines.   \n  \nAt the event we did at Motherduck's Amsterdam office last week, multiple users presented how they reach first pipelines in 1h.  \n  \nFor T our current eval shows 70% success rate with 1-shot to bridge the T from raw to a target model like a Saas,   \n  \nIn work session in cursor that 70% becomes a 95%+ match within 1h\n\nMy guess is by the end of the year multiple players will offers complete end to end automation as a \"starting point\" for AI driven customisation\n\nhere's openAI describing how they take over a stack and replace customisation with a LLM memory layer. [https://openai.com/index/inside-our-in-house-data-agent/](https://openai.com/index/inside-our-in-house-data-agent/)\n\nHere's snowflake describing generating canonical views.  \n[https://x.com/Snowflake/status/2018660572980707741](https://x.com/Snowflake/status/2018660572980707741)\n\nbut you do you man, i see your contributions here and as far as I can tell your opinions are very old school and rigid and lack acceptance of current practices and reealities",
                  "score": 1,
                  "created_utc": "2026-02-04 13:55:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3fjbzt",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -11,
          "created_utc": "2026-02-03 23:06:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g08j9",
              "author": "AskMeAboutMyHermoids",
              "text": "Your website is so slow.",
              "score": 5,
              "created_utc": "2026-02-04 00:38:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqsfmm",
      "title": "Got told ‚ÄòNo one uses Airflow/Hadoop in 2026‚Äô.",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qqsfmm/got_told_no_one_uses_airflowhadoop_in_2026/",
      "author": "Useful-Bug9391",
      "created_utc": "2026-01-30 02:06:30",
      "score": 138,
      "num_comments": 88,
      "upvote_ratio": 0.94,
      "text": "They wanted me to manage a PySpark + Databricks pipeline inside a specific cloud ecosystem (Azure/AWS). Are we finally moving away from standalone orchestration tools?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qqsfmm/got_told_no_one_uses_airflowhadoop_in_2026/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2j61kr",
          "author": "latro87",
          "text": "Standalone orchestration like Airflow is nice to have when you are orchestrating many different technologies and need to link dependencies. It‚Äôs also nice when you need to ‚Äúreplay‚Äù data assuming you wrote your dags properly.\n\nMy company uses GCP‚Äôs managed Airflow called Composer and it works great and doesn‚Äôt cost too much.",
          "score": 155,
          "created_utc": "2026-01-30 02:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jeya7",
              "author": "gajop",
              "text": "I'd like to know more because my opinion of GCP Composer is the direct opposite of yours.\n\nIt's very expensive if you want to just automate a simple job. You need an always-on Scheduler, Worker and \"Environment\", and you also end up paying for logs which is substantial. Our cheaper envs are $600/month and the more expensive ones exceed $1000/month in total costs (composer, logs, support, taxes...).\n\nIt's also kinda slow and problematic to use with multiple independent projects. The GKE part makes most jobs have 10~20s startup and imo you must containerize most projects if you don't want your team's having issues. It also sucks for DR that you can't have a proper \"cold start\" env.\n\nThe annoying bit with Composer, most projects are probably best off combining BQ and Cloud Run Jobs for actual compute, and for that the orchestrator really shouldn't be doing much, just IO. I took this thinking and deployed a sub $100/month Dagster with single webserver that orchestrates BQ and Cloud Run Jobs, works better imo..",
              "score": 27,
              "created_utc": "2026-01-30 03:35:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2jja4k",
                  "author": "latro87",
                  "text": "I do not disagree with your statement. If it is something simple then yes it is way overkill. As I said in my original comment a dedicated orchestrator is great for a complex environment with many different pieces. And yes I agree the GKE does cause a lag for job starts, but we're doing batch data processing so aside from the annoyance when you're trying to ad-hoc run something it doesn't affect us.\n\nFor my company it saved us a nice chunk of cash, relatively speaking, because we came from Prefect. On Prefect we were paying $60k a year (to Prefect) AND the prefect jobs were containerized in our GCP environment and running there as well (meaning we were also paying for container execution ontop of the 60k). This of course could be very different now, we made the decision to switch and save money 3 years ago when Prefect was pushing us to move to Prefect 2. Since upgrading to Prefect 2 was going to require a bit of rework, it was the best time to assess the cost to migrate away. If you have to rewrite code anyway... that makes the decision easier.\n\nOur Composer cost is about $30k a year total for 2 environments (Test & Prod).\n\nBut yeah, if you don't have a lot of jobs or complex stuff going on, I'd just spin up Airflow in a container or VM. I've not used Dagster but I've heard good things.",
                  "score": 13,
                  "created_utc": "2026-01-30 04:01:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2jkw8e",
                  "author": "Embarrassed-Count-17",
                  "text": "How did you deploy your dagster web server so that web traffic would be allowed to start BQ/CR jobs? \n\nAsking because we‚Äôre on composer and it‚Äôs overkill for what we use it for. Like to experiment with dagster but getting networking requests through is a nightmare.",
                  "score": 1,
                  "created_utc": "2026-01-30 04:11:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2n6b20",
                  "author": "nord2rocks",
                  "text": "We run airflow composer, but our dags spin up dataproc clusters, deploy scripts to the cluster then shut down the cluster - instead of trying to manage environments and the workers connected to airflow directly. \n\nIn all its so much cheaper than having workers constantly on. Pretty ideal horizontal scaling for us, especially since we can choose number of workers and utilize our different custom dataproc images for the environments.",
                  "score": 1,
                  "created_utc": "2026-01-30 17:57:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2j6nb3",
              "author": "Useful-Bug9391",
              "text": "That's great ... Do you see them shifting to others or have you spotted any industry trend ? \n\nWhile working actively in DE role .. what do you think industry is demanding right now on skill , tech stack requirements?",
              "score": 3,
              "created_utc": "2026-01-30 02:48:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2j9k7g",
                  "author": "latro87",
                  "text": "Honestly in terms of skills, if I am hiring someone for DE or data warehousing, in general, I wouldn‚Äôt care too much what orchestration or scheduling tech they used before.\n\nIf you already can do python, sql, and dbt then you should be fine picking up any scheduler/orchestrator.\n\nIn terms of other skills I‚Äôd say snowflake/databricks/bigquery are pretty in demand. At a data processing level: spark, python, sql, dbt are all good.\n\nA lot of people in this sub also talk about azure fabric, but I don‚Äôt know much about it.\n\nKeep in mind the market, at least in the US, is pretty cut throat right now so getting any job is going to be a struggle.",
                  "score": 18,
                  "created_utc": "2026-01-30 03:04:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2jiik3",
                  "author": "AdResident6496",
                  "text": "Airlfow/hadoop is pretty much outdated. We did this migration to airflow /aws/ spark clusters back in 2018..\n\nAnd last 2 years working for different project in airflow/gcs composer and bigqiery which is seamless.\n\nI would say airflow/hadoop is definitely outdated.\n\nAirflow is a good skill. \nThe issue in terms off interview is, the clients expect cloud experience in whatever they are using aws,gcp or azure.\n\nIt is because of the learning curve and trainings. They speak in cloud terminologies which will take time to adjust. If you have atleast one cloud provider experience with airflow, you can sail through.",
                  "score": 3,
                  "created_utc": "2026-01-30 03:56:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2jgzdt",
              "author": "kenfar",
              "text": "> It‚Äôs also nice when you need to ‚Äúreplay‚Äù data assuming you wrote your dags properly.\n\nHmm, an inability to reprocess a bad feed is terrible",
              "score": 1,
              "created_utc": "2026-01-30 03:47:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2j2ifz",
          "author": "Otherwise_Movie5142",
          "text": "Someone forgot to tell my $10b company",
          "score": 96,
          "created_utc": "2026-01-30 02:25:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j43h3",
              "author": "Useful-Bug9391",
              "text": "Get me hooked in it por favor üôÇ‚Äç‚ÜïÔ∏è",
              "score": 10,
              "created_utc": "2026-01-30 02:34:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lvmbm",
                  "author": "Old_Tourist_3774",
                  "text": "Brasil mentioned √â PENTAAAAA",
                  "score": -1,
                  "created_utc": "2026-01-30 14:24:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2jc3yh",
              "author": "Big-Touch-9293",
              "text": "Same lol, multi billion company and that‚Äôs all we use",
              "score": 4,
              "created_utc": "2026-01-30 03:19:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2k02x8",
                  "author": "Useful-Bug9391",
                  "text": "man i am really feeling wasteful in startup right now.   \nHappy for you \n\n![gif](giphy|w2ldbBLfoB37AcqVem)",
                  "score": 1,
                  "created_utc": "2026-01-30 05:54:44",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2kifl9",
              "author": "a-ha_partridge",
              "text": "Same - $35 billion revenue and its airflow all the way down.",
              "score": 1,
              "created_utc": "2026-01-30 08:28:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2muyvg",
                  "author": "Useful-Bug9391",
                  "text": "Damnnn man y'all are packing",
                  "score": 1,
                  "created_utc": "2026-01-30 17:06:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2jctgl",
          "author": "EconomixTwist",
          "text": "Not sure why you concatenated Airflow and Hadoop into a single expression because they are entirely different tools. ¬†You ask about orchestration tools, of which Hadoop is not but‚Ä¶ airflow is still INCREDIBLY common, and growing.\n\nNobody is really writing net new greenfield code in hadoop anymore though.\n\nand for the record, because this sub REALLY seems to struggle to understand:\n\nAIRFLOW IS NOT AN ‚ÄúETL TOOL‚Äù\n\n‚ÄúBut I can do etl on it‚Äù. You can also do ETL on a raspberry pi or your iPhone with the appropriate amount of motivation. Airflow is for orchestration and it orchestrates pretty much anything- ¬†not just ETL!",
          "score": 91,
          "created_utc": "2026-01-30 03:23:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jjl2y",
              "author": "Necessary-Change-414",
              "text": "You released my steam bro. That's the way!",
              "score": 14,
              "created_utc": "2026-01-30 04:03:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2nr8rf",
              "author": "arroadie",
              "text": "Someone, somewhere read this ‚ÄúETL on an iPhone‚Äù and will come up with a SaaS solution for it soon‚Ä¶",
              "score": 5,
              "created_utc": "2026-01-30 19:29:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2k09uz",
              "author": "Useful-Bug9391",
              "text": "Fair call ... hehe.. my bad .. definitely didn't mean to conflate the two. It was more about the interviewer lumping them together as 'legacy' to justify moving toward an all-in-one cloud stack.\n\nTo your point on Airflow being a conductor: I totally agree. But it seems like more shops are now prioritizing 'compute-first' stacks. They‚Äôd rather keep their PySpark logic and scheduling inside one ecosystem (like Databricks) to avoid the overhead of a separate orchestrator.\n\nIn your view, is the industry losing something by ditching specialized tools for these 'integrated' cloud schedulers?",
              "score": 3,
              "created_utc": "2026-01-30 05:56:12",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2rehg2",
              "author": "ScottFujitaDiarrhea",
              "text": "And if you want you can just execute python in the airflow environment itself with the PythonOperator. It‚Äôs not that robust, but it‚Äôs simple; and often times companies aim way too far out on their needs. Companies I‚Äôve worked for in the past used glue jobs far too loosely when they‚Äôve been completely unnecessary given the quantity of data and the size of the objects.",
              "score": 2,
              "created_utc": "2026-01-31 08:53:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jebjj",
          "author": "MonochromeDinosaur",
          "text": "Last 3 companies I worked for use airflow.",
          "score": 21,
          "created_utc": "2026-01-30 03:31:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k0dth",
              "author": "Useful-Bug9391",
              "text": "i will share this thread with that interviewer \n\n![gif](giphy|tXL4FHPSnVJ0A)",
              "score": 0,
              "created_utc": "2026-01-30 05:57:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2kqth9",
                  "author": "Little_Kitty",
                  "text": "I'm sure tech bro with a bootcamp and two years of experience and a role self-titled as lead knows more than everyone here ü§°",
                  "score": 4,
                  "created_utc": "2026-01-30 09:45:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2jovr7",
          "author": "jdl6884",
          "text": "Airflow is still very prevalent and growing. Also, not sure why Hadoop was included in that concatenation. Very different tools. \n\nAirflow / Dagster - orchestration tools. These excel in orchestrating the flow of data between various systems. Think website -> api -> database -> analytics report. Hadoop is a ‚Äúdead‚Äù technology. Essentially makes no sense for greenfield but some companies have legacy platforms that still need support.",
          "score": 13,
          "created_utc": "2026-01-30 04:36:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k1bae",
              "author": "Useful-Bug9391",
              "text": "That‚Äôs a helpful distinction. I think the interviewer was just using 'Airflow/Hadoop' as shorthand for 'tools we don't want to manage ourselves anymore.'\n\nAs someone coming at this from a **PySpark** perspective, I‚Äôll be honest: the orchestration side feels like a maze. If you were starting today, how would you recommend getting hands-on with the 'modern' way of doing this? Is it better to just learn Spark logic first and worry about the 'conductors' (like Dagster/Airflow) later, or is there a specific project type that makes the whole flow click?",
              "score": 1,
              "created_utc": "2026-01-30 06:04:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lsax1",
                  "author": "jdl6884",
                  "text": "I think so. In my opinion, the ‚Äúmodern‚Äù approach is to focus design on flexibility and extensibility. And always follow the KISS mantra. If you have a simple pipeline and only need a cron job to orchestrate, so be it. But build it in a way where that cron job can be replaced by something else. \n\nI‚Äôm not as familiar with Airbyte but use Dagster on a day to day basis. It uses a concept of software backed assets. Assets can be just about any piece of code and swapped in and out for different things. SQL, python, pyspark, databricks, snowflake, etc. Create your pipelines in a plug and play way where if you need to swap components or insert a new step in the pipeline, you can just map the expected inputs and outputs.",
                  "score": 1,
                  "created_utc": "2026-01-30 14:07:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2kiq3o",
          "author": "Nargrand",
          "text": "Marketing is a powerful tool, I was talking with some early career data engineers and they didn‚Äôt know that you can run spark outside databricks.",
          "score": 7,
          "created_utc": "2026-01-30 08:30:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l0pjf",
          "author": "Gullyvuhr",
          "text": "Databricks is literally managed spark. I will leave it to the imagination where spark comes from. I don't know of any company not using airflow, even if they use it poorly and pretend it's just roidrage chron.\n\nHDFS should be going away, since so few companies ever actually built a lake with unstructured data, but I still see it out there all the time.",
          "score": 7,
          "created_utc": "2026-01-30 11:11:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jm6lz",
          "author": "tttakudo",
          "text": "Here you are,\nhttps://airflowsummit.org/sessions/2025/airflow-openai/\nAnthropic(Claude) also ask for airflow in their analytics role",
          "score": 5,
          "created_utc": "2026-01-30 04:19:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x7qkh",
              "author": "Useful-Bug9391",
              "text": "That isssss resourceful... Thank you üôåüèª",
              "score": 2,
              "created_utc": "2026-02-01 05:21:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2kilza",
          "author": "eccentric2488",
          "text": "What we see these days is the \"managed version\" of open source frameworks and technologies. Dataproc for Spark, Cloud Composer for Airflow, Pub/Sub for Kafka etc etc...\n\nHadoop has been replaced by Spark, I agree. But Airflow I reckon is still used for scalable complex workflows. I use it for my work on the Linux Mint platform, works well.",
          "score": 4,
          "created_utc": "2026-01-30 08:29:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sqk7p",
              "author": "goldi8",
              "text": "Yeah also the amount of pseudo open source stuff like Dagster and Perfect are growing... Like SSO, Permission and User Management behind a Paywall whereas the non commercial stuff is open source. \n\nAirflow, Spark, Hadoop and all that stuff is truely open source with support of exactly these important features",
              "score": 1,
              "created_utc": "2026-01-31 14:59:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2j9qiy",
          "author": "KeeganDoomFire",
          "text": "I work at a serious large company that's a bunch of sub companies with every new product being spun up by a team that's clever and picked a new data backend from the other 100 teams. \n\nMy team does a lot of skunk works 'oh no we didn't plan for the data ' kinda projects and have landed in airflow for all of it. \n\nThere are absolutely better products that are more specialized but we have wrote our own modular dag generators and about 2/3 of our dags are 10 line yaml files now and we can easily restate data.\n\nIt's honestly super cool to be able to sensor for s3 files, kick off a pipe, sensor for its end, kick off dbt, all from the same 50-100 lines of easy to read python.\n\nI've recently also started to look at kicking emr jobs off for some of the huge pipes that need external compute.",
          "score": 9,
          "created_utc": "2026-01-30 03:05:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jkzu9",
              "author": "GuhProdigy",
              "text": "Dang I want this. What‚Äôs first step?",
              "score": 2,
              "created_utc": "2026-01-30 04:12:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2jofmz",
                  "author": "KeeganDoomFire",
                  "text": "Burn out using talend for 2 years where even just changing a name of a csv in a job took 2 hours and tell your bosses your either going to quit, cut your eyes out or find a new tool. \n\n6 months trialing tools and doing pro/con reviews with the team. Show them backfills and secrets manager so credential updates don't require a full redeploy of 100 jobs. \n\nThe moment we saw potential to not hate every minute of our lives (talend) we jumped. It took about 2 months to migrate 75% then another 4-6 for the last bit of squids so complex we just started back at the RFP stage and did a from scratch. \n\nThat was 4 years ago. We have learned a ton and refined and standardized a lot from the early days.",
                  "score": 5,
                  "created_utc": "2026-01-30 04:33:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2k0kfz",
              "author": "Useful-Bug9391",
              "text": "That YAML-driven setup sounds like the dream for a skunkworks team. Scaling Airflow to that level of 'it just works' is impressive.\n\nI‚Äôm actually looking to head in a similar direction, specifically with PySpark on EMR. Since you‚Äôre starting to offload those huge pipes to external compute, how did you bridge that gap?\n\nSpecifically, did you find it easier to keep the PySpark logic bundled in the Airflow repo, or are you treating EMR as a completely separate black box that Airflow just pings? I‚Äôd love to know how you got that first EMR integration off the ground",
              "score": 2,
              "created_utc": "2026-01-30 05:58:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jitbe",
          "author": "burningburnerbern",
          "text": "Funny you say that. I was working on a project where we were trying to migrate the orchestration from airflow to databricks. From what I see, databricks is basically a tool to do it all. You can run python scripts, schedule jobs, execute sql queries, access storage like s3, spin up clusters all without having to leave it.¬†",
          "score": 3,
          "created_utc": "2026-01-30 03:58:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jyt2m",
              "author": "HC-Klown",
              "text": "Do it all? What does \"all\" mean for you? \n\nCan it run a reverse etl to a seperate postgres db? Can it trigger the execution of ssis packages? Can it trigger the execution of an airbyte ingestion? Can it trigger the reload an aribitrary BI tool when the dependent data has been updated? Can it ingest from sharepoint? \n\nCome on, databricks is great if you're in a new company with 0 legacy system or very homogeneous systems. In reality in most companies its not like that and you have to orchestrate task dependencies between different tools and systems.",
              "score": 6,
              "created_utc": "2026-01-30 05:45:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ksl9f",
          "author": "crorella",
          "text": "We use airflow (as a orchestrator) + DBX",
          "score": 5,
          "created_utc": "2026-01-30 10:01:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jg2sb",
          "author": "sciencewarrior",
          "text": "The Databricks scheduler is basic but adequate if your pipeline is straightforward and you don't see yourself orchestrating anything outside their workspace. Using it instead of a dedicated scheduler can simplify administration.",
          "score": 6,
          "created_utc": "2026-01-30 03:42:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k90pl",
          "author": "Sweev1",
          "text": "In my experience, any data-related statement that starts with \"nobody uses\" is likely to be wrong. World is full of businesses and organisations that use all kinds of tech, many of which are several years away from ever using something quite as flashy as Airflow!",
          "score": 3,
          "created_utc": "2026-01-30 07:05:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kqs7o",
          "author": "UsefulCheck2743",
          "text": "In our organization, we ingest data from multiple sources including Cassandra, various APIs, MySQL, and external SFTP servers. The data is primarily loaded into a central data warehouse, with some pipelines also pushing data back to SFTP destinations.\nBeyond ingestion, we use these pipelines to refresh Tableau dashboards, run PySpark jobs, and trigger ML workflows. Apache Airflow acts as the orchestration layer that ties all of this together.\nFor use cases where true streaming isn‚Äôt required, we run near-real-time batch jobs using bi-minutely and five-minute DAGs, which gives us data freshness that‚Äôs good enough without the complexity of streaming. For actual streaming needs, we maintain standalone Kafka-based jobs outside Airflow. Maybe No one uses Hadoop except for some big orgs (such as eBay) but Airflow is here to stay it solves lot of industry problems.",
          "score": 3,
          "created_utc": "2026-01-30 09:44:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ktj4e",
          "author": "SnowyBiped",
          "text": "All the cloud/platform providers who built their own scheduler at the end had to offer Airflow too (waiting for Databricks to do the same, and charge more).\n\nAlso, the companies picking the right tool for the right job have usually better platforms and more happy teams",
          "score": 3,
          "created_utc": "2026-01-30 10:09:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l8m7g",
          "author": "RubyCC",
          "text": "We‚Äòre running Airflow in my company and we‚Äòre not planning on replacing it anytime soon.",
          "score": 3,
          "created_utc": "2026-01-30 12:12:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jkwfe",
          "author": "Hackerjurassicpark",
          "text": "Airflow is very heavily used in the industry. \n\nHadoop is on the decline and only a very few, most financial institutions still use it.",
          "score": 4,
          "created_utc": "2026-01-30 04:11:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k8w0k",
          "author": "Johnlee01223",
          "text": "Depends on the complexity of the work needed. Databricks pipeline is handy when you want a more managed experience and don‚Äôt want to deal with the operational overhead. But have to say Airflow is still on the rise. Airflow would be far better for more complex, cross-system workflows (and if I have devs to maintain it). Airflow also provides more control over scheduling, dependencies, retries, and custom logic, which will likely be a more preferable options for bigger companies/projects.",
          "score": 2,
          "created_utc": "2026-01-30 07:04:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k5b09",
          "author": "DoNotFeedTheSnakes",
          "text": "Airflow is in full bloom.\n\nAdoption has never been this good and development speed is reaching new heights with version 3.0+\n\nWhoever told you that doesn't know what they are talking about.",
          "score": 5,
          "created_utc": "2026-01-30 06:35:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jq5a3",
          "author": "sisyphus",
          "text": "I use airflow and it's even on-prem but all of IT is driven by fashion and FOMO so it's possible that it is considered tres gauche by now.  Anyway just agree with whatever they say and stack your bands.",
          "score": 1,
          "created_utc": "2026-01-30 04:44:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k1gn2",
              "author": "Useful-Bug9391",
              "text": "Since you‚Äôve seen these cycles, how would you suggest someone like me actually gets started without getting distracted by the FOMO? If I focus on mastering PySpark and SQL, is that enough to survive whatever 'fashion' comes next, or is there a specific piece of the modern stack I‚Äôm an idiot for ignoring right now?",
              "score": 1,
              "created_utc": "2026-01-30 06:05:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2kxrmb",
                  "author": "CommandFew7364",
                  "text": "Hadoop is dead. Airflow is growing so I wouldn‚Äôt ignore it. OpenAI, Anthropic, etc all use it a ton. Any company that‚Äôs big enough or growing fast enough will outgrow the mindset that ‚Äúorchestration just comes with databricks‚Äù b/c in the long term not decoupling orchestration from compute or LLMs or whatever is a bad idea.",
                  "score": 2,
                  "created_utc": "2026-01-30 10:46:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2l9fwt",
          "author": "Thinker_Assignment",
          "text": "GH actions is very popular with our users.",
          "score": 1,
          "created_utc": "2026-01-30 12:18:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2n5pd3",
          "author": "bigcontracts",
          "text": "That's a lie, we just migrated to using Airflow...",
          "score": 1,
          "created_utc": "2026-01-30 17:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2pqdcp",
              "author": "Useful-Bug9391",
              "text": "The reply section has opened my eyes. \nI wasn't aware of reddit that much tbh. \n\nI wanted to share somewhere. \nI think I will switch from x to here. \n\nTwitter is just filled with bots now.",
              "score": 1,
              "created_utc": "2026-01-31 01:32:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2nepo0",
          "author": "Realistic-Zebra1924",
          "text": "We use airflow to orchestrate our databricks jobs üòÄ",
          "score": 1,
          "created_utc": "2026-01-30 18:34:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ppybj",
              "author": "Useful-Bug9391",
              "text": "üòÇüòÇüòÇüòÇ",
              "score": 1,
              "created_utc": "2026-01-31 01:29:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rfmsc",
          "author": "ScottFujitaDiarrhea",
          "text": "Hadoop is a multithreaded file system and Airflow is an orchestration tool. You can orchestrate a spark job from Airflow if you wanted to using a variety of different infrastructures. Idk who told you this?",
          "score": 1,
          "created_utc": "2026-01-31 09:04:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fuxtu",
          "author": "mosqueteiro",
          "text": "I imagine Hadoop is becoming very rare. Airflow is still an industry standard even if there are other good options out there.",
          "score": 1,
          "created_utc": "2026-02-04 00:10:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jg6sb",
          "author": "ElCapitanMiCapitan",
          "text": "I live in databricks and love it, but it is woefully insufficient to manage large scale jobs. Build small jobs that you execute from an external orchestrator. We use ADF to execute our workflows, passing metadata from our control database (azure sql). I didn‚Äôt build it, but it works better than what‚Äôs native to databricks",
          "score": 1,
          "created_utc": "2026-01-30 03:42:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k15xj",
              "author": "Useful-Bug9391",
              "text": "I'll be honest, as someone looking to master PySpark, the infra side of this (ADF vs. Airflow vs. Native) feels like a maze. If you were starting today, would you focus on mastering the PySpark logic first, or is it better to learn how these 'external orchestrators' like ADF actually trigger the jobs?\n\nAlso, how did you personally learn the 'big picture' of how all these pieces (Azure SQL, ADF, Databricks) connect? Any specific resource that made it click?",
              "score": 1,
              "created_utc": "2026-01-30 06:03:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jc1qd",
          "author": "H0rob0D",
          "text": "If there are no more databricks haters on earth, I‚Äôm dead. \n\n\nBring back open source orchestration tools and normal reserved cloud instances to execute single or multi-node jobs. \n\nDatabricks = major waste of money\n\nDatabricks is for data engineers and data scientists as Tableau is for data analysts.",
          "score": -1,
          "created_utc": "2026-01-30 03:18:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jdfw7",
              "author": "droe771",
              "text": "If you‚Äôre only using databricks for small batch jobs you‚Äôre not getting your moneys worth. It has about 20,000 other features that make my life much better.¬†",
              "score": 4,
              "created_utc": "2026-01-30 03:26:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2jo1t7",
                  "author": "H0rob0D",
                  "text": "What features are worth the databricks tax?\n\nAre you referring to Delta Lake optimizations - ACID transactions, time travel, Z-ordering, liquid clustering, change data feed. \nOkay, other products such as Snowflake or other scalable DBMS can do all this at a much cheaper price. \n\nHow about collaborative workflows - Real-time notebook collaboration, version control integration, parameterized notebooks as production code? \nWell notebooks suck and should never be used imo for production workflows. They are hard to maintain, hard to do code reviews, and tend to persuade people to write monolithic spaghetti code as opposed to following good software engineering best principles. Also I don‚Äôt see a time id ever need to edit a notebook live with another user in a collaborative fashion. If I did, other cheaper platforms such as AWS Sagemaker exists. \n\nMLflow + Feature Store - Experiment tracking, model registry, feature serving with lineage?\nYeah spinning up an MLflow or WAND tracking server isn‚Äôt hard and again you can easily deploy a pre-made one via any other cloud provider much cheaper than databricks. Same thing with feature stores. \n\n\nWorkflow orchestration - Built-in scheduling with Databricks Jobs?\nNah Airflow/Prefect FTW. \n\nUnity Catalog for centralized governance, fine-grained access control, lineage tracking across all your data assets?\nAWS, Snowflake, etc. all have pretty decent catalog tools that are again much cheaper than databricks. \n\n\nI‚Äôm not saying databricks is a bad platform. I‚Äôm just saying it‚Äôs not the right platform for me if I was CTO of my company. I just don‚Äôt see the value proposition over using all AWS products and choosing my own DBMS. \n\nI think databricks to me feels like what Apple is for smartphones and laptops. They try to make a suite of tools that integrate well to form a nice ecosystem of products, but it‚Äôs a walled garden that doesn‚Äôt give you full control over the product you are buying. \n\nOne last example: databricks provides a fully managed delta lake house and SQL engine to query the data. A Delta table is composed of a series of flat files (parquet or some other type of columnar format). But it doesn‚Äôt tell you where it stores the files. It abstracts that part from you. It‚Äôs silly because we know under the hood they are just storing it in a blob storage like azure blob storage. Why can‚Äôt I go to the place where the data files sit and use the blob storage interface to copy/paste, move, or download the files? \n\nIf I want a more performant Delta table I could just use AWS S3 and query results via duckdb or some other data processing API that works with delta and iceberg tables.",
                  "score": 6,
                  "created_utc": "2026-01-30 04:31:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2jj3xu",
              "author": "Vautlo",
              "text": "Depending on your use case, I wouldn‚Äôt consider Databricks expensive by default, at least not today. I‚Äôve heard the consumption cost horror stories, but that‚Äôs been far from my experience. We migrated from Redshift into Databricks a couple years ago and don‚Äôt regret it. Not that migrating from Redshift to any of several other solutions (in our case) wouldn‚Äôt have been better. It might still be the cheapest at scale, but it wasn't what we needed.",
              "score": 1,
              "created_utc": "2026-01-30 04:00:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ka3u0",
                  "author": "Johnlee01223",
                  "text": "LOL love it. I would have to say any solution is better than Redshift at this point",
                  "score": 1,
                  "created_utc": "2026-01-30 07:14:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ko4ad",
          "author": "Disastrous_Tough7612",
          "text": "What about Prefect is it worth it to learn?",
          "score": 0,
          "created_utc": "2026-01-30 09:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2j1ues",
          "author": "Sen_ElizabethWarren",
          "text": "What‚Äôs airflow?",
          "score": -11,
          "created_utc": "2026-01-30 02:21:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j28dm",
              "author": "Useful-Bug9391",
              "text": "Apache airflow ...popular for managing ETL/ELT pipelines, machine learning workflows and infrastructure automation.",
              "score": 5,
              "created_utc": "2026-01-30 02:24:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jzpqc",
          "author": "sib_n",
          "text": "Full Hadoop usage with HDFS for storage (replaced by object storage nowadays) is probably on the edge of extinction (a few big and slow organizations may still be in the process of migrating). But running Spark on a managed Hadoop like AWS EMR is still a good practice for a cheap way to run Spark in the cloud compared to more specialized and expensive services like AWS Glue or Databricks.\n\nHaving a standalone orchestration tool is still very relevant if you have actual DE needs. Otherwise, orchestration newcomers like Prefect, Dagster and Kestra would not exist and thrive. If \"no one uses Airflow\" means that they should use more modern orchestrators if starting from scratch, I agree.",
          "score": -1,
          "created_utc": "2026-01-30 05:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k1qrx",
              "author": "Useful-Bug9391",
              "text": "that's solid point ... As someone focusing on PySpark, I find the transition from writing code in a notebook to actually deploying it on something like EMR or an orchestrator like Dagster pretty intimidating. Since you mentioned these 'newcomer' orchestrators are thriving, what‚Äôs the best way for a beginner to get hands-on with that full flow without a massive cloud bill? Should I be looking at 'EMR Serverless' or just stick to local Spark/Docker until the patterns click?",
              "score": 1,
              "created_utc": "2026-01-30 06:07:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2k7txa",
                  "author": "sib_n",
                  "text": "Optimizing cloud is complicated; but running those new orchestrators locally is actually very easy, much easier than Airflow. Basically just a `pip install`, and you have everything needed to orchestrate on your laptop, including the UI. Having used Prefect and Dagster in production, I personally recommend Dagster for its better overall design, but Prefect is good too. Their tutorials are usually pretty good too.\n\nYou can try to do some ELT based on local file -> DuckDB table -> dbt transformed table, orchestrated with Dagster. 0 cloud bill and already a lot to explore.",
                  "score": -1,
                  "created_utc": "2026-01-30 06:56:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1quvm92",
      "title": "Are we all becoming \"Full Stack-something\" nowadays?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1quvm92/are_we_all_becoming_full_stacksomething_nowadays/",
      "author": "HungryRefrigerator24",
      "created_utc": "2026-02-03 15:54:07",
      "score": 81,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "Whats up?\n\nWithout further ado... I've found myself in the position where I went from a standard data engineer where I took care of a couple of data services, some ETLs, moving a client infrastructure from one architecture to another...\n\nNowadays I'm already designing the 6th architecture of a project which includes Data Engineering + AI + ML. Besides doing that I did at the start, I also develop and design LLM applications, deploy ML algorithms, create tasks and project plannins and do follow-up with my team. I'm still a \"Senior DE\" on paper but I feel like a weird mix of coordinator (or tech lead whatever u call) and a \"Full Stack Data\" since I'm working in every step of the process. Master of none but an improviser of all arts.\n\nI wonder if this is happening at other companies or in the market in general?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1quvm92/are_we_all_becoming_full_stacksomething_nowadays/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3d0cat",
          "author": "Former_Disk1083",
          "text": "It's a mixture right now, but yes a lot of the market is like that. It's just companies hear \"AI\" and think they just need someone to push a button but it still requires lots of knowledge and understanding how they need to cleanse the data and hyperparameter tuning and understanding what model works best for what and all that. There was a small period in time, and maybe it's still true, where it was just throw XGBOOST at it and go sip your coffee, and thats what a lot of folk were doing. But that does a disservice to a lot of the actual data scientists out there doing the maths and actually understanding inputs and outputs.\n\nI guess I ranted a bit there, the short story long is, yes, that is common, and I typically avoid it if I can. But you sometimes have to do what the market dictates even if it's not sustainable.",
          "score": 21,
          "created_utc": "2026-02-03 16:01:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gswvl",
              "author": "LilParkButt",
              "text": "XGBoost does perform well pretty often though üòÇ",
              "score": 6,
              "created_utc": "2026-02-04 03:20:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3gu6ub",
                  "author": "Former_Disk1083",
                  "text": "Yeah I had a feeling not much has changed with that hahaha. Hard to beat the thing that just works.",
                  "score": 1,
                  "created_utc": "2026-02-04 03:28:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3d0a1m",
          "author": "SoggyGrayDuck",
          "text": "Yeah, it's going to happen eventually. Now management doesn't have to get involved in those pesky details that used to justify their pay. Hell mine can't even escalate problems correctly. It's like they put a quarterly PowerPoint together and sit back until quarters end and see how things shook out. They've successfully separated their individual success or failure from the teams success/failure. It's the most absurd thing I've seen and they're only getting away with it due to the shortage. I wouldn't put it past some conspiracy plan enacted to knock devs down from their high perch they got to during COVID, working multiple jobs in just 40 hour weeks. \n\nIt's just the managers/leaders taking another step away from responsibilities",
          "score": 15,
          "created_utc": "2026-02-03 16:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d9win",
              "author": "Skullclownlol",
              "text": "> It's just the managers/leaders taking another step away from responsibilities\n\n100%, exact same pattern is happening in my experience. It doesn't always mean roles become full-stack, sometimes departments are being scrapped.",
              "score": 2,
              "created_utc": "2026-02-03 16:46:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3di7b3",
                  "author": "SoggyGrayDuck",
                  "text": ">sometimes departments are being scrapped.\n\nYep, cut and replaced with a 3rd party company that is based out of India. I think it's a loophole around the 100k fee. You're not technically bringing in foreign workers to replace US workers, you're just hiring another company to do the work for you.",
                  "score": 2,
                  "created_utc": "2026-02-03 17:24:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3fu2tn",
              "author": "x246ab",
              "text": "Most managers exist to buffer the incompetence above them",
              "score": 2,
              "created_utc": "2026-02-04 00:05:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3fv9yc",
              "author": "HungryRefrigerator24",
              "text": "Im really curious about what the PM and my manager really does because im the one doing the project architecture, creating the project planning, the tasks, giving the tasks, so on..",
              "score": 1,
              "created_utc": "2026-02-04 00:11:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3d0mr3",
          "author": "ManyMuchMoosenen",
          "text": "‚ÄúT-shaped‚Äù seems to be an increasingly popular buzzword. Deep knowledge in a one/few areas but broad enough knowledge to contribute and assist in other areas.",
          "score": 12,
          "created_utc": "2026-02-03 16:02:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3d0fsb",
          "author": "EmotionalSupportDoll",
          "text": "I feel like we're all being asked to do more with less these days. Good in terms of learning opportunities, but obviously burdensome at times.",
          "score": 7,
          "created_utc": "2026-02-03 16:01:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ibr05",
              "author": "HungryRefrigerator24",
              "text": "I agree with you in terms of learning opportunities, but where is the line that you dont cross? Or are we at the point we're data will be expected to be \"full stack\" without any payment adjustment?",
              "score": 1,
              "created_utc": "2026-02-04 10:43:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e6e9z",
          "author": "kaapapaa",
          "text": "instead AI/ML, I take care of Platform Engineering/CICD.",
          "score": 2,
          "created_utc": "2026-02-03 19:13:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nmpwn",
              "author": "FarFaithlessness8812",
              "text": "I genuinely suck at CI/CD, can you point me to some sort of path on how to learn about it?",
              "score": 1,
              "created_utc": "2026-02-05 03:36:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ob2bl",
                  "author": "kaapapaa",
                  "text": "You can start with git, docker, git actions, terraform.",
                  "score": 1,
                  "created_utc": "2026-02-05 06:30:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3i4vom",
          "author": "Thinker_Assignment",
          "text": "Did you see my post from last week? that's what i'm seeing across 15% of the industry, and i think it's going to be the end state by end of year. Also AE is getting replaced - see the recent openai, snowflake about semantic views and feedback memory layer - so it looks to me like it's 3 options for people: go fullstack, stay in (shrinking) legacy until it dies, or get unemployed.",
          "score": 1,
          "created_utc": "2026-02-04 09:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ic41t",
              "author": "HungryRefrigerator24",
              "text": "The post with the funny image and pathways? I did although I believe that ML Engineer is also part of the \"Builder\" stack since ML Engineering also depends heavily in pretty much software engineering and Data Engineering. Perhaps I might be wrong but that's my viewpoint since Im also asked to do pretty much everything Engineering-like at work. \n\nWhat comes to my mind often is that if I were in this position years ago I'd be making 10K but seems that being Full Stack in Data is becoming a norm. Companies asking for a lot and paying close to nothing",
              "score": 1,
              "created_utc": "2026-02-04 10:46:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3jy0wb",
                  "author": "Thinker_Assignment",
                  "text": "Yeah. The reason i left ML to the side is because I do not see the other data roles getting into ML - they get into ML engineering. I do also see ML people now going down the stack and owning ingestion to AI. So this makes the ML specialist a bit unique in my view.\n\nand you're right - I was freelancing as full stack DE before starting this company (9-4y ago), the rate for that kind of work was usually in the 90-150 euro/h range",
                  "score": 1,
                  "created_utc": "2026-02-04 16:24:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iiy6i",
          "author": "EviliestBuckle",
          "text": "Can you share ai application tutorials you followed?",
          "score": 1,
          "created_utc": "2026-02-04 11:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ofhif",
          "author": "Ancient_Ad_916",
          "text": "I got hired as Business Intelligence Engineer, it includes data engineering (ETL, data modeling), data analysis (provide BI automation), and some data science (optimization). So I suppose you‚Äôre correct",
          "score": 1,
          "created_utc": "2026-02-05 07:09:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtwdcf",
      "title": "Best companies to settle as a Senior DE",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qtwdcf/best_companies_to_settle_as_a_senior_de/",
      "author": "Dapper-Computer-7102",
      "created_utc": "2026-02-02 14:22:50",
      "score": 73,
      "num_comments": 47,
      "upvote_ratio": 0.92,
      "text": "So I have been with startups and consulting firms for last few years and really fed up with unreal expectations and highly stressful days. \n\n  \nI am planning to switch and this time I wanted to be really careful with my choice( I know the market is tough but I can wait) \n\n  \nSo what companies do you suggest that has good work life balance that I can finally go to gym and sleep well and spend time with my family and friends. I have gathered some feedback from ex colleagues that insurance industry is the best. IS it true? Do you have any suggestions?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qtwdcf/best_companies_to_settle_as_a_senior_de/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o35rms0",
          "author": "Kenny_Lush",
          "text": "The ones that pay way less than you‚Äôre used to.",
          "score": 109,
          "created_utc": "2026-02-02 14:27:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37mavr",
              "author": "sciencewarrior",
              "text": "Consulting doesn't pay all that well for the qualifications they require and performance expectations; after all, their profit is the difference between what the client is willing to pay and your salary. \n\nIME, chemical, healthcare, and other large companies in highly regulated sectors tend to avoid crunch. They do have tons of red tape and legacy, though.",
              "score": 18,
              "created_utc": "2026-02-02 19:39:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o360m4p",
              "author": "Dapper-Computer-7102",
              "text": "I‚Äôm okay to cut down my salary and joined my last organization with the same hope and end up as single person data team apparently they don‚Äôt have money to hire the remaining team still wanted migration, dashboards everything ready in 6 months. Pay doesn‚Äôt really translate to work environment.",
              "score": 17,
              "created_utc": "2026-02-02 15:14:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36108t",
                  "author": "Kenny_Lush",
                  "text": "True, you do have to get lucky.",
                  "score": 3,
                  "created_utc": "2026-02-02 15:16:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o36d5ck",
              "author": "zazzersmel",
              "text": "I‚Äôm not senior but I make less working for a tech startup now than I did at a large non-tech company a couple years ago. It‚Äôs also like twice as much work.",
              "score": 1,
              "created_utc": "2026-02-02 16:13:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36zq0o",
                  "author": "Dapper-Computer-7102",
                  "text": "Cost cutting I guess",
                  "score": 1,
                  "created_utc": "2026-02-02 17:57:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o363ogm",
          "author": "protonchase",
          "text": "I work as mid level DE at a F500 insurance company. My organization in particular has a lot of ambitious folks. There are definitely people who have ‚Äòsettled‚Äô but most of them are not seniors. The seniors have high expectations here. That being said, insurance in general is pretty ‚Äòchill‚Äô.",
          "score": 33,
          "created_utc": "2026-02-02 15:29:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36ecu0",
              "author": "JohnPaulDavyJones",
              "text": "Oh hey, I'm also a mid-level DE at a F500 insurer. We don't really have many ambitious folks, though; we've got a ton of lifers focused on slow, iterative build outs for a new policy system we're bringing online, as well as keeping the lights on for an extremely stable series of warehouses. This team has institutional knowledge out the wazoo, which rocks.\n\nI get the feeling that a lot of the insurance industry is like this. I spent a year at USAA prior to this, and they had a ton of lifers too before they handed out a ton of early retirement incentives to thin the workforce in 2023 and then still had to do their first-ever wave of layoffs in 2024.",
              "score": 9,
              "created_utc": "2026-02-02 16:19:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36gorf",
                  "author": "protonchase",
                  "text": "Nice. I work with underwriting data. Yeah we have a lot of lifers as well actually. But those are usually the folks who stay stagnant and don‚Äôt get promoted but instead just bounce from team to team when they get bored lol.",
                  "score": 4,
                  "created_utc": "2026-02-02 16:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35y5ri",
          "author": "0sergio-hash",
          "text": "I've only been to a few companies and I honestly think work life balance is like 50/50 between the company and yourself \n\nI work at a startup type environment now and I'm just ok with being one of only a couple people on the team that doesn't volunteer for everything and stick their nose in everything lol \n\nI don't rush to deliver every single project and fall for their manufactured urgency \n\nThen again, my role isn't some mission critical thing. I produce reports so it's a little different \n\nI worked at a huge fintech and they were pretty dang slow to do anything so work life balance was decent but you get bored not getting anything done",
          "score": 16,
          "created_utc": "2026-02-02 15:01:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35zfef",
              "author": "Dapper-Computer-7102",
              "text": "I‚Äôm your kind but everyone else in my organization runs on a treadmill and behaves like they‚Äôre operating on a patient who is ready to die. I don‚Äôt really care and end my day at 5. And guess what my manager calls me on my personal number to login at 11pm as everyone else is working and in a meeting. I voice my concerns a lot. And I am only one who does that and only one to say NO. Startups are way better at least the pay and benefits are decent. But consultancies are horrible.¬†",
              "score": 8,
              "created_utc": "2026-02-02 15:08:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3cutep",
                  "author": "0sergio-hash",
                  "text": "My phone would be on DND at 11 pm lol I am not an EMT ü§£ Sounds like a leadership/culture issue, I'd get a new job my friend \n\nI won't even install work apps on my phone lol",
                  "score": 2,
                  "created_utc": "2026-02-03 15:35:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36h1q9",
          "author": "JohnPaulDavyJones",
          "text": "Established insurance companies usually rock. They're incredibly risk-averse by nature, so there are tons of lifers here.\n\nI'm a mid-level/senior-ish DE at a F500 insurer these days, after I spent time in higher education, B4 consulting, and then built the data team at a PE-backed startup in the healthcare sector. I've done the stress of consulting and PE, and I can't imagine leaving insurance these days unless it was to go back to higher ed, but the pay there doesn't compete with the pay in insurance.\n\nInsurance in general tends to have a lot of lifers, my team these days has 14 folks, with an average age of 51. Five of us are younger than 40, seven folks are older than 50, and one gentleman still plugging away at 73. Only two of us have been here less than 8 years, and six have been here 15+ years.\n\nI was at USAA for about a year before this, and they also had a ton of long-timers. My team there was \\~8 folks and only two of us had been there less than a decade, lots of folks had started in other jobs at the company and then cross-trained over into DE as the company built their org. They want to keep folks who really get the insurance business, that domain knowledge is really helpful.\n\nNot sure if I'd recommend USAA right now, though. They're going through a whole lot of flux these last few years, and I think I'd steer clear until they figure things out, maybe 2028\\~2030 or so. The thing that hurt USAA was that they got out over their skis after their big hiring burst during Covid, so they tried to thin the workforce with a ton of early retirement incentives in 2023, and then still had to do their first-ever wave of layoffs in 2024. Morale went from sky-high to the absolute gutter after the layoffs, so a lot of us bounced in the aftermath of that.\n\nOnce you've seen how stressful consulting and other industries can be, then how unerringly *stable* insurance is, it's hard to want to leave.",
          "score": 10,
          "created_utc": "2026-02-02 16:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38ucth",
              "author": "Spunelli",
              "text": "Yea but they are incredibly outdated technology wise and the culture can be quite toxic. The lifers fear change and will go to great manipulative lengths to keep their seats warm.",
              "score": 4,
              "created_utc": "2026-02-02 23:13:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38x1l5",
                  "author": "JohnPaulDavyJones",
                  "text": "The toxic culture is news to me, I've been a huge fan of the culture at both my current employer and at USAA. I'd go so far as to say that USAA had the best corporate culture I've ever seen/heard of. Folks love it there for a reason. Granted, that may have taken a hit after the layoffs, but I presume it'll come back pretty well.\n\nYou're not wrong abou the archaic tech stacks, though. USAA was still using Hadoop broadly in 2023 and my current firm is entirely on SQL Server/SSIS. Our \"new technology\" that we're integrating in 2025-2026 is Python.\n\nThat just adds to the stability, though. It works a lot better for you if you've already gone and done the high speed jobs with the fun toys, and now you want stability.",
                  "score": 2,
                  "created_utc": "2026-02-02 23:27:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ah8yn",
                  "author": "SuperTangelo1898",
                  "text": "Are they still on prem??? (Ew)",
                  "score": 1,
                  "created_utc": "2026-02-03 04:57:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38ui1g",
              "author": "number676766",
              "text": "Also in insurance. I'm not a true data engineer, but I do some and I interface between our data engineers and everyone else. Having worked at a very large EHR company, then a start up as the first engineer, and now this, I can safely say it's better. \n\nI grew up in a house where my parents were working on their business all day and into the night. Nothing weird about only stepping down to dinner and then returning to work until 11pm like my dad did my whole childhood. I took that behavior with me to my first couple of jobs and survived and thrived while others burnt out. \n\nBut at this job, I have the constant anxiety that I'm not doing enough because I'm not stressed all the time. I'm not on call, and I don't really work late except a couple nights a year. It's quite chill compared to what I'm used to. \n\nWhile the contractors cycle in and out, I haven't seen many of our IT FTEs leave. The pay is pretty good, only two days a week in office which I like, and good benefits. \n\nThere was a time when I was like \"I'll never do something boring like insurance\" and now I consider myself lucky to have a job with all of the aforementioned qualities. Especially in this economy.",
              "score": 3,
              "created_utc": "2026-02-02 23:13:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o370g9t",
              "author": "Dapper-Computer-7102",
              "text": "Last line is 100% true.¬†",
              "score": 1,
              "created_utc": "2026-02-02 18:00:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38tdts",
                  "author": "pmorrisonfl",
                  "text": "After years in the trenches of F500 dev orgs and consulting, I did a four-year stint at an insurance-adjacent organization. I called it the 'Country Club'. If I had more sense I'd probably still be there.",
                  "score": 1,
                  "created_utc": "2026-02-02 23:08:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36d14w",
          "author": "MikeDoesEverything",
          "text": "As per usual, location really helps people here as nobody knows where you are and it might differ from country to country.\n\nIn the UK, traditional industries are pretty good.  Legal, finance, banking etc.  Not the most interesting roles although you 100% get work-life balance.  Not sure if that translates to where you are, mind.",
          "score": 5,
          "created_utc": "2026-02-02 16:12:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36zih8",
              "author": "Dapper-Computer-7102",
              "text": "I‚Äôm in USA",
              "score": 2,
              "created_utc": "2026-02-02 17:56:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3834uk",
          "author": "Steelcowinc",
          "text": "Just about any large non-tech company has a high probability of being more chill than a startup. Retailers, manufacturers, insurers, financial, etc.\n\nBut as others have said, salaries tend to be lower.",
          "score": 4,
          "created_utc": "2026-02-02 20:59:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37kvbm",
          "author": "fuloqulous",
          "text": "Can confirm insurance is pretty chill. I worked with a large health insurance company and worked about 3 hours a day. Two of my colleagues each work for different insurance companies and same story.",
          "score": 3,
          "created_utc": "2026-02-02 19:33:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38j11h",
          "author": "Ketchup571",
          "text": "I‚Äôm a lead at large health insurance company. The pay is good, not FAANG level by any means, but I‚Äôm quite comfortable. The work-life balance though is out of this world. Days are low stress. I can count on one hand the amount of days I have to work late in a year and they have vary generous pto.",
          "score": 3,
          "created_utc": "2026-02-02 22:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o391buj",
          "author": "Patient_Professor_90",
          "text": "Banks!",
          "score": 3,
          "created_utc": "2026-02-02 23:51:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dvsdq",
          "author": "geek180",
          "text": "I've always worked in mid-sized, non-tech startups. I was originally in marketing and then moved to data engineering about 6-7 years ago. I'm now a staff data engineer at a mid-size biotech company. \n\nThere's a point around the $10-$30 million annual revenue mark where companies start to really need to step up their data and analytics practices and will start investing more in personnel and technology. These are great moments to get hired.\n\nIn my experience, these companies often pay above average and offer a lot of learning opportunities. Since there is always so much that needs to be done, I can often pick and choose what I want to work on. If you're in early enough, you get to do a lot of the foundational design of whatever system you need to build. \n\nI prefer this to jumping into a well-established team at a large company where the work is just delegated to you, you have to completely conform to the existing paradigm, and potential for skill or career progression is possibly a little more constrained.",
          "score": 2,
          "created_utc": "2026-02-03 18:25:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35xwik",
          "author": "West_Good_5961",
          "text": "Government",
          "score": 3,
          "created_utc": "2026-02-02 15:00:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3602i5",
              "author": "Dapper-Computer-7102",
              "text": "Right. But hardly see any openings there and not sure what criteria they have to choose a CV mine never gets picked up. I get pretty decent number of calls from other companies but from Fed, not really.",
              "score": 2,
              "created_utc": "2026-02-02 15:11:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3613t8",
                  "author": "West_Good_5961",
                  "text": "I assume you‚Äôre an American. In first world countries, public service jobs publish detailed selection criteria and transparency about how their merit system works.",
                  "score": 7,
                  "created_utc": "2026-02-02 15:16:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3928zb",
          "author": "theungod",
          "text": "Find a subsidiary of a large, well off company. Way less stress with similar pay.",
          "score": 1,
          "created_utc": "2026-02-02 23:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3awa58",
          "author": "Rand_alThor_",
          "text": "I work in a great company in Sweden. Company hit it‚Äôs goal so we all will get a 10% bonus. Yes everyone.\n\n30-35 days leave, go pick up my kid whenever; family comes first. I feel good working for the company.\n\nI will stay until the kids are grown for sure.\n\nI would make way more working for a US company, either directly or as a consultant (not even speaking of moving back to the US). But I earn good money and I‚Äôm spending time with my family. I love it.\n\n\nSo my advice is to look at overall company culture, but also a manager/team that shares your values: family, friends, taking care of yourself (gym etc.) should come first for the team/manager and you. Then it‚Äôs about finding a company culture that can support such a team stably, instead of grinding it down. Good luck!",
          "score": 1,
          "created_utc": "2026-02-03 06:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3m4o56",
          "author": "Loud-Librarian-8600",
          "text": "I see that apart from mid size to large enterprises none is recruiting for DEs and large companies expecting 5-10 yrs of expereince. Please anybody correct me if I'm wrong!",
          "score": 1,
          "created_utc": "2026-02-04 22:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37e16v",
          "author": "financialthrowaw2020",
          "text": "This isn't really the market to be choosy in. The best job is the one you can get that pays you what you want",
          "score": 0,
          "created_utc": "2026-02-02 19:01:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37qxg9",
              "author": "Dapper-Computer-7102",
              "text": "So you stay where your stress is in peak? You always have a choice.",
              "score": 2,
              "created_utc": "2026-02-02 20:01:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38fbs6",
                  "author": "financialthrowaw2020",
                  "text": "You always have the option to look for new jobs, it doesn't mean you'll get to be selective beyond your current job and your new job, and sometimes the risk is that you're now the newest guy in a rough economy. There are risks involved as with everything.",
                  "score": 1,
                  "created_utc": "2026-02-02 21:57:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35yzjm",
          "author": "rajekum512",
          "text": "Settle ?Lol. bro dreaming of retirement at a job",
          "score": -9,
          "created_utc": "2026-02-02 15:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o360svx",
              "author": "Dapper-Computer-7102",
              "text": "How is a decent WLB is retirement now?",
              "score": 12,
              "created_utc": "2026-02-02 15:15:00",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o371c5u",
              "author": "makesufeelgood",
              "text": "Not everyone lives to work lil bro.",
              "score": 2,
              "created_utc": "2026-02-02 18:04:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qrlhoj",
      "title": "Shopify coding assessment - recommendations for how to get extremely fluent in SQL",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qrlhoj/shopify_coding_assessment_recommendations_for_how/",
      "author": "Bnerna",
      "created_utc": "2026-01-30 23:18:21",
      "score": 73,
      "num_comments": 28,
      "upvote_ratio": 0.95,
      "text": "I have an upcoming coding assessment for a data engineer position at Shopify. I've used SQL to query data and create pipelines, and to build the tables and databases themselves. I know the basics (WHERE clauses, JOINs, etc) but what else should I be learning/practicing.\n\nI haven't built a data pipeline with just sql before, it's mostly python.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qrlhoj/shopify_coding_assessment_recommendations_for_how/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2p2fpy",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-30 23:18:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pyt0u",
          "author": "kirstynloftus",
          "text": "FWIW, when i interviewed with Shopify they seemed to care more about the thought process/collaboration than correctness.",
          "score": 31,
          "created_utc": "2026-01-31 02:22:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qacn0",
          "author": "Jonny-The-Commie",
          "text": "Window functions!",
          "score": 21,
          "created_utc": "2026-01-31 03:32:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r2gyj",
              "author": "eagerunicorn",
              "text": "This. Make sure you know how to sum() within a set of columns, can add a row_number() to deduplicate.¬†\n\n\nAlso, LAG() functions",
              "score": 10,
              "created_utc": "2026-01-31 07:01:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2p7uh4",
          "author": "wizzward0",
          "text": "I got better by doing leetcode sql questions myself and then asking llm if there were better syntax options for my solution or just reading top voted answers. I ended up picking up a lot of new syntax that made my queries more concise and which I use most days",
          "score": 54,
          "created_utc": "2026-01-30 23:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2pe0bh",
              "author": "Bnerna",
              "text": "But are the SQL leetcode questions just data analysis based, or data engineer based too?",
              "score": 9,
              "created_utc": "2026-01-31 00:22:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2q9x4z",
                  "author": "wizzward0",
                  "text": "If you mean dml style queries then not directly but dml queries still use similar logic to define what rows you want to change. Then just brush up on insert, update and merge into.",
                  "score": 7,
                  "created_utc": "2026-01-31 03:29:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2qn5tr",
                  "author": "SpecCRA",
                  "text": "Stratascratch has more data job focused questions. You can look at others' solutions and then use LLMs to do the same. Explain why someone else's solution is different, why it may be better, and what you could do more efficiently.",
                  "score": 5,
                  "created_utc": "2026-01-31 04:58:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2uxhje",
                  "author": "thisfunnieguy",
                  "text": "are you sure SQL is a big part of the job?\n\nI'd imagine its stuff like airflow and spark / kafka.",
                  "score": 1,
                  "created_utc": "2026-01-31 21:21:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2q7rmt",
          "author": "WhipsAndMarkovChains",
          "text": "Datalemur.com",
          "score": 8,
          "created_utc": "2026-01-31 03:15:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2t22yw",
          "author": "winnieham",
          "text": "For fun, you can do the SQL murder mystery, and the SQL squid game (google for these). I would say if you can do these fluently you are good, esp the Squid game one is rather challenging.",
          "score": 6,
          "created_utc": "2026-01-31 15:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r2da2",
          "author": "dreamintravel",
          "text": "Shopify‚Äôs SQL interview process sucked or at least it did for me with the interviewer I had. He was hung up on a small syntax nuance for no reason and even though I told him I can give him multiple ways of doing the same thing he wasn‚Äôt happy. Pretty reflective of their toxic culture I believe",
          "score": 6,
          "created_utc": "2026-01-31 07:00:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2raftj",
          "author": "West_Good_5961",
          "text": "Years of pain is the secret to anything",
          "score": 6,
          "created_utc": "2026-01-31 08:15:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rkj49",
          "author": "vegusphyseek",
          "text": "‚Äã20+ years in data/ETL here. Beyond just practicing SQL syntax, focus on these data engineering-specific concepts for Shopify:\n\n1.‚ÄãPerformance thinking: When you write queries during the assessment, always consider \"how would this perform on millions of rows?\" Shopify deals with massive scale. Use EXPLAIN plans, avoid SELECT *, and think about index usage.\n\n2. ‚ÄãData quality patterns: Practice SQL for data validation, deduplication (ROW_NUMBER() OVER PARTITION BY), and identifying data anomalies. Real data engineering involves catching bad data before it breaks pipelines.\n\n3. ‚ÄãIncremental processing: Since you mentioned building pipelines mostly in Python, practice SQL patterns for incremental loads‚Äîusing timestamps, watermarks, and merge/upsert logic. Think \"how do I process only new/changed data efficiently?\"\n\n4.‚ÄãSet-based thinking: Coming from Python, you might be used to loops. SQL is set-based. Practice writing queries that transform entire datasets at once rather than row-by-row logic.\n\n5. ‚ÄãReal-world scenarios: Go beyond LeetCode. Practice queries like:\n  ‚ÄãDetecting duplicate orders\n  ‚ÄãCalculating running totals/moving averages\n  ‚ÄãHandling NULL values and edge cases\n  ‚ÄãTransforming nested/JSON data\n\n‚ÄãFor Shopify specifically: They care about how you communicate your approach. Talk through your thinking: \"I‚Äôm using a CTE here for readability\" or \"This JOIN might be slow, but we could index X‚Ä¶\"\n\n‚ÄãGood luck!",
          "score": 12,
          "created_utc": "2026-01-31 09:51:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ety6f",
              "author": "Outside_Reason6707",
              "text": "Very well explained! I recently interviewed at Shopify and got rejected at SQL assessment. Interviewer was friendly and seemed to be happy with my solutions but there were 4 questions and I was able to solve 2 fully and only one pseudo way.",
              "score": 1,
              "created_utc": "2026-02-03 21:04:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2qt573",
          "author": "frozengrandmatetris",
          "text": "where do these people keep coming from, who focused so much on python and completely neglected SQL? why are there so many of them?",
          "score": 7,
          "created_utc": "2026-01-31 05:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2wno8y",
              "author": "Longjumping_Ad_7053",
              "text": "Cause It‚Äôs easier to pick up, so people just say they will pick it up later, at least in my case",
              "score": 2,
              "created_utc": "2026-02-01 03:07:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2slhg5",
          "author": "RazzmatazzLiving1323",
          "text": "Stratascratch all the way!",
          "score": 2,
          "created_utc": "2026-01-31 14:31:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xw3wd",
              "author": "valentin-orlovs2c99",
              "text": "StrataScratch is solid, especially for getting used to the ‚Äúdata interview‚Äù style questions.  \n\nIf you use it, don‚Äôt just grind for the answer though. For every problem, ask yourself:  \n\n- Could I write this 3 different ways?  \n- Can I explain why this works and what the query plan might look like?  \n- Can I simplify this or make it more readable?  \n\nAlso try to recreate some of their harder solutions using only joins + window functions, no subqueries, then only subqueries, etc. That kind of ‚Äúsame result, different approach‚Äù practice is what makes you actually fluent, which is what Shopify will care about.",
              "score": 2,
              "created_utc": "2026-02-01 08:51:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2r6m3n",
          "author": "Bunkerman91",
          "text": "Other important concepts are self joins, CTE tables, window functions, stored procedures",
          "score": 1,
          "created_utc": "2026-01-31 07:39:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2uxd00",
          "author": "thisfunnieguy",
          "text": "SQL is probably not a huge part of the data pipelines there.",
          "score": 1,
          "created_utc": "2026-01-31 21:21:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wv8tv",
          "author": "PossibilityRegular21",
          "text": "Tell em to do away with this graphQL business. Making our ETLs a headache¬†",
          "score": 1,
          "created_utc": "2026-02-01 03:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kal5w",
          "author": "miker5555",
          "text": "ChatGPT will give you mock questions",
          "score": 1,
          "created_utc": "2026-02-04 17:22:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2p8u4v",
          "author": "chrisgarzon19",
          "text": "Leetcode easy and medium should do \n\nWe have free trial at dataengineeracademy.com",
          "score": -10,
          "created_utc": "2026-01-30 23:53:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2pg3ag",
              "author": "apache_tomcat40",
              "text": "Nope. I haven‚Äôt came across the SQL question in Leetcode which asks developers to create time series (think of like date dimension) using in built functions and then doing cross join with rest of the data.",
              "score": 3,
              "created_utc": "2026-01-31 00:33:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2pgbxz",
                  "author": "apache_tomcat40",
                  "text": "@op: ‚¨ÜÔ∏è this is one of the questions in technical assessment",
                  "score": 2,
                  "created_utc": "2026-01-31 00:34:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqm3io",
      "title": "Was asked by a client to build a Finance Cube in 1.5 months",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qqm3io/was_asked_by_a_client_to_build_a_finance_cube_in/",
      "author": "Better_Code5670",
      "created_utc": "2026-01-29 21:45:05",
      "score": 68,
      "num_comments": 32,
      "upvote_ratio": 0.95,
      "text": "As title says!\n\n4 ERPS, no infrastructure, just an existing SQL Server!\n\nThey said okay start with 1 ERP and to be able to deliver by Q1, daily refresh, drill down functionality! I said this is not possible in such a short timeframe!\n\nThey said; data is clean, only a few tables in ERP, why would you say it takes longer than that? They said Architecture is at most 2 days, and there are only a few tables! I said for a temporary solution since they are interested not to do these excel reports manually most I can offer is an automated excel report, not a full blown cube! Otherwise Im not able to commit a 1.5 months timeline without having seen myself the ERP landscape, ERP connectors, precisely what metrics/kpis are needed etc! They got mad and accused me of ‚Äúsales pitching‚Äù for presenting the longer timeline of discovery->architecture->data modelling->medallion architecture steps!!",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qqm3io/was_asked_by_a_client_to_build_a_finance_cube_in/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2hmk1k",
          "author": "Im_probably_naked",
          "text": "Wish them the best and move on my friend.",
          "score": 86,
          "created_utc": "2026-01-29 21:49:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hmowd",
          "author": "boomerzoomers",
          "text": "Just connect excel directly to the OLTP and call it a day",
          "score": 68,
          "created_utc": "2026-01-29 21:50:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hs0oi",
              "author": "Better_Code5670",
              "text": "After that interaction, I considered it!",
              "score": 14,
              "created_utc": "2026-01-29 22:15:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2htgw8",
          "author": "Mo_Steins_Ghost",
          "text": "LMAO ... I am a senior manager of two teams of five engineers each, and it took us eight months to build a consolidated data source from about eight databases, two CRMs, three ERPs, three license servers,post-merger.  We now know more about the acquired company's license server than their own people ever did.\n\nWhy are there employers who even approach a single engineer thinking this is doable in less than six months minimum?\n\nI would have laughed out loud at their senior leaders.",
          "score": 53,
          "created_utc": "2026-01-29 22:23:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hvsxn",
              "author": "ColdStorage256",
              "text": "I'm a solo data scientist working on a model at my org. Everything is always \"let's just go with whatever will get us something fast and we can improve it later\".\n\nLet me tell you, 18 months later, because so many corners were cut from the start, all we have is a steaming pile of dogshit. My manager isn't technical though, so he has no idea how bad it really is. Really, even I would be better off tearing it up and starting over but that would mean admitting we've wasted this much time...so we'll continue in this direction until I find a new role :D",
              "score": 32,
              "created_utc": "2026-01-29 22:34:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2l30pn",
                  "author": "markwusinich_",
                  "text": "It‚Äôs not wasted time. You‚Äôve already identified all the requirements and you have them implemented in a working prototype.\n\nCreating a stable well architecture for the designed system is also not a waste of time",
                  "score": 5,
                  "created_utc": "2026-01-30 11:30:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2i9eqi",
          "author": "SaintTimothy",
          "text": "When I take my car to the shop, I always tell the mechanic how long it should take to fix my car.",
          "score": 27,
          "created_utc": "2026-01-29 23:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hu7x1",
          "author": "ZeusThunder369",
          "text": "Did you confirm you are both using the same shared understanding of what a cube is, and the steps to build?\n\nOn the surface, this sounds like a case where the TPM or Data Analyst layer is missing.",
          "score": 11,
          "created_utc": "2026-01-29 22:26:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hvbvf",
              "author": "Better_Code5670",
              "text": "There was a TPM but who has no idea about stuff, tbh! I understand that finance people refer a lot as a cube to literally an excel with pivot tables (what they see). We did a workshop session where they showed from another consulting company that implemented it star schemas, medallion architecture, SSAS Tabular Cubes and asked questions about RBAC accross different countries for their ERPs. My understanding was a full blown cube, however after seeing their reaction I approached with the ‚Äúautomated excel report‚Äù as a temporary solution since they do those reports manually and were saying how in Jan 2027 they will switch all ERPs to dynamic‚Ä¶",
              "score": 6,
              "created_utc": "2026-01-29 22:32:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2i9qjw",
                  "author": "ZeusThunder369",
                  "text": "Wow crazy -- Ya, it does seem like analysis is missing.\n\nLike, why a cube solution? What's the actual desired outcome? It doesn't seem like anyone ever discussed tradeoffs, and someone is saying \"cube\" to just mean \"a durable data source that we can trust.\"",
                  "score": 2,
                  "created_utc": "2026-01-29 23:47:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ibp6q",
          "author": "ThatOtherBatman",
          "text": "If it‚Äôs that easy you should probably just do it yourself.",
          "score": 8,
          "created_utc": "2026-01-29 23:58:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ikm9b",
          "author": "yocil",
          "text": "I got told to make a cube in a week once, the first week at that job. I told them that was ridiculous because I knew nothing about their KPIs. They insisted, so I threw an mdx cube together in a week that counted keys and summed the decimals.\n\nIt was entirely useless but I worked there for 7.5 years and rebuilt their entire backend from scratch.",
          "score": 5,
          "created_utc": "2026-01-30 00:46:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ifna5",
          "author": "reditandfirgetit",
          "text": "\"data is clean\" usually means \"it's clean now but the old stuff is a nightmare. Good luck\"\n\nJust tell them they can have it right or they can have it right now. It's going to take x time to do it right",
          "score": 4,
          "created_utc": "2026-01-30 00:20:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jzbg0",
          "author": "Illustrious_Web_2774",
          "text": "I'll go off the client pissing train.\n\n\nYour client probably wants to have something tangible, fast, to prove the value.\n\n\nIt's obvious that you don't have the customer's trust, and probably you haven't attempted to gain any yet. You simply follow what you personally think is right, without trying to solve the problems for the client.\n\n\nIn short, you have not proven yourself yet, to be the trusted advisor who can burn their budget at will.\n\n\nYou could offer to do quick and dirty raw -> cube with disclaimer that it's not for long term and should be revised later once the use cases are clearer.\n\n\nThis this basic software consulting.",
          "score": 3,
          "created_utc": "2026-01-30 05:49:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ikyna",
          "author": "zesteee",
          "text": "Well in fairness, I can build a basic cube in a few hours using ancient old Cognos software, I did a super basic one for someone yesterday in under an hour. Maybe they‚Äôve had experience with something like that, and are defining a cube as different to your definition?  Could just be an interpretation error.",
          "score": 4,
          "created_utc": "2026-01-30 00:48:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ielid",
          "author": "Sufficient_Example30",
          "text": "Op it can be built in a day.\nHook up the dataset to chatgpt and viola.\nThey can ask questions via plain English and be 50% accurate.\nAccuracy,data security are for rookies.\nSpeed is the new future",
          "score": 1,
          "created_utc": "2026-01-30 00:14:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ihqjw",
              "author": "Dunworth",
              "text": "50% is very generous lol",
              "score": 4,
              "created_utc": "2026-01-30 00:31:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2io2h0",
                  "author": "Sufficient_Example30",
                  "text": "Hey you just need to write a super tailor made prompt.\nMaybe use medival English",
                  "score": 4,
                  "created_utc": "2026-01-30 01:05:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2honke",
          "author": "LoaderD",
          "text": "‚ÄúI heard data cubes were fast to access and we want to do HFT, so build this‚Äù",
          "score": 1,
          "created_utc": "2026-01-29 21:59:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ijbii",
          "author": "TodosLosPomegranates",
          "text": "The deal is that even if you could do it, why would you trust them? They‚Äôve clearly got expectations that they developed based on who knows what. Those expectations are not grounded in reality. Either they know that and they‚Äôre trying to see what they can get out of you or they don‚Äôt know that and there‚Äôs no way to manage their expectations. This is a bad client and you‚Äôre setting yourself up for a bad experience.",
          "score": 1,
          "created_utc": "2026-01-30 00:39:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ipnyv",
          "author": "energyguy78",
          "text": "Sounds like my company",
          "score": 1,
          "created_utc": "2026-01-30 01:13:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jg0qs",
          "author": "KarmicDharmic",
          "text": "Are you looking to build an OLAP cube involving fact and dimension tables?",
          "score": 1,
          "created_utc": "2026-01-30 03:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k4y4o",
          "author": "Justbehind",
          "text": "Well, if you use SQL server, just make an ETL to one consolidated table and slap a clustered columnstore on there. Done.\n\n\nHeck, it's 2026... Cubes are outdated. They've been so for at least a decade.",
          "score": 1,
          "created_utc": "2026-01-30 06:32:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k7kcd",
          "author": "Crazy-Sir5935",
          "text": "When the word \"Cube\" comes in, coming from a Finance background, it triggers \"pivot table\" in me. Basically they want a star/snowball schema with pivot tables (preaggregated facts). Hooray for whoever invented the term cube to make things more complex....",
          "score": 1,
          "created_utc": "2026-01-30 06:54:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l21q7",
          "author": "Nekobul",
          "text": "Please provide information which 4 ERPs systems they want to use. If the ERPs are well established, you may already have third-party extensions available for SSIS to read from them.",
          "score": 1,
          "created_utc": "2026-01-30 11:22:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l3sck",
              "author": "Better_Code5670",
              "text": "SAP among others‚ò†Ô∏è‚Ä¶ Iv asked what connectors they had in place, they didn‚Äôt even share that! That‚Äôs why I included the source system analysis and architecture phase, where after this phase is delivered Id reasses once again the remainder of the delivery phases!",
              "score": 1,
              "created_utc": "2026-01-30 11:36:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2l56h4",
                  "author": "Nekobul",
                  "text": "There are SAP connectors available from Theobald Software for SSIS. If you have ERP connectivity available, the rest of the implementation will be relatively easy.",
                  "score": 1,
                  "created_utc": "2026-01-30 11:47:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2mvfah",
          "author": "No-Satisfaction1395",
          "text": "Show me an ERP system with only a few tables :(",
          "score": 1,
          "created_utc": "2026-01-30 17:09:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ppvge",
          "author": "Accomplished_Cloud80",
          "text": "I am sure they are part of specific nationals who has that mindset to hassles everything and take over. I am sure your executives believe that is the right requests.",
          "score": 1,
          "created_utc": "2026-01-31 01:29:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2imxx0",
          "author": "zangler",
          "text": "I am in a green space building a reporting and modeling layer from an operational MSSQL server that has the bespoke production tool data. It is clean...but naturally transactional. It didn't take long to explain why only \"37 rows of data\" wouldn't fit into Excel in the raw form anymore...\n\nI am ABSOLUTELY the lucky one though. One peek at the backend code, the observability, the punch list of items etc, and they got it...this is the cost of being in the big leagues. \n\nFrustration is there for transition...but NEVER aimed at me or the new paradigm. They understand this is normal but the future is worth all of the waiting and immediate discomfort.\n\nI'll show myself out...",
          "score": 1,
          "created_utc": "2026-01-30 00:58:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ibr7o",
          "author": "SadDogOwner27",
          "text": "Sigma.",
          "score": 0,
          "created_utc": "2026-01-29 23:58:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsm2gq",
      "title": "How to learn OOP in DE?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qsm2gq/how_to_learn_oop_in_de/",
      "author": "EconMadeMeBald",
      "created_utc": "2026-02-01 02:32:50",
      "score": 67,
      "num_comments": 77,
      "upvote_ratio": 0.95,
      "text": "I‚Äôm trying to learn OOP in the context of DE, while I do a lot of work DE work, I haven‚Äôt found a reason why to use classes which is probably due lack of knowledge. So I was wondering are there sources that you recommend that could help fill in the gaps on OOP in DE?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qsm2gq/how_to_learn_oop_in_de/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2x38jg",
          "author": "dukeofgonzo",
          "text": "I start with functions to do what I need to do. One at a time. After a while I have a lot of functions that use the same parameters. That's when I think I have a good candidate for building a class. I just do it to keep my own work organized.",
          "score": 62,
          "created_utc": "2026-02-01 04:49:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xgvi4",
              "author": "JunkPup",
              "text": "Bingo. My only other recommendation is if you can think of a real world ‚Äúobject‚Äù that you‚Äôre constantly writing functions to handle, then writing a class should be something you work towards from the start. It makes adding new functions (methods) so much easier to bolt on when you already have the base class written.",
              "score": 14,
              "created_utc": "2026-02-01 06:33:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2yvt11",
              "author": "Headband6458",
              "text": "Great! That‚Äôs not OOP, though, unless when you put the functions together you‚Äôre changing them to modify object state, i.e. making them not be functions anymore. I would call what you describe ‚Äúnamespacing‚Äù, which is the only benefit you get from just putting a bunch of functions into a class.",
              "score": 5,
              "created_utc": "2026-02-01 13:44:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2z17fp",
                  "author": "dukeofgonzo",
                  "text": "These are not just collections of static methods. I'm building objects all the time that use object, class, and static methods. These objects get used in other classes. I make a few abstract classes and a lot of children for specific work topics. I have found a lot of use out of Python classes to do my data engineering work. However, most of my coworkers aren't comfortable with Python that deep.",
                  "score": 4,
                  "created_utc": "2026-02-01 14:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2x6jd1",
          "author": "psychuil",
          "text": "I feel functional fits DE much more, never really use classes.",
          "score": 63,
          "created_utc": "2026-02-01 05:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xavj1",
              "author": "Otherwise_Movie5142",
              "text": "Same, at least in the type of work I do.\n\nI'll use polymorphism for things like 'rules' or 'selectors',  maybe a few data classes and an orchestrator etc but pure OOP is usually overkill.",
              "score": 7,
              "created_utc": "2026-02-01 05:45:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2xgtly",
                  "author": "psychuil",
                  "text": "Why use dataclasses when arrow exists?",
                  "score": 4,
                  "created_utc": "2026-02-01 06:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wqqzs",
          "author": "zeolus123",
          "text": "I try not to get too carried away with it because it can be easy to over engineer things. \nWe use oop to write reusable source gateway and downloader classes.",
          "score": 24,
          "created_utc": "2026-02-01 03:26:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yzgpe",
              "author": "speedisntfree",
              "text": "This is good advice, bad OOP code is awful. These cases are pretty much the only times I've used it, most code in DE doesn't need state.",
              "score": 2,
              "created_utc": "2026-02-01 14:06:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xand4",
          "author": "IDoCodingStuffs",
          "text": "OOP directly maps to table schemas. You can try to represent tables you work with as classes and rows as objects. \n\nThen you can try to play around with inheritance, interfaces etc. if you have some relationships. Or try to apply language features depending on which one you are using.\n\nBut simply mapping data from tables to defined classes puts you ahead of the curve tbh.",
          "score": 15,
          "created_utc": "2026-02-01 05:43:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ywbo9",
              "author": "Headband6458",
              "text": "Be aware the difference between the logical and physical model. You probably want the logical model in your code, not the physical model. What‚Äôs the advantage of re-using the physical model like you describe? The logical model will only change when the business that the data relates to changes. The physical model can change at the whim of the data engineer.",
              "score": 2,
              "created_utc": "2026-02-01 13:47:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o30ypit",
                  "author": "IDoCodingStuffs",
                  "text": ">¬†What‚Äôs the advantage of re-using the physical model like you describe\n\nSo that you can wire it up with different APIs that require that data in different formats.\n\nFair point though. Domain Driven Design was invented to solve the problem you brought up essentially\n\n> The physical model can change at the whim of the data engineer\n\nIt can, in which case you update the code. Or have a sit-down and try to convince them to not make breaking changes so often",
                  "score": 2,
                  "created_utc": "2026-02-01 19:44:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xbncd",
              "author": "IshiharaSatomiLover",
              "text": "This is the way.",
              "score": 1,
              "created_utc": "2026-02-01 05:51:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2x9d9k",
          "author": "dataenfuego",
          "text": "We build a lot of python libraries that help automate certain DE tasks:\n- table metadata (DDLs, table management)\n- workflow orchestration (we use maestro) \n- data diff tooling\n\nSo all of the above are OOP, so not necessarily the data transformation itself",
          "score": 6,
          "created_utc": "2026-02-01 05:33:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xam25",
              "author": "EconMadeMeBald",
              "text": "Would you suggest a way to learn from your experience?",
              "score": 2,
              "created_utc": "2026-02-01 05:43:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xex3d",
          "author": "MonochromeDinosaur",
          "text": "You don‚Äôt need to learn it in DE context just pick up a book on Python OOP. \n\nI like https://www.cosmicpython.com because it‚Äôs practical and not dogmatic about OOP which is how most Python is written anyway.",
          "score": 4,
          "created_utc": "2026-02-01 06:17:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30y61v",
              "author": "campbell363",
              "text": "Great resource for learning Python. I love when the authors post the free versions of their books online.",
              "score": 1,
              "created_utc": "2026-02-01 19:41:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xuhzq",
          "author": "islandboi124",
          "text": "I‚Äôve lately been using classes a lot supported by protocols in Python to standardize the methods in the classes. This has been helpful when I have multiple sources with different source types, schemas and/or formats. \n\nThis allows me in a main function to simply do something like:\n\nfor source in sources:\n\n    source.extract()\n    source.transform()\n    source.load()\n\n\nSorry for the formatting, writing this from my phone!",
          "score": 3,
          "created_utc": "2026-02-01 08:36:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yg9k0",
              "author": "Usurper__",
              "text": "Do you have an example. Sounds cool",
              "score": 1,
              "created_utc": "2026-02-01 11:54:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2yi98x",
                  "author": "islandboi124",
                  "text": "https://realpython.com/python-protocol/\n\nHere under structural subtyping and protocols gives a clear general example, but would suggest reading the whole thing!",
                  "score": 1,
                  "created_utc": "2026-02-01 12:10:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ye1qx",
          "author": "Frosty-Practice-5416",
          "text": "OOP is anti pattern",
          "score": 6,
          "created_utc": "2026-02-01 11:35:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xuute",
          "author": "omonrise",
          "text": "You don't need to.\nOOP makes sense when you need to store state, for example if you have a bunch of functions that can do multiple things with tables, you might like to make them methods of a class so you don't have to configure them individually.",
          "score": 3,
          "created_utc": "2026-02-01 08:39:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wiz0s",
          "author": "Tushar4fun",
          "text": "Have a look at this https://github.com/tushar5353/sports_analysis\n\nI‚Äôve created this pipeline just to show how can we leverage classes in ETL.\n\nAlso, to show modularised approach.\n\nI know there things because I‚Äôve also worked as SE.",
          "score": 4,
          "created_utc": "2026-02-01 02:39:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zer9i",
              "author": "EconMadeMeBald",
              "text": "Thank you! This is really good.",
              "score": 1,
              "created_utc": "2026-02-01 15:27:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36ewpu",
                  "author": "Headband6458",
                  "text": "No, it's not! What do you think is good about it? It's actually horrible, please don't emulate this! Every class has so many responsibilities, as one example of what's bad. The transform classes also load data from files, for example. There are no abstractions, everything is a concrete implementation. It's like somebody who has never heard of the SOLID principles trying to do OOP.",
                  "score": 0,
                  "created_utc": "2026-02-02 16:21:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wkcon",
          "author": "New-Composer2359",
          "text": "If you use Pyspark, try creating a new dataframe class based on the standard one with new functionalities that you like!",
          "score": 4,
          "created_utc": "2026-02-01 02:47:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y9wy4",
          "author": "xmBQWugdxjaA",
          "text": "For large data processing you don't want it, since you want a struct-of-arrays approach (reading from columnar data), not array of structs.\n\nBut it can be handy in orchestrators or scrapers.",
          "score": 2,
          "created_utc": "2026-02-01 10:58:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ygco4",
          "author": "robberviet",
          "text": "Unless you are writing libraries, there is not much value in learning OOP. If you still do, then it's no different from traditional SWE. Just learn how OOP is used in Python.",
          "score": 2,
          "created_utc": "2026-02-01 11:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yw2z1",
          "author": "instamarq",
          "text": "In data engineering, it's usually best to operate like Bruce Lee; take what's valuable from different approaches and apply that in areas where it will most effectively solve the problem.\n\nIn general, OOP won't get you that far in most DE scenarios _unless_ you're writing a library for some niche problem that your business data has that OOP helps you properly model.\n\nIn my opinion, OOP is for building tools and modeling reality. Most of the time, in DE, our tools are already built and our realities are mapped using data. I think someone in this thread mentioned that functional patterns are more applicable in our field. I think they're right.",
          "score": 2,
          "created_utc": "2026-02-01 13:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o301ukd",
          "author": "_Batnaan_",
          "text": "I use OOP (python mostly) to organize some complex orchestration or transformation logic when there is a lot of context information that is used repeatedly.\n\nUsually I will create one or a few classes for each problem, but nothing like what you would find in a java server app with 100+ classes.\n\nBasically I have some kafka-like stateful joins I do in incremental batch transforms. The Stateful Transform will handle its memory and its logic differently depending on what happened on inputs or depending on whether it's a replay or not. So I have a dozen functions being called with different arguments depending on the context, so I created a class to contain all of these contextual variables.\n\nSome colleagues use classes to generate transformations with very repeatable logic with some adjustments based on the size of datasets. Classes are a nice way to make the repeatable logic clear while also making the configuration well constrained (with a builder pattern for example) instead of a yaml file being called in hundreds of if/else statements)",
          "score": 2,
          "created_utc": "2026-02-01 17:14:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o312zja",
          "author": "acana95",
          "text": "I used OOP to reuse object that refer to table schema",
          "score": 2,
          "created_utc": "2026-02-01 20:04:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ze64j",
          "author": "nightslikethese29",
          "text": "Going to go against the grain here. I use OOP all the time at work. For example, we have classes for database connectors, APIs, SFTP, and other automation jobs. \n\nIf I need to download data from multiple sources and run a few checks on it, I can abstract all that away and create a method called download_data() where all of the API calls are in the method. In my opinion, it looks cleaner and it's very obvious what's happening. It's also easier to modularize and test code. \n\nOf course, both functional and OOP have their place.",
          "score": 3,
          "created_utc": "2026-02-01 15:24:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zg0rf",
              "author": "EconMadeMeBald",
              "text": "1.When you say validate here, do you integrate pd/spark or whatever into your classes? \n\n2. Any repo you recommend me looking at?",
              "score": 2,
              "created_utc": "2026-02-01 15:33:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o307gts",
                  "author": "nightslikethese29",
                  "text": "Yeah it could be things like validating API response bodies using pydantic or validating data frame schema using pandera. Just things I abstract away from the top level code. \n\nI don't have a repo to recommend unfortunately.",
                  "score": 2,
                  "created_utc": "2026-02-01 17:40:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o36e2w8",
                  "author": "Headband6458",
                  "text": "Also understand that you can do exactly the same thing with a funcitonal approach and likely end up with somehting more maintainable.\n\nIt's telling that not one single person has been able to explain a single advantage they feel they get from taking an OOP approach to a problem space that is so well-suited to the functional paradigm.",
                  "score": 0,
                  "created_utc": "2026-02-02 16:17:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wxxjp",
          "author": "Resident-Loss8774",
          "text": "While not fully in the context of DE, what has helped me gain a better understanding of OOP is first by getting a grasp the fundamental concepts (Corey Schafer has great videos) and then trying to apply those concepts. Also just reading code that uses a lot of OOP (e.g., Polars, Airflow), can help as well. Imo, for DE, OOP has a place for API clients, database connectors, custom Airflow operators, and things of that manner.",
          "score": 2,
          "created_utc": "2026-02-01 04:13:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xbn4t",
          "author": "Specific-Mechanic273",
          "text": "The only use-cases where I needed classes was when I built an ingestion tool which normally worked with most API integrations that return a JSON. And once I've built a data validation tool that runs between two databases for a migration.\n\ntbh not worth the effort, just get better in relevant stuff or look into software engineering if you're interested in OOP.",
          "score": 1,
          "created_utc": "2026-02-01 05:51:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yea1a",
          "author": "PrestigiousAnt3766",
          "text": "Don't need classes. I have a data context object containing metadata, run context though and python logger",
          "score": 1,
          "created_utc": "2026-02-01 11:37:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yeh44",
          "author": "ZirePhiinix",
          "text": "Classes only make sense when the project is so large that you bring in OOP so that you can have better control over the objects.\n\nMost DE projects don't scale in a way that particularly benefits from OOP concepts though.",
          "score": 1,
          "created_utc": "2026-02-01 11:39:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ygohd",
          "author": "D1yzz",
          "text": "In my context, we have a class DataTypeImporters, that is responsible to validate and store data in the respective tables. This class has a lot of properties/method that need to be defined/implemented to force consistency and pre validations.   \nEach of the same DataTypeImporters, can have different sources, with specific implementations, like Rest API, SOAP, XML, SFTP, DB, and so on, where the specifics are implemented but they all use a sort of client, that serves has base class for the specific client. Then we might have specific classes for data cleaning, transformation, validation, data quality checks, reports and so on.   \nWe create a template, with optional or mandatory parts, than can be reused or overwriten",
          "score": 1,
          "created_utc": "2026-02-01 11:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2z06vc",
          "author": "speedisntfree",
          "text": "If you use Airflow, writing custom Operators and Hooks will give you can idea of how OOP can be useful. They give you a structured way to write the custom behviour you want that is compatible with Airflow.",
          "score": 1,
          "created_utc": "2026-02-01 14:10:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zc4cv",
          "author": "Bach4Ants",
          "text": "If it ain't broke don't fix it. I've seen \"OOP\" go horribly wrong in DE: Using classes with many-level inheritance to write procedures and mutating internal state to store results. Python makes it especially easy to abuse classes.",
          "score": 1,
          "created_utc": "2026-02-01 15:14:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34xzdi",
          "author": "CynicalShort",
          "text": "Like many others, advice caution with OOP in DE. Namespacing static methods is nice use of classes, but applying OOP to pipeline code is usually extra abstraction. I have witnessed cases that I count as griefing the company by incompetense. But if you need a small library or custom tool for a problem, OOP could be suitable.",
          "score": 1,
          "created_utc": "2026-02-02 11:11:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsg6tc",
      "title": "Puzzle game to learn Apache Spark & Distributed Computing concepts",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qsg6tc/puzzle_game_to_learn_apache_spark_distributed/",
      "author": "Elegant_Debate8547",
      "created_utc": "2026-01-31 22:21:37",
      "score": 64,
      "num_comments": 3,
      "upvote_ratio": 0.98,
      "text": "https://i.redd.it/fsa3dtvkfrgg1.gif\n\nHello all!\n\nI'm new in this subreddit! I'm a Data Engineer with +3 years of experience in the field.\n\nAs shown in the attached image, I'm making an ETL simulator in JavaScript, that simulates the data flow in a pipeline.\n\nRecently I came across a Linkedin post of a guy showcasing this project : [https://github.com/pshenok/server-survival](https://github.com/pshenok/server-survival)\n\nHe made a little tower defense game that interactively teaches Cloud Architecture basics.\n\nIt was interesting to see the engagement of the DevOps community with the project. Many have starred and contributed to the Github repo.\n\nI'm thinking about building something silimar for Data Engineers, given that I have some background in Game Dev and UI/UX too. I still need your opinion though, to see whether or not it is going to be that useful, especially that it will take some effort to come up with something polished, and AI can't help much with that (I'm coding all of the logic manually).\n\nThe idea is that I want to make it easy to learn Apache Spark internals and distributed computing principles. I noticed that many Data Engineers (at least here in France), including seniors/experts, say they know how to use Apache Spark, yet they don't deeply understand what's happening under the hood.\n\nThrough this game, I'll try to concretize the abstract concepts and show how they impact the execution performance, such as : transformations/actions, wide/narrow transformations, shuffles, repartition/coalesce, partitions skew, spills, node failures, predicate pushdown, ...etc\n\nYou'll be able to build pipelines by stacking transformer blocks. The challenge will be to produce a given dataframe using the provided data sources, while avoiding performance killers and node failures. In the animated image above, the sample pipeline is equivalent to the following Spark line : `new_df = source_df.filter($\"shape\" === \"star\").withColumn(\"color\", lit(\"orange\"))`\n\nI represented the rows with shapes. The dataframe schema will remain static (shape, color, label) and the rendering of each shape reflects the content of the row it represents. Dataframe here is a set of shapes.\n\nI'm still hesitant about this representation. Do you think it is intuitive and easy to understand ? I can always revert to the standard tabular visualisation of rows with dynamic schemas, but I guess it won't look user friendly when there are a lot of rows in action.\n\nThe next step will be to add logical multi-node clusters in order to simulate the distributed computing. The heaviest task that I estimated would be the implementation of the data shuffling.\n\nI'll share the source code within the next few days, the project needs some final cleanups.\n\nIn the meanwhile, feel free to comment or share anything helpful :)",
      "is_original_content": false,
      "link_flair_text": "Personal Project Showcase",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qsg6tc/puzzle_game_to_learn_apache_spark_distributed/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o306k8s",
          "author": "goeb04",
          "text": "Some distributed computing architecture does seem murky to me, so I would be happy to use it once you make the code available.\n\nWish I had more to offer, but as someone who is a severe Visual Learner, this sounds great üëç.",
          "score": 6,
          "created_utc": "2026-02-01 17:36:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31c134",
              "author": "Elegant_Debate8547",
              "text": "Thank you for your comment !\nWhat do you think about the shape representation of data rows ? Is it something you feel comfortable with ?",
              "score": 2,
              "created_utc": "2026-02-01 20:48:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o32chcf",
          "author": "lezwon",
          "text": "I'd love to try something like this out ü•≥",
          "score": 4,
          "created_utc": "2026-02-01 23:55:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsqhzm",
      "title": "How to become senior data engineer",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qsqhzm/how_to_become_senior_data_engineer/",
      "author": "Sudden-Inflation2686",
      "created_utc": "2026-02-01 06:08:16",
      "score": 60,
      "num_comments": 18,
      "upvote_ratio": 0.84,
      "text": "I am trying to develop my skills be become senior data engineer and I find myself under confident during interviews .How do you analyze a candidate who can be fit as senior position?",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qsqhzm/how_to_become_senior_data_engineer/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2xv7f2",
          "author": "cmcclu5",
          "text": "Seniors can:\n- Solve problems on their own\n- Mentor juniors\n- Understand not just a single piece but how it relates to the overall architecture\n- Be aware of the cost/benefit analysis of various solutions\n- Propose new VALID design patterns (not just ‚Äúwe should refactor to Snowflake‚Äù or ‚Äúlet‚Äôs migrate everything to Dagster‚Äù)\n- And, most importantly for most companies, communicate effectively with non-technical and differently-technical stakeholders and executives",
          "score": 70,
          "created_utc": "2026-02-01 08:43:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yn3co",
              "author": "decrementsf",
              "text": "I agree. Expanding more on job leveling processes from an employer perspective.\n\nCompanies look for comparison to other companies to determine what to price their roles at. This is done through compensation surveys with data generally collected each June-July, and results published around November. This is an imperfect process as every company calls roles slightly different so an analyst goes through and tries to match the roles reasonably to a generalized guide of what other companies call this role. Part of this process is it is helpful to level how senior the duties of that role is. Usually this is done with Pay Grades. Because the companies that collect analyze and prepare the compensation surveys are broadly known, their Pay Grades are most often what companies are internally calling their pay grades.\n\nWillis Towers Watson is one of the common surveys. They provide a leveling guide with description of what is generally differences between levels of seniority for professionals. Data engineer is generally going to fall under the Professional (P) classification in the WTW system. Most data engineers would be a P2, and senior a P3. Entry level may be P1. The P4 and P5 is much more rare, usually a professional individual contributor with 20 or 30 years experience, much less common. P3 tends to be the catch all for senior.\n\nA crude difference is that a data engineer can work through core business tasks but generally needs a more senior team member for guidance and some supervision. They can follow processes and best practices. At the senior level they can work more independently thinking through novel challenges that come up, they can create the processes and best practices and serve as a resource for more junior associates when novel challenges come up outside the usual experiences.\n\nA listing of descriptions of the different Professional pay grades can be read here.\n\nhttps://itv.career-navigator.willistowerswatson.com/career-bands/definition/professional?level=P2\n\nThere are other adjustments usually tech roles receive a compensation premium in compensation surveys. They'll denote things like a \"P3 - P\" the - P denoting a tech role premium that may be a flat 15% - 20% over compensation benchmarks depending on the companies policies. With rare skills as is common in tech roles often comp surveys are less useful and they'll perform specialized analysis for compensation plans for these.\n\nNot speaking exhaustively how work gets done but enough to get a sense for the flow of why pay grades exist and a primary source you can familiarize with that are used by companies. There also exist pay grades of other career levels, M is management, senior management are E's, business admin are B's.",
              "score": 9,
              "created_utc": "2026-02-01 12:47:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o31i9vv",
              "author": "LoaderD",
              "text": "Yeah, but they have to forget the ‚Äúdon‚Äôt blindly refactor‚Äù rule if they want to move to a manager+ role.",
              "score": 2,
              "created_utc": "2026-02-01 21:19:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zz1jc",
          "author": "A_Polly",
          "text": "People here are pulling a leg out to tell you what to do. The reality is: You are Junior DE. Only Senior leaves. You are Senior now. That's like 80% of cases.\nThat's how it fucking works and never let anyone tell you something else. But you need to be able to handle the shit show.\n\nThe other way is to tell your boss what you have to do to become senior. Define clear tangible Targets. If you meet those targets you should become Senior. If not hand in your resignation. Either you are valuable and they will reward you with the role or you were not valuable (just a cost center) in your role, which is just a time bomb anyway.\n\nNobody is waiting to award you with a senior title. They will try to keep you on a lower paycheck as long as possible.",
          "score": 10,
          "created_utc": "2026-02-01 17:01:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ynagm",
          "author": "chrisgarzon19",
          "text": "Business impact \n\nEveryone whose already a level 2 or 3 know the basics and tech stuff \n\nAre you a leader with a business mind is the question",
          "score": 3,
          "created_utc": "2026-02-01 12:48:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xh6ug",
          "author": "adastra1930",
          "text": "I really want to help you, but it‚Äôs the kind of question where if you are asking, it means you‚Äôre nowhere near ready. But as a general rule, the difference between any individual contributor (IC) role and a senior IC role is the demonstrable ability to basically manage yourself. Identify and execute projects that support company objectives, develop relationships within the business, that sort of thing. \n\nThis is why: the next step from senior is often a lead or manager, so to go from junior to senior, you need to demonstrate capability, then when you‚Äôre a senior you‚Äôll be refining your capability and starting to demonstrate that you can apply your skill to leading others, which gets you to the next place.\n\nAnd obviously that varies wildly from company to company üòÖ",
          "score": 20,
          "created_utc": "2026-02-01 06:36:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z97eh",
              "author": "shittyfuckdick",
              "text": "What a gatekeepy response. We should be encouraging people to grow in their career not scare them away from it.¬†",
              "score": 3,
              "created_utc": "2026-02-01 14:59:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31indr",
          "author": "LoaderD",
          "text": "Learn to explain things well.\n\nYou don‚Äôt even outline your background, so people are giving you blind advice.\n\n‚ÄúI want to be sr‚Äù can be totally different if you‚Äôre a 5yoe intermediate vs a new grad who has 6 months of experience.",
          "score": 3,
          "created_utc": "2026-02-01 21:21:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xgnch",
          "author": "amejin",
          "text": "You have a leg up - you've interviewed!\n\nFirst, some practical advice - you sitting in an interview means on paper you're already qualified. They're getting to know you. \n\nSecond, some actionable advice - you have experienced the questions and have a newfound understanding of what the industry is looking for. Be good at those things and be the expert so you can answer confidently. Lack of confidence is usually a lack of preparation. \n\nFinally - you will be hit with imposter syndrome your entire career. Embrace the suck.",
          "score": 6,
          "created_utc": "2026-02-01 06:31:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z9ili",
              "author": "shittyfuckdick",
              "text": "This is not true in my experience. I have been interviewing for senior roles and have had many rejections all of which either saying i didnt have enough experience or they had a more qualified person. Just cause they interview you does mean your senior level imo.¬†",
              "score": 2,
              "created_utc": "2026-02-01 15:01:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o305zye",
                  "author": "Childish_Redditor",
                  "text": "It means your resume meets the minimum requirements to be a senior level engineer at those companies giving you interviews",
                  "score": 3,
                  "created_utc": "2026-02-01 17:33:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o309nr9",
                  "author": "amejin",
                  "text": "I guess the \"on paper\" part was lost on you.. maybe you're over representing yourself?",
                  "score": 1,
                  "created_utc": "2026-02-01 17:50:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xmcdg",
              "author": "Adepate",
              "text": "That imposter syndrome feels real. Sometimes, the reason for underperforming during interviews is the fear of being an imposter",
              "score": 1,
              "created_utc": "2026-02-01 07:21:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xmshd",
          "author": "circumburner",
          "text": "When a technical problem gets escalated, and there is no one to escalate higher, whether you know the solution or not, you're senior. \n\nOr, whenever your bosses changes your title. Either way.",
          "score": 4,
          "created_utc": "2026-02-01 07:25:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xzpps",
          "author": "robberviet",
          "text": "Many people has answered, just want to add: Can architecture design, and explain why to do that; understand that there are more than just technical about this role.",
          "score": 2,
          "created_utc": "2026-02-01 09:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3465sr",
          "author": "empireofadhd",
          "text": "Once you see data engineering as the ‚Äùthree body problem‚Äù and can navigate that I‚Äôd say you are senior. \n\nJuniors fixate on a specific aspect of the solution as a whole while seniors know there is more to things then eg perfect code. \n\nAlso you have seen and probably contributed to a couple of failed/sucessful projects end to end and had to do some maintenance of it after you are ‚Äùdone‚Äù. The maintenance is very important because long term that is where most costs are generated. This is why lots of senior devs are a bit sceptical about ai and the maintenance costs it will generate.\n\nSo to answer your question: make sure you are exposed to all aspects of a project lifecycle, not just greenfield nice solutions where you have free hands. Also spend time with mid career seasoned guys and listen to them rant.",
          "score": 2,
          "created_utc": "2026-02-02 06:50:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y0m4i",
          "author": "revitev1122",
          "text": "Most of the real skills one learns in the job. Once you know the basics of SQL/Python/basic Data Engineering fundamentals (CDC/Data Governance/OOP/Security/Statistic/DevOps/BI/etc), the questions one can be asked in this industry is so vast that practicing for it may be in vain. Esp in the high pressure screen share environment of difficult questions one might be asked.¬†\n\nThe longer you work at that job the more senior one can become. Avoid working in/applying to industries/for companies that intentionally use older technologies. By that I mean if they list older technologies in their job positing or the company inherently keeps themselves ancient like Intel/IBM/some pharmaceutical companies/some government jobs/etc.¬†\n\nThis approach may not be for everyone but I applied to hundreds, if not thousands of jobs in a year. Which, like reading 20 pages of a book a day, can be the simple consistency of a few jobs a day. And when my current job stopped challenging me enough during the pandemic I joined a start-up to challenge myself further. They just wanted SQL which is an easy requisite and through that process I learned Snowflake, and through that start-up/Snowflake experience I later got another job in Snowflake/GBQ/GCP, and through that job I later got a job in AWS/Databricks.\n\nI never practiced code tests for any job. Many jobs didn‚Äôt want me for many reasons outside my control and it still hurt on a deep personal level. Many jobs I didn‚Äôt want because the interviewer was rude/the company didn‚Äôt seem fun. But for the few jobs that worked out I have seen a bunch of different problems in a bunch of different contexts in a bunch of different languages in a bunch of different industries. Those things, and factors about one‚Äôs personality, seem to govern good Senior/Staff level positions. It‚Äôs more about the patterns one has seen in real scenario's and one‚Äôs temperament - that‚Äôs hard to train for.",
          "score": 1,
          "created_utc": "2026-02-01 09:33:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y19it",
          "author": "PrestigiousAnt3766",
          "text": "Work.",
          "score": -4,
          "created_utc": "2026-02-01 09:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwd5of",
      "title": "Is someone using DuckDB in PROD?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qwd5of/is_someone_using_duckdb_in_prod/",
      "author": "Free-Bear-454",
      "created_utc": "2026-02-05 05:51:13",
      "score": 60,
      "num_comments": 42,
      "upvote_ratio": 0.92,
      "text": "As many of you, I heard a lot about DuckDB then tried it and liked it for it's simplicity.\n\nBy the way, I don't see how it can be added in my current company production stack.\n\nDoes anyone use it on production? If yes, what are the use cases please?\n\nI would be very happy to have some feedbacks",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qwd5of/is_someone_using_duckdb_in_prod/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3oeowa",
          "author": "ambidextrousalpaca",
          "text": "We've been using DuckDB in production for a year now, running and generating the queries we need with Python code.  \n\nSo far it's gone great. No major problems.\n\nWe switched from developing new pipelines in PySpark to doing so with DuckDB mainly on the basis that:\n\n1. We observed that the actual data loads we were processing were never big enough to necessitate a Spark cluster.\n2. Getting rid of Spark meant we could get rid of the whole complexity of running a JVM using the massive collection of libraries Spark requires (with all of their attendant security vulnerabilities) and replace it with a single, dependency-free DuckDB compiled binary.\n3. When we tested it against Spark on our real data it ran about 10 times faster and used half the resources (and _yes_, I'm sure the Spark code could have been optimised better, but that's what our testing for our specific use-case showed).\n\nPoint 3 was the major one that allowed us to convince ourselves this was a good idea and sell it to management.",
          "score": 88,
          "created_utc": "2026-02-05 07:02:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3or0x0",
              "author": "CAPSLOCKAFFILIATE",
              "text": "> actual data loads we were processing were never big enough to necessitate a Spark cluster.\n\nThe first step towards living an easy life is realizing we overcomplicate things without actual need. There is no \"big data\" in corporate, unless you work in MAG7, major banks or AI labs. 95% of companies can run just fine with DuckDB, and that's assuming they ever leave Excel as \"data management backend\".",
              "score": 36,
              "created_utc": "2026-02-05 08:57:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qtg7i",
                  "author": "reelznfeelz",
                  "text": "For sure.  People are quick to reach for these powerhouse tools but you really should consider if you need them.   Postgres, or apparently duckDB, can take you quite far.",
                  "score": 1,
                  "created_utc": "2026-02-05 16:52:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3oma84",
              "author": "CulturMultur",
              "text": "Yeah, Spark infrastructure completely sucks. But, Dataframe API vs templated SQLs are very different, and whenever trend is to start programming with templating (dbt macros, I‚Äôm looking at you) - I would not put any important business logic under templating. With Spark I can isolate logic into pure functions - dataframes in, Dataframe out -and test it. With templating - nope.",
              "score": 8,
              "created_utc": "2026-02-05 08:12:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3p11fb",
                  "author": "Difficult-Tree8523",
                  "text": "We use SQLFrame to get a pyspark compatibility API",
                  "score": 2,
                  "created_utc": "2026-02-05 10:34:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ol9zk",
              "author": "Free-Bear-454",
              "text": "Very interesting feedback! Where do you run DuckDB though? What is the infra and architecture if you can talk about it?",
              "score": 7,
              "created_utc": "2026-02-05 08:02:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q8741",
                  "author": "ambidextrousalpaca",
                  "text": "There's very little. Just running it on Linux boxes in the cloud. That's the beauty of it. Simple.",
                  "score": 1,
                  "created_utc": "2026-02-05 15:13:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ovsug",
              "author": "singinggiraffe",
              "text": "Is spark and duckdb comparable? I don't know much but I thought spark was abiut distributed computing and duckdb is a tabular database optimized for longer tables or something, no?",
              "score": 3,
              "created_utc": "2026-02-05 09:44:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q2h8w",
                  "author": "Keizojeizo",
                  "text": "They are comparable in the sense that they write transformations in SQL - not exact same dialect but very close. They both can read and write csv, parquet, etc.\n\nOften those are the only features that people are really using from each engine.\n\nSpark is optimized for distributed compute, and duckdb is meant to execute within a single process. Spark has more overhead, always, than duckdb, and one could argue is only worth it if the data size is absolutely massive such that the data can‚Äôt fit on a single machine.",
                  "score": 2,
                  "created_utc": "2026-02-05 14:44:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3q8fco",
                  "author": "ambidextrousalpaca",
                  "text": "DuckDB actually does a better job of parallelizing queries across process cores than Spark does, based on our testing and monitoring of memory and CPU usage.",
                  "score": 1,
                  "created_utc": "2026-02-05 15:14:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ofru0",
              "author": "Difficult-Tree8523",
              "text": "+1 share same experience¬†",
              "score": 4,
              "created_utc": "2026-02-05 07:11:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o76xj",
          "author": "putokaos",
          "text": "It all depends on the size, complexity, and purpose of your stack. In my case, we use DuckDB to detach some queries from Snowflake that even with the smallest compute engine size, would be an overkill, so it's very useful with our processing pipelines. Aside from that, DuckDB is fantastic for Data Analysts, as they can make use of their computers instead of draining resources from the DWH. We also use it in its WASM version as part of the Evidence.dev stack, which nurtures a lot of our dashboards.",
          "score": 25,
          "created_utc": "2026-02-05 05:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3olg3x",
              "author": "Free-Bear-454",
              "text": "Can you tell us about how it works please? Are you using DBT or something else to handle transformations?",
              "score": 2,
              "created_utc": "2026-02-05 08:04:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3p446f",
                  "author": "putokaos",
                  "text": "We mainly use dbt for transformations, so, for some of them we use DuckDB, and for some others, we use Snowflake. That said, to make this possible you must work with external tables in Snowflake, as our architecture is based on a Data Lakehouse. You'd also need an orchestrator, such as Dagster, as dbt has some limitations in this regard, especially if you want to maintain lineage. Regarding the execution engine, it's fair to say that there are alternatives that allow you to route your queries dynamically, such as Greybeam. But they are still in a very early stage.",
                  "score": 5,
                  "created_utc": "2026-02-05 11:01:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3onyal",
          "author": "ppyil",
          "text": "Yes, heavily using DuckDB. We work with less data than most companies here I suspect, enough that tables used for analytics can be loaded into instances of our webserver in-memory for extremely quick data analytics on the front end.\n\nSo each instance is a Docker image running Django and periodically redownloading the latest DuckDB file (which is an output of our data pipeline elsewhere) and then allowing for views to be constructed via direct access to DuckDB.\n\nI've been thinking about building a proper database driver between Django and DuckDB but for now, a combination of generating direct SQL and using polars have given us everything we need.",
          "score": 10,
          "created_utc": "2026-02-05 08:28:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3otnuj",
              "author": "ILoveBNTC",
              "text": "Very interested in this. We currently run a django backend that has some slow queries consumed by our frontend and have already been optimized.\n\nWould you be able to share how this integration works?",
              "score": 4,
              "created_utc": "2026-02-05 09:23:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pbgu5",
                  "author": "ppyil",
                  "text": "We've got a cron job that downloads the latest duckdb file from S3 periodically, every 15 mins or so. Luckily our final DuckDB file is pretty small, about 30MB and so we can easily just download and use",
                  "score": 1,
                  "created_utc": "2026-02-05 12:02:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3okark",
          "author": "PrinceN71",
          "text": "I do. It's very useful although currently only a very small part. Traditionally my company uses sql in database but seeing the performance benefits of duckdb, my company is planning on using a data lake like delta lake and duck DB to do the processing\n\nCurrently my biggest issue I'm trying to figure out is how I want to update the data in delta tables because I'm mainly using polars to insert the data. I don't really have much experience in this but if anyone has any tips on how I can update delta tables using polars instead of pyspark I am all ears",
          "score": 3,
          "created_utc": "2026-02-05 07:53:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p9fuj",
              "author": "commandlineluser",
              "text": "What trouble are you having exactly?\n\nThere's many examples in the delta tests:\n\n- https://github.com/pola-rs/polars/blob/0c179b5c3edcbfd9db8745507931781327950a9d/py-polars/tests/unit/io/test_delta.py#L576-L601\n\n(`LazyFrame.sink_delta()` was also added in 1.37.0)",
              "score": 1,
              "created_utc": "2026-02-05 11:46:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3q6flx",
              "author": "shockjaw",
              "text": "Ibis supports spark if you need it to. You can switch to other coding backends if you need to without code changes.",
              "score": 1,
              "created_utc": "2026-02-05 15:04:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3oliod",
              "author": "Typical_Priority3319",
              "text": "I‚Äôm not going to tell you to not do it in Polars but what I will say is that you‚Äôre going to have a MUCH easier time just doing it in spark imo. That is if you can figure out how to get a spark instance up and running in demand (I just use glue typically)",
              "score": 1,
              "created_utc": "2026-02-05 08:05:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3om2tj",
                  "author": "PrinceN71",
                  "text": "Then I think I will just stick with spark for now. I can sacrifice abit of performance and resource if it's easier to work with",
                  "score": 2,
                  "created_utc": "2026-02-05 08:10:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3o6rea",
          "author": "nonamenomonet",
          "text": "If you‚Äôre using a severless function for some lighter weight ETL it can be used.",
          "score": 5,
          "created_utc": "2026-02-05 05:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3olryi",
          "author": "CulturMultur",
          "text": "We use DuckDB in production. Our dwh is Snowflake and I built a tool that runs worksheets (series of SQL statements) in Snowflake with little templating (Go text/template library). Some workloads started using Snowflake as an engine - in worssheet query from s3 and copy back to s3 immediately.\n\nThen we added support to DuckDB instead, now all processing happens inside the tool, so paying AWS instead of Snowflake.\n\nHowever, working with big parquets is still better in Snowflake - maybe it‚Äôs me, but ‚Äúselect from s3://prefix-with-parquets limit 100‚Äù hangs in DuckDB while taking 100ms in Snowflake.",
          "score": 2,
          "created_utc": "2026-02-05 08:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3omyja",
              "author": "Free-Bear-454",
              "text": "Please let me understand, you migrated all of Snowflake workloads to DuckDB?",
              "score": 1,
              "created_utc": "2026-02-05 08:18:40",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3ooa98",
              "author": "linos100",
              "text": "At what sizes are you having issues with parquets in duckdb? Where is duckdb running? (I assume the mentioned tool in \"...inside the tool...\" is duckdb)",
              "score": 1,
              "created_utc": "2026-02-05 08:31:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3osziz",
          "author": "pra__bhu",
          "text": "we use it for ad-hoc analytics and local development but not as a primary production db\nthe sweet spot ive found is:\n\t‚àô\trunning queries against parquet/csv exports without spinning up a full warehouse\n\t‚àô\tprototyping analytics pipelines before pushing to snowflake\n\t‚àô\tinternal tools where you need fast aggregations but dont need concurrent writes\nthe limitation is it‚Äôs single-process - no concurrent write access, so anything with multiple users writing data simultaneously is a no-go. reads scale fine though\nseen some teams embed it in data apps where users query pre-built datasets, works great for that. but if you need a traditional multi-user transactional system it‚Äôs not the right tool\nwhat‚Äôs your use case? might be able to give a more specific take‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 2,
          "created_utc": "2026-02-05 09:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pil1h",
          "author": "Thinker_Assignment",
          "text": "using it for (ELT)->L\n\ncanonical on duckdb then load",
          "score": 2,
          "created_utc": "2026-02-05 12:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oqyx0",
          "author": "blockchan",
          "text": "Hex.tech is using it in analytics layer as in memory db. Works v ery nice",
          "score": 1,
          "created_utc": "2026-02-05 08:57:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3or1ux",
          "author": "hoselorryspanner",
          "text": "I use it in a severless Vue app to speak to a parquet datalake. Works a treat for smallish (<10k records) tables.\n\nWhether or not you‚Äôd call this prod is a different story: it‚Äôs a web viewer for an intake catalog, just aiming to make life easier for our users.",
          "score": 1,
          "created_utc": "2026-02-05 08:57:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p1dx3",
          "author": "undergrinder_dareal",
          "text": "We use duckdb as processing engine mostly, very statisfied. Our use case is like duckdb as a pandas replacement, but in fact we never used pandas, but spark with low utilization or some kind of SQL Server.",
          "score": 1,
          "created_utc": "2026-02-05 10:37:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pt6l5",
          "author": "ghost-in-the-toaster",
          "text": "I use it for a small internal web app. I chose it because 1) I needed complex data structures and 2) as a tool that would get infrequent use, I wanted to limit it‚Äôs resource consumption (disk-only data store and no separate service running). Otherwise, Postgres is what our company uses.",
          "score": 1,
          "created_utc": "2026-02-05 13:54:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q1nhq",
          "author": "calimovetips",
          "text": "yes, but usually in narrow roles, not as a central warehouse. i see it used for embedded analytics, batch feature generation, or ad hoc transforms inside pipelines where spinning up infra is overkill. it works well when data fits on disk and concurrency is low, it falls apart once you expect shared state or lots of writers. what part of your stack are you thinking of replacing or augmenting with it?",
          "score": 1,
          "created_utc": "2026-02-05 14:40:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q5b06",
          "author": "phonyfakeorreal",
          "text": "We load user uploads into SQLite for intermediate processing, and I desperately want to replace it with DuckDB for its excellent column type detection",
          "score": 1,
          "created_utc": "2026-02-05 14:59:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q650k",
          "author": "shockjaw",
          "text": "Yup! Using it as a sink for data when I have to pull user information from Active Directory, a website, and another user directory. Have to reconcile all three to make sure they match or certain exceptions are met. It‚Äôs real nice to front load the LDAP query and not have to deal with latency unless I need to reach back out to Active Directory.",
          "score": 1,
          "created_utc": "2026-02-05 15:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q9crw",
          "author": "Lucky_Badger_",
          "text": "We also use it as a pandas replacement in our data pipelines . Files -> DuckDb ->  Postgres, Postgres tables -> DuckDb -> Postgres. In our event driven architecture its fantastic using it with Python. We break up the transformations into methods and we have a nice little library we have created to help us create datasets we can use in our unit tests. Loving it so far. \n\nIt does use floating point division, but we created a python udf that allows use to Pythons Decimal type which has solved that issue for us",
          "score": 1,
          "created_utc": "2026-02-05 15:19:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qoyqu",
          "author": "licyeus",
          "text": "We use it in a prod data pipeline to regularly ingest+process 10s of billions of rows of time series data. We load CSV, run a bunch of transforms + checks, and write parquet into blob storage. We wrote our own orchestration framework (though if starting over, we'd likely use dbt or sqlmesh).\n\nIt's been pretty solid, minus one problem with k8s killing the pod when it thinks it's OOM (we work around this by processing in batches).\n\nInfrastructural simplicity is the biggest benefit, IMO.",
          "score": 1,
          "created_utc": "2026-02-05 16:32:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qs1ur",
          "author": "full_arc",
          "text": "We use it very heavily at Fabi.ai\n\nAwesome for caching and quick processing for our users. Basically when you retrieve data that‚Äôs what we use to store it and reduce the load on the DB and avoid running up compute for our customers as the business vibes their way through an analysis. It also makes report loading super quick.",
          "score": 1,
          "created_utc": "2026-02-05 16:46:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3quful",
          "author": "hornyforsavings",
          "text": "We (Greybeam) help companies use DuckDB with their Snowflake workloads in production. We likely have the second or third largest DuckDB production clusters next to Motherduck and Coginiti",
          "score": 1,
          "created_utc": "2026-02-05 16:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o7zj8",
          "author": "Acceptable-Sense4601",
          "text": "As a data analyst, i use it in report automation to store intermediate data. So the report starts with CSV files that need to be cleaned and manipulated. The result of that stage is stored in DuckDB, then the rest of the automation pulls data from that DuckDB file.",
          "score": 1,
          "created_utc": "2026-02-05 06:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3okz5j",
              "author": "Free-Bear-454",
              "text": "Is it some kind of adhoc/local work or production one? I mean something with orchestrated pipelines, CICD, deployments, whatever...",
              "score": 1,
              "created_utc": "2026-02-05 08:00:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3p9sw3",
                  "author": "Acceptable-Sense4601",
                  "text": "It‚Äôs either me downloading CSV‚Äôs with the raw data or me extracting the data from the production database (the CSVs come from the same place but i only have the back end access to some of it at the moment). But the data goes into reports that are used by senior leadership.",
                  "score": 1,
                  "created_utc": "2026-02-05 11:49:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqlucd",
      "title": "Oops it's a Drakanian Product",
      "subreddit": "dataengineering",
      "url": "https://i.redd.it/v7l5msq2xcgg1.png",
      "author": "aleda145",
      "created_utc": "2026-01-29 21:35:12",
      "score": 55,
      "num_comments": 3,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qqlucd/oops_its_a_drakanian_product/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2lkbqt",
          "author": "Mooglekunom",
          "text": "Lol! Though think you need some more rows/combinations on the bottom one",
          "score": 2,
          "created_utc": "2026-01-30 13:25:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34t788",
          "author": "KritikaSharma_2000",
          "text": "Self Join: Keeping it simple üòÖ, Cross Self Join: Well, that's a whole other level! üôÉ",
          "score": 1,
          "created_utc": "2026-02-02 10:28:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ek120",
          "author": "Swagmaster5607",
          "text": "Loll",
          "score": 1,
          "created_utc": "2026-02-03 20:18:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr1ah1",
      "title": "Alternate careers from IT/Data ??",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qr1ah1/alternate_careers_from_itdata/",
      "author": "No_Song_4222",
      "created_utc": "2026-01-30 09:55:38",
      "score": 52,
      "num_comments": 22,
      "upvote_ratio": 0.88,
      "text": "Switched to data field \\~2yrs back ( had to do a masters degree) while I enjoy it I feel the time I spent in the industry isn't sufficient. There is so much more I could do would have wanted to do. Heck I have just been in one domain also.\n\nMy company lately have been asking us to prepare datasets to feed to agentic AI. While it answers the basics right it still fails at complex things which require deep domain and business knowledge.\n\nThere are several prompts injected and several key business indicators defined so the Agent performs good ( honestly if we add several more layers of prompt and chain few more agents it would get to answer come hard questions involving joining 6+ tables as well)\n\nSince it already answers some easy to medium questions based on your prompts the headcounts are just slashing. No I am good at what I do but I won't self proclaim as top 1%.  \nI have very strong skillset to figure things out if I don't know about it. A coworker of mine has been the company for 6 years and didn't even realize how to solve things which I could do it ( even though I had no idea in the first place as well) . I just guess this person has become way more comfy and isn't aware how wild things are outside.\n\nIs there anyone actively considering goose farming or something else out of this AI field ?\n\nThere is joy in browsing the internet without prompts and scrolling across website. There is joy in navigating UIs, drop downs and looking at the love they have put in. There is joy in minimizing the annoying chat pop that open ups at the website.\n\nAnd last thing I want to read is AI slop books by my fav authors.\n\nThere is reason why chess is still played by humans and journalist still put heart out in their writing. There will also be a reason human DE/DS/DA/AE would be present in future but maybe a lot less.\n\nWhat's the motivation to still pursue this field ? I love anything related to data to be honest and for me that is the only one. I love eat and breathe data even if I am jobless now because of AI first policy my company has taken.",
      "is_original_content": false,
      "link_flair_text": "Rant",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qr1ah1/alternate_careers_from_itdata/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2kvrao",
          "author": "MikeDoesEverything",
          "text": ">What's the motivation to still pursue this field ?\n\nAs somebody who went into this field from a different field, if you work in IT/programming, don't suck at it, and work for a decent company, GOOD LORD is it a sweet deal.\n\nLife as a chemist:\n\n* There is no such thing as remote work.  You are on-site 100% of the time.  I used to have to commute 1.5 hours one way if it was a quick journey.  Made me give up all of my hobbies post work.  Standard working day was around 12 hours (wake up at 6, get home at around 6).  Yeah, I could have moved closer but I'm glad I didn't because it meant I'd have moved to bum fuck nowhere for a job which ended my contract during the pandemic\n* Labs are often in shitty locations.  Good luck if you want to live near a city and have a reasonable commute time.  Didn't pack a lunch? Budget 20 minutes of your lunch time getting to and from somewhere to get something to eat\n* People think lab work is a refined art where people stand around in pristine labs and discuss how the universe works.  In reality, the labs are freezing cold in winter, swelteringly hot in summer, and poorly maintained.  Half of me isn't surprised because if there is an explosion/fire, it's not a huge amount of damage cost.\n* No windows can be quite common in buildings.  Somewhere I used to work, during winter there were days I'd see no natural light (get in before sun rise, sun sets at around 4 pm)\n* It's also a lot more physical than people give credit for.  Lifting large/heavy vessels into/out of your fume cupboard as well as transporting large quantities of materials isn't easy on your back as you get older\n* I worked in organic synthesis where if you don't have a PhD in chemistry, it's incredibly hard to not only break into the field but succeed because you're talking about the vast majority of people have a PhD, thus use it as a stick to beat you with (quite fairly, tbh).  I do not have a PhD and was usually the only person in the lab who didn't have a PhD\n* The work environment is a lot less forgiving than tech.  You can't google and hit the right answer easily.  You really have to know what you are asking the internet.  Even then, the answers are likely not widely published.  People are a lot smarter on average and a lot less willing to accept bullshit answers\n* Salaries are not remotely comparable although you do get a much better pension.  For reference, I used the chemical companies used to pretty much double your contributions.  I have never seen that figure in IT\n\nLife as a DE:\n\n* Work from home is an option.  If you have to turn up, at least your office is likely somewhere accessible and temperature controlled\n* A much lower barrier to entry.  The idea you \"need\" a Masters degree is, in my opinion, complete bollocks.  DE education requirements are not standardised across the industry whereas chemistry absolutely is.  It's not possible to get into chemistry without a chemistry degree, although you can definitely get into data without a CS degree\n* Difficulty isn't anywhere near as close.  If I ruin a reaction in the lab, good luck getting that shit back.  I guess it's like dropping a DB without a back up, although it's much easier to back something up than it is to make an extra X amount of material in case, I don't know, you drop your flask on the floor, somebody knocks it over etc.  You live in a world of glass so breakages are inevitable\n* General working is a lot easier.  Synthesis of a product can take a long time.  A long one is multiple days if not weeks.  You can turn something around quickly and have almost unlimited tries at it in DE\n* Stakes being lower means it's not as stressful although it does mean you get a lot more bozos because people are less careful.  The introduction of AI has massively exposed who is and isn't a fraud (anybody who struggles without AI or \"has to\" lie on their CV is absolutely a fraud)\n* Zero manual labour.  Much much lower chances of dying - I used to make novel pharmaceutical compounds which were definitely biologically active although since it has never been made or tested before (publicly), nobody has any idea how toxic the compound is.  So, it could either do nothing or murder you on the spot.  Fun fact: I once made something which was over 30 times more potent than fentanyl\n* Salaries are way higher on average.  After 2-3 years of being in DE, I earnt double what I did as my final salary as a chemist after around 10 years in the industry\n\nSo what I'm saying is life is relative.  If you have only ever worked in tech, then yeah, the grass will always seem greener.  As somebody coming in from the other way in, it's definitely greener within the IT industry.",
          "score": 41,
          "created_utc": "2026-01-30 10:29:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l5dbn",
              "author": "According_Layer6874",
              "text": "I went from medical science / histology lab work to analytics with 4 days from home and now transitioning into DE role after 3 years of analytics. \n\nI'm with you, I'm never going back.",
              "score": 14,
              "created_utc": "2026-01-30 11:48:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2vzpp5",
                  "author": "3n91n33r",
                  "text": "How did you get into your role? Did you complete a masters?",
                  "score": 1,
                  "created_utc": "2026-02-01 00:44:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ly9tl",
              "author": "reelznfeelz",
              "text": "Same.  Basic life sciences research to IT to remote independent contractor doing DE work.   Life now is 1000x better.  I make over $100/hr in my underwear lol.",
              "score": 3,
              "created_utc": "2026-01-30 14:37:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2vzr0f",
                  "author": "3n91n33r",
                  "text": "How did you get into your role? Did you complete a masters?",
                  "score": 1,
                  "created_utc": "2026-02-01 00:44:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2me93o",
              "author": "dontdoxxmebrosef",
              "text": "Shouted from RN to tech. Pry my ass outta this seat with a spatula.",
              "score": 3,
              "created_utc": "2026-01-30 15:52:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2n6d3e",
              "author": "AidosKynee",
              "text": ">Life as a chemist:\n>There is no such thing as remote work\n\nUnless you get into computational chemistry! It's still really challenging to find remote roles, but they do exist.\n\nWhen I did synthetic chemistry, it was always a way to have something novel for testing, but the data analysis is what I *enjoyed* doing. It was something of a revelation that people would pay me to just... analyze the data.",
              "score": 3,
              "created_utc": "2026-01-30 17:57:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2l7q99",
              "author": "magoo_37",
              "text": "This was an interesting read, thank you for sharing!",
              "score": 2,
              "created_utc": "2026-01-30 12:05:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2li0f7",
          "author": "oblectament",
          "text": "Ehhh. I mean, imo there's always going to be stuff ai can't do, at least without an informed human nudging it in the right direction and keeping an eye on the outputs at some point? And we don't even know what *new* data work is going to be opened up/made necessary by ai at this point either really. If you enjoy the work and you're good at figuring new stuff out I'd say there's no need to jump ship to full-time goose husbandry just yet, trust yourself and your abilities and keep following your nose about what's useful/interesting to learn and work on. Yeah a lot of the straightforward stuff can be handled by an agentic approach, but in my experience there's always going to be weird new stuff cropping up and that often needs a meat-based neural net aka a human to figure out üòú",
          "score": 15,
          "created_utc": "2026-01-30 13:12:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mad88",
          "author": "Brilliant-Gur9384",
          "text": "I can't give advice, but can tell you (shared this another sub) that my company is aiming to reduce ALL IT staff to me. Can they pull this off? Not sure, but that's their ye goal.\n\nThey think with a combination of AI tools I'll be ableto do everything that our staff does. Even I'm kinda like, \"Am I about to be irrelevant soon?\"\n\nSo, tell me about goose farming :)",
          "score": 5,
          "created_utc": "2026-01-30 15:34:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mr5h6",
          "author": "x1084",
          "text": ">There is joy in browsing the internet without prompts and scrolling across website. There is joy in navigating UIs, drop downs and looking at the love they have put in. There is joy in minimizing the annoying chat pop that open ups at the website.\n\nYou may not find it a perfect metaphor but I'm sure people preferred going to the library and checking out old newspapers and encyclopedias to do research even after the internet and Wikipedia came around too. \n\nI get that it's a huge paradigm shift, and a lot of our careers are in danger at the moment. But (imo) AI is proving to be the ultimate floor-raiser so we as engineers are only shooting ourselves in the foot by not trying to integrate it as best as possible into our toolkit. \n\nAI should help us with all of our lower level tasks (boilerplate code, cursory analysis, test case writing). All of the other tasks that come from experience (sniffing out bad code, identifying bad architecture, optimization) will grow to be even more valuable.",
          "score": 5,
          "created_utc": "2026-01-30 16:49:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2q4hrh",
          "author": "tbot888",
          "text": "I‚Äôm concerned about A.I. removing a lot of the joy from work but it also adds it as well.\n\nLike the data engineering field requires working with so many potentials tools because the market is so fragmented. ¬†It can be frustrating picking up something and trying to work out how to do what you want to do.\n\nSo in that scenario LLM AI is like a buddy that can point me where I want to go when I want too and it‚Äôs easy to work out if it‚Äôs offering poorly made up advice.\n\nNow for setting up agentic AI and improving it, I mean for me that‚Äôs all too early to see if making good agents is actually worthwhile.\n\nI do agree that A.I. is challenging the joy of work. ¬† Slop is a thing and it‚Äôs no good.",
          "score": 3,
          "created_utc": "2026-01-31 02:55:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2olmgo",
          "author": "West_Good_5961",
          "text": "I was an aircraft technician before this. Airline travel perks are amazing, I‚Äôm actually in first class writing this waiting to depart. I‚Äôm thinking of going back for similar reasons to you. Don‚Äôt feel like this job even produces anything meaningful most days.",
          "score": 2,
          "created_utc": "2026-01-30 21:52:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r1dfl",
          "author": "eccentric2488",
          "text": "I remember Bill Gates saying this somewhere 'AI is really doing a fantastic job but not as great as humans'",
          "score": 2,
          "created_utc": "2026-01-31 06:52:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2n96k0",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-30 18:10:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ng32f",
              "author": "dataengineering-ModTeam",
              "text": "Your post/comment was removed because it violated rule #6 (No recruiting, solicitation, or networking posts).\n\nWe do not intend for this space to be a place where people ask for, or advertise:\n\n* Job postings - Please use r/dataengineeringjobs instead.\n* Study groups\n* Referrals\n* Requests to fill in surveys\n* Market research\n\n ^*This* ^*was* ^*reviewed* ^*by* ^*a* ^*human*",
              "score": 1,
              "created_utc": "2026-01-30 18:40:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ndn03",
          "author": "kbisland",
          "text": "Remind me! 2 days",
          "score": 1,
          "created_utc": "2026-01-30 18:29:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ndrq2",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 2 days on [**2026-02-01 18:29:19 UTC**](http://www.wolframalpha.com/input/?i=2026-02-01%2018:29:19%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1qr1ah1/alternate_careers_from_itdata/o2ndn03/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1qr1ah1%2Falternate_careers_from_itdata%2Fo2ndn03%2F%5D%0A%0ARemindMe%21%202026-02-01%2018%3A29%3A19%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qr1ah1)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-30 18:29:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rcrge",
          "author": "Commercial-Fan-6453",
          "text": "Remind me! 2 days",
          "score": 1,
          "created_utc": "2026-01-31 08:36:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e3q1v",
          "author": "Certain_Leader9946",
          "text": "Farming",
          "score": 1,
          "created_utc": "2026-02-03 19:01:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qt95p7",
      "title": "First time data engineer contract- how do I successfully do a knowledge transfer quickly with a difficult client?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qt95p7/first_time_data_engineer_contract_how_do_i/",
      "author": "FiftyShadesOfBlack",
      "created_utc": "2026-02-01 20:06:16",
      "score": 46,
      "num_comments": 23,
      "upvote_ratio": 0.95,
      "text": "This is my first data engineering role after graduating and I'm expected to do a knowledge transfer starting on day one. The current engineer has only a week and a half left at the company and I observed some friction between him and his boss in our meeting.  For reference, he has no formal education in anything technical and was before this a police officer for a decade. He admitted himself that there isn't really any documentation for his pipelines and systems, \"it's easy to figure out when you look at the code.\" From what my boss has told me about this client their current pipeline is messy, not intuitive, and that there's no common gold layer that all teams are looking at (one of the company's teams makes their reports using the raw data). \n\nI'm concerned that he isn't going to make this very easy on me, and I've never had a professional industry role before, but jobs are hard to find right now and I need the experience. What steps should I take to make sure that I fully understand what's going on before this guy leaves the company? ",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qt95p7/first_time_data_engineer_contract_how_do_i/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3155wi",
          "author": "vikster1",
          "text": "record the session, have a lot of questions for him to answer before he leaves. document everything. do as much as you can while he is still there. it's a tough situation many of us have been in and there is no one right way to do it. try your best",
          "score": 39,
          "created_utc": "2026-02-01 20:15:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o315aod",
          "author": "Specific-Mechanic273",
          "text": "That's the reality in many companies.\n\nAs he said, look at the code, you'll figure it out. This is a great learning experience for you. It will be frustrating, but being able to tame messy code from other people without any help is a super valuable skill. \n\nHard times make you a great engineer, enjoy the struggle :)",
          "score": 15,
          "created_utc": "2026-02-01 20:15:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31632h",
          "author": "mr_thwibble",
          "text": "Ok, I'll go first.\n\nIf possible, take him for a coffee, establish a rapport before you get into the details.  Set him at ease away from any 'external influences'. \n\nGet the high-level starting points.  Servers.  Processes.  Credentials.  You can - yes, follow the code, but without knowing where the trail starts and what unlocks the gate you're a bit screwed.\n\nWelcome to the magical land of fuckery.  Hope you like reverse-engineering shit. üòÅ",
          "score": 21,
          "created_utc": "2026-02-01 20:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o317fxh",
              "author": "FiftyShadesOfBlack",
              "text": "Thanks for your reply! Unfortunately the role is remote and he's multiple states away, or else I definitely would establish a rapport to set him at ease. He was pretty abrasive in the meeting and defensive of his methods when I asked for clarification. When we meet (virtually) should I be leading the conversation with questions or is it typically on him to give me what he has? I don't want to break professional decorum or come across as trying to interrogate/belittle him.",
              "score": 5,
              "created_utc": "2026-02-01 20:26:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o31bnnr",
                  "author": "mr_thwibble",
                  "text": "Listen first.  Give space.  You need him a lot more than he needs you.  Spending a few mins up front to break down some barriers and show interest might just win you some social credit.\n\nUnless he clearly just can't be bothered and is irritated, in which case move right along and get to the point.\n\nEither way this is a baptism of fire in terns of 'reading the room'.  It won't be the last time you hVe to deal with something like this.  Trust me.",
                  "score": 8,
                  "created_utc": "2026-02-01 20:47:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o31cz7o",
                  "author": "mr_thwibble",
                  "text": "Sounds like he's tired of some shit.  Some of it might get flung at you initially, but keep your calm, polite, respectful.\n\nWho.  What.  Where.  When.  Why.  How.\n\nStart with that, maybe work in some questions about his background, get him to talk about himself.  Loosen him up a bit.  Difficult for sure.",
                  "score": 6,
                  "created_utc": "2026-02-01 20:53:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o31uexv",
                  "author": "VipeholmsCola",
                  "text": "He built the thing so let him explain it, its his baby. Give some compliments wherever, sound interested. With a little luck he will enjoy talking about his build.\n\nmost people like to talk about themselves and their acomplishments, abuse that in this situation...",
                  "score": 4,
                  "created_utc": "2026-02-01 22:18:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o351d60",
                  "author": "remainderrejoinder",
                  "text": ">defensive of his methods when I asked for clarification.\n\nIt may help to level set. Point out that he built these up from nothing with limited time and resources. Make sure he knows you're not going to sit there and bad-mouth him when he's gone because you'll be in the same situation someday.\n\nIgnore things that are part of his learning process--you're not there to teach him what you learned in school.",
                  "score": 2,
                  "created_utc": "2026-02-02 11:40:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33csoj",
          "author": "Mamertine",
          "text": "I'm going to go in a very different direction.¬†\n\n\nYour being set up to fail. They needed to hire an experienced engineer.\n\n\nThis is your first job out of college. You should be working at a shop where a senior person can explain things to you. Both how the code works and data engineer concepts.¬†\n\n\nGo ahead and do your best, but I'd really recommend you keep looking for a different job.",
          "score": 9,
          "created_utc": "2026-02-02 03:20:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dhsvt",
              "author": "taker223",
              "text": "I second that.\n\n\\> Already experienced engineer (with proven built and working solutions) leaves in a hurry, clearly he would NOT give a f\\*ck about newbie OP and even OP has spotted some \"friction\" between leaving engineer and his boss.\n\n\\> a fresh graduate is hired (for likely a fraction of leaving engineer's salary. Jackpot if he would be on probation/intern)  \n\\> the role is remote and he's multiple states away. Bzzzzt sorry can;t hear you Nelson. Make a jesture if you can hear me! (c) Gavin Belson\n\n\\> nothing really is documented. Means leaving engineer leaves with his institutional knowledge\n\nAs I wrote, \"The best is yet to come...\" (c) Scorpions",
              "score": 1,
              "created_utc": "2026-02-03 17:22:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31rhhb",
          "author": "MonochromeDinosaur",
          "text": "Start getting used to situations like this. Isn‚Äôt the first or last time it‚Äôll happen. \n\nDocument everything, if you have it available record sessions, AI transcripts, take copious notes. If allowed use AI and/or ripgrep to figure out the code.\n\nThe more information you have the better.",
          "score": 4,
          "created_utc": "2026-02-01 22:04:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31gred",
          "author": "chrisgarzon19",
          "text": "Loom record\nDocument \nSend\nIf they have questions questions \nHop on 15 minute call\nUpdate the doc while explaining anything AND record that session as well)",
          "score": 2,
          "created_utc": "2026-02-01 21:12:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o323bq9",
          "author": "adastra1930",
          "text": "Definitely record the meeting for reference later, there will always be stuff you won‚Äôt understand until you‚Äôre stuck into it. Also, in this case where the former person had some friction, please feel confident that if you deviate from their method and create your own approach, that might actually be good for you and your reputation with this new (to you) stakeholder ‚ò∫Ô∏è",
          "score": 2,
          "created_utc": "2026-02-01 23:04:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32mk69",
          "author": "BaddDog07",
          "text": "Focus on what to do if it breaks while he is still there and then figure out the rest later",
          "score": 1,
          "created_utc": "2026-02-02 00:50:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37wton",
          "author": "llamacoded",
          "text": "Honestly, this is a tough spot for your first role. 1.5 weeks with a guy like that is brutal. Don't even try to understand every line of code; you'll burn out.  \n  \nGet him to talk through the \\*critical data paths\\*. Which tables are consumed by the most important downstream systems? Ask:  \n1. What are the inputs for X pipeline? Where do they come from?  \n2. What are the expected outputs? Who uses them?  \n3. How do you know when it breaks? What's the runbook for common failures?  \n  \nDraw diagrams as he talks; even rough ones. Focus on the data contracts. Who relies on this data, and what format do they expect? Don't leave without clear answers on failure modes; that's what'll bite you in production. You'll figure out the \"how\" later.",
          "score": 1,
          "created_utc": "2026-02-02 20:29:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3diide",
              "author": "taker223",
              "text": "What if leaving engineer would simplify all your questions in a general GTFO graph, with arrows and nodes.",
              "score": 1,
              "created_utc": "2026-02-03 17:25:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bjzvm",
          "author": "TitanTheSpidermonkey",
          "text": "Feels like something you can ask Claude. Just audit this codebase and give me an entry point.",
          "score": 1,
          "created_utc": "2026-02-03 10:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dhxs1",
              "author": "taker223",
              "text": "Sure, do some vibes! Better directly on customer production. Real Hands-On approach",
              "score": 1,
              "created_utc": "2026-02-03 17:23:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3jeq89",
                  "author": "TitanTheSpidermonkey",
                  "text": "I meeaaannn!!! lololol\n\nBut I think auditing is ok no? seems inconsequential to me...",
                  "score": 1,
                  "created_utc": "2026-02-04 14:53:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dg0ez",
          "author": "taker223",
          "text": "\\> The current engineer has only a week and a half left at the company and \n\n\\> I observed some friction between him and his boss in our meeting.\n\n\\> This is my first data engineering role after graduating and I'm expected to do a knowledge transfer starting on day one\n\nMakes perfect alignment. \"The best is yet to come...\" (c) Scorpions",
          "score": 1,
          "created_utc": "2026-02-03 17:14:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvoj0i",
      "title": "Financial engineering at its finest",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qvoj0i/financial_engineering_at_its_finest/",
      "author": "SignalMine594",
      "created_utc": "2026-02-04 13:27:12",
      "score": 41,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "I‚Äôve been spending time lately looking into how big tech companies use specific phrasing to mask (or highlight) their updates, especially with all the chip investment deals going on. \n\nEarlier this week, I was going through the Microsoft earnings call transcript and (based on what seems like shared sentiment in the market), I was curious how Fabric was represented. From my armchair analyst position, its adoption just doesn‚Äôt seem to line up with what I assumed would exist by now...\n\nOn the recent FY26 Q2 call, Satya said:\n\n>Two years since it became broadly available, Fabric's annual revenue run rate is now over $2 billion with over 31,000 customers... revenue up 60% year over year.\n\nThe first thing that made me skeptical is the type of metrics used for Fabric. ‚ÄúAnnual revenue run rate‚Äù is NOT the same as ‚Äúwe actually generated $2B over the last 12 months.‚Äù This is super normal when startups report earnings, since if a product is growing, run rate can look great even when realized trailing revenue is still catching up. Microsoft chose run rate wording here.\n\nThen I looked at the previous earnings where Fabric was discussed. In FY25 Q3, they said Fabric had 21k paid customers and ‚Äú40% using Real-Time Intelligence‚Äù five months after GA, but ‚Äúusing‚Äù isn‚Äôt defined in a way that‚Äôs tangible, which usually is telling. In last week‚Äôs earnings, Satya immediately discusses specific metrics, customer references, etc. for other products.\n\nA huge part of why I‚Äôm also not convinced on adoption is because of the forced Power BI capacity migration. I know the world is all about financial engineering, and since Microsoft forced us all to migrate off of P-SKUs, it‚Äôs not hard to advertise those numbers as great. The conspiracist in me says the numbers line up a little too neatly with the SKU migration:\n\n* $2B in revenue run rate / 31,000 customers ‚âà $64.5k per customer per year.¬†\n* That‚Äôs conveniently right around the published price of an F64 reservation\n\nObviously an average is oversimplifying it, and I don‚Äôt think Microsoft is lying about the metrics whatsoever, but I do think the phrasing doesn‚Äôt line up with the marketing and what my account team says‚Ä¶\n\nThe other thing I saw was how Microsoft talks when they have deeper adoption. They normally use harder metrics like customers >$1M, big deployments, customer references, etc. In the same FY26 Q2 transcript, Fabric gets the run-rate/customer count and then the conversation moves on. And that‚Äôs it. After that, I was surprised that Fabric was never mentioned on its own again, nor expanded upon, and outside of that sentence, Fabric was always mentioned with Foundry.\n\nEarnings reports aren't everything, and 31,000 customers is a lot, so I went looking for proof in customer stories, and the majority of the stories are just implementation partners and consultancies whose practices depend on selling Fabric (Boutiques/Avanade types), not a flood of end-customer production migrations with scale numbers. (There are are a couple of enterprise stories like LSEG and Microsoft‚Äôs internal team, but it doesn‚Äôt feel like ‚Äúno shortage.‚Äù)\n\nPlease check me. Am I off base here? Or is the growth just because of the forced migration from Power BI?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qvoj0i/financial_engineering_at_its_finest/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3lbqv3",
          "author": "engineer_of-sorts",
          "text": "It's literally power bi\n\n  \nthe idea there are $2bn of data engineering workloads running on fabric cannot be true",
          "score": 8,
          "created_utc": "2026-02-04 20:13:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j8wly",
          "author": "Kobosil",
          "text": ">forced migration\n\nah the Microsoft way",
          "score": 16,
          "created_utc": "2026-02-04 14:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j30gf",
          "author": "Nofarcastplz",
          "text": "It would definitely validate what I read here on this subreddit",
          "score": 9,
          "created_utc": "2026-02-04 13:52:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nbkzp",
              "author": "EversonElias",
              "text": "People here just want to hate Fabric. I got downvoted hard because I said I like it.",
              "score": 0,
              "created_utc": "2026-02-05 02:31:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1quddio",
      "title": "What are people transitioning to if they can't find a job?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1quddio/what_are_people_transitioning_to_if_they_cant/",
      "author": "SoggyGrayDuck",
      "created_utc": "2026-02-03 00:48:42",
      "score": 41,
      "num_comments": 52,
      "upvote_ratio": 0.82,
      "text": "I have some time but I'm preparing myself for what will probably be the inevitable in this market. Im using outdated technology and in this market I keep seeing that classes or certs won't help. I've heard some say they changed directions and I'm curious what people are finding? \n\nI know we can transition to ML but I'm assuming that needs a math background. AI is an option but then you're competing with new grads (do we even stand a chance? Does our background experience help?). I'm asking for more general answers but my background issue is essentially being a jr-mid level at 3-4 different positions, all at smaller companies and more of a startup environment. Platform/cloud (AWS) engineering, bi developer, data engineer and architect. I would be EXTREMELY valuable if this background was at larger companies. \n\nFrom what I can see this isn't valuable unless you're senior/staff or a cloud architect level. They don't bring in jr/mid level and train them, at least not right now. ",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1quddio/what_are_people_transitioning_to_if_they_cant/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o39bubs",
          "author": "AutoModerator",
          "text": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-03 00:48:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39o739",
          "author": "chrisgarzon19",
          "text": "Become a senior BIE \nOr DE \nYou can still very much get data roles\n\nYou‚Äôre just gonna have to apply 10x more than what you thought you would",
          "score": 44,
          "created_utc": "2026-02-03 01:59:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b8oed",
              "author": "SoggyGrayDuck",
              "text": "With my outdated environment I need to learn Python as well. I'm not scared of it and have used it plenty but just not in production and definitely not senior de level.",
              "score": 5,
              "created_utc": "2026-02-03 08:53:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3e17px",
                  "author": "Thinker_Assignment",
                  "text": "If you get discouraged keep in mind the 20 hour rule (look it up for an inspiring video) - says you can get basic at anything if you just put in the time",
                  "score": 5,
                  "created_utc": "2026-02-03 18:50:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bmf85",
          "author": "Schwartz210",
          "text": "If DE is the career you want then you need to fight for it. Apply, apply, apply! Fix your resume if you can't get an interview. Fix your interview skills if you can't convert interviews to offers. Always upskill. Stay persistent and pound the pavement. I graduated during the Financial Crisis with a totally different background. Bad markets happen, but this is a high demand profession. If you can't land roles with decent experience then don't expect to walk into another profession and score jobs. If DE is what you want then you need to plant your flag.",
          "score": 15,
          "created_utc": "2026-02-03 11:04:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e1gbj",
              "author": "Outside_Reason6707",
              "text": "Can I dm you? I‚Äôm in interview process and unable to convert",
              "score": 2,
              "created_utc": "2026-02-03 18:51:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3e7qi3",
                  "author": "Schwartz210",
                  "text": "Sure",
                  "score": 1,
                  "created_utc": "2026-02-03 19:20:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3qle4p",
              "author": "shimell",
              "text": "Hi Can I dm you. I am too in interview process but unable to convert.",
              "score": 1,
              "created_utc": "2026-02-05 16:15:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ax470",
          "author": "susosexy",
          "text": "IMO if you were to transition to ML/AI engineering, you would be fighting another steeper and longer uphill battle. In your current situation you are already climbing a hill, but atleast you're on your way up. It would make more sense to build out your skills in DE and grow from there.",
          "score": 10,
          "created_utc": "2026-02-03 07:05:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c0wpg",
              "author": "SoggyGrayDuck",
              "text": "Thanks, the gatekeepers in these subs out there telling people it's pointless to upskill and you'll never get the skills you actually need doing so are just making the situation worse. I just don't want to dump months and thousands only to be pushed out anyway. I am in the rare situation I could go back to grad school but damn, that's something I haven't thought about in 7+ years and don't even know if that would help. It's such an uphill battle to get your brain back to education mode. I'm getting there but it's been a battle. I need more hands on",
              "score": 1,
              "created_utc": "2026-02-03 12:54:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3hfnuf",
                  "author": "susosexy",
                  "text": "If it was pointless to upskill then there would be no reason to learn and get better at anything. Truth be told, most engineers are probably in situations where their environment and tech stack hinders them from learning, so the best way is often to learn yourself. Whether you should pursue further studies is another question on its own, but if you have genuine interest and are certain it can help you, then go for it.",
                  "score": 2,
                  "created_utc": "2026-02-04 05:54:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c6hf9",
          "author": "Odd-Government8896",
          "text": "Dude what's your outdated tech your so worried about? Access?\n\nI use Databricks everyday, and its still just SQL, with Python for the complicated or production bits.\n\nIf you know how to use pandas, you're going to be fine.\n\nDon't let these guys fool you with their whacky stacks. Get yourself a spark docker image, maybe with dbt, or a free databricks account and just start messing with it.",
          "score": 8,
          "created_utc": "2026-02-03 13:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c9wlp",
              "author": "Spunelli",
              "text": "This is what I keep saying but employers are NOT entertaining anyone without the direct experience in databricks.",
              "score": 3,
              "created_utc": "2026-02-03 13:47:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3cnard",
                  "author": "SoggyGrayDuck",
                  "text": "This is what im finding as well. Why teach someone the interface if you don't need to. My recruiter advised learning snowflake first but I see databricks come up a LOT in requirements. This market happened at the absolute worst time for me. I kept reaching and getting positions in was slightly under qualified for (because you could and they'd let you learn) and now feel like I'm a jr-mid level in several areas. I literally had consultants trying to recruit me, telling me I think like a CIO and to continue the path of learning everything vs going deeper into a particular topic and now I'm looking at getting pushed out of the industry. I needed just one more job to tie everything together and we ended up getting offshored vs getting any kind of training.",
                  "score": 2,
                  "created_utc": "2026-02-03 14:58:31",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o3csqxa",
                  "author": "MakeoutPoint",
                  "text": "I did mine on company time as \"research into potential new system to solve issues\". Built my own little setup, got familiar using company data, and boom there's your direct experience and it's not even a lie.\n\n\nThey won't be calling your employer, and if they did it would just be to verify employment, not to ask about the tech stack.",
                  "score": 2,
                  "created_utc": "2026-02-03 15:25:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3dqssr",
                  "author": "Odd-Government8896",
                  "text": "Very unfortunate. The whole point to databricks is that anyone can build hyper scaled analytics platforms without worrying about something like pyarrow. Hell, serverless makes it even more brain dead.",
                  "score": 1,
                  "created_utc": "2026-02-03 18:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cxfcy",
          "author": "thethirdmancane",
          "text": "Unemployed senior data engineer here. Over 10 years of experience building data pipelines in Python SQL, and golang. I applied for over 200 jobs. Got plenty of interviews but no takers. I finally got a non-paying gig building data pipelines for non-profits as a volunteer. I love data engineering so much I just can't give it up. So now I just do it for free.",
          "score": 5,
          "created_utc": "2026-02-03 15:47:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3midu5",
              "author": "CaptainDawah",
              "text": "200 roles within what time frame? That seems a bit low",
              "score": 1,
              "created_utc": "2026-02-04 23:46:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o39m8n7",
          "author": "shittyfuckdick",
          "text": "Trying to figure this out as well. I have 8 years. experience with most the popular DE tools and still cant land a job anywhere.¬†",
          "score": 12,
          "created_utc": "2026-02-03 01:48:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3a2fgb",
              "author": "mistanervous",
              "text": "In what country are you located/looking? Just curious",
              "score": 4,
              "created_utc": "2026-02-03 03:20:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3a55c1",
                  "author": "thelewdfolderisvazio",
                  "text": "Yeah me too, seems quite odd...",
                  "score": 2,
                  "created_utc": "2026-02-03 03:37:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3c74j2",
                  "author": "shittyfuckdick",
                  "text": "In the US",
                  "score": 1,
                  "created_utc": "2026-02-03 13:31:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3blsxx",
          "author": "Raddzad",
          "text": "If you have experience, I would say even as a mid it's hard not to find a job in this market, even if you have to wait a little bit. DEs are literally the gold for the AI hype",
          "score": 3,
          "created_utc": "2026-02-03 10:59:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39mz7s",
          "author": "KBaggins900",
          "text": "I have been wanting a data engineering job but unfortunately I‚Äôm stuck in .net dev at the moment.",
          "score": 5,
          "created_utc": "2026-02-03 01:52:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b7ujl",
          "author": "techjobmentor",
          "text": "sometimes overlooked, but, given your data expertise, you have already learned a lot of insights into the business, so switching to a technical project manager role is an option I've seen some peers succeed at, better paid even",
          "score": 3,
          "created_utc": "2026-02-03 08:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3axjyl",
          "author": "Thinker_Assignment",
          "text": "As a senior DE with a pinch of AI, you're the GOAT in this market",
          "score": 3,
          "created_utc": "2026-02-03 07:09:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c2jrt",
              "author": "SoggyGrayDuck",
              "text": "Like the other person asked, what should I be looking at for upskilling? \n\nI agree that this best aligns with my background. I think about the big picture but my dev skills are weak. Id be the AI dev that knows what I want each piece to do and build them out independently. \n\nI also feel like I need a slightly better understanding of the new cloud architecture. I'm slowly coming to the realization that the answer is \"whatever agile demands\" but that CAN'T be right. It might be what happens but I want to know what's ideal so I can keep it as close to standard as possible. Any good links on modern data structures? Ideally it would use older architecture as an example/reference. Ie source data --> star schema --> data cube --> kpi",
              "score": 2,
              "created_utc": "2026-02-03 13:04:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ck7vs",
                  "author": "Thinker_Assignment",
                  "text": "Honestly from my experiments coding is going away - in the sense that machines will do it.  \nSo what I would do is learn the architecture and understand capabilities so you can design these systems and get a feel for what might work, how to do it.\n\n\\- understand architecture basics - fuck all the old stuff, it's not valid anymore, nobody has 5 years to debate a perfect canonical model or enteprise model nowadays. you want to understand:  Path a: Data vault, canonical data model, and denormalisation of it into snowflake->star->obt schemas. Path b: activity schema (radically different model). On canonical or its denorms, see semantic layers for chat-bi\n\n\\- understand AI basics  \n\\- rags, eval, agent skills, mcp, knoweldge graph (basically unstructured data modeling)  \n\\- multimodal data (audio video)\n\ni will write more about it on our blog as it's an interesting topic for me to push what can be done and see what's left.",
                  "score": 4,
                  "created_utc": "2026-02-03 14:42:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3b33s2",
              "author": "MightyFinch",
              "text": "What kind of AI stuff do you know in relation to DE that is helping you ?",
              "score": 1,
              "created_utc": "2026-02-03 08:00:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3c6vc3",
                  "author": "Odd-Government8896",
                  "text": "ai_query()\n\n... Seriously lol.. Google it",
                  "score": 2,
                  "created_utc": "2026-02-03 13:30:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3exfu2",
          "author": "ironmagnesiumzinc",
          "text": "Has it always been this hard to find a DE (or equivalent) job?",
          "score": 1,
          "created_utc": "2026-02-03 21:20:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eyqll",
              "author": "SoggyGrayDuck",
              "text": "Nope, people had 2-3 remote positions for a bit during/after COVID. It was back when the leaders/business side was responsible for requirements and etc. They've pushed all of that down onto the engineers. For several reasons it means they can't really use jr/mid level devs.",
              "score": 5,
              "created_utc": "2026-02-03 21:26:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qu47hc",
      "title": "When Your Career Doesn‚Äôt Go as Planned",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1qu47hc/when_your_career_doesnt_go_as_planned/",
      "author": "krmehul-tech-7564",
      "created_utc": "2026-02-02 19:02:33",
      "score": 35,
      "num_comments": 20,
      "upvote_ratio": 0.89,
      "text": "Sometimes in life, what you plan doesn‚Äôt work out.\n\nI prepared for a Data Engineer role since college. I got selected on campus at Capgemini, but after joining, I was placed into the SAP ecosystem. When I asked for a domain change, I was told it‚Äôs not possible.\n\nNow I‚Äôm studying on my own and applying daily for Data Engineer roles on LinkedIn and Naukri, but I‚Äôm not getting any responses.\n\nIt feels like no matter how much we try, our path is already written somewhere else. Still trying. Still learning.",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/dataengineering/comments/1qu47hc/when_your_career_doesnt_go_as_planned/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o37joqj",
          "author": "ironwaffle452",
          "text": "I never wanted to be data engineer but i give up LOL now almost 8yo, i never had the opportunity to choose the job",
          "score": 28,
          "created_utc": "2026-02-02 19:27:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37l7eq",
              "author": "krmehul-tech-7564",
              "text": "Everyone‚Äôs journey is different. I didn‚Äôt get many chances to choose early, so now I‚Äôm shaping my path step by step. Learning and adapting is my only option.I don't know what will happen in future....",
              "score": 5,
              "created_utc": "2026-02-02 19:34:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37ubm2",
                  "author": "SalamanderMan95",
                  "text": "If you‚Äôre not a data engineer by 7 you might as well give up, everyone knows that once you hit 12 you start getting aged out. But seriously, it‚Äôs a marathon not a sprint",
                  "score": 5,
                  "created_utc": "2026-02-02 20:17:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37keah",
          "author": "ratczar",
          "text": "Be the best prisoner you can be: [Learning to Measure Time in Love and Loss - The New York Times](https://www.nytimes.com/2024/10/18/style/modern-love-classic-learning-to-measure-time-in-love-and-loss.html)",
          "score": 9,
          "created_utc": "2026-02-02 19:31:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3all34",
          "author": "MPGaming9000",
          "text": "I feel the same way. I got lumped into Support Engineering roles due to my customer service background and I'm finding it hard to break out. People say 'just work on projects' as if it actually fucking makes a difference. Nobody actually gives a shit about your projects no matter how impressive they are because it doesn't count as 'real experience' to actual hiring managers in this job market. Just sucks man. Not sure what else to really do at this point.",
          "score": 9,
          "created_utc": "2026-02-03 05:29:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3aqal7",
              "author": "krmehul-tech-7564",
              "text": "Yeah man, what else can we do. Just keep trying skill up, apply as much as possible, and hope something works out. That‚Äôs what I‚Äôm doing too, along with a few certifications.",
              "score": 1,
              "created_utc": "2026-02-03 06:06:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3apmg0",
              "author": "Sensitive-Sugar-3894",
              "text": "In this case, automate all you can. Even minor validations. Then ask AI for a way to sell it in your LinkedIn.",
              "score": -4,
              "created_utc": "2026-02-03 06:01:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fnkt6",
          "author": "TheOverzealousEngie",
          "text": "to be clear, data engineering is one of the most turbulent careers you could choose. Except for the part about SAP. I do believe that sap will find a way to survive even when the world ends.",
          "score": 5,
          "created_utc": "2026-02-03 23:29:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gbro9",
              "author": "lmottads",
              "text": "I'm with you. It could be a lot worse. SAP is solid as hell. Of course, it is frustrating not being able to set your path. But you can actually run some local DE projects on your own and learn by yourself. You could hardly do that with SAP, and it is a good skill to have.",
              "score": 2,
              "created_utc": "2026-02-04 01:43:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jwo6n",
          "author": "Awkward_Tick0",
          "text": "Dude it sounds like you‚Äôre just starting. Why the sob story",
          "score": 2,
          "created_utc": "2026-02-04 16:18:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jywi3",
          "author": "dessmond",
          "text": "OP, I feel you. SAP is a horrible beast. It‚Äôs so complex and so huge nobody wants to touch that shit. Hence, a lot of money can be made, though.",
          "score": 2,
          "created_utc": "2026-02-04 16:28:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o8c99",
              "author": "Economy_Passenger_93",
              "text": "What is SAP",
              "score": 1,
              "created_utc": "2026-02-05 06:07:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3axqun",
          "author": "Thinker_Assignment",
          "text": "Get into any technical role closer to data and move from there",
          "score": 1,
          "created_utc": "2026-02-03 07:10:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ay17y",
              "author": "krmehul-tech-7564",
              "text": "Thanks üëç",
              "score": 1,
              "created_utc": "2026-02-03 07:13:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1quxzvb",
      "title": "Are Python UDFs in Spark still less efficient than UDFs written in Scala or Java?",
      "subreddit": "dataengineering",
      "url": "https://www.reddit.com/r/dataengineering/comments/1quxzvb/are_python_udfs_in_spark_still_less_efficient/",
      "author": "Lastrevio",
      "created_utc": "2026-02-03 17:20:05",
      "score": 30,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "I'm reading \"Spark: The Definitive\" guide and there's a part about how user defined functions in Python can be inefficient. This is the quote: \n\n\"When you use the function, there are essentially two different things that occur. If the function is written in Scala or Java, you can use it within the Java Virtual Machine (JVM). This means that there will be little performance penalty aside from the fact that you can‚Äôt take advantage of code generation capabilities that Spark has for builtin functions. There can be performance issues if you create or use a lot of objects; we cover that in the section on optimization in Chapter 19. \n\nIf the function is written in Python, something quite different happens. Spark starts a Python process on the worker, serializes all of the data to a format that Python can understand (remember, it was in the JVM earlier), executes the function row by row on that data in the Python process, and then finally returns the results of the row operations to the JVM and Spark.\n\nStarting this Python process is expensive, but the real cost is in serializing the data to Python. This is costly for two reasons: it is an expensive computation, but also, after the data enters Python, Spark cannot manage the memory of the worker. This means that you could potentially cause a worker to fail if it becomes resource constrained (because both the JVM and Python are competing for memory on the same machine). We recommend that you write your UDFs in Scala or Java‚Äîthe small amount of time it should take you to write the function in Scala will always yield significant speed ups, and on top of that, you can still use the function from Python!\" \n\nI heard from Reddit that this book was written a long time ago and some things may be outdated. Is this still relevant with the latest versions of Spark? Are Python UDFs still significantly slower than Scala/Java UDFs in Spark? If yes, have you ever encountered a situation at work where someone actually wrote a UDF in Scala or Java and avoided using Python for the sake of performance increases?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/dataengineering/comments/1quxzvb/are_python_udfs_in_spark_still_less_efficient/",
      "domain": "self.dataengineering",
      "is_self": true,
      "comments": [
        {
          "id": "o3dh9e8",
          "author": "AutoModerator",
          "text": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-03 17:20:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3djxys",
          "author": "bacondota",
          "text": "The principle still applies. Spark will serialize the data and transfer to python process. If you run out of memory, you get no error, your task will hang indefinitely until you kill it. Had this problem on spark 3.5, but it should apply even to the newest version.\n\nYou can alter your session to have a bigger memory overhead. Look what each memory options on spark does. There is an option to increase the memory the JVM uses, and one that increases the memory outside the JVM (which the python process will consume)",
          "score": 29,
          "created_utc": "2026-02-03 17:32:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dy4hb",
          "author": "WinstonCaeser",
          "text": "You can write python arrow udfs which are much more efficient",
          "score": 25,
          "created_utc": "2026-02-03 18:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3h5vwi",
              "author": "iamnotapundit",
              "text": "I second this. I did a Scala UDF vs a Python UDTF. The Python actually won the speed test. But only UDTFs.",
              "score": 4,
              "created_utc": "2026-02-04 04:43:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3dktc2",
          "author": "Sufficient_Example30",
          "text": "In my experience this rarely is a problem you will encounter.\nBut if you do writing it in spark scala is a band aid to a problem that you are kicking down the road.",
          "score": 10,
          "created_utc": "2026-02-03 17:36:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gx2x6",
          "author": "robberviet",
          "text": "Always. Avoid UDF if you can. However, if you must, it's fine to a degree. Not many people actually need optimization.",
          "score": 5,
          "created_utc": "2026-02-04 03:46:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l8fq4",
          "author": "aes110",
          "text": "Yes, though less than they used to be.  \nNative functions (the built in spark sql) functions are the best because of their inner optimizations, vectorization, and being able to be optimized by the planner\n\nWhen it comes to python vs java\\scala udfs, python is still the slowest since well, python is just slower, but most of the overhead that used to be a thing like serialization is less of an issue now with the usage of Arrow udfs \n\nBasically try to keep to native functions, but python udfs arent that much of a taboo as older guides might suggest. And unless it's some special performance issue, i wouldn't introduce scala\\java udfs to a pyspark project",
          "score": 2,
          "created_utc": "2026-02-04 19:57:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mi5kl",
              "author": "Mclovine_aus",
              "text": "Are arrow udfs better because it solves serialisation problems or because it has more parallelisation through vectorisation?",
              "score": 1,
              "created_utc": "2026-02-04 23:45:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3mvhgb",
                  "author": "aes110",
                  "text": "Well there are two different definitions, regular python UDFs can now be optimized by arrow (useArrow=True), which solves the serialization issue.\n\nApart from that, you have two other types of UDFs that also help with \"parallelisation through vectorisation\". Either Pandas UDFs that get a pandas series and can use the built in pandas stuff, or \"Arrow UDFs\" that get an array and return an array, so they can use other vectorized stuff too\n\nusing these, most of the logic really is usually in C, so the perf diff from java/scala is much smaller\nhttps://spark.apache.org/docs/latest/api/python/user_guide/udfandudtf.html#Arrow-optimization",
                  "score": 1,
                  "created_utc": "2026-02-05 00:58:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3gv45f",
          "author": "Ok-Bee-5814",
          "text": "Shouldn‚Äôt have this problem",
          "score": 1,
          "created_utc": "2026-02-04 03:34:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kj2gl",
          "author": "22Maxx",
          "text": "Have you considered using Ray for expensive UDFs?",
          "score": 0,
          "created_utc": "2026-02-04 18:01:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}