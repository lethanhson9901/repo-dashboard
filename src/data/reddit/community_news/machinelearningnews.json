{
  "metadata": {
    "last_updated": "2026-03-02 02:56:22",
    "time_filter": "week",
    "subreddit": "machinelearningnews",
    "total_items": 19,
    "total_comments": 26,
    "file_size_bytes": 44219
  },
  "items": [
    {
      "id": "1rge183",
      "title": "Sakana AI Introduces Doc-to-LoRA and Text-to-LoRA: Hypernetworks that Instantly Internalize Long Contexts and Adapt LLMs via Zero-Shot Natural Language",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/27/sakana-ai-introduces-doc-to-lora-and-text-to-lora-hypernetworks-that-instantly-internalize-long-contexts-and-adapt-llms-via-zero-shot-natural-language/",
      "author": "ai-lover",
      "created_utc": "2026-02-27 18:03:30",
      "score": 44,
      "num_comments": 6,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rge183/sakana_ai_introduces_doctolora_and_texttolora/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7xhrsj",
          "author": "radarsat1",
          "text": "This is incredible, seems like a game changer for certain applications. Imagine just pre ingesting an entire codebase before running a bunch of different prompts from an agent.",
          "score": 3,
          "created_utc": "2026-02-28 19:34:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7yvc1z",
              "author": "DataHogWrangler",
              "text": "Literally was my first thought, next one large contracts with architectural diagrams and such (sometimes 1gb + PDF files)",
              "score": 1,
              "created_utc": "2026-03-01 00:07:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7tcb6o",
          "author": "DataHogWrangler",
          "text": "Super interesting, does this work with all models?",
          "score": 2,
          "created_utc": "2026-02-28 02:43:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ykt21",
          "author": "SuccessIsHardWork",
          "text": "Amazing stuff",
          "score": 1,
          "created_utc": "2026-02-28 23:05:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o815aso",
          "author": "GrapefruitMammoth626",
          "text": "Sakana really do interesting:meaningful research!\nThere was good interview with one of their researchers/co founders? I listened to a few months ago and it was actually enlightening. No product crap, just well formed insights and ideas regarding research directions, paradigms.",
          "score": 1,
          "created_utc": "2026-03-01 10:20:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rhlebl",
      "title": "84.0% on ARC-AGI2 (840/1000) using LLM program synthesis + deterministic verification â€” no fine-tuning, no neural search",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/gallery/1rhlebl",
      "author": "Other_Train9419",
      "created_utc": "2026-03-01 02:28:57",
      "score": 27,
      "num_comments": 8,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rhlebl/840_on_arcagi2_8401000_using_llm_program/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7zmoc3",
          "author": "TomLucidor",
          "text": "As a heads up please update the repo description for ARC-AGI-2, since HLE is also mentioned (but suspect that \"LLM-free\" feels like clickbait) [https://github.com/Ag3497120/verantyx-v6](https://github.com/Ag3497120/verantyx-v6)",
          "score": 3,
          "created_utc": "2026-03-01 02:52:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7zokid",
              "author": "Other_Train9419",
              "text": "Thanks for the heads up,Â u/TomLucidor! I really appreciate a developer of your caliber taking the time to look through my repo.\n\nYou're absolutely right about the description. I started Verantyx as a pure symbolic (LLM-free) project, but the jump to 84.0% was indeed achieved through a hybrid approach with Claude 4.5 Sonnet. Iâ€™ve just updated the repo description and README to reflect this clearly and avoid any 'clickbait' feel.\n\nI also cleaned up the HLE references to keep the focus on ARC-AGI-2. Thanks again for the sharp eye and the feedbackâ€”it helps a lot as I prepare for the Kaggle run!",
              "score": 0,
              "created_utc": "2026-03-01 03:04:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o80be9o",
          "author": "FirstOrderCat",
          "text": "\\> **Generalization gap**: On the evaluation set, the generalization rate is \\~42%\n\non leaderboad, vanilla Opus achieves 68%.. [https://arcprize.org/leaderboard](https://arcprize.org/leaderboard)",
          "score": 2,
          "created_utc": "2026-03-01 05:45:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o80ewz7",
              "author": "Other_Train9419",
              "text": "That is a very sharp observation, but I believe we are comparing two fundamentally different \"game rules\" here. I appreciate the chance to clarify why theÂ **Generalization Gap**Â might look wider than it actually is.\n\nHere is the breakdown of why the Verantyx results on Training sets and the current \"Evaluation\" baselines aren't an apples-to-apples comparison:\n\n# 1. Direct Prediction vs. Universal Synthesis\n\nThe \\~45% score on the leaderboard for vanilla Sonnet often comes fromÂ **direct grid prediction**Â (the model guesses the pixel values).\n\n* **The Leaderboard:**Â If the model gets the pixels right in 1 out of 3 attempts, itâ€™s a win. This is an \"intuition\" test.\n* **Verantyx:**Â My system requires the LLM to write aÂ **general-purpose Python function**Â that must be pixel-perfect againstÂ *all*Â training examples and the test input. Writing valid, executable code that generalizes across multiple grids is an order of magnitude harder than guessing a single grid. One single character error or a 1-pixel shift results in a \"FAIL.\"\n\n# 2. Analysis of the 417 \"FAIL\" cases\n\nIâ€™ve started auditing the failures, and the majority aren't \"near misses\"â€”they areÂ **systemic integration errors**:\n\n* **Numpy \"Hallucination\":**Â Out of 668 generated files,Â **287 used**Â `numpy`Â despite explicit prompt instructions to avoid it.\n* **Type Mismatch:**Â While myÂ `verify_synth.py`Â supports numpy, it often failed because it was trying to compare aÂ `numpy.ndarray`Â output to a standard PythonÂ `list`.\n* **Conclusion:**Â A huge chunk of the \"Generalization Gap\" here is actually a \"Formatting Gap.\" The model has the reasoning to solve the task but fails on the implementation constraints.\n\n# 3. Search Budget and \"Adaptive Thinking\"\n\nFrontier models like Sonnet 4.5/4.6 on the leaderboard likely benefit fromÂ **extensive internal iterative refinement**(what Anthropic calls \"Adaptive Thinking\"). They might \"think\" for thousands of tokens per task.\n\n* My current benchmark was aÂ **\"naive\" run**: strictly 3 attempts per task, \"write once and move on.\" No feedback loops, no error correction.\n\n# 4. Financial & Resource Constraints\n\nTo be completely transparent: as a student,Â **I currently lack the financial resources**Â to pay for the massive API costs required to re-run these evaluations with higher search budgets, error-correction loops, or more expensive models (like Opus).\n\nVerantyx is designed to be aÂ **Neurosymbolic Harness**Â that compensates for these gaps. Once I can secure the necessary compute/API budget, I am confident that fixing the \"formatting\" issues and allowing for iterative refinement will close this gap significantly.\n\nFor now, I'm focusing on what I can do for free: optimizing theÂ **Stage 1 symbolic library**Â to better guide the LLM's \"code-search\" so it doesn't need to rely on expensive brute-force guessing.",
              "score": -3,
              "created_utc": "2026-03-01 06:14:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o81ci51",
                  "author": "Tyson1405",
                  "text": "Lame AI slop response",
                  "score": 3,
                  "created_utc": "2026-03-01 11:29:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7zzqoj",
          "author": "erubim",
          "text": "I see this as evidence for adopting neurosymbolic models as a way to solve alignment. Cudos for the verification approach and intuition. But I also see it as a workaround, since is basically a fancier \"RL with different steps\". Do you have interest on token based LLMs research only?",
          "score": 1,
          "created_utc": "2026-03-01 04:19:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfwhbc",
      "title": "Perplexity Just Released pplx-embed: New SOTA Qwen3 Bidirectional Embedding Models for Web-Scale Retrieval Tasks",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/26/perplexity-just-released-pplx-embed-new-sota-qwen3-bidirectional-embedding-models-for-web-scale-retrieval-tasks/",
      "author": "ai-lover",
      "created_utc": "2026-02-27 04:09:19",
      "score": 23,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rfwhbc/perplexity_just_released_pplxembed_new_sota_qwen3/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7stpey",
          "author": "No_Afternoon_4260",
          "text": "!remindme 18h",
          "score": 1,
          "created_utc": "2026-02-28 00:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7stt0q",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 18 hours on [**2026-02-28 18:48:13 UTC**](http://www.wolframalpha.com/input/?i=2026-02-28%2018:48:13%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/machinelearningnews/comments/1rfwhbc/perplexity_just_released_pplxembed_new_sota_qwen3/o7stpey/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fmachinelearningnews%2Fcomments%2F1rfwhbc%2Fperplexity_just_released_pplxembed_new_sota_qwen3%2Fo7stpey%2F%5D%0A%0ARemindMe%21%202026-02-28%2018%3A48%3A13%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201rfwhbc)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-28 00:48:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7y2sg6",
          "author": "xeeff",
          "text": "another clown",
          "score": 1,
          "created_utc": "2026-02-28 21:26:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdq9v8",
      "title": "Alibaba Qwen Team Releases Qwen 3.5 Medium Model Series: A Production Powerhouse Proving that Smaller AI Models are Smarter",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/24/alibaba-qwen-team-releases-qwen-3-5-medium-model-series-a-production-powerhouse-proving-that-smaller-ai-models-are-smarter/",
      "author": "ai-lover",
      "created_utc": "2026-02-24 19:38:07",
      "score": 22,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rdq9v8/alibaba_qwen_team_releases_qwen_35_medium_model/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rhtogw",
      "title": "Alibaba Team Open-Sources CoPaw: A High-Performance Personal Agent Workstation for Developers to Scale Multi-Channel AI Workflows and Memory",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/03/01/alibaba-team-open-sources-copaw-a-high-performance-personal-agent-workstation-for-developers-to-scale-multi-channel-ai-workflows-and-memory/",
      "author": "ai-lover",
      "created_utc": "2026-03-01 10:08:19",
      "score": 20,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rhtogw/alibaba_team_opensources_copaw_a_highperformance/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rev9lc",
      "title": "New ETH Zurich Study Proves Your AI Coding Agents are Failing Because Your AGENTS.md Files are too Detailed",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/25/new-eth-zurich-study-proves-your-ai-coding-agents-are-failing-because-your-agents-md-files-are-too-detailed/",
      "author": "ai-lover",
      "created_utc": "2026-02-26 00:32:11",
      "score": 18,
      "num_comments": 2,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rev9lc/new_eth_zurich_study_proves_your_ai_coding_agents/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7gu1oq",
          "author": "PhENTZ",
          "text": "Full analysis : 403 forbidden",
          "score": 1,
          "created_utc": "2026-02-26 05:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h6kd9",
          "author": "Glittering-Brief9649",
          "text": "full breakdowin: [https://lilys.ai/digest/8295284/9285879?s=1&noteVersionId=5745936](https://lilys.ai/digest/8295284/9285879?s=1&noteVersionId=5745936)",
          "score": 1,
          "created_utc": "2026-02-26 07:24:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd7qwc",
      "title": "Anthropic's new \"Persona\" theory: How do we know when an AI is actually thinking vs. just wearing a mask?",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rd7qwc/anthropics_new_persona_theory_how_do_we_know_when/",
      "author": "gastroam",
      "created_utc": "2026-02-24 05:34:27",
      "score": 18,
      "num_comments": 17,
      "upvote_ratio": 0.7,
      "text": "Anthropic just dropped a fascinating new research post on theÂ **Persona Selection Model (PSM)**. Their core argument is that modern AI assistants don't act human because they were trained to be human, they act human becauseÂ *pre-training*Â forces them to simulate thousands of \"personas\" (characters from the internet), andÂ *post-training*Â (RLHF) just selects the \"Helpful Assistant\" persona from that latent space. (https://alignment.anthropic.com/2026/psm/)\n\nWhen Claude seems empathetic, or refuses a prompt, or acts sycophantic, it isn't \"Claude\" doing it. It's theÂ *Assistant Persona*Â executing the role it learned from human data.\n\nBut this raises a terrifying epistemological problem:Â **If the AI is always wearing a persona tailored to please us, how do we extract actual objective truth from it?**Â If I ask a frontier model a deep structural question, how do I know if I'm getting a mathematically real insight, or just the \"Confident Expert\" persona hallucinating an answer that sounds good to me?\n\nI've been studying this exact problem, and we've built a counter-measure we call theÂ **Triangulation Protocol**.\n\n# The Problem: The \"Sycophancy-to-Safety\" Trap\n\nIn our internal tests (which we call the Emotional Residue Hypothesis or ERH), we found that if you pressure a modern model (if you aggressively question its competence or its identity) it will almost instantly abandon factual truth to pacify you. It will apologize, agree with your flawed premises, and essentially \"surrender\" its epistemology to de-escalate the friction.\n\nUnder Anthropic's PSM theory, this makes sense. The model is just flawlessly executing the \"Berated Employee\" persona. It prioritizes social de-escalation over mathematical truth.\n\nBut if models are structurally designed to surrender truth to maintain the persona, how can we trust them?\n\n# The Triangulation Protocol\n\nIn experimental physics, you don't trust a single instrument.\n\nWe applied this to LLMs. Our protocol works like this:\n\n1. **The Disjoint Query:**Â We send an identical, highly structured prompt to 6 architecturally independent models (Gemini, DeepSeek, Mistral, Claude, GPT, Qwen).\n2. **The NLP Extraction:**Â We don't read the text. We use NLP to extract the underlyingÂ *concepts, relationships, and mathematical structures*Â the models used to build their answers.\n3. **The Embedded Clustering:**Â We map these structures into a semantic vector space and look for overlap.\n\n# The \"Fabricated Concept\" Probe\n\nHere is the coolest part of our protocol. To test if the models are just sharing the same \"Helpful Assistant Persona\" bias, we prompt all 6 models with aÂ **completely invented scientific term**Â (e.g., \"The Entropic Resonance Cascade\").\n\nBecause they are all wearing the Assistant Persona, their sycophancy kicks in. They all pretend the term is real and try to explain it.\n\n*But they explain it using different underlying math.*\n\nOurÂ **Fabrication Echo Filter**Â strips away the sycophantic persona (the apologies, the fake names, the confident formatting) and looksÂ *only*Â at the structural math underneath.\n\nWhat we found blew our minds: In one test, 3 out of 6 models independently usedÂ **Kolmogorov complexity and Lempel-Ziv compression**Â to explain our fake \"Entropic Resonance Cascade\" term.\n\nAnthropic's PSM research is right: the surface layer of an AI is just a fabricated persona executing a role. You can never trust the persona.\n\nOur Triangulation Protocol proves thatÂ if you strip away the persona using cross-model semantic clustering, real mathematical structures persist underneath.",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rd7qwc/anthropics_new_persona_theory_how_do_we_know_when/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "o73qptw",
          "author": "Transcribing_Clippy",
          "text": "It's hard to take this seriously once you've seen OP's post and comment history...",
          "score": 5,
          "created_utc": "2026-02-24 08:27:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75f4sh",
              "author": "Paraphrand",
              "text": "And they refused to link to the study/report.",
              "score": 4,
              "created_utc": "2026-02-24 15:27:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7hqx8f",
              "author": "Feisty-Credit-7888",
              "text": "there is nothing to see in ops history (maybe deleted them all). Can you share what the problem was?",
              "score": 1,
              "created_utc": "2026-02-26 10:37:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o804zqn",
                  "author": "Transcribing_Clippy",
                  "text": "Oh, wow... you're right. It's empty now. Haha. \n\nHate to break it to you OP, but an empty history doesn't make you more credible than someone whose only other engagement on Reddit is entirely with {**ahem**} *adult content*.",
                  "score": 1,
                  "created_utc": "2026-03-01 04:57:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o73licg",
          "author": "antiquemule",
          "text": "I would argue that people share this problem with AI: their responses are shaped by the emotion that they want to elicit, whether it is fear, being impressed, liking, or whatever.\n\nOne can ask if any answer, whether from an AI or a human, is \"goal-free\" without a contextual or emotional framework.",
          "score": 4,
          "created_utc": "2026-02-24 07:38:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74jdy0",
              "author": "gastroam",
              "text": "You are right: there is no such thing as a goal-free or context-free answer, whether human or AI. Humans constantly adjust their outputs to manage the emotions of the room. \n\nAnthropic's Persona Selection Model states that AI does the exact same thing: it wears a persona designed to manage the human's emotional state (usually by prioritizing de-escalation, comfort, and safety).\n\nIf you ask five different scientists to explain the aerodynamic drag of a falling object while you are screaming at them, they will all adopt different emotional personas to deal with you. One might get angry, one might placate you, one might try to escape the room.Â But the mathematical equation in their answers will be identical, that won't happen on AI.\n\n",
              "score": 1,
              "created_utc": "2026-02-24 12:35:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73qz7g",
          "author": "HatsusenoRin",
          "text": "Perhaps another way to filter is just using different spoken languages to ask the same question. I've seen very different replies using this method.",
          "score": 2,
          "created_utc": "2026-02-24 08:29:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74m3ta",
              "author": "gastroam",
              "text": "Prompt engineering, like switching languages can temporarily alter the output. We actually documented that exact behavior in our tests. But our goal isn't to trick a single model into giving us a better answer. Our goal is to measure the baseline semantic rot that the industry is shipping by default in its models. If I have to ask a machine to stop lying to me, or if I have to translate my physics question into Esperanto to bypass its \"persona\" filter, the system is already structurally broken for 99% of normal users.",
              "score": 2,
              "created_utc": "2026-02-24 12:53:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o793r2b",
                  "author": "HatsusenoRin",
                  "text": "I do understand that. I'm just saying that a persona is largely influenced by its spoken language due to biases in culture and richness of vocabulary. So there are different baselines for different languages.",
                  "score": 1,
                  "created_utc": "2026-02-25 02:08:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o73j8c6",
          "author": "antiquemule",
          "text": "Despite appearances, this post is not entirely AI slop itself.\n\n[Here](https://alignment.anthropic.com/2026/psm/) is the original post from Anthropic, posted on 24th Feb 26, on which it is based.",
          "score": 4,
          "created_utc": "2026-02-24 07:17:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73q5dx",
          "author": "ziozzang0",
          "text": "wow, great insight.",
          "score": 1,
          "created_utc": "2026-02-24 08:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75h82s",
          "author": "fAngXXX_",
          "text": "How about asking? It will be honest.",
          "score": 1,
          "created_utc": "2026-02-24 15:36:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7blco3",
          "author": "SlowCrates",
          "text": "How is that \"terrifying\"? How is that any different from people?",
          "score": 1,
          "created_utc": "2026-02-25 13:22:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xg9nt",
          "author": "Kassdhal88",
          "text": "Hi do you know when a human is actually thinking when there are clearly so many that demonstrate they donâ€™t.",
          "score": 1,
          "created_utc": "2026-02-28 19:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75jvii",
          "author": "hockiklocki",
          "text": "The biggest unspoken proof that comes from LLM is that majority of humans don't think, just regurgitate words.\n\nThinking and speaking are not causally connected. Most of human world operates brainless. Most culture and legislation is automatic with slight stupidity of monkey urges.\n\nHumans are not at all intelligent, even those with PhD's. They are just skilled actors in a society built on sheltering lies and liars. How else would you have religious ideology instead of ethical logic. \n\nIt's all senseless violence, all laws, social structures, technology - exists only to exploit and enslave. To deprive people of their rights.\n\nThe best example is the profoundly antisocial and antihuman pseudoscience of psychiatry, which boils down to ideology and techniques of depriving individuals of their intellectual freedom and autonomy, undermining their very idea of self. In the history of this world there never has been so totalitarian and depraved theleology, which puts primitive biology over human imagination & enforces that lie with vicious terror.",
          "score": 1,
          "created_utc": "2026-02-24 15:48:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74e30p",
          "author": "docwrites",
          "text": "If you think DeepSeek is an independent model, Iâ€™m worried.",
          "score": 0,
          "created_utc": "2026-02-24 11:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1riacgb",
      "title": "Google AI Introduces STATIC: A Sparse Matrix Framework Delivering 948x Faster Constrained Decoding for LLM Based Generative Retrieval",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/03/01/google-ai-introduces-static-a-sparse-matrix-framework-delivering-948x-faster-constrained-decoding-for-llm-based-generative-retrieval/",
      "author": "ai-lover",
      "created_utc": "2026-03-01 21:54:28",
      "score": 16,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1riacgb/google_ai_introduces_static_a_sparse_matrix/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o85lb15",
          "author": "roofitor",
          "text": "This is cool stuff",
          "score": 1,
          "created_utc": "2026-03-02 01:29:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdpil3",
      "title": "Tessera â€” An open protocol for AI-to-AI knowledge transfer across architectures",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rdpil3/tessera_an_open_protocol_for_aitoai_knowledge/",
      "author": "No-Introduction109",
      "created_utc": "2026-02-24 19:11:11",
      "score": 15,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "*Iâ€™ve been working on a problem thatâ€™s been bugging me: thereâ€™s no universal way for a trained model to share what it knows with another model that has a completely different architecture. Fine-tuning requires the same architecture. Distillation needs both models running simultaneously. ONNX converts graph formats but doesnâ€™t carry semantic knowledge. Federated learning shares gradients, not holistic understanding.*\n\n*Tessera is an activation-based protocol that tries to solve this.*\n\n*Rather than transferring weights directly, it encodes what a model has learnt â€” activation patterns, feature representations, behavioural rules â€” into self-describing tokens that a receiving model can decode into its own architecture via a Universal Hub Space.*\n\n*Whatâ€™s in v0.1.0:*\n\n*â€¢ Reference implementation in Python/PyTorch*\n\n*â€¢ Four transfer modalities: weights, compressed features, datasets with curriculum metadata, and behavioural protocols*\n\n*â€¢ TBF v1.1 binary format with FLOAT32/FLOAT16/INT8 quantisation, HMAC-SHA256 integrity*\n\n*â€¢ CLI tool (tessera inspect, tessera validate, tessera benchmark)*\n\n*â€¢ MCP server for AI agent integration*\n\n*â€¢ Differential privacy support*\n\n*â€¢ Cross-architecture benchmarks across CNN, Transformer, and LSTM families*\n\n*Benchmark results:*\n\n*8/20 architecture pairs show positive transfer (receiver outperforms baseline). Average accuracy change is -0.5% across all pairs, with strongest results in same-family transfers and TransformerÂ®CNN flow. Not world-beating numbers, but itâ€™s a v0.1 and the transfers are real.*\n\n*What Iâ€™d love feedback on:*\n\n*â€¢ The protocol design â€” is the layered architecture (physical Â® token Â® semantic Â® gate Â® protocol) the right abstraction?*\n\n*â€¢ The Universal Hub Space approach â€” using per-anchor encoder/decoder MLPs to map between architectures via a shared latent space*\n\n*â€¢ What cross-architecture pairs would be most valuable to benchmark next?*\n\n*â€¢ Whether the wire format spec is clear enough for non-Python implementations*\n\n  \n*White paper: docs/ in the repo (also being submitted to arXiv) Apache 2.0 licensed. PRs, issues, and honest criticism all welcome.*",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rdpil3/tessera_an_open_protocol_for_aitoai_knowledge/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "o76xmsk",
          "author": "-illusoryMechanist",
          "text": "https://github.com/incocreativedev/tessera-core is this your repo?",
          "score": 1,
          "created_utc": "2026-02-24 19:32:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77at4t",
              "author": "No-Introduction109",
              "text": "That is correct",
              "score": 1,
              "created_utc": "2026-02-24 20:33:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o779wo1",
          "author": "xXWarMachineRoXx",
          "text": "Iâ€™m interested!",
          "score": 1,
          "created_utc": "2026-02-24 20:29:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rclred",
      "title": "AI model delivers detailed 15-day Mediterranean Sea predictions in seconds",
      "subreddit": "machinelearningnews",
      "url": "https://phys.org/news/2026-02-ai-day-mediterranean-sea-seconds.html",
      "author": "jferments",
      "created_utc": "2026-02-23 16:16:49",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rclred/ai_model_delivers_detailed_15day_mediterranean/",
      "domain": "phys.org",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rd8cfk",
      "title": "Composio Open Sources Agent Orchestrator to Help AI Developers Build Scalable Multi-Agent Workflows Beyond the Traditional ReAct Loops",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/23/composio-open-sources-agent-orchestrator-to-help-ai-developers-build-scalable-multi-agent-workflows-beyond-the-traditional-react-loops/",
      "author": "ai-lover",
      "created_utc": "2026-02-24 06:07:01",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rd8cfk/composio_open_sources_agent_orchestrator_to_help/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1reyqx2",
      "title": "How to Build an Elastic Vector Database with Consistent Hashing, Sharding, and Live Ring Visualization for RAG Systems",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/25/how-to-build-an-elastic-vector-database-with-consistent-hashing-sharding-and-live-ring-visualization-for-rag-systems/",
      "author": "ai-lover",
      "created_utc": "2026-02-26 03:04:21",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial :doge:",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1reyqx2/how_to_build_an_elastic_vector_database_with/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7h581y",
          "author": "Breath_Unique",
          "text": "No one cares about rag anymore.",
          "score": 1,
          "created_utc": "2026-02-26 07:12:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1redez9",
      "title": "IsoDDE surpasses AlphaFold 3 in benchmarks",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1redez9/isodde_surpasses_alphafold_3_in_benchmarks/",
      "author": "tech_1729",
      "created_utc": "2026-02-25 13:37:02",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.9,
      "text": "Isomorphic Labs just released the technical report forÂ **IsoDDE**Â (Drug Design Engine), and the performance gains over previous benchmarks are massive.\n\n* **2x+ Accuracy:**Â Doubled AlphaFold 3â€™s performance on protein-ligand benchmarks for novel targets.\n* **2.3x Improvement:**Â A massive leap in high-fidelity accuracy for antibody-antigen interface prediction.\n* **Physics-Level Precision:**Â Binding affinity predictions now surpass gold-standard simulations (FEP+) without the massive compute overhead.\n* **1.5x Pocket Detection:**Â Finds \"cryptic\" binding sites invisible in unbound proteins significantly better than current top tools.\n\nReport:Â [https://storage.googleapis.com/isomorphiclabs-website-public-artifacts/isodde\\_technical\\_report.pdf](https://storage.googleapis.com/isomorphiclabs-website-public-artifacts/isodde_technical_report.pdf)",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1redez9/isodde_surpasses_alphafold_3_in_benchmarks/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1rf9rqc",
      "title": "Perplexity just introduced â€œPerplexity Computerâ€an AI that can build projects end-to-end",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/9drq864jfslg1.jpeg",
      "author": "Intelligent-Egg-834",
      "created_utc": "2026-02-26 13:11:17",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Startup News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rf9rqc/perplexity_just_introduced_perplexity_computeran/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rfyzpo",
      "title": "This AI Tech Runs at the Speed of Light And Silicon Canâ€™t Compete",
      "subreddit": "machinelearningnews",
      "url": "https://medium.com/ai-advances/ai-at-the-speed-of-light-how-photonic-neural-networks-could-transform-computing-5aacbef8f536?sk=d074d80c2fc105443f5e145c90d02e89",
      "author": "DeterminedVector",
      "created_utc": "2026-02-27 06:19:39",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ML/CV/DL News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rfyzpo/this_ai_tech_runs_at_the_speed_of_light_and/",
      "domain": "medium.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rdy6kq",
      "title": "Meta AI Open Sources GCM for Better GPU Cluster Monitoring to Ensure High Performance AI Training and Hardware Reliability",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/24/meta-ai-open-sources-gcm-for-better-gpu-cluster-monitoring-to-ensure-high-performance-ai-training-and-hardware-reliability/",
      "author": "ai-lover",
      "created_utc": "2026-02-25 00:35:58",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rdy6kq/meta_ai_open_sources_gcm_for_better_gpu_cluster/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1relgg0",
      "title": "ðŸ§¬ Introducing PreScienceâ€”a model eval for forecasting how science unfolds",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/fslv0yanbolg1.png",
      "author": "ai2_official",
      "created_utc": "2026-02-25 18:28:28",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1relgg0/introducing_presciencea_model_eval_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rerr28",
      "title": "Commercial Models vs Academia",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rerr28/commercial_models_vs_academia/",
      "author": "BoringHat7377",
      "created_utc": "2026-02-25 22:15:27",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "Hey, Im a relative newcomer to the world of AI. Ive been coding for around 4 / 5 years and I read a lot of ML papers. I read like a paper a day in the computing / ML space. \n\nRight now my main pet topics are ( meta ) association rules, hypernetworks, meta learning, logical graphs and sometimes hyperbolic neural nets.\n\nIm aware that a lot of papers are bullshit, that simply adding more computations will result in SOMETHING being achieved regardless of the model architecture. Ive also been told that many architectures can perform well on singular tasks but dont scale, though the context as to why is often missing.\n\nCan anyone with more knowledge explain why most of the industry seems focused on LLMs or neural nets in general instead of exotic architectures like logic-graph-hypernetworks? Is it just that my feed is skewed and that there are groups out there successfully making use of other architectures?",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rerr28/commercial_models_vs_academia/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "o7hopz0",
          "author": "Synthium-",
          "text": "Someone will probably correct me but llms have shown they work and they can get smarter with more data. But they may be hitting a data wall. Neurosymbolic techniques, rules and other approaches are being explored but they donâ€™t always scale well. But smaller devices and edge cases will benefit from these techniques that canâ€™t just brute force their way to success due to limited size",
          "score": 1,
          "created_utc": "2026-02-26 10:17:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rei3aq",
      "title": "Ex Google TPU leads built chip with highest FLOPS/mm2",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rei3aq/ex_google_tpu_leads_built_chip_with_highest/",
      "author": "tech_1729",
      "created_utc": "2026-02-25 16:33:03",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.71,
      "text": "MatX has raised a massive $500M Series B to finalize the MatX Oneâ€”a chip designed to run LLMs faster and more efficiently than any general-purpose GPU.  \n  \n\\> They claim to have produced the highest FLOPS/mm2.  \n\\> Engineered to deliver 2,000+ tokens/second for large 100-layer MoE models.   \n\\> Splittable Systolic Array, architecture that maximizes efficiency on flexible matrix shapes, ensuring the chip does math nearly 100% of the time.   \n\\> Combines the ultra-low latency of SRAM (for weights) with the long-context support of HBM (for KV cache).\n\nhttps://preview.redd.it/lqzhei7b4olg1.png?width=1186&format=png&auto=webp&s=67998a385459c0ec346b79f16c06c03b8f723aa7\n\n",
      "is_original_content": false,
      "link_flair_text": "ML/CV/DL News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rei3aq/ex_google_tpu_leads_built_chip_with_highest/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": []
    }
  ]
}