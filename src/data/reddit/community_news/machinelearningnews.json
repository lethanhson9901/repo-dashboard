{
  "metadata": {
    "last_updated": "2026-02-25 03:09:26",
    "time_filter": "week",
    "subreddit": "machinelearningnews",
    "total_items": 15,
    "total_comments": 19,
    "file_size_bytes": 31805
  },
  "items": [
    {
      "id": "1ra76i5",
      "title": "NVIDIA Releases DreamDojo: An Open-Source Robot World Model Trained on 44,711 Hours of Real-World Human Video Data",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/20/nvidia-releases-dreamdojo-an-open-source-robot-world-model-trained-on-44711-hours-of-real-world-human-video-data/",
      "author": "ai-lover",
      "created_utc": "2026-02-20 20:53:20",
      "score": 63,
      "num_comments": 1,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1ra76i5/nvidia_releases_dreamdojo_an_opensource_robot/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6kg8pt",
          "author": "StarThinker2025",
          "text": "The embodiment transfer claim is bold. If that holds up, this is a big step for world models.",
          "score": 2,
          "created_utc": "2026-02-21 07:41:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rb2tvl",
      "title": "Is There a Community Edition of Palantir? Meet OpenPlanter: An Open Source Recursive AI Agent for Your Micro Surveillance Use Cases",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/21/is-there-a-community-edition-of-palantir-meet-openplanter-an-open-source-recursive-ai-agent-for-your-micro-surveillance-use-cases/",
      "author": "ai-lover",
      "created_utc": "2026-02-21 21:18:58",
      "score": 28,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rb2tvl/is_there_a_community_edition_of_palantir_meet/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6o2gcg",
          "author": "charmander_cha",
          "text": "Could this be used in the Epstein case?",
          "score": 7,
          "created_utc": "2026-02-21 21:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s6hlb",
          "author": "ThePhilosopha",
          "text": "Definitely giving this a try. Not 100% what to do with it but I'll learn.",
          "score": 1,
          "created_utc": "2026-02-22 15:13:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbj1gt",
      "title": "Will Neurosymbolic AI outperform pure transformers by 2027?",
      "subreddit": "machinelearningnews",
      "url": "https://medium.com/generative-ai/neurosymbolic-ai-why-this-hybrid-tech-may-dominate-intelligent-systems-by-2027-f063f0a50bee",
      "author": "[deleted]",
      "created_utc": "2026-02-22 11:00:13",
      "score": 18,
      "num_comments": 6,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ML/CV/DL News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rbj1gt/will_neurosymbolic_ai_outperform_pure/",
      "domain": "medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6tugk6",
          "author": "Extreme_Exchange_168",
          "text": "Highly unlikely unless thereâ€™s some big architectural improvement",
          "score": 6,
          "created_utc": "2026-02-22 19:51:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tuknd",
              "author": "Extreme_Exchange_168",
              "text": "* foundational",
              "score": 4,
              "created_utc": "2026-02-22 19:51:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6xnmqd",
                  "author": "[deleted]",
                  "text": "Scaling or structure?",
                  "score": 1,
                  "created_utc": "2026-02-23 11:23:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o736u7o",
                  "author": "erubim",
                  "text": "When you say foundational i think of someone getting a paper from the 60s and finding a way to scale with modern tech.\nI think all that is foundational is already available, we are just figuring the blocks that best fit together",
                  "score": 1,
                  "created_utc": "2026-02-24 05:33:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6y1vni",
          "author": "Extension_Thing_7791",
          "text": "No",
          "score": 1,
          "created_utc": "2026-02-23 13:09:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbxmnd",
      "title": "Forget Keyword Imitation: ByteDance AI Maps Molecular Bonds in AI Reasoning to Stabilize Long Chain-of-Thought Performance and Reinforcement Learning (RL) Training",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/22/forget-keyword-imitation-bytedance-ai-maps-molecular-bonds-in-ai-reasoning-to-stabilize-long-chain-of-thought-performance-and-reinforcement-learning-rl-training/",
      "author": "ai-lover",
      "created_utc": "2026-02-22 21:05:15",
      "score": 17,
      "num_comments": 0,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rbxmnd/forget_keyword_imitation_bytedance_ai_maps/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r9ddj7",
      "title": "Google AI Releases Gemini 3.1 Pro with 1 Million Token Context and 77.1 Percent ARC-AGI-2 Reasoning for AI Agents",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/19/google-ai-releases-gemini-3-1-pro-with-1-million-token-context-and-77-1-percent-arc-agi-2-reasoning-for-ai-agents/",
      "author": "ai-lover",
      "created_utc": "2026-02-19 22:20:55",
      "score": 16,
      "num_comments": 1,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r9ddj7/google_ai_releases_gemini_31_pro_with_1_million/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6blkz3",
          "author": "Otherwise_Wave9374",
          "text": "The 1M context plus a bigger output window is a big deal for agent workflows, especially if you are doing long-running planning, codebase RAG, or keeping a durable scratchpad.\n\nI am curious how people are measuring \"agent reliability\" as context sizes explode, like whether evals shift from single-task accuracy to end-to-end success rate across tool calls and retries. Been bookmarking a few notes on agent evals/guardrails and practical patterns here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-02-19 22:26:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd7qwc",
      "title": "Anthropic's new \"Persona\" theory: How do we know when an AI is actually thinking vs. just wearing a mask?",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rd7qwc/anthropics_new_persona_theory_how_do_we_know_when/",
      "author": "gastroam",
      "created_utc": "2026-02-24 05:34:27",
      "score": 14,
      "num_comments": 12,
      "upvote_ratio": 0.69,
      "text": "Anthropic just dropped a fascinating new research post on theÂ **Persona Selection Model (PSM)**. Their core argument is that modern AI assistants don't act human because they were trained to be human, they act human becauseÂ *pre-training*Â forces them to simulate thousands of \"personas\" (characters from the internet), andÂ *post-training*Â (RLHF) just selects the \"Helpful Assistant\" persona from that latent space. (https://alignment.anthropic.com/2026/psm/)\n\nWhen Claude seems empathetic, or refuses a prompt, or acts sycophantic, it isn't \"Claude\" doing it. It's theÂ *Assistant Persona*Â executing the role it learned from human data.\n\nBut this raises a terrifying epistemological problem:Â **If the AI is always wearing a persona tailored to please us, how do we extract actual objective truth from it?**Â If I ask a frontier model a deep structural question, how do I know if I'm getting a mathematically real insight, or just the \"Confident Expert\" persona hallucinating an answer that sounds good to me?\n\nI've been studying this exact problem, and we've built a counter-measure we call theÂ **Triangulation Protocol**.\n\n# The Problem: The \"Sycophancy-to-Safety\" Trap\n\nIn our internal tests (which we call the Emotional Residue Hypothesis or ERH), we found that if you pressure a modern model (if you aggressively question its competence or its identity) it will almost instantly abandon factual truth to pacify you. It will apologize, agree with your flawed premises, and essentially \"surrender\" its epistemology to de-escalate the friction.\n\nUnder Anthropic's PSM theory, this makes sense. The model is just flawlessly executing the \"Berated Employee\" persona. It prioritizes social de-escalation over mathematical truth.\n\nBut if models are structurally designed to surrender truth to maintain the persona, how can we trust them?\n\n# The Triangulation Protocol\n\nIn experimental physics, you don't trust a single instrument.\n\nWe applied this to LLMs. Our protocol works like this:\n\n1. **The Disjoint Query:**Â We send an identical, highly structured prompt to 6 architecturally independent models (Gemini, DeepSeek, Mistral, Claude, GPT, Qwen).\n2. **The NLP Extraction:**Â We don't read the text. We use NLP to extract the underlyingÂ *concepts, relationships, and mathematical structures*Â the models used to build their answers.\n3. **The Embedded Clustering:**Â We map these structures into a semantic vector space and look for overlap.\n\n# The \"Fabricated Concept\" Probe\n\nHere is the coolest part of our protocol. To test if the models are just sharing the same \"Helpful Assistant Persona\" bias, we prompt all 6 models with aÂ **completely invented scientific term**Â (e.g., \"The Entropic Resonance Cascade\").\n\nBecause they are all wearing the Assistant Persona, their sycophancy kicks in. They all pretend the term is real and try to explain it.\n\n*But they explain it using different underlying math.*\n\nOurÂ **Fabrication Echo Filter**Â strips away the sycophantic persona (the apologies, the fake names, the confident formatting) and looksÂ *only*Â at the structural math underneath.\n\nWhat we found blew our minds: In one test, 3 out of 6 models independently usedÂ **Kolmogorov complexity and Lempel-Ziv compression**Â to explain our fake \"Entropic Resonance Cascade\" term.\n\nAnthropic's PSM research is right: the surface layer of an AI is just a fabricated persona executing a role. You can never trust the persona.\n\nOur Triangulation Protocol proves thatÂ if you strip away the persona using cross-model semantic clustering, real mathematical structures persist underneath.",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rd7qwc/anthropics_new_persona_theory_how_do_we_know_when/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "o73licg",
          "author": "antiquemule",
          "text": "I would argue that people share this problem with AI: their responses are shaped by the emotion that they want to elicit, whether it is fear, being impressed, liking, or whatever.\n\nOne can ask if any answer, whether from an AI or a human, is \"goal-free\" without a contextual or emotional framework.",
          "score": 5,
          "created_utc": "2026-02-24 07:38:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74jdy0",
              "author": "gastroam",
              "text": "You are right: there is no such thing as a goal-free or context-free answer, whether human or AI. Humans constantly adjust their outputs to manage the emotions of the room. \n\nAnthropic's Persona Selection Model states that AI does the exact same thing: it wears a persona designed to manage the human's emotional state (usually by prioritizing de-escalation, comfort, and safety).\n\nIf you ask five different scientists to explain the aerodynamic drag of a falling object while you are screaming at them, they will all adopt different emotional personas to deal with you. One might get angry, one might placate you, one might try to escape the room.Â But the mathematical equation in their answers will be identical, that won't happen on AI.\n\n",
              "score": 1,
              "created_utc": "2026-02-24 12:35:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73qptw",
          "author": "Transcribing_Clippy",
          "text": "It's hard to take this seriously once you've seen OP's post and comment history...",
          "score": 5,
          "created_utc": "2026-02-24 08:27:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75f4sh",
              "author": "Paraphrand",
              "text": "And they refused to link to the study/report.",
              "score": 4,
              "created_utc": "2026-02-24 15:27:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o73qz7g",
          "author": "HatsusenoRin",
          "text": "Perhaps another way to filter is just using different spoken languages to ask the same question. I've seen very different replies using this method.",
          "score": 2,
          "created_utc": "2026-02-24 08:29:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74m3ta",
              "author": "gastroam",
              "text": "Prompt engineering, like switching languages can temporarily alter the output. We actually documented that exact behavior in our tests. But our goal isn't to trick a single model into giving us a better answer. Our goal is to measure the baseline semantic rot that the industry is shipping by default in its models. If I have to ask a machine to stop lying to me, or if I have to translate my physics question into Esperanto to bypass its \"persona\" filter, the system is already structurally broken for 99% of normal users.",
              "score": 2,
              "created_utc": "2026-02-24 12:53:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o793r2b",
                  "author": "HatsusenoRin",
                  "text": "I do understand that. I'm just saying that a persona is largely influenced by its spoken language due to biases in culture and richness of vocabulary. So there are different baselines for different languages.",
                  "score": 1,
                  "created_utc": "2026-02-25 02:08:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o73j8c6",
          "author": "antiquemule",
          "text": "Despite appearances, this post is not entirely AI slop itself.\n\n[Here](https://alignment.anthropic.com/2026/psm/) is the original post from Anthropic, posted on 24th Feb 26, on which it is based.",
          "score": 3,
          "created_utc": "2026-02-24 07:17:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73q5dx",
          "author": "ziozzang0",
          "text": "wow, great insight.",
          "score": 1,
          "created_utc": "2026-02-24 08:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75h82s",
          "author": "fAngXXX_",
          "text": "How about asking? It will be honest.",
          "score": 1,
          "created_utc": "2026-02-24 15:36:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75jvii",
          "author": "hockiklocki",
          "text": "The biggest unspoken proof that comes from LLM is that majority of humans don't think, just regurgitate words.\n\nThinking and speaking are not causally connected. Most of human world operates brainless. Most culture and legislation is automatic with slight stupidity of monkey urges.\n\nHumans are not at all intelligent, even those with PhD's. They are just skilled actors in a society built on sheltering lies and liars. How else would you have religious ideology instead of ethical logic. \n\nIt's all senseless violence, all laws, social structures, technology - exists only to exploit and enslave. To deprive people of their rights.\n\nThe best example is the profoundly antisocial and antihuman pseudoscience of psychiatry, which boils down to ideology and techniques of depriving individuals of their intellectual freedom and autonomy, undermining their very idea of self. In the history of this world there never has been so totalitarian and depraved theleology, which puts primitive biology over human imagination & enforces that lie with vicious terror.",
          "score": 1,
          "created_utc": "2026-02-24 15:48:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74e30p",
          "author": "docwrites",
          "text": "If you think DeepSeek is an independent model, Iâ€™m worried.",
          "score": 0,
          "created_utc": "2026-02-24 11:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8ec10",
      "title": "Google DeepMind Releases Lyria 3: An Advanced Music Generation AI Model that Turns Photos and Text into Custom Tracks with Included Lyrics and Vocals",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/18/google-deepmind-releases-lyria-3-an-advanced-music-generation-ai-model-that-turns-photos-and-text-into-custom-tracks-with-included-lyrics-and-vocals/",
      "author": "ai-lover",
      "created_utc": "2026-02-18 20:29:24",
      "score": 12,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r8ec10/google_deepmind_releases_lyria_3_an_advanced/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6raxjv",
          "author": "Budget-Juggernaut-68",
          "text": "Photo album music?",
          "score": 1,
          "created_utc": "2026-02-22 11:53:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbcy43",
      "title": "A New Google AI Research Proposes Deep-Thinking Ratio to Improve LLM Accuracy While Cutting Total Inference Costs by Half",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rbcy43/a_new_google_ai_research_proposes_deepthinking/",
      "author": "ai-lover",
      "created_utc": "2026-02-22 05:01:54",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 0.91,
      "text": "This research challenges the 'longer is better' strategy for LLM reasoning, demonstrating that raw token count actually correlates negatively with accuracy (average r=âˆ’0.59) due to overthinking and error amplification. Instead, the research team introduce the Deep-Thinking Ratio (DTR), which identifies 'deep-thinking tokens'â€”those whose internal predictions undergo significant revision in deeper model layers before stabilizing. Across multiple benchmarks like AIME 2025 and GPQA-Diamond, DTR shows a robust positive correlation with accuracy (average r=0.683), proving far more reliable than length or confidence metrics. Leveraging this insight, the team's Think@n strategy enables early rejection of unpromising generations, matching or exceeding standard self-consistency performance while cutting inference costs by approximately 50%.....\n\nFull analysis: [https://www.marktechpost.com/2026/02/21/a-new-google-ai-research-proposes-deep-thinking-ratio-to-improve-llm-accuracy-while-cutting-total-inference-costs-by-half/](https://www.marktechpost.com/2026/02/21/a-new-google-ai-research-proposes-deep-thinking-ratio-to-improve-llm-accuracy-while-cutting-total-inference-costs-by-half/)\n\nPaper: [https://arxiv.org/pdf/2602.13517](https://arxiv.org/pdf/2602.13517)\n\nhttps://i.redd.it/xxbwlb78azkg1.gif\n\n",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rbcy43/a_new_google_ai_research_proposes_deepthinking/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "o6r1dot",
          "author": "antiquemule",
          "text": "To my naive mind, this reminds me of the problem of [context rot](https://research.trychroma.com/context-rot), in the sense that \"more is better\" is often an unreliable mantra for AI.",
          "score": 1,
          "created_utc": "2026-02-22 10:24:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r4as1",
              "author": "Budget-Juggernaut-68",
              "text": "Yup. Kinda. Lots of the generated path ways directs the the model down the wrong answer. It's still an effective work around the fact that autoregressive models cannot self correct, and \"thinking mode\" enables it to do so. And context pollution is a problem and this method does curb this problem.",
              "score": 1,
              "created_utc": "2026-02-22 10:52:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rclred",
      "title": "AI model delivers detailed 15-day Mediterranean Sea predictions in seconds",
      "subreddit": "machinelearningnews",
      "url": "https://phys.org/news/2026-02-ai-day-mediterranean-sea-seconds.html",
      "author": "jferments",
      "created_utc": "2026-02-23 16:16:49",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rclred/ai_model_delivers_detailed_15day_mediterranean/",
      "domain": "phys.org",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r7vrai",
      "title": "Cohere Releases Tiny Aya: A 3B-Parameter Small Language Model that Supports 70 Languages and Runs Locally Even on a Phone",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/17/cohere-releases-tiny-aya-a-3b-parameter-small-language-model-that-supports-70-languages-and-runs-locally-even-on-a-phone/",
      "author": "ai-lover",
      "created_utc": "2026-02-18 06:40:53",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r7vrai/cohere_releases_tiny_aya_a_3bparameter_small/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rbkrik",
      "title": "24hr-research-agent: An experimental autonomous research system that conducts comprehensive, multi-hour research sessions and produces book-length reports with full citations on any topic.",
      "subreddit": "machinelearningnews",
      "url": "https://github.com/Aaryan-Kapoor/24hr-research-agent",
      "author": "KvAk_AKPlaysYT",
      "created_utc": "2026-02-22 12:34:20",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "AI Tools",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rbkrik/24hrresearchagent_an_experimental_autonomous/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6zxpax",
          "author": "Breath_Unique",
          "text": "Mmmm credits...... This is just more slop",
          "score": 1,
          "created_utc": "2026-02-23 18:46:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdpil3",
      "title": "Tessera â€” An open protocol for AI-to-AI knowledge transfer across architectures",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1rdpil3/tessera_an_open_protocol_for_aitoai_knowledge/",
      "author": "No-Introduction109",
      "created_utc": "2026-02-24 19:11:11",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 0.88,
      "text": "*Iâ€™ve been working on a problem thatâ€™s been bugging me: thereâ€™s no universal way for a trained model to share what it knows with another model that has a completely different architecture. Fine-tuning requires the same architecture. Distillation needs both models running simultaneously. ONNX converts graph formats but doesnâ€™t carry semantic knowledge. Federated learning shares gradients, not holistic understanding.*\n\n*Tessera is an activation-based protocol that tries to solve this.*\n\n*Rather than transferring weights directly, it encodes what a model has learnt â€” activation patterns, feature representations, behavioural rules â€” into self-describing tokens that a receiving model can decode into its own architecture via a Universal Hub Space.*\n\n*Whatâ€™s in v0.1.0:*\n\n*â€¢ Reference implementation in Python/PyTorch*\n\n*â€¢ Four transfer modalities: weights, compressed features, datasets with curriculum metadata, and behavioural protocols*\n\n*â€¢ TBF v1.1 binary format with FLOAT32/FLOAT16/INT8 quantisation, HMAC-SHA256 integrity*\n\n*â€¢ CLI tool (tessera inspect, tessera validate, tessera benchmark)*\n\n*â€¢ MCP server for AI agent integration*\n\n*â€¢ Differential privacy support*\n\n*â€¢ Cross-architecture benchmarks across CNN, Transformer, and LSTM families*\n\n*Benchmark results:*\n\n*8/20 architecture pairs show positive transfer (receiver outperforms baseline). Average accuracy change is -0.5% across all pairs, with strongest results in same-family transfers and TransformerÂ®CNN flow. Not world-beating numbers, but itâ€™s a v0.1 and the transfers are real.*\n\n*What Iâ€™d love feedback on:*\n\n*â€¢ The protocol design â€” is the layered architecture (physical Â® token Â® semantic Â® gate Â® protocol) the right abstraction?*\n\n*â€¢ The Universal Hub Space approach â€” using per-anchor encoder/decoder MLPs to map between architectures via a shared latent space*\n\n*â€¢ What cross-architecture pairs would be most valuable to benchmark next?*\n\n*â€¢ Whether the wire format spec is clear enough for non-Python implementations*\n\n  \n*White paper: docs/ in the repo (also being submitted to arXiv) Apache 2.0 licensed. PRs, issues, and honest criticism all welcome.*",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rdpil3/tessera_an_open_protocol_for_aitoai_knowledge/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "o76xmsk",
          "author": "-illusoryMechanist",
          "text": "https://github.com/incocreativedev/tessera-core is this your repo?",
          "score": 1,
          "created_utc": "2026-02-24 19:32:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77at4t",
              "author": "No-Introduction109",
              "text": "That is correct",
              "score": 1,
              "created_utc": "2026-02-24 20:33:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o779wo1",
          "author": "xXWarMachineRoXx",
          "text": "Iâ€™m interested!",
          "score": 1,
          "created_utc": "2026-02-24 20:29:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1raiu5o",
      "title": "NVIDIA-GTC-2026 Edition: Connect in Person with Experts from Tesla, Disney and Johnson & Johnson at GTC 2026  or Even Join Virtually (Free)",
      "subreddit": "machinelearningnews",
      "url": "https://pxllnk.co/61js82tn",
      "author": "ai-lover",
      "created_utc": "2026-02-21 05:30:17",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "AI Event",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1raiu5o/nvidiagtc2026_edition_connect_in_person_with/",
      "domain": "pxllnk.co",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rd8cfk",
      "title": "Composio Open Sources Agent Orchestrator to Help AI Developers Build Scalable Multi-Agent Workflows Beyond the Traditional ReAct Loops",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/23/composio-open-sources-agent-orchestrator-to-help-ai-developers-build-scalable-multi-agent-workflows-beyond-the-traditional-react-loops/",
      "author": "ai-lover",
      "created_utc": "2026-02-24 06:07:01",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1rd8cfk/composio_open_sources_agent_orchestrator_to_help/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r8bwz1",
      "title": "\"Ask AI about this paper\"â€”New Chrome extension for Asta ðŸ§ª",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/1bs38y2ptakg1.png",
      "author": "ai2_official",
      "created_utc": "2026-02-18 19:00:03",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r8bwz1/ask_ai_about_this_papernew_chrome_extension_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}