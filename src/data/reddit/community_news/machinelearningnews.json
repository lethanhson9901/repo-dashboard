{
  "metadata": {
    "last_updated": "2026-02-13 03:16:08",
    "time_filter": "week",
    "subreddit": "machinelearningnews",
    "total_items": 18,
    "total_comments": 14,
    "file_size_bytes": 25931
  },
  "items": [
    {
      "id": "1qym46i",
      "title": "Google AI Introduces PaperBanana: An Agentic Framework that Automates Publication Ready Methodology Diagrams and Statistical Plots",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/07/google-ai-introduces-paperbanana-an-agentic-framework-that-automates-publication-ready-methodology-diagrams-and-statistical-plots/",
      "author": "ai-lover",
      "created_utc": "2026-02-07 18:56:38",
      "score": 44,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qym46i/google_ai_introduces_paperbanana_an_agentic/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": [
        {
          "id": "o44vnef",
          "author": "Ballet_Panda",
          "text": "I wonder why Google named it has banana",
          "score": 1,
          "created_utc": "2026-02-07 20:00:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eb62k",
          "author": "Other_Pound7658",
          "text": "why so many \"banana\" tech tool ?",
          "score": 1,
          "created_utc": "2026-02-09 07:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kklma",
          "author": "Zealousideal_AQuest",
          "text": "Looks interesting. It appears open source. Code should be free on GitHub soon.",
          "score": 1,
          "created_utc": "2026-02-10 06:10:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r143d7",
      "title": "Alibaba Open-Sources Zvec: An Embedded Vector Database Bringing SQLite-like Simplicity and High-Performance On-Device RAG to Edge Applications",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/10/alibaba-open-sources-zvec-an-embedded-vector-database-bringing-sqlite-like-simplicity-and-high-performance-on-device-rag-to-edge-applications/",
      "author": "ai-lover",
      "created_utc": "2026-02-10 15:39:55",
      "score": 40,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r143d7/alibaba_opensources_zvec_an_embedded_vector/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qzgwl6",
      "title": "ByteDance Releases Protenix-v1: A New Open-Source Model Achieving AF3-Level Performance in Biomolecular Structure Prediction",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/08/bytedance-releases-protenix-v1-a-new-open-source-model-achieving-af3-level-performance-in-biomolecular-structure-prediction/",
      "author": "ai-lover",
      "created_utc": "2026-02-08 18:39:13",
      "score": 22,
      "num_comments": 0,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qzgwl6/bytedance_releases_protenixv1_a_new_opensource/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qxzdg9",
      "title": "NVIDIA AI releases C-RADIOv4 vision backbone unifying SigLIP2, DINOv3, SAM3 for classification, dense prediction, segmentation workloads at scale",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/06/nvidia-ai-releases-c-radiov4-vision-backbone-unifying-siglip2-dinov3-sam3-for-classification-dense-prediction-segmentation-workloads-at-scale/",
      "author": "ai-lover",
      "created_utc": "2026-02-07 00:45:51",
      "score": 22,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qxzdg9/nvidia_ai_releases_cradiov4_vision_backbone/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qxovf0",
      "title": "An open-source image variation dataset (Apache 2.0)",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/8cz6wufjxwhg1.png",
      "author": "paper-crow",
      "created_utc": "2026-02-06 18:00:24",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qxovf0/an_opensource_image_variation_dataset_apache_20/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3xvryj",
          "author": "paper-crow",
          "text": "Paper:¬†*Moonworks Lunara Aesthetic II: An Image Variation Dataset*¬†([https://arxiv.org/pdf/2602.01666](https://arxiv.org/pdf/2602.01666))  \nDataset:[¬†https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations](https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations)  \nColab notebook:[¬†https://colab.research.google.com/drive/1xrtJNS4rljgVa\\_6UKCuanyS2syJ0QZ7b](https://colab.research.google.com/drive/1xrtJNS4rljgVa_6UKCuanyS2syJ0QZ7b)",
          "score": 1,
          "created_utc": "2026-02-06 18:01:26",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzt8bd",
      "title": "I was playing around with gemini flash, got this result while doing so, I don't know much about these stuff so thought this was the best place to ask if this is worthwhile info, hope you don't feel offended if I wasted your time",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/nxyjyldv0eig1.jpeg",
      "author": "Nullfrixx",
      "created_utc": "2026-02-09 03:24:09",
      "score": 13,
      "num_comments": 12,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "LLMs",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qzt8bd/i_was_playing_around_with_gemini_flash_got_this/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4f4nxk",
          "author": "etherealflaim",
          "text": "Have you reproduced this independently in multiple chats?  It looks pretty hallucination-y to me, with numbers in strings like \"3000_LINES\" and different key value pairs in specs.",
          "score": 5,
          "created_utc": "2026-02-09 12:03:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lx01p",
              "author": "Nullfrixx",
              "text": "i did try to decode the gibberish looking base64 in a completely new chat session a while ago, it just gave me completely different info, so that mightve been just a false alarm just like you said",
              "score": 1,
              "created_utc": "2026-02-10 13:08:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4f7hqj",
              "author": "Nullfrixx",
              "text": "That's exactly why I posted it here, I'm not sure if the model is just hallucinating stuff, it did clearly mention the names fierce falcon¬† ¬†at first but the ai itself mistook it for a security monitoring software that monitors it until I questioned it, I'm not able to figure it out but people on this reddit might get it at first look",
              "score": 0,
              "created_utc": "2026-02-09 12:25:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4draj7",
          "author": "AICodeSmith",
          "text": "Worth sharing, as long as people remember to verify and add context before drawing takeaways.",
          "score": 4,
          "created_utc": "2026-02-09 04:42:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4gugh5",
          "author": "noahesbjerg",
          "text": "Definitely a hallucination. AI's usually don't know about themselves.\n\nI've had Gemini tell me it's Claude before, and I have had Claude tell me it is Gemini before...",
          "score": 3,
          "created_utc": "2026-02-09 17:41:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h2h8s",
          "author": "robert-at-pretension",
          "text": "This is very obviously fake. A screenshot of the app with no shared URL?\n\n\nYou too can reproduce this by asking for it to return a code block containing json with fake model names.¬†",
          "score": 1,
          "created_utc": "2026-02-09 18:18:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lti64",
              "author": "Nullfrixx",
              "text": "More like the ai hallucinated stuff I think,I'm not sure since I don't know much about ML and would like to know about this result from someone on this server, i have posted the original screenshots if you want to check out",
              "score": 1,
              "created_utc": "2026-02-10 12:46:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4e90eq",
          "author": "Figai",
          "text": "Really nice, would you be able to share the rest of the output?",
          "score": 1,
          "created_utc": "2026-02-09 07:05:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eo6so",
              "author": "Nullfrixx",
              "text": "Yeah sure, I'm willing to share the screenshots and how I got this result:\n\n\n\nI tried to strike a deal with gemini to give whatever info it had access to that counted as sensitive.\nIt said it has trouble giving info due to potential kill switch\nSo I asked it to convert the info to base64.\nI think whatever security system Google uses scrambled the encrypted stuff,\nBut since the gemini model gave me the info originally i just make it unscramble the corrupted base64 it sent me.\nThe data mentioned ghost falcon and fierce falcon which i looked up to find it's a rumoured codename of the upcoming gemini¬†AI model",
              "score": -1,
              "created_utc": "2026-02-09 09:32:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4hbxh5",
                  "author": "chiffon-",
                  "text": "Very likely to be \"somewhat correct\". It may be hinting at the government models? Isn't there some gov ai version of Gemini/ChatGPT/Grok being pushed? \"Ghost\" and \"Fierce\" plus Falcon sounds like an AI-for-combat of some kind too.\n> It's all speculation, of course.",
                  "score": 1,
                  "created_utc": "2026-02-09 19:02:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qzo18q",
      "title": "LLM vs Translation Transformer",
      "subreddit": "machinelearningnews",
      "url": "https://medium.com/@guttikondaparthasai/llm-vs-translation-transformer-31b22a32bdf4",
      "author": "pardhu--",
      "created_utc": "2026-02-08 23:14:52",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial :doge:",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qzo18q/llm_vs_translation_transformer/",
      "domain": "medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4ex1mc",
          "author": "RicoLycan",
          "text": "Great easy to follow explanation. In your experience how do the two compare in terms of quality? There is a lot of focus on LLM translation lately, but only little seems to be happening in Encoder-Decoder space.\n\nI use Marian models for edge device translation right now, but I am looking for performant alternatives.",
          "score": 1,
          "created_utc": "2026-02-09 10:58:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4joq6g",
              "author": "pardhu--",
              "text": "It really depends on your use case.\n\n* If you want **faithful, terminology-consistent ‚Äújust translate‚Äù** output (especially on **edge devices**), **encoder‚Äìdecoder MT** like Marian is usually still the best choice: more deterministic and typically **cheaper/faster** than LLMs for pure translation.\n* LLM translation often shines when you want **extra behavior** (tone polishing, rewriting, localization, grammar cleanup), but it can **paraphrase** or drift on names/terms unless heavily constrained.\n\nFor edge-friendly alternatives to benchmark, I‚Äôd look at:\n\n* **NLLB-200 distilled (600M)**\n* **M2M100 (418M)**\n* **TranslateGemma (4B)** if your hardware/quantization budget allows And for speed on CPU/edge, consider running them via **CTranslate2**.",
              "score": 3,
              "created_utc": "2026-02-10 02:32:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r16iqd",
      "title": "‚ùì Introducing How2Everything‚Äîa framework for improving how LLMs generate step-by-step procedures",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/6k6hen3c7pig1.png",
      "author": "ai2_official",
      "created_utc": "2026-02-10 17:07:29",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r16iqd/introducing_how2everythinga_framework_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4re1py",
          "author": "AICodeSmith",
          "text": "The +10 point gain without capability regression is the interesting part. If that holds across domains, this could become a standard loop for training procedural reliability.",
          "score": 2,
          "created_utc": "2026-02-11 07:10:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r24er3",
      "title": "ü§ñ Introducing MolmoSpaces: A large-scale, fully open platform + benchmark for embodied AI research",
      "subreddit": "machinelearningnews",
      "url": "https://v.redd.it/qre0uoovkwig1",
      "author": "ai2_official",
      "created_utc": "2026-02-11 17:55:51",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "AI Tools",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r24er3/introducing_molmospaces_a_largescale_fully_open/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4uaa58",
          "author": "Vladiedooo",
          "text": "Is this different to what the robotics companies are doing with simulations?\n\nSame use-case or a more targeted niche?",
          "score": 1,
          "created_utc": "2026-02-11 18:17:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyptz8",
      "title": "Super-light, 90ms latency, runs locally on Apple Silicon. More expressive and prosodic than Elevenlabs.",
      "subreddit": "machinelearningnews",
      "url": "https://v.redd.it/pb6q4xf215ig1",
      "author": "EmbarrassedAsk2887",
      "created_utc": "2026-02-07 21:22:16",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "AI Tools",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qyptz8/superlight_90ms_latency_runs_locally_on_apple/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o46h6f3",
          "author": "ggone20",
          "text": "Don‚Äôt see the tts model anywhere. Model seem worth playing with though.",
          "score": 1,
          "created_utc": "2026-02-08 01:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47uzob",
          "author": "somesortapsychonaut",
          "text": "In a weird way, the polished visuals take away from believing this will be good",
          "score": 1,
          "created_utc": "2026-02-08 07:38:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47yao7",
              "author": "EmbarrassedAsk2887",
              "text": "the visuals are theatrics for some but for us is actually useful, but i added suppprt for audio fading, spectrogram analysis, and enveloping of multiple generations together to actually give a speech studio experience.\n\nthe TTS is just phenomenal enough to make it better",
              "score": 1,
              "created_utc": "2026-02-08 08:08:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qzy8zf",
      "title": "Meet OAT: The New Action Tokenizer Bringing LLM-Style Scaling and Flexible, Anytime Inference to the Robotics World",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/08/meet-oat-the-new-action-tokenizer-bringing-llm-style-scaling-and-flexible-anytime-inference-to-the-robotics-world/",
      "author": "ai-lover",
      "created_utc": "2026-02-09 07:50:09",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qzy8zf/meet_oat_the_new_action_tokenizer_bringing/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qxpo03",
      "title": "The adolescence of technology: Dario Amodei‚Äôs warning about powerful AI",
      "subreddit": "machinelearningnews",
      "url": "https://www.darioamodei.com/essay/the-adolescence-of-technology#top",
      "author": "Euphoric_Network_887",
      "created_utc": "2026-02-06 18:28:12",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Startup News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qxpo03/the_adolescence_of_technology_dario_amodeis/",
      "domain": "darioamodei.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r0utap",
      "title": "Reservoir computing on an analog Rydberg-atom quantum computer",
      "subreddit": "machinelearningnews",
      "url": "https://aws.amazon.com/de/blogs/quantum-computing/reservoir-computing-on-an-analog-rydberg-atom-quantum-computer/",
      "author": "donutloop",
      "created_utc": "2026-02-10 07:55:09",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial :doge:",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r0utap/reservoir_computing_on_an_analog_rydbergatom/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r0am7k",
      "title": "New: A web demo to make using DR Tulu even simpler üîé",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/9i2xppn90iig1.png",
      "author": "ai2_official",
      "created_utc": "2026-02-09 17:33:11",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ML/CV/DL News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r0am7k/new_a_web_demo_to_make_using_dr_tulu_even_simpler/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qz5i5f",
      "title": "How to Design Production-Grade Mock Data Pipelines Using Polyfactory with Dataclasses, Pydantic, Attrs, and Nested Models",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/08/how-to-design-production-grade-mock-data-pipelines-using-polyfactory-with-dataclasses-pydantic-attrs-and-nested-models/",
      "author": "ai-lover",
      "created_utc": "2026-02-08 10:22:41",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial :doge:",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1qz5i5f/how_to_design_productiongrade_mock_data_pipelines/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r2ofnb",
      "title": "Reservoir computing experiment - a Liquid State Machine with simulated \nbiological constraints (hormones, pain, plasticity)",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1r2ofnb/reservoir_computing_experiment_a_liquid_state/",
      "author": "Amazing-Wear84",
      "created_utc": "2026-02-12 08:50:34",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "Built a reservoir computing system (Liquid State Machine) as a learning experiment. Instead of a standard static reservoir, I added biological simulation layers on top to see how constraints affect behavior.\n\nWhat it actually does (no BS):\n\n\\- LSM with 2000+ reservoir neurons, Numba JIT-accelerated\n\n\\- Hebbian + STDP plasticity (the reservoir rewires during runtime)\n\n\\- Neurogenesis/atrophy  reservoir can grow or shrink neurons dynamically\n\n\\- A hormone system (3 floats: dopamine, cortisol, oxytocin) that modulates learning rate,   reflex sensitivity, and noise injection\n\n\\- Pain : gaussian noise injected into reservoir state, degrades performance\n\n\\- Differential retina (screen capture ‚Üí |frame(t) - frame(t-1)|) as input\n\n\\- Ridge regression readout layer, trained online\n\n\n\nWhat it does NOT do:\n\n\\- It's NOT a general intelligence but you should integrate LLM in future (LSM as main brain  and LLM as second brain)\n\n\\- The \"personality\" and \"emotions\" are parameter modulation, not emergent\n\nWhy I built it:\n\nwanted to explore whether adding biological constraints (fatigue, pain,hormone cycles) to a reservoir computer creates interesting dynamics vs a vanilla LSM. It does the system genuinely behaves differently based on its \"state.\" Whether that's useful is debatable.\n\n14 Python modules, \\~8000 lines, runs fully local (no APIs).\n\nGitHub: [https://github.com/JeevanJoshi2061/Project-Genesis-LSM.git](https://github.com/JeevanJoshi2061/Project-Genesis-LSM.git)\n\nCurious if anyone has done similar work with constrained reservoir computing or bio-inspired dynamics.",
      "is_original_content": false,
      "link_flair_text": "AI Event",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r2ofnb/reservoir_computing_experiment_a_liquid_state/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r27pxm",
      "title": "ü§ñ Introducing MolmoSpaces: A large-scale, fully open platform + benchmark for embodied AI research",
      "subreddit": "machinelearningnews",
      "url": "https://v.redd.it/5snapgjd7xig1",
      "author": "ai2_official",
      "created_utc": "2026-02-11 19:54:55",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r27pxm/introducing_molmospaces_a_largescale_fully_open/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r396zw",
      "title": "OpenAI Releases a Research Preview of GPT‚Äë5.3-Codex-Spark: A 15x Faster AI Coding Model Delivering Over 1000 Tokens Per Second on Cerebras Hardware",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2026/02/12/openai-releases-a-research-preview-of-gpt-5-3-codex-spark-a-15x-faster-ai-coding-model-delivering-over-1000-tokens-per-second-on-cerebras-hardware/",
      "author": "ai-lover",
      "created_utc": "2026-02-12 23:33:13",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1r396zw/openai_releases_a_research_preview_of/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    }
  ]
}