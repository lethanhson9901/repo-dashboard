{
  "metadata": {
    "last_updated": "2026-01-04 05:29:58",
    "time_filter": "week",
    "subreddit": "machinelearningnews",
    "total_items": 7,
    "total_comments": 11,
    "file_size_bytes": 26425
  },
  "items": [
    {
      "id": "1py7ud5",
      "title": "LLaMA-3.2-3B fMRI-style probing: discovering a bidirectional ‚Äúconstrained ‚Üî expressive‚Äù control direction",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1py7ud5/llama323b_fmristyle_probing_discovering_a/",
      "author": "Due_Hunter_4891",
      "created_utc": "2025-12-29 00:49:46",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "I‚Äôve been building a small interpretability tool that does fMRI-style visualization and *live hidden-state intervention* on local models. While exploring LLaMA-3.2-3B, I noticed one hidden dimension (layer 20, dim \\~3039) that consistently stood out across prompts and timesteps.\n\nI then set up a simple Gradio UI to **poke that single dimension during inference** (via a forward hook) and swept epsilon in both directions.\n\nWhat I found is that this dimension appears to act as a **global control axis** rather than encoding specific semantic content.\n\n# Observed behavior (consistent across prompts)\n\nBy varying epsilon on this one dim:\n\n* **Negative Œµ**:\n   * outputs become restrained, procedural, and instruction-faithful\n   * explanations stick closely to canonical structure\n   * less editorializing or extrapolation\n* **Positive Œµ**:\n   * outputs become more verbose, narrative, and speculative\n   * the model adds framing, qualifiers, and audience modeling\n   * responses feel ‚Äúless reined in‚Äù even on factual prompts\n\nCrucially, this holds across:\n\n* conversational prompts\n* factual prompts (chess rules, photosynthesis)\n* recommendation prompts\n\nThe effect is smooth, monotonic, and bidirectional.\n\nhttps://preview.redd.it/v7iz4o25j1ag1.png?width=1526&format=png&auto=webp&s=0f1ff91637a03f6a5d937680cf1b3b90ba2f481c\n\nhttps://preview.redd.it/yas1tn25j1ag1.png?width=1526&format=png&auto=webp&s=99e7dda673885ee83c21a95999b9747c32d9ff51\n\nhttps://preview.redd.it/3jbde135j1ag1.png?width=1526&format=png&auto=webp&s=09f4add0b056efe344e9993b8cb1b1585f917a9c\n\nhttps://preview.redd.it/o67kaq25j1ag1.png?width=1526&format=png&auto=webp&s=0ff66e6b4b4e517731e614e8d5242251ff15db60\n\nhttps://preview.redd.it/u11v1q25j1ag1.png?width=1526&format=png&auto=webp&s=8f106a962283558e6ebec0f30613a39bf278e853\n\nhttps://preview.redd.it/cp29cq25j1ag1.png?width=1526&format=png&auto=webp&s=2b54d0b8d75113aec3445aad448462a0f1fd1b65\n\nhttps://preview.redd.it/mm05qr25j1ag1.png?width=1526&format=png&auto=webp&s=435ff18d9b651644f473e3573a344ac7db98690f\n\nhttps://preview.redd.it/esb4nq25j1ag1.png?width=1526&format=png&auto=webp&s=bb80f504314eba77574500e4e049945d1ef7cf5a\n\n  \n",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1py7ud5/llama323b_fmristyle_probing_discovering_a/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "nwkps7a",
          "author": "somesortapsychonaut",
          "text": "Cool!",
          "score": 1,
          "created_utc": "2025-12-29 17:13:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl57uu",
          "author": "dalaigamma",
          "text": "you‚Äôve come across the concept of steering, good stuff",
          "score": 1,
          "created_utc": "2025-12-29 18:25:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzqdyd",
      "title": "Alibaba Tongyi Lab Releases MAI-UI: A Foundation GUI Agent Family that Surpasses Gemini 2.5 Pro, Seed1.8 and UI-Tars-2 on AndroidWorld",
      "subreddit": "machinelearningnews",
      "url": "https://www.marktechpost.com/2025/12/30/alibaba-tongyi-lab-releases-mai-ui-a-foundation-gui-agent-family-that-surpasses-gemini-2-5-pro-seed1-8-and-ui-tars-2-on-androidworld/",
      "author": "ai-lover",
      "created_utc": "2025-12-30 18:54:11",
      "score": 13,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Cool Stuff",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1pzqdyd/alibaba_tongyi_lab_releases_maiui_a_foundation/",
      "domain": "marktechpost.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1pzi6xo",
      "title": "Llama 3.2 3B fMRI - findings update!",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1pzi6xo/llama_32_3b_fmri_findings_update/",
      "author": "Due_Hunter_4891",
      "created_utc": "2025-12-30 13:31:16",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Sorry, no fancy pictures today :(\n\nI tried hard ablation (zeroing) of the target dimension and saw no measurable effect on model output.\n\nHowever, targeted perturbation of the same dimension reliably modulates behavior. This strongly suggests the signal is part of a distributed mechanism rather than a standalone causal unit.\n\nI‚Äôm now pivoting to tracing correlated activity across dimensions (circuit-level analysis). Next step is measuring temporal co-activation with the target dim across tokens, focusing on correlation rather than magnitude, to map the surrounding circuit (‚Äúconstellation‚Äù) that moves together.\n\nTurns out the cave goes deeper. Time to spelunk.",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1pzi6xo/llama_32_3b_fmri_findings_update/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pz01z9",
      "title": "Roast my Career Strategy: 0-Exp CS Grad pivoting to \"Agentic AI\" (4-Month Sprint)",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1pz01z9/roast_my_career_strategy_0exp_cs_grad_pivoting_to/",
      "author": "Substantial_Sky_8167",
      "created_utc": "2025-12-29 22:19:41",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 0.89,
      "text": "Roast my Career Strategy: 0-Exp CS Grad pivoting to \"Agentic AI\" (4-Month Sprint)\n\n\n\nI am a Computer Science senior graduating in May 2026. I have 0 formal internships, so I know I cannot compete with Senior Engineers for traditional Machine Learning roles (which usually require Masters/PhD + 5 years exp).\n\n\n\n\\> \\*\\*My Hypothesis:\\*\\*\n\n\\> The market has shifted to \"Agentic AI\" (Compound AI Systems). Since this field is <2 years old, I believe I can compete if I master the specific \"Agentic Stack\" (Orchestration, Tool Use, Planning) rather than trying to be a Model Trainer.\n\n\n\nI have designed a 4-month \"Speed Run\" using O'Reilly resources. I would love feedback on if this stack/portfolio looks hireable.\n\n\n\n\\## 1. The Stack (O'Reilly Learning Path)\n\n\\* \\*\\*Design:\\*\\* \\*AI Engineering\\* (Chip Huyen) - For Eval/Latency patterns.\n\n\\* \\*\\*Logic:\\*\\* \\*Building GenAI Agents\\* (Tom Taulli) - For LangGraph/CrewAI.\n\n\\* \\*\\*Data:\\*\\* \\*LLM Engineer's Handbook\\* (Paul Iusztin) - For RAG/Vector DBs.\n\n\\* \\*\\*Ship:\\*\\* \\*GenAI Services with FastAPI\\* (Alireza Parandeh) - For Docker/Deployment.\n\n\n\n\\## 2. The Portfolio (3 Projects)\n\nI am building these linearly to prove specific skills:\n\n\n\n1.  \\*\\*Technical Doc RAG Engine\\*\\*\n\n\\* \\*Concept:\\* Ingesting messy PDFs + Hybrid Search (Qdrant).\n\n\\* \\*Goal:\\* Prove Data Engineering & Vector Math skills.\n\n\n\n2.  \\*\\*Autonomous Multi-Agent Auditor\\*\\*\n\n\\* \\*Concept:\\* A Vision Agent (OCR) + Compliance Agent (Logic) to audit receipts.\n\n\\* \\*Goal:\\* Prove Reasoning & Orchestration skills (LangGraph).\n\n\n\n3.  \\*\\*Secure AI Gateway Proxy\\*\\*\n\n\\* \\*Concept:\\* A middleware proxy to filter PII and log costs before hitting LLMs.\n\n\\* \\*Goal:\\* Prove Backend Engineering & Security mindset.\n\n\n\n\\## 3. My Questions for You\n\n1.  Does this \"Portfolio Progression\" logically demonstrate a Senior-level skill set despite having 0 years of tenure?\n\n2.  Is the 'Secure Gateway' project impressive enough to prove backend engineering skills?\n\n3.  Are there mandatory tools (e.g., Kubernetes, Terraform) missing that would cause an instant rejection for an \"AI Engineer\" role?\n\n\n\n\\*\\*Be critical. I am a CS student soon to be a graduateÔøΩdo not hold back on the current plan.\\*\\*\n\n\n\nAny feedback is appreciated!",
      "is_original_content": false,
      "link_flair_text": "Agentic AI",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1pz01z9/roast_my_career_strategy_0exp_cs_grad_pivoting_to/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": [
        {
          "id": "nwswxa2",
          "author": "SeattleChrisCode",
          "text": "I'm watching for responses.",
          "score": 3,
          "created_utc": "2025-12-30 21:29:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtsauk",
          "author": "Exotic-Mongoose2466",
          "text": "From what I understand, you plan to learn the basics of machine learning (AI engineering is based on ML + ML-OPS) in less than 4 months?\nIt takes 2 years just for the basics of ML, and ML-OPS is senior-level.\n\nYou want to level the playing field with people who are either experienced developers, experienced data scientists, or ML engineers in just 4 months?\n4 months to learn what you want won't be enough.\n\nAnd 4 months to complete 3 projects won't demonstrate senior-level or even intermediate-level work at all.\nIf you're spending 4 months on 3 projects, it means you haven't planned any proper structure (industrialization, automation, infrastructure, etc.) for them.\n\nThey'll just be junior side projects.\n\nFocus on aiming for jobs that match your experience and skill level (junior) rather than aiming for intermediate or senior positions, and you'll be fine.\n\nPS: Your basic calculation is incorrect and shows that you're definitely a junior.\n\nThe tools are less than two years old, but the underlying logic is much older.\n\nThe tools can be learned very quickly when you understand the logic behind them.",
          "score": 3,
          "created_utc": "2025-12-31 00:10:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8umrr",
              "author": "That_Ability_7126",
              "text": "It really depends on the person but 4 months is very aggressive but in my opinion it really depends on his foundation and ‚Äúsmarts‚Äù",
              "score": 1,
              "created_utc": "2026-01-02 12:50:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxa84fu",
                  "author": "Jakamo77",
                  "text": "No the smartest people in the world are spending years in this field. Ur not gonna be competing with 4 months even if ur smarter than ur competition. Iq wont bridge the learning gap from 10k-20k hours in a specific subject.",
                  "score": 1,
                  "created_utc": "2026-01-02 17:14:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvm6g8",
          "author": "Stunning_Habit_6411",
          "text": "I think you‚Äôre misunderstanding what seniority means. I am an engineer who interviews and hires developers for years, all levels. When I‚Äôm hiring for a senior role im looking for basics that you can‚Äôt learn without being a part of an organization or a team. Things like working with product managers or designers. How to manage tech debt. Did you ever have to dive into a giant 8 year old code base and do some infra work?\n\nThe language and tool usage are important but it‚Äôs not really the most important thing you‚Äôll bring, especially if you‚Äôre a smart person and more importantly in a world of coding agents.\n\nFinish your project, I think it‚Äôs great and would definitely put you ahead of other juniors. But it won‚Äôt make you look senior, I‚Äôm sorry.\n\nKeep this attitude of learning and building your skills. If you do you‚Äôll have a great career. \n\nGood luck with the job search. It‚Äôs not a great time to be a junior dev I know, but it‚Äôs possible, the opportunities are out there and it sounds like you‚Äôre ready to work hard for it so i will allow myself to predict you‚Äôll be a great engineer very soon.\n\nEdits: I tried to be clearer üòÖ",
          "score": 2,
          "created_utc": "2025-12-31 07:17:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx4jx12",
          "author": "TomatoInternational4",
          "text": "The idea that you need to show what you can do is sound. The things chatgpt chose for you to do make no sense though. They are generic, low effort, hype word projects that don't actually mean anything.\n\n If you really want to get a good job then I would first try to show consistent and enthusiastic work in the field. This means your portfolio or GitHub should be active and show a history of things you've been working on. The asterisk here is that you should work on things you truly find interesting. None of this generic RAG chatbot crap. If you make sure you're creating things you enjoy making it will naturally show through your work. You'll be able to talk about it without effort and in great detail. People will see you're happy doing it, it excites you, and there is a drive within you to do it. \n\nThe degree isn't meaningless either. It just comes second to showing people what you can do. Your portfolio is your chance to shine so you don't want to half ass it with AI. Take your time on it and make it pretty. \n\nYour job right now is to compel the client or employer to hire you.",
          "score": 2,
          "created_utc": "2026-01-01 19:27:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1zr89",
          "author": "notAllBits",
          "text": "I agree that LLMs can accelerate pointed learning, but the internalized knowledge from personal experience is not sped up by it without considerable engagement. Your coverage is very thin and does not reflect senior level ambition or knowledge. Agentic orchestration does not operate as an alternative to the old way of doing things, it is at best an extension with deep stack dependencies and unprecedented regulatory overhead. Having said that, here some tips:\n\nThis field is currently under very high pressure to innovate, both from LLM capability directly (learning, coding) and their integration into higher level services (value generation).\n\nYou need a stack to orchestrate. A future-stable stack, which does not amount to much these days.\n\nUtilize hyper-scalers. Get accustomed with deploying with IaC (fx. terraform modules) to Amazon or Google or Azure. Their inertia will provide the deepest grooves against dependency rot and tech debt in these accelerated technologies. \n\nThink about how to build genAI systems compliant with internal idiosyncrasies and heritage and external regulation in repetitive planning exercises. Pick old technologies and assume flawed system architecture and blocked upgrade paths due to abandoned products and a history of abandoned modernization projects. Develop a sense of smell for those to steer clear of them. \n\nThink about how you would implement compliant orchestration systems using off the shelf tech and services. There will always be both internal and external governance and constraints. LLMs are mediocre at identifying these and fail at comprehensive work on them, because of scaling complexity, diversity, and privileged use case access. \n\nFigure out a way to utilize systems design to operationalize complexity. Pick a field, catalogue its constraints, and design solutions for it as a strategic role play, where you explore possible synergies and solutions for each and all. LLMs can help here if you are disciplined with it. Beware, they will like to convince you very early of poor solutions being sufficient. LLMOps is deeply integrated with local and cloud architecture (deep grooves).\n\nPlay with synthetic data and budget calculations to identify gaps, bottlenecks and service cost scaling.\n\nManual devOps steps such as \"deploying with docker\" do not represent backend expertise; they look either naive, or ancient. This step should be embedded into automated pipelines. Deployment is gated on several layers for secure, compliant, and reliable releases, where the actions on the targeted machines should be completely automatic. At the very least also list CI/CD, development stages with dedicated isolated landing zones, and managed services. Similarly gateways are hyper-scrutinized attack vector nodes. Mentioning them will trigger immune-response follow ups like: where in our cloud is it deployed? And who can connect to what when?     \n\nLast, but certainly not least: orchestration is not free of legacy concerns, it is extending all the old- alongside a set of new concerns into an under-integrated (unstable tech landscape) and under-regulated (will follow) service space. Cover your basics before diving into orchestration. In regulated businesses you may be responsible personally for designs you sign off on.\n\nedits: clarifications",
          "score": 1,
          "created_utc": "2026-01-01 08:56:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8hq2p",
          "author": "DmitryPavol",
          "text": "What will you do when, in a couple of years, there is a breakthrough in quantum computers and there is a shortage of quantum programmers, and you have already spent time and energy on AI?",
          "score": 1,
          "created_utc": "2026-01-02 11:04:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa0p8t",
          "author": "Muted_Ad6114",
          "text": "Maybe don‚Äôt trust ChatGPT with your career plan",
          "score": 1,
          "created_utc": "2026-01-02 16:39:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxapy6s",
          "author": "AsukaMLEnjoyer",
          "text": "Have you considered Georgia Tech's [OMSCS](https://pe.gatech.edu/degrees/computer-science) program where they offer a MSCS degree for under $10k online? \n\nThat program has a Machine Learning specialization. This education alone won't land a new job but it will make your resume more marketable when combined with projects, certifications, and any relevant job experiences.\n\nHunt for an internship or software role and further specialize in your downtime. Employers want to see proven experience.",
          "score": 1,
          "created_utc": "2026-01-02 18:36:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbjzq2",
          "author": "peterxsyd",
          "text": "Basically you will get arse fucked by AI, and look like a complete tool in the process. People who are hyper productive with AI are the ones who know when to say no to it, and, my experience has been, on non-trivial projects requiring it, is roughly 30-50% of the time, with the rest spent steering it and providing context for it to perform really well.\n\nInvest that time learning and building things either yourself or for an average company first so you can get the fundamentals otherwise you are lost poor child.",
          "score": 1,
          "created_utc": "2026-01-02 21:00:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q17yu4",
      "title": "Llame 3.2 3B fMRI LOAD BEARING DIM FOUND",
      "subreddit": "machinelearningnews",
      "url": "https://www.reddit.com/r/machinelearningnews/comments/1q17yu4/llame_32_3b_fmri_load_bearing_dim_found/",
      "author": "Due_Hunter_4891",
      "created_utc": "2026-01-01 16:21:16",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.75,
      "text": "I‚Äôve been building a local interpretability toolchain to explore **hidden-dimension coupling** in small LLMs (Llama-3.2-3B-Instruct). This started as visualization (‚Äúconstellations‚Äù of co-activating dims), but the visuals alone were too noisy to move beyond theory.\n\nSo I rebuilt the pipeline to answer a more specific question:\n\n>\n\n# TL;DR\n\nYes.  \nAnd perturbing the top one causes **catastrophic loss of semantic commitment** while leaving fluency intact.\n\n# Step 1 ‚Äî Reducing noise upstream (not in the renderer)\n\nInstead of rendering everything, I tightened the experiment:\n\n* **Deterministic decoding** (no sampling)\n* **Stratified prompt suite** (baseline, constraints, reasoning, commitment, transitions, etc.)\n* **Event-based logging**, not frame-based\n\nI only logged events where:\n\n* the hero dim was **active**\n* the hero dim was **moving** (std gate)\n* Pearson correlation with another dim was **strong**\n* polarity relationship was consistent\n\nMetrics logged per event:\n\n* Pearson correlation (centered)\n* Cosine similarity (raw geometry)\n* Dot/energy\n* Polarity agreement\n* Classification: `FEATURE` (structural) vs `TRIGGER` (functional)\n\nThis produced a *hostile filter*: most dims disappear unless they matter repeatedly.\n\n# Step 2 ‚Äî Persistence analysis across runs\n\nInstead of asking ‚Äúwhat lights up,‚Äù I counted:\n\n>\n\nThe result was a sharp hierarchy, not a cloud.\n\nTop hits (example):\n\n* **DIM 1731 ‚Äî \\~14k hits**\n* **DIM 221 ‚Äî \\~10k hits**\n* then a steep drop-off into the long tail\n\nThis strongly suggests a **small structural core** \\+ many conditional ‚Äúguest‚Äù dims.\n\n# Step 3 ‚Äî Causal test (this is the key part)\n\nI then built a small UI to **intervene on individual hidden dimensions** during generation:\n\n* choose layer\n* choose dim\n* apply epsilon bias (not hard zero)\n* apply to attention output + MLP output\n\nWhen I biased **DIM 1731** (layer \\~20) with Œµ ‚âà +3:\n\n* grammar stayed intact\n* tokens kept flowing\n* **semantic commitment collapsed**\n* reasoning failed completely\n* output devolved into repetitive, affect-heavy, indecisive text\n\nThis was *not* random noise or total model failure.  \nIt looks like the model can still ‚Äútalk‚Äù but **cannot commit to a trajectory**.\n\nThat failure mode was consistent with what the persistence analysis predicted.\n\n# Interpretation (carefully stated)\n\nDIM 1731 does *not* appear to be:\n\n* a topic neuron\n* a style feature\n* a lexical unit\n\nIt behaves like part of a **decision-stability / constraint / routing spine**:\n\n* present whenever the hero dim is doing real work\n* polarity-stable\n* survives across prompt classes\n* causally load-bearing when perturbed\n\nI‚Äôm calling it ‚ÄúThe King‚Äù internally because removing or overdriving it destabilizes everything downstream ‚Äî but that‚Äôs just a nickname, not a claim.\n\n# Why I think this matters\n\n* This is a concrete example of **persistent, high-centrality hidden dimensions**\n* It suggests a path toward:\n   * targeted pruning\n   * hallucination detection (hero activation without core engagement looks suspect)\n   * mechanistic comparison across models\n* It bridges visualization ‚Üí aggregation ‚Üí **causal confirmation**\n\nI‚Äôm not claiming universality or that this generalizes yet.  \nNext steps are sign-flip tests, ablations on the next-ranked dim (‚Äúthe Queen‚Äù), and cross-model replication.\n\nHappy to hear critiques, alternative explanations, or suggestions for better controls.\n\n*(Screenshots attached below ‚Äî constellation persistence, hit distribution, and causal intervention output.)*\n\nDIM 1731: 13,952 hits (The King)\n\nDIM 221: 10,841 hits (The Queen)\n\nDIM 769: 4,941 hits\n\nDIM 1935: 2,300 hits\n\nDIM 2015: 2,071 hits\n\nDIM 1659: 1,900 hits\n\nDIM 571: 1,542 hits\n\nDIM 1043: 1,536 hits\n\nDIM 1283: 1,388 hits\n\nDIM 642: 1,280 hits\n\nhttps://preview.redd.it/qzd0agu1krag1.png?width=1542&format=png&auto=webp&s=1f4ca0fc58909bbd0c51ef28643b0c082c633e56\n\n",
      "is_original_content": false,
      "link_flair_text": "Research",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1q17yu4/llame_32_3b_fmri_load_bearing_dim_found/",
      "domain": "self.machinelearningnews",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q35wec",
      "title": "I took Bernard Widrow‚Äôs machine learning & neural networks classes in the early 2000s. Some recollections.",
      "subreddit": "machinelearningnews",
      "url": "https://i.redd.it/uncdscf2x6bg1.png",
      "author": "DueKitchen3102",
      "created_utc": "2026-01-03 20:56:44",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ML/CV/DL News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1q35wec/i_took_bernard_widrows_machine_learning_neural/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q2ntdf",
      "title": "Autonomous Dodging of Stochastic-Adversarial Traffic Without a Safety Driver",
      "subreddit": "machinelearningnews",
      "url": "https://youtu.be/JGN-HXj1K3w",
      "author": "shani_786",
      "created_utc": "2026-01-03 06:53:54",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Startup News",
      "permalink": "https://reddit.com/r/machinelearningnews/comments/1q2ntdf/autonomous_dodging_of_stochasticadversarial/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    }
  ]
}