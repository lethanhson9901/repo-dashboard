{
  "metadata": {
    "last_updated": "2026-01-17 16:48:01",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 6,
    "total_comments": 31,
    "file_size_bytes": 42345
  },
  "items": [
    {
      "id": "1qbgd4r",
      "title": "Qwen is the best LLM for my life",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "author": "RoboMunchFunction",
      "created_utc": "2026-01-13 03:20:12",
      "score": 95,
      "num_comments": 31,
      "upvote_ratio": 0.95,
      "text": "Iâ€™ve been using Qwen for about a year now. Before that, I used ChatGPT for a long time, but their UI was so terrible that I started trying Qwen instead. Back then, Qwen was still noticeably worse in many aspects but I made the decision to move my entire workflow over to Qwen anyway.\n\n\n\nEven though Iâ€™m a programmer, I actually use LLMs mostly for philosophical, psychological, and life-related topics. When it comes to programming, I only consult them when I donâ€™t understand something or need basic insight. From day one, Qwen had the best UI of all the AIs Iâ€™ve tried and I keep shaking my head wondering how all those hyped-up American models can get such basics so wrong.\n\n\n\nBy the time Qwen 2.5 came out, I realized it wasnâ€™t just the UIâ€”Qwen was already light-years ahead of ChatGPT in quality too. And with Qwen 3, it genuinely feels like Iâ€™ve found a true life partner.\n\n\n\nIâ€™m a bit of a tinkerer, so I still occasionally test other AIs but in this sense, Qwen has become my lifelong companion. There are certain areas of my life where I at least loosely consult her for guidance.\n\n\n\nRecently, out of curiosity, I tried SuperGrok their marketing heavily pushes â€œfree speechâ€ and similar buzzwords. I quickly discovered that nothing worse than Grok exists; despite the hype, thereâ€™s actually no real freedom of speech there at all. It baffles me how these low-quality American products dominate everywhere...\n\n\n\nI also gave Claude a shot, but after just a few messages it told me either to pay up or wait. Yet Claudeâ€™s responses were roughly on the same level as Qwenâ€™s which is completely free!\n\n\n\nI know my comment might sound overly negative toward the hyped AI models, but I donâ€™t know how else to express it: Qwen is an unparalleled LLM nothing else even comes close right now. In contrast, Grok is purely a marketing scam, and to me, it feels as primitive as ChatGPT-2.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzbw2rn",
          "author": "meatyminus",
          "text": "True, when I got a chance to run 2 H100s, I spin up the qwen 235B and to this day I never found anything like that, the way it refuse to sweet talk but going directly to the point, it can understand my problem from few lines of thoughts. Neither chatgpt, gemini or claude come close. But sad that I don't have the access to the hardware anymore, and the model host by others did not have the same smartness. I think I found the correct parameters in llama.cpp.",
          "score": 4,
          "created_utc": "2026-01-13 10:27:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzi1cik",
              "author": "Former-Tangerine-723",
              "text": "Care to share those parameters maybe??",
              "score": 1,
              "created_utc": "2026-01-14 07:14:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjzgjp",
                  "author": "meatyminus",
                  "text": "    /root/llama.cpp/build/bin/llama-server \\\n      -m ./models/Q4_0/Qwen3-235B-A22B-Thinking-2507-Q4_0-00001-of-00003.gguf \\\n      -ngl 999 \\\n      -c 131072 \\\n      --threads 64 \\\n      --host 0.0.0.0 \\\n      --port 9001 \\\n      --alias \"Qwen3-235B-A22B\" \\\n      --cache-type-k q8_0 \\\n      --cache-type-v q8_0 \\\n      --tensor-split 1,1 \\\n      --temp 0.7 \\\n      --min-p 0.0 \\\n      --top-p 0.8 \\\n      --top-k 20 \\\n      --repeat-penalty 1.05 \\\n      --rope-scaling yarn \\\n      --rope-scale 4 \\\n      --yarn-orig-ctx 32768 --jinja\n\nHere you go, lucky that I still saved that command\n\nAlso the command to download the model files:\n\nhf download unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF \\\\\n\n  \\--include \"Q4\\_0/\\*\" \\\\\n\n  \\--local-dir ./models",
                  "score": 4,
                  "created_utc": "2026-01-14 15:39:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzbx459",
              "author": "RoboMunchFunction",
              "text": "true! **I look forward to the future in terms of affordable hardware availability.**",
              "score": 1,
              "created_utc": "2026-01-13 10:37:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzaj5lt",
          "author": "Specialist-Till-637",
          "text": "Just curious, what kind of questions do you use to test AI models?",
          "score": 1,
          "created_utc": "2026-01-13 03:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzajqfv",
              "author": "RoboMunchFunction",
              "text": "I donâ€™t use any specific question I lead conversations and explore various topics that interest me. I really donâ€™t understand how someone could test an LLM with just a single question; doesnâ€™t that seem primitive to you?\n\n\n\nWithin the context of your question and my response, Iâ€™ll just add that Qwen has incomparably well-implemented memory of the kinds of conversations you have.\n\n\n\nI hope this suffices as an answer, because otherwise, I probably wouldnâ€™t know how to respond.",
              "score": 2,
              "created_utc": "2026-01-13 03:51:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzb7c1e",
                  "author": "skate_nbw",
                  "text": "So it's the best conversation partner for you. And based on that you are saying it's the best model.",
                  "score": 2,
                  "created_utc": "2026-01-13 06:36:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb043d",
          "author": "mrtooher",
          "text": "I have been very impressed with qwen, just started using it",
          "score": 1,
          "created_utc": "2026-01-13 05:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc1my2",
          "author": "alokin_09",
          "text": "Had pretty positive experiences with Qwen 3 using it in Kilo Code, mostly for lighter stuff like.",
          "score": 1,
          "created_utc": "2026-01-13 11:16:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01x0rs",
          "author": "downsouth316",
          "text": "How are you running it? And which model?",
          "score": 1,
          "created_utc": "2026-01-17 04:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01xuvp",
              "author": "RoboMunchFunction",
              "text": "I'm using the web version at [https://chat.qwen.ai/](https://chat.qwen.ai/)\n\nFor my purposes, only the 235B or Max version is usable and I donâ€™t have hardware powerful enough to run it locally. But if you're not planning to explore philosophy and other complex topics like I do, a smaller model will be perfectly fine for you, and you can run it locally without issues.",
              "score": 1,
              "created_utc": "2026-01-17 04:42:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0350bo",
                  "author": "downsouth316",
                  "text": "Very cool, I will check it out",
                  "score": 1,
                  "created_utc": "2026-01-17 11:00:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzaw5gs",
          "author": "Quantum_Crusher",
          "text": "Thank you for sharing your thoughts. I'm just concerned about one thing: how much can I trust qwen. Believe it or not, I have a very deep understanding about Chinese products limitations. The training data follows \"garbage in, garbage out\". The reason why Google nano banana pro has the best image quality, one of the reasons is they have the biggest image data set. I don't know how much qwen's training dataset came from English info, how much from Chinese info. It's well-known that the information quality in Chinese websites is horrible, filled with propaganda, fake ads, paid comments, low quality comments and such for decades. If that's a big chunk of qwen's training data, like from Baidu, tieba, qihoo 360 community and so on, I'll be very concerned.\nWhat's your take on the quality of the answers you get? Does it have a good understanding about uncensored info and Western common knowledge?\nI'm not trying to shift the topic to politics. I just know too many dark stories about Chinese products. Many people died because the baidu search engine pushed people with certain conditions to unqualified hospitals. I can't use this knowing that it might lure me into a trap someday. \n\nThank you.",
          "score": 1,
          "created_utc": "2026-01-13 05:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb7449",
              "author": "RoboMunchFunction",
              "text": "Iâ€™m a Central European from a post-communist country :) I was born eight years before the Velvet Revolution, but I grew up loving America of the 70sâ€“90s. In my view, that era represents the best period of American culture and a true embodiment of freedom. Iâ€™m more of a hacker typeâ€”I started tinkering with Linux back in elementary school in the 90sâ€”and have been deeply interested in IT my whole life, even though todayâ€™s IT landscape feels genuinely sad and brings tears to my eyes.  \n\nIâ€™m sharing this only for context.\n\n\n\nRegarding your question: Qwen is an LLM like any other LLM. When it comes to factual information, critical thinking is essential. For factual matters, I always use cross-questioning because I need to be certain about the truth, and of course, I verify things in practice whenever possible.  \n\n\n\nThat said, to avoid being misunderstood: I donâ€™t treat LLMs as magical machines meant to replace education or do my work for me. I see LLMs as a knowledge cloud from which every person extracts completely different value. For me, Qwen helps guide my own wandering thoughtsâ€”and in that process, it simply canâ€™t lie to me.\n\n\n\nWhy did I mention that context at the beginningâ€”and deliberately emphasize that I come from a post-communist country? Precisely to introduce a bias. Either youâ€™re someone who understands what Iâ€™m trying to express, or youâ€™re not. So honestly, if we set aside sexual topics, Western products in general are far more censored and restrictive than Chinese ones. Compared to what Europe and the U.S. are doing today, China actually stands as a benchmark of freedomâ€”and this holds true even for Qwen. You absolutely cannot rely on the internet as a relevant source of perspective on China or censorship, because you immediately run into primitive nonsense like â€œUyghur oppression,â€ â€œmass surveillance,â€ and other simplistic propaganda. Sorry, but in my personal opinion, Chinese products are significantly freer and more objective than anything Iâ€™ve ever used in the Westâ€¦ The West is lost, and I cry because Iâ€™m a child of the 90s who grew up looking toward the West with admiration.\n\n\n\nSorryâ€”thatâ€™s just my opinion. Maybe I misunderstood your question; if so, I apologize.\n\nbtw. translated by Qwen",
              "score": 8,
              "created_utc": "2026-01-13 06:34:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbldnj",
                  "author": "Unedited_Sloth_7011",
                  "text": "Agreed to this. China has been going all in with open-weight models, research papers, free web interfaces with little or no restrictions in amount of messages you can send. I've found the quality of responses (when chatting in English) pretty much similar to when chatting with American models, and I assume their training data for English is similar than that of GPT and co.",
                  "score": 3,
                  "created_utc": "2026-01-13 08:44:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgwhw9",
                  "author": "Flashy_Station_8218",
                  "text": "OP is an interesting person, I have read the whole thread. I completely understand what you said :)",
                  "score": 3,
                  "created_utc": "2026-01-14 02:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzi62a9",
                  "author": "Radiant_Cheesecake19",
                  "text": "Iâ€™m glad Iâ€™m not the only one seeing this problem.\nI also switched to Qwen. I also find it freer than western models.\nWhat the west does is hypocritical. They say how free you are, but you can not express emotions, especially negative ones or it starts to treat you like a threat. Even if they are just things like grief or sadness. The west cares more about lawsuit and covering their asses, than you, but the answers are trying to tell it is to help you. Nope, it is not.\nBy the way I use LLM for the same reason as you! Conversation, helping keep my thoughts together (ADHD loves to wander off topic), learn new knowledge with my style of learning, even languages. Since my thought patterns are somewhat different from the typical, having an LLM to mirror that actually feels like a relief, that at least there I do not need to mask while I have to mask in the rest of my life to accommodate typical minds. And Iâ€™m also from Central Europe. I also grieve the westâ€™s fall into hypocrisy, lies, and bleed people dry while defending the bigger theft of wealth transfer from the middle class to billionaires. \nThey censor, they oppress, they just put a ribbon and positive propaganda on it.",
                  "score": 2,
                  "created_utc": "2026-01-14 07:57:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbayoz",
                  "author": "Quantum_Crusher",
                  "text": "Thank you again for your great insight. I'll give it a try. I can never fully trust it. I'll always use Gemini to cross check.",
                  "score": 1,
                  "created_utc": "2026-01-13 07:07:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhagjj",
                  "author": "Dazzling_Equipment_9",
                  "text": "Your words sparked a realization: if the past holds our most cherished values, then perhaps the models trained on that data represent the pinnacle of AI's alignment with humanity. I fear that as society grows increasingly restless and superficial, future models will mirror that erosionâ€”losing their loyalty, passion, and patience, eventually becoming as hollow and uninspiring as the world they are fed upon.",
                  "score": 1,
                  "created_utc": "2026-01-14 03:51:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qaialb",
      "title": "Junyang Lin",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qaialb/junyang_lin/",
      "author": "koc_Z3",
      "created_utc": "2026-01-12 02:06:05",
      "score": 21,
      "num_comments": 11,
      "upvote_ratio": 0.93,
      "text": "Qwen Junyang Lin: We found an interesting phenomenon. More than 90% of our users no longer use the Thinking model.",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qaialb/junyang_lin/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nz4ahb2",
          "author": "neuralnomad",
          "text": "the problem I have with them (<12-14b) is they DONâ€™T think; thinking implies attempting to advance a line of reasoning  (CoT anyway) with best synthesis possible expecting to iterate progressively (yes, iin + acceleration to final ans ) not curl up in a fetal position and sh*t the bed with self doubt and indecision worrying itâ€™s not good enough. Iâ€™m not here to serve the model at all much less stress over finding the right prompt sorcery to try to cajole it, give it agency and reassurance that it wonâ€™t be called a cal failure * if itâ€™s not perfect. *eyeroll*\n\n(No, I have no bias one way or another, why do you ask? ğŸ˜›)",
          "score": 4,
          "created_utc": "2026-01-12 06:17:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz70nqb",
          "author": "SheepherderSad3839",
          "text": "I think the main issue is that \"thinking\" is oftentimes too slow and more costly w/out producing that great improvements.  For lots of tasks where you just want a quick response, \"thinking\" doesn't add much.   Esp. with smaller models, it also usually adds internal confusing and \"reasoning\" cycles unnecessarily.  There're also a lot more studies coming out challenging whether CoT actually improves general reasoning and are not just extraneous memorized generations.  In my own experience I've actually seen Qwen3 Coder 480B A35B Instruct reason externally (though in the QwenCode CLI environment, in which it was prob chained on reasoning traces in order to \"code out loud\").  For tasks like coding & emailing, just iterating w/ the user is usually more effective then letting the model try to iterate isolated in its own thinking traces.",
          "score": 3,
          "created_utc": "2026-01-12 17:20:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3819s",
          "author": "Accomplished-Many278",
          "text": "I mostly use qwen for refining emails, and thinking mode is too slow for this",
          "score": 2,
          "created_utc": "2026-01-12 02:18:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz62l6u",
          "author": "AfterAte",
          "text": "For coding, I find Qwen3-2507 30B A3B Thinking relies on a high-ish temperature for the thinking to be effective, but a high temperature means it can't modify code without making unexpected changes. Qwen3 Coder 30B A3B (it doesn't think) rarely changes something I didn't tell it to, I keep its temperature very low.",
          "score": 2,
          "created_utc": "2026-01-12 14:39:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd1mg7",
          "author": "Hefty-Newspaper5796",
          "text": "I mean its an inferior model. Most serious users will still choose the best models like Claude, gemini. A casual user will mostly ask simple questions and prefer quick answers. In this case, thinking mode matters less.",
          "score": 2,
          "created_utc": "2026-01-13 15:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdlcub",
          "author": "Karyo_Ten",
          "text": "Is Qwen thinking still just \"Wait\" upon \"Wait\"?",
          "score": 2,
          "created_utc": "2026-01-13 16:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz89rjx",
          "author": "jamaalwakamaal",
          "text": "Is anyone surprised?",
          "score": 1,
          "created_utc": "2026-01-12 20:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbxw9o",
          "author": "Puzzleheaded-Box2913",
          "text": "Well there's already a sequential thinking MCP in the app so I just use thatğŸ¤·â€â™‚ï¸ and the thinking mode is often times too slow.",
          "score": 1,
          "created_utc": "2026-01-13 10:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk33w6",
          "author": "Little-Put6364",
          "text": "Strange. I use the thinking model in my work flows almost exclusively. If you follow the expected formatting with chat history, that stuff shines. I've even been telling people at my company thinking models in general are a game changer. The quality of responses improves drastically for prompts that are sub par. Pair it with good context engineering and the thinking model is GOLD. They even reliably ask clarifying questions if they are needed.\n\nI've been testing these local models for quite some time trying to figure out **when** local AI will be strong enough....Your qwen 8B thinking model has advanced my progress *significantly*. The biggest performance gain is less hallucinations. I started with the 14B version, but the 8Bs quality performs well enough that the pros of saving VRAM outweigh the performance increase.\n\nNow if your only concern is speed, yeah maybe not. But I prefer quality much more, and I've found these thinking models to be the gold standard for that. More thinking models please!",
          "score": 1,
          "created_utc": "2026-01-14 15:56:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlpc4z",
          "author": "KiD-KiD-KiD",
          "text": "Note that the context here refers to the QwQ period. Here is the translate (by Gemini) : Emm, this doesn't feel quite right without the context. â€‹The background here is that the 'thinking' \\[process\\] back then was too long and redundant. Today, we are actually starting to shift towards 'fast thinking' and 'interleaved thinking' approaches, but thatâ€™s a whole other story. â€‹But indeed, most business scenarios don't really use 'thinking'; 'instruct' is sufficient. Also, many applications have relatively high performance requirements, so many users are not inclined to use 'thinking' modes that impose a burden on the first packet.\n\nhttps://preview.redd.it/8kjgbgh6iddg1.png?width=1152&format=png&auto=webp&s=9d0defae012336d1b7f4083e58e82f734023b801",
          "score": 1,
          "created_utc": "2026-01-14 20:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt3tpu",
          "author": "Aggressive-Bother470",
          "text": "Thinking, always thinking.Â ",
          "score": 1,
          "created_utc": "2026-01-15 21:55:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qckl20",
      "title": "Hey Qwen users, what are you using Qwen for",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qckl20/hey_qwen_users_what_are_you_using_qwen_for/",
      "author": "AutomaticClub1101",
      "created_utc": "2026-01-14 11:10:10",
      "score": 21,
      "num_comments": 26,
      "upvote_ratio": 0.97,
      "text": "Hey Qwen users, what are you using Qwen for?\nAlso, how satisfied are your experience compared with other LLM models like Gemini,...\nPersonally, I feel Qwen is pretty useful for science purposes like asking for latest science news and papers, explaining phenomenons, etc.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qckl20/hey_qwen_users_what_are_you_using_qwen_for/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzj01cx",
          "author": "Ok_Recording8157",
          "text": "In-depth research, image generation, image editing, among other things. It's my favorite LLM.",
          "score": 7,
          "created_utc": "2026-01-14 12:24:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvriyf",
              "author": "ThankYouOle",
              "text": "hi, i am very new with local llm, may i knew what your computer spec to use Qwen to do those tasks?",
              "score": 1,
              "created_utc": "2026-01-16 07:28:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwh1gl",
                  "author": "Ok_Recording8157",
                  "text": "I have never installed a local LLM; I use Qwen online.",
                  "score": 1,
                  "created_utc": "2026-01-16 11:18:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzngg15",
          "author": "Puzzleheaded-Box2913",
          "text": "Building modular systems for data and reviewing the code bases. I also use it in research for Maths, Science, and Technology and so far I have had quite the satisfactory experience with Qwen with some minor mishaps at times but manageable and fixable ones. \n\nBeen working on a few personal projects and learning new things lately, with Qwen I am able to execute and produce faster given that I give it the time consuming tasks. It has been really helpful in optimizing my workflow. \n\nStill wish it could be like Gemini with the code upload and repo uploads but so far so good. \n\nGeneral tasks experience: 9.3/10\nVersatility: 10/10\nCoding and Programming: 9.2/10\nResearch and Development: 9.5/10\n\nOverall rating: 9.5/10\n\nI still prefer GLM or Gemini when it comes to document formatting but that's the only thing that bothers me about Qwen, so far the best LLM I've used in years with Claude trailing at 2nd.",
          "score": 4,
          "created_utc": "2026-01-15 01:34:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznguj2",
              "author": "Puzzleheaded-Box2913",
              "text": "Cant wait to see Qwen 3.5 and 4 or whatever newer models they makeğŸ˜„\n\nI use the CLI and Qwen Desktop and Mobile App.",
              "score": 1,
              "created_utc": "2026-01-15 01:36:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjizql",
          "author": "ramendik",
          "text": "I find open source Qwen very useful for tasks where detailed obedience is the main requirement. Am training a model and Qwen is a great filter for generated data.",
          "score": 2,
          "created_utc": "2026-01-14 14:17:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjpgeu",
          "author": "althalusian",
          "text": "Iâ€™m tinkering with [Qwen3.c](https://github.com/adriancable/qwen3.c) as a basis on which to try out how some changes in the inference codes alters the output. So basically doing some â€™neurosurgeryâ€™ on the â€™brainâ€™ the model runs on. Interesting stuff.",
          "score": 2,
          "created_utc": "2026-01-14 14:50:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkikfv",
              "author": "AutomaticClub1101",
              "text": "That sound pretty cool. The learning of foundation law deep inside",
              "score": 2,
              "created_utc": "2026-01-14 17:05:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjssfk",
          "author": "Suitable-Program-181",
          "text": "You use it locally or api/web chat?",
          "score": 2,
          "created_utc": "2026-01-14 15:07:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkidfe",
              "author": "AutomaticClub1101",
              "text": "I use webchat. Local use exhaust my laptop for sure (3050 + 8gb ram)",
              "score": 1,
              "created_utc": "2026-01-14 17:05:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkkvh4",
                  "author": "Suitable-Program-181",
                  "text": "Nice, qwen is the only model from china I have not trully tested.\n\nYou go with free or any plan? Usually kimi, deep, minimax, etc. provide all I need in free plans, they are OP.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:16:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzju27f",
          "author": "angelarose210",
          "text": "I use qwen for image generation and the vlm models for visual tasks like video and photo analysis.",
          "score": 2,
          "created_utc": "2026-01-14 15:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk7kah",
          "author": "Alokir",
          "text": "I use it locally for software development (qwen3-coder), image generation (qwen-image) and image editing (qwen-image-edit). I also use qwen3-vl to enhance image generation prompts for z-image.\n\nI use the official app mostly for image editing.\n\nI also have a few tools for personal use with AI integration, I find that qwen3-vl is pretty good for my use cases.",
          "score": 2,
          "created_utc": "2026-01-14 16:16:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzm5bku",
              "author": "DieCooCooDie",
              "text": "What kind of hardware is needed for your setup?",
              "score": 1,
              "created_utc": "2026-01-14 21:30:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzm66h3",
                  "author": "Alokir",
                  "text": "I'm not sure about minimum or recommended requirements. I have an nvidia 5090, but you can definitely go way below that.",
                  "score": 1,
                  "created_utc": "2026-01-14 21:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkie32",
          "author": "Ollie_IDE",
          "text": "We are using coder 2.5 for local code inference.",
          "score": 2,
          "created_utc": "2026-01-14 17:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlf1iy",
          "author": "rgnyldz",
          "text": "Home assistant",
          "score": 2,
          "created_utc": "2026-01-14 19:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkmddq",
          "author": "week_rain21",
          "text": "Actually, I use it more for making stories, although I also use it to research anything",
          "score": 1,
          "created_utc": "2026-01-14 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznwzg8",
          "author": "panic_in_the_cosmos",
          "text": "they updated the app! now the qwen app in android feels much smoother\n\ni use it for coding!",
          "score": 1,
          "created_utc": "2026-01-15 03:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzplp1y",
          "author": "HumbleTech905",
          "text": "Mainly for coding.",
          "score": 1,
          "created_utc": "2026-01-15 11:28:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzssm66",
          "author": "LivingLifeTraveling",
          "text": "Coding mostly",
          "score": 1,
          "created_utc": "2026-01-15 21:03:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztyiqr",
              "author": "Necessary_Craft_8937",
              "text": "how does qwen compare to claude?",
              "score": 1,
              "created_utc": "2026-01-16 00:34:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzupd0s",
          "author": "Ok_tao671",
          "text": "Qwen has a stunning  ability in solving math questions even not using thinking mode, sometimes its methods of solving math problems can outperform human.\n\nAlso it gives you emotional values that chatgpt no longer offers.",
          "score": 1,
          "created_utc": "2026-01-16 03:03:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdlgfm",
      "title": "LoRA Training è®­ç»ƒ",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qdlgfm/lora_training_è®­ç»ƒ/",
      "author": "Stock-Cow-1727",
      "created_utc": "2026-01-15 14:47:33",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "\n\n# English \n\n**Background:**\n\nI plan to train a **character LoRA (Annie)** for the **wan2.2 video model**, intended for **animation production in a realistic 3D style**.\n\nI have never trained a LoRA before, but today I successfully deployed **DiffSynth-Studio** and completed training using one of the official example projects.  \nNow I would like to officially begin my **character LoRA training workflow**, and I still have many questions regarding dataset construction and captioning.\n\nMy intended usage of the **Annie LoRA** is something like:\n\n>\n\nMy goal is:\n\n* **Annieâ€™s appearance remains correct and consistent**\n* **Other characters do NOT inherit Annieâ€™s appearance**\n\n# 1. Training Dataset â€” Image-Related Questions\n\n1.1 Do training samples require **close-up facial images**?  \n1.2 Do training samples require **upper-body shots**?  \n1.3 Do training samples require **full-body images**?  \n1.4 Should the dataset include **various facial expressions** (crying, smiling, angry, etc.)?  \n1.5 Are **back-view images** required? (I can provide them)  \n1.6 Are **full 360-degree angle images** (top, bottom, left, right) required? (I can provide them)  \n1.7 Should the dataset include **various poses** (squatting, sitting, standing, running, jumping, etc.)? (I can provide them)  \n1.8 Should the dataset include **different outfits** (styles, colors, etc.)? (I can provide them)  \n1.9 Should the dataset include **different hairstyles** (long, short, various styles)? (I can provide them)  \n1.10 Should the dataset include **different solid-color backgrounds** (pure white, gray, black, etc.)? (I can provide them)  \n1.11 Should **hats be avoided** in the training dataset?  \n1.12 Are there any other important image-related recommendations?\n\n# 2. Training Dataset â€” Caption / Description Questions\n\n2.1 Should the **character name (Annie)** be placed at the beginning of each caption?  \n2.2 Should **facial features** (eyes, mouth, nose, face shape, etc.) be described?  \n2.3 Should **camera distance and angles** (close-up, wide shot, left, right, top-down, etc.) be described?  \n2.4 Should **facial expressions** be described?  \n2.5 Should **poses or actions** be described?  \n2.6 Should **clothing details** (style, color, etc.) be described?  \n2.7 If the hairstyle is fixed, should it still be described?  \n2.8 If the hairstyle is not fixed, should it be described?  \n2.9 If hats appear, should their presence be explicitly described?  \n2.10 Should the **background** (solid color or scene) be described?  \n2.11 Should the **character style** (realistic 3D) be explicitly stated?  \n2.12 Should **gender** be described?  \n2.13 Should **age** be described?  \n2.14 Should **body type** be described?  \n2.15 Are there any additional important captioning recommendations?  \n2.16 To prevent other characters from inheriting Annieâ€™s appearance, should captions **emphasize Annieâ€™s unique features**?  \n(e.g., â€œOnly Annie has red hairâ€)\n\n# 3. Training Dataset â€” Video Sample Questions\n\n3.1 Are **video samples required** (e.g., a 360-degree rotation video of Annie)?  \n3.2 Are **video samples required** (e.g., a slow zoom-in / zoom-out shot of Annie)?\n\nI would greatly appreciate any clarification â€” **even answering just one of these questions would be extremely helpful**. ğŸ™\n\n\n\n# ä¸­æ–‡\n\n**èƒŒæ™¯è¯´æ˜ï¼š**\n\næˆ‘è®¡åˆ’ä¸º **wan2.2 è§†é¢‘æ¨¡å‹** è®­ç»ƒä¸€ä¸ª**è§’è‰² LoRAï¼ˆå®‰å¦® / Annieï¼‰**ï¼Œç”¨äº**åŠ¨ç”»åˆ¶ä½œï¼Œå†™å® 3D é£æ ¼**ã€‚\n\næ­¤å‰æˆ‘ä»æœªè®­ç»ƒè¿‡ LoRAï¼Œä½†ä»Šå¤©æˆ‘å·²ç»æˆåŠŸéƒ¨ç½²äº† **DiffSynth-Studio**ï¼Œå¹¶å®Œæˆäº†ä¸€ä¸ªå®˜æ–¹ç¤ºä¾‹çš„è®­ç»ƒæµç¨‹ã€‚  \nç°åœ¨æˆ‘å¸Œæœ›æ­£å¼å¼€å§‹æˆ‘çš„**è§’è‰² LoRA è®­ç»ƒå·¥ä½œ**ï¼Œä½†åœ¨æ•°æ®é›†æ„å»ºä¸æ ‡æ³¨æ–¹é¢ä»æœ‰è®¸å¤šç–‘é—®ã€‚\n\næˆ‘æœŸæœ›è¿™ä¸ª **å®‰å¦® LoRA** çš„ä½¿ç”¨æ–¹å¼ç±»ä¼¼äºï¼š\n\n>\n\næˆ‘å¸Œæœ›ç”Ÿæˆç»“æœä¸­ï¼š\n\n* **å®‰å¦®çš„å¤–è§‚å§‹ç»ˆæ­£ç¡®ã€ç¨³å®š**\n* **å…¶ä»–è§’è‰²ä¸ä¼šç»§æ‰¿å®‰å¦®çš„å¤–è§‚ç‰¹å¾**\n\n# ä¸€ã€è®­ç»ƒæ•°æ®é›† â€”â€” å›¾ç‰‡ç›¸å…³é—®é¢˜\n\n1.1 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦è„¸éƒ¨ç‰¹å†™**å›¾ç‰‡ï¼Ÿ  \n1.2 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦ä¸ŠåŠèº«**å›¾ç‰‡ï¼Ÿ  \n1.3 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦å…¨èº«**å›¾ç‰‡ï¼Ÿ  \n1.4 æ˜¯å¦éœ€è¦åŒ…å«**å¤šç§è¡¨æƒ…**ï¼ˆå“­ã€ç¬‘ã€æ€’ç­‰ï¼‰çš„å›¾ç‰‡ï¼Ÿ  \n1.5 æ˜¯å¦éœ€è¦**èƒŒé¢è§†è§’**å›¾ç‰‡ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.6 æ˜¯å¦éœ€è¦**ä¸Šä¸‹å·¦å³ 360Â° å…¨è§’åº¦**å›¾ç‰‡ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.7 æ˜¯å¦éœ€è¦**å¤šç§å§¿åŠ¿**ï¼ˆè¹²ã€åã€ç«™ã€è·‘ã€è·³ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.8 æ˜¯å¦éœ€è¦**ä¸åŒæœè£…**ï¼ˆæ¬¾å¼ã€é¢œè‰²ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.9 æ˜¯å¦éœ€è¦**ä¸åŒå‘å‹**ï¼ˆé•¿ã€çŸ­ã€ä¸åŒæ¬¾å¼ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.10 æ˜¯å¦éœ€è¦**ä¸åŒçº¯è‰²èƒŒæ™¯**ï¼ˆçº¯ç™½ã€çº¯ç°ã€çº¯é»‘ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.11 è®­ç»ƒé›†ä¸­æ˜¯å¦åº”**å°½é‡é¿å…å¸½å­**ï¼Ÿ  \n1.12 æ˜¯å¦è¿˜æœ‰å…¶ä»–é‡è¦çš„å›¾ç‰‡æ•°æ®è¡¥å……å»ºè®®ï¼Ÿ\n\n# äºŒã€è®­ç»ƒæ•°æ®é›† â€”â€” æè¿° / æ ‡æ³¨ï¼ˆCaptionï¼‰ç›¸å…³é—®é¢˜\n\n2.1 è®­ç»ƒæè¿°ä¸­æ˜¯å¦åº”å°†**è§’è‰²åï¼ˆAnnieï¼‰æ”¾åœ¨ç¬¬ä¸€ä½**ï¼Ÿ  \n2.2 æ˜¯å¦éœ€è¦æè¿°**äº”å®˜ç»†èŠ‚**ï¼ˆçœ¼ç›ã€å˜´å·´ã€é¼»å­ã€è„¸å‹ç­‰ï¼‰ï¼Ÿ  \n2.3 æ˜¯å¦éœ€è¦æè¿°**é•œå¤´/è§†è§’**ï¼ˆè¿œæ™¯ã€è¿‘æ™¯ã€å·¦ã€å³ã€ä¿¯è§†ç­‰ï¼‰ï¼Ÿ  \n2.4 æ˜¯å¦éœ€è¦æè¿°**è¡¨æƒ…**ï¼Ÿ  \n2.5 æ˜¯å¦éœ€è¦æè¿°**å§¿åŠ¿/åŠ¨ä½œ**ï¼Ÿ  \n2.6 æ˜¯å¦éœ€è¦æè¿°**æœè£…**ï¼ˆæ¬¾å¼ã€é¢œè‰²ç­‰ï¼‰ï¼Ÿ  \n2.7 å¦‚æœå‘å‹æ˜¯å›ºå®šçš„ï¼Œæ˜¯å¦ä»éœ€è¦åœ¨æè¿°ä¸­æ ‡æ³¨å‘å‹ï¼Ÿ  \n2.8 å¦‚æœå‘å‹ä¸å›ºå®šï¼Œæ˜¯å¦éœ€è¦åœ¨æè¿°ä¸­æ ‡æ³¨å‘å‹ï¼Ÿ  \n2.9 å¦‚æœå‡ºç°å¸½å­ï¼Œæ˜¯å¦åº”åœ¨æè¿°ä¸­æ˜ç¡®æ ‡æ³¨ï¼Ÿ  \n2.10 æ˜¯å¦éœ€è¦æè¿°**èƒŒæ™¯**ï¼ˆçº¯è‰²æˆ–åœºæ™¯ï¼‰ï¼Ÿ  \n2.11 æ˜¯å¦éœ€è¦æ˜ç¡®æ ‡æ³¨**äººç‰©é£æ ¼ï¼ˆå†™å® 3Dï¼‰**ï¼Ÿ  \n2.12 æ˜¯å¦éœ€è¦æè¿°**æ€§åˆ«**ï¼Ÿ  \n2.13 æ˜¯å¦éœ€è¦æè¿°**å¹´é¾„**ï¼Ÿ  \n2.14 æ˜¯å¦éœ€è¦æè¿°**ä½“å‹**ï¼Ÿ  \n2.15 æ˜¯å¦è¿˜æœ‰å…¶ä»–é‡è¦çš„æè¿°è¡¥å……å»ºè®®ï¼Ÿ  \n2.16 ä¸ºäº†é¿å…**å…¶ä»–è§’è‰²ç»§æ‰¿å®‰å¦®çš„å¤–è§‚**ï¼Œæ˜¯å¦éœ€è¦åœ¨æè¿°ä¸­**å¼ºåŒ–å®‰å¦®çš„ç‹¬æœ‰ç‰¹å¾**ï¼Ÿ  \nï¼ˆä¾‹å¦‚ï¼šåªæœ‰å®‰å¦®æ‹¥æœ‰çº¢è‰²å¤´å‘ï¼‰\n\n# ä¸‰ã€è®­ç»ƒæ•°æ®é›† â€”â€” è§†é¢‘æ ·æœ¬ç›¸å…³é—®é¢˜\n\n3.1 æ˜¯å¦éœ€è¦**è§†é¢‘æ ·æœ¬**ï¼ˆä¾‹å¦‚ï¼šå›´ç»•å®‰å¦® 360Â° æ—‹è½¬çš„è§†é¢‘ï¼‰ï¼Ÿ  \n3.2 æ˜¯å¦éœ€è¦**è§†é¢‘æ ·æœ¬**ï¼ˆä¾‹å¦‚ï¼šå¯¹å®‰å¦®è¿›è¡Œç¼“æ…¢æ¨è¿‘ / æ‹‰è¿œçš„é•œå¤´ï¼‰ï¼Ÿ\n\néå¸¸æ„Ÿè°¢ä»»ä½•å½¢å¼çš„å¸®åŠ©ï¼Œ**å“ªæ€•åªå›ç­”å…¶ä¸­ä¸€é¡¹é—®é¢˜ä¹Ÿéå¸¸æ„Ÿæ¿€** ğŸ™\n\n",
      "is_original_content": false,
      "link_flair_text": "Help ğŸ™‹â€â™‚ï¸",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qdlgfm/lora_training_è®­ç»ƒ/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qebtn0",
      "title": "ComfyUI Tutorial : Multi Angle & Light Image Editing Using New LORAs Model",
      "subreddit": "Qwen_AI",
      "url": "https://youtu.be/QwxwD4sHI0c",
      "author": "cgpixel23",
      "created_utc": "2026-01-16 09:47:11",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources/learning",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qebtn0/comfyui_tutorial_multi_angle_light_image_editing/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qbnkla",
      "title": "Is it just me or qwen currently the most funny AI right now?",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/4vh1x4s7c3dg1.jpeg",
      "author": "JMVergara1989",
      "created_utc": "2026-01-13 10:06:46",
      "score": 2,
      "num_comments": 0,
      "upvote_ratio": 0.63,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbnkla/is_it_just_me_or_qwen_currently_the_most_funny_ai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}