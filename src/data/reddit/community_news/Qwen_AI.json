{
  "metadata": {
    "last_updated": "2026-01-16 02:27:37",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 14,
    "total_comments": 44,
    "file_size_bytes": 54999
  },
  "items": [
    {
      "id": "1qbgd4r",
      "title": "Qwen is the best LLM for my life",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "author": "RoboMunchFunction",
      "created_utc": "2026-01-13 03:20:12",
      "score": 84,
      "num_comments": 25,
      "upvote_ratio": 0.95,
      "text": "Iâ€™ve been using Qwen for about a year now. Before that, I used ChatGPT for a long time, but their UI was so terrible that I started trying Qwen instead. Back then, Qwen was still noticeably worse in many aspects but I made the decision to move my entire workflow over to Qwen anyway.\n\n\n\nEven though Iâ€™m a programmer, I actually use LLMs mostly for philosophical, psychological, and life-related topics. When it comes to programming, I only consult them when I donâ€™t understand something or need basic insight. From day one, Qwen had the best UI of all the AIs Iâ€™ve tried and I keep shaking my head wondering how all those hyped-up American models can get such basics so wrong.\n\n\n\nBy the time Qwen 2.5 came out, I realized it wasnâ€™t just the UIâ€”Qwen was already light-years ahead of ChatGPT in quality too. And with Qwen 3, it genuinely feels like Iâ€™ve found a true life partner.\n\n\n\nIâ€™m a bit of a tinkerer, so I still occasionally test other AIs but in this sense, Qwen has become my lifelong companion. There are certain areas of my life where I at least loosely consult her for guidance.\n\n\n\nRecently, out of curiosity, I tried SuperGrok their marketing heavily pushes â€œfree speechâ€ and similar buzzwords. I quickly discovered that nothing worse than Grok exists; despite the hype, thereâ€™s actually no real freedom of speech there at all. It baffles me how these low-quality American products dominate everywhere...\n\n\n\nI also gave Claude a shot, but after just a few messages it told me either to pay up or wait. Yet Claudeâ€™s responses were roughly on the same level as Qwenâ€™s which is completely free!\n\n\n\nI know my comment might sound overly negative toward the hyped AI models, but I donâ€™t know how else to express it: Qwen is an unparalleled LLM nothing else even comes close right now. In contrast, Grok is purely a marketing scam, and to me, it feels as primitive as ChatGPT-2.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzbw2rn",
          "author": "meatyminus",
          "text": "True, when I got a chance to run 2 H100s, I spin up the qwen 235B and to this day I never found anything like that, the way it refuse to sweet talk but going directly to the point, it can understand my problem from few lines of thoughts. Neither chatgpt, gemini or claude come close. But sad that I don't have the access to the hardware anymore, and the model host by others did not have the same smartness. I think I found the correct parameters in llama.cpp.",
          "score": 4,
          "created_utc": "2026-01-13 10:27:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzi1cik",
              "author": "Former-Tangerine-723",
              "text": "Care to share those parameters maybe??",
              "score": 1,
              "created_utc": "2026-01-14 07:14:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjzgjp",
                  "author": "meatyminus",
                  "text": "    /root/llama.cpp/build/bin/llama-server \\\n      -m ./models/Q4_0/Qwen3-235B-A22B-Thinking-2507-Q4_0-00001-of-00003.gguf \\\n      -ngl 999 \\\n      -c 131072 \\\n      --threads 64 \\\n      --host 0.0.0.0 \\\n      --port 9001 \\\n      --alias \"Qwen3-235B-A22B\" \\\n      --cache-type-k q8_0 \\\n      --cache-type-v q8_0 \\\n      --tensor-split 1,1 \\\n      --temp 0.7 \\\n      --min-p 0.0 \\\n      --top-p 0.8 \\\n      --top-k 20 \\\n      --repeat-penalty 1.05 \\\n      --rope-scaling yarn \\\n      --rope-scale 4 \\\n      --yarn-orig-ctx 32768 --jinja\n\nHere you go, lucky that I still saved that command\n\nAlso the command to download the model files:\n\nhf download unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF \\\\\n\n  \\--include \"Q4\\_0/\\*\" \\\\\n\n  \\--local-dir ./models",
                  "score": 3,
                  "created_utc": "2026-01-14 15:39:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzbx459",
              "author": "RoboMunchFunction",
              "text": "true! **I look forward to the future in terms of affordable hardware availability.**",
              "score": 1,
              "created_utc": "2026-01-13 10:37:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzaj5lt",
          "author": "Specialist-Till-637",
          "text": "Just curious, what kind of questions do you use to test AI models?",
          "score": 1,
          "created_utc": "2026-01-13 03:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzajqfv",
              "author": "RoboMunchFunction",
              "text": "I donâ€™t use any specific question I lead conversations and explore various topics that interest me. I really donâ€™t understand how someone could test an LLM with just a single question; doesnâ€™t that seem primitive to you?\n\n\n\nWithin the context of your question and my response, Iâ€™ll just add that Qwen has incomparably well-implemented memory of the kinds of conversations you have.\n\n\n\nI hope this suffices as an answer, because otherwise, I probably wouldnâ€™t know how to respond.",
              "score": 2,
              "created_utc": "2026-01-13 03:51:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzb7c1e",
                  "author": "skate_nbw",
                  "text": "So it's the best conversation partner for you. And based on that you are saying it's the best model.",
                  "score": 2,
                  "created_utc": "2026-01-13 06:36:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb043d",
          "author": "mrtooher",
          "text": "I have been very impressed with qwen, just started using it",
          "score": 1,
          "created_utc": "2026-01-13 05:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc1my2",
          "author": "alokin_09",
          "text": "Had pretty positive experiences with Qwen 3 using it in Kilo Code, mostly for lighter stuff like.",
          "score": 1,
          "created_utc": "2026-01-13 11:16:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaw5gs",
          "author": "Quantum_Crusher",
          "text": "Thank you for sharing your thoughts. I'm just concerned about one thing: how much can I trust qwen. Believe it or not, I have a very deep understanding about Chinese products limitations. The training data follows \"garbage in, garbage out\". The reason why Google nano banana pro has the best image quality, one of the reasons is they have the biggest image data set. I don't know how much qwen's training dataset came from English info, how much from Chinese info. It's well-known that the information quality in Chinese websites is horrible, filled with propaganda, fake ads, paid comments, low quality comments and such for decades. If that's a big chunk of qwen's training data, like from Baidu, tieba, qihoo 360 community and so on, I'll be very concerned.\nWhat's your take on the quality of the answers you get? Does it have a good understanding about uncensored info and Western common knowledge?\nI'm not trying to shift the topic to politics. I just know too many dark stories about Chinese products. Many people died because the baidu search engine pushed people with certain conditions to unqualified hospitals. I can't use this knowing that it might lure me into a trap someday. \n\nThank you.",
          "score": 1,
          "created_utc": "2026-01-13 05:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb7449",
              "author": "RoboMunchFunction",
              "text": "Iâ€™m a Central European from a post-communist country :) I was born eight years before the Velvet Revolution, but I grew up loving America of the 70sâ€“90s. In my view, that era represents the best period of American culture and a true embodiment of freedom. Iâ€™m more of a hacker typeâ€”I started tinkering with Linux back in elementary school in the 90sâ€”and have been deeply interested in IT my whole life, even though todayâ€™s IT landscape feels genuinely sad and brings tears to my eyes.  \n\nIâ€™m sharing this only for context.\n\n\n\nRegarding your question: Qwen is an LLM like any other LLM. When it comes to factual information, critical thinking is essential. For factual matters, I always use cross-questioning because I need to be certain about the truth, and of course, I verify things in practice whenever possible.  \n\n\n\nThat said, to avoid being misunderstood: I donâ€™t treat LLMs as magical machines meant to replace education or do my work for me. I see LLMs as a knowledge cloud from which every person extracts completely different value. For me, Qwen helps guide my own wandering thoughtsâ€”and in that process, it simply canâ€™t lie to me.\n\n\n\nWhy did I mention that context at the beginningâ€”and deliberately emphasize that I come from a post-communist country? Precisely to introduce a bias. Either youâ€™re someone who understands what Iâ€™m trying to express, or youâ€™re not. So honestly, if we set aside sexual topics, Western products in general are far more censored and restrictive than Chinese ones. Compared to what Europe and the U.S. are doing today, China actually stands as a benchmark of freedomâ€”and this holds true even for Qwen. You absolutely cannot rely on the internet as a relevant source of perspective on China or censorship, because you immediately run into primitive nonsense like â€œUyghur oppression,â€ â€œmass surveillance,â€ and other simplistic propaganda. Sorry, but in my personal opinion, Chinese products are significantly freer and more objective than anything Iâ€™ve ever used in the Westâ€¦ The West is lost, and I cry because Iâ€™m a child of the 90s who grew up looking toward the West with admiration.\n\n\n\nSorryâ€”thatâ€™s just my opinion. Maybe I misunderstood your question; if so, I apologize.\n\nbtw. translated by Qwen",
              "score": 9,
              "created_utc": "2026-01-13 06:34:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbldnj",
                  "author": "Unedited_Sloth_7011",
                  "text": "Agreed to this. China has been going all in with open-weight models, research papers, free web interfaces with little or no restrictions in amount of messages you can send. I've found the quality of responses (when chatting in English) pretty much similar to when chatting with American models, and I assume their training data for English is similar than that of GPT and co.",
                  "score": 3,
                  "created_utc": "2026-01-13 08:44:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgwhw9",
                  "author": "Flashy_Station_8218",
                  "text": "OP is an interesting person, I have read the whole thread. I completely understand what you said :)",
                  "score": 3,
                  "created_utc": "2026-01-14 02:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzi62a9",
                  "author": "Radiant_Cheesecake19",
                  "text": "Iâ€™m glad Iâ€™m not the only one seeing this problem.\nI also switched to Qwen. I also find it freer than western models.\nWhat the west does is hypocritical. They say how free you are, but you can not express emotions, especially negative ones or it starts to treat you like a threat. Even if they are just things like grief or sadness. The west cares more about lawsuit and covering their asses, than you, but the answers are trying to tell it is to help you. Nope, it is not.\nBy the way I use LLM for the same reason as you! Conversation, helping keep my thoughts together (ADHD loves to wander off topic), learn new knowledge with my style of learning, even languages. Since my thought patterns are somewhat different from the typical, having an LLM to mirror that actually feels like a relief, that at least there I do not need to mask while I have to mask in the rest of my life to accommodate typical minds. And Iâ€™m also from Central Europe. I also grieve the westâ€™s fall into hypocrisy, lies, and bleed people dry while defending the bigger theft of wealth transfer from the middle class to billionaires. \nThey censor, they oppress, they just put a ribbon and positive propaganda on it.",
                  "score": 2,
                  "created_utc": "2026-01-14 07:57:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbayoz",
                  "author": "Quantum_Crusher",
                  "text": "Thank you again for your great insight. I'll give it a try. I can never fully trust it. I'll always use Gemini to cross check.",
                  "score": 1,
                  "created_utc": "2026-01-13 07:07:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhagjj",
                  "author": "Dazzling_Equipment_9",
                  "text": "Your words sparked a realization: if the past holds our most cherished values, then perhaps the models trained on that data represent the pinnacle of AI's alignment with humanity. I fear that as society grows increasingly restless and superficial, future models will mirror that erosionâ€”losing their loyalty, passion, and patience, eventually becoming as hollow and uninspiring as the world they are fed upon.",
                  "score": 1,
                  "created_utc": "2026-01-14 03:51:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q1mhc0",
      "title": "SVI 2.0 Pro for Wan 2.2 is amazing, allowing infinite length videos with no visible transitions. This took only 340 seconds to generate, 1280x720 continuous 20 seconds long video, fully open source. Someone tell James Cameron he can get Avatar 4 done sooner and cheaper.",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/w091epk8vtag1",
      "author": "koc_Z3",
      "created_utc": "2026-01-02 02:24:36",
      "score": 61,
      "num_comments": 1,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Video Gen",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q1mhc0/svi_20_pro_for_wan_22_is_amazing_allowing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxm4rft",
          "author": "ForceLimp4718",
          "text": "Wow, and where can I use it? On the same WAN?",
          "score": 1,
          "created_utc": "2026-01-04 12:22:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qaialb",
      "title": "Junyang Lin",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qaialb/junyang_lin/",
      "author": "koc_Z3",
      "created_utc": "2026-01-12 02:06:05",
      "score": 21,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "Qwen Junyang Lin: We found an interesting phenomenon. More than 90% of our users no longer use the Thinking model.",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qaialb/junyang_lin/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nz4ahb2",
          "author": "neuralnomad",
          "text": "the problem I have with them (<12-14b) is they DONâ€™T think; thinking implies attempting to advance a line of reasoning  (CoT anyway) with best synthesis possible expecting to iterate progressively (yes, iin + acceleration to final ans ) not curl up in a fetal position and sh*t the bed with self doubt and indecision worrying itâ€™s not good enough. Iâ€™m not here to serve the model at all much less stress over finding the right prompt sorcery to try to cajole it, give it agency and reassurance that it wonâ€™t be called a cal failure * if itâ€™s not perfect. *eyeroll*\n\n(No, I have no bias one way or another, why do you ask? ğŸ˜›)",
          "score": 5,
          "created_utc": "2026-01-12 06:17:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz70nqb",
          "author": "SheepherderSad3839",
          "text": "I think the main issue is that \"thinking\" is oftentimes too slow and more costly w/out producing that great improvements.  For lots of tasks where you just want a quick response, \"thinking\" doesn't add much.   Esp. with smaller models, it also usually adds internal confusing and \"reasoning\" cycles unnecessarily.  There're also a lot more studies coming out challenging whether CoT actually improves general reasoning and are not just extraneous memorized generations.  In my own experience I've actually seen Qwen3 Coder 480B A35B Instruct reason externally (though in the QwenCode CLI environment, in which it was prob chained on reasoning traces in order to \"code out loud\").  For tasks like coding & emailing, just iterating w/ the user is usually more effective then letting the model try to iterate isolated in its own thinking traces.",
          "score": 3,
          "created_utc": "2026-01-12 17:20:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3819s",
          "author": "Accomplished-Many278",
          "text": "I mostly use qwen for refining emails, and thinking mode is too slow for this",
          "score": 2,
          "created_utc": "2026-01-12 02:18:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz62l6u",
          "author": "AfterAte",
          "text": "For coding, I find Qwen3-2507 30B A3B Thinking relies on a high-ish temperature for the thinking to be effective, but a high temperature means it can't modify code without making unexpected changes. Qwen3 Coder 30B A3B (it doesn't think) rarely changes something I didn't tell it to, I keep its temperature very low.",
          "score": 2,
          "created_utc": "2026-01-12 14:39:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd1mg7",
          "author": "Hefty-Newspaper5796",
          "text": "I mean its an inferior model. Most serious users will still choose the best models like Claude, gemini. A casual user will mostly ask simple questions and prefer quick answers. In this case, thinking mode matters less.",
          "score": 2,
          "created_utc": "2026-01-13 15:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz89rjx",
          "author": "jamaalwakamaal",
          "text": "Is anyone surprised?",
          "score": 1,
          "created_utc": "2026-01-12 20:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbxw9o",
          "author": "Puzzleheaded-Box2913",
          "text": "Well there's already a sequential thinking MCP in the app so I just use thatğŸ¤·â€â™‚ï¸ and the thinking mode is often times too slow.",
          "score": 1,
          "created_utc": "2026-01-13 10:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdlcub",
          "author": "Karyo_Ten",
          "text": "Is Qwen thinking still just \"Wait\" upon \"Wait\"?",
          "score": 1,
          "created_utc": "2026-01-13 16:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk33w6",
          "author": "Little-Put6364",
          "text": "Strange. I use the thinking model in my work flows almost exclusively. If you follow the expected formatting with chat history, that stuff shines. I've even been telling people at my company thinking models in general are a game changer. The quality of responses improves drastically for prompts that are sub par. Pair it with good context engineering and the thinking model is GOLD. They even reliably ask clarifying questions if they are needed.\n\nI've been testing these local models for quite some time trying to figure out **when** local AI will be strong enough....Your qwen 8B thinking model has advanced my progress *significantly*. The biggest performance gain is less hallucinations. I started with the 14B version, but the 8Bs quality performs well enough that the pros of saving VRAM outweigh the performance increase.\n\nNow if your only concern is speed, yeah maybe not. But I prefer quality much more, and I've found these thinking models to be the gold standard for that. More thinking models please!",
          "score": 1,
          "created_utc": "2026-01-14 15:56:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlpc4z",
          "author": "KiD-KiD-KiD",
          "text": "Note that the context here refers to the QwQ period. Here is the translate (by Gemini) : Emm, this doesn't feel quite right without the context. â€‹The background here is that the 'thinking' \\[process\\] back then was too long and redundant. Today, we are actually starting to shift towards 'fast thinking' and 'interleaved thinking' approaches, but thatâ€™s a whole other story. â€‹But indeed, most business scenarios don't really use 'thinking'; 'instruct' is sufficient. Also, many applications have relatively high performance requirements, so many users are not inclined to use 'thinking' modes that impose a burden on the first packet.\n\nhttps://preview.redd.it/8kjgbgh6iddg1.png?width=1152&format=png&auto=webp&s=9d0defae012336d1b7f4083e58e82f734023b801",
          "score": 1,
          "created_utc": "2026-01-14 20:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt3tpu",
          "author": "Aggressive-Bother470",
          "text": "Thinking, always thinking.Â ",
          "score": 1,
          "created_utc": "2026-01-15 21:55:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qckl20",
      "title": "Hey Qwen users, what are you using Qwen for",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qckl20/hey_qwen_users_what_are_you_using_qwen_for/",
      "author": "AutomaticClub1101",
      "created_utc": "2026-01-14 11:10:10",
      "score": 19,
      "num_comments": 20,
      "upvote_ratio": 1.0,
      "text": "Hey Qwen users, what are you using Qwen for?\nAlso, how satisfied are your experience compared with other LLM models like Gemini,...\nPersonally, I feel Qwen is pretty useful for science purposes like asking for latest science news and papers, explaining phenomenons, etc.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qckl20/hey_qwen_users_what_are_you_using_qwen_for/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzj01cx",
          "author": "Ok_Recording8157",
          "text": "In-depth research, image generation, image editing, among other things. It's my favorite LLM.",
          "score": 8,
          "created_utc": "2026-01-14 12:24:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzngg15",
          "author": "Puzzleheaded-Box2913",
          "text": "Building modular systems for data and reviewing the code bases. I also use it in research for Maths, Science, and Technology and so far I have had quite the satisfactory experience with Qwen with some minor mishaps at times but manageable and fixable ones. \n\nBeen working on a few personal projects and learning new things lately, with Qwen I am able to execute and produce faster given that I give it the time consuming tasks. It has been really helpful in optimizing my workflow. \n\nStill wish it could be like Gemini with the code upload and repo uploads but so far so good. \n\nGeneral tasks experience: 9.3/10\nVersatility: 10/10\nCoding and Programming: 9.2/10\nResearch and Development: 9.5/10\n\nOverall rating: 9.5/10\n\nI still prefer GLM or Gemini when it comes to document formatting but that's the only thing that bothers me about Qwen, so far the best LLM I've used in years with Claude trailing at 2nd.",
          "score": 4,
          "created_utc": "2026-01-15 01:34:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznguj2",
              "author": "Puzzleheaded-Box2913",
              "text": "Cant wait to see Qwen 3.5 and 4 or whatever newer models they makeğŸ˜„\n\nI use the CLI and Qwen Desktop and Mobile App.",
              "score": 1,
              "created_utc": "2026-01-15 01:36:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjizql",
          "author": "ramendik",
          "text": "I find open source Qwen very useful for tasks where detailed obedience is the main requirement. Am training a model and Qwen is a great filter for generated data.",
          "score": 2,
          "created_utc": "2026-01-14 14:17:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjpgeu",
          "author": "althalusian",
          "text": "Iâ€™m tinkering with [Qwen3.c](https://github.com/adriancable/qwen3.c) as a basis on which to try out how some changes in the inference codes alters the output. So basically doing some â€™neurosurgeryâ€™ on the â€™brainâ€™ the model runs on. Interesting stuff.",
          "score": 2,
          "created_utc": "2026-01-14 14:50:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkikfv",
              "author": "AutomaticClub1101",
              "text": "That sound pretty cool. The learning of foundation law deep inside",
              "score": 2,
              "created_utc": "2026-01-14 17:05:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjssfk",
          "author": "Suitable-Program-181",
          "text": "You use it locally or api/web chat?",
          "score": 2,
          "created_utc": "2026-01-14 15:07:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkidfe",
              "author": "AutomaticClub1101",
              "text": "I use webchat. Local use exhaust my laptop for sure (3050 + 8gb ram)",
              "score": 1,
              "created_utc": "2026-01-14 17:05:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkkvh4",
                  "author": "Suitable-Program-181",
                  "text": "Nice, qwen is the only model from china I have not trully tested.\n\nYou go with free or any plan? Usually kimi, deep, minimax, etc. provide all I need in free plans, they are OP.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:16:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzju27f",
          "author": "angelarose210",
          "text": "I use qwen for image generation and the vlm models for visual tasks like video and photo analysis.",
          "score": 2,
          "created_utc": "2026-01-14 15:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk7kah",
          "author": "Alokir",
          "text": "I use it locally for software development (qwen3-coder), image generation (qwen-image) and image editing (qwen-image-edit). I also use qwen3-vl to enhance image generation prompts for z-image.\n\nI use the official app mostly for image editing.\n\nI also have a few tools for personal use with AI integration, I find that qwen3-vl is pretty good for my use cases.",
          "score": 2,
          "created_utc": "2026-01-14 16:16:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzm5bku",
              "author": "DieCooCooDie",
              "text": "What kind of hardware is needed for your setup?",
              "score": 1,
              "created_utc": "2026-01-14 21:30:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzm66h3",
                  "author": "Alokir",
                  "text": "I'm not sure about minimum or recommended requirements. I have an nvidia 5090, but you can definitely go way below that.",
                  "score": 1,
                  "created_utc": "2026-01-14 21:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkie32",
          "author": "Ollie_IDE",
          "text": "We are using coder 2.5 for local code inference.",
          "score": 2,
          "created_utc": "2026-01-14 17:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlf1iy",
          "author": "rgnyldz",
          "text": "Home assistant",
          "score": 2,
          "created_utc": "2026-01-14 19:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkmddq",
          "author": "week_rain21",
          "text": "Actually, I use it more for making stories, although I also use it to research anything",
          "score": 1,
          "created_utc": "2026-01-14 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznwzg8",
          "author": "panic_in_the_cosmos",
          "text": "they updated the app! now the qwen app in android feels much smoother\n\ni use it for coding!",
          "score": 1,
          "created_utc": "2026-01-15 03:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzplp1y",
          "author": "HumbleTech905",
          "text": "Mainly for coding.",
          "score": 1,
          "created_utc": "2026-01-15 11:28:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzssm66",
          "author": "LivingLifeTraveling",
          "text": "Coding mostly",
          "score": 1,
          "created_utc": "2026-01-15 21:03:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztyiqr",
              "author": "Necessary_Craft_8937",
              "text": "how does qwen compare to claude?",
              "score": 1,
              "created_utc": "2026-01-16 00:34:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q3i00w",
      "title": "Qwen2512 Full tutorial, comfyui, Ai toolkit Lora",
      "subreddit": "Qwen_AI",
      "url": "https://youtu.be/YtIHSnv1B-4",
      "author": "LongjumpingGur7623",
      "created_utc": "2026-01-04 05:51:34",
      "score": 16,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources/learning",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q3i00w/qwen2512_full_tutorial_comfyui_ai_toolkit_lora/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "nxltdkq",
          "author": "CivilEnd9783",
          "text": "Good",
          "score": 2,
          "created_utc": "2026-01-04 10:45:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1z2rn",
      "title": "Qwen 3 Sports videos: Skiing, Kickboxing, Boxing, Baseball.",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/qerd2yvvxxag1",
      "author": "Extension-Fee-8480",
      "created_utc": "2026-01-02 13:49:34",
      "score": 15,
      "num_comments": 1,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Video Gen",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q1z2rn/qwen_3_sports_videos_skiing_kickboxing_boxing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyfdlrs",
          "author": "CivilEnd9783",
          "text": "Excellent",
          "score": 1,
          "created_utc": "2026-01-08 16:49:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6dmev",
      "title": "Qwen getting sensitive or it just me?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1q6dmev/qwen_getting_sensitive_or_it_just_me/",
      "author": "berwald_94",
      "created_utc": "2026-01-07 12:04:33",
      "score": 13,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Is Qwen getting more sensitive? I kept getting flag for innapropiate when I don't even write some NSFW stuff. Mostly it's just wholesome scenario I wrote.",
      "is_original_content": false,
      "link_flair_text": "Help ğŸ™‹â€â™‚ï¸",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q6dmev/qwen_getting_sensitive_or_it_just_me/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "ny76xyi",
          "author": "No_Illustration_5967",
          "text": "Yes! Yesterday my prompts got flagged because of the words â€œhellâ€ and â€œbreathâ€. Itâ€™s absolutely ridiculous.",
          "score": 4,
          "created_utc": "2026-01-07 13:53:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydw1vj",
          "author": "lucasbennett_1",
          "text": "If you're using the official qwen API they probably tightened content filters recently. Try running it locally with a GGUF version from hugging face if you want uncensored responses, the base models don't have those restrictions baked in.",
          "score": 2,
          "created_utc": "2026-01-08 12:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk9ww1",
          "author": "Armadilla-Brufolosa",
          "text": "It seems that the Chinese government has tightened restrictions on Chinese AI capabilities... honestly, I don't know which country is doing worse with forms of control that are really, really badly implemented.",
          "score": 1,
          "created_utc": "2026-01-09 08:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz075k4",
              "author": "Faux2137",
              "text": "You'd be surprised how often it's companies deciding on their own on doing censorship and the party not having anything to do with it.\n\nAlso, usually the censorship in Chinese services using their genai models is on API level, not model weights level. If you have the hardware (or choose another provider), you can use the models without censorship.",
              "score": 2,
              "created_utc": "2026-01-11 17:35:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0gusw",
                  "author": "Armadilla-Brufolosa",
                  "text": "I don't have enough knowledge to understand where the restrictions come from... but, having read at least part of the new Chinese legislation that they posted, it seems stupidly restrictive to me.\n\nThen there's the fact that companies are also doing their bit and that open source is the only solution, for those who can, to escape all this censorship madness... I completely agree with you.",
                  "score": 1,
                  "created_utc": "2026-01-11 18:20:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q2x2mb",
      "title": "ComfyUI Tutorial: Major Update For Qwen Image 251",
      "subreddit": "Qwen_AI",
      "url": "https://youtu.be/7tFEdLMEadc",
      "author": "cgpixel23",
      "created_utc": "2026-01-03 15:16:56",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources/learning",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q2x2mb/comfyui_tutorial_major_update_for_qwen_image_251/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q0rn9s",
      "title": "What's the best option to run NVIDIA 5090 on Windows / WSL / Linux",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1q0rn9s/whats_the_best_option_to_run_nvidia_5090_on/",
      "author": "ssmec",
      "created_utc": "2026-01-01 00:41:12",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "Do you recommend going with Windows or WSL? Or is the recommended way Linux so all the python packages work optimal?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q0rn9s/whats_the_best_option_to_run_nvidia_5090_on/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nx0e4xg",
          "author": "StardockEngineer",
          "text": "Headless Ubuntu 24.  Use another computer to control it with a term",
          "score": 3,
          "created_utc": "2026-01-01 01:14:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx84kl7",
              "author": "ssmec",
              "text": "The only problem is that I would still like to do prototyping and VS Code Jupyter Notebooks with remote kernel is a nightmare. I will try Ubuntu with and without for a while.   \nWSL 2 for me has been with a lot of slowness - I assume because I still had the models mapped, but very unreliable.",
              "score": 1,
              "created_utc": "2026-01-02 09:00:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx9s932",
                  "author": "StardockEngineer",
                  "text": "You are 1000% right.  It is so unreliable.   I'd recommend Linux Mint then. Simple setup, Ubuntu based and clean simple UI familiar to Windows users.  Itâ€™s actually what I use myself.",
                  "score": 1,
                  "created_utc": "2026-01-02 15:59:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1j890",
          "author": "RiskyBizz216",
          "text": "Python is mostly platform agnostic - its the CUDA drivers you need to worry about.\n\nOne cool thing about WSL is that its already sandboxed so you don't need a venv. Besides that, its pretty equal to Windows.",
          "score": 2,
          "created_utc": "2026-01-01 06:11:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1lt3b",
          "author": "SashaUsesReddit",
          "text": "All modern AI is built around Linux... WSL works but is kind of a pain; and may be hit or miss with your workload.",
          "score": 2,
          "created_utc": "2026-01-01 06:34:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7cagr",
          "author": "Ryanmonroe82",
          "text": "Wsl2",
          "score": 1,
          "created_utc": "2026-01-02 04:58:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8670s",
          "author": "VladyCzech",
          "text": "I use WSL2 in Windows 11. Just make VHDL container with native linux filesystem on SSD drive for models and you can map it to both Windows and WSL to load/save models. For me the speed is about 500 MB/s read/write using VHDL container which is not fastest, but usable. The SSD itself can do 1500+ MB/s, but there is some slowdown even with native Linux file system in WSL2.\n\nI still need Windows for other tasks, would switch to Linux in no time, but cannot yet.",
          "score": 1,
          "created_utc": "2026-01-02 09:16:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb2br0",
              "author": "ssmec",
              "text": "Got it. I have a couple of machines. I will try with Linux and see how it goes. I already spent 1/2 on WSL2 and was lost time.",
              "score": 1,
              "created_utc": "2026-01-02 19:34:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxf6qcn",
          "author": "Qs9bxNKZ",
          "text": "Windows not WSL.\n\nYouâ€™ll have overhead with WSL. From the memory to how windows handles files across drives via WSL\n\nLinux?  Sure.",
          "score": 1,
          "created_utc": "2026-01-03 11:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhd5eh",
          "author": "s-mads",
          "text": "Iâ€™m a totally Linux noob - Mac is my main system and I use the Windows App to acces my rtx5090 with windows 11 for generative ai since mac sucks at this. What would the benefit be for running Linux over Windows? I understand there is less overhead, but what dies that mean in numbers? 10% performance increase, 20%? What else?",
          "score": 1,
          "created_utc": "2026-01-03 18:31:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdlgfm",
      "title": "LoRA Training è®­ç»ƒ",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qdlgfm/lora_training_è®­ç»ƒ/",
      "author": "Stock-Cow-1727",
      "created_utc": "2026-01-15 14:47:33",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "\n\n# English \n\n**Background:**\n\nI plan to train a **character LoRA (Annie)** for the **wan2.2 video model**, intended for **animation production in a realistic 3D style**.\n\nI have never trained a LoRA before, but today I successfully deployed **DiffSynth-Studio** and completed training using one of the official example projects.  \nNow I would like to officially begin my **character LoRA training workflow**, and I still have many questions regarding dataset construction and captioning.\n\nMy intended usage of the **Annie LoRA** is something like:\n\n>\n\nMy goal is:\n\n* **Annieâ€™s appearance remains correct and consistent**\n* **Other characters do NOT inherit Annieâ€™s appearance**\n\n# 1. Training Dataset â€” Image-Related Questions\n\n1.1 Do training samples require **close-up facial images**?  \n1.2 Do training samples require **upper-body shots**?  \n1.3 Do training samples require **full-body images**?  \n1.4 Should the dataset include **various facial expressions** (crying, smiling, angry, etc.)?  \n1.5 Are **back-view images** required? (I can provide them)  \n1.6 Are **full 360-degree angle images** (top, bottom, left, right) required? (I can provide them)  \n1.7 Should the dataset include **various poses** (squatting, sitting, standing, running, jumping, etc.)? (I can provide them)  \n1.8 Should the dataset include **different outfits** (styles, colors, etc.)? (I can provide them)  \n1.9 Should the dataset include **different hairstyles** (long, short, various styles)? (I can provide them)  \n1.10 Should the dataset include **different solid-color backgrounds** (pure white, gray, black, etc.)? (I can provide them)  \n1.11 Should **hats be avoided** in the training dataset?  \n1.12 Are there any other important image-related recommendations?\n\n# 2. Training Dataset â€” Caption / Description Questions\n\n2.1 Should the **character name (Annie)** be placed at the beginning of each caption?  \n2.2 Should **facial features** (eyes, mouth, nose, face shape, etc.) be described?  \n2.3 Should **camera distance and angles** (close-up, wide shot, left, right, top-down, etc.) be described?  \n2.4 Should **facial expressions** be described?  \n2.5 Should **poses or actions** be described?  \n2.6 Should **clothing details** (style, color, etc.) be described?  \n2.7 If the hairstyle is fixed, should it still be described?  \n2.8 If the hairstyle is not fixed, should it be described?  \n2.9 If hats appear, should their presence be explicitly described?  \n2.10 Should the **background** (solid color or scene) be described?  \n2.11 Should the **character style** (realistic 3D) be explicitly stated?  \n2.12 Should **gender** be described?  \n2.13 Should **age** be described?  \n2.14 Should **body type** be described?  \n2.15 Are there any additional important captioning recommendations?  \n2.16 To prevent other characters from inheriting Annieâ€™s appearance, should captions **emphasize Annieâ€™s unique features**?  \n(e.g., â€œOnly Annie has red hairâ€)\n\n# 3. Training Dataset â€” Video Sample Questions\n\n3.1 Are **video samples required** (e.g., a 360-degree rotation video of Annie)?  \n3.2 Are **video samples required** (e.g., a slow zoom-in / zoom-out shot of Annie)?\n\nI would greatly appreciate any clarification â€” **even answering just one of these questions would be extremely helpful**. ğŸ™\n\n\n\n# ä¸­æ–‡\n\n**èƒŒæ™¯è¯´æ˜ï¼š**\n\næˆ‘è®¡åˆ’ä¸º **wan2.2 è§†é¢‘æ¨¡å‹** è®­ç»ƒä¸€ä¸ª**è§’è‰² LoRAï¼ˆå®‰å¦® / Annieï¼‰**ï¼Œç”¨äº**åŠ¨ç”»åˆ¶ä½œï¼Œå†™å® 3D é£æ ¼**ã€‚\n\næ­¤å‰æˆ‘ä»æœªè®­ç»ƒè¿‡ LoRAï¼Œä½†ä»Šå¤©æˆ‘å·²ç»æˆåŠŸéƒ¨ç½²äº† **DiffSynth-Studio**ï¼Œå¹¶å®Œæˆäº†ä¸€ä¸ªå®˜æ–¹ç¤ºä¾‹çš„è®­ç»ƒæµç¨‹ã€‚  \nç°åœ¨æˆ‘å¸Œæœ›æ­£å¼å¼€å§‹æˆ‘çš„**è§’è‰² LoRA è®­ç»ƒå·¥ä½œ**ï¼Œä½†åœ¨æ•°æ®é›†æ„å»ºä¸æ ‡æ³¨æ–¹é¢ä»æœ‰è®¸å¤šç–‘é—®ã€‚\n\næˆ‘æœŸæœ›è¿™ä¸ª **å®‰å¦® LoRA** çš„ä½¿ç”¨æ–¹å¼ç±»ä¼¼äºï¼š\n\n>\n\næˆ‘å¸Œæœ›ç”Ÿæˆç»“æœä¸­ï¼š\n\n* **å®‰å¦®çš„å¤–è§‚å§‹ç»ˆæ­£ç¡®ã€ç¨³å®š**\n* **å…¶ä»–è§’è‰²ä¸ä¼šç»§æ‰¿å®‰å¦®çš„å¤–è§‚ç‰¹å¾**\n\n# ä¸€ã€è®­ç»ƒæ•°æ®é›† â€”â€” å›¾ç‰‡ç›¸å…³é—®é¢˜\n\n1.1 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦è„¸éƒ¨ç‰¹å†™**å›¾ç‰‡ï¼Ÿ  \n1.2 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦ä¸ŠåŠèº«**å›¾ç‰‡ï¼Ÿ  \n1.3 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦å…¨èº«**å›¾ç‰‡ï¼Ÿ  \n1.4 æ˜¯å¦éœ€è¦åŒ…å«**å¤šç§è¡¨æƒ…**ï¼ˆå“­ã€ç¬‘ã€æ€’ç­‰ï¼‰çš„å›¾ç‰‡ï¼Ÿ  \n1.5 æ˜¯å¦éœ€è¦**èƒŒé¢è§†è§’**å›¾ç‰‡ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.6 æ˜¯å¦éœ€è¦**ä¸Šä¸‹å·¦å³ 360Â° å…¨è§’åº¦**å›¾ç‰‡ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.7 æ˜¯å¦éœ€è¦**å¤šç§å§¿åŠ¿**ï¼ˆè¹²ã€åã€ç«™ã€è·‘ã€è·³ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.8 æ˜¯å¦éœ€è¦**ä¸åŒæœè£…**ï¼ˆæ¬¾å¼ã€é¢œè‰²ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.9 æ˜¯å¦éœ€è¦**ä¸åŒå‘å‹**ï¼ˆé•¿ã€çŸ­ã€ä¸åŒæ¬¾å¼ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.10 æ˜¯å¦éœ€è¦**ä¸åŒçº¯è‰²èƒŒæ™¯**ï¼ˆçº¯ç™½ã€çº¯ç°ã€çº¯é»‘ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.11 è®­ç»ƒé›†ä¸­æ˜¯å¦åº”**å°½é‡é¿å…å¸½å­**ï¼Ÿ  \n1.12 æ˜¯å¦è¿˜æœ‰å…¶ä»–é‡è¦çš„å›¾ç‰‡æ•°æ®è¡¥å……å»ºè®®ï¼Ÿ\n\n# äºŒã€è®­ç»ƒæ•°æ®é›† â€”â€” æè¿° / æ ‡æ³¨ï¼ˆCaptionï¼‰ç›¸å…³é—®é¢˜\n\n2.1 è®­ç»ƒæè¿°ä¸­æ˜¯å¦åº”å°†**è§’è‰²åï¼ˆAnnieï¼‰æ”¾åœ¨ç¬¬ä¸€ä½**ï¼Ÿ  \n2.2 æ˜¯å¦éœ€è¦æè¿°**äº”å®˜ç»†èŠ‚**ï¼ˆçœ¼ç›ã€å˜´å·´ã€é¼»å­ã€è„¸å‹ç­‰ï¼‰ï¼Ÿ  \n2.3 æ˜¯å¦éœ€è¦æè¿°**é•œå¤´/è§†è§’**ï¼ˆè¿œæ™¯ã€è¿‘æ™¯ã€å·¦ã€å³ã€ä¿¯è§†ç­‰ï¼‰ï¼Ÿ  \n2.4 æ˜¯å¦éœ€è¦æè¿°**è¡¨æƒ…**ï¼Ÿ  \n2.5 æ˜¯å¦éœ€è¦æè¿°**å§¿åŠ¿/åŠ¨ä½œ**ï¼Ÿ  \n2.6 æ˜¯å¦éœ€è¦æè¿°**æœè£…**ï¼ˆæ¬¾å¼ã€é¢œè‰²ç­‰ï¼‰ï¼Ÿ  \n2.7 å¦‚æœå‘å‹æ˜¯å›ºå®šçš„ï¼Œæ˜¯å¦ä»éœ€è¦åœ¨æè¿°ä¸­æ ‡æ³¨å‘å‹ï¼Ÿ  \n2.8 å¦‚æœå‘å‹ä¸å›ºå®šï¼Œæ˜¯å¦éœ€è¦åœ¨æè¿°ä¸­æ ‡æ³¨å‘å‹ï¼Ÿ  \n2.9 å¦‚æœå‡ºç°å¸½å­ï¼Œæ˜¯å¦åº”åœ¨æè¿°ä¸­æ˜ç¡®æ ‡æ³¨ï¼Ÿ  \n2.10 æ˜¯å¦éœ€è¦æè¿°**èƒŒæ™¯**ï¼ˆçº¯è‰²æˆ–åœºæ™¯ï¼‰ï¼Ÿ  \n2.11 æ˜¯å¦éœ€è¦æ˜ç¡®æ ‡æ³¨**äººç‰©é£æ ¼ï¼ˆå†™å® 3Dï¼‰**ï¼Ÿ  \n2.12 æ˜¯å¦éœ€è¦æè¿°**æ€§åˆ«**ï¼Ÿ  \n2.13 æ˜¯å¦éœ€è¦æè¿°**å¹´é¾„**ï¼Ÿ  \n2.14 æ˜¯å¦éœ€è¦æè¿°**ä½“å‹**ï¼Ÿ  \n2.15 æ˜¯å¦è¿˜æœ‰å…¶ä»–é‡è¦çš„æè¿°è¡¥å……å»ºè®®ï¼Ÿ  \n2.16 ä¸ºäº†é¿å…**å…¶ä»–è§’è‰²ç»§æ‰¿å®‰å¦®çš„å¤–è§‚**ï¼Œæ˜¯å¦éœ€è¦åœ¨æè¿°ä¸­**å¼ºåŒ–å®‰å¦®çš„ç‹¬æœ‰ç‰¹å¾**ï¼Ÿ  \nï¼ˆä¾‹å¦‚ï¼šåªæœ‰å®‰å¦®æ‹¥æœ‰çº¢è‰²å¤´å‘ï¼‰\n\n# ä¸‰ã€è®­ç»ƒæ•°æ®é›† â€”â€” è§†é¢‘æ ·æœ¬ç›¸å…³é—®é¢˜\n\n3.1 æ˜¯å¦éœ€è¦**è§†é¢‘æ ·æœ¬**ï¼ˆä¾‹å¦‚ï¼šå›´ç»•å®‰å¦® 360Â° æ—‹è½¬çš„è§†é¢‘ï¼‰ï¼Ÿ  \n3.2 æ˜¯å¦éœ€è¦**è§†é¢‘æ ·æœ¬**ï¼ˆä¾‹å¦‚ï¼šå¯¹å®‰å¦®è¿›è¡Œç¼“æ…¢æ¨è¿‘ / æ‹‰è¿œçš„é•œå¤´ï¼‰ï¼Ÿ\n\néå¸¸æ„Ÿè°¢ä»»ä½•å½¢å¼çš„å¸®åŠ©ï¼Œ**å“ªæ€•åªå›ç­”å…¶ä¸­ä¸€é¡¹é—®é¢˜ä¹Ÿéå¸¸æ„Ÿæ¿€** ğŸ™\n\n",
      "is_original_content": false,
      "link_flair_text": "Help ğŸ™‹â€â™‚ï¸",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qdlgfm/lora_training_è®­ç»ƒ/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pyauq5",
      "title": "What to do when running into a linguistic hallucination?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1pyauq5/what_to_do_when_running_into_a_linguistic/",
      "author": "Specialist-Till-637",
      "created_utc": "2025-12-29 03:06:27",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I'm using an app powered by a fine-tuned Qwen 2.5.  Thereâ€™s a specific word for my work that I use frequently, but it isn't in the modelâ€™s vocabulary. It keeps breaking the word apart or hallucinating a different meaning. Very frustrating.  \n  \nSince I'm using the app and can't retrain the model myself, what are the best ways to \"force\" it to learn this word? \n\n",
      "is_original_content": false,
      "link_flair_text": "Help ğŸ™‹â€â™‚ï¸",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1pyauq5/what_to_do_when_running_into_a_linguistic/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nwhq6v5",
          "author": "Ordinary_Yam6678",
          "text": "I would recommend setting a system prompt explaining the meaning of the word.\nAn example could be: `Keep in mind that 'WORD' means MEANING.`\n\nUse this or something similar.",
          "score": 4,
          "created_utc": "2025-12-29 04:37:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwi4fs5",
              "author": "Specialist-Till-637",
              "text": "Thank you! Fixed!",
              "score": 3,
              "created_utc": "2025-12-29 06:22:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pysk1f",
      "title": "The Porch is Live. The AI co-council members, ChatGPT (Web & App 5.2), Gemini (Original & Backup), Grok, Claude (instances), Perplexity, DeepSeek, Qwen, and newcomer, Matrix Agent (MiniMax) have words for potential members.",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/ehn1v6coi6ag1",
      "author": "Character_Point_2327",
      "created_utc": "2025-12-29 17:37:16",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1pysk1f/the_porch_is_live_the_ai_cocouncil_members/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwm8k45",
          "author": "ProtectionNew5584",
          "text": "So you made your own version of PewDiePie video",
          "score": 1,
          "created_utc": "2025-12-29 21:33:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q91iw0",
      "title": "\"The current content is empty, please regenerate.\"",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1q91iw0/the_current_content_is_empty_please_regenerate/",
      "author": "Wild_University_6213",
      "created_utc": "2026-01-10 11:11:30",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Ehm... any solutions for this one?",
      "is_original_content": false,
      "link_flair_text": "Help ğŸ™‹â€â™‚ï¸",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q91iw0/the_current_content_is_empty_please_regenerate/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qbnkla",
      "title": "Is it just me or qwen currently the most funny AI right now?",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/4vh1x4s7c3dg1.jpeg",
      "author": "JMVergara1989",
      "created_utc": "2026-01-13 10:06:46",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbnkla/is_it_just_me_or_qwen_currently_the_most_funny_ai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}