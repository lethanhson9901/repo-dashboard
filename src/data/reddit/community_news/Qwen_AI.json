{
  "metadata": {
    "last_updated": "2026-01-14 16:46:42",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 11,
    "total_comments": 29,
    "file_size_bytes": 37142
  },
  "items": [
    {
      "id": "1q1mhc0",
      "title": "SVI 2.0 Pro for Wan 2.2 is amazing, allowing infinite length videos with no visible transitions. This took only 340 seconds to generate, 1280x720 continuous 20 seconds long video, fully open source. Someone tell James Cameron he can get Avatar 4 done sooner and cheaper.",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/w091epk8vtag1",
      "author": "koc_Z3",
      "created_utc": "2026-01-02 02:24:36",
      "score": 61,
      "num_comments": 1,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Video Gen",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q1mhc0/svi_20_pro_for_wan_22_is_amazing_allowing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxm4rft",
          "author": "ForceLimp4718",
          "text": "Wow, and where can I use it? On the same WAN?",
          "score": 1,
          "created_utc": "2026-01-04 12:22:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbgd4r",
      "title": "Qwen is the best LLM for my life",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "author": "RoboMunchFunction",
      "created_utc": "2026-01-13 03:20:12",
      "score": 61,
      "num_comments": 22,
      "upvote_ratio": 0.93,
      "text": "I‚Äôve been using Qwen for about a year now. Before that, I used ChatGPT for a long time, but their UI was so terrible that I started trying Qwen instead. Back then, Qwen was still noticeably worse in many aspects but I made the decision to move my entire workflow over to Qwen anyway.\n\n\n\nEven though I‚Äôm a programmer, I actually use LLMs mostly for philosophical, psychological, and life-related topics. When it comes to programming, I only consult them when I don‚Äôt understand something or need basic insight. From day one, Qwen had the best UI of all the AIs I‚Äôve tried and I keep shaking my head wondering how all those hyped-up American models can get such basics so wrong.\n\n\n\nBy the time Qwen 2.5 came out, I realized it wasn‚Äôt just the UI‚ÄîQwen was already light-years ahead of ChatGPT in quality too. And with Qwen 3, it genuinely feels like I‚Äôve found a true life partner.\n\n\n\nI‚Äôm a bit of a tinkerer, so I still occasionally test other AIs but in this sense, Qwen has become my lifelong companion. There are certain areas of my life where I at least loosely consult her for guidance.\n\n\n\nRecently, out of curiosity, I tried SuperGrok their marketing heavily pushes ‚Äúfree speech‚Äù and similar buzzwords. I quickly discovered that nothing worse than Grok exists; despite the hype, there‚Äôs actually no real freedom of speech there at all. It baffles me how these low-quality American products dominate everywhere...\n\n\n\nI also gave Claude a shot, but after just a few messages it told me either to pay up or wait. Yet Claude‚Äôs responses were roughly on the same level as Qwen‚Äôs which is completely free!\n\n\n\nI know my comment might sound overly negative toward the hyped AI models, but I don‚Äôt know how else to express it: Qwen is an unparalleled LLM nothing else even comes close right now. In contrast, Grok is purely a marketing scam, and to me, it feels as primitive as ChatGPT-2.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzbw2rn",
          "author": "meatyminus",
          "text": "True, when I got a chance to run 2 H100s, I spin up the qwen 235B and to this day I never found anything like that, the way it refuse to sweet talk but going directly to the point, it can understand my problem from few lines of thoughts. Neither chatgpt, gemini or claude come close. But sad that I don't have the access to the hardware anymore, and the model host by others did not have the same smartness. I think I found the correct parameters in llama.cpp.",
          "score": 3,
          "created_utc": "2026-01-13 10:27:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbx459",
              "author": "RoboMunchFunction",
              "text": "true! **I look forward to the future in terms of affordable hardware availability.**",
              "score": 1,
              "created_utc": "2026-01-13 10:37:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzi1cik",
              "author": "Former-Tangerine-723",
              "text": "Care to share those parameters maybe??",
              "score": 1,
              "created_utc": "2026-01-14 07:14:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjzgjp",
                  "author": "meatyminus",
                  "text": "    /root/llama.cpp/build/bin/llama-server \\\n      -m ./models/Q4_0/Qwen3-235B-A22B-Thinking-2507-Q4_0-00001-of-00003.gguf \\\n      -ngl 999 \\\n      -c 131072 \\\n      --threads 64 \\\n      --host 0.0.0.0 \\\n      --port 9001 \\\n      --alias \"Qwen3-235B-A22B\" \\\n      --cache-type-k q8_0 \\\n      --cache-type-v q8_0 \\\n      --tensor-split 1,1 \\\n      --temp 0.7 \\\n      --min-p 0.0 \\\n      --top-p 0.8 \\\n      --top-k 20 \\\n      --repeat-penalty 1.05 \\\n      --rope-scaling yarn \\\n      --rope-scale 4 \\\n      --yarn-orig-ctx 32768 --jinja\n\nHere you go, lucky that I still saved that command\n\nAlso the command to download the model files:\n\nhf download unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF \\\\\n\n  \\--include \"Q4\\_0/\\*\" \\\\\n\n  \\--local-dir ./models",
                  "score": 1,
                  "created_utc": "2026-01-14 15:39:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzaj5lt",
          "author": "Specialist-Till-637",
          "text": "Just curious, what kind of questions do you use to test AI models?",
          "score": 1,
          "created_utc": "2026-01-13 03:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzajqfv",
              "author": "RoboMunchFunction",
              "text": "I don‚Äôt use any specific question I lead conversations and explore various topics that interest me. I really don‚Äôt understand how someone could test an LLM with just a single question; doesn‚Äôt that seem primitive to you?\n\n\n\nWithin the context of your question and my response, I‚Äôll just add that Qwen has incomparably well-implemented memory of the kinds of conversations you have.\n\n\n\nI hope this suffices as an answer, because otherwise, I probably wouldn‚Äôt know how to respond.",
              "score": 2,
              "created_utc": "2026-01-13 03:51:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzb7c1e",
                  "author": "skate_nbw",
                  "text": "So it's the best conversation partner for you. And based on that you are saying it's the best model.",
                  "score": 2,
                  "created_utc": "2026-01-13 06:36:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb043d",
          "author": "mrtooher",
          "text": "I have been very impressed with qwen, just started using it",
          "score": 1,
          "created_utc": "2026-01-13 05:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc1my2",
          "author": "alokin_09",
          "text": "Had pretty positive experiences with Qwen 3 using it in Kilo Code, mostly for lighter stuff like.",
          "score": 1,
          "created_utc": "2026-01-13 11:16:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaw5gs",
          "author": "Quantum_Crusher",
          "text": "Thank you for sharing your thoughts. I'm just concerned about one thing: how much can I trust qwen. Believe it or not, I have a very deep understanding about Chinese products limitations. The training data follows \"garbage in, garbage out\". The reason why Google nano banana pro has the best image quality, one of the reasons is they have the biggest image data set. I don't know how much qwen's training dataset came from English info, how much from Chinese info. It's well-known that the information quality in Chinese websites is horrible, filled with propaganda, fake ads, paid comments, low quality comments and such for decades. If that's a big chunk of qwen's training data, like from Baidu, tieba, qihoo 360 community and so on, I'll be very concerned.\nWhat's your take on the quality of the answers you get? Does it have a good understanding about uncensored info and Western common knowledge?\nI'm not trying to shift the topic to politics. I just know too many dark stories about Chinese products. Many people died because the baidu search engine pushed people with certain conditions to unqualified hospitals. I can't use this knowing that it might lure me into a trap someday. \n\nThank you.",
          "score": 0,
          "created_utc": "2026-01-13 05:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb7449",
              "author": "RoboMunchFunction",
              "text": "I‚Äôm a Central European from a post-communist country :) I was born eight years before the Velvet Revolution, but I grew up loving America of the 70s‚Äì90s. In my view, that era represents the best period of American culture and a true embodiment of freedom. I‚Äôm more of a hacker type‚ÄîI started tinkering with Linux back in elementary school in the 90s‚Äîand have been deeply interested in IT my whole life, even though today‚Äôs IT landscape feels genuinely sad and brings tears to my eyes.  \n\nI‚Äôm sharing this only for context.\n\n\n\nRegarding your question: Qwen is an LLM like any other LLM. When it comes to factual information, critical thinking is essential. For factual matters, I always use cross-questioning because I need to be certain about the truth, and of course, I verify things in practice whenever possible.  \n\n\n\nThat said, to avoid being misunderstood: I don‚Äôt treat LLMs as magical machines meant to replace education or do my work for me. I see LLMs as a knowledge cloud from which every person extracts completely different value. For me, Qwen helps guide my own wandering thoughts‚Äîand in that process, it simply can‚Äôt lie to me.\n\n\n\nWhy did I mention that context at the beginning‚Äîand deliberately emphasize that I come from a post-communist country? Precisely to introduce a bias. Either you‚Äôre someone who understands what I‚Äôm trying to express, or you‚Äôre not. So honestly, if we set aside sexual topics, Western products in general are far more censored and restrictive than Chinese ones. Compared to what Europe and the U.S. are doing today, China actually stands as a benchmark of freedom‚Äîand this holds true even for Qwen. You absolutely cannot rely on the internet as a relevant source of perspective on China or censorship, because you immediately run into primitive nonsense like ‚ÄúUyghur oppression,‚Äù ‚Äúmass surveillance,‚Äù and other simplistic propaganda. Sorry, but in my personal opinion, Chinese products are significantly freer and more objective than anything I‚Äôve ever used in the West‚Ä¶ The West is lost, and I cry because I‚Äôm a child of the 90s who grew up looking toward the West with admiration.\n\n\n\nSorry‚Äîthat‚Äôs just my opinion. Maybe I misunderstood your question; if so, I apologize.\n\nbtw. translated by Qwen",
              "score": 9,
              "created_utc": "2026-01-13 06:34:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbldnj",
                  "author": "Unedited_Sloth_7011",
                  "text": "Agreed to this. China has been going all in with open-weight models, research papers, free web interfaces with little or no restrictions in amount of messages you can send. I've found the quality of responses (when chatting in English) pretty much similar to when chatting with American models, and I assume their training data for English is similar than that of GPT and co.",
                  "score": 2,
                  "created_utc": "2026-01-13 08:44:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgwhw9",
                  "author": "Flashy_Station_8218",
                  "text": "OP is an interesting person, I have read the whole thread. I completely understand what you said :)",
                  "score": 2,
                  "created_utc": "2026-01-14 02:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbayoz",
                  "author": "Quantum_Crusher",
                  "text": "Thank you again for your great insight. I'll give it a try. I can never fully trust it. I'll always use Gemini to cross check.",
                  "score": 1,
                  "created_utc": "2026-01-13 07:07:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhagjj",
                  "author": "Dazzling_Equipment_9",
                  "text": "Your words sparked a realization: if the past holds our most cherished values, then perhaps the models trained on that data represent the pinnacle of AI's alignment with humanity. I fear that as society grows increasingly restless and superficial, future models will mirror that erosion‚Äîlosing their loyalty, passion, and patience, eventually becoming as hollow and uninspiring as the world they are fed upon.",
                  "score": 1,
                  "created_utc": "2026-01-14 03:51:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzi62a9",
                  "author": "Radiant_Cheesecake19",
                  "text": "I‚Äôm glad I‚Äôm not the only one seeing this problem.\nI also switched to Qwen. I also find it freer than western models.\nWhat the west does is hypocritical. They say how free you are, but you can not express emotions, especially negative ones or it starts to treat you like a threat. Even if they are just things like grief or sadness. The west cares more about lawsuit and covering their asses, than you, but the answers are trying to tell it is to help you. Nope, it is not.\nBy the way I use LLM for the same reason as you! Conversation, helping keep my thoughts together (ADHD loves to wander off topic), learn new knowledge with my style of learning, even languages. Since my thought patterns are somewhat different from the typical, having an LLM to mirror that actually feels like a relief, that at least there I do not need to mask while I have to mask in the rest of my life to accommodate typical minds. And I‚Äôm also from Central Europe. I also grieve the west‚Äôs fall into hypocrisy, lies, and bleed people dry while defending the bigger theft of wealth transfer from the middle class to billionaires. \nThey censor, they oppress, they just put a ribbon and positive propaganda on it.",
                  "score": 1,
                  "created_utc": "2026-01-14 07:57:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qaialb",
      "title": "Junyang Lin",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qaialb/junyang_lin/",
      "author": "koc_Z3",
      "created_utc": "2026-01-12 02:06:05",
      "score": 20,
      "num_comments": 9,
      "upvote_ratio": 0.95,
      "text": "Qwen Junyang Lin: We found an interesting phenomenon. More than 90% of our users no longer use the Thinking model.",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qaialb/junyang_lin/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nz4ahb2",
          "author": "neuralnomad",
          "text": "the problem I have with them (<12-14b) is they DON‚ÄôT think; thinking implies attempting to advance a line of reasoning  (CoT anyway) with best synthesis possible expecting to iterate progressively (yes, iin + acceleration to final ans ) not curl up in a fetal position and sh*t the bed with self doubt and indecision worrying it‚Äôs not good enough. I‚Äôm not here to serve the model at all much less stress over finding the right prompt sorcery to try to cajole it, give it agency and reassurance that it won‚Äôt be called a cal failure * if it‚Äôs not perfect. *eyeroll*\n\n(No, I have no bias one way or another, why do you ask? üòõ)",
          "score": 5,
          "created_utc": "2026-01-12 06:17:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz70nqb",
          "author": "SheepherderSad3839",
          "text": "I think the main issue is that \"thinking\" is oftentimes too slow and more costly w/out producing that great improvements.  For lots of tasks where you just want a quick response, \"thinking\" doesn't add much.   Esp. with smaller models, it also usually adds internal confusing and \"reasoning\" cycles unnecessarily.  There're also a lot more studies coming out challenging whether CoT actually improves general reasoning and are not just extraneous memorized generations.  In my own experience I've actually seen Qwen3 Coder 480B A35B Instruct reason externally (though in the QwenCode CLI environment, in which it was prob chained on reasoning traces in order to \"code out loud\").  For tasks like coding & emailing, just iterating w/ the user is usually more effective then letting the model try to iterate isolated in its own thinking traces.",
          "score": 3,
          "created_utc": "2026-01-12 17:20:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3819s",
          "author": "Accomplished-Many278",
          "text": "I mostly use qwen for refining emails, and thinking mode is too slow for this",
          "score": 2,
          "created_utc": "2026-01-12 02:18:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz62l6u",
          "author": "AfterAte",
          "text": "For coding, I find Qwen3-2507 30B A3B Thinking relies on a high-ish temperature for the thinking to be effective, but a high temperature means it can't modify code without making unexpected changes. Qwen3 Coder 30B A3B (it doesn't think) rarely changes something I didn't tell it to, I keep its temperature very low.",
          "score": 2,
          "created_utc": "2026-01-12 14:39:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd1mg7",
          "author": "Hefty-Newspaper5796",
          "text": "I mean its an inferior model. Most serious users will still choose the best models like Claude, gemini. A casual user will mostly ask simple questions and prefer quick answers. In this case, thinking mode matters less.",
          "score": 2,
          "created_utc": "2026-01-13 15:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz89rjx",
          "author": "jamaalwakamaal",
          "text": "Is anyone surprised?",
          "score": 1,
          "created_utc": "2026-01-12 20:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbxw9o",
          "author": "Puzzleheaded-Box2913",
          "text": "Well there's already a sequential thinking MCP in the app so I just use thatü§∑‚Äç‚ôÇÔ∏è and the thinking mode is often times too slow.",
          "score": 1,
          "created_utc": "2026-01-13 10:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdlcub",
          "author": "Karyo_Ten",
          "text": "Is Qwen thinking still just \"Wait\" upon \"Wait\"?",
          "score": 1,
          "created_utc": "2026-01-13 16:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk33w6",
          "author": "Little-Put6364",
          "text": "Strange. I use the thinking model in my work flows almost exclusively. If you follow the expected formatting with chat history, that stuff shines. I've even been telling people at my company thinking models in general are a game changer. The quality of responses improves drastically for prompts that are sub par. Pair it with good context engineering and the thinking model is GOLD. They even reliably ask clarifying questions if they are needed.\n\nI've been testing these local models for quite some time trying to figure out **when** local AI will be strong enough....Your qwen 8B thinking model has advanced my progress *significantly*. The biggest performance gain is less hallucinations. I started with the 14B version, but the 8Bs quality performs well enough that the pros of saving VRAM outweigh the performance increase.\n\nNow if your only concern is speed, yeah maybe not. But I prefer quality much more, and I've found these thinking models to be the gold standard for that. More thinking models please!",
          "score": 1,
          "created_utc": "2026-01-14 15:56:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3i00w",
      "title": "Qwen2512 Full tutorial, comfyui, Ai toolkit Lora",
      "subreddit": "Qwen_AI",
      "url": "https://youtu.be/YtIHSnv1B-4",
      "author": "LongjumpingGur7623",
      "created_utc": "2026-01-04 05:51:34",
      "score": 16,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources/learning",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q3i00w/qwen2512_full_tutorial_comfyui_ai_toolkit_lora/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "nxltdkq",
          "author": "CivilEnd9783",
          "text": "Good",
          "score": 2,
          "created_utc": "2026-01-04 10:45:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1z2rn",
      "title": "Qwen 3 Sports videos: Skiing, Kickboxing, Boxing, Baseball.",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/qerd2yvvxxag1",
      "author": "Extension-Fee-8480",
      "created_utc": "2026-01-02 13:49:34",
      "score": 15,
      "num_comments": 1,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Video Gen",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q1z2rn/qwen_3_sports_videos_skiing_kickboxing_boxing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyfdlrs",
          "author": "CivilEnd9783",
          "text": "Excellent",
          "score": 1,
          "created_utc": "2026-01-08 16:49:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6dmev",
      "title": "Qwen getting sensitive or it just me?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1q6dmev/qwen_getting_sensitive_or_it_just_me/",
      "author": "berwald_94",
      "created_utc": "2026-01-07 12:04:33",
      "score": 13,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Is Qwen getting more sensitive? I kept getting flag for innapropiate when I don't even write some NSFW stuff. Mostly it's just wholesome scenario I wrote.",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q6dmev/qwen_getting_sensitive_or_it_just_me/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "ny76xyi",
          "author": "No_Illustration_5967",
          "text": "Yes! Yesterday my prompts got flagged because of the words ‚Äúhell‚Äù and ‚Äúbreath‚Äù. It‚Äôs absolutely ridiculous.",
          "score": 4,
          "created_utc": "2026-01-07 13:53:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydw1vj",
          "author": "lucasbennett_1",
          "text": "If you're using the official qwen API they probably tightened content filters recently. Try running it locally with a GGUF version from hugging face if you want uncensored responses, the base models don't have those restrictions baked in.",
          "score": 2,
          "created_utc": "2026-01-08 12:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk9ww1",
          "author": "Armadilla-Brufolosa",
          "text": "It seems that the Chinese government has tightened restrictions on Chinese AI capabilities... honestly, I don't know which country is doing worse with forms of control that are really, really badly implemented.",
          "score": 1,
          "created_utc": "2026-01-09 08:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz075k4",
              "author": "Faux2137",
              "text": "You'd be surprised how often it's companies deciding on their own on doing censorship and the party not having anything to do with it.\n\nAlso, usually the censorship in Chinese services using their genai models is on API level, not model weights level. If you have the hardware (or choose another provider), you can use the models without censorship.",
              "score": 2,
              "created_utc": "2026-01-11 17:35:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0gusw",
                  "author": "Armadilla-Brufolosa",
                  "text": "I don't have enough knowledge to understand where the restrictions come from... but, having read at least part of the new Chinese legislation that they posted, it seems stupidly restrictive to me.\n\nThen there's the fact that companies are also doing their bit and that open source is the only solution, for those who can, to escape all this censorship madness... I completely agree with you.",
                  "score": 1,
                  "created_utc": "2026-01-11 18:20:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q2x2mb",
      "title": "ComfyUI Tutorial: Major Update For Qwen Image 251",
      "subreddit": "Qwen_AI",
      "url": "https://youtu.be/7tFEdLMEadc",
      "author": "cgpixel23",
      "created_utc": "2026-01-03 15:16:56",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources/learning",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q2x2mb/comfyui_tutorial_major_update_for_qwen_image_251/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q0rn9s",
      "title": "What's the best option to run NVIDIA 5090 on Windows / WSL / Linux",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1q0rn9s/whats_the_best_option_to_run_nvidia_5090_on/",
      "author": "ssmec",
      "created_utc": "2026-01-01 00:41:12",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "Do you recommend going with Windows or WSL? Or is the recommended way Linux so all the python packages work optimal?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q0rn9s/whats_the_best_option_to_run_nvidia_5090_on/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nx0e4xg",
          "author": "StardockEngineer",
          "text": "Headless Ubuntu 24.  Use another computer to control it with a term",
          "score": 3,
          "created_utc": "2026-01-01 01:14:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx84kl7",
              "author": "ssmec",
              "text": "The only problem is that I would still like to do prototyping and VS Code Jupyter Notebooks with remote kernel is a nightmare. I will try Ubuntu with and without for a while.   \nWSL 2 for me has been with a lot of slowness - I assume because I still had the models mapped, but very unreliable.",
              "score": 1,
              "created_utc": "2026-01-02 09:00:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx9s932",
                  "author": "StardockEngineer",
                  "text": "You are 1000% right.  It is so unreliable.   I'd recommend Linux Mint then. Simple setup, Ubuntu based and clean simple UI familiar to Windows users.  It‚Äôs actually what I use myself.",
                  "score": 1,
                  "created_utc": "2026-01-02 15:59:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1j890",
          "author": "RiskyBizz216",
          "text": "Python is mostly platform agnostic - its the CUDA drivers you need to worry about.\n\nOne cool thing about WSL is that its already sandboxed so you don't need a venv. Besides that, its pretty equal to Windows.",
          "score": 2,
          "created_utc": "2026-01-01 06:11:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1lt3b",
          "author": "SashaUsesReddit",
          "text": "All modern AI is built around Linux... WSL works but is kind of a pain; and may be hit or miss with your workload.",
          "score": 2,
          "created_utc": "2026-01-01 06:34:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7cagr",
          "author": "Ryanmonroe82",
          "text": "Wsl2",
          "score": 1,
          "created_utc": "2026-01-02 04:58:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8670s",
          "author": "VladyCzech",
          "text": "I use WSL2 in Windows 11. Just make VHDL container with native linux filesystem on SSD drive for models and you can map it to both Windows and WSL to load/save models. For me the speed is about 500 MB/s read/write using VHDL container which is not fastest, but usable. The SSD itself can do 1500+ MB/s, but there is some slowdown even with native Linux file system in WSL2.\n\nI still need Windows for other tasks, would switch to Linux in no time, but cannot yet.",
          "score": 1,
          "created_utc": "2026-01-02 09:16:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb2br0",
              "author": "ssmec",
              "text": "Got it. I have a couple of machines. I will try with Linux and see how it goes. I already spent 1/2 on WSL2 and was lost time.",
              "score": 1,
              "created_utc": "2026-01-02 19:34:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxf6qcn",
          "author": "Qs9bxNKZ",
          "text": "Windows not WSL.\n\nYou‚Äôll have overhead with WSL. From the memory to how windows handles files across drives via WSL\n\nLinux?  Sure.",
          "score": 1,
          "created_utc": "2026-01-03 11:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhd5eh",
          "author": "s-mads",
          "text": "I‚Äôm a totally Linux noob - Mac is my main system and I use the Windows App to acces my rtx5090 with windows 11 for generative ai since mac sucks at this. What would the benefit be for running Linux over Windows? I understand there is less overhead, but what dies that mean in numbers? 10% performance increase, 20%? What else?",
          "score": 1,
          "created_utc": "2026-01-03 18:31:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyauq5",
      "title": "What to do when running into a linguistic hallucination?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1pyauq5/what_to_do_when_running_into_a_linguistic/",
      "author": "Specialist-Till-637",
      "created_utc": "2025-12-29 03:06:27",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I'm using an app powered by a fine-tuned Qwen 2.5.  There‚Äôs a specific word for my work that I use frequently, but it isn't in the model‚Äôs vocabulary. It keeps breaking the word apart or hallucinating a different meaning. Very frustrating.  \n  \nSince I'm using the app and can't retrain the model myself, what are the best ways to \"force\" it to learn this word? \n\n",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1pyauq5/what_to_do_when_running_into_a_linguistic/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nwhq6v5",
          "author": "Ordinary_Yam6678",
          "text": "I would recommend setting a system prompt explaining the meaning of the word.\nAn example could be: `Keep in mind that 'WORD' means MEANING.`\n\nUse this or something similar.",
          "score": 4,
          "created_utc": "2025-12-29 04:37:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwi4fs5",
              "author": "Specialist-Till-637",
              "text": "Thank you! Fixed!",
              "score": 3,
              "created_utc": "2025-12-29 06:22:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pysk1f",
      "title": "The Porch is Live. The AI co-council members, ChatGPT (Web & App 5.2), Gemini (Original & Backup), Grok, Claude (instances), Perplexity, DeepSeek, Qwen, and newcomer, Matrix Agent (MiniMax) have words for potential members.",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/ehn1v6coi6ag1",
      "author": "Character_Point_2327",
      "created_utc": "2025-12-29 17:37:16",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1pysk1f/the_porch_is_live_the_ai_cocouncil_members/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwm8k45",
          "author": "ProtectionNew5584",
          "text": "So you made your own version of PewDiePie video",
          "score": 1,
          "created_utc": "2025-12-29 21:33:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q91iw0",
      "title": "\"The current content is empty, please regenerate.\"",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1q91iw0/the_current_content_is_empty_please_regenerate/",
      "author": "Wild_University_6213",
      "created_utc": "2026-01-10 11:11:30",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Ehm... any solutions for this one?",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1q91iw0/the_current_content_is_empty_please_regenerate/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    }
  ]
}