{
  "metadata": {
    "last_updated": "2026-02-19 17:08:33",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 20,
    "total_comments": 82,
    "file_size_bytes": 73124
  },
  "items": [
    {
      "id": "1r662ls",
      "title": "Qwen3.5-397B-A17B <Release>",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/9tm49g6b2ujg1",
      "author": "vibedonnie",
      "created_utc": "2026-02-16 10:24:10",
      "score": 313,
      "num_comments": 28,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r662ls/qwen35397ba17b_release/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5pdx2n",
          "author": "Sirius_Sec_",
          "text": "How much vram do I need ?",
          "score": 6,
          "created_utc": "2026-02-16 16:17:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t10ql",
              "author": "RG_Fusion",
              "text": "A bit over 200 GB for Q4-K-XL, not including your context window.",
              "score": 3,
              "created_utc": "2026-02-17 03:39:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w6fco",
                  "author": "stavrosg",
                  "text": "20t/s on 2x3090 and 3x3080, epyc 7352..",
                  "score": 3,
                  "created_utc": "2026-02-17 16:57:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5y2rcu",
                  "author": "yaxir",
                  "text": "and if you include context window, then?",
                  "score": 2,
                  "created_utc": "2026-02-17 22:19:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ny4rm",
          "author": "nunodonato",
          "text": "In that video where it is doing computer use in excel, what kind of software is that where the model runs? Is that something internal to the qwen team or is it publicly available?",
          "score": 4,
          "created_utc": "2026-02-16 11:11:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5omdfh",
          "author": "Efficient_Cattle_958",
          "text": "A model with 397Bparameter, that's something i didn't expect",
          "score": 8,
          "created_utc": "2026-02-16 13:59:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o07y2",
          "author": "chiliraupe",
          "text": "Will it come to qwen code cli?",
          "score": 2,
          "created_utc": "2026-02-16 11:29:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ph8mk",
              "author": "Popular_Tomorrow_204",
              "text": "It says \"more than just a CLI tool\" so i guess yes, it will come soon",
              "score": 2,
              "created_utc": "2026-02-16 16:33:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5q799a",
              "author": "itsappleseason",
              "text": "I'm seeing a reasoning model in qwen code. Have you checked today?",
              "score": 1,
              "created_utc": "2026-02-16 18:33:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5reo1p",
                  "author": "chiliraupe",
                  "text": "yes its in there but how many parameters?",
                  "score": -2,
                  "created_utc": "2026-02-16 22:02:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ourwf",
          "author": "NoobMLDude",
          "text": "But can it Code ? ðŸ˜‰",
          "score": 2,
          "created_utc": "2026-02-16 14:44:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qbtg0",
          "author": "Extension-Pen-109",
          "text": "Ok. Opensource, but for what machine?",
          "score": 2,
          "created_utc": "2026-02-16 18:54:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ybu5r",
              "author": "Any_Reading_5090",
              "text": "GPU Cluster...appr 700000â‚¬",
              "score": 3,
              "created_utc": "2026-02-17 23:06:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5p72cy",
          "author": "infdevv",
          "text": "why is this edited like some cinematic movie trailer. actually peak",
          "score": 1,
          "created_utc": "2026-02-16 15:45:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qqpp1",
              "author": "Opposite-Station-337",
              "text": "there is a non-zero chance ai made the video... and yeah... ngl the audio/video combination gave me chills. damn nervous system responding to hype.",
              "score": 1,
              "created_utc": "2026-02-16 20:05:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5sudjn",
          "author": "hazeslack",
          "text": "Is there any flash version?",
          "score": 1,
          "created_utc": "2026-02-17 02:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vyy42",
          "author": "jemand_tw",
          "text": "Any version below 120B?",
          "score": 1,
          "created_utc": "2026-02-17 16:19:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w6fod",
          "author": "Sea-Share6668",
          "text": "And it's a complete black ass with generating images and videos, it looks especially shitty after the TRIUMPH in December 2025 with the Qwen-image-2512 model!!! :-(((",
          "score": 1,
          "created_utc": "2026-02-17 16:57:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y2ti5",
          "author": "yaxir",
          "text": "I wish ChatGPT would do the same for GPT 4.1",
          "score": 1,
          "created_utc": "2026-02-17 22:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ygiow",
          "author": "yaxir",
          "text": "abliterated version?",
          "score": 1,
          "created_utc": "2026-02-17 23:32:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60w8hr",
          "author": "No-Daikon1554",
          "text": "Why doesn't qwem cite at least 50 sources per query to beat perplexity and chatgpt plus?Â ",
          "score": 1,
          "created_utc": "2026-02-18 09:22:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61lpkx",
          "author": "ClueCool1165",
          "text": "Any optimized guffs?",
          "score": 1,
          "created_utc": "2026-02-18 12:47:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67vr6f",
          "author": "Sharp-Mouse9049",
          "text": "Wah wah we wah",
          "score": 1,
          "created_utc": "2026-02-19 10:19:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6s0ri",
      "title": "Alibaba just open-sourced a model that rivals GPT-5.2",
      "subreddit": "Qwen_AI",
      "url": "https://medium.com/reading-sh/alibaba-just-open-sourced-a-model-that-rivals-gpt-5-2-708502e25250?sk=425ccf8e2abb8068adedabd2b2cc9050",
      "author": "jpcaparas",
      "created_utc": "2026-02-17 01:10:00",
      "score": 159,
      "num_comments": 24,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r6s0ri/alibaba_just_opensourced_a_model_that_rivals_gpt52/",
      "domain": "medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5slls3",
          "author": "Puzzleheaded-Box2913",
          "text": "And it's actually pretty good",
          "score": 18,
          "created_utc": "2026-02-17 02:04:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tgd2b",
          "author": "johanna_75",
          "text": "What are the usage limits on the public website?",
          "score": 6,
          "created_utc": "2026-02-17 05:27:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5u241x",
              "author": "Unedited_Sloth_7011",
              "text": "I've never run into usage limits, personally. I suspect they aren't any",
              "score": 6,
              "created_utc": "2026-02-17 08:38:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5u28s9",
                  "author": "johanna_75",
                  "text": "If itâ€™s as good as people are saying, and it has little or no usage limits then that seems almost too good to be true?",
                  "score": 5,
                  "created_utc": "2026-02-17 08:40:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ukt9e",
          "author": "solarkraft",
          "text": "30B version when?\n\nThis model really looks great, would be even more awesome to have a small model to run locally. Makes total sense to release the big headliner first of course.Â ",
          "score": 6,
          "created_utc": "2026-02-17 11:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63ovow",
              "author": "Qwen30bEnjoyer",
              "text": "Could be that these results are just from scale.",
              "score": 1,
              "created_utc": "2026-02-18 18:48:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u7wpf",
          "author": "FederalLook5060",
          "text": "Waiting for Qwen code 3.5 400b as well.",
          "score": 1,
          "created_utc": "2026-02-17 09:34:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60crhv",
          "author": "TopTippityTop",
          "text": "5.3 codex is out though, and really good. 5.2 is old news, and Qwen loses on some significant benchmarks to both 5.2 and Claude. Obviously benchmarks only go so far, the real test is actually trying it out on useful tasks.",
          "score": 1,
          "created_utc": "2026-02-18 06:25:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61o8wt",
          "author": "MrMrsPotts",
          "text": "It's really not as good as chatgpt 5.2 or Gemini 3  for math, at least. I gave it a medium hard grade 9 question which chatgpt and Gemini  can both do and it completely failed.  You can try it with this: \n\nProve that there exists an infinity of a, b, c âˆˆ Q strictly positive such that  \n\n  \n\na + b + c âˆˆ Z and 1/a + 1/b + 1/c âˆˆ Z.  \n\n  \n\nPlease use 9th-grade level math.",
          "score": 1,
          "created_utc": "2026-02-18 13:03:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61tjhf",
          "author": "thecodeassassin",
          "text": "I'm running this model locally, and while I'm surprised how good it is it still doesn't really feel on the same level as GPT 5.2. mostly fine but it does make quite a lot of mistakes and doesn't correct it's mistakes as well as the frontier models.\n\nIt's really quite bad at designing good architecture.\n\nIn short: it's getting closer but it's not quite there yet.",
          "score": 1,
          "created_utc": "2026-02-18 13:33:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62rq95",
              "author": "JaatGuru",
              "text": "Which version are you running locally? Am looking for coding.",
              "score": 1,
              "created_utc": "2026-02-18 16:20:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o62wycp",
                  "author": "thecodeassassin",
                  "text": "Qwen 3.5 379b-A17B with llama cpp",
                  "score": 1,
                  "created_utc": "2026-02-18 16:44:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5w65lz",
          "author": "getaway-3007",
          "text": "What are you basing your claims off of? I always look at these chinese models like MiniMax, GLM-5, Kimi-k2.5 claiming they're on same level as OPUS etc when they're actually not.\n\nI've spent 500M tokens on GLM 4.7+GLM 5+MiniMax m2.1 and the amount of steering, additional context I have to give in comparison of codex or Opus is huge. Also the speed difference is very noticeable.",
          "score": 1,
          "created_utc": "2026-02-17 16:56:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o627akm",
              "author": "ChainPlastic7530",
              "text": "I have yet too find anyone using deepseek yet supposedly its \"crushing the west\"   \nthey mastered the art of performing good on benchmark though",
              "score": 1,
              "created_utc": "2026-02-18 14:45:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63eu9x",
                  "author": "Additional_Long_8589",
                  "text": "i use it \n\n",
                  "score": 1,
                  "created_utc": "2026-02-18 18:04:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ti7q0",
          "author": "VillPotr",
          "text": "Code version too?",
          "score": 0,
          "created_utc": "2026-02-17 05:41:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ulzw8",
              "author": "Particular-Way7271",
              "text": "It can already code pretty well and it has vision as well.",
              "score": 1,
              "created_utc": "2026-02-17 11:40:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7ftal",
      "title": "QWEN 3.5 - I'm impressed",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r7ftal/qwen_35_im_impressed/",
      "author": "Possible-Ad-6815",
      "created_utc": "2026-02-17 19:20:08",
      "score": 129,
      "num_comments": 18,
      "upvote_ratio": 0.97,
      "text": "I have to say I am really impressed with what I am seeing so far.  I am working on a 250,000 line SaaS project right now and working largely with Codex 5.3 X high, Opus 4.6 and have used GLM 5 and Kimi 2.5 for reviewing and comparison work. \n\nI had would should have been a simple issue with fly our menus from a compacted side menu, only one worked. Codex had 3 attempts and failed so aftr 3 attempts I would switch to Opus and usually the 'fresh eyes' fix it right away (happens if the issues appears on Opus 4.6 and then introduce codex, it fixes it right away). However, on this occasion both failed after 3 attempts. As it had recently been installed, I asked Qwen to take a look. I explained in the prompt (as I had to Opus) that lateral thinking was required, it the issue was as it first appeared, Codex would have fixed it. \n\n\n\nBoth codex and Opus had suggested the same fault and were looking in that area. Qwen suggested something different, extracted and presented small pieces of code to explain why why there was and issue and how to fix it. Additionally, it pointed out several areas where the code could be improved (a module per pop-out menu was being used, it suggested use one to suit all. simple stuff but neither opus nor codex suggested this.\n\nthe fix worked first time so was exactly as Qwen had suggested and not as either opus or codex had considered \n\n**Optimisation for benchmarking?**\n\nWhilst on Qwen is up there but not topping the charts and having used Qwen to further optimise this project by reducing resource usage on server monitoring by 50%, it got me thinking. in another world of mine I design and optimise high performance directional antennas. These are compared with others on a standard computer model comparison bench. I have optimised models in the past to fair well on benchmarks even though in the real-world applications, a deviance from the bench optimisation shows better results. \n\nPerhaps it is worth trying qwen on your own projects and take a leap of faith. it might be Qwen engineers just haven't worked out how best to 'cheat' the benchmarks yet or perhaps, they just don't want to. \n\nNot read back no edited with AI. However, I am sure you guessed that :-)\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r7ftal/qwen_35_im_impressed/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5xx5nf",
          "author": "Final-Rush759",
          "text": "Qwen models are very intelligent . Sometimes making mistakes writing code. They usually don't do well on the benchmarks.  If you just use them in chat, they gives some crazy good ideas.",
          "score": 10,
          "created_utc": "2026-02-17 21:52:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ydrav",
          "author": "arjundivecha",
          "text": "Qwen is the only chinese company that doesnâ€™t have a reputation for benchmaxxing",
          "score": 4,
          "created_utc": "2026-02-17 23:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zixeo",
          "author": "AndThenFlashlights",
          "text": "What do you like for tooling to interact with Qwen3.5? I generally prefer the output of the Qwen models, but Claude's tooling is just so much easier and better out of the box.",
          "score": 1,
          "created_utc": "2026-02-18 02:59:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60f8pc",
              "author": "Possible-Ad-6815",
              "text": "Why not run qwen in Claude Code and get the best of both worlds? Additionally, I create my own /skills/ folder with a workflow and set of opus 4.6 designed skills and workflow any agent must follow (set in agents.md) so each LLM is singing from the say hymn sheet, so to speak",
              "score": 1,
              "created_utc": "2026-02-18 06:46:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o65yuqu",
                  "author": "yaxir",
                  "text": "how can I run this in Claude code?\n\nAnd we are running an external model and clout code affect Claude usage limits or not?",
                  "score": 1,
                  "created_utc": "2026-02-19 01:36:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60ew4m",
          "author": "TopTippityTop",
          "text": "I'm not impressed with the Qwen models I've been using, but I'll give the new one a shot",
          "score": 1,
          "created_utc": "2026-02-18 06:43:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60r7iu",
          "author": "InfamousReward1419",
          "text": "Which IDE do you use to access Qwen ?",
          "score": 1,
          "created_utc": "2026-02-18 08:35:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64usem",
          "author": "Potential_Bicycle648",
          "text": "Im not surprised Codex and Opus were stuck... Qwens lateral thinking is wild.",
          "score": 1,
          "created_utc": "2026-02-18 22:01:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5x1mkd",
          "author": "Samy_Horny",
          "text": "Qwen is a company that's practically being overshadowed even by Minimax, so it doesn't surprise me. Although, it's been a while since I've worked with programming, to mention that it's better than Opus... that says quite a lot. Many engineers consider Claude's models to be the best in that area. I remember working with the newly released Sonnet 3.5 and being fascinated, even though it still had bugs.",
          "score": -3,
          "created_utc": "2026-02-17 19:23:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xfc8g",
              "author": "Possible-Ad-6815",
              "text": "I donâ€™t suggest it is better than opus nor codex. In other tests it might fall behind. However, from what I am seeing it gives a different an very useful â€˜view pointâ€™ from a coding perspective",
              "score": 4,
              "created_utc": "2026-02-17 20:28:35",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5zeyg3",
              "author": "Euphoric_Oneness",
              "text": "Qwen is from Alibaba and the it can buy Openai, claude together. What company is overshadowed lol. Africa is not a country sir.",
              "score": 2,
              "created_utc": "2026-02-18 02:37:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60f161",
                  "author": "TopTippityTop",
                  "text": "For that reason alone the models should be much better, which they are not. They get overshadowed.",
                  "score": 1,
                  "created_utc": "2026-02-18 06:44:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o62vxn3",
                  "author": "PlatypusWinterberry",
                  "text": "Isnt OpenAI worth 500b now while Alibaba sits at 400ish?",
                  "score": 1,
                  "created_utc": "2026-02-18 16:39:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r37m7c",
      "title": "Alexandria: A free & Open-source Qwen3TTS based audiobook generator",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r37m7c/alexandria_a_free_opensource_qwen3tts_based/",
      "author": "finrandojin_82",
      "created_utc": "2026-02-12 22:29:49",
      "score": 78,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nI'm a long-time reader and AI enthusiast. I've used all the available TTS options, but nothing really stuck out to me, so I decided to make my own.\n\n**Introducing: Alexandria.** Itâ€™s a free, open-source audio book generator for creating audio versions of fiction or books locally on your own computer.\n\n**AUDIO SAMPLE:** [https://vocaroo.com/1cG82gVS61hn](https://vocaroo.com/1cG82gVS61hn) (Sion LoRA, comes built-in)\n\n# What it does:\n\n* **Automatic Scripting:** An LLM reads your text and automatically splits it into a script, identifying speakers, dialogue, and narration, while writing vocal directions for each line.\n* **Local TTS Engine:** Uses **Qwen3-TTS 1.7B** to generate audio with per-line emotion and delivery control. No character limits or subscription fees.\n* **Character Management:** Assign individual voices to every character in your story.\n\n# Advanced Voice System (5 Types):\n\n* **Custom:** 9 built-in voices with instruct control (emotion, tone, pacing).\n* **Clone:** Clone any voice from a short reference audio clip.\n* **LoRA:** Train a persistent custom voice identity from \\~15-60 samples (includes the training pipeline).\n* **Voice Design:** Describe a voice in plain text (*\"A gravelly old man with a dry wit\"*) and generate it on the fly.\n* **Saved Design:** Save your created voices to keep them consistent across a long series.\n\n# The Editor & Export:\n\n* **Fine-Grained Control:** Review and edit every line. Regenerate individual lines with different seeds, voices, or instructions.\n* **Directives:** Tell the TTS exactly how to deliver a line (e.g., *\"Cold fury, dangerously quiet\"* or *\"Exhausted, barely holding it together\"*).\n* **Flexible Export:** Export as a single MP3 or as a **per-speaker Audacity project** (separate tracks for each character with labels).\n\n**GitHub Repository:** [https://github.com/Finrandojin/alexandria-audiobook](https://github.com/Finrandojin/alexandria-audiobook)\n\nIâ€™m really looking for feedback from users on this, specifically if there are features (like better handling of markdown or specific web-novel formatting) that would make it more useful.",
      "is_original_content": false,
      "link_flair_text": "Vibe Coding",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r37m7c/alexandria_a_free_opensource_qwen3tts_based/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o6237ou",
          "author": "joofio",
          "text": "Testing now. Using Qwen3:4b, will report ASAP",
          "score": 2,
          "created_utc": "2026-02-18 14:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o543kii",
          "author": "Impossible_Ground_15",
          "text": "great share! thank you!",
          "score": 1,
          "created_utc": "2026-02-13 05:06:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o548oyb",
          "author": "Luisgmnz",
          "text": "Does it work in Spanish?",
          "score": 1,
          "created_utc": "2026-02-13 05:45:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55gq5g",
              "author": "finrandojin_82",
              "text": "Yes, the Qwen3TTS supports: Chinese, English, German, Italian, Portuguese, Spanish, Japanese, Korean, French, and Russian.\n\nYou might need to to rewrite or modify the system and script review prompts to better support languages other than English. there is also a manual setting for language in the settings menu that defaults to \"Auto\"",
              "score": 1,
              "created_utc": "2026-02-13 12:14:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o54n7e2",
          "author": "throwawayaccount931A",
          "text": "This is great! Thank you!\n\n",
          "score": 1,
          "created_utc": "2026-02-13 07:51:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bdxrv",
          "author": "Neat_Cartographer864",
          "text": "I'll tell you about a feature I'm looking for that no one seems to have.\n\n\nThere are two very widely spoken languages â€‹â€‹in the world: English and Spanish.\n\nI'm Spanish and I read a lot of books in English... But... Why do I read so many in English? Simply because there's no official Spanish translation.\n\n\nSo the feature I'm looking for is for an English book to first be translated into Spanish and then converted into an audiobook.",
          "score": 1,
          "created_utc": "2026-02-14 09:41:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bnsin",
              "author": "finrandojin_82",
              "text": "Well the LLM system prompt could technically be modified to translate the work on the fly along with the script parsing. Or repurpose the script review step to do that. The underlying TTS engine already supports Spanish so.\n\nYou would need a rather good LLM model to do so. If you're up, give it a spin. The system prompt is user configurable under \"Prompt settings\" in the setup page.",
              "score": 1,
              "created_utc": "2026-02-14 11:17:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5kh81w",
          "author": "EconomySerious",
          "text": "Your works is really a work of love, i'll test and feedbak",
          "score": 1,
          "created_utc": "2026-02-15 20:36:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5mchx",
      "title": "Waiting room for Qwen3.5",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r5mchx/waiting_room_for_qwen35/",
      "author": "No-Evidence8589",
      "created_utc": "2026-02-15 18:41:36",
      "score": 67,
      "num_comments": 7,
      "upvote_ratio": 0.96,
      "text": "Creating a thread for anyone refreshing GitHub waiting for Qwen3.5 ðŸ˜…",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r5mchx/waiting_room_for_qwen35/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5jvo6g",
          "author": "Samy_Horny",
          "text": "I just hope it doesn't take more than 2 weeks. I remember when they created the Qwen support thread (edit 1125), the model came out almost 3 weeks later.",
          "score": 4,
          "created_utc": "2026-02-15 18:48:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k4phv",
              "author": "Significant_Fig_7581",
              "text": "Someone told me 24 Feb but I hope sooner\n\nedit: they're dropping it today!",
              "score": 2,
              "created_utc": "2026-02-15 19:32:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5kkrvk",
          "author": "Whole_Entrance2162",
          "text": "Don't worry, I think it will be released today(Chinese New Year's Eve).",
          "score": 2,
          "created_utc": "2026-02-15 20:55:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5muo1n",
          "author": "Fair-Position8134",
          "text": "![gif](giphy|sthmCnCpfr8M8jtTQy)",
          "score": 2,
          "created_utc": "2026-02-16 05:14:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5k4mc8",
          "author": "Significant_Fig_7581",
          "text": "I swear to God you must be talking about me",
          "score": 1,
          "created_utc": "2026-02-15 19:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5l0c8m",
          "author": "GCoderDCoder",
          "text": "If qwen3 coder- next is this good now I'm curious to see the qwen3 235b update. That was my first big local model eventhough I struggled running it with my original hardware. Im always rooting for Qwen!",
          "score": 1,
          "created_utc": "2026-02-15 22:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jvhlo",
          "author": "kmuentez",
          "text": ".\n\n",
          "score": -1,
          "created_utc": "2026-02-15 18:47:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4jfw7",
      "title": "The newly introduced Qwen Slides (Qwen-3 + Qwen-Image-2) is insane, I gave it 79 page PDF, and it gave me a professionally made 80 Mb PPT",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r4jfw7/the_newly_introduced_qwen_slides_qwen3_qwenimage2/",
      "author": "abdouhlili",
      "created_utc": "2026-02-14 12:29:22",
      "score": 53,
      "num_comments": 2,
      "upvote_ratio": 0.98,
      "text": "Link : \n\nhttps://chat.qwen.ai/s/t_60e10220-d105-4eee-a284-58083b27df6b?fev=0.2.0",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r4jfw7/the_newly_introduced_qwen_slides_qwen3_qwenimage2/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5df86h",
          "author": "tuxedo0",
          "text": "how do i do this? i uploaded a PDF, used the same prompt, and i get a big summary of the slides but i don't get a deck itself. do i need a paid account?",
          "score": 1,
          "created_utc": "2026-02-14 17:42:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dghzp",
              "author": "abdouhlili",
              "text": "In the main page click in the (+) button, scroll down (if you use the mobile), and a list of features will appear, click on slides, it's free but limited quota/day.",
              "score": 1,
              "created_utc": "2026-02-14 17:48:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5wml6",
      "title": "Something big is coming on Feb 17",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r5wml6/something_big_is_coming_on_feb_17/",
      "author": "botkeshav",
      "created_utc": "2026-02-16 01:50:30",
      "score": 37,
      "num_comments": 5,
      "upvote_ratio": 0.97,
      "text": "Just saw the teaser. Qwen 3.5 is reportedly being tested in the arena. Are you ready?",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r5wml6/something_big_is_coming_on_feb_17/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5m62zz",
          "author": "Hefty-Newspaper5796",
          "text": "It will be big if it makes Claude cheaper.",
          "score": 4,
          "created_utc": "2026-02-16 02:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m6ixp",
          "author": "JestonT",
          "text": "Nice, so basically on the first day of Lunar New Year.",
          "score": 1,
          "created_utc": "2026-02-16 02:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mexv6",
          "author": "neil_555",
          "text": "arena as in [https://arena.ai/](https://arena.ai/) if so it's not on there yet\n\n",
          "score": 0,
          "created_utc": "2026-02-16 03:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5n917l",
          "author": "madaradess007",
          "text": "qwen, please don't forget 8b size!\n\ni feel bad using 4b, while having capacity for 8b",
          "score": 0,
          "created_utc": "2026-02-16 07:16:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5n9exa",
              "author": "hosohep",
              "text": "What ur achiving with that small model?",
              "score": 0,
              "created_utc": "2026-02-16 07:20:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r68lqf",
      "title": "Did you like the new Qwen 3.5?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r68lqf/did_you_like_the_new_qwen_35/",
      "author": "drhenriquesoares",
      "created_utc": "2026-02-16 12:41:45",
      "score": 35,
      "num_comments": 19,
      "upvote_ratio": 0.93,
      "text": "I did some tests and found it to be so-so, kind of \"meh\".\n\nWhat did you guys think?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r68lqf/did_you_like_the_new_qwen_35/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5oa2gk",
          "author": "Shoddy-Department630",
          "text": "Personally I'm just waiting for the Coder version of it. I don't usually use Multimodal.",
          "score": 9,
          "created_utc": "2026-02-16 12:45:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oa4pb",
              "author": "drhenriquesoares",
              "text": "I understood.",
              "score": 1,
              "created_utc": "2026-02-16 12:45:56",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5ptpud",
              "author": "Boring_Aioli7916",
              "text": "I heard there will be no new models from scratch by Qwen/Alibaba anytime soon cause Qwen Coder next was released just 2 weeks ago and in their own words ''\n\n# From the Qwen3-Coder-Next Technical Report:\n\n>*\"Looking ahead, we believe strong agent skillsâ€”like using tools by itself, handling tough problems, and managing complex tasksâ€”are key for better coding agents. Next, we plan to improve the model's reasoning and decision-making, support more tasks, and update quickly based on how people use it.*\n\n**Translation:** They're iterating *on Coder-Next itself*, not building a new parallel coding model.",
              "score": 1,
              "created_utc": "2026-02-16 17:30:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5tb9hy",
              "author": "alfons_fhl",
              "text": "Do you get any information about the coder version?\n\nI hope they will release something like qwen3.5-coder-next",
              "score": 1,
              "created_utc": "2026-02-17 04:49:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5odeau",
          "author": "Significant_Fig_7581",
          "text": "I haven't tried them yet since they chose not to release the 9B and 35B models...",
          "score": 5,
          "created_utc": "2026-02-16 13:07:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ozyrk",
              "author": "AppealThink1733",
              "text": "Will 4B or less be released?",
              "score": 2,
              "created_utc": "2026-02-16 15:11:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ph5vg",
                  "author": "Significant_Fig_7581",
                  "text": "Yup. I think they've confirmed 2B Already and I don't see a reason for them not to release a 4B model as well, Qwen is a great model, Alibaba Cloud in general are great and they have a lot of compute power so dw :)",
                  "score": 2,
                  "created_utc": "2026-02-16 16:32:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ogkk1",
          "author": "Puzzleheaded-Box2913",
          "text": "Seems interesting but haven't really used it yet",
          "score": 2,
          "created_utc": "2026-02-16 13:27:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5p1xte",
          "author": "gusnbru1",
          "text": "I use Qwen 3 max thinking on an API. I find it quite good. I get great output that sometimes is indistinguishable from Gemini 3 pro. When I don't care about burning tokens that's might go to. It's very cost effective.",
          "score": 2,
          "created_utc": "2026-02-16 15:21:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r3yyh",
          "author": "Sketusky",
          "text": "Waiting for 30B coder",
          "score": 2,
          "created_utc": "2026-02-16 21:10:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ow974",
          "author": "ciprianveg",
          "text": "waiting for awq to test it on vllm :)",
          "score": 1,
          "created_utc": "2026-02-16 14:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qqe54",
          "author": "Samy_Horny",
          "text": "I think it's the best model for extracting prompts from existing images.\n\n\nAlthough I think there's variability between the two versions. Qwen 3VL already outperformed models like Grok 4.1; let's see how Grok 4.20 performs in that regard.",
          "score": 1,
          "created_utc": "2026-02-16 20:03:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tgwiz",
          "author": "rambadhur",
          "text": "nothing new nothing feels like an improvementÂ ",
          "score": 1,
          "created_utc": "2026-02-17 05:31:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ts3hs",
          "author": "First_Ambition_7717",
          "text": "No good code plan to access qwen 3.5, not local llm friendly, no one will care it.",
          "score": 1,
          "created_utc": "2026-02-17 07:04:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uvqat",
          "author": "Cool-Chemical-5629",
          "text": "My use cases are coding and creative writing that requires good general knowledge and I'd really like to see some examples that showcase what makes this model better than their last Qwen 3 235B or the big coder model, because I don't really see it and yet this one is so much bigger than the previous model. I'm like, there simply must be some noticeable significant improvements somewhere, right?\n\nNot to mention that at this point they made a significantly bigger model than GLM 4.7 (397B of Qwen 3.5 vs 358B of GLM 4.7), but GLM 4.7 is significantly better. How? Just how do you make a bigger but worse model? If anything, Qwen 3.5 is a testament that the size of these models is not everything.",
          "score": 1,
          "created_utc": "2026-02-17 12:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62czhk",
          "author": "Happy-Scholar9411",
          "text": "Yes",
          "score": 1,
          "created_utc": "2026-02-18 15:13:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r30ezv",
      "title": "Good girl",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/3v1cg12or3jg1",
      "author": "SnooComics9369",
      "created_utc": "2026-02-12 17:58:09",
      "score": 32,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Video Gen",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r30ezv/good_girl/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5dg8vk",
          "author": "Mx4n1c41_s702y73ll3",
          "text": "How easy it is to manipulate a human by showing him pictures.",
          "score": 1,
          "created_utc": "2026-02-14 17:47:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3ixmk",
      "title": "I open-sourced qwen3-asr-swift â€” native on-device ASR & TTS for Apple Silicon in pure Swift",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r3ixmk/i_opensourced_qwen3asrswift_native_ondevice_asr/",
      "author": "ivan_digital",
      "created_utc": "2026-02-13 07:31:13",
      "score": 26,
      "num_comments": 15,
      "upvote_ratio": 0.94,
      "text": "Hey everyone! I just published a blog post breaking down the architecture and benchmarks behindÂ **qwen3-asr-swift**, an open-source Swift package that brings Qwen3's speech models to Apple Silicon natively using MLX Swift.\n\n**What it does:**\n\n* **ASR (Speech-to-Text):**Â Qwen3-ASR running on-device with \\~100ms time-to-first-token and RTF of 0.064 â€” supports 52 languages (30 major + 22 Chinese dialects)\n* **TTS (Text-to-Speech):**Â Qwen3-TTS generating natural, expressive speech faster than real-time (RTF < 1.0)\n* Runs entirely on Mac (M1â€“M4) and iOS â€” no cloud, no API keys\n\n**Why I built it:**Â There was no native Swift implementation of Qwen3 speech models. The Python/MLX ecosystem hadÂ `mlx-audio`, but if you wanted to integrate ASR or TTS into a Swift app, you were out of luck. This package gives you a clean Swift API with SPM support.\n\n**Quick taste of the API:**\n\nswift\n\n    import Qwen3ASR\n    let model = try await Qwen3ASRModel.fromPretrained()\n    let text = model.transcribe(audio: samples, sampleRate: 16000)\n\n**Key benchmarks (M3 Max):**\n\n* Qwen3-ASR-0.6B: WER 2.11% on LibriSpeech clean â€” and crucially, 17.88% in noisy conditions vs Whisper's 63.17%\n* Qwen3-ASR-1.7B: even better at 1.63% WER clean\n\nThe blog post dives into the full encoder-decoder architecture, mel spectrogram pipeline, how the audio encoder and Qwen3 text decoder are wired together, and real-world performance numbers.\n\nðŸ“– Blog post:Â [https://blog.ivan.digital/qwen3-asr-swift-on-device-asr-tts-for-apple-silicon-architecture-and-benchmarks-27cbf1e4463f](https://blog.ivan.digital/qwen3-asr-swift-on-device-asr-tts-for-apple-silicon-architecture-and-benchmarks-27cbf1e4463f)\n\nðŸ’» GitHub:Â [https://github.com/ivan-digital/qwen3-asr-swift](https://github.com/ivan-digital/qwen3-asr-swift)\n\nLicensed Apache 2.0. Stars, issues, and PRs welcome!",
      "is_original_content": false,
      "link_flair_text": "Experiment",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r3ixmk/i_opensourced_qwen3asrswift_native_ondevice_asr/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5563am",
          "author": "otzjog",
          "text": "Very cool! I am not into Swift, but this sounds like a great project. Just wanted to cheer you up, GJ!",
          "score": 1,
          "created_utc": "2026-02-13 10:48:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5565q7",
              "author": "ivan_digital",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2026-02-13 10:49:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5566pj",
                  "author": "exclaim_bot",
                  "text": ">Thanks!\n\nYou're welcome!",
                  "score": 1,
                  "created_utc": "2026-02-13 10:49:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55gv6t",
          "author": "QuanstScientist",
          "text": "I did the same, gonna compare the code! ",
          "score": 1,
          "created_utc": "2026-02-13 12:15:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58q1iw",
          "author": "finrandojin_82",
          "text": "Hi,\n\n  \nI'm using the CUDA version of Qwen3TTS in my project and took a look at your repo. I'm by no means a coder but it seems there is no parallelisation avalable? With the Python API on [https://github.com/QwenLM/Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) it's possible to pass a list of texts. the primary problem is that token generation only stops when the longest sequence stops but there is still room for 2-3x speedup if generating many lines as fast as possible is the target and you have the lines ready to go.",
          "score": 1,
          "created_utc": "2026-02-13 22:10:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5930kl",
              "author": "ivan_digital",
              "text": "u/finrandojin_82 I added batch support, to run inference on list of texts, it might affect memory usage though - [https://github.com/ivan-digital/qwen3-asr-swift/pull/6](https://github.com/ivan-digital/qwen3-asr-swift/pull/6) check out this PR",
              "score": 1,
              "created_utc": "2026-02-13 23:21:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o597vm0",
                  "author": "finrandojin_82",
                  "text": "Okay, a few lessons I learned, relayed here.\n\n1. Batching can lead to OOM really easily, all it requires is making a batch of short clips and one fails to hit EOS, now all \"short\" lines are 2048 tokens worth of KV cache filled.\n\n2.  Again grouping one reeeaaally long line with a bunch of small ones, same effect.\n\n3.  The ref\\_audio token count isn't known until it's been processed into a clone prompt, you can approximate from audio duration at \\~12 tokens/sec, but the exact cost depends on the tokenizer output.",
                  "score": 1,
                  "created_utc": "2026-02-13 23:50:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5b8j4x",
          "author": "pinthead",
          "text": "Could this be compiled into some app like whisper flow that runs natively on the Mac but uses the local qwen models instead ?",
          "score": 1,
          "created_utc": "2026-02-14 08:47:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5b8vjv",
              "author": "ivan_digital",
              "text": "This is exact purpose of the library, to be plugged in into some application, to run locally.",
              "score": 1,
              "created_utc": "2026-02-14 08:51:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e1rf2",
          "author": "Appropriate-Past6472",
          "text": "What about this\n\nBuilt-in speakers (varies by model): aiden, dylan, eric, ono\\_anna, ryan, serena, sohee, uncle\\_fu, vivian?",
          "score": 1,
          "created_utc": "2026-02-14 19:35:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ehdpt",
              "author": "ivan_digital",
              "text": "I added support for custom voice [https://github.com/ivan-digital/qwen3-asr-swift/pull/9](https://github.com/ivan-digital/qwen3-asr-swift/pull/9)",
              "score": 1,
              "created_utc": "2026-02-14 20:59:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ehkol",
                  "author": "Appropriate-Past6472",
                  "text": "Thanks, awesome.  \n  \nIs any plan for supporting 8-bit TTS model?",
                  "score": 1,
                  "created_utc": "2026-02-14 21:00:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r66h5k",
      "title": "Qwen-3.5 is here",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r66h5k/qwen35_is_here/",
      "author": "Unedited_Sloth_7011",
      "created_utc": "2026-02-16 10:48:22",
      "score": 25,
      "num_comments": 2,
      "upvote_ratio": 0.97,
      "text": "https://preview.redd.it/6h4te0ci6ujg1.jpg?width=679&format=pjpg&auto=webp&s=51bf3a09de42ff561501f3f88aed2b5833d7aa15\n\nAnd Qwen3.5-397B-A17B released as the first open-weight model in the Qwen3.5 series\n\n[https://x.com/Alibaba\\_Qwen/status/2023331062433153103](https://x.com/Alibaba_Qwen/status/2023331062433153103)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r66h5k/qwen35_is_here/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5pdosc",
          "author": "dirtybeagles",
          "text": "yeah but who can run it? lol",
          "score": 2,
          "created_utc": "2026-02-16 16:16:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q1g61",
          "author": "NICKatMICME",
          "text": "It'll run in the app and web app",
          "score": 1,
          "created_utc": "2026-02-16 18:06:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6cjjr",
      "title": "Qwen3.5 Plus and Qwen3.5 397B A17B Comparison",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/00htasb9kvjg1",
      "author": "sirjoaco",
      "created_utc": "2026-02-16 15:26:50",
      "score": 24,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r6cjjr/qwen35_plus_and_qwen35_397b_a17b_comparison/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5pt926",
          "author": "Samy_Horny",
          "text": "They're supposed to be the same, but the Plus version has more context and smarter tool calls.\n\nIs this why Qwen 3.5 Plus seems \"better\"?",
          "score": 1,
          "created_utc": "2026-02-16 17:28:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5q574g",
              "author": "madaradess007",
              "text": "doesn't seem like that to me  \nmy now outdated qwen3 prompts work better with 397B\n\ni didn't tweak prompts yet, so may be a skill issue",
              "score": 2,
              "created_utc": "2026-02-16 18:23:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5pyllj",
              "author": "sirjoaco",
              "text": "Does seem so, and its cheaper too",
              "score": 1,
              "created_utc": "2026-02-16 17:53:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o620cfz",
          "author": "GCoderDCoder",
          "text": "What quant is the 397B? I think especially with graphical things the nuance level changes with quantization. I started looking at the perplexity measurements for different models and perplexity isn't a 1:1 but seeing the rate of incorrect tokens explode usually with q4 being the cliff highlights how we are likely experiencing slightly different behaviors from our local models vs the full-size ones. I don't think that getting a different token from the original equates to a non working token but if something is 80% different you wouldn't call it identical either. Based on inferencer labs' HF for the model, q4 is around 90% accuracy. 1 out of every 10 tokens being different would make these local results make sense. It becomes a signal to noise issue for models with heavier quantization.\n\nPerfect timing describing quantization affect on token accuracy- \nhttps://youtu.be/Mq6FQIZ-GMw",
          "score": 1,
          "created_utc": "2026-02-18 14:10:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3e8ol",
      "title": "I made a website that runs LLMs in your browser.",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r3e8ol/i_made_a_website_that_runs_llms_in_your_browser/",
      "author": "Alexander_Chneerov",
      "created_utc": "2026-02-13 03:20:53",
      "score": 14,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "I madeÂ [a private and easy website that runs LLMs in your browser](https://mystaticsite.com/chatbot/).\n\nI was looking for a private and easy way to run a model locally (Including Qwen!), but they all seemed complicated, I would need to download some software in mostÂ [cases](https://localai.io).\n\nSo as a software developer I decided to make my own, this is a website that loads a model locally into to your browser, and lets you chat with it completely offline.\n\nI just wanted to share it, and if anyone has any suggestions I am open ears.\n\n[https://mystaticsite.com/chatbot/](https://mystaticsite.com/chatbot/)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r3e8ol/i_made_a_website_that_runs_llms_in_your_browser/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o53qaqh",
          "author": "NoobMLDude",
          "text": "Before I click on that link could you please explain a few details:\n- where would the website download the model to? \n- what resources would it use to run the model (WebGPU Iâ€™m guessing)\n- Which models are loaded by default?\n- Can it run on a mobile phone? \n\nThanks. \nI like the idea of WebGPU and websites using it for heavy computations if the models can run everywhere without wasting a lot of user disk space.",
          "score": 3,
          "created_utc": "2026-02-13 03:34:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53uw7c",
              "author": "Alexander_Chneerov",
              "text": "Hi! \n\nIt downloads the model to memory, so once you leave the website it disappears (doesn't fill up space on your device)\n\nWebGPU indeed\n\nQwen and Llama models mostly.\n\nYes, but I hope it is strong enough.\n\n\n\n  \n",
              "score": 2,
              "created_utc": "2026-02-13 04:05:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53xnpc",
                  "author": "NoobMLDude",
                  "text": "Ok thanks for sharing. \nWhich size models are downloaded?",
                  "score": 2,
                  "created_utc": "2026-02-13 04:24:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o598s9g",
          "author": "Available-Craft-5795",
          "text": "I can do this in a simpler and faster way  \nWebLLM",
          "score": 1,
          "created_utc": "2026-02-13 23:55:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59jfvo",
              "author": "Alexander_Chneerov",
              "text": "Ok then do it and share lol",
              "score": 2,
              "created_utc": "2026-02-14 00:59:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o59mkbf",
                  "author": "Available-Craft-5795",
                  "text": "one sec",
                  "score": 1,
                  "created_utc": "2026-02-14 01:19:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5l9z7k",
          "author": "shlok-codes",
          "text": "I appreciate the effort, mate. I think it might be more useful if you created a repository in which we could put our own open router like API and change models in the environment folder. I know I would appreciate if someone else took care of the front end portion of that.",
          "score": 1,
          "created_utc": "2026-02-15 23:07:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6dr4z",
      "title": "Qwen 3.5 Coder Plus already in qwen code",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r6dr4z/qwen_35_coder_plus_already_in_qwen_code/",
      "author": "chiliraupe",
      "created_utc": "2026-02-16 16:11:12",
      "score": 13,
      "num_comments": 4,
      "upvote_ratio": 0.84,
      "text": "Anybody knows which model exactly is used? (Parameters, quant etc)\n\nhttps://preview.redd.it/qy3feim6svjg1.png?width=1093&format=png&auto=webp&s=a40362dad2f4de948e77927e5cc594ae6a8d6612\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r6dr4z/qwen_35_coder_plus_already_in_qwen_code/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5pdo3t",
          "author": "NoobMLDude",
          "text": "You screenshot says Qwen3.5 Plus. \nWhere do you see the Coder Plus mentioned?",
          "score": 2,
          "created_utc": "2026-02-16 16:16:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5q55yh",
              "author": "chiliraupe",
              "text": "Its says coder model right above?",
              "score": 0,
              "created_utc": "2026-02-16 18:23:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5shxhx",
                  "author": "NoobMLDude",
                  "text": "Ok. I saw the Qwen3.5 Plus below that. \nMaybe Qwen3.5 Plus is a general purpose model with good Coding skills as well. \nSimilar to all recent open source models from Kimi, minimax , Z.ai",
                  "score": 1,
                  "created_utc": "2026-02-17 01:42:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5rgo12",
          "author": "myeleventhreddit",
          "text": "Howâ€™s your experience been? I was using Qwen3.5 in Xcode 26.3 agent mode earlier and it was working pretty well",
          "score": 1,
          "created_utc": "2026-02-16 22:12:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7p97k",
      "title": "They are blaming tech to deflect from what is really wrong with childrenâ€™s education.",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/wagutqd5o5kg1.png",
      "author": "LinkAmbitious8931",
      "created_utc": "2026-02-18 01:28:20",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r7p97k/they_are_blaming_tech_to_deflect_from_what_is/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o63pc2v",
          "author": "crusoe",
          "text": "Korea tried AI lesson plans and text books. It was a complete disaster.",
          "score": 1,
          "created_utc": "2026-02-18 18:50:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8oyqy",
      "title": "Massive props for adding 82 new languages!",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r8oyqy/massive_props_for_adding_82_new_languages/",
      "author": "hosohep",
      "created_utc": "2026-02-19 03:56:38",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Going from 119 to 201 languages is incredible. The global community appreciates this!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r8oyqy/massive_props_for_adding_82_new_languages/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r681wf",
      "title": "JUST IN: Alibaba Releases Qwen3.5 Model for Agentic AI Era",
      "subreddit": "Qwen_AI",
      "url": "https://www.allblogthings.com/2026/02/alibaba-releases-qwen35-model-for-agentic-ai-era.html",
      "author": "umerprince",
      "created_utc": "2026-02-16 12:14:13",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r681wf/just_in_alibaba_releases_qwen35_model_for_agentic/",
      "domain": "allblogthings.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5o9xt1",
          "author": "drhenriquesoares",
          "text": "I didn't like it very much.",
          "score": 0,
          "created_utc": "2026-02-16 12:44:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r77zlv",
      "title": "What is security for you?",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/wz6auwdgi2kg1",
      "author": "Dapper-Win1539",
      "created_utc": "2026-02-17 14:49:24",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r77zlv/what_is_security_for_you/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5yhkc6",
          "author": "atari_61",
          "text": "same thing happens me too, it just keeps asking the verification, i just gave up using qwen looks like no solution. my ip is regular home ip, but i heard this nowadays happen to alotof ppl qwen users it has to be a bug",
          "score": 2,
          "created_utc": "2026-02-17 23:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w9m8r",
          "author": "Samy_Horny",
          "text": "That's never happened to me, but I understand how frustrating it is. Have you used LMArena (now just \"arena\")?\n\n\nThat site is the most cumbersome; it asks you to verify yourself constantly, and it seems to either have limits on responses per minute or have backend glitches, meaning you have to send the query a thousand times for it to work once.",
          "score": 1,
          "created_utc": "2026-02-17 17:13:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vjsnq",
          "author": "Cool-Chemical-5629",
          "text": "It's probably related to your IP address. If you don't have a dedicated public IP address, but rather shared public IP address, you may be unfortunate enough to share the same IP address associated with suspicious online activities that would indicate automated scripts (also known as bot activities) and the first line of defense against that may just be enforced captcha. Some systems don't recognize individual devices, only IP addresses, so if there are multiple failed captcha solutions in a row, the system always resets and you have to try again which may seem to you as an individual that this captcha is broken because it denies you access even if you solve it correctly. The reason why is that at the same time there may be multiple other users from the same shared IP address trying to make the connection but failing the captcha at the same time which would overwhelm and confuse the protection layer so no matter what you're just not getting inside. This is pretty common with Tor connections or VPNs which are often associated with bots and hacking activities, but it may happen with regular connections as well.",
          "score": 0,
          "created_utc": "2026-02-17 15:04:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vtpqc",
              "author": "Dapper-Win1539",
              "text": "Interesting suggestion. I'm living in dormitory so many students are using Qwen. Maybe some of my devices are connected and its personal authentication codes based om m.a.c. is saved. So any other devices marked as suspicious and broken captcha doing ts.\n\nSo there's no way I can fix it.",
              "score": 1,
              "created_utc": "2026-02-17 15:53:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vvf8y",
                  "author": "Cool-Chemical-5629",
                  "text": "Ironically, if you tried a proxy server, or a VPN, it would change your public address temporarily that could solve the problem, but then again this issue is usually associated with well known IP addresses associated with suspicious connections which in turn are usually associated with proxies, VPNs. It would be a 50:50 chance of success, but still worth trying.",
                  "score": 1,
                  "created_utc": "2026-02-17 16:01:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r5znx3",
      "title": "Qwen3.5 final countdown",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r5znx3/qwen35_final_countdown/",
      "author": "Ash_Skiller",
      "created_utc": "2026-02-16 04:16:48",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "Feels close.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r5znx3/qwen35_final_countdown/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5myhri",
          "author": "azvd_",
          "text": "did they give us a date?",
          "score": 1,
          "created_utc": "2026-02-16 05:45:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62ysep",
              "author": "Extra_Treacle_4601",
              "text": "Almost. Yep.\n\n",
              "score": 1,
              "created_utc": "2026-02-18 16:52:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5ug6s",
      "title": "Qwen3.5 multimodal expectations?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1r5ug6s/qwen35_multimodal_expectations/",
      "author": "ischanitee",
      "created_utc": "2026-02-16 00:09:38",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Do you expect native vision support?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1r5ug6s/qwen35_multimodal_expectations/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o5m5qdv",
          "author": "Samy_Horny",
          "text": "It's very likely so; I think the Qwen 3.5 commit reveals this. Furthermore, one of the lead engineers confirmed a long time ago (I believe since the release of Qwen VL) that future models would be multimodal by default, meaning that Qwen 3 VL is the last of its kind.",
          "score": 1,
          "created_utc": "2026-02-16 02:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5y6p3w",
          "author": "No-Evidence8589",
          "text": "I hope so. Would be huge.",
          "score": 1,
          "created_utc": "2026-02-17 22:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}