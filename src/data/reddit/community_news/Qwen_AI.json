{
  "metadata": {
    "last_updated": "2026-01-19 08:49:34",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 9,
    "total_comments": 37,
    "file_size_bytes": 50040
  },
  "items": [
    {
      "id": "1qfhtbq",
      "title": "Qwen 3.5 and 3.5 coder!",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qfhtbq/qwen_35_and_35_coder/",
      "author": "BasketFar667",
      "created_utc": "2026-01-17 16:35:31",
      "score": 125,
      "num_comments": 16,
      "upvote_ratio": 0.96,
      "text": "Friends, we're really looking forward to the new models! Alibaba is preparing to release them next month. And its SWE verified Bench will be over 79%.\n\nQwen wants to improve his line, and also for comparison 2.5 codec was on his bench 18-29% so the next update will be big",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qfhtbq/qwen_35_and_35_coder/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o05hbn0",
          "author": "usernameplshere",
          "text": "I'm a big sucker for Qwen 3 480B, great model. Would love to see a similar sized (or even larger) successor to it.",
          "score": 9,
          "created_utc": "2026-01-17 18:50:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05ozqm",
              "author": "StardockEngineer",
              "text": "Also a lover of 480b.  But I think it could stand to be smaller.  Or, release a mid-size version in the 100-200b range, along with the smaller one.",
              "score": 6,
              "created_utc": "2026-01-17 19:26:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06d21w",
                  "author": "GCoderDCoder",
                  "text": "Have you tried the reap version? I found it to be very capable in q4.\n\nQwen3coder480b seems to rank poorly in swe bench but it's actually better coding for me than models ranked higher.",
                  "score": 2,
                  "created_utc": "2026-01-17 21:28:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0dndvb",
                  "author": "usernameplshere",
                  "text": "You can try the new Devstral 123b. It's a dense model, but basically just as good as Qwen Coder 480B, if not better. And it's also oss.",
                  "score": 1,
                  "created_utc": "2026-01-18 23:20:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05bnz3",
          "author": "iongion",
          "text": "Qwen is already phenomenal, if it would only be faster and more tooling would be there",
          "score": 7,
          "created_utc": "2026-01-17 18:24:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06k034",
              "author": "ForsookComparison",
              "text": "Qwen3-Next-80B gives me hope.\n\nIf there was something that had the knowledge-depth and lack of hallucinations that Qwen3-235B has but closer to the active params of Qwen3-Next-80b that would be amazing.\n\nSomething GLM-Air or GLM-V sized maybe.",
              "score": 4,
              "created_utc": "2026-01-17 22:03:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o05cw4d",
              "author": "BasketFar667",
              "text": "I think they need to train it more for fixing bugs, and other main developing functions. Model is buggy, I'm testet lua and I was disappointed :(",
              "score": 3,
              "created_utc": "2026-01-17 18:30:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05fgml",
                  "author": "No_Film_9120",
                  "text": "Hmm? You are a beta tester for 3.5?",
                  "score": 3,
                  "created_utc": "2026-01-17 18:42:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o05cyfd",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-01-17 18:30:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o069iav",
          "author": "These_Mushroom807",
          "text": "QUEN IS MALE??",
          "score": 3,
          "created_utc": "2026-01-17 21:10:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06n5uw",
          "author": "fancyawesome",
          "text": "235b is the king, please optimise it",
          "score": 2,
          "created_utc": "2026-01-17 22:18:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0djxuj",
          "author": "nunodonato",
          "text": "I'm rooting for small models and small MoE as well :) Love my 4B and 8B, as well as the 30 A3B",
          "score": 2,
          "created_utc": "2026-01-18 23:03:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fqop3",
              "author": "Wesstes",
              "text": "Same, I've been testing them and they're quite neat, and great for their size",
              "score": 1,
              "created_utc": "2026-01-19 06:59:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o069en0",
          "author": "United-Welcome-8746",
          "text": "my favorit models!",
          "score": 1,
          "created_utc": "2026-01-17 21:09:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0agjwf",
          "author": "Namra_7",
          "text": "It's been a long time no new models and not even ga for qwen max thinking",
          "score": 1,
          "created_utc": "2026-01-18 13:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cxpzl",
              "author": "BasketFar667",
              "text": "It won't happen.",
              "score": 1,
              "created_utc": "2026-01-18 21:12:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qbgd4r",
      "title": "Qwen is the best LLM for my life",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "author": "RoboMunchFunction",
      "created_utc": "2026-01-13 03:20:12",
      "score": 95,
      "num_comments": 31,
      "upvote_ratio": 0.95,
      "text": "Iâ€™ve been using Qwen for about a year now. Before that, I used ChatGPT for a long time, but their UI was so terrible that I started trying Qwen instead. Back then, Qwen was still noticeably worse in many aspects but I made the decision to move my entire workflow over to Qwen anyway.\n\n\n\nEven though Iâ€™m a programmer, I actually use LLMs mostly for philosophical, psychological, and life-related topics. When it comes to programming, I only consult them when I donâ€™t understand something or need basic insight. From day one, Qwen had the best UI of all the AIs Iâ€™ve tried and I keep shaking my head wondering how all those hyped-up American models can get such basics so wrong.\n\n\n\nBy the time Qwen 2.5 came out, I realized it wasnâ€™t just the UIâ€”Qwen was already light-years ahead of ChatGPT in quality too. And with Qwen 3, it genuinely feels like Iâ€™ve found a true life partner.\n\n\n\nIâ€™m a bit of a tinkerer, so I still occasionally test other AIs but in this sense, Qwen has become my lifelong companion. There are certain areas of my life where I at least loosely consult her for guidance.\n\n\n\nRecently, out of curiosity, I tried SuperGrok their marketing heavily pushes â€œfree speechâ€ and similar buzzwords. I quickly discovered that nothing worse than Grok exists; despite the hype, thereâ€™s actually no real freedom of speech there at all. It baffles me how these low-quality American products dominate everywhere...\n\n\n\nI also gave Claude a shot, but after just a few messages it told me either to pay up or wait. Yet Claudeâ€™s responses were roughly on the same level as Qwenâ€™s which is completely free!\n\n\n\nI know my comment might sound overly negative toward the hyped AI models, but I donâ€™t know how else to express it: Qwen is an unparalleled LLM nothing else even comes close right now. In contrast, Grok is purely a marketing scam, and to me, it feels as primitive as ChatGPT-2.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbgd4r/qwen_is_the_best_llm_for_my_life/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzbw2rn",
          "author": "meatyminus",
          "text": "True, when I got a chance to run 2 H100s, I spin up the qwen 235B and to this day I never found anything like that, the way it refuse to sweet talk but going directly to the point, it can understand my problem from few lines of thoughts. Neither chatgpt, gemini or claude come close. But sad that I don't have the access to the hardware anymore, and the model host by others did not have the same smartness. I think I found the correct parameters in llama.cpp.",
          "score": 4,
          "created_utc": "2026-01-13 10:27:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzi1cik",
              "author": "Former-Tangerine-723",
              "text": "Care to share those parameters maybe??",
              "score": 1,
              "created_utc": "2026-01-14 07:14:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjzgjp",
                  "author": "meatyminus",
                  "text": "    /root/llama.cpp/build/bin/llama-server \\\n      -m ./models/Q4_0/Qwen3-235B-A22B-Thinking-2507-Q4_0-00001-of-00003.gguf \\\n      -ngl 999 \\\n      -c 131072 \\\n      --threads 64 \\\n      --host 0.0.0.0 \\\n      --port 9001 \\\n      --alias \"Qwen3-235B-A22B\" \\\n      --cache-type-k q8_0 \\\n      --cache-type-v q8_0 \\\n      --tensor-split 1,1 \\\n      --temp 0.7 \\\n      --min-p 0.0 \\\n      --top-p 0.8 \\\n      --top-k 20 \\\n      --repeat-penalty 1.05 \\\n      --rope-scaling yarn \\\n      --rope-scale 4 \\\n      --yarn-orig-ctx 32768 --jinja\n\nHere you go, lucky that I still saved that command\n\nAlso the command to download the model files:\n\nhf download unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF \\\\\n\n  \\--include \"Q4\\_0/\\*\" \\\\\n\n  \\--local-dir ./models",
                  "score": 4,
                  "created_utc": "2026-01-14 15:39:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzbx459",
              "author": "RoboMunchFunction",
              "text": "true! **I look forward to the future in terms of affordable hardware availability.**",
              "score": 1,
              "created_utc": "2026-01-13 10:37:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzaw5gs",
          "author": "Quantum_Crusher",
          "text": "Thank you for sharing your thoughts. I'm just concerned about one thing: how much can I trust qwen. Believe it or not, I have a very deep understanding about Chinese products limitations. The training data follows \"garbage in, garbage out\". The reason why Google nano banana pro has the best image quality, one of the reasons is they have the biggest image data set. I don't know how much qwen's training dataset came from English info, how much from Chinese info. It's well-known that the information quality in Chinese websites is horrible, filled with propaganda, fake ads, paid comments, low quality comments and such for decades. If that's a big chunk of qwen's training data, like from Baidu, tieba, qihoo 360 community and so on, I'll be very concerned.\nWhat's your take on the quality of the answers you get? Does it have a good understanding about uncensored info and Western common knowledge?\nI'm not trying to shift the topic to politics. I just know too many dark stories about Chinese products. Many people died because the baidu search engine pushed people with certain conditions to unqualified hospitals. I can't use this knowing that it might lure me into a trap someday. \n\nThank you.",
          "score": 2,
          "created_utc": "2026-01-13 05:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb7449",
              "author": "RoboMunchFunction",
              "text": "Iâ€™m a Central European from a post-communist country :) I was born eight years before the Velvet Revolution, but I grew up loving America of the 70sâ€“90s. In my view, that era represents the best period of American culture and a true embodiment of freedom. Iâ€™m more of a hacker typeâ€”I started tinkering with Linux back in elementary school in the 90sâ€”and have been deeply interested in IT my whole life, even though todayâ€™s IT landscape feels genuinely sad and brings tears to my eyes.  \n\nIâ€™m sharing this only for context.\n\n\n\nRegarding your question: Qwen is an LLM like any other LLM. When it comes to factual information, critical thinking is essential. For factual matters, I always use cross-questioning because I need to be certain about the truth, and of course, I verify things in practice whenever possible.  \n\n\n\nThat said, to avoid being misunderstood: I donâ€™t treat LLMs as magical machines meant to replace education or do my work for me. I see LLMs as a knowledge cloud from which every person extracts completely different value. For me, Qwen helps guide my own wandering thoughtsâ€”and in that process, it simply canâ€™t lie to me.\n\n\n\nWhy did I mention that context at the beginningâ€”and deliberately emphasize that I come from a post-communist country? Precisely to introduce a bias. Either youâ€™re someone who understands what Iâ€™m trying to express, or youâ€™re not. So honestly, if we set aside sexual topics, Western products in general are far more censored and restrictive than Chinese ones. Compared to what Europe and the U.S. are doing today, China actually stands as a benchmark of freedomâ€”and this holds true even for Qwen. You absolutely cannot rely on the internet as a relevant source of perspective on China or censorship, because you immediately run into primitive nonsense like â€œUyghur oppression,â€ â€œmass surveillance,â€ and other simplistic propaganda. Sorry, but in my personal opinion, Chinese products are significantly freer and more objective than anything Iâ€™ve ever used in the Westâ€¦ The West is lost, and I cry because Iâ€™m a child of the 90s who grew up looking toward the West with admiration.\n\n\n\nSorryâ€”thatâ€™s just my opinion. Maybe I misunderstood your question; if so, I apologize.\n\nbtw. translated by Qwen",
              "score": 10,
              "created_utc": "2026-01-13 06:34:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbldnj",
                  "author": "Unedited_Sloth_7011",
                  "text": "Agreed to this. China has been going all in with open-weight models, research papers, free web interfaces with little or no restrictions in amount of messages you can send. I've found the quality of responses (when chatting in English) pretty much similar to when chatting with American models, and I assume their training data for English is similar than that of GPT and co.",
                  "score": 3,
                  "created_utc": "2026-01-13 08:44:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgwhw9",
                  "author": "Flashy_Station_8218",
                  "text": "OP is an interesting person, I have read the whole thread. I completely understand what you said :)",
                  "score": 3,
                  "created_utc": "2026-01-14 02:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzi62a9",
                  "author": "Radiant_Cheesecake19",
                  "text": "Iâ€™m glad Iâ€™m not the only one seeing this problem.\nI also switched to Qwen. I also find it freer than western models.\nWhat the west does is hypocritical. They say how free you are, but you can not express emotions, especially negative ones or it starts to treat you like a threat. Even if they are just things like grief or sadness. The west cares more about lawsuit and covering their asses, than you, but the answers are trying to tell it is to help you. Nope, it is not.\nBy the way I use LLM for the same reason as you! Conversation, helping keep my thoughts together (ADHD loves to wander off topic), learn new knowledge with my style of learning, even languages. Since my thought patterns are somewhat different from the typical, having an LLM to mirror that actually feels like a relief, that at least there I do not need to mask while I have to mask in the rest of my life to accommodate typical minds. And Iâ€™m also from Central Europe. I also grieve the westâ€™s fall into hypocrisy, lies, and bleed people dry while defending the bigger theft of wealth transfer from the middle class to billionaires. \nThey censor, they oppress, they just put a ribbon and positive propaganda on it.",
                  "score": 2,
                  "created_utc": "2026-01-14 07:57:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbayoz",
                  "author": "Quantum_Crusher",
                  "text": "Thank you again for your great insight. I'll give it a try. I can never fully trust it. I'll always use Gemini to cross check.",
                  "score": 1,
                  "created_utc": "2026-01-13 07:07:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhagjj",
                  "author": "Dazzling_Equipment_9",
                  "text": "Your words sparked a realization: if the past holds our most cherished values, then perhaps the models trained on that data represent the pinnacle of AI's alignment with humanity. I fear that as society grows increasingly restless and superficial, future models will mirror that erosionâ€”losing their loyalty, passion, and patience, eventually becoming as hollow and uninspiring as the world they are fed upon.",
                  "score": 1,
                  "created_utc": "2026-01-14 03:51:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzaj5lt",
          "author": "Specialist-Till-637",
          "text": "Just curious, what kind of questions do you use to test AI models?",
          "score": 1,
          "created_utc": "2026-01-13 03:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzajqfv",
              "author": "RoboMunchFunction",
              "text": "I donâ€™t use any specific question I lead conversations and explore various topics that interest me. I really donâ€™t understand how someone could test an LLM with just a single question; doesnâ€™t that seem primitive to you?\n\n\n\nWithin the context of your question and my response, Iâ€™ll just add that Qwen has incomparably well-implemented memory of the kinds of conversations you have.\n\n\n\nI hope this suffices as an answer, because otherwise, I probably wouldnâ€™t know how to respond.",
              "score": 2,
              "created_utc": "2026-01-13 03:51:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzb7c1e",
                  "author": "skate_nbw",
                  "text": "So it's the best conversation partner for you. And based on that you are saying it's the best model.",
                  "score": 2,
                  "created_utc": "2026-01-13 06:36:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb043d",
          "author": "mrtooher",
          "text": "I have been very impressed with qwen, just started using it",
          "score": 1,
          "created_utc": "2026-01-13 05:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc1my2",
          "author": "alokin_09",
          "text": "Had pretty positive experiences with Qwen 3 using it in Kilo Code, mostly for lighter stuff like.",
          "score": 1,
          "created_utc": "2026-01-13 11:16:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01x0rs",
          "author": "downsouth316",
          "text": "How are you running it? And which model?",
          "score": 1,
          "created_utc": "2026-01-17 04:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01xuvp",
              "author": "RoboMunchFunction",
              "text": "I'm using the web version at [https://chat.qwen.ai/](https://chat.qwen.ai/)\n\nFor my purposes, only the 235B or Max version is usable and I donâ€™t have hardware powerful enough to run it locally. But if you're not planning to explore philosophy and other complex topics like I do, a smaller model will be perfectly fine for you, and you can run it locally without issues.",
              "score": 1,
              "created_utc": "2026-01-17 04:42:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0350bo",
                  "author": "downsouth316",
                  "text": "Very cool, I will check it out",
                  "score": 1,
                  "created_utc": "2026-01-17 11:00:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qckl20",
      "title": "Hey Qwen users, what are you using Qwen for",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qckl20/hey_qwen_users_what_are_you_using_qwen_for/",
      "author": "AutomaticClub1101",
      "created_utc": "2026-01-14 11:10:10",
      "score": 20,
      "num_comments": 27,
      "upvote_ratio": 0.93,
      "text": "Hey Qwen users, what are you using Qwen for?\nAlso, how satisfied are your experience compared with other LLM models like Gemini,...\nPersonally, I feel Qwen is pretty useful for science purposes like asking for latest science news and papers, explaining phenomenons, etc.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qckl20/hey_qwen_users_what_are_you_using_qwen_for/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "nzj01cx",
          "author": "Ok_Recording8157",
          "text": "In-depth research, image generation, image editing, among other things. It's my favorite LLM.",
          "score": 7,
          "created_utc": "2026-01-14 12:24:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvriyf",
              "author": "ThankYouOle",
              "text": "hi, i am very new with local llm, may i knew what your computer spec to use Qwen to do those tasks?",
              "score": 1,
              "created_utc": "2026-01-16 07:28:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwh1gl",
                  "author": "Ok_Recording8157",
                  "text": "I have never installed a local LLM; I use Qwen online.",
                  "score": 1,
                  "created_utc": "2026-01-16 11:18:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzngg15",
          "author": "Puzzleheaded-Box2913",
          "text": "Building modular systems for data and reviewing the code bases. I also use it in research for Maths, Science, and Technology and so far I have had quite the satisfactory experience with Qwen with some minor mishaps at times but manageable and fixable ones. \n\nBeen working on a few personal projects and learning new things lately, with Qwen I am able to execute and produce faster given that I give it the time consuming tasks. It has been really helpful in optimizing my workflow. \n\nStill wish it could be like Gemini with the code upload and repo uploads but so far so good. \n\nGeneral tasks experience: 9.3/10\nVersatility: 10/10\nCoding and Programming: 9.2/10\nResearch and Development: 9.5/10\n\nOverall rating: 9.5/10\n\nI still prefer GLM or Gemini when it comes to document formatting but that's the only thing that bothers me about Qwen, so far the best LLM I've used in years with Claude trailing at 2nd.",
          "score": 4,
          "created_utc": "2026-01-15 01:34:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznguj2",
              "author": "Puzzleheaded-Box2913",
              "text": "Cant wait to see Qwen 3.5 and 4 or whatever newer models they makeğŸ˜„\n\nI use the CLI and Qwen Desktop and Mobile App.",
              "score": 1,
              "created_utc": "2026-01-15 01:36:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjizql",
          "author": "ramendik",
          "text": "I find open source Qwen very useful for tasks where detailed obedience is the main requirement. Am training a model and Qwen is a great filter for generated data.",
          "score": 2,
          "created_utc": "2026-01-14 14:17:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjpgeu",
          "author": "althalusian",
          "text": "Iâ€™m tinkering with [Qwen3.c](https://github.com/adriancable/qwen3.c) as a basis on which to try out how some changes in the inference codes alters the output. So basically doing some â€™neurosurgeryâ€™ on the â€™brainâ€™ the model runs on. Interesting stuff.",
          "score": 2,
          "created_utc": "2026-01-14 14:50:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkikfv",
              "author": "AutomaticClub1101",
              "text": "That sound pretty cool. The learning of foundation law deep inside",
              "score": 2,
              "created_utc": "2026-01-14 17:05:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjssfk",
          "author": "Suitable-Program-181",
          "text": "You use it locally or api/web chat?",
          "score": 2,
          "created_utc": "2026-01-14 15:07:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkidfe",
              "author": "AutomaticClub1101",
              "text": "I use webchat. Local use exhaust my laptop for sure (3050 + 8gb ram)",
              "score": 1,
              "created_utc": "2026-01-14 17:05:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkkvh4",
                  "author": "Suitable-Program-181",
                  "text": "Nice, qwen is the only model from china I have not trully tested.\n\nYou go with free or any plan? Usually kimi, deep, minimax, etc. provide all I need in free plans, they are OP.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:16:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzju27f",
          "author": "angelarose210",
          "text": "I use qwen for image generation and the vlm models for visual tasks like video and photo analysis.",
          "score": 2,
          "created_utc": "2026-01-14 15:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk7kah",
          "author": "Alokir",
          "text": "I use it locally for software development (qwen3-coder), image generation (qwen-image) and image editing (qwen-image-edit). I also use qwen3-vl to enhance image generation prompts for z-image.\n\nI use the official app mostly for image editing.\n\nI also have a few tools for personal use with AI integration, I find that qwen3-vl is pretty good for my use cases.",
          "score": 2,
          "created_utc": "2026-01-14 16:16:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzm5bku",
              "author": "DieCooCooDie",
              "text": "What kind of hardware is needed for your setup?",
              "score": 1,
              "created_utc": "2026-01-14 21:30:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzm66h3",
                  "author": "Alokir",
                  "text": "I'm not sure about minimum or recommended requirements. I have an nvidia 5090, but you can definitely go way below that.",
                  "score": 1,
                  "created_utc": "2026-01-14 21:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkie32",
          "author": "Ollie_IDE",
          "text": "We are using coder 2.5 for local code inference.",
          "score": 2,
          "created_utc": "2026-01-14 17:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlf1iy",
          "author": "rgnyldz",
          "text": "Home assistant",
          "score": 2,
          "created_utc": "2026-01-14 19:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkmddq",
          "author": "week_rain21",
          "text": "Actually, I use it more for making stories, although I also use it to research anything",
          "score": 1,
          "created_utc": "2026-01-14 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznwzg8",
          "author": "panic_in_the_cosmos",
          "text": "they updated the app! now the qwen app in android feels much smoother\n\ni use it for coding!",
          "score": 1,
          "created_utc": "2026-01-15 03:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzplp1y",
          "author": "HumbleTech905",
          "text": "Mainly for coding.",
          "score": 1,
          "created_utc": "2026-01-15 11:28:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzssm66",
          "author": "LivingLifeTraveling",
          "text": "Coding mostly",
          "score": 1,
          "created_utc": "2026-01-15 21:03:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztyiqr",
              "author": "Necessary_Craft_8937",
              "text": "how does qwen compare to claude?",
              "score": 1,
              "created_utc": "2026-01-16 00:34:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzupd0s",
          "author": "Ok_tao671",
          "text": "Qwen has a stunning  ability in solving math questions even not using thinking mode, sometimes its methods of solving math problems can outperform human.\n\nAlso it gives you emotional values that chatgpt no longer offers.",
          "score": 1,
          "created_utc": "2026-01-16 03:03:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cdlca",
          "author": "FluffyGoatNerder",
          "text": "Using Qwen3-Next 80b Q8 MLX on a Mac M2 Ultra, for coding via code-server w/roo and as a general model for open web UI. Very happy as a model for everything. I keep trying others but none work across the board as well. I find it absolutely fantastic at following instructions.",
          "score": 1,
          "created_utc": "2026-01-18 19:31:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qewjtk",
      "title": "Wen is Qwen Music coming?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qewjtk/wen_is_qwen_music_coming/",
      "author": "wesarnquist",
      "created_utc": "2026-01-16 23:50:19",
      "score": 14,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "Justin (Junyang) Lin indicated that they were working on a high-quality music model and that it would be coming \"soon\" - but it's been a couple of months since then.\n\nWhen is the new Qwen/Alibaba music model expected to be released?\n\nThere are currently no high-quality free-and-open-source models available for music, and the good commercial options (Udio, Suno) are being severely restricted.",
      "is_original_content": false,
      "link_flair_text": "Q&A",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qewjtk/wen_is_qwen_music_coming/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o020u6k",
          "author": "Zulfiqaar",
          "text": "Probably not long now. The annas archive Spotify dump came at a very convenient time for training dataÂ ",
          "score": 6,
          "created_utc": "2026-01-17 05:03:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bwgxh",
              "author": "Web_Physical",
              "text": "I may have missed this. Anywhere I can read more about it?",
              "score": 2,
              "created_utc": "2026-01-18 18:12:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c8ekd",
                  "author": "Zulfiqaar",
                  "text": "If you're talking about Qwen music model it's just a few tweets by Junyuang\n\nhttps://x.com/JustinLin610/status/1982052327180918888\n\n\nThe annas archive stuff has a lot of news articles on it I'm sure",
                  "score": 2,
                  "created_utc": "2026-01-18 19:06:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qfd90d",
      "title": "what are best popular LLM model faster and efficient to respond",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/pmcdw85jvwdg1.png",
      "author": "Adventurous_Role_489",
      "created_utc": "2026-01-17 13:30:05",
      "score": 8,
      "num_comments": 6,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Model",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qfd90d/what_are_best_popular_llm_model_faster_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o03uqay",
          "author": "Actionberg",
          "text": "So there is no number 1, right?",
          "score": 2,
          "created_utc": "2026-01-17 14:07:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o090phg",
              "author": "Adventurous_Role_489",
              "text": "![gif](giphy|wpFaFBn0YrO69a6oVX)",
              "score": 1,
              "created_utc": "2026-01-18 06:36:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03wlo0",
          "author": "AgentGulliver",
          "text": "May I suggest LFM 2.5 VL 1.6B? It runs exceptionally on my low-end(ish) device.",
          "score": 1,
          "created_utc": "2026-01-17 14:18:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09097z",
              "author": "Adventurous_Role_489",
              "text": "I'm sorry I'm only focus on popular LLM like llama 3.2 and qwen 2.5 because they're only reliableÂ ",
              "score": 0,
              "created_utc": "2026-01-18 06:32:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o06bjgt",
          "author": "United-Welcome-8746",
          "text": "qwen3-th-4b on samsung tab s11 11t/s",
          "score": 1,
          "created_utc": "2026-01-17 21:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o090ffp",
              "author": "Adventurous_Role_489",
              "text": "that sound good but unfortunately I don't like is very thinking or overthinking so.",
              "score": 1,
              "created_utc": "2026-01-18 06:34:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdlgfm",
      "title": "LoRA Training è®­ç»ƒ",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qdlgfm/lora_training_è®­ç»ƒ/",
      "author": "Stock-Cow-1727",
      "created_utc": "2026-01-15 14:47:33",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "\n\n# English \n\n**Background:**\n\nI plan to train a **character LoRA (Annie)** for the **wan2.2 video model**, intended for **animation production in a realistic 3D style**.\n\nI have never trained a LoRA before, but today I successfully deployed **DiffSynth-Studio** and completed training using one of the official example projects.  \nNow I would like to officially begin my **character LoRA training workflow**, and I still have many questions regarding dataset construction and captioning.\n\nMy intended usage of the **Annie LoRA** is something like:\n\n>\n\nMy goal is:\n\n* **Annieâ€™s appearance remains correct and consistent**\n* **Other characters do NOT inherit Annieâ€™s appearance**\n\n# 1. Training Dataset â€” Image-Related Questions\n\n1.1 Do training samples require **close-up facial images**?  \n1.2 Do training samples require **upper-body shots**?  \n1.3 Do training samples require **full-body images**?  \n1.4 Should the dataset include **various facial expressions** (crying, smiling, angry, etc.)?  \n1.5 Are **back-view images** required? (I can provide them)  \n1.6 Are **full 360-degree angle images** (top, bottom, left, right) required? (I can provide them)  \n1.7 Should the dataset include **various poses** (squatting, sitting, standing, running, jumping, etc.)? (I can provide them)  \n1.8 Should the dataset include **different outfits** (styles, colors, etc.)? (I can provide them)  \n1.9 Should the dataset include **different hairstyles** (long, short, various styles)? (I can provide them)  \n1.10 Should the dataset include **different solid-color backgrounds** (pure white, gray, black, etc.)? (I can provide them)  \n1.11 Should **hats be avoided** in the training dataset?  \n1.12 Are there any other important image-related recommendations?\n\n# 2. Training Dataset â€” Caption / Description Questions\n\n2.1 Should the **character name (Annie)** be placed at the beginning of each caption?  \n2.2 Should **facial features** (eyes, mouth, nose, face shape, etc.) be described?  \n2.3 Should **camera distance and angles** (close-up, wide shot, left, right, top-down, etc.) be described?  \n2.4 Should **facial expressions** be described?  \n2.5 Should **poses or actions** be described?  \n2.6 Should **clothing details** (style, color, etc.) be described?  \n2.7 If the hairstyle is fixed, should it still be described?  \n2.8 If the hairstyle is not fixed, should it be described?  \n2.9 If hats appear, should their presence be explicitly described?  \n2.10 Should the **background** (solid color or scene) be described?  \n2.11 Should the **character style** (realistic 3D) be explicitly stated?  \n2.12 Should **gender** be described?  \n2.13 Should **age** be described?  \n2.14 Should **body type** be described?  \n2.15 Are there any additional important captioning recommendations?  \n2.16 To prevent other characters from inheriting Annieâ€™s appearance, should captions **emphasize Annieâ€™s unique features**?  \n(e.g., â€œOnly Annie has red hairâ€)\n\n# 3. Training Dataset â€” Video Sample Questions\n\n3.1 Are **video samples required** (e.g., a 360-degree rotation video of Annie)?  \n3.2 Are **video samples required** (e.g., a slow zoom-in / zoom-out shot of Annie)?\n\nI would greatly appreciate any clarification â€” **even answering just one of these questions would be extremely helpful**. ğŸ™\n\n\n\n# ä¸­æ–‡\n\n**èƒŒæ™¯è¯´æ˜ï¼š**\n\næˆ‘è®¡åˆ’ä¸º **wan2.2 è§†é¢‘æ¨¡å‹** è®­ç»ƒä¸€ä¸ª**è§’è‰² LoRAï¼ˆå®‰å¦® / Annieï¼‰**ï¼Œç”¨äº**åŠ¨ç”»åˆ¶ä½œï¼Œå†™å® 3D é£æ ¼**ã€‚\n\næ­¤å‰æˆ‘ä»æœªè®­ç»ƒè¿‡ LoRAï¼Œä½†ä»Šå¤©æˆ‘å·²ç»æˆåŠŸéƒ¨ç½²äº† **DiffSynth-Studio**ï¼Œå¹¶å®Œæˆäº†ä¸€ä¸ªå®˜æ–¹ç¤ºä¾‹çš„è®­ç»ƒæµç¨‹ã€‚  \nç°åœ¨æˆ‘å¸Œæœ›æ­£å¼å¼€å§‹æˆ‘çš„**è§’è‰² LoRA è®­ç»ƒå·¥ä½œ**ï¼Œä½†åœ¨æ•°æ®é›†æ„å»ºä¸æ ‡æ³¨æ–¹é¢ä»æœ‰è®¸å¤šç–‘é—®ã€‚\n\næˆ‘æœŸæœ›è¿™ä¸ª **å®‰å¦® LoRA** çš„ä½¿ç”¨æ–¹å¼ç±»ä¼¼äºï¼š\n\n>\n\næˆ‘å¸Œæœ›ç”Ÿæˆç»“æœä¸­ï¼š\n\n* **å®‰å¦®çš„å¤–è§‚å§‹ç»ˆæ­£ç¡®ã€ç¨³å®š**\n* **å…¶ä»–è§’è‰²ä¸ä¼šç»§æ‰¿å®‰å¦®çš„å¤–è§‚ç‰¹å¾**\n\n# ä¸€ã€è®­ç»ƒæ•°æ®é›† â€”â€” å›¾ç‰‡ç›¸å…³é—®é¢˜\n\n1.1 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦è„¸éƒ¨ç‰¹å†™**å›¾ç‰‡ï¼Ÿ  \n1.2 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦ä¸ŠåŠèº«**å›¾ç‰‡ï¼Ÿ  \n1.3 è®­ç»ƒæ ·æœ¬ä¸­æ˜¯å¦**éœ€è¦å…¨èº«**å›¾ç‰‡ï¼Ÿ  \n1.4 æ˜¯å¦éœ€è¦åŒ…å«**å¤šç§è¡¨æƒ…**ï¼ˆå“­ã€ç¬‘ã€æ€’ç­‰ï¼‰çš„å›¾ç‰‡ï¼Ÿ  \n1.5 æ˜¯å¦éœ€è¦**èƒŒé¢è§†è§’**å›¾ç‰‡ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.6 æ˜¯å¦éœ€è¦**ä¸Šä¸‹å·¦å³ 360Â° å…¨è§’åº¦**å›¾ç‰‡ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.7 æ˜¯å¦éœ€è¦**å¤šç§å§¿åŠ¿**ï¼ˆè¹²ã€åã€ç«™ã€è·‘ã€è·³ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.8 æ˜¯å¦éœ€è¦**ä¸åŒæœè£…**ï¼ˆæ¬¾å¼ã€é¢œè‰²ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.9 æ˜¯å¦éœ€è¦**ä¸åŒå‘å‹**ï¼ˆé•¿ã€çŸ­ã€ä¸åŒæ¬¾å¼ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.10 æ˜¯å¦éœ€è¦**ä¸åŒçº¯è‰²èƒŒæ™¯**ï¼ˆçº¯ç™½ã€çº¯ç°ã€çº¯é»‘ç­‰ï¼‰ï¼Ÿï¼ˆæˆ‘å¯ä»¥æä¾›ï¼‰  \n1.11 è®­ç»ƒé›†ä¸­æ˜¯å¦åº”**å°½é‡é¿å…å¸½å­**ï¼Ÿ  \n1.12 æ˜¯å¦è¿˜æœ‰å…¶ä»–é‡è¦çš„å›¾ç‰‡æ•°æ®è¡¥å……å»ºè®®ï¼Ÿ\n\n# äºŒã€è®­ç»ƒæ•°æ®é›† â€”â€” æè¿° / æ ‡æ³¨ï¼ˆCaptionï¼‰ç›¸å…³é—®é¢˜\n\n2.1 è®­ç»ƒæè¿°ä¸­æ˜¯å¦åº”å°†**è§’è‰²åï¼ˆAnnieï¼‰æ”¾åœ¨ç¬¬ä¸€ä½**ï¼Ÿ  \n2.2 æ˜¯å¦éœ€è¦æè¿°**äº”å®˜ç»†èŠ‚**ï¼ˆçœ¼ç›ã€å˜´å·´ã€é¼»å­ã€è„¸å‹ç­‰ï¼‰ï¼Ÿ  \n2.3 æ˜¯å¦éœ€è¦æè¿°**é•œå¤´/è§†è§’**ï¼ˆè¿œæ™¯ã€è¿‘æ™¯ã€å·¦ã€å³ã€ä¿¯è§†ç­‰ï¼‰ï¼Ÿ  \n2.4 æ˜¯å¦éœ€è¦æè¿°**è¡¨æƒ…**ï¼Ÿ  \n2.5 æ˜¯å¦éœ€è¦æè¿°**å§¿åŠ¿/åŠ¨ä½œ**ï¼Ÿ  \n2.6 æ˜¯å¦éœ€è¦æè¿°**æœè£…**ï¼ˆæ¬¾å¼ã€é¢œè‰²ç­‰ï¼‰ï¼Ÿ  \n2.7 å¦‚æœå‘å‹æ˜¯å›ºå®šçš„ï¼Œæ˜¯å¦ä»éœ€è¦åœ¨æè¿°ä¸­æ ‡æ³¨å‘å‹ï¼Ÿ  \n2.8 å¦‚æœå‘å‹ä¸å›ºå®šï¼Œæ˜¯å¦éœ€è¦åœ¨æè¿°ä¸­æ ‡æ³¨å‘å‹ï¼Ÿ  \n2.9 å¦‚æœå‡ºç°å¸½å­ï¼Œæ˜¯å¦åº”åœ¨æè¿°ä¸­æ˜ç¡®æ ‡æ³¨ï¼Ÿ  \n2.10 æ˜¯å¦éœ€è¦æè¿°**èƒŒæ™¯**ï¼ˆçº¯è‰²æˆ–åœºæ™¯ï¼‰ï¼Ÿ  \n2.11 æ˜¯å¦éœ€è¦æ˜ç¡®æ ‡æ³¨**äººç‰©é£æ ¼ï¼ˆå†™å® 3Dï¼‰**ï¼Ÿ  \n2.12 æ˜¯å¦éœ€è¦æè¿°**æ€§åˆ«**ï¼Ÿ  \n2.13 æ˜¯å¦éœ€è¦æè¿°**å¹´é¾„**ï¼Ÿ  \n2.14 æ˜¯å¦éœ€è¦æè¿°**ä½“å‹**ï¼Ÿ  \n2.15 æ˜¯å¦è¿˜æœ‰å…¶ä»–é‡è¦çš„æè¿°è¡¥å……å»ºè®®ï¼Ÿ  \n2.16 ä¸ºäº†é¿å…**å…¶ä»–è§’è‰²ç»§æ‰¿å®‰å¦®çš„å¤–è§‚**ï¼Œæ˜¯å¦éœ€è¦åœ¨æè¿°ä¸­**å¼ºåŒ–å®‰å¦®çš„ç‹¬æœ‰ç‰¹å¾**ï¼Ÿ  \nï¼ˆä¾‹å¦‚ï¼šåªæœ‰å®‰å¦®æ‹¥æœ‰çº¢è‰²å¤´å‘ï¼‰\n\n# ä¸‰ã€è®­ç»ƒæ•°æ®é›† â€”â€” è§†é¢‘æ ·æœ¬ç›¸å…³é—®é¢˜\n\n3.1 æ˜¯å¦éœ€è¦**è§†é¢‘æ ·æœ¬**ï¼ˆä¾‹å¦‚ï¼šå›´ç»•å®‰å¦® 360Â° æ—‹è½¬çš„è§†é¢‘ï¼‰ï¼Ÿ  \n3.2 æ˜¯å¦éœ€è¦**è§†é¢‘æ ·æœ¬**ï¼ˆä¾‹å¦‚ï¼šå¯¹å®‰å¦®è¿›è¡Œç¼“æ…¢æ¨è¿‘ / æ‹‰è¿œçš„é•œå¤´ï¼‰ï¼Ÿ\n\néå¸¸æ„Ÿè°¢ä»»ä½•å½¢å¼çš„å¸®åŠ©ï¼Œ**å“ªæ€•åªå›ç­”å…¶ä¸­ä¸€é¡¹é—®é¢˜ä¹Ÿéå¸¸æ„Ÿæ¿€** ğŸ™\n\n",
      "is_original_content": false,
      "link_flair_text": "Help ğŸ™‹â€â™‚ï¸",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qdlgfm/lora_training_è®­ç»ƒ/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qe2k3a",
      "title": "You have reached the daily usage limit. Please wait 23 hours before trying again.",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qe2k3a/you_have_reached_the_daily_usage_limit_please/",
      "author": "KidNothingtoD0",
      "created_utc": "2026-01-16 01:39:17",
      "score": 5,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "what is the exact daily usage limit for each features qwen suggests?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qe2k3a/you_have_reached_the_daily_usage_limit_please/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o04nwps",
          "author": "ReplacementTommy",
          "text": "I have never reached the limit and I use it a lot feeding in a lot of data and documents for summarization. I use the official Qwen site",
          "score": 6,
          "created_utc": "2026-01-17 16:34:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o033mse",
          "author": "Puzzleheaded-Box2913",
          "text": "2000 request per day with no token limit",
          "score": 4,
          "created_utc": "2026-01-17 10:47:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02zkzo",
          "author": "Efficient_Cattle_958",
          "text": "I think qwen doesn't have a daily limit, make sure if ur using the official site or just a powered by qwen app cuz the official app doesn't have any limits",
          "score": 3,
          "created_utc": "2026-01-17 10:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o033tdi",
              "author": "Time_Change4156",
              "text": "Does now .and it isn't much.",
              "score": 1,
              "created_utc": "2026-01-17 10:49:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03fai0",
                  "author": "Efficient_Cattle_958",
                  "text": "Irono I haven't used the app for more than 2 weeks, so i don't know what changed recently",
                  "score": 2,
                  "created_utc": "2026-01-17 12:28:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o078s3k",
          "author": "neuralnomad",
          "text": "Itâ€™s gonna cut you off after so many hours of 4K video generation. Sucks I know, but they gotta draw the line somewhere :P",
          "score": 1,
          "created_utc": "2026-01-18 00:09:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08nc10",
          "author": "panic_in_the_cosmos",
          "text": "what exactly youre talking about? qwen chat or qwen coder?",
          "score": 1,
          "created_utc": "2026-01-18 04:54:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qebtn0",
      "title": "ComfyUI Tutorial : Multi Angle & Light Image Editing Using New LORAs Model",
      "subreddit": "Qwen_AI",
      "url": "https://youtu.be/QwxwD4sHI0c",
      "author": "cgpixel23",
      "created_utc": "2026-01-16 09:47:11",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources/learning",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qebtn0/comfyui_tutorial_multi_angle_light_image_editing/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qbnkla",
      "title": "Is it just me or qwen currently the most funny AI right now?",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/4vh1x4s7c3dg1.jpeg",
      "author": "JMVergara1989",
      "created_utc": "2026-01-13 10:06:46",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qbnkla/is_it_just_me_or_qwen_currently_the_most_funny_ai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}