{
  "metadata": {
    "last_updated": "2026-01-24 08:42:05",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 6,
    "total_comments": 15,
    "file_size_bytes": 17721
  },
  "items": [
    {
      "id": "1qfhtbq",
      "title": "Qwen 3.5 and 3.5 coder!",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qfhtbq/qwen_35_and_35_coder/",
      "author": "BasketFar667",
      "created_utc": "2026-01-17 16:35:31",
      "score": 157,
      "num_comments": 17,
      "upvote_ratio": 0.96,
      "text": "Friends, we're really looking forward to the new models! Alibaba is preparing to release them next month. And its SWE verified Bench will be over 79%.\n\nQwen wants to improve his line, and also for comparison 2.5 codec was on his bench 18-29% so the next update will be big",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qfhtbq/qwen_35_and_35_coder/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o05hbn0",
          "author": "usernameplshere",
          "text": "I'm a big sucker for Qwen 3 480B, great model. Would love to see a similar sized (or even larger) successor to it.",
          "score": 11,
          "created_utc": "2026-01-17 18:50:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05ozqm",
              "author": "StardockEngineer",
              "text": "Also a lover of 480b.  But I think it could stand to be smaller.  Or, release a mid-size version in the 100-200b range, along with the smaller one.",
              "score": 7,
              "created_utc": "2026-01-17 19:26:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06d21w",
                  "author": "GCoderDCoder",
                  "text": "Have you tried the reap version? I found it to be very capable in q4.\n\nQwen3coder480b seems to rank poorly in swe bench but it's actually better coding for me than models ranked higher.",
                  "score": 3,
                  "created_utc": "2026-01-17 21:28:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0dndvb",
                  "author": "usernameplshere",
                  "text": "You can try the new Devstral 123b. It's a dense model, but basically just as good as Qwen Coder 480B, if not better. And it's also oss.",
                  "score": 1,
                  "created_utc": "2026-01-18 23:20:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o19wmnq",
              "author": "_Pantom_",
              "text": "Qwen 3  ? is a great model ?  it always tells me that i cannot do i cannot do that, so what kind of great it is  ?  it cannot even generate  react.js  + php + mysql + tailwind  app, yet it is great ? really ?",
              "score": 1,
              "created_utc": "2026-01-23 17:39:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05bnz3",
          "author": "iongion",
          "text": "Qwen is already phenomenal, if it would only be faster and more tooling would be there",
          "score": 7,
          "created_utc": "2026-01-17 18:24:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06k034",
              "author": "ForsookComparison",
              "text": "Qwen3-Next-80B gives me hope.\n\nIf there was something that had the knowledge-depth and lack of hallucinations that Qwen3-235B has but closer to the active params of Qwen3-Next-80b that would be amazing.\n\nSomething GLM-Air or GLM-V sized maybe.",
              "score": 4,
              "created_utc": "2026-01-17 22:03:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o05cw4d",
              "author": "BasketFar667",
              "text": "I think they need to train it more for fixing bugs, and other main developing functions. Model is buggy, I'm testet lua and I was disappointed :(",
              "score": 3,
              "created_utc": "2026-01-17 18:30:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05fgml",
                  "author": "No_Film_9120",
                  "text": "Hmm? You are a beta tester for 3.5?",
                  "score": 3,
                  "created_utc": "2026-01-17 18:42:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o05cyfd",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-01-17 18:30:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o069iav",
          "author": "These_Mushroom807",
          "text": "QUEN IS MALE??",
          "score": 3,
          "created_utc": "2026-01-17 21:10:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0djxuj",
          "author": "nunodonato",
          "text": "I'm rooting for small models and small MoE as well :) Love my 4B and 8B, as well as the 30 A3B",
          "score": 3,
          "created_utc": "2026-01-18 23:03:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fqop3",
              "author": "Wesstes",
              "text": "Same, I've been testing them and they're quite neat, and great for their size",
              "score": 1,
              "created_utc": "2026-01-19 06:59:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o06n5uw",
          "author": "fancyawesome",
          "text": "235b is the king, please optimise it",
          "score": 2,
          "created_utc": "2026-01-17 22:18:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o069en0",
          "author": "United-Welcome-8746",
          "text": "my favorit models!",
          "score": 1,
          "created_utc": "2026-01-17 21:09:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0agjwf",
          "author": "Namra_7",
          "text": "It's been a long time no new models and not even ga for qwen max thinking",
          "score": 1,
          "created_utc": "2026-01-18 13:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cxpzl",
              "author": "BasketFar667",
              "text": "It won't happen.",
              "score": 1,
              "created_utc": "2026-01-18 21:12:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfd90d",
      "title": "what are best popular LLM model faster and efficient to respond",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/pmcdw85jvwdg1.png",
      "author": "Adventurous_Role_489",
      "created_utc": "2026-01-17 13:30:05",
      "score": 11,
      "num_comments": 8,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Model",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qfd90d/what_are_best_popular_llm_model_faster_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o03uqay",
          "author": "Actionberg",
          "text": "So there is no number 1, right?",
          "score": 2,
          "created_utc": "2026-01-17 14:07:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o090phg",
              "author": "Adventurous_Role_489",
              "text": "![gif](giphy|wpFaFBn0YrO69a6oVX)",
              "score": 1,
              "created_utc": "2026-01-18 06:36:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03wlo0",
          "author": "AgentGulliver",
          "text": "May I suggest LFM 2.5 VL 1.6B? It runs exceptionally on my low-end(ish) device.",
          "score": 1,
          "created_utc": "2026-01-17 14:18:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09097z",
              "author": "Adventurous_Role_489",
              "text": "I'm sorry I'm only focus on popular LLM like llama 3.2 and qwen 2.5 because they're only reliable ",
              "score": 0,
              "created_utc": "2026-01-18 06:32:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0gdtu6",
                  "author": "Fabulous-Courage819",
                  "text": "Popular doesnt mean reliable, and if you’ll search for lfm2.5 benchmark results you will be quite surprised",
                  "score": 2,
                  "created_utc": "2026-01-19 10:32:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06bjgt",
          "author": "United-Welcome-8746",
          "text": "qwen3-th-4b on samsung tab s11 11t/s",
          "score": 1,
          "created_utc": "2026-01-17 21:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o090ffp",
              "author": "Adventurous_Role_489",
              "text": "that sound good but unfortunately I don't like is very thinking or overthinking so.",
              "score": 1,
              "created_utc": "2026-01-18 06:34:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qju11o",
      "title": "Qwen model",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qju11o/qwen_model/",
      "author": "BasketFar667",
      "created_utc": "2026-01-22 13:06:11",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.67,
      "text": "We will get it this week ",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qju11o/qwen_model/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o122jr4",
          "author": "HyperWinX",
          "text": "We've got it already.",
          "score": 2,
          "created_utc": "2026-01-22 15:04:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12l07z",
              "author": "BasketFar667",
              "text": "okay",
              "score": 0,
              "created_utc": "2026-01-22 16:29:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgzdii",
      "title": "Alibaba Qwen models laggy, batches failing constantly",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qgzdii/alibaba_qwen_models_laggy_batches_failing/",
      "author": "elaith9",
      "created_utc": "2026-01-19 09:09:14",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "Hello friends, I was wondering if you are experiencing the same issues with Alibaba Qwen models as I do. I'm using qwen-flash and qwen-plus in Singapore region for both realtime and batch inference.   \n  \nRealtime response times can go from anything like 50ms response time to 2 minutes for 2.5K context being sent.\n\nBatching with qwen-flash and qwen-plus also fails regularly with errors like ResponseTimeout despite the fact that my request tokens are way below the TPM limits.\n\nI have raised my issues with the customer support and they said it's probably due to their team fixing some scaling issues. This has been going on for 5 days now and I'm wondering is this normal and expected from Alibaba. In my view it's completely unreliable and I should probably move to alternative. \n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qgzdii/alibaba_qwen_models_laggy_batches_failing/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o0hdjur",
          "author": "elaith9",
          "text": "Anyone having these issues?",
          "score": 1,
          "created_utc": "2026-01-19 14:40:19",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qif4xd",
      "title": "Manus AI inspired skill tuned for Qwen Code CLI",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qif4xd/manus_ai_inspired_skill_tuned_for_qwen_code_cli/",
      "author": "Minimum_Peak_6879",
      "created_utc": "2026-01-20 22:05:16",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nI recently created a skill to be used in the Qwen Code CLI inspired by other tools that are not so friendly with Open Source.\n\nRepo: [https://github.com/Abimael10/planning-with-files-qwen](https://github.com/Abimael10/planning-with-files-qwen)\n\nThe initial idea behind it is kind of to transform your workflow to use persistent markdown files for planning, progress tracking, and knowledge storage similar to what the recently adquired Manus AI exposed in this article: [https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)\n\nAs of any demo that us 996s can create for the sake of exposure of real usage, I used it to create a demo CRUD service, very simple, using the Axum framework and Rust with screenshots on the very minimal initial prompt that I gave Qwen Code to generate, the code and setup for this generated project is inside the demo folder of the repo, you can cd to it with the required Rust tooling to validate.\n\nThis was the very only initial prompt and the result can be seen in the demo folder of the repo:\n\nhttps://preview.redd.it/txmaucnuskeg1.png?width=1747&format=png&auto=webp&s=cdf6d8d901163417070362e3f65e914e5951d957\n\nLet me know if this is something that actually can be used for real and if any suggestion or issue, I am completely open even if it just to make it look cleaner for anyone to understand.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qif4xd/manus_ai_inspired_skill_tuned_for_qwen_code_cli/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o0s2okf",
          "author": "Practical-Nerve-2262",
          "text": "Can this be used to solve ComfyUI error issues? How did you guys start doing code?",
          "score": 1,
          "created_utc": "2026-01-21 01:51:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e4jx0",
          "author": "Previous_Highway4442",
          "text": "super cool!",
          "score": 1,
          "created_utc": "2026-01-24 07:58:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg2ue6",
      "title": "Working on a system which animates light based on LLM prompts (locally via LM Studio Qwen + Schema Studio)",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qg2ue6/working_on_a_system_which_animates_light_based_on/",
      "author": "domjjj",
      "created_utc": "2026-01-18 08:05:41",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "",
      "is_original_content": false,
      "link_flair_text": "Experiment",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qg2ue6/working_on_a_system_which_animates_light_based_on/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o09qgu5",
          "author": "Full-Flower3325",
          "text": "I don't understand. Could you please explain?",
          "score": 1,
          "created_utc": "2026-01-18 10:31:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a3v3o",
              "author": "domjjj",
              "text": "Sure, I am using the qwen model here to add essentially code generation capabilities into my application for controlling lights and media installations.\n\nSo instead of having to build blocks manually in the visual environment, I can simply prompt the LLM with something like \"switch between colors of the rainbow\". As a result I will get that animation, fully editable.\n\nIt's quite similar to code generation in IDEs like cursor, except that the language is represented more visually and the whole environment is geared toward controlling physical devices.",
              "score": 1,
              "created_utc": "2026-01-18 12:27:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}