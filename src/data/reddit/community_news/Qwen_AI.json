{
  "metadata": {
    "last_updated": "2026-02-05 09:15:02",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 8,
    "total_comments": 33,
    "file_size_bytes": 33616
  },
  "items": [
    {
      "id": "1qsbzz5",
      "title": "The Qwen Mac app keeps surprising me.",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qsbzz5/the_qwen_mac_app_keeps_surprising_me/",
      "author": "pakalolo7123432",
      "created_utc": "2026-01-31 19:38:39",
      "score": 27,
      "num_comments": 10,
      "upvote_ratio": 0.97,
      "text": "This damn app and model keeps luring me back over and over. I find its responses to be very matter of fact and blunt. It frequently says \"I'm going to be honest here\" and proceeds to thoughtfully debate me.  I keep finding myself choosing Qwen first when I want to have general life chats, procedure building chats, Knowledge Graph suggestions, you name it.\n\nIt gives me a popup whenever it remembers something about me, or if it changes a previous memory. It also seems to know when to use memories at just the right time. \n\nThe MCP servers are wild, too. I have created projects in Qwen and have it dig through my KG and Obsidian Vault for project data. \n\nI really thought I would just be using Qwen as a toy for a few days and then move on to play with the next model, but the reverse happened. I'm kind of addicted to it. I know that I am freely volunteering my data to them but its really not that important to me for what I'm getting. \n\nIs anyone else surprised by Qwen's chatting abilities or have I just done drank the kool aid??? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qsbzz5/the_qwen_mac_app_keeps_surprising_me/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2uktgv",
          "author": "ReadGorilla",
          "text": "Qwen reminds me a lot of the earlier GPT-4 series‚Äîbut with a touch of Eastern elegance and philosophical depth. I was so drawn to her during our chats over the December holidays that I‚Äôm now considering connecting her to an OpenClaw bot via API.",
          "score": 6,
          "created_utc": "2026-01-31 20:19:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2v7b30",
              "author": "Unedited_Sloth_7011",
              "text": "Especially Qwen3-235B-A22B has exactly similar style like GPT-4o, but with significantly less flattery and slightly more goofiness (plus tone/style of reasoning similar to Deepseek-R1). Qwen3-Max is absolutely awesome model too.",
              "score": 5,
              "created_utc": "2026-01-31 22:09:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2vj7wo",
                  "author": "pakalolo7123432",
                  "text": "Nice. I will switch to that one for a couple of days and see how I like it. Thanks for the tip!",
                  "score": 4,
                  "created_utc": "2026-01-31 23:11:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2upi3x",
          "author": "azvd_",
          "text": "yes!!! i‚Äôve been using qwen for so long now i don‚Äôt even know when did it start being my preference. i think that‚Äôs cool as hell, Qwen is such a great chatbot i‚Äôve stopped using paid alternatives i got promos on bc his free tier had more to offer lol. \nIt‚Äôs a shame that most companies are funnelling resources into coding when there‚Äôs so much more still unexplored on other AI features",
          "score": 6,
          "created_utc": "2026-01-31 20:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xiem9",
          "author": "Realistic_Pen_8614",
          "text": "Qwen app is good. The only sad part for me is that I can‚Äôt have the app on my Linux laptop. It would have been wonderful.",
          "score": 2,
          "created_utc": "2026-02-01 06:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31m7mk",
          "author": "Hot_Clothes1623",
          "text": "Been using Qwen CLI again and again. It just works.",
          "score": 2,
          "created_utc": "2026-02-01 21:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kwo61",
          "author": "jokab",
          "text": "i got the 10gbp a month coding plan. great value!",
          "score": 1,
          "created_utc": "2026-02-04 19:02:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqoqlw",
      "title": "Developers, how are you using Qwen in your personal projects?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qqoqlw/developers_how_are_you_using_qwen_in_your/",
      "author": "TKB21",
      "created_utc": "2026-01-29 23:28:41",
      "score": 20,
      "num_comments": 29,
      "upvote_ratio": 1.0,
      "text": "I recently came across Qwen as I cut my teeth in ML. I've seen the capabilities of what it can do but was curious to see \"how\" developers are using it within their personal projects, codebases, and product offerings. Many thanks in advance for sharing!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqoqlw/developers_how_are_you_using_qwen_in_your/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2i9s0g",
          "author": "haradaken",
          "text": "I'm using it for an on-device AI companion app. It's amazing to see models like Qwen  actually run on your iPhone!",
          "score": 3,
          "created_utc": "2026-01-29 23:48:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i9yvc",
              "author": "TKB21",
              "text": "That‚Äôs awesome! I‚Äôm guessing you run it server side?",
              "score": 2,
              "created_utc": "2026-01-29 23:49:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ictsm",
                  "author": "haradaken",
                  "text": "I'm running Qwen models on device, on iPhone. Once the model data is downloaded, no internet connection is necessary, as far as the language model is concerned.",
                  "score": 1,
                  "created_utc": "2026-01-30 00:04:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2iwz8g",
          "author": "Puzzleheaded-Box2913",
          "text": "Using CLI to create boilerplate code for infrastructure prototyping. Qwen Code CLI + Jules",
          "score": 2,
          "created_utc": "2026-01-30 01:54:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jvn1y",
              "author": "Realistic_Pen_8614",
              "text": "Care to share some of your prompts?",
              "score": 1,
              "created_utc": "2026-01-30 05:22:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2k20zo",
                  "author": "Puzzleheaded-Box2913",
                  "text": "Generic Systems Infrastructure Development Template\n[SYSTEM_NAME] Unified Data Platform ‚Äì Technical Specification\nOverview\nA production-grade data and application platform designed to manage information workflows, automate routine operations, and deliver structured outputs for professional users. Built for reliability, extensibility, and offline-capable operation.\nCore Architecture\nLayered Service Architecture  \n\n    Persistence Layer: Local-first data storage with synchronization capability  \n    Business Logic Layer: Domain-specific rule processing and workflow orchestration  \n    Integration Layer: External system connectivity and API management  \n    Presentation Layer: Command-line and programmatic interfaces\n\nCore Engine Components  \n\n    [CORE_ENGINE]: Manages data persistence, workflow execution, error recovery, and configuration  \n    [EXTENSION_ENGINE]: Handles optional integrations, advanced analytics, and third-party connectivity\n\nStandard Infrastructure Modules (select/replace as needed)  \n\n    Data Store Manager ‚Äì Local SQLite/JSON storage with schema validation  \n    Task Scheduler ‚Äì Priority-based job queuing and execution  \n    Event Bus ‚Äì Publish/subscribe messaging between components  \n    Authentication Module ‚Äì Role-based access control and session management  \n    File Processor ‚Äì Batch and streaming file handling with format conversion  \n    Report Generator ‚Äì Structured output creation in multiple formats (CSV, JSON, plain text)  \n    Notification System ‚Äì Event-triggered alerts via multiple channels  \n    Metrics Collector ‚Äì Usage tracking and performance monitoring\n\nAdaptive Capabilities  \n\n    Context-aware workflow adjustments based on input patterns  \n    Automatic recovery from common error states  \n    Configurable behavior per user-defined profiles\n\nDomain Adaptability\nSupports multiple operational contexts (e.g., research, operations, analysis) through swappable configuration profiles and data schemas.\nSecurity & Reliability  \n\n    Input validation and sanitization  \n    Structured error logging  \n    Configurable access boundaries  \n    Data integrity checks on read/write operations\n\nExecution Directive Template\nROLE: You are a senior systems architect capable of designing and implementing production-grade software infrastructure.\nOBJECTIVE: Build a complete, self-contained [SYSTEM_NAME] platform targeting [LINE_COUNT]+ lines of production-ready code. This is not a prototype ‚Äî deliver a functional, tested implementation.\nINPUT SPECIFICATION:\nImplement a unified system incorporating:  \n\n    Layered architecture (persistence ‚Üí logic ‚Üí integration ‚Üí interface)  \n    Core engine with workflow orchestration  \n    Selected standard modules from the list above  \n    Error resilience and recovery mechanisms\n\nMANDATORY IMPLEMENTATION RULES:  \n\n    ZERO PLACEHOLDERS: No # TODO, pass, stubs, or incomplete logic. Every function must contain executable code.  \n    FULL DOCUMENTATION:  \n        Type hints on all parameters and returns  \n        Docstrings (Google style) for all public classes/methods  \n        Inline comments explaining non-obvious logic  \n        Embedded test cases in if __name__ == \"__main__\" blocks\n    DEFENSIVE PROGRAMMING:  \n        Validate all external inputs  \n        Catch and log recoverable errors  \n        Fail gracefully on unrecoverable conditions\n    MODULAR DELIVERY: Output one logical module/file per response. Maintain dependency order.\n\nDELIVERY PROTOCOL:\nWork in sequential PHASES due to output limits:  \n\n    PHASE 1: Project structure, dependencies (requirements.txt), configuration system  \n    PHASE 2: Core engine and persistence layer  \n    PHASE 3+: Additional modules per priority\n\nCONTINUITY RULE:\nTerminate output cleanly at phase boundaries or token limits. Await explicit \"PROCEED TO NEXT PHASE\" before continuing. Never summarize previous output.\nBEGIN: Start with PHASE 1 ‚Äî output only the directory tree and requirements.txt.\n\n\n\nUsage Instructions\n\n    Replace [SYSTEM_NAME] with your project identifier  \n    Set [LINE_COUNT] to your target (e.g., 10000)  \n    Select 3‚Äì5 modules from the \"Standard Infrastructure Modules\" list matching your scope  \n    Optionally adjust layers/architecture to fit your domain.",
                  "score": 3,
                  "created_utc": "2026-01-30 06:09:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2jkrjg",
          "author": "skibud2",
          "text": "Fully automated full C++ app building. Took a year to get here. Still work to do. qwen3-coder 30b, 4bit",
          "score": 2,
          "created_utc": "2026-01-30 04:10:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k2ajz",
          "author": "awesomeunboxer",
          "text": "I  had it scan 24k images and tag them for a weird project im working on. it took about 20 hours:3",
          "score": 2,
          "created_utc": "2026-01-30 06:11:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m1n6n",
          "author": "HelpfulSource7871",
          "text": "we install the newest qwen3-tts in our server, won't pay any other voice generator any more",
          "score": 2,
          "created_utc": "2026-01-30 14:54:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i81ef",
          "author": "ridablellama",
          "text": "keyword classification",
          "score": 1,
          "created_utc": "2026-01-29 23:38:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jeyt4",
          "author": "Remarkable_Speed1402",
          "text": "In Moltbot, I connected Qwen, and I'm still trying. I told it to send me the latest AI news every morning at 9 o'clock, but it failed. I don't know if it doesn't support this kind of play or if there's something wrong with my configurationüòÇ",
          "score": 1,
          "created_utc": "2026-01-30 03:35:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k3p3s",
              "author": "cool-beans-yeah",
              "text": "Where do you run Moltbot? I would like to do something similar...",
              "score": 1,
              "created_utc": "2026-01-30 06:22:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kkkp9",
                  "author": "Remarkable_Speed1402",
                  "text": "Alibaba Cloud, if you can read Chinese, they have a Chinese version of the deployment document.",
                  "score": 1,
                  "created_utc": "2026-01-30 08:47:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2pgp0s",
              "author": "somas",
              "text": "Your Qwen is local or cloud based? I‚Äôm struggling to get a local Qwen 235 B running well with Moltbot",
              "score": 1,
              "created_utc": "2026-01-31 00:36:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2zejpa",
                  "author": "Remarkable_Speed1402",
                  "text": "cloud based, after experiencing it for a few days, it seems that moltbot doesn't shock me as much as I thought, maybe I haven't found the right scenario for me yet.",
                  "score": 1,
                  "created_utc": "2026-02-01 15:26:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2k3hzz",
          "author": "No_Astronaut873",
          "text": "This is a project I run locally on my Mac mini and can control it remotely with tailscale from my iPhone, its just a web app with different modules that i use daily instead of having or paying for 9 different apps. I found the abliterated qwen though working best for the diary log entries and the reverse diary thingy\n\nhttps://www.reddit.com/r/LocalLLaMA/s/gADOVetwTf",
          "score": 1,
          "created_utc": "2026-01-30 06:21:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k6zre",
          "author": "FrostyTomatillo8174",
          "text": "Local RAG system to search, and do little stuff like summarize, create document, searching document based on context, etc. Knowledge was stored locally also from semantic embadding. Its suprised me that the result is quite good and fast (using qwen3:30B in RTX 4060) even the file used for chunked still small (around 50 file). The development used agno library in python.",
          "score": 1,
          "created_utc": "2026-01-30 06:49:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k77l6",
          "author": "Alokir",
          "text": "I'm using a local Qwen Coder as a coding agent for light tasks. Not everything requires a huge and expensive cloud model.\n\nI'm using Qwen VL in a card game I'm making to come up with silly cards (with names, descriptions, actions, effects, etc.) depending on the user's previous actions. The game has no prebuilt cards, everything is generated by Qwen on the fly. It's a personal project for learning, nothing more, but it's a lot of fun.",
          "score": 1,
          "created_utc": "2026-01-30 06:51:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lfk5m",
          "author": "celsowm",
          "text": "For state attorneys to summarize lawsuites and to write drafts in our own local web app",
          "score": 1,
          "created_utc": "2026-01-30 12:57:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2u8p3d",
          "author": "a_menezes",
          "text": "Embedding text",
          "score": 1,
          "created_utc": "2026-01-31 19:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mg921",
          "author": "ramendik",
          "text": "I'm fine-tuning a small Granite on Kimi K2 Instruct data - but Qwen models play a hugely important role. I use them for classifier tasks - discarding bad examples, selecting examples that require fact-checking, and so on. Qwen models are extremely obedient. Right now I run Qwen3 32B VL on a [vast.ai](http://vast.ai) node for the classifier tasks; in many other cases I use 235B A22B on the could.",
          "score": 1,
          "created_utc": "2026-02-04 23:34:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quwunq",
      "title": "17 days ago I saw \"Qwen-3.5 and 3.5-coder!\" First, we got -next",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1quwunq/17_days_ago_i_saw_qwen35_and_35coder_first_we_got/",
      "author": "BasketFar667",
      "created_utc": "2026-02-03 16:38:58",
      "score": 15,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Today is big step to agentic coding. We got qwen-3-coder-next. Next steps this month, next will be bigger.",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1quwunq/17_days_ago_i_saw_qwen35_and_35coder_first_we_got/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o3olnr8",
          "author": "Puzzleheaded-Box2913",
          "text": "Can't wait for the 3.5süòÑ",
          "score": 1,
          "created_utc": "2026-02-05 08:06:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrnvan",
      "title": "Chat feels responsive with Qwen2.5 7B 4bit running locally on iPhone!",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/ck73h7bj1lgg1",
      "author": "haradaken",
      "created_utc": "2026-01-31 00:56:55",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qrnvan/chat_feels_responsive_with_qwen25_7b_4bit_running/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2pzp3q",
          "author": "Available-Craft-5795",
          "text": "Streaming text token by token would be better",
          "score": 3,
          "created_utc": "2026-01-31 02:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2q174i",
              "author": "haradaken",
              "text": "Thanks for your reply u/Available-Craft-5795 ! Though the video above does not include sound, the app actually generates TTS audio of language model output. The TTS part is on cloud, for now. Once the TTS is stream-based, streaming language model output is definitely something I want to explore!",
              "score": 2,
              "created_utc": "2026-01-31 02:36:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pkx0p",
          "author": "haradaken",
          "text": "My typing looks slow when compared to the model response... :D",
          "score": 2,
          "created_utc": "2026-01-31 01:00:14",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2wx11l",
          "author": "qwen_next_gguf_when",
          "text": "You can type even slower.",
          "score": 1,
          "created_utc": "2026-02-01 04:07:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o381vq9",
          "author": "Temporaryattemp",
          "text": "How can I install it to my iPhone?",
          "score": 1,
          "created_utc": "2026-02-02 20:53:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv4g31",
      "title": "Qwen3‚ÄëCoder‚ÄëNext in Qwen Code (cli)?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qv4g31/qwen3codernext_in_qwen_code_cli/",
      "author": "alonemushk",
      "created_utc": "2026-02-03 21:13:04",
      "score": 12,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "Does anyone know if the coder-next model will be available in qwen code cli?\n\n[https://qwen.ai/blog?id=qwen3-coder-next](https://qwen.ai/blog?id=qwen3-coder-next)\n\n  \nI dont see it yet. (*already updated the cli to latest*)\n\nhttps://preview.redd.it/l3pta397ichg1.png?width=1620&format=png&auto=webp&s=6133e97b4990551bfaba8c0724ecfdacea3e90f8\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qv4g31/qwen3codernext_in_qwen_code_cli/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o3f8bt8",
          "author": "BasketFar667",
          "text": "soon, this week",
          "score": 1,
          "created_utc": "2026-02-03 22:11:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iw6mx",
          "author": "aitorserra",
          "text": "Today I think my Qwen is smarter, it could be for that? It also asked me about the session. Never before asked for feedback.",
          "score": 1,
          "created_utc": "2026-02-04 13:14:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3iwm9u",
              "author": "alonemushk",
              "text": "Which model do you see with /model ?",
              "score": 1,
              "created_utc": "2026-02-04 13:16:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jbftw",
          "author": "FanTzy17",
          "text": "can't wait to try it!",
          "score": 1,
          "created_utc": "2026-02-04 14:36:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mq7fy",
          "author": "kingabzpro",
          "text": "I have been runing it locally and using it with qwen code. Working smothly. ",
          "score": 1,
          "created_utc": "2026-02-05 00:29:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqo6xs",
      "title": "Why no updates (or love) for Qwen3 32B dense?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qqo6xs/why_no_updates_or_love_for_qwen3_32b_dense/",
      "author": "ramendik",
      "created_utc": "2026-01-29 23:06:08",
      "score": 10,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "EDIT: RESOLVED. There is a recent update to the dense Qwen3 32B, it's Qwen3 32B VL, which exists as separate Instruct and Thinking versions and claims better performance as pure text too. Kudos u/[Due-Project-7507](https://www.reddit.com/user/Due-Project-7507/) \n\nSo I'm doing a distill of a different model (not Qwen) and needed LLM-based filtering for a mass generation result. I'm camping on a Vast A100 40Gb, so wanted something running there. Qwen3 30B A3B 2507 fit comfortably in AWQ4 vllm and minimally in 8bit llama.cpp but was Just Wrong at the task. Qwen3 80B A3B fits only in IQ3 llama.cpp, but, while better than the 30B, wasn't really great at this classification even on a cloud subscription.\n\nThen I found Qwen3 32B, which in AWQ4, on vllm, is doing a stellar job and is also blazing fast on the hardware.\n\nSo question: why is there not much discussion on this hidden gem of a model and why was there no 2507 power-up for it? Okay, for compute-limited applications (as in \"the edge\") the MoE speedup makes all the difference. But when one is memory-limited more than compute-limited, the \"extra smart\" of a 32B dense model without the massive memory requirements of 80/235B MoEs is quite formidable.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqo6xs/why_no_updates_or_love_for_qwen3_32b_dense/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2vgus6",
          "author": "Due-Project-7507",
          "text": "The latest version was released as \"VL\", so it was updated some time ago. Qwen3-VL-32B version should be better than the original Qwen3-32B also just for text. But the 32B dense version is similar in speed than the 235B-A22B MoE version and not as good.",
          "score": 3,
          "created_utc": "2026-01-31 22:59:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vx6jf",
              "author": "ramendik",
              "text": "I am really enjoying Qwen3 32B dense, 4bit AWQ, on a 40Gb VRAM GPU - and it would even run on 24Gb VRAM. THAT is the difference from the 235 A22B.\n\nThank you very much for pointing me to the VL version as the update! I will now update this post, the question is resolved.",
              "score": 1,
              "created_utc": "2026-02-01 00:30:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2zrpq2",
              "author": "kryptkpr",
              "text": "This, the VL 32B is the closest to a 2507 we got. It's a really good model in my tests but 235B does beat it if you got the VRAM.",
              "score": 1,
              "created_utc": "2026-02-01 16:28:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2otcr0",
          "author": "loadsamuny",
          "text": "I think 2507 was the long context extension and I‚Äôm guessing that‚Äôs prohibitively expensive to train compared to MoEs",
          "score": 2,
          "created_utc": "2026-01-30 22:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iowva",
          "author": "Available-Craft-5795",
          "text": "Speed, modernization, efficiency, ect...  \nDense models are good, but they are inefficient and MoE provides the same thing but better most of the time.",
          "score": 1,
          "created_utc": "2026-01-30 01:09:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j508h",
              "author": "ramendik",
              "text": "Except when memory-limited, the dense will do more. Om taht 40G machine, the best Qwen MoE I could theoretically run is 80B A3B, and it's exceedingly slow in llama.cpp IQ3, \\*and\\* not as capable too (the standard estimate formula makes it similar to a 15B dense model).\n\nOkay there are not that many A100 40Gbs, but the 5090 is common and its math is abundant. While the 32B even in 4bit might be too slow on the 3090/4090, 5050 should be a breeze.",
              "score": 1,
              "created_utc": "2026-01-30 02:39:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2irr8t",
          "author": "ClimateBoss",
          "text": "how is it compared to Qwen3 coder 30b a3b  ?",
          "score": 1,
          "created_utc": "2026-01-30 01:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j3ltl",
              "author": "ramendik",
              "text": "I am not coding, I am classifying text. so I didn't try Qwen3 Coder.",
              "score": 1,
              "created_utc": "2026-01-30 02:31:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k905w",
          "author": "No-Consequence-1779",
          "text": "All I use is qwen. They are great. ¬†Interesting dense and moe take the same vram and are almost the same size. I may be stupid.¬†",
          "score": 1,
          "created_utc": "2026-01-30 07:05:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xy4bg",
              "author": "Space__Whiskey",
              "text": "yea i was having a hard time deciding which one to use. I ended up picking the moe.",
              "score": 1,
              "created_utc": "2026-02-01 09:10:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqp9q2",
      "title": "Help. I am using Qwen 3 TTS 1.7B and whenever I generate audio with the text I give in voice clone section, the result comes as 2-3 min audio with AI speaking ultra fast.",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qqp9q2/help_i_am_using_qwen_3_tts_17b_and_whenever_i/",
      "author": "Obvious_Ad8471",
      "created_utc": "2026-01-29 23:50:44",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "It starts normal for few seconds and it paces up my 100 words text and try to fit under 2 mins",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqp9q2/help_i_am_using_qwen_3_tts_17b_and_whenever_i/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qqhr5s",
      "title": "I vibe coded a local audio inference engine for Qwen3-TTS and Qwen3-ASR",
      "subreddit": "Qwen_AI",
      "url": "https://github.com/agentem-ai/izwi-audio",
      "author": "zinyando",
      "created_utc": "2026-01-29 19:05:11",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqhr5s/i_vibe_coded_a_local_audio_inference_engine_for/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2iqa19",
          "author": "haradaken",
          "text": "Great work! Thanks for sharing. I‚Äôm trying to get Qwen3‚ÄìTTS work on iPhones, and your success gives me inspiration.  :)",
          "score": 1,
          "created_utc": "2026-01-30 01:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mdgha",
              "author": "zinyando",
              "text": "How far have you gone with your project? Sounds amazing",
              "score": 2,
              "created_utc": "2026-01-30 15:48:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2pb11j",
                  "author": "haradaken",
                  "text": "Thanks, u/zinyando ! My iPhone app below can run a language model on device. Qwen3-TTS sounds like a great technology in pursuing the privacy-first vision of my app.\n\n[https://apps.apple.com/jp/app/aicrest/id6752296250?l=en-US](https://apps.apple.com/jp/app/aicrest/id6752296250?l=en-US)",
                  "score": 1,
                  "created_utc": "2026-01-31 00:05:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}