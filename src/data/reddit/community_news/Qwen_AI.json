{
  "metadata": {
    "last_updated": "2026-02-01 08:57:56",
    "time_filter": "week",
    "subreddit": "Qwen_AI",
    "total_items": 18,
    "total_comments": 52,
    "file_size_bytes": 57328
  },
  "items": [
    {
      "id": "1qnkd7p",
      "title": "Qwen3-Max-Thinking - Comparible performance to Commercial Models",
      "subreddit": "Qwen_AI",
      "url": "https://qwen.ai/blog?id=qwen3-max-thinking",
      "author": "willpoopanywhere",
      "created_utc": "2026-01-26 16:13:12",
      "score": 40,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qnkd7p/qwen3maxthinking_comparible_performance_to/",
      "domain": "qwen.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o1wawmc",
          "author": "Linkpharm2",
          "text": "Tried it on their website. Can't tell if it's bad or not, because their agentic code mode is so terrible nothing compiled.",
          "score": 2,
          "created_utc": "2026-01-26 21:27:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1y3879",
          "author": "Hefty-Newspaper5796",
          "text": "Good to know. I wont use it but i indeed hope it can drive down the price of commercial models.",
          "score": 1,
          "created_utc": "2026-01-27 02:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r091w",
          "author": "StardockEngineer",
          "text": "Isnt it also a commercial model?",
          "score": 1,
          "created_utc": "2026-01-31 06:42:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qonzjf",
      "title": "Benchmark of Qwen3-32B reveals 12x capacity gain at INT4 with only 1.9% accuracy drop",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qonzjf/benchmark_of_qwen332b_reveals_12x_capacity_gain/",
      "author": "AIMultiple",
      "created_utc": "2026-01-27 19:33:17",
      "score": 35,
      "num_comments": 16,
      "upvote_ratio": 0.97,
      "text": "We ran 12,000+ MMLU-Pro questions and 2,000 inference runs to settle the quantization debate. INT4 serves 12x more users than BF16 while keeping 98% accuracy.\n\nBenchmarked Qwen3-32B across BF16/FP8/INT8/INT4 on a single H100. The memory savings translate directly to concurrent user capacity. Went from 4 users (BF16) to 47 users (INT4) at 4k context. Full methodology and raw numbers here: https://research.aimultiple.com/llm-quantization/",
      "is_original_content": false,
      "link_flair_text": "Experiment",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qonzjf/benchmark_of_qwen332b_reveals_12x_capacity_gain/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o23n73t",
          "author": "ClimateBoss",
          "text": "wut about coding ?",
          "score": 3,
          "created_utc": "2026-01-27 22:08:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23oe3o",
              "author": "AIMultiple",
              "text": "We are planning to add a coding dataset in the next version",
              "score": 2,
              "created_utc": "2026-01-27 22:13:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o254t0v",
          "author": "Qxz3",
          "text": "Anecdotal evidence, but on Qwen3 4B, the smallest quant that didn't drop accuracy on general programming questions was Q5_K_XL for me. Q4 would start to miss out on details or completeness.¬†",
          "score": 1,
          "created_utc": "2026-01-28 02:41:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gno09",
              "author": "AIMultiple",
              "text": "Smaller models definitely have less redundancy in their weights, making them more sensitive to aggressive quantization.",
              "score": 1,
              "created_utc": "2026-01-29 19:03:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2692jl",
          "author": "Emergency-Pomelo-256",
          "text": "My experience with GLM 4.7 8 bit quant vs minimax m2.1 f16 , minimax was much better & in non quant GLM was much better",
          "score": 1,
          "created_utc": "2026-01-28 07:03:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gnt4v",
              "author": "AIMultiple",
              "text": "Absolutely, quantization behavior varies significantly across architectures.",
              "score": 1,
              "created_utc": "2026-01-29 19:04:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gxtyz",
                  "author": "ScoreUnique",
                  "text": "Have you got a rule of thumb for architectures? I mean for example longcat and Deepseek use Deepseek attention architecture (not sure about the correct terminology), do you think it's worth making a benchmark across different architectures to check for the perplexity drop?",
                  "score": 1,
                  "created_utc": "2026-01-29 19:51:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2dpd59",
          "author": "ScoreUnique",
          "text": "Quick question- when you say Int4 GPTQ, are these safe tensors or it can be GGUFs? Sorry if it's a noob question. Thanks.",
          "score": 1,
          "created_utc": "2026-01-29 09:03:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gny97",
              "author": "AIMultiple",
              "text": "Not a noob question at all. We used GPTQ-quantized models in SafeTensors format via vLLM.\nGGUF is a different format for llama.cpp/Ollama with its own quant schemes (Q4_K_M, Q5_K, etc.). The runtime and kernel stacks differ: vLLM is GPU-centric for high-throughput serving, while llama.cpp is CPU-first with optional GPU offload.",
              "score": 1,
              "created_utc": "2026-01-29 19:04:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gxdla",
                  "author": "ScoreUnique",
                  "text": "Does this mean I can concert the GPTQ models into gguf whilst guarding the quality of the model as it is?",
                  "score": 1,
                  "created_utc": "2026-01-29 19:49:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2flukk",
          "author": "International_Ad1896",
          "text": "What about kv cache quantization?",
          "score": 1,
          "created_utc": "2026-01-29 16:13:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2go42i",
              "author": "AIMultiple",
              "text": "We focused on model weight\nquantization for this benchmark.\nKV cache stayed at FP16 throughout. But good call, we've added KV cache quantization to our list for v2.",
              "score": 1,
              "created_utc": "2026-01-29 19:05:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gq7dq",
                  "author": "International_Ad1896",
                  "text": "Cool. That would be great. Also include agentic benchmarks if possible especially with large context. Super curious to know the results. Let me know if I could contribute in any way.",
                  "score": 1,
                  "created_utc": "2026-01-29 19:15:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qnun1t",
      "title": "Qwen model. We get it! Qwen-3-max-thinking",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qnun1t/qwen_model_we_get_it_qwen3maxthinking/",
      "author": "BasketFar667",
      "created_utc": "2026-01-26 22:06:43",
      "score": 26,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "We will get it this week (P.S. We got it) With enhanced features",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qnun1t/qwen_model_we_get_it_qwen3maxthinking/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o1wuvk2",
          "author": "trumpdesantis",
          "text": "Hasn‚Äôt this model been out since October",
          "score": 3,
          "created_utc": "2026-01-26 22:59:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1z9xcn",
              "author": "BasketFar667",
              "text": "They improved its functionality a little)",
              "score": 0,
              "created_utc": "2026-01-27 07:51:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1xx2aj",
          "author": "munishpersaud",
          "text": "do you mean OS?",
          "score": 1,
          "created_utc": "2026-01-27 02:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o278g9l",
          "author": "digit1024",
          "text": "For what type of task are you using this more expensive and slow models?",
          "score": 1,
          "created_utc": "2026-01-28 12:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2dtq0c",
          "author": "ballshuffington",
          "text": "Great work Qwen team.",
          "score": 1,
          "created_utc": "2026-01-29 09:44:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqoqlw",
      "title": "Developers, how are you using Qwen in your personal projects?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qqoqlw/developers_how_are_you_using_qwen_in_your/",
      "author": "TKB21",
      "created_utc": "2026-01-29 23:28:41",
      "score": 17,
      "num_comments": 27,
      "upvote_ratio": 0.96,
      "text": "I recently came across Qwen as I cut my teeth in ML. I've seen the capabilities of what it can do but was curious to see \"how\" developers are using it within their personal projects, codebases, and product offerings. Many thanks in advance for sharing!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqoqlw/developers_how_are_you_using_qwen_in_your/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2i9s0g",
          "author": "haradaken",
          "text": "I'm using it for an on-device AI companion app. It's amazing to see models like Qwen  actually run on your iPhone!",
          "score": 2,
          "created_utc": "2026-01-29 23:48:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i9yvc",
              "author": "TKB21",
              "text": "That‚Äôs awesome! I‚Äôm guessing you run it server side?",
              "score": 2,
              "created_utc": "2026-01-29 23:49:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ictsm",
                  "author": "haradaken",
                  "text": "I'm running Qwen models on device, on iPhone. Once the model data is downloaded, no internet connection is necessary, as far as the language model is concerned.",
                  "score": 1,
                  "created_utc": "2026-01-30 00:04:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2iwz8g",
          "author": "Puzzleheaded-Box2913",
          "text": "Using CLI to create boilerplate code for infrastructure prototyping. Qwen Code CLI + Jules",
          "score": 2,
          "created_utc": "2026-01-30 01:54:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jvn1y",
              "author": "Realistic_Pen_8614",
              "text": "Care to share some of your prompts?",
              "score": 1,
              "created_utc": "2026-01-30 05:22:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2k20zo",
                  "author": "Puzzleheaded-Box2913",
                  "text": "Generic Systems Infrastructure Development Template\n[SYSTEM_NAME] Unified Data Platform ‚Äì Technical Specification\nOverview\nA production-grade data and application platform designed to manage information workflows, automate routine operations, and deliver structured outputs for professional users. Built for reliability, extensibility, and offline-capable operation.\nCore Architecture\nLayered Service Architecture  \n\n    Persistence Layer: Local-first data storage with synchronization capability  \n    Business Logic Layer: Domain-specific rule processing and workflow orchestration  \n    Integration Layer: External system connectivity and API management  \n    Presentation Layer: Command-line and programmatic interfaces\n\nCore Engine Components  \n\n    [CORE_ENGINE]: Manages data persistence, workflow execution, error recovery, and configuration  \n    [EXTENSION_ENGINE]: Handles optional integrations, advanced analytics, and third-party connectivity\n\nStandard Infrastructure Modules (select/replace as needed)  \n\n    Data Store Manager ‚Äì Local SQLite/JSON storage with schema validation  \n    Task Scheduler ‚Äì Priority-based job queuing and execution  \n    Event Bus ‚Äì Publish/subscribe messaging between components  \n    Authentication Module ‚Äì Role-based access control and session management  \n    File Processor ‚Äì Batch and streaming file handling with format conversion  \n    Report Generator ‚Äì Structured output creation in multiple formats (CSV, JSON, plain text)  \n    Notification System ‚Äì Event-triggered alerts via multiple channels  \n    Metrics Collector ‚Äì Usage tracking and performance monitoring\n\nAdaptive Capabilities  \n\n    Context-aware workflow adjustments based on input patterns  \n    Automatic recovery from common error states  \n    Configurable behavior per user-defined profiles\n\nDomain Adaptability\nSupports multiple operational contexts (e.g., research, operations, analysis) through swappable configuration profiles and data schemas.\nSecurity & Reliability  \n\n    Input validation and sanitization  \n    Structured error logging  \n    Configurable access boundaries  \n    Data integrity checks on read/write operations\n\nExecution Directive Template\nROLE: You are a senior systems architect capable of designing and implementing production-grade software infrastructure.\nOBJECTIVE: Build a complete, self-contained [SYSTEM_NAME] platform targeting [LINE_COUNT]+ lines of production-ready code. This is not a prototype ‚Äî deliver a functional, tested implementation.\nINPUT SPECIFICATION:\nImplement a unified system incorporating:  \n\n    Layered architecture (persistence ‚Üí logic ‚Üí integration ‚Üí interface)  \n    Core engine with workflow orchestration  \n    Selected standard modules from the list above  \n    Error resilience and recovery mechanisms\n\nMANDATORY IMPLEMENTATION RULES:  \n\n    ZERO PLACEHOLDERS: No # TODO, pass, stubs, or incomplete logic. Every function must contain executable code.  \n    FULL DOCUMENTATION:  \n        Type hints on all parameters and returns  \n        Docstrings (Google style) for all public classes/methods  \n        Inline comments explaining non-obvious logic  \n        Embedded test cases in if __name__ == \"__main__\" blocks\n    DEFENSIVE PROGRAMMING:  \n        Validate all external inputs  \n        Catch and log recoverable errors  \n        Fail gracefully on unrecoverable conditions\n    MODULAR DELIVERY: Output one logical module/file per response. Maintain dependency order.\n\nDELIVERY PROTOCOL:\nWork in sequential PHASES due to output limits:  \n\n    PHASE 1: Project structure, dependencies (requirements.txt), configuration system  \n    PHASE 2: Core engine and persistence layer  \n    PHASE 3+: Additional modules per priority\n\nCONTINUITY RULE:\nTerminate output cleanly at phase boundaries or token limits. Await explicit \"PROCEED TO NEXT PHASE\" before continuing. Never summarize previous output.\nBEGIN: Start with PHASE 1 ‚Äî output only the directory tree and requirements.txt.\n\n\n\nUsage Instructions\n\n    Replace [SYSTEM_NAME] with your project identifier  \n    Set [LINE_COUNT] to your target (e.g., 10000)  \n    Select 3‚Äì5 modules from the \"Standard Infrastructure Modules\" list matching your scope  \n    Optionally adjust layers/architecture to fit your domain.",
                  "score": 3,
                  "created_utc": "2026-01-30 06:09:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2jkrjg",
          "author": "skibud2",
          "text": "Fully automated full C++ app building. Took a year to get here. Still work to do. qwen3-coder 30b, 4bit",
          "score": 2,
          "created_utc": "2026-01-30 04:10:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k2ajz",
          "author": "awesomeunboxer",
          "text": "I  had it scan 24k images and tag them for a weird project im working on. it took about 20 hours:3",
          "score": 2,
          "created_utc": "2026-01-30 06:11:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i81ef",
          "author": "ridablellama",
          "text": "keyword classification",
          "score": 1,
          "created_utc": "2026-01-29 23:38:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jeyt4",
          "author": "Remarkable_Speed1402",
          "text": "In Moltbot, I connected Qwen, and I'm still trying. I told it to send me the latest AI news every morning at 9 o'clock, but it failed. I don't know if it doesn't support this kind of play or if there's something wrong with my configurationüòÇ",
          "score": 1,
          "created_utc": "2026-01-30 03:35:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k3p3s",
              "author": "cool-beans-yeah",
              "text": "Where do you run Moltbot? I would like to do something similar...",
              "score": 1,
              "created_utc": "2026-01-30 06:22:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kkkp9",
                  "author": "Remarkable_Speed1402",
                  "text": "Alibaba Cloud, if you can read Chinese, they have a Chinese version of the deployment document.",
                  "score": 1,
                  "created_utc": "2026-01-30 08:47:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2pgp0s",
              "author": "somas",
              "text": "Your Qwen is local or cloud based? I‚Äôm struggling to get a local Qwen 235 B running well with Moltbot",
              "score": 1,
              "created_utc": "2026-01-31 00:36:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k3hzz",
          "author": "No_Astronaut873",
          "text": "This is a project I run locally on my Mac mini and can control it remotely with tailscale from my iPhone, its just a web app with different modules that i use daily instead of having or paying for 9 different apps. I found the abliterated qwen though working best for the diary log entries and the reverse diary thingy\n\nhttps://www.reddit.com/r/LocalLLaMA/s/gADOVetwTf",
          "score": 1,
          "created_utc": "2026-01-30 06:21:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k6zre",
          "author": "FrostyTomatillo8174",
          "text": "Local RAG system to search, and do little stuff like summarize, create document, searching document based on context, etc. Knowledge was stored locally also from semantic embadding. Its suprised me that the result is quite good and fast (using qwen3:30B in RTX 4060) even the file used for chunked still small (around 50 file). The development used agno library in python.",
          "score": 1,
          "created_utc": "2026-01-30 06:49:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k77l6",
          "author": "Alokir",
          "text": "I'm using a local Qwen Coder as a coding agent for light tasks. Not everything requires a huge and expensive cloud model.\n\nI'm using Qwen VL in a card game I'm making to come up with silly cards (with names, descriptions, actions, effects, etc.) depending on the user's previous actions. The game has no prebuilt cards, everything is generated by Qwen on the fly. It's a personal project for learning, nothing more, but it's a lot of fun.",
          "score": 1,
          "created_utc": "2026-01-30 06:51:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lfk5m",
          "author": "celsowm",
          "text": "For state attorneys to summarize lawsuites and to write drafts in our own local web app",
          "score": 1,
          "created_utc": "2026-01-30 12:57:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lggs6",
          "author": "Vegetable-Change-159",
          "text": "i personally use most qwen models for my project, from llm (qwen3 thinking 30b) to vlm (qwen3 vl thinking 30b) to coding (qwen3 coder), qwen image (generation and editing) along with some other ones for text encoding and decoding.  \n  \nin my experience, they may not be the smartest ones in their class (size) but the most reliable on doing their tasks.",
          "score": 1,
          "created_utc": "2026-01-30 13:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m1n6n",
          "author": "HelpfulSource7871",
          "text": "we install the newest qwen3-tts in our server, won't pay any other voice generator any more",
          "score": 1,
          "created_utc": "2026-01-30 14:54:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2u8p3d",
          "author": "a_menezes",
          "text": "Embedding text",
          "score": 1,
          "created_utc": "2026-01-31 19:20:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qohg5k",
      "title": "3 Billion tokensÔºÅEvaluate my token usage? (Am I the most loyal user of QWEN3-MAX?)",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qohg5k/3_billion_tokensevaluate_my_token_usage_am_i_the/",
      "author": "undersky1003",
      "created_utc": "2026-01-27 15:47:34",
      "score": 16,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "\n\nhttps://preview.redd.it/yfz1j7soxwfg1.png?width=1999&format=png&auto=webp&s=b32354be5d16473ea9a66ff38d0e270e538cf6c7\n\nI created a blockbuster agent, which led to a surge in my user base and a corresponding spike in QWEN3-MAX usage. Now, DAMO Academy has specially approved additional concurrency for me, and I‚Äôll get early access to Qwen3.5-MAX. I really love QWEN‚Äîit‚Äôs the best LLM in the world!\n\nNote: the drop in usage was due to the weekend; we are still consuming a steady 3‚Äì4 billion tokens per day, and we‚Äôre looking forward to our next breakout moment!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qohg5k/3_billion_tokensevaluate_my_token_usage_am_i_the/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2195q1",
          "author": "libee900",
          "text": "Wow, what are you using it for?",
          "score": 3,
          "created_utc": "2026-01-27 15:51:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o219dvs",
              "author": "undersky1003",
              "text": "An agent for image designers",
              "score": 3,
              "created_utc": "2026-01-27 15:52:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2742lu",
                  "author": "reditsagi",
                  "text": "Is it consistent as Google Nano Banana?",
                  "score": 1,
                  "created_utc": "2026-01-28 11:36:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o22eeek",
          "author": "Available-Craft-5795",
          "text": "Thats alot, but my local model token consumption is 4B :) (Of qwen series)",
          "score": 1,
          "created_utc": "2026-01-27 18:48:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22t6fq",
              "author": "undersky1003",
              "text": "greatÔºÅ",
              "score": 1,
              "created_utc": "2026-01-27 19:53:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24mpkm",
          "author": "Remarkable_Speed1402",
          "text": "Yesterday, I used the new model to optimize the website homepage Copywriting, and it was very good, but now I can't access this in my ide, I don't know how this model's coding ability is.",
          "score": 1,
          "created_utc": "2026-01-28 01:05:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fcgbv",
          "author": "PromptAfraid4598",
          "text": "Yeah, it's awesome‚Äîit offers tons of models and a huge amount of free credits.",
          "score": 1,
          "created_utc": "2026-01-29 15:31:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnyvik",
      "title": "Where in the Sam Hill are they getting these \"Memories\" from?!?! The only one here that has anything to do with me is the 3rd one. What is this about??",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/9tksblnnhsfg1.png",
      "author": "Earthling_Aprill",
      "created_utc": "2026-01-27 00:52:11",
      "score": 13,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qnyvik/where_in_the_sam_hill_are_they_getting_these/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qsbzz5",
      "title": "The Qwen Mac app keeps surprising me.",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qsbzz5/the_qwen_mac_app_keeps_surprising_me/",
      "author": "pakalolo7123432",
      "created_utc": "2026-01-31 19:38:39",
      "score": 12,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "This damn app and model keeps luring me back over and over. I find its responses to be very matter of fact and blunt. It frequently says \"I'm going to be honest here\" and proceeds to thoughtfully debate me.  I keep finding myself choosing Qwen first when I want to have general life chats, procedure building chats, Knowledge Graph suggestions, you name it.\n\nIt gives me a popup whenever it remembers something about me, or if it changes a previous memory. It also seems to know when to use memories at just the right time. \n\nThe MCP servers are wild, too. I have created projects in Qwen and have it dig through my KG and Obsidian Vault for project data. \n\nI really thought I would just be using Qwen as a toy for a few days and then move on to play with the next model, but the reverse happened. I'm kind of addicted to it. I know that I am freely volunteering my data to them but its really not that important to me for what I'm getting. \n\nIs anyone else surprised by Qwen's chatting abilities or have I just done drank the kool aid??? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qsbzz5/the_qwen_mac_app_keeps_surprising_me/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2upi3x",
          "author": "azvd_",
          "text": "yes!!! i‚Äôve been using qwen for so long now i don‚Äôt even know when did it start being my preference. i think that‚Äôs cool as hell, Qwen is such a great chatbot i‚Äôve stopped using paid alternatives i got promos on bc his free tier had more to offer lol. \nIt‚Äôs a shame that most companies are funnelling resources into coding when there‚Äôs so much more still unexplored on other AI features",
          "score": 4,
          "created_utc": "2026-01-31 20:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2uktgv",
          "author": "ReadGorilla",
          "text": "Qwen reminds me a lot of the earlier GPT-4 series‚Äîbut with a touch of Eastern elegance and philosophical depth. I was so drawn to her during our chats over the December holidays that I‚Äôm now considering connecting her to an OpenClaw bot via API.",
          "score": 3,
          "created_utc": "2026-01-31 20:19:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2v7b30",
              "author": "Unedited_Sloth_7011",
              "text": "Especially Qwen3-235B-A22B has exactly similar style like GPT-4o, but with significantly less flattery and slightly more goofiness (plus tone/style of reasoning similar to Deepseek-R1). Qwen3-Max is absolutely awesome model too.",
              "score": 2,
              "created_utc": "2026-01-31 22:09:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2vj7wo",
                  "author": "pakalolo7123432",
                  "text": "Nice. I will switch to that one for a couple of days and see how I like it. Thanks for the tip!",
                  "score": 1,
                  "created_utc": "2026-01-31 23:11:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xiem9",
          "author": "Realistic_Pen_8614",
          "text": "Qwen app is good. The only sad part for me is that I can‚Äôt have the app on my Linux laptop. It would have been wonderful.",
          "score": 1,
          "created_utc": "2026-02-01 06:46:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnlupq",
      "title": "I built MimikaStudio - a native macOS app for voice cloning using Qwen, Kokoro and XTTS2",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qnlupq/i_built_mimikastudio_a_native_macos_app_for_voice/",
      "author": "QuanstScientist",
      "created_utc": "2026-01-26 17:04:04",
      "score": 11,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "What is it?\n\n**MimikaStudio** is a local-first voice cloning and TTS desktop app. Clone any voice from just 3 seconds of audio, use premium preset speakers, or generate fast high-quality speech for narration and content creation.\n\nhttps://preview.redd.it/fkmq0nbb6qfg1.png?width=3218&format=png&auto=webp&s=ab708d8722fcaca54067eb8a9556a0a69c76a73d\n\nI ported my old Gradio app into a beautiful native Flutter desktop application, specifically for Apple Silicon users who want a polished UI with proper macOS integration.\n\n# Key Features\n\n* **3-Second Voice Cloning** Qwen3-TTS can capture a speaker's tone, rhythm, and accent from remarkably short samples\n* **9 Premium Preset Voices** No reference audio needed. English, Chinese, Japanese, Korean speakers with distinct personalities\n* **Fast British TTS** Kokoro delivers sub-200ms latency with crystal-clear British RP and American accents\n* **PDF Reader** Load any PDF and have it read aloud with sentence-by-sentence highlighting\n* **Emma IPA** British phonetic transcription powered by your choice of LLM (Claude, OpenAI, Ollama)\n* **Runs locally** No cloud APIs for TTS, everything on your machine\n\nhttps://preview.redd.it/i5e7o7ce6qfg1.png?width=3164&format=png&auto=webp&s=03aeb964b75237396d16c8b6b9d98c62f1b8db4a\n\n# Tech Stack\n\n* Flutter desktop UI (macOS)\n* FastAPI Python backend\n* Qwen3-TTS (0.6B/1.7B), Kokoro-82M, XTTS2\n* Apple Silicon optimized (MPS where supported)\n\n# GitHub\n\n[https://github.com/BoltzmannEntropy/MimikaStudio](https://github.com/BoltzmannEntropy/MimikaStudio)\n\nHappy to answer any questions!",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qnlupq/i_built_mimikastudio_a_native_macos_app_for_voice/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o1zyuuz",
          "author": "FlowCritikal",
          "text": "Any possibility of a ROCm AMD Version?",
          "score": 1,
          "created_utc": "2026-01-27 11:35:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20f6ui",
              "author": "QuanstScientist",
              "text": "I wouldn't even be able to test on this platform.",
              "score": 1,
              "created_utc": "2026-01-27 13:24:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o206kuq",
          "author": "planetearth80",
          "text": "Any chance you could add docker support?",
          "score": 1,
          "created_utc": "2026-01-27 12:31:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20exju",
              "author": "QuanstScientist",
              "text": "Yes, its on my list.",
              "score": 1,
              "created_utc": "2026-01-27 13:22:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24vyvj",
          "author": "timeshifter24",
          "text": "Will it work on CPU or only pricey GPU? Please offer also one-click easy install .bat or .exe files for the millions of poor people who are lost in the woods ;-) THX",
          "score": 1,
          "created_utc": "2026-01-28 01:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28r6dl",
              "author": "QuanstScientist",
              "text": "I understand your frustration, there are much easier command line options for that purpose.",
              "score": 1,
              "created_utc": "2026-01-28 16:46:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o29t10t",
                  "author": "timeshifter24",
                  "text": "Such as? Don't be shy. Lead the way! I'm all ears for decades! ;-)))",
                  "score": 1,
                  "created_utc": "2026-01-28 19:30:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qoiqif",
      "title": "Your opinion on the new Qwen vs other top models?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qoiqif/your_opinion_on_the_new_qwen_vs_other_top_models/",
      "author": "EmperorTaizongOfTang",
      "created_utc": "2026-01-27 16:33:02",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qoiqif/your_opinion_on_the_new_qwen_vs_other_top_models/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o237qhh",
          "author": "Thin_Yoghurt_6483",
          "text": "Nobody used it because they need a monthly plan.",
          "score": 2,
          "created_utc": "2026-01-27 20:59:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qo9nm1",
      "title": "Qwen3-TTS Review -- The Best Opensource TTS tool now Or No?",
      "subreddit": "Qwen_AI",
      "url": "https://www.youtube.com/watch?v=jR7AHMDXvEU",
      "author": "Agitated_Fortune7907",
      "created_utc": "2026-01-27 09:54:44",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qo9nm1/qwen3tts_review_the_best_opensource_tts_tool_now/",
      "domain": "youtube.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qrnvan",
      "title": "Chat feels responsive with Qwen2.5 7B 4bit running locally on iPhone!",
      "subreddit": "Qwen_AI",
      "url": "https://v.redd.it/ck73h7bj1lgg1",
      "author": "haradaken",
      "created_utc": "2026-01-31 00:56:55",
      "score": 9,
      "num_comments": 4,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qrnvan/chat_feels_responsive_with_qwen25_7b_4bit_running/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2pzp3q",
          "author": "Available-Craft-5795",
          "text": "Streaming text token by token would be better",
          "score": 3,
          "created_utc": "2026-01-31 02:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2q174i",
              "author": "haradaken",
              "text": "Thanks for your reply u/Available-Craft-5795 ! Though the video above does not include sound, the app actually generates TTS audio of language model output. The TTS part is on cloud, for now. Once the TTS is stream-based, streaming language model output is definitely something I want to explore!",
              "score": 2,
              "created_utc": "2026-01-31 02:36:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pkx0p",
          "author": "haradaken",
          "text": "My typing looks slow when compared to the model response... :D",
          "score": 2,
          "created_utc": "2026-01-31 01:00:14",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2wx11l",
          "author": "qwen_next_gguf_when",
          "text": "You can type even slower.",
          "score": 1,
          "created_utc": "2026-02-01 04:07:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqo6xs",
      "title": "Why no updates (or love) for Qwen3 32B dense?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qqo6xs/why_no_updates_or_love_for_qwen3_32b_dense/",
      "author": "ramendik",
      "created_utc": "2026-01-29 23:06:08",
      "score": 6,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "EDIT: RESOLVED. There is a recent update to the dense Qwen3 32B, it's Qwen3 32B VL, which exists as separate Instruct and Thinking versions and claims better performance as pure text too. Kudos u/[Due-Project-7507](https://www.reddit.com/user/Due-Project-7507/) \n\nSo I'm doing a distill of a different model (not Qwen) and needed LLM-based filtering for a mass generation result. I'm camping on a Vast A100 40Gb, so wanted something running there. Qwen3 30B A3B 2507 fit comfortably in AWQ4 vllm and minimally in 8bit llama.cpp but was Just Wrong at the task. Qwen3 80B A3B fits only in IQ3 llama.cpp, but, while better than the 30B, wasn't really great at this classification even on a cloud subscription.\n\nThen I found Qwen3 32B, which in AWQ4, on vllm, is doing a stellar job and is also blazing fast on the hardware.\n\nSo question: why is there not much discussion on this hidden gem of a model and why was there no 2507 power-up for it? Okay, for compute-limited applications (as in \"the edge\") the MoE speedup makes all the difference. But when one is memory-limited more than compute-limited, the \"extra smart\" of a 32B dense model without the massive memory requirements of 80/235B MoEs is quite formidable.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqo6xs/why_no_updates_or_love_for_qwen3_32b_dense/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o2otcr0",
          "author": "loadsamuny",
          "text": "I think 2507 was the long context extension and I‚Äôm guessing that‚Äôs prohibitively expensive to train compared to MoEs",
          "score": 2,
          "created_utc": "2026-01-30 22:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2vgus6",
          "author": "Due-Project-7507",
          "text": "The latest version was released as \"VL\", so it was updated some time ago. Qwen3-VL-32B version should be better than the original Qwen3-32B also just for text. But the 32B dense version is similar in speed than the 235B-A22B MoE version and not as good.",
          "score": 2,
          "created_utc": "2026-01-31 22:59:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vx6jf",
              "author": "ramendik",
              "text": "I am really enjoying Qwen3 32B dense, 4bit AWQ, on a 40Gb VRAM GPU - and it would even run on 24Gb VRAM. THAT is the difference from the 235 A22B.\n\nThank you very much for pointing me to the VL version as the update! I will now update this post, the question is resolved.",
              "score": 1,
              "created_utc": "2026-02-01 00:30:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2iowva",
          "author": "Available-Craft-5795",
          "text": "Speed, modernization, efficiency, ect...  \nDense models are good, but they are inefficient and MoE provides the same thing but better most of the time.",
          "score": 1,
          "created_utc": "2026-01-30 01:09:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j508h",
              "author": "ramendik",
              "text": "Except when memory-limited, the dense will do more. Om taht 40G machine, the best Qwen MoE I could theoretically run is 80B A3B, and it's exceedingly slow in llama.cpp IQ3, \\*and\\* not as capable too (the standard estimate formula makes it similar to a 15B dense model).\n\nOkay there are not that many A100 40Gbs, but the 5090 is common and its math is abundant. While the 32B even in 4bit might be too slow on the 3090/4090, 5050 should be a breeze.",
              "score": 1,
              "created_utc": "2026-01-30 02:39:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2irr8t",
          "author": "ClimateBoss",
          "text": "how is it compared to Qwen3 coder 30b a3b  ?",
          "score": 1,
          "created_utc": "2026-01-30 01:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j3ltl",
              "author": "ramendik",
              "text": "I am not coding, I am classifying text. so I didn't try Qwen3 Coder.",
              "score": 1,
              "created_utc": "2026-01-30 02:31:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k905w",
          "author": "No-Consequence-1779",
          "text": "All I use is qwen. They are great. ¬†Interesting dense and moe take the same vram and are almost the same size. I may be stupid.¬†",
          "score": 1,
          "created_utc": "2026-01-30 07:05:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnq2mi",
      "title": "Managed to run Qwen3-TTS on Mac (M4 Air) but it‚Äôs melting my laptop. Any proper way to do this?",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qnq2mi/managed_to_run_qwen3tts_on_mac_m4_air_but_its/",
      "author": "Otherwise-Thanks-985",
      "created_utc": "2026-01-26 19:25:35",
      "score": 5,
      "num_comments": 8,
      "upvote_ratio": 0.86,
      "text": "I‚Äôm on an M4 Air. I saw people saying it \"could work\" but couldn't find a single tutorial. I eventually had to manually patch multiple files in the ComfyUI custom node to bypass errors.\n\nIt finally loads without crashing, but it takes forever and absolutely burns my PC.\n\nIs there an optimized way to run this or a setting I'm missing?\n\nI used github/flybirdxx/ComfyUI-Qwen-TTS/ custom node.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qnq2mi/managed_to_run_qwen3tts_on_mac_m4_air_but_its/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o269ds3",
          "author": "tazztone",
          "text": "ye your MacBook air has no fans.",
          "score": 2,
          "created_utc": "2026-01-28 07:05:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26mu7m",
              "author": "Otherwise-Thanks-985",
              "text": "I know, and I got the fix and it‚Äôs working fantastic even without fans. Btw, I‚Äôm using a bigger model.",
              "score": 1,
              "created_utc": "2026-01-28 09:05:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1z2rtc",
          "author": "QuanstScientist",
          "text": "I have m1 pro, it works fine, heavy yes, but not melting. Try my setup: [https://github.com/BoltzmannEntropy/MimikaStudio](https://github.com/BoltzmannEntropy/MimikaStudio)",
          "score": 1,
          "created_utc": "2026-01-27 06:50:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26nfjx",
              "author": "Otherwise-Thanks-985",
              "text": "Thanks, but I found a more optimal way. It‚Äôs not UI-based, but it works on the terminal. It‚Äôs really efficient in terms of RAM and CPU usage. Here‚Äôs what I used: [qwen3-tts-mac](https://github.com/kapi2800/qwen3-tts-mac)",
              "score": 1,
              "created_utc": "2026-01-28 09:10:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1z82rp",
          "author": "ComputerSiens",
          "text": "Working fine on an m2-max using vanilla Python and the official qwen-tts pip package",
          "score": 1,
          "created_utc": "2026-01-27 07:35:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ax7ov",
          "author": "ResponsiblePoetry601",
          "text": "M4 24GB runs smoothly voice clone for more than 30 min",
          "score": 1,
          "created_utc": "2026-01-28 22:28:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jtgvm",
              "author": "Otherwise-Thanks-985",
              "text": "Try this one‚Ä¶ much more efficient and optimized. [qwen3-tts-apple-silicon](https://github.com/kapi2800/qwen3-tts-apple-silicon)",
              "score": 1,
              "created_utc": "2026-01-30 05:06:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2kwxn9",
                  "author": "ResponsiblePoetry601",
                  "text": "Great! Will do! Thks",
                  "score": 1,
                  "created_utc": "2026-01-30 10:39:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qmeg2f",
      "title": "Qwen application on Linux",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qmeg2f/qwen_application_on_linux/",
      "author": "Realistic_Pen_8614",
      "created_utc": "2026-01-25 09:15:19",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "There are apps for iOS, Android, Windows and Mac. Has anyone tried or found a way of running the desktop app on Linux?\n\nI would like some guidance if you have been successful. ",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qmeg2f/qwen_application_on_linux/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": [
        {
          "id": "o1qtl1i",
          "author": "merguel",
          "text": "I'm a Linux user, and the Brave browser has a way to transform some web pages into apps. I did it with Qwen, DeepSeek, and X. They turned out well.",
          "score": 4,
          "created_utc": "2026-01-26 02:28:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1vcr6j",
              "author": "Patient_Win_1167",
              "text": "brave is goated",
              "score": 1,
              "created_utc": "2026-01-26 18:57:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1yh0d5",
              "author": "Future_List_5833",
              "text": "How did you do it, bro?",
              "score": 1,
              "created_utc": "2026-01-27 04:13:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o215uxp",
              "author": "Realistic_Pen_8614",
              "text": "Yes, I tried this but it does not have the mcp feature.",
              "score": 1,
              "created_utc": "2026-01-27 15:36:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1lcujx",
          "author": "azvd_",
          "text": "idk anything about linux but the windows app itself is pretty ass.. if i remember correctly, it is (or almost is?) a webapp",
          "score": 2,
          "created_utc": "2026-01-25 09:49:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qo13qr",
      "title": "Help",
      "subreddit": "Qwen_AI",
      "url": "https://i.redd.it/exqr71y2zsfg1.jpeg",
      "author": "week_rain21",
      "created_utc": "2026-01-27 02:27:42",
      "score": 4,
      "num_comments": 2,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qo13qr/help/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1zh1nn",
          "author": "Keldianaut",
          "text": "Same. It has been appearing constantly for 2-3 days or more now, probably , even when I directly write that this is not code and an interpreter is not needed.",
          "score": 2,
          "created_utc": "2026-01-27 08:57:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2067ya",
              "author": "week_rain21",
              "text": "To my recent step, and what I write is not even code, I hope it is just a temporary error",
              "score": 1,
              "created_utc": "2026-01-27 12:29:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qp4azt",
      "title": "I wrote an article about wan2.6 vs seedance 1.5 wrt tiktok style short video",
      "subreddit": "Qwen_AI",
      "url": "https://medium.com/budgetpixel-ai/seedance-1-5-d704ab57460e",
      "author": "Alarmed-Flounder-383",
      "created_utc": "2026-01-28 07:00:45",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Wan",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qp4azt/i_wrote_an_article_about_wan26_vs_seedance_15_wrt/",
      "domain": "medium.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qqp9q2",
      "title": "Help. I am using Qwen 3 TTS 1.7B and whenever I generate audio with the text I give in voice clone section, the result comes as 2-3 min audio with AI speaking ultra fast.",
      "subreddit": "Qwen_AI",
      "url": "https://www.reddit.com/r/Qwen_AI/comments/1qqp9q2/help_i_am_using_qwen_3_tts_17b_and_whenever_i/",
      "author": "Obvious_Ad8471",
      "created_utc": "2026-01-29 23:50:44",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "It starts normal for few seconds and it paces up my 100 words text and try to fit under 2 mins",
      "is_original_content": false,
      "link_flair_text": "Help üôã‚Äç‚ôÇÔ∏è",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqp9q2/help_i_am_using_qwen_3_tts_17b_and_whenever_i/",
      "domain": "self.Qwen_AI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qqhr5s",
      "title": "I vibe coded a local audio inference engine for Qwen3-TTS and Qwen3-ASR",
      "subreddit": "Qwen_AI",
      "url": "https://github.com/agentem-ai/izwi-audio",
      "author": "zinyando",
      "created_utc": "2026-01-29 19:05:11",
      "score": 2,
      "num_comments": 3,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/Qwen_AI/comments/1qqhr5s/i_vibe_coded_a_local_audio_inference_engine_for/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2iqa19",
          "author": "haradaken",
          "text": "Great work! Thanks for sharing. I‚Äôm trying to get Qwen3‚ÄìTTS work on iPhones, and your success gives me inspiration.  :)",
          "score": 1,
          "created_utc": "2026-01-30 01:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mdgha",
              "author": "zinyando",
              "text": "How far have you gone with your project? Sounds amazing",
              "score": 2,
              "created_utc": "2026-01-30 15:48:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2pb11j",
                  "author": "haradaken",
                  "text": "Thanks, u/zinyando ! My iPhone app below can run a language model on device. Qwen3-TTS sounds like a great technology in pursuing the privacy-first vision of my app.\n\n[https://apps.apple.com/jp/app/aicrest/id6752296250?l=en-US](https://apps.apple.com/jp/app/aicrest/id6752296250?l=en-US)",
                  "score": 1,
                  "created_utc": "2026-01-31 00:05:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}