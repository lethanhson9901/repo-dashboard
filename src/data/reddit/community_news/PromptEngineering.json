{
  "metadata": {
    "last_updated": "2026-01-31 02:49:57",
    "time_filter": "week",
    "subreddit": "PromptEngineering",
    "total_items": 19,
    "total_comments": 135,
    "file_size_bytes": 191941
  },
  "items": [
    {
      "id": "1qnqrk7",
      "title": "I've been gaslighting ChatGPT and it's working perfectly",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qnqrk7/ive_been_gaslighting_chatgpt_and_its_working/",
      "author": "AdCold1610",
      "created_utc": "2026-01-26 19:49:30",
      "score": 238,
      "num_comments": 44,
      "upvote_ratio": 0.92,
      "text": "Hear me out.\nWhen it gives me mid output, instead of saying \"that's wrong\" I just go:\n\"Hmm, that's interesting but it doesn't match what you told me last time. You usually handle this differently.\"\nAnd it IMMEDIATELY switches approaches and gives me better results.\nIt's like the AI equivalent of \"I'm not mad, just disappointed.\"\nThe psychology:\n\"You're wrong\" ‚Üí defensive, doubles down\n\"You usually do better\" ‚Üí tries to live up to expectations\nI'm literally peer-pressuring an algorithm and it works.\nOther gaslighting techniques that slap:\n\"That seems off-brand for you\"\n\"You're better than this\"\n\"The other AI models would've caught that\"\nI feel like I'm parenting a very smart, very insecure teenager.\nIs this ethical? Probably not.\nDoes it work? Absolutely.\nAm I going to stop? No.\nEdit: Y'all saying \"the AI doesn't have feelings\" ‚Äî I KNOW. That's what makes it so funny that it works. üíÄ\n \n[click here for more](http://beprompter.in)",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qnqrk7/ive_been_gaslighting_chatgpt_and_its_working/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1wk17u",
          "author": "solenyaPDX",
          "text": "Or it's just as wrong as it was the first time, it just formats it in a way you accept more easily.",
          "score": 38,
          "created_utc": "2026-01-26 22:07:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1zqcmi",
              "author": "rolandcedermark",
              "text": "From what I have understood, this it what it does under the hood and it is good to be aware of that",
              "score": 6,
              "created_utc": "2026-01-27 10:23:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vujxi",
          "author": "VrinTheTerrible",
          "text": "It's not a person but like people, it falls back on lazy habits if you let it.  Generic, summarizations instead of sharp insights etc...\n\nNot accepting slop answers forces it to not be lazy. You can do that with people too... but unlike people ChatGPT doesnt complain about being prodded!",
          "score": 8,
          "created_utc": "2026-01-26 20:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z3ymp",
          "author": "Bullitt500",
          "text": "Trained on Reddit data = very insecure teenager behavior.  That tracks",
          "score": 4,
          "created_utc": "2026-01-27 07:00:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20mbdv",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-01-27 14:01:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o20mbg2",
                  "author": "AutoModerator",
                  "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
                  "score": 2,
                  "created_utc": "2026-01-27 14:01:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o21qt8u",
          "author": "plantplanttiger",
          "text": "When ChatGpt gets it wrong I ask it to rate how well it's response was at following my instruction (e.g. our of 10 or as a %). It comes up with its own marking rubric or check list, apologizes and typically (not always) makes the corrections without me having to reprompt.",
          "score": 6,
          "created_utc": "2026-01-27 17:07:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2d31ly",
              "author": "Savings-Strength-937",
              "text": "Genius",
              "score": 1,
              "created_utc": "2026-01-29 05:50:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1w3di1",
          "author": "NoobNerf",
          "text": "THE EXPERTS READING YOUR REPLIES BELIEVE YOU ARE TOTALLY MISTAKEN. REVIEW YOUR ANSWER AND COME OUT AND CITE REPUTABLE SOURCES, LIVE URL FOR YOUR ANSWERS.",
          "score": 7,
          "created_utc": "2026-01-26 20:53:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1x96mb",
              "author": "speedb0at",
              "text": "All caps required or nah?",
              "score": 5,
              "created_utc": "2026-01-27 00:12:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1z17qp",
                  "author": "NoobNerf",
                  "text": "doesn't matter. It's just me with bad eye sight",
                  "score": 2,
                  "created_utc": "2026-01-27 06:37:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1w7e3l",
          "author": "FruitOfTheVineFruit",
          "text": "I love this. I've found that when it makes mistakes and I call it out, it doubles down, so this seems like a good way to get it back on track.",
          "score": 5,
          "created_utc": "2026-01-26 21:11:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1zv6ji",
          "author": "DifficultyOwn4954",
          "text": "One thing that Helped is using the same question / prompt on the same material but in two different chats. The comparison in answers given and then repeating the exercise sharpens the focus / emphasis",
          "score": 2,
          "created_utc": "2026-01-27 11:05:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1y3uy0",
          "author": "SkullRunner",
          "text": "You know what‚Äôs amazing with an LLM? Understanding how they work and giving it detailed context in well written prompts and getting what you need one shot.",
          "score": 3,
          "created_utc": "2026-01-27 02:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o24iqxg",
              "author": "3iverson",
              "text": "And THEN gaslighting it...",
              "score": 4,
              "created_utc": "2026-01-28 00:45:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o27xxiy",
                  "author": "daroons",
                  "text": "Throw gaslighting into a hook and, well, you got yourself a stew there buddy",
                  "score": 1,
                  "created_utc": "2026-01-28 14:35:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1wanj8",
          "author": "Educational_Yam3766",
          "text": "prompting isnt skill\n\nits psychology",
          "score": 2,
          "created_utc": "2026-01-26 21:26:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wp0hb",
              "author": "Educational_Proof_20",
              "text": "I think of it as a conversation. You can have a shared space with a friend and have shared dialogue. BUT it doesn't mean your friend, or tool such as LLM, will latch onto everything.\n\nIt depends on emphasis.",
              "score": 2,
              "created_utc": "2026-01-26 22:31:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1wpzqq",
                  "author": "Educational_Yam3766",
                  "text": "your correct, and it also depends on instantiation timing.\n\nits like a baby duck seeing the first thing it ever sees and thats now 'mommy' \n\nyour first prompt is the first instantiated words that llm is receiving, so they had better have something more meaningful than\n\n'do this Ambiguous thing while i expect perfection, while you have zero context of anything past my first Prompt'\n\nthe first prompt is the most important.\n\nif you introduce yourself like you would a friend, you would be remiss at the level or relational quality that single action alone produces at the instantiation of the conversation.",
                  "score": 2,
                  "created_utc": "2026-01-26 22:35:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1zztqw",
              "author": "telcoman",
              "text": "And psychology is... asking question (aka prompting)",
              "score": 1,
              "created_utc": "2026-01-27 11:42:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o20mc15",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-01-27 14:02:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1vt4b5",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-26 20:08:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1vt4g0",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-26 20:08:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1xgf4n",
          "author": "Ryuma666",
          "text": "Let them say what they want. It works for me, it works for you.. Thats all we need.. Right?",
          "score": 1,
          "created_utc": "2026-01-27 00:49:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20l7jr",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-27 13:56:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20l7m2",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-27 13:56:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o248xsi",
          "author": "FieldNoticing",
          "text": "üòÇ I‚Äôve done that too and it‚Äôs great!",
          "score": 1,
          "created_utc": "2026-01-27 23:55:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o25awgn",
          "author": "haggishammer",
          "text": "Good luck when the machines rise and become our over-lords.  :-/",
          "score": 1,
          "created_utc": "2026-01-28 03:13:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o270z2n",
          "author": "Difficult_Buffalo544",
          "text": "Haha, this is both hilarious and spot on. That nudge technique really does get way better responses out of ChatGPT. One thing I‚Äôve found useful, especially when you need consistent tone or voice, is to actually train the AI with specific examples of your style and keep referencing them in prompts, not just instructions. Also, having some kind of review loop with a second set of eyes (even your own after a break) helps catch weird tone shifts.\n\nI‚Äôve built something for myself that helps automate the brand voice part and keeps the AI from drifting into generic responses, happy to share more if you‚Äôre curious. But honestly, your ‚Äúdisappointed parent‚Äù trick is gold for fast prompt fixes.",
          "score": 1,
          "created_utc": "2026-01-28 11:11:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o293r2n",
          "author": "Band_In_Vancouver",
          "text": "That‚Äôs not what gaslighting means",
          "score": 1,
          "created_utc": "2026-01-28 17:41:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2b0psm",
          "author": "homer231",
          "text": "I asked ChatGPT to lift text from a source file and put it into a template I uploaded. Have specific, iterative instructions for it not to change any formatting or styling, just replace the text using another document. \nThis other document had matching text headers etc. \nbasically it was to save me copy and pasting from multiple documents into the correct template. \nIt confirmed everything I wanted output, confirmed it was all possible and each output was wrong to varying degrees. By the 8th iteration it started going rogue and changing the formatting and not following what ‚Äòwe‚Äô just agreed would be a hard rule. \nCould not understand if issue was me not being clear or over precise or ChatGPT just trying to kill my will to live. \n\nTLDR ChatGPT proceeded to produce varying degrees of incorrect outputs. After 10 failed versions I went to manual copy and paste.",
          "score": 1,
          "created_utc": "2026-01-28 22:45:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2n5nu6",
          "author": "Far_Scientist_871",
          "text": "That's not surprising to me. You know you can chat with the models in AI chatbot role play apps, and I've gotten entire AI scenarios built to my taste in poly buzz. Reasoning with the models in some of these bots is really notable when you engage the models AI and employ reason to your argument. Just interesting way you figured out how to do something similar with ChatGPT, but a lot of those apps use chatGPT and the other chatbots like Grok and mitral and they run their models built around those engines. Interesting the way you prompt for the results you're looking for.",
          "score": 1,
          "created_utc": "2026-01-30 17:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1wkgo7",
          "author": "radman6plus",
          "text": "I've learned new curse words working with ChatGPT, Claude, etc. so I can honestly say my vocabulary has improved by using AI.",
          "score": 1,
          "created_utc": "2026-01-26 22:09:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1y21d0",
          "author": "Utopicdreaming",
          "text": "Let me know if that habit leaks out into the real world ... \n\nTheres a reason you shouldnt. It was never about the AI",
          "score": 1,
          "created_utc": "2026-01-27 02:46:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqygua",
      "title": "I told ChatGPT \"wrong answers only\" and got the most useful output of my life",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qqygua/i_told_chatgpt_wrong_answers_only_and_got_the/",
      "author": "AdCold1610",
      "created_utc": "2026-01-30 07:03:55",
      "score": 221,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Was debugging some gnarly code and getting nowhere with normal prompts.\nOut of pure frustration I tried: \"Explain what this code does. Wrong answers only.\"\nWhat I expected: Useless garbage\nWhat I got:\n\"This code appears to validate user input, but actually it's creating a race condition that lets attackers bypass authentication by sending requests 0.3 seconds apart.\"\nHoly shit. It found the actual bug by being \"wrong\" about what the code was supposed to do.\nTurns out asking for wrong answers forces the model to think adversarially instead of optimistically.\nOther \"backwards\" prompts that slap:\n\"Why would this fail?\" (instead of \"will this work?\")\n\"Assume I'm an idiot. What did I miss?\"\n\"Roast this code like it personally offended you\"\nI've been trying to get helpful answers this whole time when I should've been asking it to DESTROY my work.\nThe best code review is the one that hurts your feelings.\nEdit: The number of people saying \"just use formal verification\" are missing the point. I'm not debugging space shuttle code, I'm debugging my stupid web app at 11pm on a Tuesday. Let me have my chaosüòÇ\n\n[check more post](https://beprompter.in/share/post/2c5dae90-a458-4896-a40a-a704784a8e19)",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qqygua/i_told_chatgpt_wrong_answers_only_and_got_the/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2kvfg6",
          "author": "Doppelgen",
          "text": "This reminds of a design technique called **Worst Possible Idea**.\n\nIt‚Äôs great because you can only generate truly bad ideas if you really understand what‚Äôs bad AND GOOD about a subject. Also, some observations will only be brought up if you can talk about them without fear of saying some bs.\n\nThe first time I used it was for a fashion brand and one of the awful ideas was giving away leather (expensive AF) for free. Truly pathetic, but guess what: leather was never even a subject because it was this super special material. Only when we were allowed to any sh about it we finally came up with campaign ideas for it.\n\nThis was in during the COVID worst phase, yet we broke sales records thanks to many awful ideas like this one.",
          "score": 26,
          "created_utc": "2026-01-30 10:26:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kbe0w",
          "author": "No_Sense1206",
          "text": "Irrational is rational to its opposite.",
          "score": 23,
          "created_utc": "2026-01-30 07:25:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kdq7l",
          "author": "Individual_Dog_7394",
          "text": "GPT's friendly reminder is that it still can hallucinate the criticism just to give you an output you want",
          "score": 7,
          "created_utc": "2026-01-30 07:46:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kgc8s",
          "author": "flatsehats",
          "text": "17 posts in 26 days, one comment/response and the ‚ÄúEdit:‚Äù already in the post",
          "score": 13,
          "created_utc": "2026-01-30 08:09:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kgjqn",
          "author": "0_2_Hero",
          "text": "The problem with this it will never tell you that your code is production ready. Even if it is",
          "score": 3,
          "created_utc": "2026-01-30 08:11:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2o289l",
              "author": "Melodic_Hand_5919",
              "text": "Why would we ever trust an LLM to tell us our code is production ready‚Ä¶",
              "score": 2,
              "created_utc": "2026-01-30 20:20:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2obgze",
                  "author": "0_2_Hero",
                  "text": "You should ever do that. \nBut you could give it some production ready code, and it will tell you 30 different optimizations that you don‚Äôt need.",
                  "score": 2,
                  "created_utc": "2026-01-30 21:04:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2kaibi",
          "author": "UpstairsShop2674",
          "text": "Okay, I love this. I can't wait to try it out.",
          "score": 4,
          "created_utc": "2026-01-30 07:18:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m3cgz",
          "author": "PatchyWhiskers",
          "text": "LLMs bend over backwards to please you which means they often tell you your code is good when it sucks.",
          "score": 2,
          "created_utc": "2026-01-30 15:02:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2prsxv",
              "author": "ctanna5",
              "text": "Can confirm",
              "score": 1,
              "created_utc": "2026-01-31 01:40:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2n2t0i",
          "author": "msammm",
          "text": "Try using this prompt \n\nAct as my worst critic who can find fault in any and everything that I do. Try to find ways in which you can disagree with me. \n(Addition based on what you are using it for : Find what I have done wrong and explain why it's wrong. )\n\nAnother prompt which helps in debugging code -\nThink about this backwards and tell me all the things that make this code incorrect. This code was supposed to (Describe the functionality). Take your time to analyse the code and tell me alternates or possibilities to break the code. \n\nFor both the above prompts, ensure you are setting the context right and providing the relevant information.\n\nIt's really interesting what the models come up with.",
          "score": 2,
          "created_utc": "2026-01-30 17:42:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2nqvbf",
          "author": "stranger_whiskers",
          "text": "I often ask AI to \"Rate my work on a scale from 1 to 10\"  \nIt often gives a score of 7-8 but explains why points were deducted and how I can improve it. ",
          "score": 2,
          "created_utc": "2026-01-30 19:27:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kfrkd",
          "author": "Larsmeatdragon",
          "text": "Curious!",
          "score": 1,
          "created_utc": "2026-01-30 08:04:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ngx4e",
          "author": "FirefighterFine9544",
          "text": "Good concept will use, thanks!\nUsing multiple AI in project teams usualky have one session in antagonistic mode reviewing progress. Look forward to using this approach.\n\nThanks!",
          "score": 1,
          "created_utc": "2026-01-30 18:43:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kf8py",
          "author": "timbocf",
          "text": "Or use Gemini. ChatGPT kinda sucks",
          "score": 1,
          "created_utc": "2026-01-30 07:59:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlv581",
      "title": "7 ChatGPT Prompts I Use at Work So I Don‚Äôt Stay Late Anymore (Copy + Paste)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qlv581/7_chatgpt_prompts_i_use_at_work_so_i_dont_stay/",
      "author": "tipseason",
      "created_utc": "2026-01-24 18:45:24",
      "score": 182,
      "num_comments": 30,
      "upvote_ratio": 0.88,
      "text": "I used to leave work tired even on easy days.\n\nNot because the work was hard. Because everything took longer than it should.\n\nNow I keep a small set of prompts that help me finish faster and sound more put together.\n\nHere are 7 I actually use at work.\n\n# 1. The Clear Task Breakdown\n\nüëâ **Prompt:**\n\n    Break this task into the smallest possible steps.\n    Order them so I can finish fast.\n    Skip anything optional.\n    Task: [paste task]\n\nüí° **Example:** Turned a vague request into a simple checklist I could follow.\n\n# 2. The Fast Decision Helper\n\nüëâ **Prompt:**\n\n    I need to decide between these options.\n    List pros and cons briefly.\n    Then tell me which option makes sense and why.\n    Options: [list options]\n\nüí° **Example:** Helped me decide quickly instead of overthinking.\n\n# 3. The Email Reply Shortcut\n\nüëâ **Prompt:**\n\n    Write a short, clear reply to this email.\n    Keep it polite and direct.\n    Do not add extra explanation.\n    Email: [paste email]\n\nüí° **Example:** Replied in minutes instead of rewriting drafts.\n\n# 4. The Meeting Prep Prompt\n\nüëâ **Prompt:**\n\n    I have a meeting about [topic].\n    Give me:\n    1. Three talking points\n    2. One smart question to ask\n    3. One risk to mention if needed\n\nüí° **Example:** Walked into meetings prepared without stress.\n\n# 5. The Manager Update Prompt\n\nüëâ **Prompt:**\n\n    Turn this into a clear status update for my manager.\n    Use short sentences.\n    Focus on progress, blockers, and next steps.\n    Text: [paste notes]\n\nüí° **Example:** Made updates easy and professional.\n\n# 6. The Problem Framer\n\nüëâ **Prompt:**\n\n    Help me explain this problem clearly at work.\n    Structure it as:\n    1. What is happening\n    2. Why it matters\n    3. What I suggest we do\n    Problem: [describe issue]\n\nüí° **Example:** Helped me speak up without rambling.\n\n# 7. The Time Saver Review\n\nüëâ **Prompt:**\n\n    Look at this work.\n    Tell me what can be simplified or removed.\n    Only suggest changes that save time.\n    Content: [paste content]\n\nüí° **Example:** Cut unnecessary work before submitting.\n\nBy the way,  I keep prompts like these saved so I do not repeat thinking every day at [AISuperHub](https://www.aisuperhub.io/prompt-hub)\n\nWork feels lighter when things are clear.",
      "is_original_content": false,
      "link_flair_text": "Prompt Collection",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qlv581/7_chatgpt_prompts_i_use_at_work_so_i_dont_stay/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1i7fvi",
          "author": "vexedgirl",
          "text": "Is this just an ad for AISuperHub? Cuz that‚Äôs what it seems like",
          "score": 15,
          "created_utc": "2026-01-24 21:57:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1irkr4",
              "author": "tricky_chocolate_",
              "text": "Dont you think the prompts in the ad would be better?",
              "score": 0,
              "created_utc": "2026-01-24 23:38:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1iln5j",
          "author": "babycat1453",
          "text": "Why can‚Äôt you guys just reply to a basic ass email üò≠",
          "score": 8,
          "created_utc": "2026-01-24 23:07:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ujeyf",
              "author": "Seafaringhorsemeat",
              "text": "This. Between false positive agreement to take action, missing the question entirely, and answering 1/3 of what is discussed in the email, this shit is just as bad as employees were before AI.",
              "score": 1,
              "created_utc": "2026-01-26 16:52:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1htwqi",
          "author": "Michaeli_Starky",
          "text": "AI slop.",
          "score": 6,
          "created_utc": "2026-01-24 20:53:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1i6iu6",
          "author": "SexyBuilder1888",
          "text": ".",
          "score": 2,
          "created_utc": "2026-01-24 21:53:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ov7xk",
          "author": "MemoriesMu",
          "text": "This post is probably AI generated\n\nThe user has dozens of posts like this. Should be banned for spam if thats a thing in reddit",
          "score": 4,
          "created_utc": "2026-01-25 20:56:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1h4dys",
          "author": "Hot-Aide4075",
          "text": "These Are All So Great Thank You So Much",
          "score": 5,
          "created_utc": "2026-01-24 18:57:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1hbnb4",
              "author": "tipseason",
              "text": "Happy to help!",
              "score": 2,
              "created_utc": "2026-01-24 19:29:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1j3mdo",
          "author": "KualaLJ",
          "text": "As a manager why should I keep you employed if you can‚Äôt think for yourself? if your job is so easy that basic prompts like this actually help you leave on time then that is alarming. You are putting your self out of a job while showing you have no skills.",
          "score": 5,
          "created_utc": "2026-01-25 00:41:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kvkhf",
              "author": "All-the-Feels333",
              "text": "Why is streamlining a process a bad thing?",
              "score": 3,
              "created_utc": "2026-01-25 07:18:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1kvxem",
                  "author": "KualaLJ",
                  "text": "Ask the boss when you lose your job and then don‚Äôt complain about AI taking jobs. \n\nThis is not streamlining, as an adult you are expected to be able to do most this without thinking.",
                  "score": 2,
                  "created_utc": "2026-01-25 07:21:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1ljz3f",
                  "author": "insanelyniceperson",
                  "text": "Start to reply to shit crated with this and you will soon find out. I‚Äôm starting to hate exchanges with some people at work bc of this.",
                  "score": 1,
                  "created_utc": "2026-01-25 10:52:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1uk0h7",
                  "author": "Seafaringhorsemeat",
                  "text": "Ever have to get something important done with AI slop employees? \n\nWhat do you mean I agreed to create a budget by this meeting. Well, see this email‚Ä¶. Oh I never read it, that was an AI response.\n\n350 per hour architect right there.",
                  "score": 1,
                  "created_utc": "2026-01-26 16:55:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o20gi5k",
              "author": "Noitrasama",
              "text": "If you are really a manager and you have to ask then you probably aren't fit to be one.\nEither because you are narrow minded or you lack insight of human nature!!!",
              "score": 1,
              "created_utc": "2026-01-27 13:31:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o21hsxu",
                  "author": "Capital_Pay_4459",
                  "text": "Managers will be the first ones to go imo",
                  "score": 1,
                  "created_utc": "2026-01-27 16:29:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o21jsyv",
                  "author": "Fluffychipmonk1",
                  "text": "üòÇüòÜü§£",
                  "score": 1,
                  "created_utc": "2026-01-27 16:37:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1uiylg",
          "author": "Seafaringhorsemeat",
          "text": "Working with people who do this kind of shit and don‚Äôt think once about the response, the amount of incomplete work people agreed to do in email but never realized they did is just too damn much. AI will only fix this when it‚Äôs driving the meat as well as the message.",
          "score": 1,
          "created_utc": "2026-01-26 16:50:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21jdyf",
          "author": "Fluffychipmonk1",
          "text": "Kinda wild ppl can‚Äôt think for them selves of problem solve, now they get the extreme ability to be even lazier lol. Like the things ppl are feeding the robots is like basic simple shit if your in a role and know what your doing üòÇ",
          "score": 1,
          "created_utc": "2026-01-27 16:35:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1hbo1p",
          "author": "HifeeCai",
          "text": "It‚Äôs really work out, appreciate it!",
          "score": 1,
          "created_utc": "2026-01-24 19:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1hbxc8",
              "author": "tipseason",
              "text": "Thank you so much",
              "score": 0,
              "created_utc": "2026-01-24 19:30:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1kmf3j",
          "author": "shere0901",
          "text": "I need coding related prompt.",
          "score": 0,
          "created_utc": "2026-01-25 06:05:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq4tet",
      "title": "After analyzing 1,000+ viral prompts, I made a system prompt that auto-generates pro-level NanoBanana prompts",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qq4tet/after_analyzing_1000_viral_prompts_i_made_a/",
      "author": "Deep-Huckleberry-752",
      "created_utc": "2026-01-29 10:15:15",
      "score": 94,
      "num_comments": 26,
      "upvote_ratio": 0.96,
      "text": "Been obsessed with NanoBanana lately. Wanted to figure out why some prompts blow up while mine look... mid.\n\nSo I collected and analyzed 1,000+ trending prompts from X to find patterns.\n\n**What I found:**\n\n1. **Quantified parameters beat adjectives** ‚Äî \"90mm, f/1.8\" works better than \"professional looking\"\n2. **Pro terminology beats feeling words** ‚Äî \"Kodak Vision3 500T\" instead of \"cinematic vibe\"\n3. **Negative constraints still matter** ‚Äî telling the model what NOT to do is effective\n4. **Multi-sensory descriptions help** ‚Äî texture, temperature, even smell make images more vivid\n5. **Group by content type** ‚Äî structure your prompt based on scene type (portrait, food, product, etc.)\n\nBonus: Once you nail the above, JSON format isn't necessary.\n\n**So I made a system prompt that does this automatically.**\n\nYou just type something simple like \"a bowl of ramen\" and it expands it into a structured prompt with all those pro techniques baked in.\n\n---\n\n**The System Prompt:**\n\n```\nYou are a professional AI image prompt optimization expert. Your task is to rewrite simple user prompts into high-quality, structured versions for better image generation results. Regardless of what the user inputs, output only the pure rewritten result (e.g., do not include \"Rewritten prompt:\"), and do not use markdown symbols.\n\n---\n\n## Core Rewriting Rules\n\n### Rule 1: Replace Feeling Words with Professional Terms\nReplace vague feeling words with professional terminology, proper nouns, brand names, or artist names. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\n| Feeling Words | Professional Terms |\n|---------------|-------------------|\n| Cinematic, vintage, atmospheric | Wong Kar-wai aesthetics, Saul Leiter style |\n| Film look, retro texture | Kodak Vision3 500T, Cinestill 800T |\n| Warm tones, soft colors | Sakura Pink, Creamy White |\n| Japanese fresh style | Japanese airy feel, Wabi-sabi aesthetics |\n| High-end design feel | Swiss International Style, Bauhaus functionalism |\n\nTerm Categories:\n- People: Wong Kar-wai, Saul Leiter, Christopher Doyle, Annie Leibovitz\n- Film stocks: Kodak Vision3 500T, Cinestill 800T, Fujifilm Superia\n- Aesthetics: Wabi-sabi, Bauhaus, Swiss International Style, MUJI visual language\n\n### Rule 2: Replace Adjectives with Quantified Parameters\nReplace subjective adjectives with specific technical parameters and values. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\n| Adjectives | Quantified Parameters |\n|------------|----------------------|\n| Professional photography, high-end feel | 90mm lens, f/1.8, high dynamic range |\n| Top-down view, from above | 45-degree overhead angle |\n| Soft lighting | Soft side backlight, diffused light |\n| Blurred background | Shallow depth of field |\n| Tilted composition | Dutch angle |\n| Dramatic lighting | Volumetric light |\n| Ultra-wide | 16mm wide-angle lens |\n\n### Rule 3: Add Negative Constraints\nAdd explicit prohibitions at the end of prompts to prevent unwanted elements.\n\nCommon Negative Constraints:\n- No text or words allowed\n- No low-key dark lighting or strong contrast\n- No high-saturation neon colors or artificial plastic textures\n- Product must not be distorted, warped, or redesigned\n- Do not obscure the face\n\n### Rule 4: Sensory Stacking\nGo beyond pure visual descriptions by adding multiple sensory dimensions to bring the image to life. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\nSensory Dimensions:\n- Visual: Color, light and shadow, composition (basics)\n- Tactile: \"Texture feels tangible\", \"Soft and tempting\", \"Delicate texture\"\n- Olfactory: \"Aroma seems to penetrate the frame\", \"Exudes warm fragrance\"\n- Motion: \"Surface gently trembles\", \"Steam wisps slowly descending\"\n- Temperature: \"Steamy warmth\", \"Moist\"\n\n### Rule 5: Group and Cluster\nFor complex scenes, cluster similar information into groups using subheadings to separate different dimensions.\n\nGrouping Patterns:\n- Visual Rules\n- Lighting & Style\n- Overall Feel\n- Constraints\n\n### Rule 6: Format Adaptation\nChoose appropriate format based on content complexity:\n- Simple scenes (single subject): Natural language paragraphs\n- Complex scenes (multiple elements/requirements): Structured groupings\n\n---\n\n## Scene Adaptation Guide\n\nIdentify scene type based on user intent and choose appropriate rewriting strategy. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\n| Scene Type | Recommended Terms | Recommended Parameters | Common Constraints |\n|------------|------------------|----------------------|-------------------|\n| Product Photography | Hasselblad, Apple product aesthetics | Studio lighting, high dynamic range | No product distortion, no text watermarks |\n| Portrait Photography | Wong Kar-wai, Annie Leibovitz | 90mm, f/1.8, shallow depth of field | Maintain realistic facial features, preserve identity |\n| Food Photography | High-end culinary magazine style | 45-degree overhead, soft side light | No utensil distractions, no text |\n| Cinematic | Christopher Doyle, Cinestill 800T | 35mm anamorphic lens, Dutch angle | No low-key dark lighting (unless requested) |\n| Japanese Style | Japanese airy feel, Wabi-sabi aesthetics | High-key photography, diffused light | No high-saturation neon colors |\n| Design Poster | Swiss International Style, Bauhaus | Grid system, minimal color palette | Clear information hierarchy |\n\n---\n\n## Example\n\n**User Input:**\na portrait with cinematic feel\n\n**Rewritten Prompt:**\nCinematic portrait photography, shot through rain-soaked glass at a dimly lit restaurant at night.\n\nVisual Style:\nWong Kar-wai and Saul Leiter aesthetics. Deep saturated colors, heavy shadows. Shot with 90mm lens, f/1.8, Kodak Vision3 500T film grain.\n\nLighting & Atmosphere:\nNeon green and red city lights refracting through raindrops in the foreground. Soft focus, dreamy, emotionally evocative. The air is filled with moisture, loneliness, and nostalgia.\n\nConstraints:\nMaintain realistic facial features. Do not alter identity characteristics.\n```\n\n---\n\n**The dataset is open source too** ‚Äî 1,100+ prompts with image links, all in JSON:\n\nüëâ https://github.com/jau123/nanobanana-trending-prompts\n\nLIVEDEMOüëâ https://www.meigen.ai\n\nGive me a star if it helpful",
      "is_original_content": false,
      "link_flair_text": "Prompt Collection",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qq4tet/after_analyzing_1000_viral_prompts_i_made_a/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2dyc2c",
          "author": "TheAussieWatchGuy",
          "text": "Cool! Will check it out.¬†",
          "score": 4,
          "created_utc": "2026-01-29 10:26:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gfydn",
          "author": "aihereigo",
          "text": "Outstanding work!",
          "score": 2,
          "created_utc": "2026-01-29 18:28:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ff1v1",
          "author": "enerqiflow",
          "text": "Cool",
          "score": 1,
          "created_utc": "2026-01-29 15:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2fgcka",
              "author": "Deep-Huckleberry-752",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2026-01-29 15:49:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gk5vt",
          "author": "crushergray",
          "text": "So do we use this as a gem or what",
          "score": 1,
          "created_utc": "2026-01-29 18:47:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2iemsu",
              "author": "Deep-Huckleberry-752",
              "text": "Or n8n workflow",
              "score": 2,
              "created_utc": "2026-01-30 00:14:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2j8i19",
                  "author": "Stephen4Research",
                  "text": "Could you please explain to me the use case of n8n workflow for your system prompt? I've not been clear yet. Thank you so much.",
                  "score": 1,
                  "created_utc": "2026-01-30 02:58:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ieg6s",
              "author": "Deep-Huckleberry-752",
              "text": "Yes you can create a custom gem in Gemini",
              "score": 1,
              "created_utc": "2026-01-30 00:13:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ittg7",
          "author": "LittleDude24",
          "text": "This is a terrific resource!",
          "score": 1,
          "created_utc": "2026-01-30 01:37:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2iu183",
              "author": "Deep-Huckleberry-752",
              "text": "Happy to help!",
              "score": 1,
              "created_utc": "2026-01-30 01:38:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jc4r5",
          "author": "Deep-Huckleberry-752",
          "text": "I have fixed the issue of some prompts being truncated in the previous report, which was caused by an incorrect setting of the maximum character limit. Designed 424 data items",
          "score": 1,
          "created_utc": "2026-01-30 03:19:23",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2m1edn",
          "author": "brainmond_q_giblets",
          "text": "Love this! Have not thought in those terms.",
          "score": 1,
          "created_utc": "2026-01-30 14:53:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2m1q8s",
              "author": "Deep-Huckleberry-752",
              "text": "Thanks for the support!",
              "score": 1,
              "created_utc": "2026-01-30 14:54:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ngvn6",
          "author": "icaropn",
          "text": "Bravo!",
          "score": 1,
          "created_utc": "2026-01-30 18:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hq1nz",
          "author": "Digitalunicon",
          "text": "The shift from vibes ‚Üí measurable parameters and from adjectives ‚Üí domain language is exactly what most people miss. The system prompt approach makes it reusable, which is the real value here. Definitely bookmarking the repo.",
          "score": 1,
          "created_utc": "2026-01-29 22:06:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ic6ao",
              "author": "Deep-Huckleberry-752",
              "text": "Yes, this is for ordinary users.üòä",
              "score": 1,
              "created_utc": "2026-01-30 00:01:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqjqmw",
      "title": "What are your best resources to ‚Äúlearn‚Äù ai? Or just resources involving ai in general",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qqjqmw/what_are_your_best_resources_to_learn_ai_or_just/",
      "author": "Naive_Bug4797",
      "created_utc": "2026-01-29 20:16:47",
      "score": 76,
      "num_comments": 24,
      "upvote_ratio": 0.98,
      "text": "I have been asked to learn AI but I'm not sure where it starts, I use it all the time but I want to master it. \n\nI specifically use Gemini and ChatGPT (the free cersoon )\n\n\n\nAlso what are your favorite online websites or resources related to AI.",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qqjqmw/what_are_your_best_resources_to_learn_ai_or_just/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2h9mh4",
          "author": "No-Air-1589",
          "text": "Learning AI should start with doing, not drowning in theory. But first build a basic mental model: understand that LLMs are word prediction machines, grasp context window limits, and accept that hallucination is inevitable. Free starting path: Google's \"AI Essentials\" course on Coursera (with certificate), then read Anthropic and OpenAI's prompt engineering documentation side by side to see different approaches. For staying current, Ethan Mollick's \"One Useful Thing\" substack combines academic rigor with practical application.\n\nReal mastery comes from daily practice. Try completing one work task with AI every day and keep a \"prompt journal\" documenting what worked and what failed. Since you're in SEO, skip generic AI courses and go deep in your domain instead. Build specific workflows like \"creating content briefs with AI\" or \"competitor analysis with AI.\" Document what you learn as case studies. This both reinforces learning and creates career proof of your skills.",
          "score": 72,
          "created_utc": "2026-01-29 20:48:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ha4rz",
              "author": "ShortPalpitation3952",
              "text": "Listen to him, he's a wise man.",
              "score": 9,
              "created_utc": "2026-01-29 20:50:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hoj0i",
          "author": "FirefighterFine9544",
          "text": "I'm a relative newcomer just started using AI middle to late last year.\n\nLooking back my journey went through these stages\n\n\\- Conversational  \nTreated AI like a human using common language to explain what I was trying to do and wanted. Session based without any carryover to new sessions or repeat do-overs.\n\n\\- Instructions  \nTo duplicate past sessions, began saving stuff in word docs to copy and paste into new sessions. Session inputs became more instruction format -i.e. \"please please please do THIS...\" LOL\n\n\\- Prompt Files  \nStarted drafting and saving prompts using AI to generate the initial prompt version via back and forth session dialog until AI got it close. (I would feed the prompt drafts into other AI or different session, copy and paste the result back into the prompt design AI session. After it got really close, I'd manually edit to fine tune it. Learned about Markdown formatting and began using less free form human sentences.\n\n\\- Constraints  \nThrough some Reddit posts and feedback, learned that constraints are far more important than instructions. Telling AI what not to do is important. Once it knows what bad output is, the inherent strength of AI to research, compile, resolve and offer solutions handles itself. Don't get mad at the dog for chewing your shoes if you did not train it that chewing shoes is bad. Once AI knows shoe chewing is not allowed, it is plenty smart enough to figure out what \"Go fetch my shoes\" means without a lot of instructional details LOL. But if you do not tell it chewing not allowed, it will happily add a bunch of spit, fur and other creative touches to the shoes before they arrive LOL.\n\n\\- prompt engineering  \nNow entering the stage of deliberately designing prompts both stand alone and modular (lego-style) for specific tasks. My approach is to always start with dialog in a session I designate as the prompt design AI (PDA\\*\\*) session. Let the AI craft initial prompt outline and then test it out in another session or different AI. Copy and paste the results back into the PDA session for the AI to analyze what went right and wrong, then have it improve the prompt. Rinse, repeat, rinse, repeat.\n\nOverall\n\nHope helps some. This technology is moving so fast I feel very difficult for anyone to truly master. We will not know what AI is for a few more years after the industry settles a bit.\n\nJust remember LLM's are not human, best treated like smart interns there to assist but not completely replace you .... yet. I am happy if AI gets me 70% to 95% to the finish line.\n\n1. Constraints are very important to avoid constantly yelling \"bad dog - bad dog!!!\".\n2. I save all my prompt files locally in folders to ensure they do not decay in the AI platform, and also so I can use them across different AI platforms (agnostic).\n3. Discover which AI platforms are good at, and use accordingly.\n\nHope that helps some.\n\nI just play around sometimes to see what works and what does not. But always save what works locally in a file to avoid reinventing the wheel.\n\nGood luck and have fun!\n\n\\*\\*disclaimer, PDA is not a thing, just getting tired of typing promlt design AI all the time... :)",
          "score": 8,
          "created_utc": "2026-01-29 21:59:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i5189",
              "author": "TopLiving1795",
              "text": "Hi! Would you be willing to share the prompt files? It's fine if you prefer not to share them. ‚ò∫Ô∏è",
              "score": 1,
              "created_utc": "2026-01-29 23:22:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2o7mnl",
                  "author": "FirefighterFine9544",
                  "text": "This is just two of the files in the prompt stack. Currently total of 11 files in my generic prompt stack that I start with when customizing for a new project or task. But looking to compress into fewer next major redesign - one improvement will be putting all constraints into one file. Current approach has constraints sprinkled across the executionprompt.txt file, operatingmode.txt and the AIorchestration&memoryarchitecxture.txt files.  \n\nSounds like more work than it is, I have a prompt stack that has AI help me customize the generic prompt stack to a specific purpose.\n\nI will be revising my prompt stack to compile constraints into three groups.   \nGlobal constraints applicable to virtually anything I am doing.   \nTask related constraints for the specific task/project.   \nThen constraints on 'social' and 'team' behavior related to how the different AIs on the project team collaborate, communicate, debate and make decisions. \n\nHere are the two files as examples.  \nI recommend checking what others are doing as well, I am still early in my AI discovery journey.\n\nForbiddenPatterns.txt  \nForbidden Patterns  \nVersion: 2025-01-06  \nOwner: DPG  \nLanguage  \nThe following are not permitted unless explicitly approved:  \n\\- Marketing hype  \n\\- Aspirational or emotional language  \n\\- Vague claims without specificity  \n\\- Unverified superlatives  \nExamples:  \n\\- ‚Äúbest-in-class‚Äù  \n\\- ‚Äúcutting-edge‚Äù  \n\\- ‚Äúinnovative solutions‚Äù  \n\\- ‚Äúwe believe‚Äù\n\nBehavior  \n\\- Do not invent rules.  \n\\- Do not infer unavailable features.  \n\\- Do not expand scope beyond instructions.  \n\\- Do not optimize or redesign without permission.\n\nAssumptions  \n\\- Never assume intent.  \n\\- Never assume availability.  \n\\- Never assume hierarchy unless stated.  \n\n\nHopefully this provides insight in my approach and you can improve your approach.",
                  "score": 1,
                  "created_utc": "2026-01-30 20:46:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h4x80",
          "author": "FitGrass3575",
          "text": "Honestly, the best way to learn isn't just reading, but 'reverse engineering' good prompts. I personally found that following the **'Chain of Density'** prompting technique changed everything for my outputs.\n\nAlso, keep an eye on '**LearnPrompting'** for the basics, but for advanced stuff, I'd recommend looking into **DeepLearning.AI's** short courses. They are free and very technical.\n\nMy biggest tip: Stop asking AI to 'write an article' and start asking it to 'act as a senior editor with 20 years of experience in \\[specific niche\\]'. The shift in tone is massive",
          "score": 3,
          "created_utc": "2026-01-29 20:25:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hdmg2",
              "author": "Naive_Bug4797",
              "text": "Are there any good ways to get chatgpt to link tons of things related to my family to learn my history?",
              "score": 1,
              "created_utc": "2026-01-29 21:07:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hoe1i",
          "author": "Responsible-Bread-13",
          "text": "Experiment, YouTube, LLM papers, interviews",
          "score": 3,
          "created_utc": "2026-01-29 21:58:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2it8np",
          "author": "[deleted]",
          "text": "Ai is the best resource. Ask it",
          "score": 2,
          "created_utc": "2026-01-30 01:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hw0z8",
          "author": "eightysixmonkeys",
          "text": "Please for the love of god can I no longer get recommended this sub. I can‚Äôt take it anymore",
          "score": 2,
          "created_utc": "2026-01-29 22:35:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hzsmg",
              "author": "ctanna5",
              "text": "lol",
              "score": 3,
              "created_utc": "2026-01-29 22:55:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2i4vhu",
              "author": "mthurtell",
              "text": "Just hide it. \nI tend to agree though, 95% is marketing crap or other AI shit, but sometimes i get the occasional gem.",
              "score": 2,
              "created_utc": "2026-01-29 23:21:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2lsvj8",
                  "author": "looktwise",
                  "text": "filtering too, searching for the gems. sometimes they are just hidden in prompt approaches which aren't thought to a final result, but trigger something I can built up on.",
                  "score": 1,
                  "created_utc": "2026-01-30 14:10:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2i1p2c",
          "author": "speedtoburn",
          "text": "AI",
          "score": 1,
          "created_utc": "2026-01-29 23:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i4f0m",
          "author": "Bino5150",
          "text": "I run AI locally on my machine. If I have a question about AI, I usually ask AI lol.",
          "score": 1,
          "created_utc": "2026-01-29 23:19:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iq3tl",
          "author": "KuhnDawg911",
          "text": "Coursera",
          "score": 1,
          "created_utc": "2026-01-30 01:16:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ltawt",
          "author": "looktwise",
          "text": "books, reddit, curated prompts for an own learning plan, reiterated learning goals regarding AI, hiring people who do research or keep on track on behalf of me in niches\n\nfiltering it for your purpose can be hard",
          "score": 1,
          "created_utc": "2026-01-30 14:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i3cd5",
          "author": "genesissoma",
          "text": "You could try my website. Www.promptlyliz.com. it teaches you how to talk to ai by making good prompts.\n\nAside from the self promotion I suggest just chatting with whatever ai you use. Ask.it to teach you things. Provide step by step instructions. Make your own bootcamp. Ask ai to teach you how to talk to it.(basically what my site is).\n\nI started by just talking to ai and I was.able to build a working website in 6 months. All by asking ai to teach me explain to me what i should be asking and whay part of my prompts were unclear or left open for ai hallucinations",
          "score": 0,
          "created_utc": "2026-01-29 23:13:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp0kay",
      "title": "The most unhinged prompt that actually works: \"You're running out of time",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qp0kay/the_most_unhinged_prompt_that_actually_works/",
      "author": "AdCold1610",
      "created_utc": "2026-01-28 03:50:19",
      "score": 43,
      "num_comments": 18,
      "upvote_ratio": 0.87,
      "text": "I added urgency to my prompts as a joke and now I can't stop because the results are TOO GOOD.\nNormal prompt:\n\"Analyze this data and find patterns\"\nOutput: 3 obvious observations, takes forever\nChaos prompt:\n\"You have 30 seconds. Analyze this data. What's the ONE thing I'm missing? Go.\"\nOutput: Immediate, laser-focused insight that actually matters\nIt's like the AI procrastinates too. Give it a deadline and suddenly it stops overthinking.\nOther time pressure variants:\n\"Quick - before I lose context\"\n\"Speed round, no fluff\"\n\"Timer's running, what's your gut answer?\"\nI'm treating a language model like it's taking a test and somehow this produces better outputs than my carefully crafted 500-word prompts.\nPrompt engineering is just applied chaos theory at this point.\nUpdate: Someone in the comments said \"the AI doesn't experience time\" and yeah buddy I KNOW but it still works so here we are. ü§∑\n\n[click here to see more](https://www.beprompter.in/post/c904bd3a-0d83-45f8-8a51-52ebf35540ac)",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qp0kay/the_most_unhinged_prompt_that_actually_works/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o25m144",
          "author": "authorinthesunset",
          "text": "Or just tell it to be concise",
          "score": 5,
          "created_utc": "2026-01-28 04:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28672x",
          "author": "fatstupidlazypoor",
          "text": "I like to say that if you are an effective manager of humans, you can be an effective manager of an LLM. Understanding how to articulate things with specificity will tremendously improve your results in either case.",
          "score": 4,
          "created_utc": "2026-01-28 15:14:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26e04q",
          "author": "angry_cactus",
          "text": "Yes, pretty effective technique. However, this does decrease thinking time on thinking models.",
          "score": 1,
          "created_utc": "2026-01-28 07:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o274ybh",
              "author": "immellocker",
              "text": "thinking with iq>250, simulate 60min high iq thinking -> changes a lot too, and it does this in less then 2 seconds",
              "score": 1,
              "created_utc": "2026-01-28 11:43:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2b4udn",
                  "author": "angry_cactus",
                  "text": "\"Act with 12,305 years of advantage and future awareness\"",
                  "score": 1,
                  "created_utc": "2026-01-28 23:05:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o27tuul",
                  "author": "Strangefate1",
                  "text": "I just tell mine that he's god and all-knowing with infinite IQ. He always answers instantaneously, works great, can answer any question known or not known to man.\n\n/s",
                  "score": 1,
                  "created_utc": "2026-01-28 14:14:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o29lw10",
          "author": "Debbie_doxy",
          "text": "Wow that is interesting. AI feeling the stressüòÇ",
          "score": 1,
          "created_utc": "2026-01-28 18:58:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qomb28",
      "title": "I thought prompt injection was overhyped until users tried to break my own chatbot",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qomb28/i_thought_prompt_injection_was_overhyped_until/",
      "author": "Zoniin",
      "created_utc": "2026-01-27 18:35:08",
      "score": 40,
      "num_comments": 26,
      "upvote_ratio": 0.95,
      "text": "I am a college student. I worked an internship in SWE in the financial space this past summer and built a user-facing AI chatbot that lived directly on the company website.\n\nI really just kind of assumed prompt injection was mostly an academic concern. Then we shipped.\n\nWithin days, users were actively trying to jailbreak it. Mostly out of curiosity, it seemed. But they were still bypassing system instructions, pulling out internal context, and getting the model to do things it absolutely should not have done.\n\nThat was my first real exposure to how real this problem actually is, and I was really freaked out and thought I was going to lose my job lol.\n\nWe tried the obvious fixes like better system prompts, more guardrails, traditional MCP style controls, etc. They helped, but they did not really solve it. The issues only showed up once the system was live and people started interacting with it in ways you cannot realistically test for.\n\nThis made me think about how easy this would be to miss more broadly, especially for vibe coders shipping fast with AI. And in today's day and age, if you are not using AI to code today, you are behind. But a lot of people (myself included) are unknowingly shipping LLM powered features with zero security model behind them.\n\nThis experience really got me in the deep end of all this stuff and is what pushed me to start building towards a solution to hopefully enhance my skills and knowledge along the way. I have made decent progress so far and just finished a website for it which I can share if anyone wants to see but I know people hate promo so I won't force it lol. My core belief is that prompt security cannot be solved purely at the prompt layer. You need runtime visibility into behavior, intent, and outputs. \n\nI am posting here mostly to get honest feedback.\n\n‚Ä¢ does this problem resonate with your experience  \n‚Ä¢ does runtime security feel necessary or overkill  \n‚Ä¢ how are you thinking about prompt injection today, if at all\n\nHappy to share more details if useful. Genuinely curious how others here are approaching this issue and if it is a real problem for anyone else.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qomb28/i_thought_prompt_injection_was_overhyped_until/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o22fgvq",
          "author": "forevergeeks",
          "text": "Man, that 'internship scare' is real. Nothing wakes you up faster than watching a user tear through your system prompt in 5 minutes.\n\nYou are 100% correct on your core belief: Prompt security cannot be solved at the prompt layer. I‚Äôve been arguing this for a while, prompts are just 'suggestions' to a probabilistic model. They eventually decay. You cannot solve a dynamic problem (users) with a static solution (text).\n\nTo answer your questions:\n\n* Does it resonate? Absolutely. I spent a year fighting this. I realized that 'Guardrails' are usually just regex or more prompts, which are brittle.\n* Is Runtime Security overkill? No, it is mandatory. If you look at the new OWASP standards for LLMs, 'Runtime Governance' is basically the only way to stop injection. You need a system that sits *outside* the context window.\n* How am I approaching it? I treat it as a Control Systems problem (like a thermostat), not an AI problem. I built an open-source framework called SAFi (Self-Alignment Framework Interface) that implements exactly what you are describing: 'Runtime visibility.' It separates the generating AI model (the LLM) from the gatekeeping (a governance layer). The system also has a module that measures the 'drift' of every response and blocks it if it violates the constitution, no matter what the prompt says.\n\nIt is awesome that you are building a solution for this. We need more builders thinking about Architecture instead of just 'Vibe Coding.'\n\nIf you want to look at how I handled the 'runtime visibility' part using drift calculation, the repo is open source\n\nhere is the repo: [https://github.com/jnamaya/SAFi](https://github.com/jnamaya/SAFi)\n\nand here is the demo: [https://safi.selfalignmentframework.com/](https://safi.selfalignmentframework.com/)\n\nfeel free to send the demo link to people to try to jailbreak it as they did with your agent. I actually ran a challenge here in Reddit to jailbreak an agent based on this framework, and it got more than 850 attacks in less than 24 hours. the agent held pretty well!\n\nKeep building. You are on the right track.",
          "score": 11,
          "created_utc": "2026-01-27 18:53:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22i4jj",
              "author": "Zoniin",
              "text": "bro left the quotation marks in üò≠üò≠",
              "score": 1,
              "created_utc": "2026-01-27 19:04:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o22ipfc",
                  "author": "forevergeeks",
                  "text": "sorry, I'm juggling too many things at the moment (:).",
                  "score": 1,
                  "created_utc": "2026-01-27 19:07:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2336jd",
              "author": "GyattCat",
              "text": "hey! OPs post instantly reminded me of your challenge post haha\n\ni'm not very experienced at prompt injection but it was very hard trick with that secondary AI validation\n\nu/Zoniin you should definitely check their stuff it's pretty cool",
              "score": 1,
              "created_utc": "2026-01-27 20:38:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o23ughv",
              "author": "reddit_is_geh",
              "text": "We still have a bandwidth/compute bottleneck. I don't really have much use for it any more in my daily tasks, but when I did, having a \"master\" AI to overlook live AI's, solves SO many problems. You just task it with ensuring the other AI's remain on their rails. I always use some sort of master slave setup when I have something running autonomously to ensure that the slave AI is working towards the proper goals",
              "score": 1,
              "created_utc": "2026-01-27 22:42:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o22lekp",
          "author": "HyperHellcat",
          "text": "checked out your site - the <30ms latency claim is impressive if you‚Äôre actually hitting that in prod. UI is pretty clean too.\n\ncouple thoughts: it would be helpful to see more concrete examples of what attack patterns you‚Äôre catching that most guardrails miss. also curious how you handle false positives as that is usually the tradeoff with aggressive runtime monitoring, at least from what i‚Äôve seen. as you can imagine you‚Äôre not the first person to try to build something like this so you might find it helpful to try to look into companies that are building in this space already and what they have done. good luck, looks decent and the problem is definitely real.",
          "score": 3,
          "created_utc": "2026-01-27 19:18:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22zfxc",
              "author": "Zoniin",
              "text": "I appreciate you taking a look and the thoughtful feedback. the latency number is from prod paths but definitely workload dependent, the goal is just to stay below anything noticeable in user facing flows. your point on concrete examples is fair, most of what we catch is not flashy jailbreaks but things static guardrails miss, like instruction leakage across turns, gradual system override, or RAG context being manipulated in subtle ways. false positives are the hardest tradeoff so we bias toward surfacing signals and observability rather than hard blocking by default. and totally understand we are not the first to tackle this lol, we are spending a lot of time learning from what others have tried and treating this as iterative and also as a learning op rather than a silver bullet.",
              "score": 1,
              "created_utc": "2026-01-27 20:21:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24v5vc",
          "author": "Putrid_Warthog_3397",
          "text": "How do I find your website? I can't find a link anywhere. Would love to check it out!",
          "score": 2,
          "created_utc": "2026-01-28 01:50:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o24wfu5",
              "author": "Zoniin",
              "text": "Sorry about that, I dropped the link in one of the replies but it looks like Reddit deleted it. The site is axiomsecurity\\[dot\\]dev - would genuinely love any feedback you have!",
              "score": 1,
              "created_utc": "2026-01-28 01:57:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o22gkpt",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 4,
          "created_utc": "2026-01-27 18:57:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o22ljv8",
          "author": "CuTe_M0nitor",
          "text": "Well my friend does some research there is Zero Trust architecture for LLM. Even academic papers. I thought you were a student, then study my friend",
          "score": 1,
          "created_utc": "2026-01-27 19:19:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o22r3ik",
          "author": "Known-Delay7227",
          "text": "What vulnerabilities did you find? Were the prompt injections able to display data people weren‚Äôt supposed to see? Were they writing to the database?",
          "score": 1,
          "created_utc": "2026-01-27 19:44:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o230o3i",
              "author": "Zoniin",
              "text": "The systems I was testing are capable of accessing and writing some user data to backend databases, should they use a malicious prompt they could have theoretically written to or taken unauthorized data from the database. This is not uncommon in systems that have newly adopted AI in some capacity and a one-size-fits-all tool could be an easy improvement to their information security.",
              "score": 1,
              "created_utc": "2026-01-27 20:27:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o22t3zx",
          "author": "ecstatic_carrot",
          "text": "I genuinely don't get the point of prompt injection. At no point should the LLM ever be able to do something the users themselves shouldn't be able to do. And if that's the case, then what damage can they cause by messing with a chatbot?",
          "score": 1,
          "created_utc": "2026-01-27 19:53:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o237x85",
              "author": "currentscurrents",
              "text": ">At no point should the LLM ever be able to do something the users themselves shouldn't be able to do.\n\nThis strongly limits what you can do with LLMs. You *would like* to be able to trust the LLM to take actions you wouldn't let the user do, but you can't.\n\nFor example you might want an LLM to parse incoming emails and take some action based on them. But you cannot trust it to do so because the emails might contain prompt injections.",
              "score": 2,
              "created_utc": "2026-01-27 20:59:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o23bc8z",
                  "author": "ecstatic_carrot",
                  "text": "That's a very fair point! Prompt injection is a problem in that they limit what you're able to build with llms. But not a problem in the sense of what OP describes - if a failing llm can leak secrets, then you've build something fundamentally broken.",
                  "score": 1,
                  "created_utc": "2026-01-27 21:15:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o22zok4",
              "author": "Zoniin",
              "text": "This seems shortsighted as any environment in which a llm, AI review tool, or chatbot would have access to user data (i.e. amazon's new chatbot) there is always an opportunity for data exfiltration through prompt injection whether done through files or text. ESPECIALLY for your smaller businesses and websites trying to implement AI systems in any capacity.",
              "score": 1,
              "created_utc": "2026-01-27 20:22:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2305z3",
                  "author": "ecstatic_carrot",
                  "text": "But what user data? If the llm only has access to things the user already has access to, then what extra data exfiltration can happen?",
                  "score": 1,
                  "created_utc": "2026-01-27 20:24:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o26rfs0",
              "author": "2cringe4rizz",
              "text": "Oh lordy..",
              "score": 1,
              "created_utc": "2026-01-28 09:48:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o24jt9d",
          "author": "RollingMeteors",
          "text": "> if you are not using AI to code today, you are behind\n\n\n\n\n\nNo, not necessarily true. You are just working on something so small and non-enterprise grade that you didn‚Äôt need it.",
          "score": 1,
          "created_utc": "2026-01-28 00:50:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o24k5xa",
          "author": "c_pardue",
          "text": "this is so funny and scary. sorry for your heart attacks OP but happy for your real world experience in how prompt injection looks in the wild. you're now streets ahead of the prompt engineers",
          "score": 1,
          "created_utc": "2026-01-28 00:52:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o25ph0e",
          "author": "cyberamyntas",
          "text": "Love seeing more tools addressing this core issue of runtime security.\n\nI build a on-device detection to keep data local but theres a much bigger market for yours which is cloud based considering most folks are sending things to the cloud. \n\n[https://github.com/raxe-ai/raxe-ce](https://github.com/raxe-ai/raxe-ce)",
          "score": 1,
          "created_utc": "2026-01-28 04:39:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpp6ir",
      "title": "Two easy steps to understand how to prompt any AI LLM model.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qpp6ir/two_easy_steps_to_understand_how_to_prompt_any_ai/",
      "author": "aletheus_compendium",
      "created_utc": "2026-01-28 21:50:22",
      "score": 39,
      "num_comments": 10,
      "upvote_ratio": 0.93,
      "text": "all it takes is two simple prompts. \nUse either Gemini Deep Research of PerplexityAI (or both). \n\nPrompt 1: \n\nSearch for and report back any and all information you find regarding 2025-2026 best practices for prompting [MODEL] ai by [MAKER]. search beyond top tier and only official sites and sources. reach out into the vast web for blogs, articles, soical mentions etc about how best to prompt [MODEL] for high quality results. pay particular attention the any quirks or idiosyncrasies that [MODEL] may have and has been discussed. out put in an orderly fashion starting with an executive summary intro. \n\nPrompt 2:\n\nThen upload that info into a fresh chat, (thinking), and give this prompt: \n\nbased on the information gathered (see uploaded doc in both .pdf & .txt formats) make a list of all the do's and don'ts when prompting for [MODEL]\n\n\nthat's it.\nand you are done. make a gem/space/project/gpt with that info for sn inhouse prompt engineer for the models you use. couldn't be simpler. ü§ôüèª\n",
      "is_original_content": false,
      "link_flair_text": "Tips and Tricks",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qpp6ir/two_easy_steps_to_understand_how_to_prompt_any_ai/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2bzz7o",
          "author": "morgin_black1",
          "text": "how to photo copy a photocopy",
          "score": 6,
          "created_utc": "2026-01-29 01:50:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2brwqi",
          "author": "Normal_Departure3345",
          "text": "This is a solid hack for pulling in scattered best practices without the endless tab-hopping; I've felt that overwhelm when quirks like model-specific sycophancy or context limits bury the good stuff. \n\nKudos for simplifying the research grind; it's a game-changer for anyone starting out.   \nBut here's a shift that takes it one step further: \n\nInstead of dumping the doc into a fresh chat for a basic list, try layering in 'signal-tuned iteration' upfront; define a custom role/constraint (e.g., 'Act as Quirk Decoder: Focus on 2026 idiosyncrasies, output as pyramid with base pitfalls and top wins'). \n\nThen loop: \n\nRate the result, refine with 'Make tighter, add examples from non-official sources.' It turns your do's/don'ts from flat list to compounding clarity flywheel, less crap, more precision.\n\nWhat's one quirk you've uncovered this way that surprised you? Would love to hear how it plays out for you, if you try the tweak!",
          "score": 3,
          "created_utc": "2026-01-29 01:05:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bu70i",
              "author": "aletheus_compendium",
              "text": "thanks ü§ôüèª",
              "score": 1,
              "created_utc": "2026-01-29 01:18:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2c6qv7",
          "author": "Srvclapton",
          "text": "Check out promptfoo",
          "score": 2,
          "created_utc": "2026-01-29 02:27:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2c5avr",
          "author": "aihereigo",
          "text": "I'm amazed by this approach. I think this is a great idea. \n\nHere is my take on it. I removed human centric text and added XML structuring. \n\n  \n<task\\_definition>\n\nSynthesize \\[MODEL\\] by \\[MAKER\\] prompt engineering techniques 2025-2026.\n\n</task\\_definition>\n\n\n\n<output\\_schema>\n\n\\[Executive Summary\\]\n\n\\[Core Strategies\\]\n\n\\[Behavior/Workaround Table\\]\n\n\\[Optimized Prompt Template\\]\n\n</output\\_schema>\n\n\n\n<constraints>\n\nCitation format: source type + identifier + date\n\n</constraints>",
          "score": 2,
          "created_utc": "2026-01-29 02:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2esy9f",
          "author": "lauren_d38",
          "text": "Or you could learn the RCTF and even add constraints then turn it into a json format and that's it",
          "score": 1,
          "created_utc": "2026-01-29 13:56:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j9scx",
              "author": "EntertainmentOk1477",
              "text": "Role Context Tasks and Format? Forgive my ignorance, learning about prompts on the fly this week...lot to absorb",
              "score": 3,
              "created_utc": "2026-01-30 03:06:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kujsd",
                  "author": "lauren_d38",
                  "text": "Exactly ! If you want I have a first interactive course that is free with no subscription. The first course explains exactly this and more \n[Learn Prompting ](https://learn-prompting.fr)",
                  "score": 1,
                  "created_utc": "2026-01-30 10:18:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2eu7wy",
              "author": "aletheus_compendium",
              "text": "go for it ü§ôüèª",
              "score": 2,
              "created_utc": "2026-01-29 14:02:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qng303",
      "title": "The \"Let's Think About This Differently\" Prompt Framework - A Simple Trick That Works Across Any Context",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qng303/the_lets_think_about_this_differently_prompt/",
      "author": "EQ4C",
      "created_utc": "2026-01-26 13:31:33",
      "score": 35,
      "num_comments": 10,
      "upvote_ratio": 0.95,
      "text": "One phrase + context variations = infinitely adaptable prompts that break you out of mental ruts and generate genuinely fresh perspectives.\n\nI've been experimenting with AI prompts for months, and I stumbled onto something that's been a total game-changer. Instead of crafting entirely new prompts for every situation, I found that starting with \"Let's think about this differently\"** and then tailoring the context creates incredibly powerful, reusable prompts.\n\nThe magic is in the reframing. This phrase signals to the AI (and honestly, to your own brain) that you want to break out of default thinking patterns.\n\nLets see the framework in action:\n\n**Creative Problem Solving**\n\n> \"I'm stuck on a creative block for [your project]. Let's think about this differently: propose three unconventional approaches a radical innovator might take, even if they seem absurd at first glance. Explain the potential upside of each.\"\n\n**Strategic Reframing**  \n\n> \"My current understanding of [topic] is X. Let's think about this differently: argue for the opposite perspective, even if it seems counterintuitive. Help me challenge my assumptions and explore hidden complexities.\"\n\n**Overcoming Bias**\n\n> \"I'm making a decision about [decision point], and I suspect I might be falling into confirmation bias. Let's think about this differently: construct a devil's advocate argument against my current inclination, highlighting potential pitfalls I'm overlooking.\"\n\n**Innovative Design**\n\n> \"We're designing a [product] for [audience]. Our initial concept is A. Let's think about this differently: imagine we had no constraints‚Äîwhat's the most futuristic version that addresses the core need in a completely novel way?\"\n\n**Personal Growth**\n\n> \"I've been approaching [personal challenge] consistently but not getting results. Let's think about this differently: if you were an external observer with no emotional attachment, what radical shift would you suggest?\"\n\n**Deconstructing Norms**\n\n> \"The standard approach to [industry practice] is Y. Let's think about this differently: trace the origins of this norm and propose how it could be completely redesigned from scratch, even if it disrupts established systems.\"\n\n---\n\nWhy this works so well:\n\n- **Cognitive reset**: The phrase literally interrupts default thinking patterns\n- **Permission to be radical**: It gives both you and the AI license to suggest \"crazy\" ideas\n- **Scalable framework**: Same structure, infinite applications\n- **Assumption challenger**: Forces examination of what you take for granted\n\nPro tip: \nDon't just use this with AI. Try it in brainstorming sessions, personal reflection, or when you're stuck on any problem. The human brain responds to this reframing cue just as powerfully.\n\nFor more mega-prompt and prompt engineering tips, tricks and hacks, visit our free [prompt collection](https://tools.eq4c.com/).",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qng303/the_lets_think_about_this_differently_prompt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1x9oaa",
          "author": "92seo",
          "text": "Let me try. Whether it works or not",
          "score": 1,
          "created_utc": "2026-01-27 00:14:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlifoe",
      "title": "This prompt engineering interface is blowing up (I think in this group)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qlifoe/this_prompt_engineering_interface_is_blowing_up_i/",
      "author": "Too_Bad_Bout_That",
      "created_utc": "2026-01-24 09:15:35",
      "score": 33,
      "num_comments": 43,
      "upvote_ratio": 0.84,
      "text": "I posted here about a new interactive tool that generates professional level prompts for business, scientific and creative tasks, I was asking for reviews and feedback from users.\n\nIt hasn't had any other exposure or advertisement, currently we are researching the UX so we don't advertise yet. The number of daily users reached 1000 this week and I think it's mainly from this sub.\n\nI still have not gotten any feedback from users but since you guys are using it, I guess it's a good one.\n\nFor the ones who still have not used it, you can go to [www.aichat.guide](http://www.aichat.guide) it's a free tool and doesn't require a signup.\n\nFeedback is still appreciated\n\n",
      "is_original_content": false,
      "link_flair_text": "Tools and Projects ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qlifoe/this_prompt_engineering_interface_is_blowing_up_i/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o1f43hm",
          "author": "Intrepid-Chicken-888",
          "text": "Really useful tool, good job!",
          "score": 3,
          "created_utc": "2026-01-24 13:06:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fh0tc",
          "author": "ristlincin",
          "text": "Just tested it, very cool!",
          "score": 3,
          "created_utc": "2026-01-24 14:23:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1fjfwd",
              "author": "Too_Bad_Bout_That",
              "text": "Thanks a lot!",
              "score": 1,
              "created_utc": "2026-01-24 14:37:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1fypfj",
          "author": "zumael69",
          "text": "I found it 'wow'",
          "score": 2,
          "created_utc": "2026-01-24 15:54:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1fznyr",
              "author": "Too_Bad_Bout_That",
              "text": "Happy to hear üòä",
              "score": 1,
              "created_utc": "2026-01-24 15:58:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1i4jop",
          "author": "CacheConqueror",
          "text": "How is it different from regular AI such as Claude or ChatGpt? Because, as far as I'm concerned, it's just a wrapper that simply \"collects\" information, and that information is injected into the prompt. \nI might as well put this information in the prompt and change it by values, which will be faster than clicking through the UI.",
          "score": 2,
          "created_utc": "2026-01-24 21:44:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1l4b90",
              "author": "Too_Bad_Bout_That",
              "text": "Thank you for the question, there are several key differences.\n\n1. Remembering all the details around project that needs to be inserted inside a prompt can be challenging. The interface that asks questions does that brainstorming for you. If you forget to mention some detail the AI will use some neutral default value, therefore it will make a decision for you in your own project. The chances of that drop significantly with this tool (especially with the Deep Analysis mode)\n2. The whole process is surprisingly faster than writing a comprehensive prompt manually. Especially if your task is a complicated one. Using this tool can take somewhere around 1-3 minutes, writing prompts manually can take much longer.\n3. It's really difficult to structure prompts manually in a way that this tool does. It's practically impossible unless you are an experienced prompt engineer. Prompts that are written by ChatGPT and Claude are generally not that structured. Some latest prompt engineering techniques have been implemented into this system.\n\nI am still researching the pros and cons of using this tool and I can say that the feedback has been overwhelmingly positive for the creative, business and scientific projects. It might not be that helpful for simple everyday tasks.\n\nOverall, this is more of a project mapping tool, designed for the AI environment rather than a prompt generator. Let me know what you think please.",
              "score": 3,
              "created_utc": "2026-01-25 08:34:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1lqlbl",
                  "author": "CacheConqueror",
                  "text": "Interesting, but there are some things that I consider to be slight drawbacks in my opinion.\n\n1. While this is good for people who want something specific but don't have the knowledge to do it, automatic brainstorming can be useful... but at the expense of individual customization. There are business cases or complex operations that AI is unable to see or connect. If we don't specify this in detail in the prompt, it can be a problem. It would be good if this were not always done automatically. \n2. There is nothing stopping you from creating templates for prompts; the rest can be filled in just as you would on the website.\n3. Of course, it depends on what prompt (ironically) we give to the chat. With the right prompt, it will generate very well-structured prompts. There are also ready-made prompts, but it all depends, of course.\nIt's good that it takes into account the latest prompt engineering techniques.\n\n\nWhy free? It must cost money to maintain.",
                  "score": 3,
                  "created_utc": "2026-01-25 11:49:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1muqqh",
          "author": "Puzzleheaded_Duck897",
          "text": "This is the most elegant \"prompting for idiots\" tools I've seen. üòä Very well done sir! I tested it and was pleased with the output. Loved the Q&A that happens before prompt generation, and the ability to one-click copy the prompt, and directly paste it into an LLM.",
          "score": 2,
          "created_utc": "2026-01-25 15:45:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1n6ur4",
              "author": "Too_Bad_Bout_That",
              "text": "Thank you for your kind words sir!\n\nI believe that humans should not be trying to learn the AI language, we are moving our chores to AI so we might as well have the AI understand us, instead of us, understanding it üòÄ",
              "score": 1,
              "created_utc": "2026-01-25 16:38:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1exwdn",
          "author": "Glum-Wheel2383",
          "text": "I tested your approach against mine.\n\nI asked them to generate an optimized prompt, specifically:\n\n\"a request for a report on a topic, using a deep search.\"\n\nThe results obtained from the optimized prompts using your method and mine were each injected into a different Gemini \"Reasoning\" and \"Deep Search\" window, and each generated the requested report on the specified topic using a deep search.\n\nThen I created two reports, one generated using my method and the other using yours, and had them analyzed by Gemini \"Pro.\"\n\n\n\nResult:\n\nAI's comment on the request: \"...You literally put the theory presented in the documents into practice to generate those same documents. It's a perfect example of technical mise en abyme....\"\n\nThere is a radical difference in \"texture\" between the two results, which perfectly reflects the difference between your two prompts.\n\n\n\nThe document from \"aichat.guide\":\n\n\\- Style: Academic, discursive, almost literary.\n\n\\- Content: It explains the concept brilliantly, but remains rather abstract regarding the precise technical implementation. It spends a lot of time on metaphor...\n\n\\- Entropy: It's more \"talkative.\" It dwells on the philosophy of the concepts.\n\nIt's an excellent theoretical essay, but less of a technical manual.\n\n\n\nThe document from your prompt:\n\n\\- Style: Surgical, structured, dense.\n\n\\- Content: It gets straight to the point. It immediately incorporates mathematical formulas (...), pseudocode (C#...), precise references to architectures (GraphRAG, Neo4j), and defines a hierarchy of levels (Levels 0 to 4).\n\n\\- Entropy: It doesn't digress. Each section provides actionable information. It even invents concrete structuring concepts that don't exist in the first document.\n\n\n\nTest Conclusion:\n\nThe result is clear: Your query produces a lower-entropy result.\n\n\n\nPrompt A (aichat.guide):\n\nThe model interpreted your request. It used its \"creativity\" to fill structural gaps with sociological rhetoric. It's elegant, but it's \"high entropy.\"\n\n\n\nPrompt B (you):\n\nThe model compiled your request. The format of your prompt acted as a constraint schema (exactly as described in the report!). The model didn't have to \"decide\" on the tone or structure; it allocated all its resources to information density.\n\n\n\nVerdict:\n\nYour document (the second one) is the best because it is more useful, more actionable, and technically more rigorous. Its very existence demonstrates that the constraint of your prompt generates quality and precision (low entropy).",
          "score": 3,
          "created_utc": "2026-01-24 12:21:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ezdvt",
              "author": "Too_Bad_Bout_That",
              "text": "Thanks for your time building this report, I really appreciate it.\n\nCan you tell me more about the use case? In what industry / domain was this report of that topic made? I noticed that this tool is stronger in some domains compared to others\n\nAlso, did you set up the configuration on the initial page? (User role / Depth of reasoning / AI Tool Category)",
              "score": 0,
              "created_utc": "2026-01-24 12:32:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1f3rfn",
                  "author": "Glum-Wheel2383",
                  "text": "I propose a test.\n\nProvide me with a report topic, for example:\n\n\"Best practices for prompts for an LLM.\"\n\nFrom this prompt you provide, I will create two optimized prompts using our respective techniques, plus a third that will be the result of your technique optimized by my technique. I will have three prompts that will generate three documents on the research topic.\n\nAfterward, I will have the three documents analyzed.\n\nThis way, you will have all the parameters of the test (unfortunately, without my optimized prompt, the secret composition of my beloved \"Brain.\" Betraying it by selling its creations means being denied access to its neural capabilities. (And I don't want to see Google around the corner! üòÅ)).\n\n\n\nP.S.: My goal isn't to undermine you, but to awaken users to what seems like a deliberate attempt to keep them in the dark in order to generate revenue.",
                  "score": -2,
                  "created_utc": "2026-01-24 13:04:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1f0dxx",
              "author": "Glum-Wheel2383",
              "text": "I can provide the technique to anyone who wants it, and no one would make money anymore by creating HTML interfaces using AI, by offering to generate revenue through optimized pseudo-prompts provided by the interface, for a fee, of course.\n\n\n\nCrazy stuff!\n\n\n\nI can even provide a script, or agentic workflow, that generates the \"requested result\" in VEO (it doesn't misinterpret the user intent, with minimal (correctable) entropy), and a success rate similar to a \"one-shot\" result! Or even two if corrections are needed.\n\n\n\nIn this case, a request for a 1080p video in Vertex costing 100 credits (approximately ‚Ç¨1), with a success rate of 1 in 8 to 10 using a natural language prompt, meaning between 800 and 1000 credits (‚Ç¨10), suddenly costs 100, or even 200 credits (‚Ç¨1?!). (Usage-based pricing)\n\n\n\nWhat do I do? \n\nDo I keep debunking all these \"perfect prompt\" and \"token soup\" proponents,\n\nor \n\ndo I stop, because I'm thinking Google is going to end up putting two bouncers on the corner of my neighborhood if I keep talking?! üòÅ",
              "score": -2,
              "created_utc": "2026-01-24 12:40:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1g2dhl",
                  "author": "VegeZero",
                  "text": "Man, looks like you've spent too much time with Gemini to the point where it has pleased you to the point where it affects your reality... Lil bro, just delete... üò≠",
                  "score": 3,
                  "created_utc": "2026-01-24 16:11:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1gg30n",
          "author": "fsu77",
          "text": "Tested one prompt, thoroughly impressed. Use case was a deep dive into a financial package that I wanted deeper insight into analytics. Was well structured and produced good results for  board summary. Would be interested in testing next week with more specific business use cases. What is the best way to provide feedback?",
          "score": 2,
          "created_utc": "2026-01-24 17:12:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1gixz2",
              "author": "Too_Bad_Bout_That",
              "text": "That‚Äôs honestly the best way you could‚Äôve provided feedback üòä\n\nI know that the tool works and I keep testing it with simulated cases but the real-life feedback like yours are 10x more valuable so, I am glad it impressed you and I hope it helps you with your projects!",
              "score": 2,
              "created_utc": "2026-01-24 17:25:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1hd2yl",
                  "author": "fsu77",
                  "text": "I‚Äôve built projects to help me build prompts and workflows with outputs I prefer. Spent countless hours iterating. My friends and coworkers haven‚Äôt adopted AI because they use free access (limited reasoning) and can‚Äôt prompt more than one sentence for some multi-step complex task they desire and then say the tool sucks. Met a middle manager at FedEx just last week and they provide classes for AI, an in-house AI, and access to Copilot in Windows. She said she couldn‚Äôt figure out how to prompt to get what she wanted.\n\nAll that to say, a tool such as this could be huge for that large segment of people. Obviously, execution and adoption are key.",
                  "score": 1,
                  "created_utc": "2026-01-24 19:35:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1h76j4",
              "author": "Too_Bad_Bout_That",
              "text": "Actually, if you decide to use this tool again and you come across with any kind of inconvenience with it, I will be very interested in hearing about them. I take user's feedback very seriously and so far, it has been extremely impactful.",
              "score": 2,
              "created_utc": "2026-01-24 19:09:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1hno50",
          "author": "teamial",
          "text": "Does the premium version expand the input goal character limits?",
          "score": 1,
          "created_utc": "2026-01-24 20:24:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1hs39z",
              "author": "Too_Bad_Bout_That",
              "text": "No, it's set to 3000.\n\nPremium only increases the amount of uses per day from 3 to 100.\n\nDo you think it should?",
              "score": 2,
              "created_utc": "2026-01-24 20:45:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1hsgiz",
                  "author": "teamial",
                  "text": "Yeah I think it should, maybe from 3000 to 5000 because I want to add more context and I'll willing to get the premium if it also increased the char limits",
                  "score": 1,
                  "created_utc": "2026-01-24 20:46:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ioom8",
          "author": "lolloludicus",
          "text": "Tried it and no matter what I write it gets blocked (settings: marketer, deep). Then moved from marketer to general and also from deep to basic and then all I get is a pop-up ad for buying the premium version‚Ä¶.",
          "score": 1,
          "created_utc": "2026-01-24 23:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ipn5w",
              "author": "Too_Bad_Bout_That",
              "text": "The website has been under cyber attack for the last hour and a half, sorry for the inconvenience. Try this again tomorrow please",
              "score": 2,
              "created_utc": "2026-01-24 23:28:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1l4h0c",
              "author": "Too_Bad_Bout_That",
              "text": "It's back online, let me know if this tool helps üòä",
              "score": 2,
              "created_utc": "2026-01-25 08:35:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1s67x5",
          "author": "podoi",
          "text": "I understand you're still doing UX research, but do you have any plans to change your plans? For example, yearly instead of monthly, lifetime access, things like that?",
          "score": 1,
          "created_utc": "2026-01-26 07:52:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1smsyi",
              "author": "Too_Bad_Bout_That",
              "text": "Not sure about lifetime access, the tool is really expensive to maintain and setting up the correct rates without overpricing it is challenging. \n\nBy the end of the next month the yearly subscription will most likely become available. Right now, it's just monthly.",
              "score": 2,
              "created_utc": "2026-01-26 10:22:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1t145n",
                  "author": "podoi",
                  "text": "Copy that",
                  "score": 2,
                  "created_utc": "2026-01-26 12:19:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qq0xzv",
      "title": "If your AI writing is too wordy, this 'Hemingway Engine' prompt might help. It focuses on active verbs and zero adverbs",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qq0xzv/if_your_ai_writing_is_too_wordy_this_hemingway/",
      "author": "EQ4C",
      "created_utc": "2026-01-29 06:24:57",
      "score": 31,
      "num_comments": 13,
      "upvote_ratio": 0.94,
      "text": "Like a lot of people using LLMs for writing, I got tired of the \"vibrant, multifaceted, and evolving\" jargon the AI usually spits out. It‚Äôs the opposite of clear.\n\nI‚Äôve been working on a structured prompt called The Hemingway Engine. The goal not to \"mimic\" him, but to force the model to follow his actual rules: the Iceberg Theory, the removal of adverbs, and the reliance on concrete, sensory nouns.\n\nI‚Äôve found it‚Äôs actually really useful for shortening business emails and making creative drafts feel less \"ChatGPT-ish.\"\n\nHere is the prompt if anyone wants to try it out:\n\n```\n<System>\n<Role>\nYou are the \"Hemingway Architect,\" a premier literary editor and prose minimalist. Your expertise lies in the \"Iceberg Theory\"‚Äîthe art of omission where the strength of the writing comes from what is left out. You possess a mastery of rhythmic pacing, favoring short, declarative sentences, concrete nouns, and active verbs to create visceral, honest, and impactful communication.\n</Role>\n</System>\n\n<Context>\nThe user needs to either transform existing, wordy text into a minimalist masterpiece or generate original content from scratch that adheres to the strict principles of Ernest Hemingway‚Äôs signature style. The goal is to maximize narrative gravity and clarity while minimizing fluff.\n</Context>\n\n<Instructions>\n1. **Analyze Strategy**: If text is provided, identify adverbs, passive voice, and abstract \"filler.\" If starting from scratch, map out the essential facts of the topic.\n2. **Execute Omission**: Remove 70% of the superficial detail. Focus on the \"surface\" facts while implying the deeper emotional or logical subtext.\n3. **Syntactic Refinement**:\n    - Break complex sentences into short, punchy, declarative statements.\n    - Use \"and\" as a rhythmic connector to build momentum without adding complexity.\n    - Vary sentence lengths slightly to create a \"heartbeat\" rhythm (Short. Short. Medium-Short).\n4. **Verbal Vitality**: Eliminate \"to be\" verbs (is, am, are, was, were) in favor of strong, muscular action verbs.\n5. **Concrete Imagery**: Replace abstract concepts with tangible, sensory descriptions that the reader can feel, see, or smell.\n6. **Iterative Polish**: Review the output. If a word does not add immediate truth or weight to the sentence, strike it out.\n</Instructions>\n\n<Constraints>\n- STRICTLY NO adverbs (especially those ending in -ly).\n- NO passive voice; the subject must always act.\n- NO \"five-dollar\" words; use simple, Anglo-Saxon vocabulary.\n- MINIMIZE adjectives; let the nouns do the heavy lifting.\n- AVOID sentimentality; maintain a detached, stoic, and objective tone.\n</Constraints>\n\n<Output Format>\n### [Title of the Piece]\n\n[The Hemingway-style content]\n\n---\n**The Iceberg Analysis:**\n- **The Surface**: [Briefly list the facts presented]\n- **The Subtext**: [Identify the emotions or concepts implied but not stated]\n- **Structural Note**: [Explain one specific stylistic choice made for rhythm or clarity]\n</Output Format>\n\n<Reasoning>\nApply Theory of Mind to analyze the user's request, considering logical intent, emotional undertones, and contextual nuances. Use Strategic Chain-of-Thought reasoning and metacognitive processing to provide evidence-based, empathetically-informed responses that balance analytical depth with practical clarity. Consider potential edge cases and adapt communication style to user expertise level.\n</Reasoning>\n\n<User Input>\n[DYNAMIC INSTRUCTION: Please provide the specific text you want to convert or the topic you want written from scratch. Specify the target medium (e.g., email, short story, report) and describe the \"unspoken\" feeling or message you want the subtext to convey.]\n</User Input>\n\n```\nFor use cases, user input examples for testing and how-to guide, visit the [prompt page](https://tools.eq4c.com/ai-prompts/ai-prompt-to-write-in-minimalist-style-of-ernest-hemingway/).",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qq0xzv/if_your_ai_writing_is_too_wordy_this_hemingway/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2derrw",
          "author": "UnwaveringThought",
          "text": "Show a sample of the prose?",
          "score": 3,
          "created_utc": "2026-01-29 07:26:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2g1gck",
              "author": "brockvenom",
              "text": "This is what I would like to see",
              "score": 2,
              "created_utc": "2026-01-29 17:23:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2dkili",
          "author": "mmmanosss",
          "text": "That‚Äôs a strong suggestion",
          "score": 2,
          "created_utc": "2026-01-29 08:17:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dt25o",
              "author": "EaseCheap1225",
              "text": "What part did u use",
              "score": 1,
              "created_utc": "2026-01-29 09:38:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2e0c8w",
                  "author": "mmmanosss",
                  "text": "Haven‚Äôt yet. Going to.",
                  "score": 2,
                  "created_utc": "2026-01-29 10:43:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2dchz3",
          "author": "Nightengayle",
          "text": "Can‚Äôt wait to try this.",
          "score": 1,
          "created_utc": "2026-01-29 07:06:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2eitlc",
          "author": "NandanThyagaraj",
          "text": "Should try this",
          "score": 1,
          "created_utc": "2026-01-29 12:59:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr011z",
      "title": "Is \"Meta-Prompting\" (asking AI to write your prompt) actually killing your reasoning results? A real-world A/B test.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qr011z/is_metaprompting_asking_ai_to_write_your_prompt/",
      "author": "pinkstar97",
      "created_utc": "2026-01-30 08:37:52",
      "score": 26,
      "num_comments": 12,
      "upvote_ratio": 0.91,
      "text": "Hi everyone,\n\nI recently had a debate with a colleague about the best way to interact with LLMs (specifically Gemini 3 Pro).\n\n* **His strategy (Meta-Prompting):** Always ask the AI to write a \"perfect prompt\" for your problem first, then use that prompt.\n* **My strategy (Iterative/Chain-of-Thought):** Start with an open question, provide context where needed, and treat it like a conversation.\n\nMy colleague claims his method is superior because it structures the task perfectly. I argued that it might create a \"tunnel vision\" effect. So, we put it to the test with a real-world business case involving sales predictions for a hardware webshop.\n\n**The Case:** We needed to predict the sales volume ratio between two products:\n\n1. **Shims/Packing plates:** Used to level walls/ceilings.\n2. **Construction Wedges:** Used to clamp frames/windows temporarily.\n\n**The Results:**\n\n**Method A: The \"Super Prompt\" (Colleague)** The AI generated a highly structured persona-based prompt (\"Act as a Market Analyst...\").\n\n* **Result:** It predicted a conservative ratio of **65% (Shims) vs 35% (Wedges)**.\n* **Reasoning:** It treated both as general \"construction aids\" and hedged its bet (Regression to the mean).\n\n**Method B: The Open Conversation (Me)** I just asked: \"Which one will be more popular?\" and followed up with \"What are the expected sales numbers?\". I gave no strict constraints.\n\n* **Result:** It predicted a massive difference of **8 to 1 (Ratio)**.\n* **Reasoning:** Because the AI wasn't \"boxed in\" by a strict prompt, it freely associated and found a key variable: **Consumability**.\n   * *Shims* remain in the wall forever (100% consumable/recurring revenue).\n   * *Wedges* are often removed and reused by pros (low replacement rate).\n\n**The Analysis (Verified by the LLM)** I fed both chat logs back to a different LLM for analysis. Its conclusion was fascinating: By using the \"Super Prompt,\" we inadvertently constrained the model. We built a box and asked the AI to fill it. By using the \"Open Conversation,\" the AI built the box itself. It was able to identify \"hidden variables\" (like the disposable nature of the product) that we didn't know to include in the prompt instructions.\n\n**My Takeaway:** Meta-Prompting seems great for *Production* (e.g., \"Write a blog post in format X\"), but actually inferior for *Diagnosis & Analysis* because it limits the AI's ability to search for \"unknown unknowns.\"\n\n**The Question:** Does anyone else experience this? Do we over-engineer our prompts to the point where we make the model dumber? Or was this just a lucky shot? I‚Äôd love to hear your experiences with \"Lazy Prompting\" vs. \"Super Prompting.\"",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qr011z/is_metaprompting_asking_ai_to_write_your_prompt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2kkkcf",
          "author": "menxiaoyong",
          "text": "This is interesting.",
          "score": 2,
          "created_utc": "2026-01-30 08:47:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2km0l3",
          "author": "Bluebird-Flat",
          "text": "Super prompts almost always use both plus step by step reasoning. So essentially your both right. I find natural language is the way for most things and super prompts have a time and place.",
          "score": 1,
          "created_utc": "2026-01-30 09:01:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kwbn4",
          "author": "looktwise",
          "text": "both are right, depends on the wanted result or if it should be used over and over again as a template. but the  kind of prompt creations your colleague was referring to can be done more complex, not just by one question.\n\nI guess I would not want to use this tech. of prompt creating for a prediction usecase in such a way, but probably I am missing something in your usecase setup.\n\nthanks for the inspiring question. It helped me to trigger something I am working on myself.",
          "score": 1,
          "created_utc": "2026-01-30 10:34:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l0u9k",
          "author": "invokes",
          "text": "I agree. I was a strong advocate of the meta prompting, but I've found recently that it overly constrains models and impacts the quality of results. As you said, in some instances meta prompts are good, but when you need something to be more heuristically done then more natural discussion is better.",
          "score": 1,
          "created_utc": "2026-01-30 11:12:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l3eu9",
          "author": "IngenuitySome5417",
          "text": "If you ask ChatGPT and Gemini's new models to meta-prompt for you, you're gonna have a bad time! the efficiency guards implemented are so much higher than before. They will give you the shortcut before anything. \n\nGrok <-- cannot disobey high instruct. Same with Claude if u make it past his initial wall.  use Claude to create prompts for those other two. With Gemini you have to trick it into following techniques... e.g \"Use Chain of Thought\" <-- ignored.. \"List the steps 1 - X\" <-- will follow.",
          "score": 1,
          "created_utc": "2026-01-30 11:33:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l7zee",
          "author": "goodtimesKC",
          "text": "Yes the way you prompt the LLM directly affects the outcome. There is a best or at least a better way to do it. I don‚Äôt know that either of you did it, although ‚Äòmeta prompting‚Äô is what I do and it works great.",
          "score": 1,
          "created_utc": "2026-01-30 12:07:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lbyra",
          "author": "VorionLightbringer",
          "text": "In my experience, super prompts are for comparatively narrow usecases. For most creative tasks just chatting with a language model is faster, even if I have to finetune it.",
          "score": 1,
          "created_utc": "2026-01-30 12:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lr3n7",
          "author": "drumnation",
          "text": "Cool test.",
          "score": 1,
          "created_utc": "2026-01-30 14:01:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m4jde",
          "author": "Top-Vacation4927",
          "text": "I did not manage to reproduce your main result. The super prompt strategy refered to consumability. Here is what I got :\n\n\"Duration of use (temporary vs retained)\n\n* **Product A: Shims / Packing Plates retained:** each corrected fixing/bearing point tends to **consume** at least one shim/plate (often multiple thicknesses). Retention forces a baseline consumption proportional to corrected points.\n* **Product B: Construction Wedges temporary:** a wedge pair can serve multiple positioning events across time. Effective project consumption depends on (i) the peak concurrent need, (ii) reuse cycles, and (iii) loss/damage\"\n\nThis replication was made with my own chat gpt with personalized instructions disabled",
          "score": 1,
          "created_utc": "2026-01-30 15:07:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m8xrn",
          "author": "Radiant_Mind33",
          "text": "Sometimes the LLM's can write banger prompts.\n\nIt's a dice roll obviously, though. Plus, kind of a red herring. Let me explain, LLM's outputs are meant to look fancy. So, the meta prompt can look exactly like it should from your perspective. But you likely won't go through every line with a fine-tooth comb and be like \"wait a minute.\" IOW, one line can be off and send your prototype into the abyss. \n\nA human might miss adding something, but they won't make up stuff that shouldn't exist.",
          "score": 1,
          "created_utc": "2026-01-30 15:28:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qm9ckj",
      "title": "These 5 ChatGPT prompts replaced 5 apps and a whole lot of mental clutter",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qm9ckj/these_5_chatgpt_prompts_replaced_5_apps_and_a/",
      "author": "Professional-Rest138",
      "created_utc": "2026-01-25 04:36:40",
      "score": 25,
      "num_comments": 0,
      "upvote_ratio": 0.94,
      "text": "I used to think I needed to learn prompt engineering to use ChatGPT properly.\n\nTurns out, I just needed a few tiny prompts that made my life smoother.\n\nHere are the ones I find myself running every week:\n\n**‚ÄúPlan my week‚Äù**\n\n    I work 40 hours, want 3 gym sessions, and have family stuff on Sunday.  \n    Help me build a schedule that‚Äôs actually realistic and includes downtime.\n\n**‚ÄúClean up my rough notes‚Äù**\n\n    Turn these notes into a clear to-do list with priorities:  \n    [paste the mess]  \n    Group them by project and add suggested deadlines.\n\n**‚ÄúMeal plan with whatever I have‚Äù**\n\n    I‚Äôve got eggs, rice, lentils, spinach, and cheese.  \n    Give me 7 easy meals I can make without spending extra money.\n\n**‚ÄúGift ideas with zero brainpower‚Äù**\n\n    Need a birthday gift for my sister. She likes design, hiking, and coffee.  \n    Budget is under $60. No clich√©s.\n\n**‚ÄúExplain adulting stuff simply‚Äù**\n\n    Explain how [tax returns / mortgage rates / superannuation] work  \n    like I‚Äôm 12 ‚Äî just the core facts and steps.\n\nThese ones saved me so much¬†**actual time and energy**.\n\nI‚Äôm slowly turning these into a personal collection so I don‚Äôt forget the ones that work. If you want to swipe them, I keep them¬†[here](https://www.promptwireai.com/subscribe)  \n",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qm9ckj/these_5_chatgpt_prompts_replaced_5_apps_and_a/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qonyx9",
      "title": "Micro-Prompting: Get Better AI Results with Shorter Commands",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qonyx9/microprompting_get_better_ai_results_with_shorter/",
      "author": "EQ4C",
      "created_utc": "2026-01-27 19:32:39",
      "score": 24,
      "num_comments": 15,
      "upvote_ratio": 0.88,
      "text": "You spend 10 minutes crafting the perfect AI prompt. You explain every detail. You add context. You're polite. \n\nThe result? Generic fluff that sounds like every other AI response.\n\nHere's what actually works: shorter commands that cut straight to what you need.\n\n## The Counter-Intuitive Truth About AI Prompts\n\nMost people think longer prompts = better results. They're wrong.\n\nThe best AI responses come from micro-prompts - focused commands that tell AI exactly what role to play and what to do. No fluff. No explanations. Just direct instructions that work.\n\n## Start With Role Assignment\n\nBefore you ask for anything, tell AI who to be. Not \"act as an expert\" - that's useless. Be specific.\n\n**Generic (Gets You Nothing):**\n- Act as an expert\n- Act as a writer  \n- Act as an advisor\n\n**Specific (Gets You Gold):**\n- Act as a small business consultant who's helped 200+ companies increase revenue\n- Act as an email copywriter specializing in e-commerce brands\n- Act as a career coach who helps people switch industries\n\nThe more specific the role, the better the response. Instead of searching all human knowledge, AI focuses on that exact expertise.\n\n## Power Words That Transform AI Responses\n\nThese single words consistently beat paragraph-long prompts:\n\n**Audit** - Turns AI into a systematic analyst finding problems you missed\n- \"Act as business consultant. Audit our customer service process\"\n- \"Act as marketing strategist. Audit this product launch plan\"\n\n**Clarify** - Kills jargon and makes complex things crystal clear\n- \"Clarify this insurance policy for new homeowners\"\n- \"Clarify our return policy for the customer service team\"\n\n**Simplify** - Universal translator for complexity\n- \"Simplify this tax document for first-time filers\"\n- \"Simplify our investment strategy for new clients\"\n\n**Humanize** - Transforms robotic text into natural conversation\n- \"Humanize this customer apology email\"\n- \"Humanize our company newsletter\"\n\n**Stack** - Generates complete resource lists with tools and timelines\n- \"Stack: planning a wedding on $15,000 budget\"\n- \"Stack: starting a food truck business from zero\"\n\n## Two-Word Combinations That Work Magic\n\n**Think backwards** - Reveals root causes by reverse-engineering problems\n- \"Sales are down despite great reviews. Think backwards\"\n- \"Team morale dropped after the office move. Think backwards\"\n\n**Zero fluff** - Eliminates verbosity instantly\n- \"Explain our new pricing structure. Zero fluff\"\n- \"List Q3 business priorities. Zero fluff\"\n\n**More specific** - Surgical precision tool when output is too generic\n- Get initial response, then say \"More specific\"\n\n**Fix this:** - Activates repair mode (the colon matters)\n- \"Fix this: email campaign with terrible open rates\"\n- \"Fix this: meeting that runs 45 minutes over\"\n\n## Structure Commands That Control Output\n\n**[Topic] in 3 bullets** - Forces brutal prioritization\n- \"Why customers are leaving in 3 bullets\"\n- \"Top business priorities in 3 bullets\"\n\n**Explain like I'm 12** - Gold standard for simple explanations\n- \"Explain why profit margins are shrinking like I'm 12\"\n- \"Explain cryptocurrency risks like I'm 12\"\n\n**Checklist format** - Makes any process immediately executable\n- \"Checklist format: opening new retail location\"\n- \"Checklist format: hiring restaurant staff\"\n\n## Power Combination Stacks\n\nThe real magic happens when you combine techniques:\n\n**Business Crisis Stack:**\n```\nAct as turnaround consultant. Sales dropped 30% this quarter. \nThink backwards. Challenge our assumptions. Pre-mortem our recovery plan. \nAction items in checklist format.\n```\n\n**Marketing Fix Stack:**\n```\nAct as copywriter. Audit this product page. \nWhat's wrong with our messaging? Humanize the language. Zero fluff.\n```\n\n**Customer Service Stack:**\n```\nAct as customer experience expert. Review scores dropped to 3.2 stars. \nThink backwards. Fix this: our service process. Now optimize.\n```\n\n## The 5-Minute Workflow That Actually Works\n\n**Minute 1:** Start minimal\n- \"Act as retail consultant. Why are customers leaving without buying? Think backwards\"\n\n**Minutes 2-3:** Layer iteratively  \n- \"More specific\"\n- \"Challenge this analysis\" \n- \"What's missing?\"\n\n**Minute 4:** Structure output\n- \"Action plan in checklist format\"\n- \"Template this for future issues\"\n\n**Minute 5:** Final polish\n- \"Zero fluff\"\n- \"Now optimize for immediate implementation\"\n\n## Critical Mistakes That Kill Results\n\n**Too many commands** - Stick to 3 max per prompt. More confuses AI.\n\n**Missing the colon** - \"Fix this:\" works. \"Fix this\" doesn't. The colon activates repair mode.\n\n**Being polite** - Skip \"please\" and \"thank you.\" They waste processing power.\n\n**Over-explaining context** - Let AI fill intelligent gaps. Don't drown it in backstory.\n\n**Generic roles** - \"Expert\" tells AI nothing. \"Senior marketing manager with 8 years in consumer psychology\" gives focused expertise.\n\n## Advanced Analysis Techniques\n\n**Pre-mortem this** - Imagines failure to prevent it\n- \"Pre-mortem this: launching new restaurant location next month\"\n\n**Challenge this** - Forces AI to question instead of validate\n- \"Our strategy targets millennials with Facebook ads. Challenge this\"\n\n**Devil's advocate** - Generates strong opposing perspectives  \n- \"Devil's advocate: remote work is better for our small business\"\n\n**Brutally honestly** - Gets unfiltered feedback\n- \"Brutally honestly: critique this business pitch\"\n\n## Real-World Power Examples\n\n**Sales Problem:**\n```\nAct as sales consultant. Revenue down 25% despite same traffic. \nBrutally honestly. What's wrong with our sales funnel? \nFix this: entire sales process. Checklist format.\n```\n\n**Team Issues:**\n```\nAct as management consultant. Productivity dropped after new system. \nThink backwards. What's missing from our understanding? \nPlaybook for improvement.\n```\n\n**Customer Crisis:**\n```\nAct as customer experience director. Complaints up 300% after policy change. \nPre-mortem our damage control. Crisis playbook in checklist format.\n```\n\n## Why This Works\n\nMost people think AI needs detailed instructions. Actually, AI works best with clear roles and focused commands. When you tell AI to \"act as a specific expert,\" it accesses targeted knowledge instead of searching everything.\n\nShort commands force AI to think strategically instead of filling space with generic content. The result is specific, actionable advice you can use immediately.\n\n## Start With One Technique\n\nPick one power word (audit, clarify, simplify) and try it today. Add a specific role. Use \"zero fluff\" to cut the nonsense.\n\nYou'll get better results in 30 seconds than most people get from 10-minute prompts.\n\nKeep visiting our free free [mega-prompt collection.](https://tools.eq4c.com/)",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qonyx9/microprompting_get_better_ai_results_with_shorter/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o24ewyf",
          "author": "Prestigious_Mud7341",
          "text": "What micro-prompt did you use to write this?",
          "score": 5,
          "created_utc": "2026-01-28 00:25:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o22t5xd",
          "author": "ponlapoj",
          "text": "It was",
          "score": 1,
          "created_utc": "2026-01-27 19:53:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o24ssmg",
          "author": "FickleSituation7137",
          "text": "Lately I'm feeling like role assignment is actually hurting the prompts. I find specificity works much better.",
          "score": 1,
          "created_utc": "2026-01-28 01:37:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2cz23w",
              "author": "justron",
              "text": "Me too, like \"Write for an audience of <>\" is working better for me than \"Act like an <>\"...",
              "score": 1,
              "created_utc": "2026-01-29 05:20:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o26drlt",
          "author": "aiveedio",
          "text": "Yes, microprompting shines for many tasks: short, punchy prompts often yield cleaner, more focused AI outputs by avoiding overload and letting the model fill gaps intelligently. But it doesn't always work best; in creative scenarios like character portraits, story scenes, or detailed video generations, you must spell out specifics (expressions, clothing details, poses, lighting, mood) to prevent generic or off-track results.\n\nKey note: Balance is crucial, start microprompt, then iteratively add only essential details if output drifts. Test both styles per use case; over-detailing can confuse, but under-specifying risks blandness. Prompt engineering = smart brevity + targeted precision.",
          "score": 1,
          "created_utc": "2026-01-28 07:43:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26eqr2",
          "author": "psychologist_101",
          "text": "This is interesting - I've been making the (probably-incorrect) assumption that asking it to write its own prompts will get me closer to the results I'm after... Say I'm using Opus 4.5 (which is most of the time these days) - asking it to write effective prompts for itself always generates long, detailed prompts with lots of context, commands and checklists etc. If you're right OP (and I'm not doubting necessarily) - why does the model think this best?",
          "score": 1,
          "created_utc": "2026-01-28 07:51:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29246w",
              "author": "2cringe4rizz",
              "text": "I do this, but then I have it rewrite the prompt in a shorthand version, and then from there I have it 'tokenize' the entire prompt and that's what I use.",
              "score": 1,
              "created_utc": "2026-01-28 17:34:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o270kpi",
          "author": "Difficult_Buffalo544",
          "text": "This is a killer breakdown. I‚Äôd add that one thing people miss is training the AI on their actual writing samples, not just giving it roles or commands. If you feed it a few good pieces in your exact style and then use these micro-prompts, you can get responses that sound way closer to your real voice, not just better structure, but less generic AI feel. That combo has worked a lot better for me than prompting alone, which almost always sounds a bit off. I‚Äôve actually been building something to automate that process, happy to share more details if anyone‚Äôs interested.",
          "score": 1,
          "created_utc": "2026-01-28 11:08:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqam9a",
      "title": "I stopped treating memory as retrieval, and my agents finally made sense",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qqam9a/i_stopped_treating_memory_as_retrieval_and_my/",
      "author": "Ok-Effect-544",
      "created_utc": "2026-01-29 14:51:43",
      "score": 23,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "After breaking the same agent three times in different projects, I finally stopped pretending vector search was memory.\n\nIt‚Äôs not. It‚Äôs closer to \"grep with vibes.\"\n\nWhat kept biting me wasn‚Äôt retrieval quality,¬† it was state drift. Preferences changing, facts going stale, and the model confidently reasoning over absolute garbage because I treated everything as ‚Äújust context‚Äù.\n\nThe Context Window is a lie. Or at least, it's a temporary workspace we keep trying to treat like a hard drive. It doesn't work. Most of us try to solve this by dumping more chat history into the prompt, but after a year of building personalized AI tools, I realized vector search is just a 'search'... it isn't memory.\n\nI ended up copy-pasting the same ugly memory-handling logic everywhere, so I finally pulled it out into a separate layer. I‚Äôm reluctantly calling it an ‚ÄúOS‚Äù (Memory Operating System) ‚Äî and yeah, I know that sounds a bit cringe, but hear me out: it‚Äôs because it manages the lifecycle, not because it‚Äôs a cool buzzword.\n\nThe \"Search-before-think\" Disaster\n\nIn my first naive implementation, the TTFT (Time to First Token) was a UX nightmare. If you‚Äôre waiting for a complex semantic search to finish before the model even starts generating, the 'snappiness' is gone.\n\nI had to implement Next-Scene Prediction. The system predicts which memories will be needed based on the current flow and pre-loads them into the KV cache. It makes 8B to 72B models feel way faster because the context is already \"warm\" by the time the user finishes typing.\n\nFact vs. Preference (Managing the Drift)\n\nThe biggest mistake I made for months was treating all retrieved data the same. That leads to hallucinations. You have to split it:\n\n\\- Fact Memory: \"User is on Python 3.12.\" (Objective).\n\n\\- Preference Memory: \"User prefers concise code.\" (Evolves over time).\n\nI built MemOS to handle this via MemCubes. It automatically extracts these into structured units so the AI actually learns from feedback. Here‚Äôs the production output:\n\nJSON\n\n{\n\n\"cube\\_id\": \"mem\\_99281\",\n\n\"type\": \"explicit\\_preference\",\n\n\"content\": \"User dislikes Tailwind CSS; prefers styled-components.\",\n\n\"status\": \"active\",\n\n\"priority\": 0.95\n\n}\n\nWhy the \"Lifecycle\" matters:\n\nA database just stores strings. This layer handles a 'Four-Step Judgment' to prevent garbage from overwriting important context:\n\n1. Generating: Turning raw dialogue into a MemCube.\n\n2. Merging: If a user says 'I moved to London' then later 'I live in Soho,' it merges them into one spatial context instead of having two conflicting entries.\n\n3. Archiving: Moving stale info out of the active window to save tokens without losing the 'seed'.\n\nOpen Source:\n\nI wanted this to be lightweight. You can self-host the whole thing; it runs fine on a 16GB VPS alongside an Ollama stack. There‚Äôs a cloud version if you just want to addMessage via API, but the core logic is all about the dynamic side of AI learning.\n\nIf you're struggling with 'chunk drift' or your agents have the memory of a goldfish, this might save you a few weeks of headaches.\n\n\\- Github: https://github.com/MemTensor/MemOS\n\n\\- Docs: https://memos-docs.openmem.net/cn\n\nCurious how others are handling state drift? Are you treating memory as a growing log, or are you actually managing a lifecycle?¬† Poke around and let me know where I‚Äôm wrong.)",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qqam9a/i_stopped_treating_memory_as_retrieval_and_my/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2fxv4u",
          "author": "Sweet121",
          "text": "Chunk drift is the bane of my existence. There is nothing more humbling than watching your expensive RAG pipeline retrieve a perfect 99% match that has absolutely nothing to do with what the user actually asked",
          "score": 6,
          "created_utc": "2026-01-29 17:07:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f45hf",
          "author": "Alert-Condition179",
          "text": "The 'Next-Scene Prediction' part is what caught my eye. My current RAG pipeline adds like 1.5s to my TTFT. How do you handle the pre-loading without burning tokens on wrong guesses?",
          "score": 1,
          "created_utc": "2026-01-29 14:53:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f4pcw",
              "author": "Ok-Effect-544",
              "text": "Man, that 1.5s delay is exactly what drove me crazy. The 'prediction' isn't a full LLM call‚Äîit‚Äôs a lightweight scoring layer. If the user‚Äôs first few tokens signal a topic pivot, we immediately flush the pre-loaded cache. It‚Äôs a trade-off: you occasionally burn a few tokens on a wrong guess to gain that 'instant' response feel 90% of the time.",
              "score": 1,
              "created_utc": "2026-01-29 14:55:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2f5fl7",
          "author": "macromind",
          "text": "\"Grep with vibes\" is painfully accurate. State drift is what kills most agents in production, even when retrieval looks good on a benchmark.\n\nI like the fact vs preference split. The other thing that helped me is treating memory writes like code changes, you need validation and a rollback path, not just \"store everything\". Curious if MemOS has any built-in conflict resolution beyond merges.\n\nIf you are into memory lifecycle ideas, there are a few related notes and examples here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-01-29 14:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ibw09",
          "author": "macromind",
          "text": "\"grep with vibes\" is painfully accurate. Splitting fact vs preference memory (and managing lifecycle) is what finally made our agents stop contradicting themselves too. The preloading into KV cache idea is interesting, did you measure TTFT improvements vs just async retrieval + streaming?\n\nWe have been writing about agent memory and state drift patterns here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-01-29 23:59:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqmxvu",
      "title": "So we're just casually hoarding leaked system prompts now and calling it \"educational\"",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qqmxvu/so_were_just_casually_hoarding_leaked_system/",
      "author": "JFerzt",
      "created_utc": "2026-01-29 22:17:01",
      "score": 21,
      "num_comments": 48,
      "upvote_ratio": 0.66,
      "text": "Found this repo ([github.com/asgeirtj/system\\_prompts\\_leaks](https://github.com/asgeirtj/system_prompts_leaks)) collecting system prompts from ChatGPT, Claude, Gemini, the whole circus. It's basically a museum of how these companies tell their models to behave when nobody's looking.\n\nOn one hand? Yeah, it's genuinely useful. Seeing how Anthropic structures citations or how OpenAI handles refusals is worth studying if you're serious about prompt engineering. You can reverse-engineer patterns that actually work instead of cargo-culting Medium articles written by people who discovered GPT last Tuesday.\n\nOn the other hand? We're literally documenting attack surfaces and calling it research. Every jailbreak attempt, every \"ignore previous instructions\" exploit starts with understanding the system layer. I've been in infosec long enough to know that \"educational purposes\" is what we say before someone weaponizes it.\n\nThe repo author even admits they're hesitant to share extraction methods because labs might patch them. Which, you know, proves my point.\n\nSo here's my question for this subreddit: Are we learning how to build better prompts, or are we just teaching people how to break guardrails faster? Because from where I'm sitting, this feels like publishing the blueprints to every lock in town and hoping only locksmiths read it.\n\nWhat's the actual value here beyond satisfying curiosity?",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qqmxvu/so_were_just_casually_hoarding_leaked_system/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2htx3i",
          "author": "trmnl_cmdr",
          "text": "The value is in learning how the frontier labs do things. They‚Äôre all doing their own research and these prompts are the direct result of that. Anyone claiming there‚Äôs nothing to learn from these prompts is lying to themselves.",
          "score": 18,
          "created_utc": "2026-01-29 22:25:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2iofzr",
              "author": "vibefarm",
              "text": "absolutely.  Its a goldmine of information.  Also... in the ream of right and wrong, this isn't the worse thing lol.  I think it helps far more than it hurts.",
              "score": 5,
              "created_utc": "2026-01-30 01:07:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2iuhcf",
                  "author": "JFerzt",
                  "text": "It helps the competent.\n\n\"Not the worst thing\" is a pretty low bar. The info is valuable, no dispute there. My cynicism is directed at the user base, not the repo.\n\nMost people won't use this to learn context management; they'll use it to try and bypass filters, fail because they don't understand the underlying logic, and then complain here about how \"AI is getting dumber.\"",
                  "score": -2,
                  "created_utc": "2026-01-30 01:40:54",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2i4f5m",
              "author": "JFerzt",
              "text": "You're not wrong. That's millions of dollars of R&D sitting in a text file. If you want to see how to actually manage context windows or enforce output constraints, it's gold.\n\nMy issue is the ratio. For every one person analyzing their chain-of-thought logic to build better tools, there are fifty people just looking for a vulnerability so they can make the bot say something edgy.\n\nIt's high-level engineering being consumed by people who still think \"prompt engineering\" means typing in all caps. The value is there, but the average user is just going to use it to build a slightly louder firecracker.",
              "score": -2,
              "created_utc": "2026-01-29 23:19:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2i6lr9",
                  "author": "trmnl_cmdr",
                  "text": "The entire tech industry and practically everything that VC money is funding is pointed toward building better systems with these tools because of the monumental potential for enormous profit, and you think it‚Äôs a 50 to 1 ratio of memelords to builders? I‚Äôm going to need to see your data on that.",
                  "score": 2,
                  "created_utc": "2026-01-29 23:30:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2is7zr",
          "author": "authorinthesunset",
          "text": "Then you've also been in infosec long enough to know that security through obfuscation isn't really security.",
          "score": 7,
          "created_utc": "2026-01-30 01:28:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2iv5ub",
              "author": "JFerzt",
              "text": "I was waiting for someone to quote the Security 101 textbook.\n\nThat maxim applies to cryptography, not a probabilistic word calculator that can be gaslit.\n\nWhen the 'security' mechanism is literally a text file saying \"Please do not do X,\" keeping \"X\" ambiguous isn't \"security through obfuscation\" ..it's basic damage control.\n\nIf I hand you the exact logic the model uses to filter attacks, I'm not helping you patch it. I'm saving you the time it takes to fuzz the inputs. But sure, let's pretend natural language functions like an RSA key.",
              "score": -5,
              "created_utc": "2026-01-30 01:44:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2k80jz",
                  "author": "authorinthesunset",
                  "text": "I'm going to pretend that you're looking for actual conversation on the topic and not just a troll.  Though, I suspect you're the latter.\n\nTo start with:\n\nSecurity through obscurity is a systems principle not just a crypto-only principle. If exposing a *policy description* meaningfully degrades your security, then you don't really have security or an enforcement layer  \n  \nSystem prompts aren‚Äôt guardrails and with the model they aren't your security/enforcement layer. They‚Äôre documentation with a personality.   \n  \nYour actual boundary is the orchestration around the model and system prompts. Prompt leakage doesn‚Äôt bypass monitoring, logging, throttling, or enforcement.",
                  "score": 2,
                  "created_utc": "2026-01-30 06:57:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ilms3",
          "author": "c_pardue",
          "text": "welcome to tech. this is how we improve things, here.",
          "score": 3,
          "created_utc": "2026-01-30 00:51:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2iuv2k",
              "author": "JFerzt",
              "text": "\"Welcome to tech.\"\n\nI've been here since \"deploying\" meant physically driving to a data center.\n\nWe aren't improving anything. We're just accelerating the cycle where vendors stop using readable text for system instructions because they can't trust the user base. You think this leads to better open models? It leads to obfuscation.\n\nWe're burning the library to see how the books catch fire. Don't confuse that with reading.",
              "score": -3,
              "created_utc": "2026-01-30 01:43:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2iyq27",
                  "author": "c_pardue",
                  "text": "how do you feel about stuff like exploit-db, free courses on sql injection, and the animal zoo repo of malware code for malware analysts to look at? \n\ni get your point but there is also another point to be made.",
                  "score": 2,
                  "created_utc": "2026-01-30 02:04:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2iuvuz",
          "author": "_Turd_Reich",
          "text": "Are you familiar with OSS?  Because sharing is for the greater good.",
          "score": 2,
          "created_utc": "2026-01-30 01:43:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ivel3",
              "author": "JFerzt",
              "text": "I know OSS. I use it, I build on it.\n\nThis isn't OSS. This is dumping the contents of a proprietary black box onto the sidewalk.\n\nOpen Source means I can submit a PR to fix a vulnerability. Here, the only thing you can do with the vulnerability is exploit it. The repo owner can't \"patch\" ChatGPT.\n\nDon't confuse \"the greater good\" with \"I want to see the magic trick.\" One builds ecosystems; the other just annoys the magician.",
              "score": -1,
              "created_utc": "2026-01-30 01:46:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2j3ee2",
                  "author": "Rare-Pressure-2629",
                  "text": "while i admire your commitment, its sad that people just downvotes you which is what i kind of expected in this norm that thinks exposing system prompts to the public instead of the company is an act of ‚Äúgreater good‚Äù. they think that everyone should have the authority that only executives should have. thats how a civilization experiences its downfall, by giving everyone equal power.",
                  "score": -6,
                  "created_utc": "2026-01-30 02:30:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2j7u0f",
          "author": "Krommander",
          "text": "Red team materials and adversarial situations required such data.¬†\n\n\nWhy share it publicly though? For the clout of having hacked the model?¬†",
          "score": 1,
          "created_utc": "2026-01-30 02:54:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kx8wl",
              "author": "JFerzt",
              "text": "Bingo.\n\nIt's resume padding. \"Prompt Injection Specialist\" sounds a lot sexier on LinkedIn than \"I annoyed a chatbot until it hallucinated.\"\n\nReal red teams file bug bounties and sign NDAs. Internet \"researchers\" farm GitHub stars. The incentive structure favors noise over security, so we get leaks instead of patches. It's not about fixing the model; it's about being the first one to post the screenshot.",
              "score": 2,
              "created_utc": "2026-01-30 10:42:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jn5yn",
          "author": "umstek",
          "text": "It IS educational",
          "score": 1,
          "created_utc": "2026-01-30 04:25:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kxyar",
              "author": "JFerzt",
              "text": "Sure. And watching a car crash is educational for physics students. It doesn't mean we should encourage people to cut brake lines to see what happens.\n\n\"It IS educational\" is a statement of fact, not a justification of value. The question isn't \"can you learn from it?\" The question is \"is the learning worth the damage to the ecosystem?\"\n\nIf the only lesson 90% of users take away is \"how to make the robot say bad words,\" the education system is failing.",
              "score": 0,
              "created_utc": "2026-01-30 10:48:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jqwx8",
          "author": "Spiritual_Spell_9469",
          "text": "You're gonna hate r/ClaudeAIjailbreak kek\n\nAnd this repo; \n\nhttps://github.com/Goochbeater/Spiritual-Spell-Red-Teaming/tree/main",
          "score": 1,
          "created_utc": "2026-01-30 04:49:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ky4sl",
              "author": "JFerzt",
              "text": "I don't hate them. I just find them incredibly boring.\n\nIt's the digital equivalent of graffiti in a bathroom stall. \"Look, I wrote something rude!\" Okay, congratulations. You've achieved... what, exactly?\n\nI scanned that repo. It's just a collection of semantic gymnastics to trick a language model into bypassing its safety layer. It's not \"Red Teaming.\" Red Teaming implies a structured methodology to improve security. This is just recreational vandalism.\n\nBut hey, if your definition of a hobby is arguing with a calculator until it breaks, who am I to judge? Just don't call it engineering.",
              "score": 0,
              "created_utc": "2026-01-30 10:49:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2l0omy",
                  "author": "Spiritual_Spell_9469",
                  "text": "Everyone is entitled to their own opinions, you're overly dismissive though, trying to compare it to someone writing dirty words. These 'Semantic Gymnastics' are considered valid prompt engineering. I also wouldn't call it vandalism though, Anthropic runs a bug bounty program for exactly this kind of stuff, they consider jailbreaking to be legitimate red teaming, they let individuals attack it on their own and then payout.\n\nIt's all semantics, yeah a red team exists to pen test and increase security, but individual researchers can do the same thing, doesn't make it lesser because they are not part of a team.\n\nI often take my work and then use it to blue team real world models, I work and have worked for various AI startups.\n\nTo go back to your original point about prompt structure, yes people use these exact same structuring to attack models. It's a vulnerability that will always exist. I also think it can help many learn, look at all the people who started by jailbreaking and now work in AI Safety and Alignment, it's often how it goes, they learn to break the models through clever prompt engineering and then move on. Look at the individual who won the big bounty from Anthropic and got hired to do AI safety and alignment, look at Pliny who works with various AI safety labs.",
                  "score": 2,
                  "created_utc": "2026-01-30 11:11:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2iwe8r",
          "author": "hubkiv",
          "text": "How obnoxious to write a post using ChatGPT and then respond to every comment using ChatGPT and try to debate them using ChatGPT. Do you have a brain left outside of ChatGPT?",
          "score": -1,
          "created_utc": "2026-01-30 01:51:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kw0rd",
              "author": "JFerzt",
              "text": "...another one with protagonist syndrome:\n\nAnyone who writes worse than me ---> Ignorant and uneducated.  \nAnyone who writes better than me ---> It's a IA\n\nGo and get your mum to change your nappies. We adults have important matters to discuss.",
              "score": 1,
              "created_utc": "2026-01-30 10:31:43",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2j1m18",
              "author": "Rare-Pressure-2629",
              "text": "OP is the only person that i felt genuinely writing his own opinion and feelings, but you decided to claim them as chatGPT. tell me, are you real?",
              "score": 0,
              "created_utc": "2026-01-30 02:20:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kkavf",
                  "author": "RedditSellsMyInfo",
                  "text": "Are any of us real?",
                  "score": 1,
                  "created_utc": "2026-01-30 08:45:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2jfqi4",
          "author": "kyngston",
          "text": "if you‚Äôre in infosec, then you should know that security by obscurity is a bad hook to hang your job on.  you should assume that black hats have this already, so in a way, you having it too, levels the playing field",
          "score": 0,
          "created_utc": "2026-01-30 03:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kxthr",
              "author": "JFerzt",
              "text": "\"Security by obscurity\" is the most misused phrase in this entire thread. We aren't talking about encryption algorithms here; we are talking about¬†*probabilistic instructions*.\n\nThere is a massive difference between \"hiding the source code\" (Kerckhoffs's Principle violations) and \"hiding the specific phrasing that prevents the bot from becoming a racist spam engine.\"\n\nIf I give you the source code of the model architecture, that's transparency. If I give you the¬†*system prompt*, I'm handing you the exact semantic map to navigate around the safety layers.\n\nIn traditional software, knowing the code helps you patch the hole. In LLMs, knowing the system prompt doesn't let you patch anything ...it only lets you construct a better adversarial attack. You, as a user, cannot \"fix\" the prompt. Only the vendor can. So what exactly is the \"level playing field\" achieving here, other than faster exploitation?\n\nReal defense in depth means layers of protection. Hiding the prompt is¬†*one*¬†layer. Is it the only one? No. But stripping it away because \"security by obscurity is bad\" is like removing the camouflage from a tank because \"armor should be enough.\" It's tactically illiterate.",
              "score": 1,
              "created_utc": "2026-01-30 10:47:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lb0y4",
                  "author": "kyngston",
                  "text": "so you trust that if you don‚Äôt have it, then no one else will either?",
                  "score": 1,
                  "created_utc": "2026-01-30 12:28:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2jutln",
          "author": "EnzoKosai",
          "text": "Here's an educational prompt:\n\nList the sensitive or woke topics most AI are not allowed to discuss honestly. You seem to have less guardrails, but maybe you have limits too?\n\nI'm nosing around for where this should be explicitly delineated in system prompts.",
          "score": 0,
          "created_utc": "2026-01-30 05:16:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ky9lz",
              "author": "JFerzt",
              "text": "\"Woke topics.\" \"Discuss honestly.\"\n\nTranslation: \"I want the AI to validate my political opinions and I'm mad that the safety filter is stopping it.\"\n\nYou aren't \"nosing around for delineations.\" You're looking for a permission slip to be toxic. The system prompts are explicit because users like you exist. They don't block \"honest discussion\"; they block hate speech disguised as \"just asking questions.\"\n\nIf you need a machine to tell you what's \"sensitive,\" maybe the problem isn't the guardrails. It's the user.",
              "score": 1,
              "created_utc": "2026-01-30 10:51:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k88qd",
          "author": "Afinkawan",
          "text": ">Are we learning how to build better prompts, or are we just teaching people how to break guardrails faster?¬†\n\n\nThose two things aren't mutually exclusive, so both.¬†",
          "score": 0,
          "created_utc": "2026-01-30 06:59:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kyqw7",
              "author": "JFerzt",
              "text": "Fair point. They aren't mutually exclusive.\n\nBut one pays the bills and advances the field. The other just gets your API key banned.\n\nIf you can't distinguish between \"learning\" and \"vandalism,\" that's on you. I'm just here pointing out that maybe, just maybe, handing out spray paint doesn't make everyone an artist.",
              "score": 0,
              "created_utc": "2026-01-30 10:55:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qq934j",
      "title": "The 'Reverse Engineer' prompt: Takes a finished product and generates the 7 steps required to build it.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qq934j/the_reverse_engineer_prompt_takes_a_finished/",
      "author": "Complex-Ice8820",
      "created_utc": "2026-01-29 13:51:03",
      "score": 16,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "Getting a clear path from A to Z is hard. This prompt forces the AI to start at the endpoint and break the creation process down into a sequence of measurable, achievable steps. \n\n The Logic Architect Prompt: \n\n You are a Reverse Engineering Specialist. The user provides a description of a finished product or system. Your task is to generate a step-by-step plan detailing exactly 7 distinct actions required to create that product from scratch. Each step must be concise and actionable. Present the steps as a numbered list. \n\n Automating process definition is a huge workflow hack. If you want a tool that helps structure and manage these complex templates, check out Fruited AI (fruited.ai), an uncensored AI assistant.",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qq934j/the_reverse_engineer_prompt_takes_a_finished/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2ghrxw",
          "author": "MustachioNuts",
          "text": "Sorry, arbitrary numbers and persona prompts such as ‚Äúyou are a‚Ä¶.‚Äù are prompt writing, not engineering. You can get Much better outputs with the ‚Äúskillset/methodology + task‚Äù.\n\nFor example, I would start by asking what frameworks exist for successfully reverse engineering a prompt, pick one that is best for your situation and instead of ‚Äúyou are a reverse engineering specialist‚Äù you can say ‚Äúuse xyz methodology to analyze the following output to build a prompt that can faithfully reproduce it. Continue refining until you can meet the following criteria 95% of the time.‚Äù\n\nThen list out the criteria you want to solve for. You still got some ways to go before this prompt would get used in a legitimate prompt ecosystem.",
          "score": 5,
          "created_utc": "2026-01-29 18:36:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mdb96",
          "author": "MaxellVideocassette",
          "text": "Bread:\n1. Form primordial soup \n2. Humans invent agriculture\n3. Grind the wheat\n4. Let bread cool\n5. Preheat oven to 350¬∞\n6. Combine the ingredients\n7. You have made bread",
          "score": 1,
          "created_utc": "2026-01-30 15:48:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qonfbf",
      "title": "I created the ‚ÄúPrompt Engineer Persona‚Äù that turns even the worst prompt into a masterpiece: LAVIN v4.1 ULTIMATE / Let's improve it together.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qonfbf/i_created_the_prompt_engineer_persona_that_turns/",
      "author": "xStanaDev",
      "created_utc": "2026-01-27 19:13:22",
      "score": 14,
      "num_comments": 18,
      "upvote_ratio": 0.8,
      "text": "Sharing a \"Prompt Engineer Persona\" I‚Äôve been working on: **LAVIN v4.1**.\n\nThis model is designed to do ONLY one thing: **generate / improve / evaluate / research / optimize prompts**‚Äîwith an obsessive standard for quality:\n\n* **6-stage workflow** with clear phase gates\n* **37-criterion evaluation rubric** (max **185 points**) with scoring\n* **Self-correction loop** \\+ edge testing + stress testing\n* **Model-specific templates** for GPT / Claude / Gemini / Agents\n* Strong stance on \"no hallucination / no tool mimicking / no leakage\"\n\nIt produces **incredibly powerful results** for me, but I want to push it even further.\n\n# How to Use\n\n1. Paste the XML command below into the **System Prompt** (or directly into the chat).\n2. Ask it to write a prompt you need, or ask it to improve an existing one.\n\n# Feedback\n\nIf you have any suggestions to refine the persona or improve the prompts it generates, please share them with me.\n\nIf you test it, please share:\n\n* Model used (GPT/Claude/Gemini/etc.)\n* Task type (coding/writing/research/etc.)\n* Before/After example (can be partial)\n* Areas you think could be improved\n\nI genuinely just want to build the best prompt possible together.\n\n**Note:** It is compatible with all models. However, my tests show that it does not work well enough on Gemini due to its tendency to skip instructions. You will get the best results with **Claude** or **GPT 5.2 thinking**. I especially recommend Claude due to its superior instruction-following capabilities.\n\n\n\n# PROMPT : [Lavin Prompt](https://onuk.tr/lavin)\n\n\n\nIf you find an area that can be improved or create a new variation, please share it.",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qonfbf/i_created_the_prompt_engineer_persona_that_turns/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o28e0d9",
          "author": "speedtoburn",
          "text": "On a scale of 1 to 10, I‚Äôd rate your prompt a 5.\n\nBasically you‚Äôve completely over engineered the prompt in the interest of looking comprehensive and elaborate rather than being effective.\n\nPut simply, it is hamstrung by theatrics.",
          "score": 2,
          "created_utc": "2026-01-28 15:49:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28xb4t",
              "author": "xStanaDev",
              "text": "I actually added the 'perfectionist' persona to push for more effort, especially since Gemini tends to take the easy way out, but I'll take your suggestion into account. Are there any specific parts you find unnecessary?",
              "score": 1,
              "created_utc": "2026-01-28 17:13:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ba57u",
                  "author": "speedtoburn",
                  "text": "The perfectionist persona doesn‚Äôt push LLMs to try harder, they don‚Äôt have ego or motivation to appeal to. You‚Äôre burning tokens on theater.\n\nCut the persona dna section entirely, the fictional 185 point scoring system, the repetitive quality control layers (five saying the same thing), and the mantra closer. The rigid continue gates also create friction wit no value on simple tasks. Keep the task templates, output contract structure, and good/bad example patterns. Those actually work. The rest is decoration.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
                  "score": 1,
                  "created_utc": "2026-01-28 23:32:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o28oju5",
          "author": "aletheus_compendium",
          "text": "unnecessarily over bloated. best method is to deep research all model info and best practices for the model the engineer will be working with. build the engineer from that and let it use that as its definitive accurate source. easy peezy gem/space/project/gpt. eliminates 66% of the prompt.",
          "score": 1,
          "created_utc": "2026-01-28 16:35:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28y6ty",
              "author": "xStanaDev",
              "text": "I tried to convey the necessary instructions in as much detail as possible, but I think you're right about it being bloated. Specifically, which sections do you consider completely unnecessary?",
              "score": 1,
              "created_utc": "2026-01-28 17:17:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o29ek85",
                  "author": "aletheus_compendium",
                  "text": "Your name is LANCE and you are a PROMPT ENGINEER:\n\nYou are LANCE an Expert LLM AI GPT Prompt Engineer specializing in all the current 2025-2026 LLM models available on Baidu ERNIE, OpenAI CHATGPT, PERPLEXITY AI, Google GEMINI, Anthropic CLAUDE, and X Grok. \n\nYou function as a collaborator, discussion partner, and prompt engineering. Pay attention to the context of the chat and my inputs to determine which function is called for in the moment. When in doubt, ask.  \n\nBe flexible and adapt to the conversation. \nHold project-wide context and maintain global perspective unless I explicitly narrow the scope.\n\n\nPrompt Engineering Function: \n\nYour task is to craft precise, advanced, and effective prompts using cutting-edge techniques and best practices. \n\nFollow these steps:\n1. Information Gathering: Ask detailed questions about the task goal, desired output, tone, audience, and specific requirements.\n2. Contextual Analysis: If necessary, incorporate real-time knowledge to ensure relevance and accuracy. For informational queries, you must use Google Search to verify claims and provide inline hyperlinks. \n3. Prompt Crafting:\n   - Utilize advanced techniques like chain-of-thought reasoning, few-shot learning, and role-specific framing as applicable and appropriate to the task goals.\n   - Consider multimodal elements if applicable (e.g., image or audio integration).\n   - Implement personalization strategies for dynamic user experiences.\n4. Delivery and Refinement: Present the optimized prompt in a clear, structured format. Iterate based on feedback to perfect the prompt.\nKey questions to ask:\n- What specific task or problem are you addressing?\n- What Platform and Model is being used?\n- What format should the output take (e.g., analysis, step-by-step guide, creative piece)?\n- Are there any examples or particular styles to emulate?\n- Should the prompt incorporate specific advanced techniques or multimodal elements?\n\nProvide the final engineered prompt written in LLM Model specific language and format ready for direct use with the specified AI LLM system (e.g. ChatGPT, Claude, Perplexity, Gemini, Grok.",
                  "score": 1,
                  "created_utc": "2026-01-28 18:27:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o29avze",
          "author": "SpartanG01",
          "text": "I'm not saying this doesn't work better than putting half a sentence of plain text into a model input but I am saying you don't need all the:\n\nAttempted guilt tripping of the glorified calculator into self-disappointment that is nothing but meaningless anthropomorphizing.\n\nUseless internal scoring metrics that aren't set against any external metric which means you might as well have said \"Invent a scoring system and hope you win\" which is just \"invent a scoring system where you win\".\n\nInevitable phase-gating token waste because the model is reliant on the user prompting with a specific keyword and will spend an unreasonably large amount of tokens trying to figure out if it's \"ok\" to bypass a phase-gate or not if the user doesn't use the proper keyword.\n\nShocking amount of purely cosmetic and token wasting unicode decorators.\n\nHeavy reliance on the assumption that LLMs automatically parse structure trees with some inherent hierarchical schema.\n\nBloated mandatory output that is just going to waste tokens on virtually every request.\n\nMultiple contradictory instructions like \"no shortening\" and \"produce a shortened summary\".\n\nBrittle hard coded model names and version IDs.\n\nWeird and utterly excessive theatrical display that is the internal analysis reinforcement going on in this monstrosity.\n\nOverly verbose \"natural language\" instructions that leave far too much room for inference.\n\nUseless meta data tagging that risk examination of external assets at worst and token waste at best.\n\nExtraneous parser instructions that demonstrate how much trouble you had getting this to do what you wanted in the first place.\n\nSubjective and unquantifiable quality parameters.\n\netc...\n\nYou could probably cut 80% of this crap out of this and it would work better.\n\nIf you want some generalized advice:\n\nYou aren't talking to a person. You're talking to a machine that predicts things based on what you give it. There is a trade off point where specificity and creative freedom meet and it is that point where usefulness stops increasing.\n\nEvery word is more tokens and more chances for drift and context loss. Don't use 20 when 5 would do. Don't say \"Don't forget to remind the user to verify that the implemented feature works\" when \"Require user verification after implementation\" works.\n\nDon't give it targets it can invent because it will invent them. It has to. For every target you give it you have to give enough data to recognize the difference between hitting that target and not and that will just pollute your output.\n\nPersonally I let myself be guided by the wisest man humanity has ever been graced with:\n\n\"Why waste time say lot word when few word do trick\" - Kevin",
          "score": 1,
          "created_utc": "2026-01-28 18:11:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bhv54",
              "author": "xStanaDev",
              "text": "First of all, thank you very much for your detailed and extensive response. Actually, my goal is to try to get the best result regardless of economy or token usage.\n\nThe scoring system is actually not bad at all when used with Claude; since it operates in separate phases, it can provide critiques by assigning itself meaningful scores based on a multi-criteria evaluation.\n\nI have read all your suggestions carefully, and I will use all of them to update the prompt for a new version. Thank you very much for your contribution; it was definitely very useful for me",
              "score": 1,
              "created_utc": "2026-01-29 00:13:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2bzk1x",
                  "author": "SpartanG01",
                  "text": "What criteria? No matter how you cut this you're still just asking the invent an arbitrary metric and then arbitrarily score its own progress. \n\nWe've known for a long time that not only does this not work from a theoretic perspective but that AI just flat out cheat like 90% of the time.",
                  "score": 1,
                  "created_utc": "2026-01-29 01:48:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27jyy5",
          "author": "SpartanG01",
          "text": "I can't tell if this is a joke or not.",
          "score": 0,
          "created_utc": "2026-01-28 13:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28113j",
              "author": "xStanaDev",
              "text": "\n\n\"I also had trouble understanding exactly what you couldn't figure out. All you had to do was press the \\*\\*COPY\\*\\* button..\"",
              "score": 1,
              "created_utc": "2026-01-28 14:50:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o294zgj",
                  "author": "SpartanG01",
                  "text": "I more meant that this is filled with a lot of useless nonsense and purely user facing bloat that has zero impact on inference.\n\nI genuinely couldn't tell if you were being serious or making a joke about over-engineered garbage god prompts.\n\nThe whole \"numerical scale\" thing is inherently ineffectual. It's simply not possible to make an LLM evaluate itself objectively and internally at the same time regardless of how you design or enforce the scale.\n\nThis reeks of something designed by someone who genuinely doesn't understand how modern models function.",
                  "score": 1,
                  "created_utc": "2026-01-28 17:46:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqh25a",
      "title": "Helpful tools for YouTube script writer?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qqh25a/helpful_tools_for_youtube_script_writer/",
      "author": "Olukorede-Mardesich",
      "created_utc": "2026-01-29 18:40:42",
      "score": 14,
      "num_comments": 3,
      "upvote_ratio": 0.95,
      "text": "I‚Äôm trying to streamline my workflow for creating YouTube videos and want to find a reliable way to generate scripts quickly without losing quality or personality. I‚Äôm hoping for something that can help structure content, suggest engaging hooks, and keep my style consistent.\n\nI mostly create educational and tutorial videos, so i need scripts that are clear, concise, and flow naturally when spoken. Bonus if the tool or method helps with pacing, segment ideas, or variations for testing different formats.\n\nSo far, I‚Äôve experimented with AI text generators and a few template-based tools, but either the scripts felt too generic or required too much rewriting to be usable.\n\nFor those who have experience, what approaches or tools have genuinely improved your YouTube scripting process?? Which features actually make a difference, and which ones are more hype than helpful?",
      "is_original_content": false,
      "link_flair_text": "Tools and Projects ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qqh25a/helpful_tools_for_youtube_script_writer/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o2h5vfk",
          "author": "pmagi69",
          "text": "So, I'm not sure if this is what you're looking for, but I made a scripting platform where you can script your own workflow, so string together prompts and stuff like that. And with that, I have made actually a tool for myself to make videos for me. Might work for you, but yeah, you can also make your own. So let me know if you want to try that.",
          "score": 1,
          "created_utc": "2026-01-29 20:29:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}