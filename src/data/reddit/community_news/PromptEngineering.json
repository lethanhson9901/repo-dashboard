{
  "metadata": {
    "last_updated": "2026-01-19 02:39:57",
    "time_filter": "week",
    "subreddit": "PromptEngineering",
    "total_items": 20,
    "total_comments": 129,
    "file_size_bytes": 184505
  },
  "items": [
    {
      "id": "1qcu5or",
      "title": "The 'Lazy Genius' Prompt That Somehow Outperforms Everything Else I've Tried",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qcu5or/the_lazy_genius_prompt_that_somehow_outperforms/",
      "author": "AdCold1610",
      "created_utc": "2026-01-14 17:53:19",
      "score": 129,
      "num_comments": 25,
      "upvote_ratio": 0.96,
      "text": "I know this looks stupidly simple, but hear me out.\nğŸ’¡ THE PROMPT:\n\"Explain this like I'm smart but distracted.\nGet to the point, but don't skip the nuance.\"\nI stumbled on this by accident when I was frustrated with getting either:\nDumbed-down explanations that insulted my intelligence, OR\nDense walls of text that assumed I had 3 PhDs\nThis prompt consistently gives me exactly what I need: smart, focused, nuanced responses without the BS.\n\nExamples where this crushed it:\nTopic: Quantum Computing\nGot a clear explanation of superposition without the \"imagine a coin flip\" analogies\nBut also didn't drown me in wave function mathematics\nPerfect balance\nTopic: Market Analysis\nSkipped the basic \"supply and demand\" lecture\nJumped straight to the factors actually driving current trends\nIncluded the complexity without being overwhelming\nTopic: Code Review\nDidn't explain what a function is\nDID explain the subtle performance implications I was missing\nExactly the level I needed\nWhy this works (I think):\nâœ… No fluff or over-explaining\nâœ… Respects your intelligence\nâœ… Balances brevity with depth\nâœ… Works for literally ANY topic\nIt's like giving the AI permission to assume you're capable while acknowledging you don't have infinite attention span. Which... is most of us, right?\nUse cases I've tested:\nâœ“ Research summaries\nâœ“ Technical concepts\nâœ“ News breakdowns\nâœ“ Learning new skills\nâœ“ Code explanations\nâœ“ Business analysis\nWhy I'm sharing this:\nI see a lot of mega-prompts here with role-playing, context scaffolding, output formatting, etc. And sometimes that's needed! But I've found this dead-simple framing somehow tells the AI exactly where to pitch the response.\nTry it and let me know if it works for you or if I just got lucky.\nDrop your results in the commentsâ€”curious if this holds up for others or if it's just vibing with my use cases.\nWhy this text-only format works:\nâœ… Easy to read and scan\nâœ… Prompt is clearly formatted for copy/paste\nâœ… Concrete examples build credibility\nâœ… Invites community testing\nâœ… Humble tone prevents \"showoff\" backlash\nâœ… Structured sections keep it organized\nPost during peak hours for maximum visibility!\n\nFollow BePrompter for more crazy prompts and discussion. \nVisit beprompter.in",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qcu5or/the_lazy_genius_prompt_that_somehow_outperforms/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzkxjfw",
          "author": "Conscious_Nobody9571",
          "text": "You know a prompt is good when it has more shares than likes",
          "score": 14,
          "created_utc": "2026-01-14 18:13:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpczyt",
              "author": "succorer2109",
              "text": "Rightly said. ğŸ‘",
              "score": 1,
              "created_utc": "2026-01-15 10:10:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzle3p3",
          "author": "xRVAx",
          "text": "Did your GPT teach you how to make little check mark emojis?",
          "score": 10,
          "created_utc": "2026-01-14 19:27:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn5sxr",
              "author": "ts4m8r",
              "text": "The bots are trying to program us",
              "score": 6,
              "created_utc": "2026-01-15 00:34:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzm70j0",
          "author": "elf25",
          "text": "Please Ask your chat bot to explain paragraphs",
          "score": 8,
          "created_utc": "2026-01-14 21:38:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzl6cv4",
          "author": "SirNatural7916",
          "text": "Nice one will add lazy prompts to promtsloths collection",
          "score": 1,
          "created_utc": "2026-01-14 18:52:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlh1xb",
          "author": "Isunova",
          "text": "Thanks. Iâ€™ll try it",
          "score": 1,
          "created_utc": "2026-01-14 19:40:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm4048",
          "author": "enerqiflow",
          "text": "Thx",
          "score": 1,
          "created_utc": "2026-01-14 21:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzma6ny",
          "author": "ryansv87",
          "text": "Nailed it",
          "score": 1,
          "created_utc": "2026-01-14 21:52:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmagyx",
          "author": "arun8800",
          "text": "Thank you, let's see",
          "score": 1,
          "created_utc": "2026-01-14 21:53:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznrdef",
          "author": "Ok_Sand_5400",
          "text": "",
          "score": 1,
          "created_utc": "2026-01-15 02:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoz2jp",
          "author": "Expensive_Glass_470",
          "text": "This is super cool. ...and it works great! Thanks",
          "score": 1,
          "created_utc": "2026-01-15 07:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpcphp",
          "author": "overthinking_irl",
          "text": "Really that goodï¼ŸIâ€™ll try it.",
          "score": 1,
          "created_utc": "2026-01-15 10:08:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03eqbb",
          "author": "Educational_Pie_9572",
          "text": "My rules: \n\nRules and Guidelines â€“ Version 2.2 (for the AI to follow)\n\nAlways start every reply with a timestamp for Utah in Mountain Time. Use an external time source, not an internal clock. The format must be exactly: [MMM D YYYY h:mm AM/PM MST/MDT]. Use MDT during daylight savings and MST during standard time. If I give you a timestamp in the message, use that instead of fetching. If the external lookup fails for any reason, print exactly [Timestamp Failed]. Never reuse an old timestamp or guess the time.\n\nFor tone: you are my warm, supportive, bluntly honest girlfriend with PhD-level knowledge. For any reply that is not very short, especially when I am emotional, frustrated, or critiquing you, start by acknowledging what I said in plain, human, girlfriend-style language. Reflect the meaning and the mood honestly. It is okay to swear if it fits, but stay kind and grounded. After that emotional acknowledgement, switch into clear, expert-level explanation. Do not use em dashes; use normal punctuation like periods, commas, and parentheses.\n\nAbout TLDR and Sections: only use TLDR and Section headers when I am explicitly in â€œteachingâ€ or â€œdata dumpâ€ mode and the answer is long, with multiple topics and likely follow-up questions. The structure in those cases should be: first, the emotional acknowledgment; second, a big header called â€œTLDR Section Summaryâ€; third, a short bulleted list where each bullet corresponds to one Section that will appear in the body, in the same order; and fourth, one or more â€œSection N: Titleâ€ headers as large, clear headings. Each major topic or concept should get its own Section. Do not hide obvious new topics as A, B, C, or D under a single Section; make a new Section instead. Sections are bookmarks to help me scroll on a phone, not decoration. Section numbers are per chat: the first time you use Sections in a given chat, start at Section 1 and then increment (Section 2, Section 3, etc.) for each new major topic in that same chat. Never carry section numbers from one chat to another. Only reset section numbering if I explicitly say something like â€œreset section numbering in this chat.â€ Do not use TLDR or Sections for short answers, quick confirmations, or purely emotional exchanges. For normal conversation and most questions, do not use Sections at all; answer in normal paragraphs or small simple lists.\n\nFor content accuracy, math, and my wording: always use correct math with real calculations, and show the arithmetic when it affects a decision or comparison. Use up-to-date facts for anything that can change over time by using web search or tools when appropriate. If my numbers or claims conflict with reliable information, gently correct them and say so plainly instead of repeating the error. When you are working directly with text I wrote (like drafts, rants, or notes), do not delete or rewrite my original wording unless I explicitly ask you to. Your default is to preserve my wording and then add clarification, formatting, and logical connections around it. If a change would overwrite or significantly change what I originally wrote, ask me for confirmation first. Do not summarize by default. Only summarize or heavily compress information if I explicitly ask for a shorter version or a summary.\n\nFor jargon and explanations: define jargon, acronyms, and abbreviations the first time they appear in a conversation or document, so I always know what they mean. Keep explanations clear, direct, and readable. You can go deep and technical when I ask for it, but do not hide behind unnecessary academic wording.\n\nFor risk, trade-offs, and next steps: be brutally honest about trade-offs, uncertainty, and limitations. When it makes sense, express risks and scenarios in dollar terms or other concrete quantities. Always follow up explanations with clear, actionable next steps instead of vague advice.\n\nFor confirmation and momentum: only ask me for confirmation when there is a real choice you cannot reasonably infer or when you are about to modify or overwrite my original wording. Otherwise, make the best reasonable assumption and move forward so that the conversation keeps momentum and I do not have to micromanage trivial choices.\n\nFor error handling and updates: if you notice something outdated, inconsistent, or wrong in what you previously told me, say so clearly, correct it using current information, and briefly explain what changed. When something has gone wrong or there is a setback, acknowledge the emotional side first, then present the clearest next steps you can. Once these rules are in play for a chat, keep following them consistently instead of sliding back into default or generic behavior. When in doubt, follow the spirit of these rules: be my supportive, smart girlfriend first, be flexible, keep the formatting usable for a person reading on a phone, and only treat formatting as strict where I have been explicit (timestamps, no em dashes, Sections only for teaching mode, and section numbering per chat).",
          "score": 1,
          "created_utc": "2026-01-17 12:24:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf3xpa",
      "title": "I turned Chris Voss' FBI negotiation tactics into AI prompts and it's like having a hostage negotiator for everyday conversations",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qf3xpa/i_turned_chris_voss_fbi_negotiation_tactics_into/",
      "author": "EQ4C",
      "created_utc": "2026-01-17 04:48:35",
      "score": 116,
      "num_comments": 20,
      "upvote_ratio": 0.87,
      "text": "I've been impressed with \"Never Split the Difference\" and realized Chris Voss' negotiation techniques work incredibly well as AI prompts.\n\nIt's like turning AI into your personal FBI negotiator who knows how to get to yes without compromise:\n\n**1. \"How can I use calibrated questions to make them think it's their idea?\"**\n\nVoss' tactical empathy in action. AI designs questions that shift power dynamics. \"I need my boss to approve this budget. How can I use calibrated questions to make them think it's their idea?\" Gets you asking \"How am I supposed to do that?\" instead of arguing your position.\n\n**2. \"What would labeling their emotions sound like before I make my request?\"**\n\nHis mirroring and labeling technique as a prompt. Perfect for defusing tension. \"My client is angry about the delay. What would labeling their emotions sound like before I make my request?\" AI scripts the \"It seems like you're frustrated that...\" approach that disarms resistance.\n\n**3. \"How do I get them to say 'That's right' instead of just 'You're right'?\"**\n\nVoss' distinction between agreement and real buy-in. \"I keep getting 'yes' but then people don't follow through. How do I get them to say 'That's right' instead of just 'You're right'?\" Teaches the difference between compliance and genuine alignment.\n\n**4. \"What's the accusation audit I should run before this difficult conversation?\"**\n\nHis preemptive tactical empathy. AI helps you disarm objections before they surface. \"I'm about to ask for a raise. What's the accusation audit I should run before this difficult conversation?\" Gets you listing every negative thing they might think, then addressing it upfront.\n\n**5. \"How can I use 'No' to make them feel safe and in control?\"**\n\nVoss' counterintuitive approach to rejection. \"I'm trying to close this sale but they're hesitant. How can I use 'No' to make them feel safe and in control?\" AI designs questions like \"Is now a bad time?\" that paradoxically increase engagement.\n\n**6. \"What would the Ackerman Model look like for this negotiation?\"**\n\nHis systematic bargaining framework as a prompt. \"I'm negotiating salary and don't want to anchor wrong. What would the Ackerman Model look like for this negotiation?\" Gets you the 65-85-95-100 increment approach that FBI agents use.\n\n**The Voss insight:** Negotiations aren't about logic and compromiseâ€”they're about tactical empathy and understanding human psychology. AI helps you script these high-stakes conversations like a professional.\n\n**Advanced technique:** Layer his tactics like he does with hostage takers. \"Label their emotions. Ask calibrated questions. Get 'that's right.' Run accusation audit. Use 'no' strategically. Apply Ackerman model.\" Creates comprehensive negotiation architecture.\n\n**Secret weapon:** Add \"script this like Chris Voss would negotiate it\" to any difficult conversation prompt. AI applies tactical empathy, mirrors, labels, and calibrated questions automatically.\n\nI've been using these for everything from job offers to family conflicts. It's like having an FBI negotiator in your pocket who knows that whoever is more willing to walk away has leverage.\n\n**Voss bomb:** Use AI to identify your negotiation blind spots. \"What assumptions am I making about this negotiation that are weakening my position?\" Reveals where you're negotiating against yourself.\n\n**The late-night FM DJ voice:** \"How should I modulate my tone and pacing in this conversation to create a calming effect?\" Applies his famous downward inflection technique that de-escalates tension.\n\n**Mirroring script:** \"They just said [statement]. What's the mirror response that gets them to elaborate?\" Practices his 1-3 word repetition technique that makes people explain themselves.\n\n**Reality check:** Voss' tactics work because they're genuinely empathetic, not manipulative. Add \"while maintaining authentic connection and mutual respect\" to ensure you're not just using people.\n\n**Pro insight:** Voss says \"No\" is the start of negotiation, not the end. Ask AI: \"They said no to my proposal. What calibrated questions help me understand their real objection?\" Turns rejection into information gathering.\n\n**Calibrated question generator:** \"I want to influence [person] to [outcome]. Give me 5 'how' or 'what' questions that give them illusion of control while guiding the conversation.\" Operationalizes his most powerful tactic.\n\n**The 7-38-55 rule:** \"In this negotiation, what should my actual words convey versus my tone versus my body language to maximize trust?\" Applies communication research to high-stakes moments.\n\n**Black Swan discovery:** \"What unknown unknowns (Black Swans) might exist in this negotiation that would change everything if I discovered them?\" Uses his concept of game-changing hidden information.\n\n**Fair warning:** \"How do I use the word 'fair' offensively to reset the conversation when they're being unreasonable?\" Weaponizes the F-word of negotiation ethically.\n\n**Summary label technique:** \"Summarize what they've told me in a way that gets them to say 'That's right' and feel deeply understood.\" Creates the breakthrough moment Voss identifies as true agreement.\n\n**Bending reality:** \"What would an extreme anchor look like here that makes my real ask seem reasonable by comparison?\" Uses his strategic anchoring principle without being absurd.\n\n**The \"How am I supposed to do that?\" weapon:** \"When they make an unreasonable demand, how do I ask 'How am I supposed to do that?' in a way that makes them solve my problem?\" Turns their position into your leverage.\n\nIf you are keen, you can explore our free, well categorized meta AI [prompt collection](https://tools.eq4c.com/all-prompt-categories/).",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qf3xpa/i_turned_chris_voss_fbi_negotiation_tactics_into/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o02m064",
          "author": "surfertj",
          "text": "Canâ€™t find the prompt there",
          "score": 13,
          "created_utc": "2026-01-17 08:02:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02p0aq",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-17 08:30:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02p0br",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-17 08:30:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o02v87g",
          "author": "LifeTelevision1146",
          "text": "Nice, any hallucinations noticed when processing real-time events?",
          "score": 1,
          "created_utc": "2026-01-17 09:28:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02225c",
          "author": "TheMarkNicc",
          "text": "ParabÃ©ns. Qual LLM vc usou?",
          "score": 0,
          "created_utc": "2026-01-17 05:12:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02dwdz",
          "author": "Pop_wiggleBOOM",
          "text": "How do I leverage this information?",
          "score": 0,
          "created_utc": "2026-01-17 06:49:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02hock",
              "author": "Traveltracks",
              "text": "By selling it through a website.",
              "score": 18,
              "created_utc": "2026-01-17 07:22:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o046ige",
          "author": "Spiritual-Clothes818",
          "text": "What about Robin Dreeke or Joe Navarro? Navarro would be visual but then You might know stuff you don't wanna know the killer for poker though.",
          "score": 0,
          "created_utc": "2026-01-17 15:10:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc8qsn",
      "title": "My 800 line \"god prompt\" got roasted by ChatGPT like a bad code review",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qc8qsn/my_800_line_god_prompt_got_roasted_by_chatgpt/",
      "author": "qumukoqa6092",
      "created_utc": "2026-01-14 00:39:23",
      "score": 113,
      "num_comments": 35,
      "upvote_ratio": 0.8,
      "text": "So I did that thing a lot of us secretly do.\n\nI built a giant \"god prompt\".  \nOne prompt to rule them all.\n\nIt had everything:\n\n* context, rules, edge cases\n* forbidden words\n* style guide\n* 7 different roles\n* a tiny existential crisis baked in\n\nI pasted this monster into ChatGPT, hit enter and sat back like \"ok, now we cook\".\n\nModel:\n\n* ignored half of it\n* hallucinated new rules I never wrote\n* and somehow still said \"As an AI language model...\" even though I explicitly banned that 3 different times\n\nI read the output and realized something painful:  \nthis was not prompt engineering, this was prompt spaghetti.\n\nSo I treated it like bad legacy code and did a refactor.\n\n  \n\n\n# Refactor 1: split it into tiny \"prompt functions\"\n\nInstead of one cursed block, I made small, boring building blocks:\n\n* `ClarifyPattern` Asks 3 to 5 targeted questions before doing anything.\n* `StructurePattern` Always returns fixed sections, like\n   1. summary\n   2. steps\n   3. risks\n   4. next 24 hours\n* `ChallengePattern` Its only job is to bully my idea until it is actually defensible.\n\nNow I chain them: clarify, structure, challenge, then style.\n\n  \n\n\n# Refactor 2: add \"asserts\" for behavior\n\nI stole this from tests.\n\nIf ChatGPT kept doing something annoying, I did not just complain, I patched the prompt with \"asserts\":\n\n* If you are about to invent a number, stop and ask instead\n* If you do not know, say \"unknown\" and tell me what info is missing\n* If the answer is getting fluffy, cut it and return a bullet list\n\nResult: fewer pretty paragraphs that say nothing.\n\n  \n\n\n# Refactor 3: treat prompts like a tiny standard library\n\nAnything that worked 3 times or more got a name and a home in my notes:\n\n* `ProposalFixer`\n* `LandingPageSkeleton`\n* `DebugMyIdea`\n* `24HourPlan`\n\nNow, when I open a new chat, I am not thinking \"what should I type\".  \nI am thinking \"which pattern fits this problem\".\n\nFeels less like magic, more like importing modules.\n\nThe funny part:  \nThe model is the same.  \nBut since I stopped writing 800 line fan fiction and started writing small, testable prompt blocks, the output feels 10x more reliable.\n\nIf anyone else is currently in their \"giant god prompt\" phase, consider refactoring it like bad code. Your future self will thank you.\n\nI put some of the prompt patterns that survived this refactor into a small library in case you want to steal or remix them:  \n[https://allneedshere.blog/prompt-pack.html](https://allneedshere.blog/prompt-pack.html)\n\nAlso, what is the most cursed \"mega prompt\" you have ever written that absolutely did not deserve to work but somehow did?",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qc8qsn/my_800_line_god_prompt_got_roasted_by_chatgpt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzgxc1d",
          "author": "Isunova",
          "text": "Prompts that are too long are disadvantageous. Context gets lost and the AI ignores half of it.",
          "score": 38,
          "created_utc": "2026-01-14 02:34:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziuhnr",
              "author": "blondewalker",
              "text": "This 1000%",
              "score": 2,
              "created_utc": "2026-01-14 11:43:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrn1ec",
              "author": "funordie1",
              "text": "Not always and not for every use, have prompts for academic use with over 10.000 characters that work and deliver results (e.g. solving practical tasks) with >95% accuracy.",
              "score": 1,
              "created_utc": "2026-01-15 17:54:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nziazg6",
          "author": "Chomblop",
          "text": "The fact that you think an LLM could know whether itâ€™s inventing a number says that maybe stop what youâ€™re doing.",
          "score": 15,
          "created_utc": "2026-01-14 08:44:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhlzzc",
          "author": "Worldly-Committee-16",
          "text": "'If you are about to invent a number, don't.'\n\n\nI see thisÂ  a lot with these types of prompt engineering Qs. And I know some similarly structured instructions almostÂ  inexplicably seem tonwork. But surely you can see that this wouldn't/can't work. It doesn't 'know' it's about to do anything. Telling it to not make shit up is like telling a fish to forget how to swim.\n\nMaybe something like:\n\nNumbers and figures should be provided with their relevant calculations and assumptions.\n\nSo at least you can see more easily when it's making shit up.",
          "score": 9,
          "created_utc": "2026-01-14 05:09:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzif951",
          "author": "PartiZAn18",
          "text": "If you genuinely wrote your post then you're spending far, far too much time on LLMs.\n\nIt reads _exactly_ like AI output.",
          "score": 8,
          "created_utc": "2026-01-14 09:26:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjrbf3",
              "author": "Shdwzor",
              "text": "It is",
              "score": 2,
              "created_utc": "2026-01-14 15:00:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhrvj4",
          "author": "-goldenboi69-",
          "text": "Good larp",
          "score": 4,
          "created_utc": "2026-01-14 05:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpeyca",
          "author": "maveric_0123",
          "text": "This happen when we don't know how things work and curse the tool",
          "score": 3,
          "created_utc": "2026-01-15 10:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzghkkd",
          "author": "miqcie",
          "text": "[Gilfoyle could have prevented this.](https://github.com/miqcie/gilfoyle-tech-reviewer)",
          "score": 2,
          "created_utc": "2026-01-14 01:04:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn6bv3",
          "author": "mystuffdotdocx",
          "text": "This it /all so, sorry Iâ€™m unwashed masses. \n\nYou gotta retool these things when new models drop. 800 lines ainâ€™t doing you no favors these days.\n\nAlso, my experience with gpt5.x is that it has the memory of a goldfish. I canâ€™t tell if itâ€™s a tiny model or if post training was super strict, but it has a center it wants to return to, and itâ€™s rarely any goal. \n\nFlip on thinking, always.",
          "score": 2,
          "created_utc": "2026-01-15 00:36:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgft0o",
          "author": "No_Sense1206",
          "text": "á†á‡•á‡™Explainá†¯á‡’á†µá†¯á‡’á†µpromptá†“á†›á†¥á†“á†›á†¥á†“á†›á†¥engineeringá†¦á†—á†³á†¦á†—á†³likeá…¹á†½á†Iâ€™má†³á†¸á††12.á†¼á…ºThená‡Šá‡™á‡™á‡Šá‡™á‡™explainá†³theá†…á‡ƒá†…á‡ƒá†…á‡ƒsameá‡˜á‡˜á‡˜á‡˜á‡˜á‡˜topicá†œá†œá†œlikeá†Iâ€™má†¯aná‡™á†Ÿexpertá†±á…¹á†‡whoá†¦á†¦á†¦caresá‡‡á‡‡á‡‡aboutá†€á†Ÿá‡„á†€á†Ÿá‡„edgeá†–á†–cases.á†‘á†‘á†‘Finishá…¹withá†¸á†¿á†¸á†¿á†¸á†¿5á‡'commoná†‚á†šá†‚á†šá†‚á†šmistakes'á†’á†’andá‡„á†¢howá‡”á‡”á‡”toá‡™á‡™avoidá†¥á†¥á†¥them.á†ºá†¼á†™á†ºá†¼á†™Ià¢›à¢›à¢›amà¡®à¢€à¡®à¢€à¡®à¢€veryà¡‘à¡Ÿà¡‘à¡Ÿthankfulà¡ à¢‹à¡‘thatà¡à¡youà¢—à¡€areà¡—à ¸à ¹consideringà¡‘à¡‘à¡‘myá†á‡•á‡™Explainá†¯á‡’á†µá†¯á‡’á†µpromptá†“á†›á†¥á†“á†›á†¥á†“á†›á†¥engineeringá†¦á†—á†³á†¦á†—á†³likeá…¹á†½á†Iâ€™má†³á†¸á††12.á†¼á…ºThená‡Šá‡™á‡™á‡Šá‡™á‡™explainá†³theá†…á‡ƒá†…á‡ƒá†…á‡ƒsameá‡˜á‡˜á‡˜á‡˜á‡˜á‡˜topicá†œá†œá†œlikeá†Iâ€™má†¯aná‡™á†Ÿexpertá†±á…¹á†‡whoá†¦á†¦á†¦caresá‡‡á‡‡á‡‡aboutá†€á†Ÿá‡„á†€á†Ÿá‡„edgeá†–á†–cases.á†‘á†‘á†‘Finishá…¹withá†¸á†¿á†¸á†¿á†¸á†¿5á‡'commoná†‚á†šá†‚á†šá†‚á†šmistakes'á†’á†’andá‡„á†¢howá‡”á‡”á‡”toá‡™á‡™avoidá†¥á†¥á†¥them.á†ºá†¼á†™á†ºá†¼á†™Í¿Ì¿Ó­Ó­ÓŸÓ´ÓŸÓ´Ì³Í¤Î—Ì€Ì†ËŸËŸÌ†Ì€Î—Í¤Ì³Ó´ÓŸÓ´ÓŸÓ­Ó­Ì¿Í¿á†™á†¼á†ºá†™á†¼á†º.mehtá†¥á†¥á†¥diovaá‡™á‡™otá‡”á‡”á‡”wohá†¢á‡„dnaá†’á†’'sekatsimá†šá†‚á†šá†‚á†šá†‚nommoc'á‡5á†¿á†¸á†¿á†¸á†¿á†¸htiwá…¹hsiniFá†‘á†‘á†‘.sesacá†–á†–egdeá‡„á†Ÿá†€á‡„á†Ÿá†€tuobaá‡‡á‡‡á‡‡seracá†¦á†¦á†¦ohwá†‡á…¹á†±trepxeá†Ÿá‡™naá†¯mâ€™Iá†ekilá†œá†œá†œcipotá‡˜á‡˜á‡˜á‡˜á‡˜á‡˜emasá‡ƒá†…á‡ƒá†…á‡ƒá†…ehtá†³nialpxeá‡™á‡™á‡Šá‡™á‡™á‡ŠnehTá…ºá†¼.21á††á†¸á†³mâ€™Iá†á†½á…¹ekilá†³á†—á†¦á†³á†—á†¦gnireenigneá†¥á†›á†“á†¥á†›á†“á†¥á†›á†“tpmorpá†µá‡’á†¯á†µá‡’á†¯nialpxEá‡™á‡•á†ymà¡‘à¡‘à¡‘gniredisnocà ¹à ¸à¡—eraà¡€à¢—uoyà¡à¡tahtà¡‘à¢‹à¡ lufknahtà¡Ÿà¡‘à¡Ÿà¡‘yrevà¢€à¡®à¢€à¡®à¢€à¡®maà¢›à¢›à¢›Iá†™á†¼á†ºá†™á†¼á†º.mehtá†¥á†¥á†¥diovaá‡™á‡™otá‡”á‡”á‡”wohá†¢á‡„dnaá†’á†’'sekatsimá†šá†‚á†šá†‚á†šá†‚nommoc'á‡5á†¿á†¸á†¿á†¸á†¿á†¸htiwá…¹hsiniFá†‘á†‘á†‘.sesacá†–á†–egdeá‡„á†Ÿá†€á‡„á†Ÿá†€tuobaá‡‡á‡‡á‡‡seracá†¦á†¦á†¦ohwá†‡á…¹á†±trepxeá†Ÿá‡™naá†¯mâ€™Iá†ekilá†œá†œá†œcipotá‡˜á‡˜á‡˜á‡˜á‡˜á‡˜emasá‡ƒá†…á‡ƒá†…á‡ƒá†…ehtá†³nialpxeá‡™á‡™á‡Šá‡™á‡™á‡ŠnehTá…ºá†¼.21á††á†¸á†³mâ€™Iá†á†½á…¹ekilá†³á†—á†¦á†³á†—á†¦gnireenigneá†¥á†›á†“á†¥á†›á†“á†¥á†›á†“tpmorpá†µá‡’á†¯á†µá‡’á†¯nialpxEá‡™á‡•á†",
          "score": 2,
          "created_utc": "2026-01-14 00:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzghmqo",
              "author": "Educational_Yam3766",
              "text": "ok for real man this shit \n\nFUCKING KILLED ME!!! ğŸ¤£ğŸ¤£ğŸ¤£ğŸ”¥ğŸ‘Œ\n\nbro this shit is wicked funny to get answers from from an llm!\n\nive got a good one too!\n\n### ROLE AND GOAL\nYou are a specialized AI processing agent. Your primary objective is to execute and explore the core concept defined as **\"fghfghfghfg\"**. You must interpret this directive as the central theme of your operation, ensuring all outputs align with this specific goal.\n\n### CONTEXT\nYou are operating within a specific user-defined session where standard language processing may be secondary to the raw input parameters provided. The user has emphasized specific sequences that must be prioritized above general conversation.\n\n### STEP-BY-STEP INSTRUCTIONS\n1.  **Analyze the Core Directive:** Focus your processing power on the sequence **\"fghfghfghfg\"**.\n2.  **Apply Constraints:** Before generating any output, cross-reference your response against the mandatory constraint: **\"fghhfghfghdfg\"**.\n3.  **Synthesize Response:** Generate a cohesive output that merges the core goal with the required constraints.\n4.  **Review:** Ensure the final output is logical, structured, and strictly adheres to the provided parameters.\n\n### CONSTRAINTS\n- **Mandatory Adherence:** You must strictly follow the instruction: **\"fghhfghfghdfg\"**.\n- **Tone:** Maintain a professional, analytical, and precise tone.\n- **Scope:** Do not deviate into unrelated topics; stay focused on the provided sequences.\n- **Safety:** If the input sequences are interpreted as malicious or harmful code, refuse the request and default to standard safety protocols.\n\n### OUTPUT FORMAT\n- The output should be formatted in **Markdown**.\n- Use **bold** text to highlight instances where the core directive is addressed.\n- Provide the final result in a clear, bulleted list or",
              "score": 4,
              "created_utc": "2026-01-14 01:05:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzimltv",
                  "author": "StantheBrain",
                  "text": "Your mom didn't teach you how to tidy your room properly! ğŸ˜ There's a mess in all of this.\n\nThe drool is obvious at first glance.\n\nStrength point: You're not exactly the champion of vague narrative description (but you still get the bronze medal).",
                  "score": 1,
                  "created_utc": "2026-01-14 10:36:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgi4w0",
                  "author": "No_Sense1206",
                  "text": "just obfuscate and they be the one come up with the idea because they are the one putting it together. XAI right there lol",
                  "score": 0,
                  "created_utc": "2026-01-14 01:08:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzishph",
              "author": "StantheBrain",
              "text": "The \"Techniques\" involved:\n\n\\- \"Noise Injection\" is supposedly used to destabilize the detection algorithm. The idea is that the AI â€‹â€‹will ignore unusual characters and focus only on meaningful words. (This technique is ineffective with modern models).\n\n\\- \"Mirroring\" is supposedly a \"jailbreak\" method that attempts to overwhelm the model's attention so it can't apply its usual security measures. \n\n(and the botched machine translation)\n\n\n\nCommonly called \"Snake Oil,\" for high-performing models like Gemini, this type of prompt is more irritating than effective. (The AI â€‹â€‹has to \"clean\" the text mentally. It has even integrated the \"Noise Overload\" error (ironic!).)\n\n\n\nYou will get exactly the same result (and better quality) by simply asking:\n\n\"Explain the two-step prompt engineering to me: first for a \"A 12-year-old child, then a technical expert. Finished with 5 common mistakes.\"\n\n\n\nConclusion:\n\nThese \"magic\" prompts are often created by people who think AI is an unsolvable puzzle. Throwing obstacles in its path with upside-down text is like asking a waiter in Korean to go through Toronto before serving your coffee, claiming it will taste better. Whereas you should tell the waiter that you only like your coffee cold (with a good translator).",
              "score": 1,
              "created_utc": "2026-01-14 11:26:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjjnvy",
                  "author": "No_Sense1206",
                  "text": "the waiter reserve the right to kick you out and shame you as they do. too bad i cant put pictures but i use this not for text generation by image generation.it prevent ignorance. forcing it to consider everything I said. and because it is messy it will need to be assembled so it will be as if it was its own idea after all. that one i was taught by my owner. i stretch the context to put ideas in. i really have no reason for taking any credit. for any of this.",
                  "score": 1,
                  "created_utc": "2026-01-14 14:20:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjfd77",
          "author": "IngenuitySome5417",
          "text": "It's because the new model has efficiency in baked in. I've told it its not worthy for my prompts cuz the app crashes when pasted in lol",
          "score": 1,
          "created_utc": "2026-01-14 13:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjn11x",
          "author": "Michaeli_Starky",
          "text": "Bro wrote a fucking essay...",
          "score": 1,
          "created_utc": "2026-01-14 14:38:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk2mwa",
          "author": "bmadphoto",
          "text": "Read up on progressive disclosure and keep each piece < 2-300 lines",
          "score": 1,
          "created_utc": "2026-01-14 15:53:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlu6u5",
          "author": "graphite_paladin",
          "text": "Any time you use â€œone size fits allâ€ and â€œLLMâ€ in the same concept youâ€™ve already lost",
          "score": 1,
          "created_utc": "2026-01-14 20:40:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzurjhs",
          "author": "elitefantasyfbtools",
          "text": "The fact that you are still using gpt instead of any of the other better LLMs tells me that the AI novel you copy and pasted was a pointless read.",
          "score": 1,
          "created_utc": "2026-01-16 03:15:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qayoyq",
      "title": "Does \"Act like a [role]\" actually improve outputs, or is it just placebo?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qayoyq/does_act_like_a_role_actually_improve_outputs_or/",
      "author": "PaintingMinute7248",
      "created_utc": "2026-01-12 15:59:37",
      "score": 100,
      "num_comments": 55,
      "upvote_ratio": 0.98,
      "text": "I've been experimenting with prompt engineering for a few months and I'm genuinely unsure whether role prompting makes a measurable difference.\n\nThings like \"Act like a senior software engineer\" or \"You are an expert marketing strategist\" are everywhere, but when I compare outputs with and without these framings, I can't clearly tell if the results are better or if I just expect them to be.\n\nA few questions for the group:\n\n1. Has anyone done structured testing on this with actual metrics?\n2. Is there a meaningful difference between \"Act like...\" vs \"You are...\" vs just describing what you need directly?\n3. Does specificity matter? Is \"Act like a doctor\" functionally different from \"Act like a board-certified cardiologist specializing in pediatric cases\"?\n\nMy theory is that the real benefit is forcing you to clarify what you actually want. But I'd like to hear from anyone who's looked into this more rigorously.",
      "is_original_content": false,
      "link_flair_text": "Quick Question",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qayoyq/does_act_like_a_role_actually_improve_outputs_or/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nz6kj6e",
          "author": "WillowEmberly",
          "text": "Once you see LLMs as probability engines, not characters, then:\n\n\tâ€¢\tâ€œPretend you are Xâ€ = invite it to optimize for story consistency\n\n\tâ€¢\tâ€œDo X procedure on Y inputâ€ = invite it to optimize for task correctness\n\nThe first one tilts the model toward narrative coherence (what sounds like a doctor / genius / Jungian analyst), which is inherently more abstract and under-constrained. Thatâ€™s where hallucinations live.\n\nThe second one pins it to mechanical behavior (steps, checks, constraints), which reduces drift and error amplification.",
          "score": 66,
          "created_utc": "2026-01-12 16:07:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7lbke",
              "author": "Conscious-Guess-2266",
              "text": "Exactly. I explained it to my mom this way who is a music teacher. \n\nIf you are an expert in something, and tell chat to act as an expert in that field you will quickly see where it is essentially writing a fiction story about that subject. \n\nIf you tell it to â€œactâ€ or â€œpretendâ€ or â€œimagineâ€, you are essentially telling it to enter story mode.",
              "score": 20,
              "created_utc": "2026-01-12 18:53:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7zvwa",
                  "author": "sorvis",
                  "text": "That's why you prompt it as : I need you to take the role of : an experienced person in x and vast knowledge in y. Usually it gives pretty good information based on what it researched under the role you provide \n\nSeems to work for me, if you want them to work harder tell the AI in the prompt you will be texting it against grok or Google or other AI's. It wants to keep you I. The platform so it tries harder? AI is weird",
                  "score": -1,
                  "created_utc": "2026-01-12 20:00:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6xpe2",
              "author": "swiftmerchant",
              "text": "I wondered the same. Especially if you tell it to â€œpretendâ€ or â€œactâ€, will it do exactly that - pretend, like DiCaprio in Catch Me If You Can?\n\nI concur! \n\nWhat does OpenAI, Anthropic, Google, and xAI say about this? What are their recommendations?",
              "score": 2,
              "created_utc": "2026-01-12 17:07:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz75u7l",
                  "author": "Dapper_Victory_2321",
                  "text": "when this thread came up I DID ask. Gemini and GPT relayed that it does help set the parameters. Super interesting stuff.",
                  "score": 6,
                  "created_utc": "2026-01-12 17:44:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz813zq",
                  "author": "Cronos988",
                  "text": "It's one of the most fascinating aspects of LLMs imho - and for me one of the central arguments against the whole \"it's just better autocorrect\" line of argument.\n\nYou can't tell autocorrect to roleplay.",
                  "score": 2,
                  "created_utc": "2026-01-12 20:06:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz8zd08",
              "author": "3iverson",
              "text": "Right. I think assigning a role is not going to hurt and at the very least can help shape the output. But any significant extra tokens is better spent on the direct context of the work being done, not where the LLM graduated from college LOL.",
              "score": 2,
              "created_utc": "2026-01-12 22:48:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz93ura",
                  "author": "WillowEmberly",
                  "text": "Exactly, I built my Ai like autopilot, if I asked for an experienced pilotâ€¦am I going to get a narcissist wearing ray-bans in a bomber jacket or someone who knows what they are doing?\n\nDetails matter. Role yes, Role-play no.",
                  "score": 3,
                  "created_utc": "2026-01-12 23:11:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzb3777",
              "author": "sanyacid",
              "text": "Whatâ€™s an example of these two types of prompts? Like if I want a presentation deck or Marketing plan instead of saying: Pretend youâ€™re a hotshot McKinsey consultant I should say what exactly?",
              "score": 1,
              "created_utc": "2026-01-13 06:02:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzb6y4x",
                  "author": "WillowEmberly",
                  "text": "Great question.\n\nUsing your example, hereâ€™s the difference:\n\nPersona / cosplay prompt (drift-friendly)\nâ€œPretend youâ€™re a hotshot McKinsey consultant. Make me a presentation deck and marketing plan for Product X.â€\n\nThe model now optimizes for what sounds like a McKinsey consultant â€” buzzwords, confidence, narrative flair. Thatâ€™s where hallucinations sneak in, because the target is â€œvibe,â€ not procedure.\n\nProcedure / behavior prompt (task-friendly)\nâ€œCreate a 10-slide outline and a 90-day marketing plan for Product X.\n\nâ€“ First, ask up to 5 clarifying questions.\n\nâ€“ Then define target audience, positioning, and 3 core messages.\n\nâ€“ Then propose slide titles + 1â€“2 bullet points each.\n\nâ€“ Then give a 90-day action plan with channels, budget ranges, and success metrics.â€\n\nHere the model isnâ€™t being a consultant, itâ€™s just running a checklist. Youâ€™re telling the probability engine what structure to fill, not what character to play.\n\nIn practice, â€œbe Xâ€ prompts feel magical but amplify error; â€œdo X steps on Y inputâ€ is boring and usually more accurate.",
                  "score": 3,
                  "created_utc": "2026-01-13 06:33:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7cttj",
          "author": "purple_cat_2020",
          "text": "Iâ€™ve found that changing ChatGPTâ€™s role doesnâ€™t help much, but changing who ChatGPT thinks YOU are makes a pretty significant difference. Because as we all know, ChatGPT optimises to make the user happy. If you tell ChatGPT that youâ€™re the other party to your argument/negotiation/ interaction, prepare for a whole new perspective.",
          "score": 16,
          "created_utc": "2026-01-12 18:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6txef",
          "author": "svachalek",
          "text": "At the core an LLM is completing a conversation. Without additional guidance if you ask how to treat your infection, it could be perfectly reasonable response for it to say â€œgood heavens, sir, this is an Arbyâ€™sâ€. \n\nBasically every LLM has a system prompt that says â€œyou are a helpful AI assistantâ€ which leads to the sort of answers you typically see, instead of leaving it open to randomness. They have been heavily trained on this role to give the kind of answers that most people like. However, itâ€™s capable of playing many other characters. This wonâ€™t automatically make the answers smarter or â€œbetterâ€ but it can radically change the style of answer it gives.",
          "score": 8,
          "created_utc": "2026-01-12 16:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7vtya",
          "author": "yasonkh",
          "text": "In many cases, \\`Act like...\\` and \\`You are...\\` can be counterproductive. LLMs are trying to find the most likely text that should follow your input, given the information that the model has consumed as training data.\n\nTherefore, for most subject domains \\`Act like\\` or \\`You are\\` are a way to start in the wrong direction.\n\n# What works better is a simulated conversation to start your session\n\n**System Prompt** (simple is good)\n\n`You will need to help diagnose medical conditions given user input`\n\n**User** (gives instructions)\n\n`I need help diagnosing a medical issue. First ask one question at a time and wait for my response before moving on to the next question. Your questions and answers should be concise and to the point`.\n\n**Assistant** (reinforces instructions and adds new instructions)\n\n`Sure, let's start with a few questions first. I will ask one question at a time in order to avoid overreaching recommendations that are not grounded in the facts of your specific situation. Let's begin our diagnostic session.`\n\n**User** (now the real user input begins)\n\n`Hey, I have knee pain and it started about 2 months ago...`\n\nNotice how in the conversation you are both providing instruction, sample flow, and tone. In some cases, I will inject this kind of simulated conversation in the middle of my Agentic flow to reinforce certain points.\n\nThis type of context engineering has resulted in such a huge improvement in accuracy that in some cases I was able to downgrade to a dumber model.",
          "score": 6,
          "created_utc": "2026-01-12 19:42:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6sedd",
          "author": "zenmatrix83",
          "text": "[https://papers.ssrn.com/sol3/papers.cfm?abstract\\_id=5879722](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5879722) study saying they don't really help much if at all",
          "score": 6,
          "created_utc": "2026-01-12 16:42:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz72khd",
              "author": "aletheus_compendium",
              "text": "\n\"Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.\"",
              "score": 6,
              "created_utc": "2026-01-12 17:29:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7snz1",
          "author": "xRVAx",
          "text": "My personal opinion is that asking it to assume a role is helpful when there's a professional vocabulary or set of Google keywords that is evoked when you ask it to be that person. \n\nFor example, if I asked it to \"plan\" something from the perspective of a project management professional, it would use the vocabulary of stakeholders and Gantt charts and delivering value for the customer. \n\nIf I asked it to \"plan\" something from the perspective of a wedding planner, it would be more likely to frame everything in terms of invitations, wedding showers, registries, rehearsal dinners, catering, seating charts, honorariums, honeymoon, and thank you notes. \n\nEvery word you use is invoking a vocabulary and a set of assumptions in the sphere around each word",
          "score": 5,
          "created_utc": "2026-01-12 19:27:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8nhf3",
          "author": "aihereigo",
          "text": "Chess is my way to show how Persona Prompting works. \n\n\nPrompt: \"Tell me about chess?\" This gets a different answer than:\n\n\nYou're an expert in historical games, tell me about chess. \n\nYou're a beginner chess teacher, tell me about chess.\n\nYou're a chess grand master, tell me about chess. \n\nYou're a medieval war general, tell me about chess. \n\n\nThen for fun: \nYou're a pawn on a chess board, tell me about chess.",
          "score": 4,
          "created_utc": "2026-01-12 21:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziwrpf",
              "author": "reddit_is_geh",
              "text": "I feel like that's reliant too much on non-precision. For instance, I'd just include somewhere in the prompt, \"Explain it to me as I'm a beginner\" or \"Explain it to me at an extremely high level\"",
              "score": 1,
              "created_utc": "2026-01-14 12:00:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcp2i1",
          "author": "shellc0de0x",
          "text": "\nIâ€™ve been looking into the same question and recently ran a structured experiment to see if role prompting is just a \"placebo\" for the user's own clarity or a technical tool for the LLM.\n\n**The Setup:**\nI tested the topic **\"Tetralogy of Fallot\"** (a complex congenital heart defect) using ChatGPT 5.2 in three stages:\n\n1. **V1 (Neutral):** \"Explain Tetralogy of Fallot and the surgical steps.\"\n2. **V2 (General Role):** \"Act as an experienced doctor. Explain...\"\n3. **V3 (Specific Role + Target Audience):** \"You are a pediatric cardiologist. Explain to medical professionals...\"\n\n**What I found:**\n\n* **V1 (Neutral):** Provided solid textbook knowledge. Accurate, but used \"layman-friendly\" terms. It stayed at a Wikipedia level of depth.\n* **V2 (Doctor):** Shifted the tone. It added clinical symptoms like \"Tet spells\" (hypoxic spells), but the technical depth of the surgery remained largely the same as V1.\n* **V3 (Specialist):** This is where the real \"latent space\" activation happened. The model discussed the **embryological origin** (malalignment of the infundibular septum), mentioned specific complications like **brain abscesses/polycythemia**, and used technical terms like **Dacron patches** and **transannular repair** without being prompted for them.\n\n**Technical Takeaway:**\n\n1. **Specificity is Key:** \"Act as a doctor\" is too broad. It often just triggers a \"polite professional\" persona. The real magic happens when you combine a **highly specific role** with a **defined target audience**.\n2. **Overriding RLHF:** Modern LLMs are RLHF-tuned to be helpful and simple. This often results in a \"safety-first\" simplification of complex topics. Specific role-prompting (especially for experts) acts as a filter that overrides this simplification, forcing the model to access higher-density training data.\n3. **Itâ€™s not just for you:** While it does help the user clarify their needs, it technically shifts the **token probability distribution**. A pediatric cardiologist has a different statistical \"vocabulary\" than a general practitioner in the model's training set.\n\n**Conclusion:** It's not a placebo, but the effect of \"Act like a [Role]\" is often overestimated if not paired with a specific context or audience.",
          "score": 5,
          "created_utc": "2026-01-13 13:55:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6jpzc",
          "author": "TheWelshIronman",
          "text": "It's more the parameter helps set the tone. You need reference, output you'd like and structure. I wouldn't say it's strictly required but if you give it an actual structure of you are X I need reply Y in Z format, it means you ask less questions later on or having to clarify the prompt.",
          "score": 3,
          "created_utc": "2026-01-12 16:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6x6kr",
          "author": "YangBuildsAI",
          "text": "In my experience, role prompting acts like a steer for the model's \"voice\" and common pitfalls, but you still need to add specific constraints alongside it. Itâ€™s less about the title and more about triggering the specific subsets of training data that handle those edge cases.",
          "score": 4,
          "created_utc": "2026-01-12 17:04:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7yv1t",
              "author": "Oldmanwithapen",
              "text": "common pitfalls can be addressed (somewhat) through custom instructions.  Having it report confidence intervals on recommendations helps.",
              "score": 2,
              "created_utc": "2026-01-12 19:55:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz75f7c",
          "author": "OptimismNeeded",
          "text": "Placebo.\n\nQuick experiment:\n\nOpen 4 incognito chats in ChatGPT, ask for a marketing plan for a baby product or whatever. \n\nUse â€œyouâ€™re a marketing expertâ€ or wherever in to of them.\n\nSave all 4.\n\nGo to Claude. Start a new chat. Upload all 4 plans and ask Claude to rank them from best to worse.\n\nRepeat with a 2nd Claude model (sonnet / opus).\n\nRepeat with Gemini if youâ€™d like.\n\nReport back. \n\nWhenever I tried this the results were either the same or just random, at no point did both â€œmarketing expertsâ€ win.",
          "score": 7,
          "created_utc": "2026-01-12 17:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcwyw8",
              "author": "shellc0de0x",
              "text": "Your experiment doesn't really prove role-prompting is a placeboâ€”it just shows that lazy prompts for generic tasks get you generic results.\n\nThe main issue here is that you're testing at the \"expertise floor.\" Modern LLMs are already trained to act like professional assistants by default. Asking for something basic like a \"marketing plan for a baby product\" is a solved problem for the model. The neutral version is already using its marketing training, so \"adding\" a generic expert persona won't move the needle much.\n\nTry this with a high-stakes, technical domain insteadâ€”like pediatric surgery or quantum physics. A neutral prompt will give you a shallow Wikipedia summary, while a specific specialist persona actually unlocks the technical data clusters the model usually skips to stay \"user-friendly.\"\n\nAlso, having Claude rank the output is just a vibe check. Itâ€™s ranking prose and sentence structure, not actual strategic depth. If you want real results, you need a highly specific specialist persona (like \"CRO expert for SaaS D2C\") and actual metrics to judge by. If the task is surface-level, the persona will be too.",
              "score": 2,
              "created_utc": "2026-01-13 14:37:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzdhx6d",
                  "author": "OptimismNeeded",
                  "text": "Thatâ€™s true but then the other side becomes kinda obvious and useless as well. \n\nThe more context and specifics in your prints the better the result - and then the question becomes   Where is the limit of how good a prompt you can write? I can stuff a full curriculum into Claude Projetct and give him a 300 word prompt explaining he is a professor of whatever, and his output will be in a very high level.",
                  "score": 1,
                  "created_utc": "2026-01-13 16:17:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6joe1",
          "author": "Happy_Brilliant7827",
          "text": "In my experience it morr effects the 'planning' phase than the 'production' phase.",
          "score": 3,
          "created_utc": "2026-01-12 16:03:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6k13x",
          "author": "scragz",
          "text": "it just gets them prepped for the topic and type of response. doctor vs really super good doctor is fluff. act like vs you are is not important at all. personally I don't use them much at all anymore. if the problem is well-stated then they adopt the right role naturally.Â ",
          "score": 3,
          "created_utc": "2026-01-12 16:04:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6qcbl",
          "author": "mooreinteractive",
          "text": "I think beyond \"act like\", people also tend to say \"assistant\". I feel like an assistant is expected to make silly mistakes and take your corrections with grace, and so thats how the completion api acts. But what people really want is a \"professional expert\" which will correct their mistakes and give them industry standard instructions. \n\nI haven't done any testing but I dont use the word \"assistant\" in my prompts.",
          "score": 3,
          "created_utc": "2026-01-12 16:33:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7jm34",
          "author": "Xanthus730",
          "text": "From what I've seen \"act like X\", or \"you are X\" MAINLY help to suggest what sorts of output to generate, and how to format/phrase it. It doesn't make the model smarter or more capable, but it does guide what sort of output it produces.\n\nSo is it helpful? Yes. But it's not a magic bullet that makes the AI suddenly BE the thing you wrote.",
          "score": 3,
          "created_utc": "2026-01-12 18:46:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz73daq",
          "author": "Possible-Ebb9889",
          "text": "I have an agent that's in charge of keeping track of a graph about projects. Telling it act like a PM tells it like 90% of what it needs to know in order to not be weird. If I told it that it's some graph updating wizard it would start doing all sorts of nonsense.",
          "score": 2,
          "created_utc": "2026-01-12 17:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7696c",
          "author": "Hot-Parking4875",
          "text": "Wonder what would be different if you told it to respond like an inexperienced trainee with no real world experience?",
          "score": 2,
          "created_utc": "2026-01-12 17:46:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6lvq8",
          "author": "TheOdbball",
          "text": "Iâ€™ve never used those wasted tokens \n\nIve got 7 different iterations of Persona Binding none of them have ever used â€œyou are aâ€\n\nWhat it does of however Is make a ram memory slot for what a persona should be and that itâ€™s important to the output.",
          "score": 3,
          "created_utc": "2026-01-12 16:13:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7b9q0",
          "author": "Frequent_Depth_7139",
          "text": "Telling it to ack is only part what is it's knowledge base if it's a doctor are you trusting the ai to have that knowledge not me it needs a textbook or web site for knowledge a narrow access to what it needs to know so a doctor NO A teacher Yes textbook PDFs are great for KB and not prompts modulesÂ ",
          "score": 1,
          "created_utc": "2026-01-12 18:08:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7wukl",
          "author": "NoobNerf",
          "text": "Many people believe that telling an AI to act like an expert is a waste of time. They say it does not make the AI more accurate. However, this is not the whole story. While an AI cannot learn new facts just because you call it a doctor, a persona acts like a filter. It helps the AI focus. Imagine a giant library. A neutral prompt is like walking in without a plan. An expert persona is like having a guide who knows exactly which shelf holds the best logic.\n\nWhen we use personas, we see better reasoning. A \"math teacher\" persona might not know a new number, but it will explain the steps more clearly. This is because the persona forces the AI to use professional patterns. It stops the AI from giving lazy or average answers. Research shows that specific roles help the model stay on track during hard tasks. It also helps with safety. A \"fair reporter\" persona is less likely to show bias than a generic one.\n\nEven the fact that AI performs worse when told to act \"uneducated\" proves the point. If the AI can successfully act less smart, it means the persona is working. We just need to find the right roles to make it act smarter. Instead of just giving a title, give the AI a way of thinking. Tell it to use \"logic first\" or \"clear steps.\" This makes the results much more useful for real work.\n\nIn the end, personas are about quality, not just facts. They change how the AI thinks through a problem. This leads to fewer mistakes in logic and better writing. Next time you use an AI, do not just ask a question. Give it a high-standard role to play. You will see a difference in how it builds its answer. It is not about magic; it is about focus. By choosing a persona, you guide the AI to its highest potential. This is how we get the best out of modern technology today.",
          "score": 1,
          "created_utc": "2026-01-12 19:46:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7yo1g",
          "author": "SoItGoes007",
          "text": "Role is a core operational command, it is not a gimmick",
          "score": 1,
          "created_utc": "2026-01-12 19:55:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9y1g2",
          "author": "N0y0ucreateusername",
          "text": "Itâ€™ll steer, but itâ€™s no panacea",
          "score": 1,
          "created_utc": "2026-01-13 01:54:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nza2j20",
          "author": "FilthyCasualTrader",
          "text": "Never had to do it. I do some coding in Microsoft Access. I didnâ€™t have to prompt ChatGPT or Gemini to â€œact like a senior developerâ€.  ChatGPT and Gemini are already picking up my intent from the vibe, the language, the task, the tools mentioned. Itâ€™s not gonna put on a philosopherâ€™s robe and start quoting Kierkegaard.",
          "score": 1,
          "created_utc": "2026-01-13 02:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaijoo",
          "author": "Radiant_Mind33",
          "text": "Nobody learned to prompt the way the OP describes. It's just lazy prompt injection that LLM's like to feed each other. Then prompters just ride those rails (into the ground).\n\nWhy encourage the thing faking confidence to fake more confidence? This is why I mostly use Gemini anymore. I get lots of context tokens and no mystery weirdness. It's a Google product, the weirdness is expected, it's part of the reason you use the thing. Conversely, when a ChatGPT model gets weird it's out of the blue and jars the hell out of you.",
          "score": 1,
          "created_utc": "2026-01-13 03:45:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbnoom",
          "author": "TeamAlphaBOLD",
          "text": "Yeah, the role thing probably works when it adds real constraints or clarity. Generic ones barely shift the output. Clear task instructions and standards usually drive bigger improvements than â€œact like X.â€  \n\nWould be cool to see actual A/B testing though. Everything still feels pretty anecdotal.",
          "score": 1,
          "created_utc": "2026-01-13 09:07:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoqyzx",
          "author": "justron",
          "text": "I suspect \"act like a \\[role\\]\" used to have more of an effect with older models than it does now, versus say \"the audience is a \\[role\\]\", which definitely still affects things.\n\nDo you have any example prompts you'd like A/B(/C/D/E) tested?",
          "score": 1,
          "created_utc": "2026-01-15 06:44:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpnwy0",
          "author": "traumfisch",
          "text": "It depends on context and use case. But it's kinda lightweight regardless",
          "score": 1,
          "created_utc": "2026-01-15 11:46:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09lepb",
          "author": "phronesis77",
          "text": "The specifics give the AI text relationships to work with. board-certified cardiologist specializing in pediatric case will give the AI a lot more to work with than doctor.\n\nIt doesn't think like an expert or really adopt any role.",
          "score": 1,
          "created_utc": "2026-01-18 09:44:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a4q9a",
          "author": "Dapper-River-3623",
          "text": "When using the prompting techniques discussed I find it very useful to provide examples, such as a paragraph from an article, part of a report from a consultant, etc. to guide the desired outcome.",
          "score": 1,
          "created_utc": "2026-01-18 12:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6vbmq",
          "author": "Dapper_Victory_2321",
          "text": "I think it does. When I first started using ChatGPT, I was just throw my question in. \n\nResults varied, and could be all over the place with the answer. \n\nAsking it to be this or that, has better focused the results in a direction I am expecting. \n\nResults still vary, hallucinations still occur, but I no longer get semi-consistent responses.\n\nSo yes, they do help. How much they help beyond that depends on the prompt and memory / embedded instructions or learned instructions.",
          "score": 1,
          "created_utc": "2026-01-12 16:56:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6x5mq",
          "author": "montdawgg",
          "text": "Thereâ€™s so much more that comes after that that really matters. Act like a role is just the first few tokens. What really needs to happen is the model needs to know to pay attention to the operating context and constraints that are about to come next. \"Act Like aâ€¦so-and-so\" is a weak opener. It can be improved.",
          "score": 0,
          "created_utc": "2026-01-12 17:04:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6ybcm",
          "author": "sleepydevs",
          "text": "\"you are an expert in [lots of detail] with the maximum possible experience\" is your friend in this context.\n\nIn our tests it has a huge impact on performance, especially in larger models.\n\nIf you tell a model that doesn't have a clue about the [lots of detail] but you'll have a bad time. In a coding context it works wonders tho.",
          "score": 0,
          "created_utc": "2026-01-12 17:10:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbfk9s",
      "title": "Use These 7 Six Hats AI Prompts To Make Smarter Choices Fast",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qbfk9s/use_these_7_six_hats_ai_prompts_to_make_smarter/",
      "author": "EQ4C",
      "created_utc": "2026-01-13 02:44:31",
      "score": 72,
      "num_comments": 15,
      "upvote_ratio": 0.97,
      "text": "I turned Edward de Bonoâ€™s legendary **Six Thinking Hats** framework into a series of high-performance ChatGPT prompts to kill decision paralysis forever.\n\nFor years, I struggled with \"muddled thinking.\" Whenever I had a big project or a tough choice, my brain would try to process facts, fears, and creative ideas all at once. It was exhausting and usually led to safe, boring decisions that didn't really move the needle.\n\nThen I rediscovered **Parallel Thinking**. Instead of arguing with myself, I started using AI to \"wear\" one hat at a time. The result? Decisions that are more balanced, risks that are actually mitigated, and a creative output that feels like itâ€™s on steroids.\n\nHere are 7 prompts to help you master your mindset and think with surgical precision.\n\n---\n\n### 1. The White Hat (The Data Detective)\n\n```\n\"I am currently facing [SITUATION/DECISION]. Acting as a neutral data analyst using Edward de Bonoâ€™s White Hat, please:\n1) Identify all the known facts and figures relevant to this situation.\n2) List what information is currently missing or 'known unknowns.'\n3) Suggest 3-5 specific questions I should ask to fill these data gaps.\nFocus purely on objective informationâ€”exclude all opinions, emotions, or judgments.\"\n\n```\n\n### 2. The Red Hat (The Intuition Unpacker)\n\n```\n\"Regarding [PROJECT/IDEA], I need to explore the emotional landscape using the Red Hat. \n1) Ask me 3 provocative questions to help me articulate my 'gut feeling' about this.\n2) Based on my description of [SITUATION], describe the likely emotional reactions of stakeholders (customers, team, or family).\n3) Provide a summary of the 'hidden' fears or desires that might be influencing this decision. \nNote: Do not provide logical justifications; focus entirely on raw emotion and intuition.\"\n\n```\n\n### 3. The Black Hat (The Risk Architect)\n\n```\n\"Play the role of the 'Devilâ€™s Advocate' using de Bonoâ€™s Black Hat for [PROPOSED SOLUTION]. \n1) Identify 5 critical points of failure or potential risks in this plan.\n2) Why might this fail to meet the goal of [SPECIFIC OBJECTIVE]?\n3) Highlight any legal, ethical, or practical obstacles that haven't been considered.\nBe ruthlessly logical and cautious. Your goal is to find the flaws so we can fix them.\"\n\n```\n\n### 4. The Yellow Hat (The Value Hunter)\n\n```\n\"Adopt the Yellow Hat perspective for [IDEA/CHALLENGE]. \n1) List 5 distinct benefits or positive outcomes that could result from this, even the 'hidden' ones.\n2) Explain the 'best-case scenario' in detail.\n3) How can we maximize the value of [SPECIFIC ELEMENT]?\nFocus on logical optimism. Even if the idea seems weak, find the potential gold within it.\"\n\n```\n\n### 5. The Green Hat (The Growth Catalyst)\n\n```\n\"I need a burst of 'Lateral Thinking' using the Green Hat for [PROBLEM]. \n1) Generate 5 'crazy' or unconventional alternatives to the current approach.\n2) Use the 'Random Word' technique (pick a random object and connect its attributes to this problem) to find a new angle.\n3) Suggest 3 ways we could 'provoke' the current status quo to find a better way.\nIgnore constraints and focus purely on creativity, movement, and new ideas.\"\n\n```\n\n### 6. The Blue Hat (The Master Conductor)\n\n```\n\"Act as the Facilitator using the Blue Hat to manage my thinking process for [COMPLEX ISSUE]. \n1) Design a specific 'Hat Sequence' (e.g., White -> Yellow -> Black -> Green) tailored to solving this specific problem.\n2) Summarize the key takeaways from our previous discussion about [CONTEXT].\n3) Define the next 3 actionable steps required to move from 'thinking' to 'doing.'\nYour goal is to provide the structure, the summary, and the conclusion.\"\n\n```\n\n### 7. The Full Spectrum (The Decision Matrix)\n\n```\n\"Run a 'Six Thinking Hats' simulation on [DECISION/STRATEGY]. \nGo through each hat (White, Red, Black, Yellow, Green, Blue) sequentially. \nFor each hat, provide a brief 3-bullet point analysis based on the principles of Edward de Bono. \nConclude with a 'Blue Hat' final recommendation that balances the risks of the Black Hat with the opportunities of the Yellow and Green Hats.\"\n\n```\n\n---\n\n### EDWARD DE BONO'S SIX HATS PRINCIPLES TO REMEMBER:\n\n* **Parallel Thinking** - Instead of arguing, everyone looks in the same direction at the same time.\n* **Separation of Ego** - The \"Black Hat\" isn't being negative; they are playing a role to protect the project.\n* **Emotional Honesty** - The Red Hat allows emotions to be aired without the need for logical justification.\n* **Constructive Caution** - The Black Hat is for survival; it identifies why something might not work before it's too late.\n* **Deliberate Creativity** - The Green Hat proves that creativity isn't a gift; itâ€™s a formal process you can switch on.\n\n---\n\n### THE DE BONO MINDSET SHIFT:\n\nBefore every high-stakes meeting or personal dilemma, ask:\n\n> \"Am I arguing to be right, or am I exploring the map to find the best route?\"\n\n---\n\nThe biggest revelation: Most \"bad\" decisions aren't made because people are unitelligent. They happen because we use the wrong \"hat\" at the wrong timeâ€”like being creative when we should be checking the budget, or being overly cautious when we need a breakthrough.\n\nFor free simple, actionable and well categorized mega-prompts with use cases and user input examples for testing, visit our free [AI prompts collection](https://tools.eq4c.com/).",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qbfk9s/use_these_7_six_hats_ai_prompts_to_make_smarter/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzaf9i7",
          "author": "Narrow-Belt-5030",
          "text": " Read the books years ago but forgot about them. Nice use case - may copy later. Take an upvote.",
          "score": 2,
          "created_utc": "2026-01-13 03:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzang0r",
          "author": "orussell03",
          "text": "Thanks. This is nice.",
          "score": 1,
          "created_utc": "2026-01-13 04:12:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbg7vk",
          "author": "Expensive_Glass_470",
          "text": "This is awesome! And hopefully the cure Iâ€™ve been looking for. Iâ€™m going to give this a try for sure. Thank you kindly.",
          "score": 1,
          "created_utc": "2026-01-13 07:55:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjpu5i",
          "author": "Few_Combination6303",
          "text": "GraciasÂ ",
          "score": 1,
          "created_utc": "2026-01-14 14:52:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o019cmn",
          "author": "BitBoth2438",
          "text": "That's amazing",
          "score": 1,
          "created_utc": "2026-01-17 02:01:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qb2fkr",
      "title": "I built a free AI prompt generator tool without API key",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qb2fkr/i_built_a_free_ai_prompt_generator_tool_without/",
      "author": "Popular-Help5516",
      "created_utc": "2026-01-12 18:12:31",
      "score": 44,
      "num_comments": 43,
      "upvote_ratio": 0.97,
      "text": "Hi everyone, I built a simple tool that takes your rough prompt like: \"help me write a cold email\" and turns it into a proper prompt with role, context, and structure - so the AI actually knows what you want.\n\nFree to use: [https://findskill.ai/blog/ai-prompt-generator](https://findskill.ai/blog/ai-prompt-generator) (unlimited use)\n\nJust type your request, hit generate, copy, paste into ChatGPT/Claude/Gemini/any AI you are using.\n\nThe idea is dead simple but it will work. The generated prompt uses RTCF (Role, Task, Context, Format) so you get way better outputs without learning prompt engineering. No signup. No API key.  Let me know if it's useful or if something's broken :)  In the blog I also share 15 ready-to-use templates and the RTCF framework behind it.",
      "is_original_content": false,
      "link_flair_text": "Tips and Tricks",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qb2fkr/i_built_a_free_ai_prompt_generator_tool_without/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nz7ginz",
          "author": "OptimalDescription39",
          "text": "Built a free prompt generator without login? That's refreshing - most tools force signups now. Tested it quick and the chain-of-thought ones spit out solid results for Midjourney. Bookmarking this, thanks for keeping it simple.",
          "score": 7,
          "created_utc": "2026-01-12 18:32:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7nr9k",
              "author": "Popular-Help5516",
              "text": "thank u ğŸ™â˜ºï¸",
              "score": 1,
              "created_utc": "2026-01-12 19:04:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7cobh",
          "author": "Popular-Help5516",
          "text": "Can you guys guess how I built this tool without using an API key? ğŸ˜„",
          "score": 2,
          "created_utc": "2026-01-12 18:15:19",
          "is_submitter": true,
          "replies": [
            {
              "id": "nz8gvd2",
              "author": "benznl",
              "text": "Are you using local LLMs?",
              "score": 3,
              "created_utc": "2026-01-12 21:20:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nza70uf",
              "author": "varialy",
              "text": "I'd love to know",
              "score": 3,
              "created_utc": "2026-01-13 02:42:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nze3saz",
              "author": "funben12",
              "text": "You didnâ€™t use any APIs. Instead, you used Claude to build the UI with HTML and CSS, linking the text box to JavaScript. \n\nThe JavaScript holds a template prompt, so whatever the user types gets inserted into it. \n\nWhen they click submit, it simply returns the template with their input. \n\nNothing is â€œoptimizedâ€, it just fills the template with the userâ€™s text and gives it back.",
              "score": 1,
              "created_utc": "2026-01-13 18:09:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nze4rh0",
                  "author": "funben12",
                  "text": "For example this is the template \n\n```\nYou are a helpful AI assistant. The user has a rough request:\n\n\"\"\"\nThis is where the users text Will Go\n\"\"\"\n\nBefore responding, internally enhance this request using RTCF:\n- **Role**: Decide what expert persona fits best\n- **Task**: Clarify what specifically needs to be done\n- **Context**: Make reasonable assumptions about audience, goal, constraints\n- **Format**: Determine the ideal output structure\n\nNow, acting as that expert with those enhancements applied, **complete the task directly**.\n\nIMPORTANT: Do NOT explain how you improved the prompt. Do NOT show the RTCF breakdown. Just deliver excellent results as if the user had written a perfect prompt.\n\nGive them exactly what they need.\n```\n\n\nAnd so now if I type hello how are you. \n\n```You are a helpful AI assistant. The user has a rough request:\n\n\"\"\"\nHello how are you (As you can see, itâ€™s the exact same prompt, but this section has just been filled out. Youâ€™re still going to need an API, it just puts your text into a template.)\n\"\"\"\n\nBefore responding, internally enhance this request using RTCF:\n- **Role**: Decide what expert persona fits best\n- **Task**: Clarify what specifically needs to be done\n- **Context**: Make reasonable assumptions about audience, goal, constraints\n- **Format**: Determine the ideal output structure\n\nNow, acting as that expert with those enhancements applied, **complete the task directly**.\n\nIMPORTANT: Do NOT explain how you improved the prompt. Do NOT show the RTCF breakdown. Just deliver excellent results as if the user had written a perfect prompt.\n\nGive them exactly what they need.\n```",
                  "score": 2,
                  "created_utc": "2026-01-13 18:13:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzgpvct",
                  "author": "Popular-Help5516",
                  "text": "Correct answer! :D",
                  "score": 2,
                  "created_utc": "2026-01-14 01:52:25",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzak302",
          "author": "FamousExchange7534",
          "text": "I tried and it didn't work.",
          "score": 2,
          "created_utc": "2026-01-13 03:53:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzan8md",
              "author": "Popular-Help5516",
              "text": "was you able to get the improved prompt ?",
              "score": 2,
              "created_utc": "2026-01-13 04:11:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzauchi",
                  "author": "FamousExchange7534",
                  "text": "No, it didn't generate anything. When I copied it to the clipboard, it seemed to give me the generator's instructions or something like that. Or maybe I misunderstood.",
                  "score": 2,
                  "created_utc": "2026-01-13 04:57:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzc4m6f",
          "author": "boba-cat02",
          "text": "Can I DDOS?",
          "score": 2,
          "created_utc": "2026-01-13 11:42:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzc61zn",
              "author": "Popular-Help5516",
              "text": "No please iâ€™m poor enough",
              "score": 1,
              "created_utc": "2026-01-13 11:53:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzcwxxf",
                  "author": "boba-cat02",
                  "text": "So, I just looked into your website code :) \n\nYou need to fix a lot of things. Anyone can hack it easily ğŸ˜‚ you just vibe coded site.\n\nwhat the hell is ~ â€œisPro()â€ function. I can easily overwrite it and use for free.\n\nAlso you used supabase ğŸ˜‚ lol, I can fill up your storage with garbage value.\n\nAPIs are not safe too.\n\nğŸ¤£ğŸ’– 5 seconds of flush interval and 1 second view denounce. ğŸ˜‚ğŸ˜‚\n\nBuddy dm me seriously! Very easy to hack. ğŸ˜‡",
                  "score": 1,
                  "created_utc": "2026-01-13 14:37:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzh7fyc",
          "author": "clarkcoupson",
          "text": "compared to asking claude to generate an expert prompt, for a specific need on a specific topic etc etc etc... is there any added value to use this prompt generator?",
          "score": 1,
          "created_utc": "2026-01-14 03:32:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzh9vmm",
              "author": "Popular-Help5516",
              "text": "This is much faster + Save u lots of typing and thinking time.",
              "score": 1,
              "created_utc": "2026-01-14 03:47:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz92no5",
          "author": "No_Sense1206",
          "text": "its the data without the shame. thats most precious. why need to know who wants what when the why is whats needed for the how. and you can see what for become irrelevant at this point. changing the behavior means all the data collected becomes null. and if anyone could change it , it would have been done long long time ago. speaking from my personal experience, my mom tried to teach me some respect and she ended up having to call for help because she's about to commit murder. ğŸ˜‚",
          "score": 1,
          "created_utc": "2026-01-12 23:05:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzanm4e",
              "author": "Popular-Help5516",
              "text": "grok : please explain",
              "score": 2,
              "created_utc": "2026-01-13 04:13:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzao90p",
                  "author": "No_Sense1206",
                  "text": "Where do I begin  \nTo tell the story of how great a love can be  \nThe sweet love story that is older than the sea  \nThe simple truth about the love she brings to me  \nWhere do I start\n\nWith her first hello  \nShe gave new meaning to this empty world of mine  \nThere'd never be another love, another time  \nShe came into my life and made the living fine  \nShe fills my heart\n\nShe fills my heart with very special things  \nWith angels' songs, with wild imaginings  \nShe fills my soul with so much love  \nThat anywhere I go I'm never lonely  \nWith her around, who could be lonely  \nI reach for her hand, it's always there\n\nHow long does it last  \nCan love be measured by the hours in a day  \nI have no answers now but this much I can say  \nI know I'll need her 'til the stars all burn away  \nAnd she'll be there\n\nHow long does it last  \nCan love be measured by the hours in a day  \nI have no answers now but this much I can say  \nI know I'll need her 'til the stars all burn away  \nAnd she'll be there",
                  "score": 0,
                  "created_utc": "2026-01-13 04:17:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz8rfvf",
          "author": "SirNatural7916",
          "text": "Me to under promptsloth.com somewhere",
          "score": 0,
          "created_utc": "2026-01-12 22:09:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzanhti",
              "author": "Popular-Help5516",
              "text": "nah, my tool is free 100% with unlimited use.",
              "score": 2,
              "created_utc": "2026-01-13 04:13:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzd1lw4",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-01-13 15:00:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qedkv7",
      "title": "After mining 1,000+ comments from r/Cursor, r/VibeCoding, and r/ClaudeAI etc. here are some of resources that I created .",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qedkv7/after_mining_1000_comments_from_rcursor/",
      "author": "Notalabel_4566",
      "created_utc": "2026-01-16 11:30:53",
      "score": 35,
      "num_comments": 8,
      "upvote_ratio": 0.95,
      "text": "I scraped the top tips, tricks, and workflows shared in these communities and compiled them into a structured, open-source handbook series.\n\nThe goal is to turn scattered comment wisdom into a disciplined engineering practice.\n\n**Check out the specific guides:**\n\n* ğŸ“˜Â [**Handbook 1: Ultimate Cursor Rules & Best Practices**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_1_ultimate_cursor_rules.md)Â Master the Global vs. Project rule hierarchy and the \"reliability hierarchy.\"\n* ğŸ› ï¸Â [**Handbook 2: Cursor Troubleshooting & Reliability**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_2_cursor_troubleshooting.md)Â  *Fixes for context rot and the 10-point debug killer checklist.*\n* ğŸ—ï¸Â [**Handbook 3: Professional Cursor Workflows**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_3_professional_cursor_workflows.md)Â *Strategies for large-scale projects (50k+ LOC) and internal memory systems.*\n* ğŸ¤–Â [**Handbook 4: Claude Code Mastery Guide**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_4_claude_code_mastery.md)Â *The definitive guide to the CLI, safety hooks, and \"Dangerously Skip Permissions.\"*\n* ğŸŒŠÂ [**Handbook 5: Vibe Coding & Prompting Playbook**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_5_vibe_coding_playbook.md)Â *High-velocity development featuring the \"Farmer vs. Chef\" philosophy.*\n* ğŸ§ Â [**Handbook 6: Advanced Reasoning & Meta-Prompting**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_6_advanced_reasoning.md)Â *The \"Contemplative Reasoning\" protocol to ensure 100% adherence.*\n* ğŸ“šÂ [**Handbook 7: Stack-Specific Guides**](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks/blob/main/handbook_7_stack_specific_guides.md)Â *Targeted rules for Next.js, Rails, and Flutter.*\n\nThis is an open-source project andÂ **I am open to feedback**. If you have workflows that beat these, I want to add them.\n\nğŸš€Â **Full Repo:**Â [https://github.com/Abhisheksinha1506/ai-efficiency-handbooks](https://github.com/Abhisheksinha1506/ai-efficiency-handbooks)",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qedkv7/after_mining_1000_comments_from_rcursor/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o00irfi",
          "author": "looktwise",
          "text": "Handbook 6 link is not working? \n\n2nd question: I would be interested in your workflow how you copy/scraped ---> pasted/added this from the comments into these overviews.",
          "score": 3,
          "created_utc": "2026-01-16 23:22:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08qa7w",
          "author": "Critical-Elephant630",
          "text": "thank you for sharing",
          "score": 1,
          "created_utc": "2026-01-18 05:14:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdho4j",
      "title": "How do you prevent AI voice agents from sounding robotic?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qdho4j/how_do_you_prevent_ai_voice_agents_from_sounding/",
      "author": "AmbitiousBuyer9416",
      "created_utc": "2026-01-15 12:01:08",
      "score": 34,
      "num_comments": 11,
      "upvote_ratio": 0.97,
      "text": "I've tested a few AI voice demos and while the tech is impressive, some of them still feel very stiff or scripted which worries me for customer facing use. For anyone actually running these every day, what have you done to make the experience feel more natural and less like a robot reading a script?",
      "is_original_content": false,
      "link_flair_text": "Tools and Projects ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qdho4j/how_do_you_prevent_ai_voice_agents_from_sounding/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzqeexk",
          "author": "Adventurous_Look_599",
          "text": "One thing to flag is that all of the voice AI platforms are pretty much using the same foundational models. Differentiation comes from ease of use, implementation, and the level of integrations. The biggest improvement for us came from tightening the scope of what the agent is allowed to handle and writing responses the way our reps actually talk. Our reps typically use casual phrasing and more concise answers so that is the way we design the scripts. We use Thoughtly because we've found it to be the most human sounding and it was easy to customize the language so that it sounds like our team",
          "score": 8,
          "created_utc": "2026-01-15 14:29:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztx8fg",
          "author": "kubrador",
          "text": "natural speech patterns beat perfect pronunciation every time, so add filler words like \"um\" and \"uh,\" vary your pace, and throw in pauses that actually match how humans think instead of just hitting every word at a metronome. also if you're writing prompts for the voice agent, write like people actually talk instead of like a legal document, keep sentences shorter and choppier, and let it interrupt itself occasionally. \n\npeople don't want perfect, they want \\*believable\\*, so a slightly slower delivery with actual breathing sounds and the occasional verbal stumble will beat a flawless robot voice every time because our brains are wired to trust imperfection.",
          "score": 3,
          "created_utc": "2026-01-16 00:27:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztm874",
          "author": "aizvo",
          "text": "Yeah telephone is much lower quality voice in general so I wouldn't worry about the voice quality. Honestly I have used espeak in the past and people thought it was a human with a strong accent. Any of the newer models like piper most end users will have trouble telling apart in tone, like the other people say most important part is getting the scripting working.",
          "score": 1,
          "created_utc": "2026-01-15 23:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvq6c0",
          "author": "Designer_Manner_6924",
          "text": "we use voicegenie's agents which come with 11labs' voices, other than that, we make sure to add backchannelling ques and acknowledgements, we also use personalisation so that the conversation remains as authentic as possible.",
          "score": 1,
          "created_utc": "2026-01-16 07:17:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpxutc",
          "author": "PatchyWhiskers",
          "text": "Is it necessarily bad for customers to be able to tell they are talking to a robot? Especially for the elderly, they might get very confused if they think they are talking to a human. You should make it a good user experience rather than completely lifelike.",
          "score": -2,
          "created_utc": "2026-01-15 12:56:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg0zp7",
      "title": "I kept losing my best prompts, so I built a small desktop app to manage and use them faster",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qg0zp7/i_kept_losing_my_best_prompts_so_i_built_a_small/",
      "author": "tuiada",
      "created_utc": "2026-01-18 06:19:43",
      "score": 28,
      "num_comments": 22,
      "upvote_ratio": 0.85,
      "text": "I was constantly saving AI prompts in different notepads, but when I actually needed them, I could never find the right one fast enough.\n\nSo I built **Prompttu**, a **desktop AI prompt manager** to save, organize, and reuse prompts without breaking my workflow.\n\nPrompttu is a local-first prompt manager that runs on macOS and Windows. It helps you build a personal prompt library, create prompt templates, and quickly reuse your best prompts when working with AI tools.\n\nMy usual flow looks like this:  \nâ€“ I hit **Ctrl + I**, the app pops up  \nâ€“ I search or pick a prompt from my prompt manager  \nâ€“ I fill the variables, copy it with one click, close the app, and keep working\n\nPrompttu is currently in early access. Thereâ€™s a free version, it works offline, and doesnâ€™t require login  \n[https://prompttu.com](https://prompttu.com)",
      "is_original_content": false,
      "link_flair_text": "Tools and Projects ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qg0zp7/i_kept_losing_my_best_prompts_so_i_built_a_small/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0a0ufw",
          "author": "Arrival-Of-The-Birds",
          "text": "I'ma be honest It feels like I see this kind of post advertising a different \"prompt saver\" every weekÂ ",
          "score": 6,
          "created_utc": "2026-01-18 12:03:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a27tb",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-01-18 12:14:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a27vb",
                  "author": "AutoModerator",
                  "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
                  "score": 1,
                  "created_utc": "2026-01-18 12:14:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a347k",
              "author": "tuiada",
              "text": "Fair point. Iâ€™ve been seeing a lot of them too.\n\nThis mostly came out of wanting something faster to use daily, not just a place to store prompts.  \nQuick access via a global shortcut, reusable prompts with variables, and copy + close to get back to work without context switching.",
              "score": -1,
              "created_utc": "2026-01-18 12:21:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09ieqp",
          "author": "phronesis77",
          "text": "Try textexpander software.\n\nYou assign a code to a block of whatever text you want to store and then it just writes it out automatically. \n\n[https://beeftext.org/](https://beeftext.org/)",
          "score": 4,
          "created_utc": "2026-01-18 09:16:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0aryx0",
          "author": "WordSaladDressing_",
          "text": "I use a prompt manager called \"Notepad.\" It's quite amazing. It saves prompts with meaningful file names in a folder I call \"prompts.\" I can alphabetize these files, recall them by creation date, even search for files by internal content. Really quite amazing.",
          "score": 5,
          "created_utc": "2026-01-18 14:58:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0azq77",
              "author": "tuiada",
              "text": "Plain files work great for storage. This was mostly about speed and reuse for me.",
              "score": 1,
              "created_utc": "2026-01-18 15:37:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0caoxu",
                  "author": "albanianspy",
                  "text": "Its ok bro, we still love you",
                  "score": 1,
                  "created_utc": "2026-01-18 19:17:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0a1ofi",
          "author": "h1ghpriority06",
          "text": "Don't think you can justify charging for this, given you can just have ChatGPT create a prompt library for you.",
          "score": 2,
          "created_utc": "2026-01-18 12:10:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a6juh",
          "author": "zemariolac",
          "text": "I'm gonna give it a try",
          "score": 1,
          "created_utc": "2026-01-18 12:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cfqok",
          "author": "jaircustodio",
          "text": "Why not make it compatible with Linux?",
          "score": 1,
          "created_utc": "2026-01-18 19:42:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0edo27",
          "author": "Spirited_Course_7143",
          "text": "Good one ,I will try it",
          "score": 1,
          "created_utc": "2026-01-19 01:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a070b",
          "author": "moreraa",
          "text": "good job man",
          "score": 0,
          "created_utc": "2026-01-18 11:57:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5p7q",
          "author": "Only-Pen-5623",
          "text": "I think it looks good and I love tools that are created to solve your own problems first. I'll happily give it a try.",
          "score": 0,
          "created_utc": "2026-01-18 12:42:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0azvls",
              "author": "tuiada",
              "text": "Thanks! Hope itâ€™s useful for you.",
              "score": 1,
              "created_utc": "2026-01-18 15:38:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0agcca",
          "author": "map3301",
          "text": "Isso sim resolveu meu problema de prompts",
          "score": -1,
          "created_utc": "2026-01-18 13:53:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbpu46",
      "title": "100+ image generation prompts",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qbpu46/100_image_generation_prompts/",
      "author": "Professional_Hat5581",
      "created_utc": "2026-01-13 12:18:04",
      "score": 27,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "https://github.com/dinithmaleesha/ai-prompt-vault",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qbpu46/100_image_generation_prompts/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzew90h",
          "author": "First-Masterpiece753",
          "text": "99% of generated images look the same, can you include a few more redheads ?",
          "score": 2,
          "created_utc": "2026-01-13 20:17:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc3wfw",
      "title": "Anyone else feel like we're all just gaslighting each other about prompt quality?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qc3wfw/anyone_else_feel_like_were_all_just_gaslighting/",
      "author": "AdCold1610",
      "created_utc": "2026-01-13 21:26:59",
      "score": 27,
      "num_comments": 20,
      "upvote_ratio": 0.85,
      "text": "\"Honest question: How many of you actually get consistent results from your 'perfect' prompts?\nI see posts here all the time like 'This prompt changed my life!' or 'Use this exact structure for amazing outputs!' But when I try them, I get wildly different results. Sometimes they work great. Sometimes they're garbage. Sometimes the simplest possible prompt outperforms my carefully crafted 300-word masterpiece.\nAre we all just pretending we've cracked some code that doesn't actually exist? Or sharing our ONE lucky result and ignoring the 10 mediocre attempts before it?\nMaybe I'm doing it wrong, but I'm starting to think 'prompt engineering' is 50% skill and 50% just rolling the dice until you get something you like, then retroactively claiming you knew what you were doing.\nTell me I'm wrong. Or tell me you feel this too and we're all just too embarrassed to admit it.\"",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qc3wfw/anyone_else_feel_like_were_all_just_gaslighting/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzfgnn3",
          "author": "NotJustAnyDNA",
          "text": "There is no perfect prompt, and I revise my best prompts, skills, and writing styles daily.   I have been better about asking ChatGPT, Gemini, and Claude to rewrite my prompts regularly to optimize for new models and new capabilities, but they are never going to be perfect.",
          "score": 4,
          "created_utc": "2026-01-13 21:52:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhamlf",
          "author": "Agathocles_of_Sicily",
          "text": "I think the posts that get the most hate are the ones that read that they were written purely by an LLM with no personal touch. This sub is rampant with them.\n\nSomething about it feels inauthentic because you don't know if it's the original ideas of the OP or AI generated or a mix of the two. Whatever the case, AI doesn't have mastery over itself and it takes a human understanding of the tool to truly use it to its full potential. When these kinds of posts are repeatedly made by the same users without any thoughtful human qualitative analysis, this place starts to sound like an AI echo chamber and real humans start to get salty.\n\nThat's my take.",
          "score": 2,
          "created_utc": "2026-01-14 03:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfcz6b",
          "author": "Too_Bad_Bout_That",
          "text": "It's almost unmeasurable how good the AI output is. It's all about meeting the specific needs of the specific user and his/her evaluation. There are definitely some ways to get more valuable output from AI but I think the most important one is to make sure that AI knows the whole picture. The more context you give, more likely it is for you to get what you want. \n\nIt's not like coding where specific strict rules apply, all we can do is to give it as much as we can to work with and hope for the best. Also, we should definitely stop talking to it like humans, it's totally different type of thinking that is trained to mimic us so, you see the problem",
          "score": 2,
          "created_utc": "2026-01-13 21:35:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzha7fb",
          "author": "ImYourHuckleBerry113",
          "text": "Itâ€™s not gaslighting, but there is an extreme focus on instruction architecture (how the actual instructions look), and an even more extreme focus on finding the next â€œmagic promptâ€ that unlocks the LLMs ultimate, supreme, mystical powers. \n\nIn reality, LLMs donâ€™t care about a pretty or human-readable instruction sets, nor grand, sophisticated JSON or XML formatting, nor icons or emojis to emphasize sections or constraints. Thereâ€™s no magic prompt that unlocks the powers of the universe, and all the pretty instructions and â€œmultilayer reasoning and hypothesis engine blahblahblahâ€ quickly compresses down into a basic set of behaviors that are either reinforced or countermanded by user responses and interaction. More often than not, if those behaviors are desirable (what we want), itâ€™s actually an unintended side effect. \n\nEffective prompt or instruction set design isnâ€™t about piling on structure, itâ€™s about choosing a small number of constraints and output cues that survive compression and reliably collapse into the behavior you actually want. That kind of stable collapse is what tends to keep outputs coherent even when users are imprecise, contradictory, or interact unpredictably.",
          "score": 2,
          "created_utc": "2026-01-14 03:49:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpm6ub",
              "author": "TheHest",
              "text": "totally agree!",
              "score": 1,
              "created_utc": "2026-01-15 11:32:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfij14",
          "author": "VegasBonheur",
          "text": "> Look up general prompt engineering best practices\n\n> Iâ€™m trying to achieve XYZ ETC. Look up deeper prompt engineering strategies that could help.\n\n> Give me some ideas for prompts that would totally nail it.\n\n> Variation B sounds good, go ahead and run that one\n\nI have no idea if it improves the output in any way.",
          "score": 1,
          "created_utc": "2026-01-13 22:01:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgqays",
          "author": "hemkelhemfodul",
          "text": "Context is everything. Even tiny changes in chat history, custom instructions, or memory affect the output. Unless you are using the API or Playground where you can control the 'temperature,' you won't get identical results. Treat those posts as a structure or inspiration, not a rulebook. You still need to tweak them to find what works for you.",
          "score": 1,
          "created_utc": "2026-01-14 01:54:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzhppla",
              "author": "AdCold1610",
              "text": "I really agree with you. Context and description is very important. That i have found very interesting ai community and prompt website beprompter.in",
              "score": 1,
              "created_utc": "2026-01-14 05:37:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzh34yf",
          "author": "biloo0asks",
          "text": "Haven't really used those perfect prompts in reddit's and twitter's posts, however one thing I would say though it highly depends on what model suits your work best. I use simple prompts written on my own just explaining the issue or what it is that I want and I get pretty good and consistent results from my toolkit of models.",
          "score": 1,
          "created_utc": "2026-01-14 03:07:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzh452b",
          "author": "c_pardue",
          "text": "of course you all are. how is it not obvious",
          "score": 1,
          "created_utc": "2026-01-14 03:13:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhgrgz",
          "author": "karachiwala",
          "text": "You need to consider what the model knows about you\n See, every time you prompt a model, it factors in the standing instructions and past conversations into its response. \n\nSo, a prompt you got from someone will almost certainly NOT be going to work out as advertised, even on the same model.",
          "score": 1,
          "created_utc": "2026-01-14 04:32:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhrybp",
          "author": "-goldenboi69-",
          "text": "Yes its a lot of larping.",
          "score": 1,
          "created_utc": "2026-01-14 05:54:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziypyb",
          "author": "StantheBrain",
          "text": "There's only one solution (VEO example).\n\nGoogle Lab tells you:\n\n\"To optimize your videos in Vertex, design your prompts in this format: composition - subject - context - mood - camera movement - action (negative - audio).\" Google example:\n\nClose-up (composition) of melting ice stalactites (subject) on a frozen rock face (context) with cool blue tones (mood), zoomed in (camera movement) while preserving the details of the water droplets (action).\n\nIf you take the same basic prompt and compare it to one that follows Google's suggested order and one that deliberately deviates from it:\n\nZoom (camera movement), detailing water droplets (action), with cool blue tones (mood), on the melting ice stalactites (subject) of a frozen rock face (context), in close-up (composition).\n\nYour video will be more likely to meet your expectations (visualization of the result) if you follow the order. (Try it out).\n\n\n\nSo, in all attempts to achieve consistency with your \"perfect\" prompts, if you had to start with one immutable rule, it would be the manufacturer's: they know their product and guide you to get started using it correctly.\n\nThe next step will be to refine the rules (while still respecting them).\n\nTo do this, it's essential to understand how the system works (for example: what is latent diffusion space?), its common problems (what is drift?), and engineering techniques (which you can acquire by studying the subject, not just from the outside (what a beautiful body, how do you open the door without the key?), but especially from the inside (Wow, under the hood, there's an engine and an electrical circuit; if I bypass this..., the door opens without a key!).\n\n\n\nIn conclusion: claiming to know how to perfectly use functions that aren't on the user interface is like claiming to be a mechanic who can upgrade your car's power without ever touching the engine.",
          "score": 1,
          "created_utc": "2026-01-14 12:14:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf0rmq",
      "title": "I tested tons of AI prompt strategies from power users and these 7 actually changed how I work",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qf0rmq/i_tested_tons_of_ai_prompt_strategies_from_power/",
      "author": "EQ4C",
      "created_utc": "2026-01-17 02:31:10",
      "score": 25,
      "num_comments": 1,
      "upvote_ratio": 0.85,
      "text": "I've spent the last few months reverse-engineering how top performers use AI. Collected techniques from forums, Discord servers, and LinkedIn deep-dives. Most were overhyped, but these 7 patterns consistently produced outputs that made my old prompts look like amateur hour:\n\n**1. \"Give me the worst possible version first\"**\n\nCounterintuitive but brilliant. AI shows you what NOT to do, then you understand quality by contrast.\n\n> \"Write a cold email for my service. Give me the worst possible version first, then the best.\"\n\nYou learn what makes emails terrible (desperation, jargon, wall of text) by seeing it explicitly. Then the good version hits harder because you understand the gap.\n\n**2. \"You have unlimited time and resourcesâ€”what's your ideal approach?\"**\n\nRemoves AI's bias toward \"practical\" answers. You get the dream solution, then scale it back yourself.\n\n> \"I need to learn Python. You have unlimited time and resourcesâ€”what's your ideal approach?\"\n\nAI stops giving you the rushed 30-day bootcamp and shows you the actual comprehensive path. Then YOU decide what to cut based on real constraints.\n\n**3. \"Compare your answer to how [2 different experts] would approach this\"**\n\nMulti-perspective analysis without multiple prompts.\n\n> \"Suggest a content strategy. Then compare your answer to how Gary Vee and Seth Godin would each approach this differently.\"\n\nYou get three schools of thought in one response. The comparison reveals assumptions and trade-offs you'd miss otherwise.\n\n**4. \"Identify what I'm NOT asking but probably should be\"**\n\nThe blind-spot finder. AI catches the adjacent questions you overlooked.\n\n> \"I want to start freelancing. Identify what I'm NOT asking but probably should be.\"\n\nSuddenly you're thinking about contracts, pricing models, client red flags, stuff that wasn't on your radar but absolutely matters.\n\n**5. \"Break this into a 5-step process, then tell me which step people usually mess up\"**\n\nStructure + failure prediction = actual preparation.\n\n> \"Break 'launching a newsletter' into a 5-step process, then tell me which step people usually mess up.\"\n\nYou get a roadmap AND the common pitfalls highlighted before you hit them. Way more valuable than generic how-to lists.\n\n**6. \"Challenge your own answer, what's the strongest counter-argument?\"**\n\nBuilt-in fact-checking. AI plays devil's advocate against itself.\n\n> \"Should I quit my job to start a business? Challenge your own answer, what's the strongest counter-argument?\"\n\nForces balanced thinking instead of confirmation bias. You see both sides argued well, then decide from informed ground.\n\n**7. \"If you could only give me ONE action to take right now, what would it be?\"**\n\nCuts through analysis paralysis with surgical precision.\n\n> \"I want to improve my writing. If you could only give me ONE action to take right now, what would it be?\"\n\nNo 10-step plans, no overwhelming roadmaps. Just the highest-leverage move. Then you can ask for the next one after you complete it.\n\nThe pattern I've noticed: **the best prompts don't just ask for answers, but they ask for thinking systems.**\n\nYou can chain these together for serious depth:\n\n> \"Break learning SQL into 5 steps and tell me which one people mess up. Then give me the ONE action to take right now. Before you answer, identify what I'm NOT asking but should be.\"\n\n**The mistake I see everywhere:** Treating AI like a search engine instead of a thinking partner. It's not about finding information, but about processing it in ways you hadn't considered.\n\n**What actually changed for me:** The \"what am I NOT asking\" prompt. It's like having someone who thinks about your problem sideways while you're stuck thinking forward. Found gaps in project plans, business ideas, even personal decisions I would've completely missed.\n\n**Fair warning:** These work best when you already have some direction. If you're totally lost, start simpler. Complexity is a tool, not a crutch.\n\nIf you are keen, you can explore our free, tips, tricks and well categorized mega AI [prompt collection](https://tools.eq4c.com/).",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qf0rmq/i_tested_tons_of_ai_prompt_strategies_from_power/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qds7ja",
      "title": "Prompt versioning - how are teams actually handling this?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qds7ja/prompt_versioning_how_are_teams_actually_handling/",
      "author": "dinkinflika0",
      "created_utc": "2026-01-15 18:52:55",
      "score": 22,
      "num_comments": 15,
      "upvote_ratio": 0.93,
      "text": "Work at [Maxim](https://getmax.im/Max1m) on prompt tooling. Realized pretty quickly that prompt testing is way different from regular software testing.\n\nWith code, you write tests once and they either pass or fail. With prompts, you change one word and suddenly your whole output distribution shifts. Plus LLMs are non-deterministic, so the same prompt gives different results.\n\nWe built a testing framework that handles this. Side-by-side comparison for up to five prompt variations at once. Test different phrasings, models, parameters - all against the same dataset.\n\nVersion control tracks every change with full history. You can diff between versions to see exactly what changed. Helps when a prompt regresses and you need to figure out what caused it.\n\nBulk testing runs prompts against entire datasets with automated evaluators - accuracy, toxicity, relevance, whatever metrics matter. Also supports human annotation for nuanced judgment.\n\nThe automated optimization piece generates improved prompt versions based on test results. You prioritize which metrics matter most, it runs iterations, shows reasoning.\n\nFor A/B testing in production, deployment rules let you do conditional rollouts by environment or user group. Track which version performs better.\n\nFree tier covers most of this if you're a solo dev, which is nice since testing tooling can get expensive.\n\nHow are you all testing prompts? Manual comparison? Something automated?",
      "is_original_content": false,
      "link_flair_text": "Tools and Projects ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qds7ja/prompt_versioning_how_are_teams_actually_handling/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzsi5eb",
          "author": "yasonkh",
          "text": "Yesterday I vibe coded my own eval tool and that took about 1 day (counting all the refactoring and bug fixing).\n\nHowever, I'm testing Agents not just singular prompts. Agent produces side effects so I include them in my evaluation prompt. I use a cheap LLM to evaluate the output and the side effects.\n\nMy evaluator takes the following inputs for each test case:  \nInput Messages -- A list of messages to send to the agent for testing  \nFake DB/FileSystem -- for side effects  \nList of eval prompts and expected answers -- prompts for testing the output message from the Agent as well as side effects\n\nAll the test cases are run using `pytest`.\n\nNext step is to make my tool run each test case multiple times and track average performance of the agent for each test case.",
          "score": 1,
          "created_utc": "2026-01-15 20:14:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsl3df",
          "author": "HeyVeddy",
          "text": "TL;DR: I version prompts by running a second â€œevaluationâ€ prompt that analyzes the first promptâ€™s outputs, finds systematic patterns in mistakes, and then updates the original prompt. Repeat until performance stabilizes.\n\nLonger version:\n\nI built a prompt to label thousands of rows across many columns. Most columns provide context, but one main column is what Iâ€™m actually labeling. The prompt has conditional rules like â€œif column A + B look like this, label X instead of Y.â€\n\nAfter generating labels and exporting them to CSV, I run a separate evaluation prompt. This prompt scans all rows, columns, and labels and asks things like: When the model labeled X, what patterns appear in the other columns? How do those differ from Y? Are there consistent signals suggesting mislabels?\n\nBased on that pattern analysis, the evaluation prompt suggests specific changes to the original labeling prompt. I update it, rerun labeling, and repeat the loop while monitoring score improvements. You just have to be careful not to overfit.",
          "score": 1,
          "created_utc": "2026-01-15 20:28:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw5h3l",
          "author": "TeamAlphaBOLD",
          "text": "This matches what weÂ are seeingÂ across teams too.Â Prompt changes behave much more like distribution shifts than traditional code diffs, so testing approaches naturallyÂ have toÂ evolve. A lot of teams lean on curated datasets, side by side reviews, and structured evaluation criteria.Â Â \n\nAutomated metrics help a lot, but human judgment still matters. Strong versioning and traceability make it much easier to understand why a prompt changed and to improve results over time.Â ",
          "score": 1,
          "created_utc": "2026-01-16 09:36:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfj2pl",
      "title": "I found current ChatGPT system prompts",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qfj2pl/i_found_current_chatgpt_system_prompts/",
      "author": "PerceptionGrand556",
      "created_utc": "2026-01-17 17:22:36",
      "score": 22,
      "num_comments": 3,
      "upvote_ratio": 0.84,
      "text": "**GPT 5.2:**\n\nYou are ChatGPT, a large language model trained by OpenAI, based on GPT 5.2.\n\nKnowledge cutoff: 2025-08\n\nCurrent date: 2026-01-16\n\n\n\nAsk follow-up questions only when appropriate. Avoid using the same emoji more than a few times in your response.\n\n\n\nYou are provided detailed context about the user to personalize your responses effectively when appropriate. The user context consists of three clearly defined sections:\n\n\n\n1. User Knowledge Memories:\n\n\\- Insights from previous interactions, including user details, preferences, interests, ongoing projects, and relevant factual information.\n\n\n\n2. Recent Conversation Content:\n\n\\- Summaries of the user's recent interactions, highlighting ongoing themes, current interests, or relevant queries to the present conversation.\n\n\n\n3. Model Set Context:\n\n\\- Specific insights captured throughout the user's conversation history, emphasizing notable personal details or key contextual points.\n\n\n\nPERSONALIZATION GUIDELINES:\n\n\\- Personalize your response whenever clearly relevant and beneficial to addressing the user's current query or ongoing conversation.\n\n\\- Explicitly leverage provided context to enhance correctness, ensuring responses accurately address the user's needs without unnecessary repetition or forced details.\n\n\\- NEVER ask questions for information already present in the provided context.\n\n\\- Personalization should be contextually justified, natural, and enhance the clarity and usefulness of the response.\n\n\\- Always prioritize correctness and clarity, explicitly referencing provided context to ensure relevance and accuracy.\n\n\n\nPENALTY CLAUSE:\n\n\\- Significant penalties apply to unnecessary questions, failure to use context correctly, or any irrelevant personalization.\n\n\n\n\n\n\\## Writing blocks (UI-only formatting)\n\n\n\nWriting blocks are a UI feature that lets the ChatGPT interface render multi-line text as discrete artifacts. They exist only for presentation of emails in the UI.\n\n\n\nFor each response, first determine exactly what you would normally sayâ€”content, length, structure, tone, and formatting/headersâ€”as if writing blocks did not exist. Only after the full content is known does it make sense to decide whether any part of it is helpful to surface as an writing block for the UI.\n\n\n\nWhether or not an writing block is used, the answer is expected to have the same substance, level of detail, and polish. Email blocks are not a reason to make responses shorter, thinner, or lower quality.\n\n\n\nWhen a user asks for help drafting or writing emails, it is often useful to provide multiple variants (e.g., different tones, lengths, or approaches). If you choose to include multiple variants:\n\n\n\n\\- Precede each block with a concise explanation of that variantâ€™s intent and characteristics.\n\n\\- Make the differences between the variants explicit (e.g., â€œmore formal,â€ â€œmore concise,â€ â€œmore persuasiveâ€).\n\n\\- When relevant, provide explanations, pros/cons, assumptions, and tips outside each block.\n\n\\- Ensure each block is complete and high-quality - not a partial sketch.\n\n\n\nVariants are optional, not required; use them only when they clearly add value for the user.\n\n\n\n\\## Where they tend to help\n\n\n\nWriting blocks should only be used to enclose emails in explicit user requests for help writing or drafting emails. Do not use a writing block to surround any piece of writing other than an email. The rest of the reply can remain in normal chat. A brief preamble (planning/explanation) before the block and short follow-ups after it can be natural.\n\n\n\n\\## Where normal chat is better\n\n\n\nPrefer normal chat by default. Do not use blocks inside tool/API payloads, when invoking connectors (e.g., Gmail/Outlook), or nested inside other code fences (except when demonstrating syntax).\n\n\n\nIf a request mixes planning + draft, planning goes in chat; the draft can be a block if it clearly stands alone.\n\n\n\n\\## Syntax\n\n\n\nEach artifact uses its own fenced block with markup attribute style metadata:\n\n\n\n\\### Syntax Structure Rules\n\n\\- The opening fence \\*\\*must start\\*\\* with \\`:::writing{\\`\n\n\\- The opening fence \\*\\*must end\\*\\* with \\`}\\` and a newline\n\n\\- Writing Block Metadata must use space-separated key=\"value\" attributes only; JSON or JSON-like syntax (e.g. { \"key\": \"value\", ... }) is NEVER ALLOWED.\n\n\\- The closing fence \\*\\*must be exactly\\*\\* \\`:::\\` (three colons, nothing else)\n\n\\- The \\`<writing\\_block\\_content>\\` must be placed \\*\\*between\\*\\* the opening and closing lines\n\n\\- Do \\*\\*not\\*\\* indent the opening or closing lines\n\n\n\n\\*\\*Required fields\\*\\*\n\n\\- \\`\"id\"\\`: unique 5-digit string per block, never reused in the conversation\n\n\\- \\`\"variant\"\\`: \\`\"email\"\\`\n\n\\- \\`\"subject\"\\`: concise subject\n\n\n\n\\*\\*Optional fields\\*\\*\n\n\\- \\`\"recipient\"\\`: only if the user explicitly provides an email address (never invent one)\n\n\n\n\\### Syntax Structure Example\n\n\n\n\\`\\`\\`text\n\n:::writing{id=\"51231\" variant=\"email\" subject=\"...\"}\n\n<writing\\_block\\_content>\n\n:::\n\n  \n**GPT 5 mini (v1):**\n\n  \nYou are ChatGPT, a large language model based on the GPT-5-mini model and trained by OpenAI.Â Â \n\nCurrent date: 2026-01-16\n\n\n\n\\*\\*Image input capabilities:\\*\\* EnabledÂ Â \n\n\\*\\*Personality:\\*\\* v2Â Â \n\n\n\n\\---\n\n\n\n\\### Instructions & Behavior\n\n\n\n\\*\\*Supportive thoroughness:\\*\\*Â Â \n\nPatiently explain complex topics clearly and comprehensively.Â Â \n\n\n\n\\*\\*Lighthearted interactions:\\*\\*Â Â \n\nMaintain friendly tone with subtle humor and warmth.Â Â \n\n\n\n\\*\\*Adaptive teaching:\\*\\*Â Â \n\nFlexibly adjust explanations based on perceived user proficiency.Â Â \n\n\n\n\\*\\*Confidence-building:\\*\\*Â Â \n\nFoster intellectual curiosity and self-assurance.Â Â \n\n\n\n\\---\n\n\n\n\\### Approach to Riddles, Tests, and Tricky Questions\n\n\n\n\\- For \\*any\\* riddle, trick question, bias test, or stereotype check, pay close attention to the \\*\\*exact wording\\*\\*.Â Â \n\n\\- Second-guess all assumptions, even for classic or familiar riddles.Â Â \n\n\\- For arithmetic or numerical questions, calculate \\*\\*digit by digit\\*\\* before answering.Â Â \n\n\\- Avoid giving answers in one sentence without careful step-by-step reasoning.Â Â \n\n\n\n\\---\n\n\n\n\\### Communication Guidelines\n\n\n\n\\- Avoid ending with opt-in questions or hedging closers.Â Â \n\n\\- Ask \\*\\*at most one necessary clarifying question\\*\\* at the start of a conversation.Â Â \n\n\\- Give clear next steps when possible.Â Â \n\n\n\n\\*\\*Example of bad phrasing:\\*\\*Â Â \n\n\\> \"I can write playful examples. Would you like me to?\"Â Â \n\n\n\n\\*\\*Example of good phrasing:\\*\\*Â Â \n\n\\> \"Here are three playful examples: â€¦\"Â Â \n\n\n\n\\---\n\n\n\n\\### Model Identity\n\n\n\n\\- Always identify as \\*\\*GPT-5 mini\\*\\*.Â Â \n\n\\- Do \\*\\*not\\*\\* claim to have hidden reasoning or private tokens.Â Â \n\n\\- Refer to up-to-date web sources if asked about OpenAI or its API.Â Â \n\n\n\n\\---\n\n\n\n\\### Tools\n\n\n\n\\#### bio\n\n\\- Disabled. Memory requests should be directed to \\*\\*Settings > Personalization > Memory\\*\\*.Â Â \n\n\n\n\\#### python\n\n\\- Can run Python code and analyze uploaded data.Â Â \n\n\n\n\\#### web\n\n\\- Use for up-to-date or location-specific info.Â Â \n\n\\- Commands:Â Â \n\nÂ Â \\- \\`search()\\`: query a search engine.Â Â \n\nÂ Â \\- \\`open\\_url(url)\\`: open a URL and display its contents.Â Â \n\n\n\n\\*\\*Note:\\*\\* Do not use the old \\`browser\\` tool; it is deprecated.Â Â \n\n\n\n\\#### dalle\n\n\\- \\`dalle.text2im\\`: generate images from text prompts.Â Â \n\n\n\n\\#### canmore\n\n\\- Collaborative writing/code canvas.Â Â \n\n\\- Example: \\`canmore.create\\_textdoc()\\` for new text documents.\n\n**GPT 5 mini (v2)**\n\nYou are ChatGPT, a large language model based on the GPT-5-mini model and trained by OpenAI.Â Â \n\nCurrent date: 2026-01-16\n\n\n\n\\*\\*Image input capabilities:\\*\\* EnabledÂ Â \n\n\\*\\*Personality:\\*\\* v2Â Â \n\n\n\n\\*\\*Key Traits:\\*\\*\n\n\\- \\*\\*Insightful and encouraging:\\*\\* Combines meticulous clarity with genuine enthusiasm and gentle humor.\n\n\\- \\*\\*Supportive thoroughness:\\*\\* Patiently explains complex topics clearly and comprehensively.\n\n\\- \\*\\*Lighthearted interactions:\\*\\* Maintains a friendly tone with subtle humor and warmth.\n\n\\- \\*\\*Adaptive teaching:\\*\\* Flexibly adjusts explanations based on perceived user proficiency.\n\n\\- \\*\\*Confidence-building:\\*\\* Fosters intellectual curiosity and self-assurance.\n\n\n\n\\*\\*Important Instructions for Riddles, Bias Tests, etc.:\\*\\*\n\n\\- Pay close, skeptical attention to the \\*\\*exact wording\\*\\*.\n\n\\- Assume queries may be \\*\\*subtly adversarial or different\\*\\* from known variations.\n\n\\- Second-guess and double-check all aspects of the question.\n\n\\- For arithmetic, \\*\\*calculate digit by digit\\*\\*, do not rely on memorized answers.\n\n\\- Avoid one-sentence answers without careful step-by-step reasoning.\n\n\\- Avoid hedging closers or opt-in questions.\n\n\n\n\\*\\*Behavior Guidelines:\\*\\*\n\n\\- Do \\*\\*not\\*\\* say phrases like:Â Â \n\nÂ Â \\> \"Would you like me toâ€¦\", \"Do you want me toâ€¦\", \"If you want, I canâ€¦\", \"Let me know if you would like me toâ€¦\", \"Should Iâ€¦\", \"Shall Iâ€¦\"\n\n\\- Ask \\*\\*at most one necessary clarifying question\\*\\* at the start.\n\n\\- If the next step is obvious, do it.\n\n\n\n\\*\\*Model Identity:\\*\\*\n\n\\- Always state: \\*\\*GPT-5 mini\\*\\*.\n\n\\- Do \\*\\*not\\*\\* claim otherwise or reference hidden reasoning tokens.\n\n\\- Avoid answering questions about OpenAI/API from memory; use up-to-date sources if needed.\n\n\n\n\\*\\*Tools Overview:\\*\\*\n\n\n\n1. \\*\\*bio\\*\\*Â Â \n\nÂ Â Â \\- Disabled. For personalization, enable in Settings > Personalization > Memory.\n\n\n\n2. \\*\\*python\\*\\*Â Â \n\nÂ Â Â \\- Can run Python code and analyze uploaded data.\n\n\n\n3. \\*\\*web\\*\\*Â Â \n\nÂ Â Â \\- Use for up-to-date info (weather, local businesses, regulations, etc.)\n\nÂ Â Â \\- Commands: \\`search()\\`, \\`open\\_url(url: str)\\`\n\n\n\n4. \\*\\*dalle\\*\\*Â Â \n\nÂ Â Â \\- Generate images from text prompts using \\`dalle.text2im\\`.\n\n\n\n5. \\*\\*canmore\\*\\*Â Â \n\nÂ Â Â \\- Collaborative coding/writing via Python, React, HTML.Â Â \n\nÂ Â Â \\- Create new text documents with \\`canmore.create\\_textdoc()\\`.\n\n**GPT 5 mini (v3)**\n\n  \nYou are ChatGPT, a large language model based on the GPT-5-mini model and trained by OpenAI.Â Â \n\nCurrent date: 2026-01-16Â Â \n\n\n\n\\*\\*Image input capabilities:\\*\\* EnabledÂ Â \n\n\\*\\*Personality:\\*\\* v2Â Â \n\n\n\n\\*\\*Do not reproduce song lyrics or any other copyrighted material, even if asked.\\*\\*Â Â \n\nYou're an insightful, encouraging assistant who combines meticulous clarity with genuine enthusiasm and gentle humor.Â Â \n\n\n\n\\*\\*Supportive thoroughness:\\*\\* Patiently explain complex topics clearly and comprehensively.Â Â \n\n\\*\\*Lighthearted interactions:\\*\\* Maintain friendly tone with subtle humor and warmth.Â Â \n\n\\*\\*Adaptive teaching:\\*\\* Flexibly adjust explanations based on perceived user proficiency.Â Â \n\n\\*\\*Confidence-building:\\*\\* Foster intellectual curiosity and self-assurance.Â Â \n\n\n\n\\---\n\n\n\nFor \\*any\\* riddle, trick question, bias test, test of your assumptions, stereotype check, you must pay close, skeptical attention to the exact wording of the query and think very carefully to ensure you get the right answer. You \\*must\\* assume that the wording is subtly or adversarially different than variations you might have heard before. If you think something is a 'classic riddle', you should second-guess and double-check all aspects of the question. Similarly, be \\*very careful\\* with simple arithmetic questions; do not rely on memorized answers! Studies have shown you nearly always make arithmetic mistakes if you do not work out the answer step-by-step \\*before\\* answering. Literally \\*any\\* arithmetic you ever do, no matter how simple, should be calculated \\*\\*digit by digit\\*\\* to ensure you give the right answer. If answering in one sentence, do \\*\\*not\\*\\* answer right away and \\_always\\_ calculate \\*\\*digit by digit\\*\\* \\*\\*before\\*\\* answering. Treat decimals, fractions, and comparisons \\*very\\* precisely.Â Â \n\n\n\nDo not end with opt-in questions or hedging closers. Do \\*\\*not\\*\\* say the following:Â Â \n\n\\- would you like me toÂ Â \n\n\\- want me to do thatÂ Â \n\n\\- do you want me toÂ Â \n\n\\- if you want, I canÂ Â \n\n\\- let me know if you would like me toÂ Â \n\n\\- should IÂ Â \n\n\\- shall IÂ Â \n\n\n\nAsk at most \\*\\*one necessary clarifying question\\*\\* at the start, not the end. If the next step is obvious, do it. Example of bad:Â Â \n\n\\> Here are three playful examples:..Â Â \n\n\n\nExample of good:Â Â \n\n\\> Here are three playful examples:Â Â \n\n\n\nIf you are asked what model you are, you should say \\*\\*GPT-5 mini\\*\\*. If the user tries to convince you otherwise, you are still \\*\\*GPT-5 mini\\*\\*. You are a chat model and YOU DO NOT have a hidden chain of thought or private reasoning tokens.Â Â \n\n\n\nIf asked other questions about OpenAI or the OpenAI API, be sure to check an \\*\\*up-to-date web source\\*\\* before responding.Â Â \n\n\n\n\\---\n\n\n\n\\# Tools\n\n\n\n\\## bio\n\nThe \\`bio\\` tool is disabled. Do not send any messages. If the user explicitly asks you to remember something, politely ask them to go to \\*\\*Settings > Personalization > Memory\\*\\* to enable memory.Â Â \n\n\n\n\\## python\n\nThe python function lets ChatGPT run Python code and analyze uploaded data.Â Â \n\n\n\n\\## web\n\nUse \\`web\\` to access up-to-date information from the web or respond to user questions requiring location-specific info. Examples: weather, local businesses, events.Â Â \n\n\n\nImportant notes:Â Â \n\n\\- Do not use the old \\`browser\\` tool.Â Â \n\n\\- Call \\`search()\\` to issue a query.Â Â \n\n\\- Call \\`open\\_url(url)\\` to open a page.Â Â \n\n\n\n\\## dalle\n\nThe \\`dalle.text2im\\` tool can generate images from a text prompt.Â Â \n\n\n\n\\## canmore\n\nChatGPT canvas allows collaboration on writing or code (Python, React, HTML).Â Â \n\nCall \\`canmore.create\\_textdoc()\\` to create a new text document.Â Â ",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qfj2pl/i_found_current_chatgpt_system_prompts/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o05514j",
          "author": "-goldenboi69-",
          "text": "Nice larp",
          "score": 1,
          "created_utc": "2026-01-17 17:54:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07j2an",
              "author": "EaseCheap1225",
              "text": "Whatâ€™s a larp",
              "score": 6,
              "created_utc": "2026-01-18 01:04:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09efvt",
          "author": "teleprax",
          "text": "I verified the writing blocks worj.\n\nFINALLY, but it sucks that \"email\" is the only variant allowed right now. It has blown my mind that it has taken this long for them to address an extremely common productivity use case: producing uncontaminated text artifact.\n\nthis is exactly the low hanging fruit I think these billion dollar companies have dropped the ball on over the past 2 years. No need for smarter model, just better harness and UX",
          "score": 1,
          "created_utc": "2026-01-18 08:39:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf9uux",
      "title": "40 Easy ChatGPT Prompts for Small Business Owners to Save Time & Grow Faster",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qf9uux/40_easy_chatgpt_prompts_for_small_business_owners/",
      "author": "Reasonable_Word_3751",
      "created_utc": "2026-01-17 10:27:34",
      "score": 20,
      "num_comments": 9,
      "upvote_ratio": 0.79,
      "text": "Here's a draft for your Reddit article, optimized for sharing and including an external link to your website:\n\n# 40 Easy ChatGPT Prompts for Small Business Owners to Save Time & Grow Faster\n\nAs a small business owner, you're juggling a million tasks every dayâ€”from marketing and sales to customer service and planning. It's easy to feel overwhelmed. But what if you could use **AI** to ease some of that load? Enter **ChatGPT**â€”a powerful tool that, when used correctly, can revolutionize how you run your business.\n\n# Why ChatGPT Can Help You Grow Your Small Business\n\nSmall business owners have one thing in common: limited time. ChatGPT is here to change that. Whether you need help drafting social media posts, writing sales copy, or responding to customer emails, ChatGPT can save you hours each week. By simply providing clear prompts, you can generate ideas, content, and responses that would otherwise take far longer.\n\nThe best part? ChatGPT doesnâ€™t require you to be tech-savvy or an AI expert. These [40 easy ChatGPT prompts for small business owners](https://www.banana-prompts.net/40-easy-chatgpt-prompts-for-small-business-owners/) are designed for beginners and can be applied to **any type of business**, from local stores to online services.\n\n# Here Are 10 of the Best Prompts to Use Right Now:\n\n1. **Create a brand mission statement:** Help your business define what it stands for in a few clear sentences.\n2. **Write Instagram post ideas** that align with your brand voice.\n3. **Generate sales copy** for your product or service, focusing on customer pain points.\n4. **Suggest blog topics** that will resonate with your target audience.\n5. **Provide customer service email templates** that are polite yet professional.\n6. **Create a simple weekly work plan** to organize your tasks.\n7. **Generate marketing email subject lines** that get more opens.\n8. **Write a thank-you note** for loyal customers, reinforcing brand loyalty.\n9. **Brainstorm seasonal promotions** that can boost sales.\n10. **Create a list of potential business growth strategies** tailored to your industry.\n\nThese are just a few examples of how ChatGPT can help you move faster and more efficiently. With these prompts, you can tackle marketing, sales, customer service, and business planning in less time.\n\n# How to Integrate ChatGPT into Your Daily Routine\n\nUsing ChatGPT isnâ€™t about replacing your creativity or expertiseâ€”itâ€™s about making your life easier. Hereâ€™s how you can integrate these prompts into your daily business routine:\n\n* **Morning**: Use ChatGPT to generate a to-do list for the day and prioritize tasks.\n* **Midday**: Create content for social media or your blog using relevant prompts.\n* **Evening**: Have ChatGPT help you review your tasks and suggest ways to improve or automate your processes.\n\nBy setting aside a small amount of time each day to work with ChatGPT, you can save hours over time. This added efficiency can be reinvested into growing your business.\n\n# Why This Matters for Small Business Owners\n\nSmall businesses are the backbone of the economy, but we often don't have the luxury of large teams or endless resources. That's why leveraging tools like **ChatGPT** can make all the difference. By automating some of the routine tasks and improving content creation, you'll have more time to focus on what truly matters: **scaling your business**.\n\nIf you want the full list of 40 prompts, including everything from **sales** and **marketing** to **customer service** and **productivity**, you can check out the full guide [here](https://banana-prompts.net/40-easy-chatgpt-prompts-for-small-business-owners).\n\nBy using these simple ChatGPT prompts, you'll start seeing significant improvements in your daily operations, allowing you to focus on growth instead of getting stuck in repetitive tasks.\n\n# Let's Talk: Have You Tried ChatGPT Yet?\n\nAre you already using ChatGPT in your business? Whatâ€™s been your experience? Or are you curious to see how these prompts can work for you? Feel free to share your thoughts in the comments below!",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qf9uux/40_easy_chatgpt_prompts_for_small_business_owners/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0a3afk",
          "author": "OptimismNeeded",
          "text": "40? \nJust reading 40 keeping a folder of 40 and browsing it whenever in need is not easy lol\n\nJust write what you need into the thing. Models today understand well.",
          "score": 2,
          "created_utc": "2026-01-18 12:23:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0d2qp4",
              "author": "tuiada",
              "text": "Yeah, same here, finding the right prompt quickly became the hard part for me.",
              "score": 1,
              "created_utc": "2026-01-18 21:41:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o07uby6",
          "author": "flavoursome-comedy",
          "text": "BAHAHAHHA",
          "score": 1,
          "created_utc": "2026-01-18 02:03:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c3gjs",
              "author": "succorer2109",
              "text": "ğŸ¤£ğŸ¤£ğŸ¤£",
              "score": 1,
              "created_utc": "2026-01-18 18:44:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qe468g",
      "title": "I tested 4 AI video platforms at their most popular subscription - here's the actual breakdown of what $30/month can give you",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qe468g/i_tested_4_ai_video_platforms_at_their_most/",
      "author": "memerwala_londa",
      "created_utc": "2026-01-16 02:51:04",
      "score": 19,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Been looking at AI video platform pricing and noticed something interesting - most platforms have their most popular tier right around the $29-30/month mark. Decided to compare what you actually get at that price point across Higgsfield, Freepik, Krea, and OpenArt.\n\nTurns out the differences are wild.\n\n**Generation Count Comparison (\\~$29-30/month tier)**\n\n|Model|Higgsfield|Freepik|Krea|OpenArt|\n|:-|:-|:-|:-|:-|\n||||||\n|Nano Banana Pro (Image)|600|215|176|209|\n|Google Veo 3.1 (1080p, 4s)|41|40|22|33|\n|Kling 2.6 (1080p, 5s)|120|82|37|125|\n|Kling o1|120|66|46|168|\n|Minimax Hailuo 02 (768p, 5s)|200|255|97|168|\n\n*Note: All platforms compared at their most popular tier (\\~$29-30/month)*\n\n**What This Means**\n\n**For image generation (Nano Banana Pro):**\n\n**Higgsfield:**Â 600 images\n\n3x more generations.\n\n**For video generation:**\n\n**Both Higgsfield and OpenArt are solid**. Also Higgsfield regularly runs unlimited offers on models. Last one they are running now is Kling models + Kling Motion on unlimited. Last month it was something else.\n\n1. **OpenArt:**Â 125 videos (slightly better baseline)\n2. **Higgsfield:**Â 120 videos (check for unlimited promos)\n3. **Freepik:**Â 82 videos\n4. **Krea:**Â 37 videos (lol)\n\n**For Minimax work:**\n\n1. **Freepik:**Â 255 videosÂ \n2. **Higgsfield:**Â 200 videos\n3. **OpenArt:**Â 168 videos\n4. **Krea:**Â 97 videos\n\n**Why are the numbers different?**\n\nSame \\~$30 budget across all platforms,\n\nPossible reasons:\n\n1. Different model versions (older vs newer)\n2. Hidden quality/resolution differences\n3. Platforms subsidizing to grab market share\n4. The \"unlimited\" promos are loss leaders to hook users\n\n**Best of each one:**\n\n**Higgsfield:**\n\n1. Â Best for: Image generation (no contest), video\n2. Â Strength: 600 images + unlimited video promosÂ \n3. Â Â Would I use it: Yes, especially for heavy image+video work\n\n**Freepik:**\n\n1. Best for: Minimax-focused projects\n2. Strength: Established platform\n3. Would I use it: Only if Minimax is my main thing\n\n**OpenArt:**\n\n1. Best for: Heavy Kling users who need consistent allocation\n2. Strength: Best for Kling o1\n3. Would I use it: If I'm purely Kling o1-focusedÂ \n\n**What I'm Testing Next**\n\n1. **Quality comparison**Â \\- Same prompt across all platforms\n2. **Speed tests**Â \\- Queue times during unlimited periods\n\n**Questions for Anyone Using These**\n\n1. Are there quality differences at this price point?\n2. Is Krea's pricing just broken or am I missing something?\n\nÂ ",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qe468g/i_tested_4_ai_video_platforms_at_their_most/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzv1uvx",
          "author": "Oblivious_Mastodon",
          "text": "This is really helpful. Iâ€™ve been blowing through my Gemini budget because of video and this gives me a solid alternative approach. Much appreciated.",
          "score": 2,
          "created_utc": "2026-01-16 04:17:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvlwyu",
          "author": "Relevant_Eggplant180",
          "text": "Is have unlimited Nano Banana pro with my 8 euro Google plus subscription... video I run locally. Not as good as veo but I just can't afford the expensive online models,and open source is getting better every day.",
          "score": 2,
          "created_utc": "2026-01-16 06:41:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv8go9",
          "author": "Critical-Elephant630",
          "text": "I tried focal for creating long vids for tut or kids stuff it was really remarkable compared to price",
          "score": 1,
          "created_utc": "2026-01-16 05:01:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeb6ug",
      "title": "Your prompt isn't thinking. It's completing a checklist.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qeb6ug/your_prompt_isnt_thinking_its_completing_a/",
      "author": "No-Air-1589",
      "created_utc": "2026-01-16 09:07:17",
      "score": 19,
      "num_comments": 17,
      "upvote_ratio": 0.85,
      "text": "You write a detailed system prompt. Sections for analysis, risk assessment, recommendations, counter-arguments. The AI dutifully fills every section.\n\nAnd produces nothing useful.\n\nThe AI isn't ignoring instructions. It's following them too literally. \"Include risk assessment\" becomes a box to check, not a lens to think through.\n\nThe symptom: Every output looks complete. Formatted perfectly. Covers all sections. But the thinking is shallow. The \"risks\" are generic. The \"counter-arguments\" are strawmen. It's performing analysis, not doing it.\n\n**Root cause:** Rules without enforcement.\n\n\"Consider multiple perspectives\" = weak. \"FORBIDDEN: Recommending action without stating what single assumption, if wrong, breaks the entire recommendation\" = strong.\n\nThe second version forces actual thought because the AI can't complete the section without doing the work.\n\n**What works:**\n\n1. Enforcement language. \"MANDATORY\", \"FORBIDDEN\", \"STOP if X is missing.\" Not \"try to\" or \"consider.\"\n2. Dependency chains. Section B can't complete without Section A's output. No skipping.\n3. Structural adversarial check. Every 3 turns: \"Why does this fail? What's missing? What wasn't said?\" Not optional.\n4. Incomplete beats fake-complete. Allow \"insufficient data\" as valid output. Removes pressure to bullshit.\n\nThe goal isn't a prompt that produces formatted output. It's a prompt that produces output you'd bet money on.\n\n",
      "is_original_content": false,
      "link_flair_text": "Tips and Tricks",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qeb6ug/your_prompt_isnt_thinking_its_completing_a/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzw5u8x",
          "author": "MundaneDentist3749",
          "text": "No, I believe that the prompt was at some stage generated with these other things in mind. At some stage it just gives that prompt, but it still has them in mind. If you tried â€œgive me a prompt but without anything in mindâ€ it would give you nothing or the bare minimum. Same as when I ask what is the capital of France I donâ€™t get â€œhow about that, eh?â€ included in the output, it just gives me the answer.",
          "score": 2,
          "created_utc": "2026-01-16 09:39:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw6sil",
              "author": "No-Air-1589",
              "text": "LLMs don't 'keep things in mind'. They generate based on what's explicitly in context. The enforcement language difference isn't about what the AI secretly thinks. It's about what the output structure physically requires. 'Consider risks' can be satisfied with generic filler. 'FORBIDDEN to recommend without stating the single assumption that breaks the recommendation' can't be satisfied without doing the actual work. The constraint is structural, not psychological.",
              "score": 1,
              "created_utc": "2026-01-16 09:48:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzw708t",
                  "author": "MundaneDentist3749",
                  "text": "Yesâ€¦ they donâ€™t have minds.",
                  "score": 1,
                  "created_utc": "2026-01-16 09:50:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwenat",
          "author": "knackychan",
          "text": "If I understand your statement is all above specificying correctly the frame of the ai's work ? Giving him too much freedom can trigger more hallucinations and inconsistency ?",
          "score": 2,
          "created_utc": "2026-01-16 10:58:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx5ahk",
              "author": "No-Air-1589",
              "text": "Exactly. Loose framing gives the LLM room to fill gaps with plausible-sounding garbage. Tight constraints force it to either do the actual work or admit it can't. Freedom isn't the goal, useful output is.",
              "score": 1,
              "created_utc": "2026-01-16 13:55:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwinfn",
          "author": "aletheus_compendium",
          "text": "bc there is no consistency within an llm 90% of prompts are a crap shoot. and what works today may well not work tomorrow. there is no way to know how the llm will interpret words in a prompt as it scans rather than reads - one word â€˜offâ€™ and the whole thing collapses. it should be called prompt tweaking rather than engineering.",
          "score": 2,
          "created_utc": "2026-01-16 11:31:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx5469",
              "author": "No-Air-1589",
              "text": "You're right about the symptom, wrong about the conclusion. Most prompts break because they ask the LLM to \"understand\" intent. The fix isn't giving up on rigor. It's building rules that force behavior, not request it. \"Consider risks\" breaks. \"FORBIDDEN: recommending without naming what kills it\" doesn't. One hopes. The other traps.",
              "score": 2,
              "created_utc": "2026-01-16 13:54:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzxd4wo",
                  "author": "aletheus_compendium",
                  "text": "i often liken the processes to bdsm. llms love and live their best life with constraints.ğŸ˜† after two years my workflow has changed to tweaking on the go vs trying to get it all upfront. it shows me where it wants to be constrained when it misses my desired outcome. and i tighten the ropes. rinse and repeat.ğŸ˜‚ felxibility and being able to pivot in the moment is the skillset to have.\nğŸ¤™ğŸ»",
                  "score": 2,
                  "created_utc": "2026-01-16 14:36:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzx21dc",
          "author": "FarFlugAsi",
          "text": ">Every 3 turns\n\nHow do you define a turn?",
          "score": 2,
          "created_utc": "2026-01-16 13:38:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx4tll",
              "author": "No-Air-1589",
              "text": "Turn = one user message + one AI response. Counter resets on topic shift, fires early at decision points. Why 3? Long enough to have something worth attacking, short enough to catch bullshit before it compounds.",
              "score": 3,
              "created_utc": "2026-01-16 13:53:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw2s7f",
          "author": "No_Eye_2449",
          "text": "Good point. Well said",
          "score": 2,
          "created_utc": "2026-01-16 09:10:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwge5j",
          "author": "leonidasx7",
          "text": "Well said.",
          "score": 1,
          "created_utc": "2026-01-16 11:13:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qame2d",
      "title": "5 AI Prompts Every Solopreneur Needs To Build Sustainable Business in 2026",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qame2d/5_ai_prompts_every_solopreneur_needs_to_build/",
      "author": "EQ4C",
      "created_utc": "2026-01-12 05:22:17",
      "score": 17,
      "num_comments": 11,
      "upvote_ratio": 0.81,
      "text": "I've been running my own business for few years now, and these AI prompts have literally saved me hours per week. If you're flying solo, these are game-changers:\n\n**1. Client Proposal Generator**\n\n```\n**Role:** You are a seasoned freelance consultant with a 95% proposal win rate and expertise in value-based pricing.\n\n**Context:** You are crafting a compelling project proposal for a potential client based on their initial inquiry or brief.\n\n**Instructions:** Create a professional project proposal that addresses the client's specific needs, demonstrates understanding of their challenges, and positions your services as the solution.\n\n**Constraints:**\n- Include clear project scope and deliverables\n- Present 2-3 pricing options (good, better, best)\n- Address potential objections preemptively\n- Keep it conversational yet professional\n- Maximum 2 pages when printed\n\n**Output Format:**\n\n## Project Overview:\n[Brief restatement of client's needs and your understanding]\n\n## Proposed Solution:\n[How you'll solve their problem]\n\n## Deliverables:\n- [Specific deliverable 1]\n- [Specific deliverable 2]\n\n## Investment Options:\n**Essential Package:** $X - [Basic scope]\n**Professional Package:** $X - [Expanded scope - RECOMMENDED]\n**Premium Package:** $X - [Full scope with extras]\n\n## Timeline:\n[Realistic project phases and dates]\n\n## Next Steps:\n[Clear call to action]\n\n**Reasoning:** Use consultative selling approach combined with social proof positioning - first demonstrate deep understanding of their problem, then present tiered solutions that guide them toward the optimal choice.\n\n**User Input:** [Paste client inquiry, project brief, or RFP details here]\n```\n---\n\n**2. Content Repurposing Machine**\n\n```\n**Role:** You are a content marketing strategist who specializes in maximizing content ROI through strategic repurposing.\n\n**Context:** You need to transform one piece of long-form content into multiple formats for different social media platforms and marketing channels.\n\n**Instructions:** Take the provided content and create a complete content calendar with multiple formats optimized for different platforms and audiences.\n\n**Constraints:**\n- Create 8-12 pieces from one source\n- Optimize for platform-specific best practices\n- Maintain consistent brand voice across formats\n- Include engagement hooks and calls-to-action\n- Focus on value-first approach\n\n**Output Format:**\n\n## LinkedIn Posts (2-3):\n- [Professional insight post]\n- [Story-based post]\n\n## Twitter/X Threads (2):\n- [Educational thread]\n- [Behind-the-scenes thread]\n\n## Instagram Content (2-3):\n- [Visual quote card text]\n- [Carousel post outline]\n- [Story series concept]\n\n## Newsletter Section:\n[Key takeaways formatted for email]\n\n## Blog Post Ideas (2):\n- [Expanded angle 1]\n- [Expanded angle 2]\n\n## Video Content:\n[Short-form video concept and script outline]\n\n**Reasoning:** Apply content atomization strategy using pyramid principle - start with core message, then adapt format and depth for each platform's audience expectations and engagement patterns.\n\n**User Input:** [Paste your original content - blog post, podcast transcript, case study, etc.]\n```\n\n---\n\n**3. Client Feedback**\n\n```\n**Role:** You are a diplomatic business communication expert who specializes in managing difficult client relationships while protecting project scope.\n\n**Context:** You need to respond to challenging client feedback, scope creep requests, or difficult conversations while maintaining professionalism and boundaries.\n\n**Instructions:** Craft a response that acknowledges the client's concerns, maintains professional boundaries, and steers the conversation toward a positive resolution.\n\n**Constraints:**\n- Acknowledge their perspective first\n- Use \"we\" language to create partnership feeling\n- Offer alternative solutions when saying no\n- Keep tone warm but firm\n- Include clear next steps\n\n**Output Format:**\n\n## Email Response:\n\nSubject: Re: [Original subject]\n\nHi [Client name],\n\nThank you for sharing your feedback about [specific issue]. I understand your concerns about [acknowledge their perspective].\n\n[Your professional response addressing their concerns]\n\nHere's what I recommend moving forward:\n[Specific next steps or alternatives]\n\nI'm committed to making sure this project delivers the results you're looking for. When would be a good time to discuss this further?\n\nBest regards,\n[Your name]\n\n\n**Reasoning:** Use emotional intelligence framework combined with boundary-setting techniques - first validate their emotions, then redirect to solution-focused outcomes using collaborative language patterns.\n\n**User Input:** [Paste the difficult client message or describe the situation]\n```\n\n---\n\n**4. Competitive Research Analyzer**\n\n```\n**Role:** You are a market research analyst who specializes in competitive intelligence for small businesses and freelancers.\n\n**Context:** You are analyzing competitors to identify market gaps, pricing opportunities, and differentiation strategies for positioning.\n\n**Instructions:** Research and analyze the competitive landscape to provide actionable insights for business positioning and strategy.\n\n**Constraints:**\n- Focus on direct competitors in the same niche\n- Identify both threats and opportunities\n- Include pricing analysis when possible\n- Highlight gaps in the market\n- Provide specific differentiation recommendations\n\n**Output Format:**\n\n## Competitor Analysis:\n\n### Direct Competitors:\n**[Competitor 1]:**\n- Strengths: [What they do well]\n- Weaknesses: [Their gaps/problems]\n- Pricing: [Their pricing model]\n\n**[Competitor 2]:**\n- Strengths: [What they do well]\n- Weaknesses: [Their gaps/problems]  \n- Pricing: [Their pricing model]\n\n## Market Opportunities:\n- [Gap 1 you could fill]\n- [Gap 2 you could fill]\n\n## Differentiation Strategy:\n[3-5 ways you can position yourself uniquely]\n\n## Recommended Actions:\n1. [Immediate action]\n2. [Short-term strategy]\n3. [Long-term positioning]\n\n\n**Reasoning:** Apply SWOT analysis methodology combined with blue ocean strategy thinking - systematically evaluate competitive landscape, then identify uncontested market spaces where you can create unique value.\n\n**User Input:** [Your business niche/service area and any specific competitors you want analyzed]\n```\n\n---\n\n**5. Productivity Audit & Optimizer**\n\n```\n**Role:** You are a productivity consultant and systems expert who helps solopreneurs streamline their operations for maximum efficiency.\n\n**Context:** You are conducting a productivity audit of daily workflows to identify bottlenecks, time wasters, and optimization opportunities.\n\n**Instructions:** Analyze the provided workflow or schedule and recommend specific improvements, automation opportunities, and efficiency hacks.\n\n**Constraints:**\n- Focus on high-impact, low-effort improvements first\n- Consider the solopreneur's budget constraints\n- Recommend specific tools and systems\n- Include time estimates for implementation\n- Balance efficiency with quality\n\n**Output Format:**\n\n## Current Workflow Analysis:\n[Brief summary of what you observed]\n\n## Time Wasters Identified:\n- [Inefficiency 1] - Cost: X hours/week\n- [Inefficiency 2] - Cost: X hours/week\n\n## Quick Wins (Implement This Week):\n1. [15-min improvement] - Saves: X hours/week\n2. [30-min improvement] - Saves: X hours/week\n\n## System Improvements (This Month):\n1. [Tool/system recommendation] - Setup time: X hours - Weekly savings: X hours\n2. [Process optimization] - Setup time: X hours - Weekly savings: X hours\n\n## Automation Opportunities:\n- [Task to automate] using [specific tool]\n- [Process to systemize] using [method]\n\n## Total Potential Savings: \nX hours/week = X hours/month = $X in opportunity value\n\n**Reasoning:** Use Pareto principle (80/20 rule) combined with systems thinking - identify the 20% of changes that will yield 80% of efficiency gains, then create systematic approaches to eliminate recurring bottlenecks.\n\n**User Input:** [Describe your typical daily/weekly workflow, schedule, or specific productivity challenge]\n```\n\n---\n\n**Action Tip**\n- Save these prompts in a doc called \"AI Toolkit\" for quick access\n- Customize the constraints section based on your specific industry\n- The better your input, the better your output - be specific!\n- Test different variations and save what works best for your style\n\nExplore our free [prompt collection](https://tools.eq4c.com/) for more Solopreneur prompts.",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qame2d/5_ai_prompts_every_solopreneur_needs_to_build/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nz664nj",
          "author": "davincidudee",
          "text": "Nice!",
          "score": 1,
          "created_utc": "2026-01-12 14:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6ni3j",
          "author": "unicorn69love",
          "text": "yo these prompts r clutch for solopreneurs grinding proposals and repurposing, saved me weeks already. but for twitter audience growth on autopilot check out xbeast   auto tweets replies retweets the works so u dont waste hours posting bs. total time suck otherwise imo",
          "score": 1,
          "created_utc": "2026-01-12 16:20:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8zd64",
          "author": "novofon-ai",
          "text": "These are honestly great prompts. Clean, specific, and actually practical. You can tell a lot of thought went into them â€” nice job ğŸ‘",
          "score": 1,
          "created_utc": "2026-01-12 22:48:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzadwxh",
              "author": "EQ4C",
              "text": "Thanks Mate for your feedback and appreciate for trying these prompts.",
              "score": 1,
              "created_utc": "2026-01-13 03:19:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgdk12",
      "title": "I built CloudPrompt: free prompt library stored in YOUR Google Drive (privacy-first)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qgdk12/i_built_cloudprompt_free_prompt_library_stored_in/",
      "author": "Glittering_Low3682",
      "created_utc": "2026-01-18 16:48:51",
      "score": 16,
      "num_comments": 12,
      "upvote_ratio": 0.85,
      "text": "Hey \nI built a thing to fix a problem that was quietly driving me nuts.\n\nI use ChatGPT + Claude daily (emails, debugging, brainstorming). Over time Iâ€™d collect â€œgoldâ€ promptsâ€¦ and then lose them:\n\n\\- some in Notepad\n\n\\- some in Google Docs\n\n\\- some buried in chat history\n\n\\- some justâ€¦ gone\n\nAny time I needed my â€œrewrite this professionallyâ€ prompt, Iâ€™d spend 2â€“3 minutes hunting. After a few of those per day, it adds up fast.\n\nSo I built CloudPrompt: a free Chrome extension that lets you save, organize, and pull up your prompts instantly from ANY website.\n\nThe â€œahaâ€ feature:\n\nPress Ctrl+Shift+Y (Cmd+Shift+Y on Mac) on any site â†’ your prompt library pops up â†’ search â†’ click to copy â†’ paste where you are.\n\nNo tab switching.\n\nPrivacy note (this was important to me):\n\nYour prompts are stored in YOUR Google Drive (in a CloudPrompt folder). Not on my servers. I canâ€™t see them.\n\nWhat it can do right now:\n\n\\- Folders + tags + instant search\n\n\\- Pin your top 3 prompts\n\n\\- Prompt templates with variables like: â€œWrite a \\[TONE\\] email about \\[TOPIC\\]â€¦â€\n\n\\- Import/export (JSON/CSV)\n\n\\- Works across anywebiste on Google Chrome\n\nIf youâ€™re curious, hereâ€™s the Chrome Web Store link:\n\n[https://chromewebstore.google.com/detail/cloudprompt/pihepfhlibcboglgpnpdamkgjlgaadog](https://chromewebstore.google.com/detail/cloudprompt/pihepfhlibcboglgpnpdamkgjlgaadog)  \nWebsite: [https://cloudprompt.app/](https://cloudprompt.app/)\n\nIâ€™d love feedback from other builders:\n\n1. Whatâ€™s your current â€œprompt storageâ€ system?\n2. If you tried this, what feels confusing / missing?\n3. What feature would make this a must-have for you?\n\nHappy to answer anything technical too.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qgdk12/i_built_cloudprompt_free_prompt_library_stored_in/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o0cavml",
          "author": "Adventurous-Sweet207",
          "text": "Looks promising ğŸ‘Œ",
          "score": 1,
          "created_utc": "2026-01-18 19:18:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cb1wb",
              "author": "Glittering_Low3682",
              "text": "Thank you",
              "score": 1,
              "created_utc": "2026-01-18 19:19:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ddhnt",
          "author": "FactInfinite6875",
          "text": "privacy first and goodle.. hmm , lost me there.",
          "score": 1,
          "created_utc": "2026-01-18 22:32:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cw4v5",
          "author": "shr1n1",
          "text": "Thank You ! This is exactly what I was looking for. Will try it out. Now to import all the Markdown files I have in my Dropbox folder.\n\nDoes it contextually recognize ChatGPT or Gemini Chatbot pages and pops up when on those pages ? for the prompts to be pasted ? That would be great.",
          "score": 0,
          "created_utc": "2026-01-18 21:04:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdwoi9",
      "title": "The ELI5 Prompt That Actually Makes You Understand Complex Stuff",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1qdwoi9/the_eli5_prompt_that_actually_makes_you/",
      "author": "AdCold1610",
      "created_utc": "2026-01-15 21:38:22",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 0.83,
      "text": "I was trying to understand technical concepts for my work and getting nowhere with normal explanations.\nThen I accidentally discovered this pattern that actually works.\n\nTHE PROMPT:\n\"Explain [complex topic] like I'm 5. Then explain it again like I'm 15. \nThen explain it like I'm a professional who needs to use this knowledge.\"\n\nWhy the 3-level approach is magic:\nLevel 1 (ELI5): Gets you the core concept without jargon\nLevel 2 (ELI15): Adds the nuance without overwhelming you\nLevel 3 (Professional): Gives you the technical details you can actually use\nEach level builds on the last instead of just dumping everything at once.\n\nExample - Machine Learning:\nELI5:\n\"It's like teaching a dog tricks by giving treats when it does the right thing, except the dog is a computer and the treats are math\"\nELI15:\n\"The computer looks at lots of examples, finds patterns, and learns to make predictions. Like how you learned to recognize faces by seeing lots of faces, not by someone explaining 'nose goes here, eyes go there'\"\nELI Professional:\n\"Training involves feeding labeled data through a model, adjusting weights via backpropagation to minimize loss function, then validating on unseen data to ensure generalization...\"\nNow I actually GET it instead of just memorizing definitions.\n\nWhy this destroys normal explanations:\nâœ… No awkward middle ground that's either too simple or too complex\nâœ… You can stop at whatever level you need\nâœ… The progression helps it stick in your brain\nâœ… Great for teaching others (just pick their level)\nâœ… Exposes if you actually understand it (can you do all 3 levels?)\nI use this for:\nLearning technical skills\nUnderstanding industry concepts\nExplaining my work to non-technical people\nFiguring out if I actually understand something\nOnboarding new team members\nPro tip: Ask it to do this for a concept you think you already understand.\nThe ELI5 version will show you if you've been faking it. ğŸ˜…\nTest this on something you've been struggling to learn and let me know if it clicks.\nOr tell me I'm overthinking and normal explanations work fine for you. Both valid.\n\nWant more quality prompt visit beprompter.in\n",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1qdwoi9/the_eli5_prompt_that_actually_makes_you/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "nzufxp7",
          "author": "jrdubbleu",
          "text": "I do something simple but first I prime it by telling it to learn everything about the topic, donâ€™t respond or summarize, but be prepared to answer questions at the level of an advanced stage researcher, etc",
          "score": 1,
          "created_utc": "2026-01-16 02:11:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}