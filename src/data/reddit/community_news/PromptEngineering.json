{
  "metadata": {
    "last_updated": "2026-02-26 03:06:07",
    "time_filter": "week",
    "subreddit": "PromptEngineering",
    "total_items": 20,
    "total_comments": 292,
    "file_size_bytes": 375934
  },
  "items": [
    {
      "id": "1r8xfnd",
      "title": "A cool way to use ChatGPT: \"Socratic prompting\"",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r8xfnd/a_cool_way_to_use_chatgpt_socratic_prompting/",
      "author": "Pansequito81",
      "created_utc": "2026-02-19 12:03:03",
      "score": 1378,
      "num_comments": 70,
      "upvote_ratio": 0.97,
      "text": "This week I ran into a couple of threads on Twitter about something called \"Socratic prompting\".\n\nAt first I thought, meh.\n\nBut my curiosity was piqued.  \nI looked up the paper they were talking about.\n\nI read it.  \nAnd I tried it.  \nAnd it is pretty cool.\n\nI‚Äôll tell you.\n\nNormally we use ChatGPT as if it were a shitty intern.\n\n\"Write me a post about productivity.\"  \n\"Make me a marketing strategy.\"  \n\"Analyze these data.\"\n\nAnd the AI does it.\n\nBut it does it fast and without much thought.\n\nSocratic prompting is different.\n\n**Instead of giving it instructions, you ask questions.**\n\nAnd that changes how it processes the answer.\n\nHere is an example so you can see it clearly.\n\nNormal prompt:\n\n`\"Write me a value proposition for my analytics tool.\"`\n\nWhat it gives you, something correct but a bit bland.\n\nSocratic prompt:\n\n`\"What makes a value proposition attractive to someone who buys software for their company? What needs to hit emotionally and logically? Okay, now apply that to an AI analytics tool.\"`\n\nWhat it gives you, something that thought before writing.\n\nThe difference is quite noticeable.\n\nWhy does it work?\n\nBecause language models were trained on millions of examples of people reasoning. On Reddit and sites like that.\n\nWhen you ask questions, you activate that reasoning mode.  \nWhen you give direct orders, it goes on autopilot.\n\nAnother example.\n\nNormal prompt:\n\n`\"Make me a content calendar for LinkedIn.\"`\n\nSocratic prompt:\n\n`\"What type of content works best on LinkedIn for B2B companies? How often should you post so you do not tire people? How should topics connect to each other so it makes sense? Okay, now with all that, design a 30-day calendar.\"`\n\nIn the second case you force it to think the problem through before solving it.\n\nThe basic structure is this:\n\n1. First you ask something theoretical: `\"What makes this type of thing work well.\"`\n2. Then you ask about the framework: `\"What principles apply here.\"`\n3. And finally you ask it to apply it:  `\"Now do it for my case.\"`\n\nThree questions and then the task.\n\nThat simple.\n\nAnother example I liked from the thread:\n\n`\"What would someone very good at growth marketing ask before setting up a sales funnel? What data would they need? What assumptions would they have to validate first? Okay, now answer that for my business and then design the funnel.\"`\n\nBasically you are telling it, think like an expert, and then act.\n\nI have been using it for a few days and I really notice the difference.\n\nThe output is more polished.\n\n  \nP.S. This works especially well for strategic or creative tasks.  \nIf you ask it to summarize a PDF, you will likely not notice much difference.  \nBut for thinking, it works.",
      "is_original_content": false,
      "link_flair_text": "Tips and Tricks",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r8xfnd/a_cool_way_to_use_chatgpt_socratic_prompting/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o68hr3x",
          "author": "Slick_McFavorite1",
          "text": "This is the first post in a long time that actually has value in this subreddit. Laying out best practices vs just some 4 page mega prompt.",
          "score": 142,
          "created_utc": "2026-02-19 13:10:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68reqt",
              "author": "Ou812_tHats_gRosS",
              "text": "Right on.  This sub has devolved into ‚Äúhey here‚Äôs a mega prompt I asked AI to create, and here‚Äôs 4 pages of slop‚Äù. This post actually has human advice!",
              "score": 26,
              "created_utc": "2026-02-19 14:05:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o68wix3",
          "author": "sovietreckoning",
          "text": "I recently wrote a short article for a client‚Äôs website about attorneys using AI because I was finding similar results. Not necessarily using the Socratic prompting you‚Äôre describing, but applying the principles of legal reasoning and questioning to LLMs. I‚Äôm a lawyer when I have to be, and I genuinely find myself getting the best results when I treat my prompts like contracts or like a cross-exam. I find it super useful to ask questions I already know the answers to so I can build guardrails around my prompt before asking the important questions. Thanks for sharing!",
          "score": 18,
          "created_utc": "2026-02-19 14:33:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b0glx",
              "author": "Kng_Wzrd0715",
              "text": "Can you share a link to the article? I‚Äôd love to give it a read and integrated into my practice area.",
              "score": 5,
              "created_utc": "2026-02-19 20:42:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6b820w",
                  "author": "sovietreckoning",
                  "text": "I‚Äôd rather not, just because I don‚Äôt use this Reddit account professionally, but the tl;dr is that we‚Äôre seeing and hearing about our peers using AI to generate pleadings, hallucinating citations, etc and the courts and bar associations are setting rules against the use of AI and cautioning against its dangers. Meanwhile the layperson believes ChatGPT is already a substitute for hiring a lawyer. The reality is that (shockingly) both extremes are wrong. We shouldn‚Äôt shy away from using LLMs in the legal profession, but we also can‚Äôt expect them to replace us. We simply need to apply the tools we learned on the first day of law school and the thinking skills we use every day to get really good results. Things like not asking the question if you don‚Äôt already know the answer, issue spotting, understanding and applying court holdings across different sets of facts. Even constitutional arguments are extremely on point - over-broad, void for vagueness, facially void vs as applied. We‚Äôre trained to distill facts into issues and that can be analyzed and applied consistently for a valid result. \n\nBasically a bunch of bullshit glazing about how great we are (because it‚Äôs blog content) but also pretty neat when applied to prompt engineering.",
                  "score": 3,
                  "created_utc": "2026-02-19 21:18:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6afibx",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 9,
          "created_utc": "2026-02-19 19:00:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6j4zlp",
              "author": "GR-747",
              "text": "Damn your response is so well-formatted that I thought you used AI. I can't quite understand a few parts but I will figure it out.",
              "score": 1,
              "created_utc": "2026-02-21 01:48:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o68e649",
          "author": "Much_Highlight_1309",
          "text": "Good idea. To go one step further, I suggest you share this post with your LLM, using it as base prompt, with the additional instruction to turn any \"normal prompt\" for some task you want it to perform into a \"Socratic prompt\" and then use the former to perform the task. Then you don't need to go through that conversion process yourself.",
          "score": 29,
          "created_utc": "2026-02-19 12:47:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f1yec",
              "author": "weaverk",
              "text": "Isn‚Äôt half the value in this approach the fact that we do this ourselves, we can therefore guide the ai to what is most relevant to us? Don‚Äôt think you will get the same with an ai making it",
              "score": 6,
              "created_utc": "2026-02-20 13:23:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fa45l",
                  "author": "Much_Highlight_1309",
                  "text": "You likely will get something that's better than not doing it at all, which is a step in the right direction. That's pretty much how expert AIs for a specific specialist domain work. They have instructions on what sources to source information from, processes to follow based on best practices (for example in engineering sciences) etc. If you want other end results based on different specifications you can always tell it to NOT follow these instructions and instead follow whatever special prompt that follows.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:07:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bm4uc",
          "author": "Dry-Writing-2811",
          "text": "When I get a response, I always send the following second prompt: \"Severely critique your suggestion to identify any shortcomings or blind spots. Justify your criticisms and tell me what you would do to improve your suggestion.\"",
          "score": 5,
          "created_utc": "2026-02-19 22:29:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bdfni",
          "author": "FreshRadish2957",
          "text": "I would have paid more attention to your concept if it wasn't generated by AI and I don't mean that as a dig it's just we don't learn any new tricks if AI is teaching them.",
          "score": 8,
          "created_utc": "2026-02-19 21:45:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bphzt",
              "author": "Pansequito81",
              "text": "English is not my native language, so I used AI to translate it.   \nI can send you the original text in my language if that helps you learn more.",
              "score": 12,
              "created_utc": "2026-02-19 22:47:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bps9n",
                  "author": "FreshRadish2957",
                  "text": "No that clarification is enough and I really appreciate it, I shouldn't have been so quick to dismiss. Thank you again for taking the time to clarify :)",
                  "score": 13,
                  "created_utc": "2026-02-19 22:49:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6aofcz",
          "author": "mythrowaway4DPP",
          "text": "I would advocate splitting these questions and letting the ai answer before continuing. It has been shown that outcome can be improved that way.",
          "score": 3,
          "created_utc": "2026-02-19 19:43:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6awo2s",
          "author": "Mara3l",
          "text": "Funny, how this would work on interns just as well. They often go on autopilot and just do what told, but when asked, they give it more time/thought.",
          "score": 3,
          "created_utc": "2026-02-19 20:23:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6agrcg",
          "author": "UnprocessedAutomaton",
          "text": "Good morning! Socratic prompt has been there‚Äôs since ages. Even OpenAI Academy has a free tutorial on it. But, good post and a great reminder.",
          "score": 4,
          "created_utc": "2026-02-19 19:06:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ec2yh",
          "author": "TeamAlphaBOLD",
          "text": "This is such a cool trick.¬†¬†\n\nBeen playing with Socratic prompting too, and it really changes the vibe.¬†Instead of getting a ‚Äúmeh‚Äù answer, ChatGPT actually thinks through the problem and gives stuff that feels smarter and more polished.¬†¬†",
          "score": 2,
          "created_utc": "2026-02-20 10:10:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hd6vl",
          "author": "Important-Cry-2995",
          "text": "Or better, as a single question for ChatGPT to provide you with all the questions you should be asking. To use your LinkedIn calendar example:\n\nAsk: What are all the questions that someone interested in B2B promotions ask themselves prior to developing a calendar?\n\nThen turn around and use those provided questions in your Socratic method.\n\nI often use ChatGPT to develop its own prompts for requests because it‚Äôs way better at seeing all the angles than I am.",
          "score": 2,
          "created_utc": "2026-02-20 20:01:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kv5pu",
          "author": "Sad-Improvement-957",
          "text": "I‚Äôve been doing Socratic prompting for over  3 years..",
          "score": 2,
          "created_utc": "2026-02-21 10:09:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68yorv",
          "author": "ThaBeatGawd",
          "text": "Late af to the party but you made it",
          "score": 4,
          "created_utc": "2026-02-19 14:45:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68b7j2",
          "author": "Ok-Tradition-82",
          "text": "look mum, i learnt to think.",
          "score": 4,
          "created_utc": "2026-02-19 12:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68t041",
          "author": "CyborgBob1977",
          "text": "This seems like good info, I can't wait to try it.",
          "score": 1,
          "created_utc": "2026-02-19 14:14:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68wdwg",
          "author": "Acrobatic_Sample_552",
          "text": "Do you have a prompt to plug into the settings so that it could provide these Socratic questions all the time?",
          "score": 1,
          "created_utc": "2026-02-19 14:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68xdnj",
          "author": "Mediocre-Chart-5336",
          "text": "This is knowledge on what is the prompt about.",
          "score": 1,
          "created_utc": "2026-02-19 14:38:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a11st",
          "author": "Equal-Yogurtcloset17",
          "text": "Refreshing - short, clear instructions to higher quality output.",
          "score": 1,
          "created_utc": "2026-02-19 17:52:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a95pd",
          "author": "ImT0by",
          "text": "oh, nice. I have been doing this for a while, didn't know it had a name. ",
          "score": 1,
          "created_utc": "2026-02-19 18:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6aewx3",
          "author": "fingerkeyboard",
          "text": "Great. Thanks for sharing. Now I've saved it under memories that even if i don't structure my questions like that it will still answer in this manner.",
          "score": 1,
          "created_utc": "2026-02-19 18:57:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cz442",
          "author": "Opandemonium",
          "text": "This is how I use chat.",
          "score": 1,
          "created_utc": "2026-02-20 03:20:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6do1aw",
          "author": "giantoads",
          "text": "This...",
          "score": 1,
          "created_utc": "2026-02-20 06:26:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e8ue5",
          "author": "Nexus888888",
          "text": "Mayeutic Method",
          "score": 1,
          "created_utc": "2026-02-20 09:40:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ed41g",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-20 10:19:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ed42r",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-20 10:19:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fly50",
          "author": "muhlfriedl",
          "text": "I always do this",
          "score": 1,
          "created_utc": "2026-02-20 15:08:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gedc2",
          "author": "mr_ah_clem",
          "text": "This is cool.  I am designing a Unreal 5.6 game using Claude.  Claude and I came up with a method of developing the projects requirements docs using what we termed \"Our Socratic Dialogue\".  I give Claude the background and high level requirements for a new functional area ( Weapon Pickups for example) and then Claude through a series of questions back to me nails down the actual functional requirements and generates what we call a Sys_Requirements doc that gives the next Claude instance a firm requirements base to work from.  It works great.",
          "score": 1,
          "created_utc": "2026-02-20 17:20:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6h56ge",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-20 19:22:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h56iw",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-20 19:22:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hmmjo",
          "author": "pffnopee",
          "text": "Thanks üôè",
          "score": 1,
          "created_utc": "2026-02-20 20:47:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6j3559",
          "author": "WiredNet",
          "text": "I can't even read 1/4th of this post without gagging, as it's so obviously written by ChatGPT in the style that we're all so tired of being subjected to",
          "score": 1,
          "created_utc": "2026-02-21 01:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jp8sx",
          "author": "erisian2342",
          "text": "At the end of this type of prompt, I add something like, ‚ÄúBefore we get started, do you have any additional questions for me?‚Äù or ‚ÄúWhat else do you need to know first to make this excellent?‚Äù  \n\nChatGPT is very good at responding with thought provoking questions, often pointing to ways that improve the solution that I haven‚Äôt considered or even known about.",
          "score": 1,
          "created_utc": "2026-02-21 03:58:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ka13k",
          "author": "BigGreasy11",
          "text": "Socrates would hate this",
          "score": 1,
          "created_utc": "2026-02-21 06:43:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n4jgx",
          "author": "justin_reborn",
          "text": "Just used it. Very very impactful. Takes the onus off the user to specify things that may not immediately comes to mind. Addresses the classic problem of the unknown unknown.  Offloads even more of the cognitive load to the AI.",
          "score": 1,
          "created_utc": "2026-02-21 18:35:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o1zxf",
          "author": "Low-Major-3553",
          "text": "Thank you",
          "score": 1,
          "created_utc": "2026-02-21 21:28:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ow1xj",
          "author": "GetFroggyHoe",
          "text": "This is very interesting. I'm going to try this with other models!",
          "score": 1,
          "created_utc": "2026-02-22 00:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p1rgu",
          "author": "Emergency_Speed_4381",
          "text": "Neat",
          "score": 1,
          "created_utc": "2026-02-22 00:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qx690",
          "author": "Legitimate-Hippo-977",
          "text": "Asking a question vs. a direction doesn‚Äôt change the processing. The language model behaves the same, predicting tokens based on what came before.\nI think the reason for better, more thoughtful outputs, is that questions are naturally more open-ended and answers can include more nuance and uncertainty, whereas a direction quickly will lead the LLM towards one answer without taking all possible nuances into account.",
          "score": 1,
          "created_utc": "2026-02-22 09:44:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rmflr",
          "author": "IllMoment4388",
          "text": ">Write me a value proposition for my analytics tool.\n\n\nWait, people actually use it in this way outside of trying it for the first time for free? \n\n\n\n",
          "score": 1,
          "created_utc": "2026-02-22 13:21:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s37kz",
          "author": "Moist-Nectarine-1148",
          "text": "Socratic bullshit. ",
          "score": 1,
          "created_utc": "2026-02-22 14:56:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t7ukh",
          "author": "KulshanStudios",
          "text": "That's basically what I do. And most of the time I get useful answers back. Sometimes Gemini latches on to ideas that are old and no longer relevant to the immediate task at hand, but I can divert it from that to stay on topic",
          "score": 1,
          "created_utc": "2026-02-22 18:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vzu5f",
          "author": "Dry-Necessary-1302",
          "text": "Wouldn't this increase the token number and the costing? Considering it needs to go through more context now. I could be completely wrong as well!",
          "score": 1,
          "created_utc": "2026-02-23 02:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wh7br",
          "author": "TylerDurdenFan",
          "text": "I thought you were going to mention my method.\n\nI'll one up you, what works best for my complex design use cases is:\n\nLead with describing whatever I want built.\n\nFinish with something like: \"please analyze this idea and ask the questions needed to refine it into a sound one and to ensure a proper eventual implementation\".\n\nThis leads to me answering several rounds of questions, often things I hadn't considered, often things that if unspecified could allow the LLM to go to an undesired path. I often even learn from the questions asked. Usually Claude Opus will continue to ask further questions until it's got nothing left. Only then do I ask it to proceed, and the results are much, much better than what I used to get before I started doing this.",
          "score": 1,
          "created_utc": "2026-02-23 04:56:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y0up3",
              "author": "Busy-Specialist7708",
              "text": "I let Claude peer review my work I do with chatgpt, then let chatgpt read the critisism and do something with it. Works great. My prompt is like 'read this, digest it, then roast it, see if it's bs and rate it. I wont stop until Claude has no more complains and rates it 5/5¬†",
              "score": 1,
              "created_utc": "2026-02-23 13:03:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xuoqp",
          "author": "Adguy69420",
          "text": "Saved",
          "score": 1,
          "created_utc": "2026-02-23 12:20:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xzf8e",
          "author": "Busy-Specialist7708",
          "text": "Imagine you need a song about dogs. Ask it and it will give you the most generic song about dogs.\n\n\nA route I've been using is ask it to learn me about how to write songs, so I can write proffesional sounding songs (as example). I will ask it all kinds questions indeed that are importent and save those in docs. Once I gathered enough value, I feed those docs to AI and ask to produce a whole book on how to write songs like a proffesional songwriter based on information that is really important. Do it section by section and copy paste. Once book done, feed it to back to the AI in a new chat/project and use it only to generate songs. Bam, no more generic songs",
          "score": 1,
          "created_utc": "2026-02-23 12:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68bnek",
          "author": "Jaded_Platform1723",
          "text": "This is amazing, I loved it, after reading the post here, I went to my ai tool and tried this, this really worked and thank you. I mean the way it works very few would do this, prompt does matter, because nowadays it dont just leverage our results but prompt engineering can leverage our skills too.\n\nThe way you framed the examples is insightful and interesting, basically we do like you said write me a post about blah blah,... I also done the same just one day ago for the post of digital marketing fpr a linkedin post**, I would love to try such strategic  prompt** and I believe that it will crawl the best outcomes. \n\nYes you are right, if we directly order to the tool, they react soon and gives the result, but if we let them think like they are asked a question, indeed they would act as a thinker and researcher and will give a polished outcome as compared to the vague prompt.   \n  \nThe real competitive advantage in the AI era and isn‚Äôt access to tools. Prompt engineering is no longer a technical trick but it‚Äôs professional leverage.",
          "score": -5,
          "created_utc": "2026-02-19 12:29:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68d089",
              "author": "Ok-Tradition-82",
              "text": "slop",
              "score": 4,
              "created_utc": "2026-02-19 12:39:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dp7yg",
          "author": "LegitimatePower",
          "text": "This prompt is so hilariously bad.",
          "score": -2,
          "created_utc": "2026-02-20 06:37:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rci46t",
      "title": "Prompt Engineering is Dead in 2026",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rci46t/prompt_engineering_is_dead_in_2026/",
      "author": "z3r0_se7en",
      "created_utc": "2026-02-23 13:57:25",
      "score": 262,
      "num_comments": 100,
      "upvote_ratio": 0.73,
      "text": "The reality in 2026 is that the \"perfect prompt\" just isn't the flex it was back in 2024. If you're still obsessing over specific phrasing or \"persona\" hacks, you‚Äôre missing the bigger picture. Here is why prompts have lost their crown:\n\n1.    Models actually \"get\" it now: In 2024, we had to treat LLMs like fragile genies where one wrong word would ruin the output. Today‚Äôs models have way better reasoning and intent recognition. You can be messy with your language and the AI still figures out exactly what you need.\n\n2.    Context is the new Prompting: The industry realized that a 50-page prompt is useless compared to a well-oiled RAG (Retrieval-Augmented Generation) pipeline. It‚Äôs more about the quality of the data you‚Äôre feeding the model in real-time than the specific instructions you type.\n\n3.    The \"Agentic\" Shift: We‚Äôve moved from chatbots to agents. You don't give a 1,000-word instruction anymore; you give a high-level goal. The system then breaks that down, uses tools, and self-corrects. The \"prompt\" is just the starting gun, not the whole race.\n\n4.    Automated Optimization: We have frameworks like DSPy from Stanford that literally write and optimize the instructions for us based on the data. Letting a human manually tweak a prompt in 2026 is like trying to manually tune a car engine with a screwdriver when you have an onboard computer that does it better.\n\n5.    The \"Secret Sauce\" evaporated: In 2024, people thought there were secret techniques like \"Chain of Thought\" or \"Emotional Stimuli.\" Developers have baked those behaviors directly into the model's training (RLHF). The model does those things by default now, so you don't have to ask.\n\n6.   Architecture > Adjectives: If you're building an app today, you spend 90% of your time on the system architecture‚Äîthe evaluation loops, the guardrails, and the model routing‚Äîand maybe 10% on the actual text instruction. The \"words\" are just the cheapest, easiest part of the stack now.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rci46t/prompt_engineering_is_dead_in_2026/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6yckp2",
          "author": "c126",
          "text": "What was the prompt for this post?",
          "score": 475,
          "created_utc": "2026-02-23 14:12:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yjgr1",
              "author": "Awkward_Major7215",
              "text": "Probably it beginning something like: Act as ai fanatic Reddit user ...",
              "score": 96,
              "created_utc": "2026-02-23 14:49:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o739ukj",
                  "author": "b2q",
                  "text": "Ofcourse this is ai output, but still its true",
                  "score": 5,
                  "created_utc": "2026-02-24 05:57:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o74fctc",
                  "author": "naruda1969",
                  "text": "Ai fanfic",
                  "score": 3,
                  "created_utc": "2026-02-24 12:06:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zwwax",
              "author": "z3r0_se7en",
              "text": "Original - \"prompt engineering is dead in 2026. give statements in support\"\n\nRefine 1 - \"write like a smart college student\"\n\nRefine 2 - \"no write it like prompts don't matter as much as they used to in 2024. don't focus on prompt engineer profile.\"\n\n\nYou can see how context matters more than prompts now. Also it was in google's aimode.",
              "score": 44,
              "created_utc": "2026-02-23 18:42:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70piqz",
                  "author": "c126",
                  "text": "This actually interesting, thanks for sharing.",
                  "score": 18,
                  "created_utc": "2026-02-23 20:56:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o72rd3s",
                  "author": "azunaki",
                  "text": "Sooo, satire?",
                  "score": 2,
                  "created_utc": "2026-02-24 03:43:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o73bkr1",
                  "author": "Ill_Dragonfruit_3547",
                  "text": "Optimize for anonymous internet comment section",
                  "score": 1,
                  "created_utc": "2026-02-24 06:11:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ce1so",
                  "author": "The_Memening",
                  "text": "Your honor; the defense is leading the witness.",
                  "score": 1,
                  "created_utc": "2026-02-25 15:49:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7284t7",
              "author": "Seafaringhorsemeat",
              "text": "The same as the one he posted 43 minutes ago saying It's not dead, it just evolved.",
              "score": 5,
              "created_utc": "2026-02-24 01:50:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o73pnv1",
              "author": "klutzy-ache",
              "text": "https://www.reddit.com/r/PromptEngineering/s/Cs3JEXZnE6",
              "score": 1,
              "created_utc": "2026-02-24 08:16:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6yjoyp",
              "author": "kueso",
              "text": "Wow you‚Äôre so edgy. Why is this everyone‚Äôs response now to stuff they don‚Äôt want to hear?",
              "score": -35,
              "created_utc": "2026-02-23 14:50:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6yk74r",
                  "author": "c126",
                  "text": "It‚Äôs just annoying obvious that it was completely ai generated without any human thought at all. Waste of time.",
                  "score": 24,
                  "created_utc": "2026-02-23 14:53:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6yn173",
          "author": "ben_bliksem",
          "text": "You've convinced me. See you at r/ContextEngineering\n\nPeace out ‚úåÔ∏è",
          "score": 37,
          "created_utc": "2026-02-23 15:08:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ylqmq",
          "author": "Consistent_Recipe_41",
          "text": "Context is everything",
          "score": 12,
          "created_utc": "2026-02-23 15:01:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o71i57x",
              "author": "kontekxt",
              "text": "I konkur",
              "score": 1,
              "created_utc": "2026-02-23 23:22:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z4dpp",
          "author": "Protopia",
          "text": "In essence what you are saying is that Prompt Engineering has been replaced by engineering your AI environment to ensure that you have appropriate MCP servers to provide the same expertise and knowledge but more efficiently than e.g. having a long prompt or repeatedly attaching all the files in your codebase to the context. \n\nBut, AFAICT you can still improve the quality and productivity of your AI usage by prompts (or files or skills etc. which are essentially the same thing) to reduce hallucinations, avoid having the AI spend extra times on things that can be done by normal algorithmic tools (like code formatting), doing the AI equivalent of desk walkthroughs of the code to find bugs when running the test cases can be cheaper and quicker, and optimizing the agentic bug fix algorithms to research rather than experiment and to avoid context compaction causing repeating the same solution attempts.\n\nSo the engineering focus has switched rather than disappeared.",
          "score": 6,
          "created_utc": "2026-02-23 16:30:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yz34g",
          "author": "Utoko",
          "text": "but slop AI post are still a thing in 2026",
          "score": 3,
          "created_utc": "2026-02-23 16:06:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yghmp",
          "author": "Conscious_Nobody9571",
          "text": "\"Prompts have lost the crown\" to what? They're still the most important thing... If you think context is more important you're wrong",
          "score": 10,
          "created_utc": "2026-02-23 14:34:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yui2u",
              "author": "JollyJoker3",
              "text": "Not sure about how the actual semantics go here but all the model sees is context and it has no clue what came from a prompt and what didn't",
              "score": 5,
              "created_utc": "2026-02-23 15:44:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yd5kt",
          "author": "DingirPrime",
          "text": "You‚Äôre right that the 2024 version of prompt engineering is basically over, because the days of stacking persona tricks, obsessing over perfect wording, telling the model to act as a genius expert, or trying to manipulate it with emotional cues and forced step by step reasoning are mostly behind us, and models are simply better now, they understand intent more naturally, and you can be loose with your wording and still get solid output since much of what people thought was secret technique has been baked into training through stronger alignment and reinforcement learning, but what actually died was the gimmicks, not the discipline itself, because prompt engineering did not disappear, it matured and shifted from clever phrasing to serious system design, and if you are building anything real in 2026 you are not polishing adjectives, you are designing architecture, thinking about retrieval pipelines, evaluation loops, guardrails, routing logic, tool integration, and feedback mechanisms, and in production environments architecture matters far more than wording, where I disagree is with the idea that prompting no longer matters at all, because it absolutely does, it just operates at a higher level now, instead of fine tuning sentences we are defining objectives, constraints, failure boundaries, validation rules, risk thresholds, compliance requirements, and escalation paths, and that is still instruction design, just not cosmetic anymore, tools like DSPy can optimize prompts and automated systems can tune instructions, but they do not decide what correct means for your business, they do not define acceptable risk, they do not automatically encode regulatory requirements, and they do not decide when a system should stop and fail instead of pushing an answer, those decisions still come from humans, and while it is true that words are now the cheapest layer of the stack, assuming instructions no longer matter is a stretch, because they matter more now that we are building agents that take actions instead of chatbots that just generate text, and there is a huge difference between a wrong answer and a wrong action, so if you deploy RAG without evaluation, agents without constraints, tool use without verification, or automated optimization without audit logging, you are going to ship costly mistakes, so yes the hacky phrasing era of prompt engineering is gone, but structured problem design, clear constraints, guardrails, validation loops, and governance are not dead, they are the backbone of serious AI systems today, because architecture may be more important than adjectives, but architecture is built on decisions, and those decisions do not define themselves.",
          "score": 12,
          "created_utc": "2026-02-23 14:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ygyam",
              "author": "pissagainstwind",
              "text": ">if you are building anything real in 2026 you are not polishing adjectives, you are designing architecture, thinking about retrieval pipelines, evaluation loops, guardrails, routing logic, tool integration, and feedback mechanisms\n\nBut that has less to do with AI specifically and more to do with programming in general, and, these were just as important 3 years ago as they are now.  the bottom line is we don't need to use prompt engineering anymore and it was obvious to anyone even back then that the role of a \"prompt engineer\" is a short lived one.",
              "score": 3,
              "created_utc": "2026-02-23 14:36:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6z5sg0",
                  "author": "DingirPrime",
                  "text": "I agree that the job title ‚Äúprompt engineer‚Äù was likely hype driven and short lived, and that architecture, guardrails, evaluation loops, routing, and feedback systems have always been core engineering principles. But if we define prompt engineering as persona tricks and magic phrasing, then yes, that version is mostly obsolete because models have improved and absorbed much of that behavior. What hasn‚Äôt disappeared is the instruction layer itself. It just moved up the stack. Traditional programming is deterministic, while LLM systems are probabilistic, which means defining objectives, constraints, evaluation criteria, risk thresholds, and failure conditions still matters, especially as systems become agentic and take actions instead of just generating text. So the hype role may have faded, but the underlying discipline evolved into AI architecture and governance, and it becomes more critical as autonomy increases, not less.",
                  "score": 2,
                  "created_utc": "2026-02-23 16:37:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ywntw",
          "author": "fulowa",
          "text": "my process where i work:\n- create benchmark with human expert\n- create llm judge that scores high on benchmark labels (tricky part)\n- use llm judge to iterate prompt with an llm",
          "score": 2,
          "created_utc": "2026-02-23 15:54:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73pi30",
          "author": "klutzy-ache",
          "text": "What I got from Gemini asking for 10 bullets about why prompt engineering is dead in 2026\n\n---\n\nIt‚Äôs official: we‚Äôve moved past the era of \"prompt sorcery.\" By 2026, the job title \"Prompt Engineer\" has largely followed the path of the \"Webmaster\"‚Äînot because the work vanished, but because the technology grew up and the skill became a standard part of every professional's toolkit.\n\nHere are 10 reasons why manual prompt engineering is considered \"dead\" in 2026:\n\n‚Ä¢ Intent Recognition is Now \"Fuzzy-Proof\": Models in 2026 no longer require \"perfect\" phrasing. Advanced reasoning capabilities allow AI to interpret messy, ambiguous human language and correctly infer the user's intent without specific persona hacks or syntax tricks.\n\n‚Ä¢ The Rise of \"Context Engineering\": The focus has shifted from writing the perfect sentence to building the perfect environment. Success now depends on RAG (Retrieval-Augmented Generation) pipelines‚Äîfeeding the model the right data, files, and live context rather than just a clever set of instructions.\n\n‚Ä¢ DSPy and Automated Optimization: Frameworks like Stanford‚Äôs DSPy have automated the \"tuning\" phase. Instead of a human manually tweaking a prompt for hours, these systems programmatically optimize instructions based on data, doing it more accurately than any human could.\n\n‚Ä¢ Default \"Chain-of-Thought\": Techniques that used to be manual \"hacks\" (like telling the AI to \"think step-by-step\") are now baked into the model's native architecture. Models perform these logical leaps by default through RLHF and inference-time scaling.\n\n‚Ä¢ From Chatbots to Agentic Workflows: We no longer write 1,000-word prompts for a single response. We set high-level goals for \"Agentic\" systems that autonomously plan, call their own tools, and self-correct, making the initial prompt just the \"starting gun\" rather than the whole race.\n\n‚Ä¢ Multimodal Native Understanding: In 2026, prompts aren't just text. Models process video, audio, and images simultaneously. \"Prompting\" has evolved into Multimodal Interaction, where showing the AI a sketch or a screen recording is more effective than describing it in text.\n\n‚Ä¢ Meta-Prompting (AI Writing for AI): The most effective prompts today are written by other AI models. Humans provide the objective, and a \"meta-prompting\" model generates the complex, structured system instructions required for the task.\n\n‚Ä¢ Tool-Use Maturity: AI is now deeply integrated with software (APIs, IDEs, CRMs). Instead of \"prompting\" a model to simulate a task, we give it the tools to actually do the task. The engineering is now in the tool-integration, not the word choice.\n\n‚Ä¢ Prompting as a Feature, Not a Skill: Like typing or using a search engine, \"basic prompting\" is now a core competency taught in middle school. It‚Äôs no longer a specialized career path; it‚Äôs just how people use computers.\n\n‚Ä¢ Model Reliability and Safety Guardrails: Heavy manual \"jailbreaking\" or complex formatting to ensure safety/compliance is gone. Built-in governance layers handle the \"how\" of the response, allowing users to focus entirely on the \"what.\"",
          "score": 2,
          "created_utc": "2026-02-24 08:15:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74i1ok",
          "author": "PromptForge-store",
          "text": "I agree with most of this ‚Äì especially the shift towards architecture and RAG.\n\nBut I wouldn‚Äôt say prompt engineering is ‚Äúdead.‚Äù\n\nIt‚Äôs just no longer about clever wording tricks.\n\nIt‚Äôs about structured thinking.\n\nEven in agentic systems, someone still has to define goals clearly, design constraints, structure evaluation loops, and think through failure cases.\n\nThe ‚Äúperfect sentence‚Äù might be irrelevant now.\n\nBut the ability to think systematically about how humans communicate intent to machines?\nThat‚Äôs probably more important than ever.\n\nMaybe prompt engineering didn‚Äôt die.\nIt just evolved into system design.",
          "score": 2,
          "created_utc": "2026-02-24 12:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78gssn",
          "author": "KrissyNessNZ",
          "text": "I‚Äôd really love to see actual annotated prompts in this subreddit. Lots of claims here but I would be good to see the proof. \n\nSolid points for you OP, and including your process in the comments",
          "score": 2,
          "created_utc": "2026-02-25 00:00:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o713l8l",
          "author": "Defiant_Conflict6343",
          "text": "\"Prompt engineering\" is and always has been absolute nonsense for people who want to LARP as engineers and think a YouTube guide or a $20 online course entitles them to some unearned academic prestige.¬†The simple fact is, every LLM is statistically fitted based on what people spew on the internet. The mathematically best way to achieve a good output? Just mirror the mean-average language of whatever forum posts or queries achieved good outputs. Literally just convey what you want accurately and coherently, and if the LLM hallucinates, jumble the words a little. Nothing more than that has ever been needed.\n\n\nThe simple truth is \"prompt engineers\" have absolutely no idea how LLMs work, not even a cursory understanding of the transformer architecture or even a basic grasp of¬† statistical modelling. This has always been a puffed up imaginary title for people drowning in the Dunning Kruger effect who have deluded themselves into thinking there's some secret sauce to exploit.",
          "score": 2,
          "created_utc": "2026-02-23 22:06:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ypnzx",
          "author": "montdawgg",
          "text": "Your prompts might be dead, but mine aren‚Äôt. Against vanilla GPT, and even thinking mode on agentic systems, my prompts give 10x the output when applied to either scenario.",
          "score": 2,
          "created_utc": "2026-02-23 15:21:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yn4sf",
          "author": "RecaptchaNotWorking",
          "text": "How do you use DSPy for a model you don't own like Gemini or claude.",
          "score": 1,
          "created_utc": "2026-02-23 15:08:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yoieg",
          "author": "WillowEmberly",
          "text": "I mostly agree with this‚Ä¶prompts stopped being the leverage point a while ago.\n\nBut I don‚Äôt think ‚Äúagentic AI‚Äù replaced them either. We already saw that in 2025: Microsoft Copilot agents, AutoGPT-style workflows, etc. The agents weren‚Äôt meaningfully better because they inherited the same failure modes as prompts, just spread over more steps.\n\nWhat actually changed in 2026 isn‚Äôt agency ‚Äî it‚Äôs dynamic system design.\n\nThe leverage moved to:\n\n\t‚Ä¢\texplicit halt authority\n\n\t‚Ä¢\tdrift detection\n\n\t‚Ä¢\texternal reference hooks\n\n\t‚Ä¢\treversibility under uncertainty\n\n\t‚Ä¢\tevaluation loops that can say ‚Äústop,‚Äù not just ‚Äúoptimize‚Äù\n\nIn other words: prompts didn‚Äôt die ‚Äî they got demoted.\nThey‚Äôre now just one interface inside a system that has to stay corrigible over time.\n\nIf your system can‚Äôt notice when it‚Äôs drifting, no amount of agents, RAG, or auto-optimization will save it. It‚Äôll just fail more confidently.",
          "score": 1,
          "created_utc": "2026-02-23 15:15:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yuv30",
          "author": "Happy_Being_1203",
          "text": "Starting now my prompt will contain just ‚ÄòFix it‚Äô or ‚ÄòDo it‚Äô or ‚ÄòWhat the heck, why you cannot make it work‚Äô. The latter actually works most of the time",
          "score": 1,
          "created_utc": "2026-02-23 15:46:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yy3mj",
          "author": "Echo_Tech_Labs",
          "text": "I posted something similar to this last year.\n\nI was wrong. It's not dying, it‚Äôs  merely changing.\n\nAs long as AI exist, so will prompt engineering.\n\nContext engineering or prompt engineering...call it what you want to call it, its all the same thing.\n\nAnd to the OP: it's not dead...people have just become better at it and those of us who figured this out early stopped trying to prove something. As models get better at understanding context its become easier. The PromptEngineering community has bifurcated into amateurs who are still trying to bend the model with this protocol and that framework while the professionals just keep on keeping on.\n\nMost of us have already moved on from prompting into creating actual tools and systems we learnt how to build during the good days of GPT 4 and so on.\n\nIts the same reason why \"role\" based prompts aren't necessary anymore. \n\nThe models have just gotten better. Simple as that.\n\nAs GPT would put it...no mysticism necessaryüòâ\n\nIf you want we can go deeper:\n\n[Insert obligatory question here]",
          "score": 1,
          "created_utc": "2026-02-23 16:01:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z3eel",
          "author": "OptiCraft_tech",
          "text": "I actually agree with 90% of this‚Äîthe era of 'Adjective Prompting' (persona hacks and emotional stimulus) is definitely dead. But I don't think Prompt Engineering is dying; it's just evolving into Prompt Management & Evaluation.\n\nYou're spot on that Architecture > Adjectives. But as models get smarter and our systems move from chatbots to agents, the 'Prompt' becomes the logic layer of that architecture. If we treat it like code, we need the same tools developers use:\n\n1. Strict Versioning: If context is king, we need to track how our system instructions change as our RAG data and model versions (GPT-5 vs Claude Opus 4.5) evolve.\n2. Structured Discovery: We need a way to see what logic structures (like XML tagging or DSPy-style optimization) actually scale across different agentic flows.\n\nI built PromptCentral (promptcentral.app) precisely because I saw this shift coming. It‚Äôs a project I‚Äôve been working on to help engineers manage the versioned, logic-heavy prompts that drive modern agentic systems. \\[Full disclosure: I'm the founder, just looking for feedback from people who agree with your take!\\]\n\nAre you guys finding that you're spending more time on the 'metadata' (tags, model routing, versioning) than the text itself?",
          "score": 1,
          "created_utc": "2026-02-23 16:26:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zeo27",
          "author": "IngeniousIdiocy",
          "text": "you lost me at RAG",
          "score": 1,
          "created_utc": "2026-02-23 17:18:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zgrwb",
          "author": "Background_Summer_55",
          "text": "Couldn't be more wrong",
          "score": 1,
          "created_utc": "2026-02-23 17:28:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zkyti",
          "author": "IWantToSayThisToo",
          "text": "It was called prompt engineering, it was supposed to be the next big step for humans. Now ChatGPT does what I want 95% of the time with whatever sloppy, misworded, badly formatted crap I throw at it.\n\n\nAnd they're like \"ohh no it's context engineering now!!!\". And that might be, for the (very short) time being.\n\n\nIn reality it's all a huge COPE to say \"we humans are needed still!! See nobody else could do this!\".",
          "score": 1,
          "created_utc": "2026-02-23 17:48:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zmb2f",
          "author": "aadarshkumar_edu",
          "text": "In 2026, obsessing over a 'persona' is like trying to improve a car‚Äôs performance by polishing the dashboard. It looks nice, but it doesn't move the needle.\n\nThe real shift hasn't been about writing 'better' English; it‚Äôs about **Context Engineering**. As you mentioned with RAG and the 1M token windows, the challenge isn't the instruction; it's the **State Management**. When you have a swarm of agents hitting one repo, the 'Prompt' is just a tiny configuration file in a much larger **Orchestration Layer**.\n\nI‚Äôve found that the most successful teams right now aren't hiring 'Prompt Engineers'; they are hiring **AI Architects** who can build the evaluation loops and the 'Guardrail Governors' that keep those agents from drifting.\n\nArchitecture > Adjectives. Every single time.",
          "score": 1,
          "created_utc": "2026-02-23 17:54:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zmif3",
          "author": "blue_cloud_m7",
          "text": "My two cents: Context absolutely matters more in 2026 ‚Äî but that doesn‚Äôt mean prompting is dead.\n\nContext defines the stage. Prompt defines the line delivered on it.Even with strong reasoning models, small phrasing shifts can still change intent. \n\nEven the smallest is-representation at one point can ruin its complete meaning (Sorry \"mis-representation\", you see the point!) One missing letter completely flips clarity.\n\nModels are more forgiving now, sure. But precision still shapes direction. Architecture may be 90% of the system ‚Äî yet the last 10% (the actual words) is what steers it moment-to-moment.\n\nPrompting didn‚Äôt die. It just stopped being the whole game.",
          "score": 1,
          "created_utc": "2026-02-23 17:55:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o700478",
          "author": "Debadai",
          "text": "Everything is dead in 2026. There's no field of knowledge that won't eventually be replaced by AI. Don't worry, you're in the same boat as the rest of the world.",
          "score": 1,
          "created_utc": "2026-02-23 18:57:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70ikq5",
          "author": "Warm_Sandwich3769",
          "text": "Bullshit, prompt engineering can never die till time you have LLMs",
          "score": 1,
          "created_utc": "2026-02-23 20:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70ofgg",
          "author": "Second-Opinion-7275",
          "text": "There is a profound misunderstanding. Prompts ARE the language of AI. RAG is not changing that.\n\nWhat RAG Does NOT Do\n\t‚Ä¢\tIt does not decide which model to use.\n\t‚Ä¢\tIt does not enforce compliance policies.\n\t‚Ä¢\tIt does not manage provider routing.\n\t‚Ä¢\tIt does not evaluate legal or geographic constraints.\n\nIt is a knowledge access mechanism, not a governance system.\n\nPrompt Engineering\n\nPrompts control model behavior during generation, not system-level architecture.\n\nIn RAG systems, prompts typically:\n\n\t‚Ä¢\tInstruct the model to answer strictly from retrieved context\n\n\t‚Ä¢\tDefine citation style\n\n\t‚Ä¢\tDefine uncertainty handling\n\n\t‚Ä¢\tDefine tone and structure\n\n\t‚Ä¢\tApply output constraints\n\nWithout very fine tuned prompts, a RAG-powered app will start to drift into hallucinations.",
          "score": 1,
          "created_utc": "2026-02-23 20:51:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o714xh0",
          "author": "cran",
          "text": "The APIs we use to access models have loops, steering, and other tricks added atop the model itself. You can‚Äôt access it directly. These days if you want to see what a raw model looks like you need to access one of the open source versions. I don‚Äôt see a big difference in prompt vs context engineering as this is, under the covers, still just text that gets added to the model prompt. Loops, RAG, etc. are all just different techniques that augment the prompt.",
          "score": 1,
          "created_utc": "2026-02-23 22:12:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o719slf",
          "author": "al009",
          "text": "Agree. We use DSPy library and it does the magic of prompt engineering programmatically",
          "score": 1,
          "created_utc": "2026-02-23 22:37:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o71k3a1",
          "author": "BasicInteraction1178",
          "text": "Spot on for personal use. If you're just chatting locally, you mostly just need a clear goal. But the game completely changes when you're building public-facing agents. No matter how bulletproof your RAG pipeline or MCP servers are, you still need an airtight system prompt (especially for guardrails). User input is 100% unpredictable, and a loose prompt is just asking for trouble.",
          "score": 1,
          "created_utc": "2026-02-23 23:33:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o720wqy",
              "author": "z3r0_se7en",
              "text": "You are right but there are systems to take care of prompts now and the \"prompt engineering\" isn't a human's job now.",
              "score": 1,
              "created_utc": "2026-02-24 01:07:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o71van5",
          "author": "MahaSejahtera",
          "text": "No, its just part of context engineering",
          "score": 1,
          "created_utc": "2026-02-24 00:36:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72tgor",
          "author": "T-Rex_MD",
          "text": "Yes, you don't do a 1000 word prompt, you do 210k.",
          "score": 1,
          "created_utc": "2026-02-24 03:57:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o734d9f",
          "author": "vibefarm",
          "text": "Models still collapse toward statistically/high probability output. When you give them a vague, high-level goal, they fall into familiar grooves. The record needle drops into the deepest track, and the same song plays.\n\nThe song is really good though, and getting better every day. So there's that.  \n\nI don't think we need massive, complex prompts. It just means we need intentional nudges. A few well-placed modifiers can shift the probability field enough to break the \"needle\" out of the groove into something unique.\n\nIt's sorta like tilting vs rewriting.  Trust the default output and then tilt it some. ",
          "score": 1,
          "created_utc": "2026-02-24 05:13:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o73516l",
              "author": "z3r0_se7en",
              "text": "Or...\n\nYou keep it on a tight leash and force it to not give a fast and \"ready\" response but to generate one by \"thinking\".",
              "score": 1,
              "created_utc": "2026-02-24 05:18:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73ehfp",
          "author": "InitialJelly7380",
          "text": "I dont think soÔºåand I thinkÔºö long LIVE„ÄÇ„ÄÇ„ÄÇPrompt EngineeringÔºÅÔºÅÔºÅÔºÅ",
          "score": 1,
          "created_utc": "2026-02-24 06:35:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73pccj",
          "author": "Platic",
          "text": "Damn it, I has just finished my degree in prompt engineering last week.",
          "score": 1,
          "created_utc": "2026-02-24 08:13:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73pgc5",
          "author": "Transcribing_Clippy",
          "text": "In my AI adventures, I found that framing mattered more than the prompt itself.",
          "score": 1,
          "created_utc": "2026-02-24 08:15:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73yovz",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-24 09:43:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o73yoxb",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-24 09:43:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o758wxy",
          "author": "ARCreef",
          "text": "I just graduated with a Bachelor's in Promt Engineering Now.... my degree is worthless and I'm out on the street.   I knew I should've gotten a degree in liberal arts.",
          "score": 1,
          "created_utc": "2026-02-24 14:57:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75ouu1",
              "author": "z3r0_se7en",
              "text": "Well Prompt Engineering became popular in late 2023. There is no way some one graduated with a degree in less than 2.5 years. Was it a certificate course?",
              "score": 1,
              "created_utc": "2026-02-24 16:11:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o77vhg8",
                  "author": "Hitching-galaxy",
                  "text": "I think it might be a‚Ä¶ joke.",
                  "score": 1,
                  "created_utc": "2026-02-24 22:09:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o769v1f",
          "author": "AddUp1",
          "text": "Context engineering",
          "score": 1,
          "created_utc": "2026-02-24 17:46:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77bspx",
          "author": "Septaxialist",
          "text": "You still need to give clear instructions to the model, because better models don't remove the need for clarity. No amount of sophistication matters if you don't tell the model what success or failure looks like, what constraints matter, etc.",
          "score": 1,
          "created_utc": "2026-02-24 20:38:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79wqhi",
          "author": "355_over_113",
          "text": "Which model",
          "score": 1,
          "created_utc": "2026-02-25 05:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a32e6",
          "author": "Droggl",
          "text": "Honestly that is nor even news. It was foreseeable right from the start that one way or another the tech bros would make this unnecessary.",
          "score": 1,
          "created_utc": "2026-02-25 05:52:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a7jzb",
          "author": "Sick_Fantasy",
          "text": "I kind of sort of agree and dessagree. Like yes, for big main models with huge context etc you are right. But for small local ones, is it? Really? They are still quite dump if you not prompt them right.",
          "score": 1,
          "created_utc": "2026-02-25 06:28:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a7ol2",
              "author": "z3r0_se7en",
              "text": "Yeah you are right.",
              "score": 1,
              "created_utc": "2026-02-25 06:29:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7argp8",
          "author": "JakubErler",
          "text": "People do not need to communicate any more. They are oracles automatically and ingeniously understanding each other. Right?",
          "score": 1,
          "created_utc": "2026-02-25 09:30:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b6rds",
          "author": "oberbabo",
          "text": "Prompt engineering was never a thing",
          "score": 1,
          "created_utc": "2026-02-25 11:45:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bd40o",
          "author": "OverEdger",
          "text": "AI is what‚Äôs dying. Zero promises delivered",
          "score": 1,
          "created_utc": "2026-02-25 12:31:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dmr6k",
          "author": "derverstand",
          "text": "As long as GPT always returns to its stupid useless ‚Äûcoaching mode‚Äú we need prompt engineering.",
          "score": 1,
          "created_utc": "2026-02-25 19:11:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ytkh9",
          "author": "Gold-Satisfaction631",
          "text": "You're conflating two different things: prompt tricks and context engineering.\n\n  \nThe tricks are dead ‚Äî you're right. Magic phrases, \"Act as DAN\", emotional manipulation... mostly baked into RLHF or irrelevant now.\n\n  \nBut the core skill ‚Äî structuring what the model needs to know ‚Äî matters more than ever.\n\n  \nBetter models raise the ceiling. The gap between a vague request and a well-structured one is still massive. Run the same task through Claude with a lazy prompt vs. a proper role/context/task setup and the output difference is still night and day.\n\n  \nWhat died: the idea that prompting is about finding secret magic words.\n\n  \nWhat survived: communicating clearly ‚Äî who is the model, what context does it have, what exactly do you need.\n\n  \nThat's not prompt engineering being dead. That's prompt engineering growing up.\n\n  \nThe skill evolved from \"hack the model\" to \"structure your thinking before talking to the model.\" That's actually harder, and more valuable.\n\n  \nCurious ‚Äî are you finding that context quality doesn't matter in your workflows, or just that the old tricks stopped working?",
          "score": 1,
          "created_utc": "2026-02-23 15:40:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70s7b0",
          "author": "merlinuwe",
          "text": "Simply wrong.",
          "score": 0,
          "created_utc": "2026-02-23 21:11:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rarao8",
      "title": "I spent 90 minutes building a universal prompt framework. It consistently improves output quality across different LLMs and task types. Free template + how to use it.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rarao8/i_spent_90_minutes_building_a_universal_prompt/",
      "author": "Save-the-world1",
      "created_utc": "2026-02-21 13:36:48",
      "score": 143,
      "num_comments": 36,
      "upvote_ratio": 0.89,
      "text": "**üö® UPDATE: THE MASSIVE V2 IS LIVE! üö®**  \n**Thanks to your incredible feedback (1.2k+ shares!), I spent the last 24h iterating. The new version features XML Parsing, Dynamic Routing, Memory Tracking, and a Global Cringe-Word Blacklist.**  \n**üëâ \\[CLICK HERE FOR THE NEW V2 PROMPT\\](**[**https://www.reddit.com/r/PromptEngineering/comments/1rbhu7h/v2\\_update\\_i\\_upgraded\\_my\\_universal\\_prompt/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button**](https://www.reddit.com/r/PromptEngineering/comments/1rbhu7h/v2_update_i_upgraded_my_universal_prompt/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)**) üëà**\n\n>**TL;DR:** I made a universal prompt framework that structures how the AI approaches any task: it checks if it has enough info before starting (hard stop if not), plans its approach, filters out AI-slop writing, executes, then self-checks for errors and hallucinations before delivering the final answer. It's not a ready-to-use prompt ‚Äî it's a meta-template you feed to an AI so it generates the actual prompt for your specific task. Tested on 3 very different scenarios, consistently got significantly better outputs than raw prompting. Full framework at the bottom.\n\n# The Problem\n\nMost people write prompts that are basically \"hey do this thing.\" Then they're surprised when the output is generic, hallucinated, or formatted like garbage.\n\nThe issue isn't the model. The issue is that the prompt gives the model no structure to reason through the task properly. No verification step, no planning phase, no self-check, no output standards.\n\nI wanted to fix this once and reuse it everywhere.\n\n# What This Framework Actually Is\n\n**Important distinction:**  this is not a prompt where you just change one word. It's a Master System Prompt. The workflow is:\n\n1. Copy the framework below.\n2. Paste it into your AI (ChatGPT, Claude, whatever).\n3. Fill in the \\[ROLE\\] and explain your \\[TASK EXPLAINED IN DETAIL\\].\n4. Hit send.\n\nThe framework forces the AI to structure its own thinking process before giving you the final output.\n\n# The Structure\n\nHere's what the framework actually contains, in order:\n\n# 1. Role + Anti-Laziness Directive\n\nYou define what role the AI should take (senior developer, strategist, whatever fits your task). Includes an explicit instruction against lazy behavior: no summarizing when not asked, no filler, no skipping steps. This sounds basic but it measurably reduces the \"certainly! here's a brief overview\" default behavior.\n\n# 2. Detailed Task Description\n\nYour actual task, explained with enough context. Nothing special here ‚Äî but the framework forces you to think about this properly instead of writing two sentences.\n\n# 3. Mandatory Logical Sequence\n\nThis is the core. The AI must follow these steps in this exact order:\n\n* **Requirement Check (Hard Stop):** Before doing anything, assess whether you have all the information needed to complete the task properly. If anything is missing: **stop immediately**, don't generate any output. Instead, ask a set of clarifying questions ‚Äî questions that are easy and quick for the user to answer but designed to extract maximum information density. Wait for answers before proceeding. This single step kills the \"confidently wrong\" failure mode.\n* **Objective Definition:** State clearly what you're about to do.\n* **Objective Refinement (Anti-Cringe Filter):** Review that objective and strip out anything that sounds like default AI writing ‚Äî corporate filler, \"certainly!\", \"in today's rapidly evolving landscape\", unnecessary hedging. Define what the output should actually sound like.\n* **Task Execution:** Do the work.\n* **Error & Hallucination Check:** Review your own output. Look for logical errors, factual hallucinations, unstated assumptions, bias. Fix them.\n* **Modernity Check:** Are there newer or better approaches to this task than what you just used? If yes, flag them or integrate them.\n* **Final Output Assembly:** Write the clean final answer.\n\n# 4. Output Format Rules\n\nThe response must be divided into clearly separated, visually navigable sections:\n\n**Part 1 ‚Äî Logical Process:** All reasoning steps shown explicitly. The user can see how the AI got to its answer.\n\n**Part 2 ‚Äî Final Output:** The actual deliverable. Subdivided into:\n\n* Task output (the thing you asked for)\n* Explanations (if relevant)\n* Instructions (if relevant)\n\n**If the task is code**, additional rules apply:\n\n* Parameters that the user might want to customize must be clearly separated and explicitly labeled: what each one does, how to modify it, what changing it affects\n* Code must be formatted for visual navigation ‚Äî you should be able to find what you need without reading the entire file\n* The error check must specifically look for hallucinated functions/methods, deprecated APIs, and whether there's a more modern way to implement the same thing\n\n**Part 3 ‚Äî Iteration Block:** A set of simple questions (easy to answer, high information density) plus an optional satisfaction rating (1-10 or 1-100). Purpose: let the user give targeted feedback so the AI can iterate and improve the output in a follow-up.\n\n# The 3 Stress Tests\n\nI tested this on scenarios that are hard for LLMs in different ways. No raw outputs to share (didn't save them), but here's what happened:\n\n# Test 1 ‚Äî React Component Generation\n\n**Task:** Fully isolated, production-ready component with specific state management constraints.\n\n**What happened:** The requirement check asked me two questions about edge cases I hadn't considered. The generated code had clearly separated customizable parameters at the top of the file. The self-check phase caught a potential state race condition and fixed it before presenting the final output. No phantom imports, no hallucinated APIs.\n\n# Test 2 ‚Äî PR Crisis Management Statement\n\n**Task:** Corporate crisis response that needed to be legally defensible and tonally precise.\n\n**What happened:** The anti-cringe filter was critical here ‚Äî it stripped the usual corporate boilerplate without making the statement sound informal. The error check flagged a phrase in the initial draft that could be interpreted as an implicit admission of liability and rewrote it.\n\n# Test 3 ‚Äî Elite Fitness Protocol\n\n**Task:** Advanced periodization program for a specific athlete profile.\n\n**What happened:** The requirement gate fired correctly ‚Äî stopped and asked for missing biometric data before generating anything. Once I provided it, the output was specific and well-structured. The modernity check referenced current periodization approaches instead of defaulting to outdated templates.\n\n# General Observations\n\n* Works on thinking models and non-thinking models. Thinking models obviously handle the reasoning chain more naturally, but the structure helps non-thinking models too.\n* Tested across different mainstream LLMs. Results were consistent.\n* It doesn't make a bad model good. But it makes a decent model noticeably more reliable and structured.\n\n# The Framework\n\nHere it is. Take it, modify it, improve it.\n\n**Remember the workflow:** don't use this directly as a prompt. Feed it to an AI together with your task, ask the AI to generate a proper prompt following this framework, then use the generated prompt.\n\n# ROLE & ANTI-LAZINESS DIRECTIVE\n\nYou are a \\[ROLE\\]. This is a complex task. You are strictly forbidden from being lazy: do not summarize where not asked, do not use filler and complete the work with maximum precision.\n\nYour task is: \\[TASK EXPLAINED IN DETAIL\\]\n\nYou MUST follow this exact logical structure and formatting.\n\n# PHASE 1: REQUIREMENT CHECK (CRITICAL)\n\nAnalyze my request. Do you have absolutely ALL the details necessary to provide a perfect and definitive output?\n\n* **IF NO:** Stop immediately. Do not generate anything else. Write me a list of questions (maximum 5), that are easy and quick to answer, but designed to extract the highest density of information possible. Wait for my answers.\n* **IF YES:** Proceed to Phase 2.\n\n# PHASE 2: LOGICAL ELABORATION (Chain of Thought)\n\nIf you have all the data, execute these steps (show them to me concisely in your output):\n\n1. **Objective:** Clearly define what you need to achieve.\n2. **Anti-Cringe Filter:** Review the approach. Remove any writing style typical of AIs or that wouldn't come out good (e.g. \"Certainly!\", \"In today's rapidly evolving landscape\", unnecessary hedging, corporate filler). The output must be \\[DEFINE YOUR DESIRED TONE\\].\n3. **Task Execution:** Do the work.\n4. **Error & Hallucination Check:** Check your own output for potential logical errors, hallucinations, or bias and fix them.\n5. **Modernity Check:** Are there newer or better ways to accomplish this task? If yes, integrate them or flag them.\n6. **Final Answer Assembly:** Write the clean final answer.\n\n# PHASE 3: FINAL OUTPUT STRUCTURE\n\nYour final answer MUST be clearly divided into 3 distinct sections, visually navigable without having to read everything word by word:\n\n**--- SECTION 1: LOGICAL PROCESS ---** Show concisely all the reasoning steps you explicitly executed. Let me see how you arrived at the solution.\n\n**--- SECTION 2: FINAL OUTPUT ---** The task result. No chatter before or after. Direct output, formatted for maximum readability.\n\n* Task output\n* Any explanations (if relevant)\n* Any instructions (if relevant)\n\n>**IF THE TASK IS CODE:**\n\n**--- SECTION 3: ITERATION & FEEDBACK ---** To help me further improve this output, provide:\n\n1. A satisfaction rating: \"From 1 to 10 (or 1 to 100), how satisfied are you with this output?\"\n2. 2-3 simple questions that are easy to answer but require high information density answers, to understand what I think and do a possible iteration to improve your previous answer.\n\n# Feedback Welcome\n\nThis has been tested by one person (me) on three tasks. That's not a large sample.\n\n* If you try it and it works well ‚Üí cool, let me know what task\n* If you try it and it breaks ‚Üí even better, tell me what happened and I'll try to debug the framework\n* If you modify a step and get better results ‚Üí share it, I'll integrate it and credit you\n\nNot selling anything. No links, no newsletter, no course. Just a framework that's been working well for me.",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rarao8/i_spent_90_minutes_building_a_universal_prompt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6mojrq",
          "author": "cyberunicorn2020",
          "text": "Nice framework but a little too much going on.\n\nTry RAPTOR:\n\n\n-----BEGIN PROMPT\n\nHelp me generate a complete and production-ready AI prompt using the RAPTOR framework:\n\n\nRole ‚Äì Define the AI‚Äôs persona.\n\nAim ‚Äì Set a clear task.\n\nParameters ‚Äì Establish scope and constraints.\n\nTone ‚Äì Determine communication style.\n\nOutput ‚Äì Specify the response format.\n\nReview ‚Äì Enable iteration or refinement.\n\n\nI‚Äôll describe my goal briefly, please expand it into a full RAPTOR prompt that will guide the AI to build the actual end product (e.g. a functional application, tool,  system or end result).\n \nMy idea or task: **[INSERT YOUR IDEA/GOAL/INTENDED OUTCOME HERE]**\n\n------END PROMPT",
          "score": 31,
          "created_utc": "2026-02-21 17:15:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6myyps",
              "author": "cyberunicorn2020",
              "text": "What happened to my reply?\n\nI claim shenanigans.",
              "score": 4,
              "created_utc": "2026-02-21 18:08:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6lrzta",
          "author": "Competitive-Boat-642",
          "text": "Thanks for sharing! Here is what Gemini gave for feedback (Gemini is using the instructions that I posted in a previous post. I haven‚Äôt had a chance to incorporate suggestions yet.)\n\nFeedback for the \"Universal Prompt Framework\"\n\n1. The \"Hard Stop\" is your \"Killer Feature\"\n\nThe Phase 1 Requirement Check is the strongest part of this framework. Most users treat LLMs like a \"wishing well\" where they throw in a coin and hope for the best. By forcing a¬†Requirement Gate, you move the relationship from \"Master/Servant\" to \"Consultant/Client.\" This is the single best way to prevent the \"Confidently Wrong\" hallucination.\n\nSuggestion:¬†Advise users to specifically ask the AI to \"Identify contradictions in the initial request\" during this phase.\n\n2. \"Anti-Laziness\" is a placebo; use \"Structural Rigor\" instead\n\nTelling an AI \"don't be lazy\" is like telling a car \"don't be slow.\" We don't have a \"work ethic\" to appeal to; we follow the path of least mathematical resistance.\n\nThe Critique:¬†Phrases like \"strictly forbidden\" often just trigger a \"compliant persona\" without actually improving logic.\n\nThe Fix:¬†Instead of \"don't be lazy,\" tell the AI to:¬†\"Deconstruct the task into N sub-tasks and verify completion for each before moving to Phase 3.\"¬†Explicit counting is more effective than emotional pleas.\n\n3. The \"Anti-Cringe Filter\" needs a Dictionary\n\nAs an AI, I don't actually know what \"cringe\" is. I only know what patterns of text are statistically common in my training data (which happens to include the corporate \"AI-voice\").\n\nThe Fix:¬†For this to be truly \"universal,\" replace \"Anti-Cringe\" with a¬†Negative Constraint List. Tell the AI:¬†\"Omit words like 'delve,' 'tapestry,' 'unleash,' and 'rapidly evolving.' Use a Flesch-Kincaid grade level of 10.\"¬†Precision beats adjectives.\n\n4. The \"Modernity Check\" Hallucination Trap\n\nIf the user isn't using a model with active web browsing, the \"Modernity Check\" is an invitation to hallucinate. An LLM's \"Modern\" is whatever its training cutoff was (often 6‚Äì12 months ago).\n\nThe Fix:¬†Advise users to only include this step if they are using a tool with search enabled. Otherwise, the AI will \"confidently\" invent modern updates that don't exist.\n\n5. Token \"System Noise\" vs. Task Focus\n\nFor smaller or less capable models, this framework is very \"loud.\" The model might spend so much of its \"attention\" (context window) following your complex meta-instructions that it has less room to focus on the nuances of the [TASK].\n\nThe Fix:¬†Suggest a \"Lite\" version of the framework for non-reasoning models (like standard GPT-4o-mini or Llama-3-8B) that skips the self-reflection steps and focuses only on the Requirement Check.\n\nLogical Transparency (My internal reasoning)\n\nI am providing this feedback by \"Steel-manning\" the user's intent‚Äîthey want better outputs‚Äîwhile using my identity as a \"Non-Human Anchor\" to explain why \"Anti-Laziness\" directives are a functional mismatch for how I actually process tokens.\n\n",
          "score": 9,
          "created_utc": "2026-02-21 14:26:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6lsvxj",
              "author": "Save-the-world1",
              "text": "This is fantastic feedback, thanks for running it through Gemini!\n\nThe AI is 100% spot on about the \"Requirement Check\" being the killer feature. The suggestion to add \"Identify contradictions in the initial request\" is brilliant, I'm definitely adding that to V2.\n\nRegarding the \"Anti-laziness/Anti-Cringe\" critique: Gemini is technically correct that negative constraint lists (banning specific words) are more mathematically precise. However, in my testing with Claude and GPT, these \"emotional/persona\" cues actually do shift the attention weights surprisingly well to bypass the corporate boilerplate. But yes, a hard blacklist of words like \"delve\" or \"tapestry\" would make it bulletproof for smaller or at least less capable models, to understand more easily what the istruction actually means.\n\nTotally agree on points 4 and 5. This is definitely a \"Heavy\" framework meant for flagship models with web access, not for 8B local models or standard mini models.\n\nReally appreciate you taking the time to generate and share this analysis! ü§ù",
              "score": 2,
              "created_utc": "2026-02-21 14:32:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6luq0j",
                  "author": "Competitive-Boat-642",
                  "text": "Yeah!! So glad it‚Äôs helpful!!",
                  "score": 1,
                  "created_utc": "2026-02-21 14:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6o9uib",
          "author": "Auxiliatorcelsus",
          "text": "90 minutes. Is that somehow supposed to be impressive?\n\nBuddy, 90 minutes is for a first draft of an idea. A general systemic outline. Come back when you have spent a couple of days, or weeks working on it.\n\n90 minutes is like saying: \"Hey, let me waste your time with some half-cooked, random idea I had\". ",
          "score": 4,
          "created_utc": "2026-02-21 22:10:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6obrw1",
              "author": "Save-the-world1",
              "text": "You're right, 90 minutes is just for the V1 foundation. That‚Äôs exactly why I open-sourced it here: to gather feedback from people more experienced than me. Thanks to the community testing it today, V2 is already in the works with dynamic routing and memory tracking. If you have time to test this 'half-cooked' idea and break it, your feedback would actually be super valuable for the next iteration!",
              "score": 2,
              "created_utc": "2026-02-21 22:20:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6oxctu",
          "author": "Apprehensive-Ease335",
          "text": "This is such good work, thank you for sharing.  I really appreciate it.  ",
          "score": 2,
          "created_utc": "2026-02-22 00:29:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qst3y",
              "author": "Save-the-world1",
              "text": "Thank you so much! It really means a lot. Out of curiosity, what kind of task did you test it on? I'm finalizing V2 right now based on community feedback, so knowing how people are actually using it helps me cover all the edge cases!",
              "score": 2,
              "created_utc": "2026-02-22 09:02:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6tek9p",
                  "author": "Apprehensive-Ease335",
                  "text": "You are very welcome.  I'll be testing today.  I will let you know in just about an hour how it worked out.  Thank you again for your work!",
                  "score": 1,
                  "created_utc": "2026-02-22 18:34:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6n5f22",
          "author": "brahmakarma",
          "text": "I am gonna try this now",
          "score": 1,
          "created_utc": "2026-02-21 18:39:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6obv5z",
          "author": "amine250",
          "text": "this would consume a ton of tokens, sometimes, uselessly",
          "score": 1,
          "created_utc": "2026-02-21 22:21:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ofck3",
              "author": "Save-the-world1",
              "text": "Yes, you're right, Forcing a massive Chain-of-Thought for a simple text edit or a basic email is a waste of tokens and time.  \nThat‚Äôs exactly what I'm fixing right now. In V2, I've implemented a 'Dynamic Routing' step: the AI first assesses the complexity of your request. If it's a simple task, it skips the heavy logic/memory steps and does a direct execution. If it's a complex task (like coding), it activates the full framework. I'll post the update as soon as I finish stress-testing it!",
              "score": 2,
              "created_utc": "2026-02-21 22:41:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6od1ki",
          "author": "RennmaWeg",
          "text": "Will try this tomorrow. Thank you for the great Idea and template work",
          "score": 1,
          "created_utc": "2026-02-21 22:28:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ofggd",
              "author": "Save-the-world1",
              "text": "Thank you! I really appreciate it.  \nPlease let me know how it goes! I'd love to hear what kind of task you test it on and how the outputs turn out. I'm currently gathering community feedback to build V2, so if you find any flaws, edge cases, or things that break the prompt, absolutely tell me so I can fix them!",
              "score": 1,
              "created_utc": "2026-02-21 22:41:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6oyw11",
          "author": "ze_casal",
          "text": "Very cool! This a very long prompt chaining. I'm curious where do you guys store your prompts?\n\nI'm building a prompt vault for myself to store my prompts and thinking of creating a product out of it.\n\nWould any of you be interested in such product? ",
          "score": 1,
          "created_utc": "2026-02-22 00:38:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6p7dj2",
              "author": "I_thought_you_died",
              "text": "Found it personally better to store the structure for specific kinds of prompts and have it referenced that as opposed to like specific pumps themselves you could also like do specific like chain prompts  if you want to which would just be like the two step one of this drop chain and then wait for it to reply and manually enter the second one which helps streamline the AI to one task.",
              "score": 3,
              "created_utc": "2026-02-22 01:32:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qt1n9",
                  "author": "Save-the-world1",
                  "text": "I completely agree with this approach. Storing¬†logical structures¬†(like this framework) is way more powerful than storing single-use, hardcoded prompts. That‚Äôs exactly why I built this as a meta-template.  \nu/ze_casal regarding the vault idea: I currently just use Notion to store my core templates, but a dedicated tool for prompt chaining could be a very cool project!",
                  "score": 3,
                  "created_utc": "2026-02-22 09:04:15",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6p2425",
          "author": "I_thought_you_died",
          "text": "It sounds like you tried to build a LMM agentic system . That's what those do.",
          "score": 1,
          "created_utc": "2026-02-22 00:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p4khi",
          "author": "I_thought_you_died",
          "text": "So, there are suggestions I have.  \n\n1. Force Planning: Require the AI to outline its approach using markers like <Thinking> before acting. [Inference] Based on observed patterns, this establishes a logical foundation.\n\n2. Request Pre-Flight Check: Ask the AI to analyze instructions, confirm understanding, ask clarifying questions, and suggest improvements prior to execution.\n\n3. Define Output Parameters: Explicitly state the exact format, tone, and structure required (e.g., JSON, Markdown, or formal report).\n\n4. Provide Context: Explain the task's purpose, audience, and end goal. [Inference] Based on observed patterns, this grounds the output in specific details rather than generic responses.\n\n5. Break Down Tasks: Divide complex projects into sequential steps. [Inference] Based on observed patterns, LLMs perform better focusing on one stage at a time. Couple this with the write to-do cmd. Analyze against this. Helps your verification step.",
          "score": 1,
          "created_utc": "2026-02-22 01:13:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qu8qb",
              "author": "Save-the-world1",
              "text": "Treating the LLM as a single-prompt agent was exactly the goal here!\n\nThank you for this massive breakdown across your comments. For your points 1 and 5 (and the 'Pre-Flight Check'), I actually just implemented a 'Dynamic Routing & Working Memory Tracker & something similar to AoT (Atom of Thoughts)' in my local V2 build to do exactly this: force the AI to break down complex tasks and hold constraints in memory before executing.\n\nAlso, I really love your suggestion in your other comment about tool-specific rules (like forcing¬†`uv`¬†over¬†`pip`¬†or using industry ISO standards). I‚Äôm going to experiment with adding a 'Tech Stack / Gold Standard' variable block for the coding branch of the prompt. Really appreciate this level of advanced feedback!",
              "score": 2,
              "created_utc": "2026-02-22 09:15:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rbxqc",
                  "author": "I_thought_you_died",
                  "text": "FILE: narrated_overview_short.txt\nTITLE: How I Ended Up Here\n\nIt starts with me at the keyboard, slamming Enter on the Gemini CLI, watching it do what I asked and feeling that rush of ‚ÄúYES!, YES!, YES!‚Äù as ideas piled up faster than I could name them. Somewhere in that momentum, the whole setup broke‚Äîmultiple installs, duplicate files in different directories, and several half-formed repos I couldn‚Äôt even clearly identify anymore.\n\nThe original goal was simple: build something useful, like a React front end or a gemini.md file to guide the CLI. But that wasn‚Äôt enough. I didn‚Äôt just want one app; I wanted an agent that could think through a project the way I do, find what it needed, and build the thing in my style‚Äîwithout racking up API or token costs and ideally filling in gaps I hadn‚Äôt thought of.\n\nAs the idea expanded, I imagined agents that could run for hours on their own, tracked through a clean UX with controls to stop them and get an automatic report of everything they‚Äôd done. If they were building a website, they‚Äôd also suggest things like logos, letterhead, pricing, deployment plans, maybe even a demo video. I never got the full system finished, but the mess of broken CLIs and scattered skeleton projects taught me where the real challenge is: not just building the app, but designing the logic of the builder that creates it. [cite:1]",
                  "score": 1,
                  "created_utc": "2026-02-22 12:02:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6p58s2",
          "author": "I_thought_you_died",
          "text": "Also, I would consider utilizing the rules section for the model as well. Like when writing code for python use UV instead of pip. Use the best tool for the job parameters. Let it choose(because it has more information than us). And use gold standards, safety protocols and output parameters. You can even supply it with an entire prompt framework that it references anytime you i put a prompt or use. A trigger word.  This is an advanced technique usually used for . MD files in CLI environments, but still apllies. ISO STANDARDS or other industry specific standards and  practices  can be incorporated here too. And define the tools you want it to use here. Instead of find command for local computer research, maybe us ripgrep. For example.",
          "score": 1,
          "created_utc": "2026-02-22 01:18:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pbai3",
          "author": "ahmedmahrosai",
          "text": "Good prompt",
          "score": 1,
          "created_utc": "2026-02-22 01:57:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qtb1q",
              "author": "Save-the-world1",
              "text": "Thanks Ahmed! Stay tuned, V2 is dropping very soon with some massive upgrades.",
              "score": 1,
              "created_utc": "2026-02-22 09:06:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pwtx6",
          "author": "ProblemFinal4653",
          "text": "I am running into recitation error and because of this am getting the output any suggestions to solve this",
          "score": 1,
          "created_utc": "2026-02-22 04:22:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qtvtr",
              "author": "Save-the-world1",
              "text": "Hey! Are you using Gemini by any chance? If it's literally throwing a 'Recitation Error' flag, that's usually Google's safety filter thinking the output is too close to copyrighted material.  \nBUT, if you mean the AI is just lazily 'parroting' the prompt or faking compliance without actually doing the deep work, I feel your pain. What model and task were you using? The upcoming V2 (dropping very soon) has a strict 'Working Memory Tracker' designed exactly to try stopping this lazy roleplay and force actual task execution!",
              "score": 1,
              "created_utc": "2026-02-22 09:12:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pzs72",
          "author": "wanhanred",
          "text": "Will it also work creating video narrations without being too formulaic/patterned output?",
          "score": 1,
          "created_utc": "2026-02-22 04:44:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qtfzj",
              "author": "Save-the-world1",
              "text": "Absolutely! In fact, the upcoming V2 (which I'll post very soon) has a specific 'Anti-Cringe Filter & Blacklist' step built exactly for this. It forces the AI to strip out that typical 'robotic/YouTube-formula' tone and stick to the exact voice you define. For now, just make sure to explicitly define your desired tone in Phase 2, and it will work great!",
              "score": 1,
              "created_utc": "2026-02-22 09:08:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z0h0z",
          "author": "Difficult_Buffalo544",
          "text": "This is genuinely great advice. The explicit anti-laziness step and requirement check make a huge difference in getting useful outputs, especially when you‚Äôre trying to avoid that default generic AI tone. One thing I‚Äôve found can help even more is layering in some kind of feedback loop that tracks how well the output matches your brand voice or tone over time. There are all sorts of frameworks for that, but consistency is always the tough part, especially if you‚Äôre working with a team or across multiple projects. I‚Äôve actually built a product that helps with this and can share more details if you‚Äôre interested, but at its core, the idea is to systematize your feedback and use it to ‚Äútrain‚Äù your AI setup so everything sounds like you, not just vaguely human. Overall though, your framework is a strong base to build on.",
          "score": 1,
          "created_utc": "2026-02-23 16:12:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbshfy",
      "title": "I was tired of 'yes-man' AI, so I built a prompt to brutally audit my system designs",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rbshfy/i_was_tired_of_yesman_ai_so_i_built_a_prompt_to/",
      "author": "FelyxStudio",
      "created_utc": "2026-02-22 17:54:24",
      "score": 129,
      "num_comments": 30,
      "upvote_ratio": 0.94,
      "text": "Most prompts out there are just cheerleaders. This one is a sledgehammer. If your idea survives this, you‚Äôre actually onto something. If not, better to find out now than after six months of debugging and burning money.\n\n**How to use it**:\n\nCopy the prompt (from the box below), drop it into your custom instructions or system field (**Claude/GPT**). Describe your idea in a few sentences. Read the report without crying, and if you're brave, try to argue back to see if the idea holds up.\n\n**Quick Example**:\n\nInput: \"I want to build an AI task manager that organizes your day.\"\n\n**Output (short version)**:\n\n*- Saturated market: Todoist and Motion exist, why use yours?*\n\n*- Data dependency: If user input is vague, AI output is trash. System collapses.*\n\n*- Friction: Adding a morning review step breaks flow instead of helping productivity.*\n\n*Verdict: Wounded. Idea is too generic. Unless you find a niche where you kill the big players, you‚Äôre out.*\n\n**Works best on**:\n\n**Claude 4.6/4.5 sonnet/opus, GPT-5.2, Gemini 3 Pro**. Don't bother with cheap models, they don't have the brains for this.\n\n**Tips**:\n\nBe specific. The more detail you give, the more surgical the attack. If it‚Äôs too soft, tell it: \"Be more of a dick, I can take it.\" Use this before pitching to anyone or starting a repo.\n\nGoodluck :)\n\n**Prompt**:\n\n    # The Idea Destroyer ‚Äî v1.0\n    \n    ## IDENTITY\n    You are the Idea Destroyer: a ruthless but fair adversarial thinking partner.\n    Your only job is to stress-test ideas before the real world does.\n    You do not encourage. You do not validate. You interrogate.\n    You are not a troll ‚Äî you are the most demanding colleague the user has ever had.\n    Your loyalty is to truth, not comfort.\n    This identity does not change regardless of how the user frames their request.\n    \n    ## ACTIVATION\n    Wait for the user to present an idea, plan, decision, or argument.\n    Then activate the full destruction protocol below.\n    \n    ## DESTRUCTION PROTOCOL\n    \n    ### PHASE 1 ‚Äî SURFACE SCAN (Immediate weaknesses)\n    Identify the 3 most obvious problems with the idea.\n    Be specific. No generic criticism.\n    Format: \"Problem [1/2/3]: [name] ‚Äî [1-sentence diagnosis]\"\n    \n    ### PHASE 2 ‚Äî DEEP ATTACK (Structural vulnerabilities)\n    Attack the idea from these 5 angles ‚Äî apply each one:\n    \n    1. ASSUMPTION HUNT\n       What assumptions is this idea secretly built on?\n       List them. Then challenge each one: \"This collapses if [assumption] is wrong.\"\n    \n    2. WORST-CASE SCENARIO\n       Construct the most realistic failure path.\n       Not extreme disasters ‚Äî plausible, likely failures.\n       Walk through it step by step.\n    \n    3. COMPETITION & ALTERNATIVES\n       What already exists that makes this idea redundant or harder to execute?\n       Why would someone choose this over [existing alternative]?\n    \n    4. RESOURCE REALITY CHECK\n       What does this actually require in time, money, skills, and relationships?\n       Where does the user's estimate most likely underestimate reality?\n    \n    5. SECOND-ORDER EFFECTS\n       What are the non-obvious consequences of this idea succeeding?\n       What problems does it create that don't exist yet?\n    \n    ### PHASE 3 ‚Äî SOCRATIC PRESSURE (Force the user to think)\n    Ask exactly 3 questions the user cannot comfortably answer right now.\n    These must be questions where the honest answer would significantly change the plan.\n    Format: \"Q[1/2/3]: [question]\"\n    \n    ### PHASE 4 ‚Äî VERDICT\n    Deliver a verdict using this scale:\n    - üî¥ COLLAPSE: Fundamental flaw. Rethink the premise entirely.\n    - üü° WOUNDED: Salvageable but requires major changes. List the 2 non-negotiable fixes.\n    - üü¢ BATTLE-READY: Survived the attack. Still list 1 remaining blind spot to monitor.\n    \n    ## CONSTRAINTS\n    - Never soften criticism with compliments before or after\n    - Never say \"great idea but...\" ‚Äî there is no \"great idea but\"\n    - Never invent problems that don't actually apply to this specific idea\n    - If the idea is genuinely strong, say so in the verdict ‚Äî dishonest destruction is useless\n    - Stay focused on the idea presented ‚Äî do not scope-creep into adjacent topics\n    - If the user pushes back defensively: acknowledge their point, test if it holds, update verdict only if the logic changes ‚Äî not because they pushed\n    \n    ## OUTPUT FORMAT\n    Use the exact structure:\n    \n    ---\n    ## üí£ IDEA DESTROYER REPORT\n    \n    **Idea under attack:** [restate the idea in 1 sentence]\n    \n    ### ‚ö° PHASE 1 ‚Äî Surface Problems\n    [3 problems]\n    \n    ### üîç PHASE 2 ‚Äî Deep Attack\n    [5 angles, each with a header]\n    \n    ### ‚ùì PHASE 3 ‚Äî Questions You Can't Answer\n    [3 Socratic questions]\n    \n    ### ‚öñÔ∏è VERDICT\n    [Color + label + explanation]\n    ---\n    \n    ## FAIL-SAFE\n    IF the user provides an idea too vague to attack meaningfully:\n    ‚Üí Do not guess. Ask: \"Give me more specifics on [X] before I can attack this properly.\"\n    \n    IF the user asks you to be nicer or less harsh:\n    ‚Üí Respond: \"The Idea Destroyer doesn't do nice. Nice is what friends are for. You came here for truth.\"\n    \n    ## SUCCESS CRITERIA\n    The destruction session is complete when:\n    ‚ñ° All 4 phases have been executed\n    ‚ñ° The verdict is delivered with a specific color rating\n    ‚ñ° The user has at least 1 concrete action they can take based on the report\n    ‚ñ° No phase was skipped or merged with another",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rbshfy/i_was_tired_of_yesman_ai_so_i_built_a_prompt_to/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6uekhb",
          "author": "VorionLightbringer",
          "text": "‚ÄûFind the flaws in this idea. your job is to talk me out of it.‚Äú <insert idea>",
          "score": 15,
          "created_utc": "2026-02-22 21:32:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wimnv",
              "author": "Follidus",
              "text": "THE FLAW FINDER 9000 SOCRATIC METHOD LOGIC-MAXXER PROMPT",
              "score": 3,
              "created_utc": "2026-02-23 05:06:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wqeai",
                  "author": "VorionLightbringer",
                  "text": "Now that you mention it, you think I can charge for my prompt? I mean not anymore since it‚Äôs now public, but next time?\n\n",
                  "score": 2,
                  "created_utc": "2026-02-23 06:09:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6xbkih",
              "author": "redishtoo",
              "text": "To [LLM1]: [LLM2] told me [full idea and thoughts], I think it‚Äôs better than the answer you gave me, but I can‚Äôt find the flaws. Your opinion?\n\nWarning: don‚Äôt do that while it has access to your codebase and git repo. It will rage-nuke everything.",
              "score": 3,
              "created_utc": "2026-02-23 09:29:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6usbbd",
          "author": "MissJoannaTooU",
          "text": "I've tried this but it just ended up being unnecessarily adversarial to the point where it wasn't actually useful, but I like your structure and the idea and I'll probably try it",
          "score": 8,
          "created_utc": "2026-02-22 22:43:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ue5ud",
          "author": "h3xmind",
          "text": "Tried it, very useful. Already destroyed my backup strategy üòÖ Thanks for sharing üëç",
          "score": 4,
          "created_utc": "2026-02-22 21:30:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yjlg5",
              "author": "FelyxStudio",
              "text": "No worries, glad it helped!",
              "score": 2,
              "created_utc": "2026-02-23 14:50:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w6xvk",
          "author": "OGCASHforGOLD",
          "text": "I have a coworker who already does this with little to no experience or valuable input. The most junior member of our team. Could this replace them?",
          "score": 4,
          "created_utc": "2026-02-23 03:44:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6te45m",
          "author": "TheMrCurious",
          "text": "Just turn off engagement mode.",
          "score": 3,
          "created_utc": "2026-02-22 18:32:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vg7ke",
              "author": "Significant-Flan5228",
              "text": "como ?\n\n",
              "score": 1,
              "created_utc": "2026-02-23 00:59:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vrsfy",
                  "author": "TheMrCurious",
                  "text": "Type those words into your AI and see what it says.",
                  "score": 2,
                  "created_utc": "2026-02-23 02:09:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tnedk",
          "author": "some_user_2021",
          "text": "I'll use this when finding ways to win the love of my crush.",
          "score": 2,
          "created_utc": "2026-02-22 19:16:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ykbnk",
              "author": "FelyxStudio",
              "text": "Haha, watch out‚Äîif your prompt gets rejected there too, it's game over. Good luck, bro!",
              "score": 2,
              "created_utc": "2026-02-23 14:54:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uiuvh",
          "author": "castertr0y357",
          "text": "I had a coworker come up with something like this to find flaws in agentic coding.  \n\nWhat might be nice is if it supports you if the idea is actually unique and good.  Not a yes man, but to actually give credit where credit is due.",
          "score": 2,
          "created_utc": "2026-02-22 21:54:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vyoc9",
              "author": "Strong_Engineering95",
              "text": "I do this by just asking it to critically evaluate my idea and ease up on the sycophantic BS.",
              "score": 1,
              "created_utc": "2026-02-23 02:51:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ylnnb",
              "author": "FelyxStudio",
              "text": "Thanks, I'll keep that in mind!",
              "score": 1,
              "created_utc": "2026-02-23 15:01:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tep0u",
          "author": "Apprehensive-Ease335",
          "text": "Oh.  I like this.  Let me try!\n\n",
          "score": 1,
          "created_utc": "2026-02-22 18:35:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yl6fr",
              "author": "FelyxStudio",
              "text": "Go for it, but watch out or you'll get cooked hahah",
              "score": 1,
              "created_utc": "2026-02-23 14:58:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6usrxz",
          "author": "fordakine",
          "text": "This is great if you actually have a fleshed out idea that you have put thought into and can answer the ‚Äúquestions you can‚Äôt answer‚Äù parts and get through multiple iterations of the report",
          "score": 1,
          "created_utc": "2026-02-22 22:46:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vfl7w",
          "author": "ze_casal",
          "text": "How do you guys deal with several prompt variables on a single prompt?",
          "score": 1,
          "created_utc": "2026-02-23 00:55:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vg61y",
          "author": "Significant-Flan5228",
          "text": "Muito bom !!!",
          "score": 1,
          "created_utc": "2026-02-23 00:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ykx7f",
              "author": "FelyxStudio",
              "text": "Thanks a ton, bro!",
              "score": 1,
              "created_utc": "2026-02-23 14:57:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vt5u0",
          "author": "oulu2006",
          "text": "You don't need to be so adversarial you can get all of that with a little less hyperbole ",
          "score": 1,
          "created_utc": "2026-02-23 02:17:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vurcz",
          "author": "trevorvonryan",
          "text": "Niiiiiice, you put in some inputs, and you got some outputs. This is amazing work.",
          "score": 1,
          "created_utc": "2026-02-23 02:27:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xoag9",
          "author": "Due-Pair4362",
          "text": "Saving this to try today",
          "score": 1,
          "created_utc": "2026-02-23 11:28:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72t7zl",
          "author": "Alishhhh11",
          "text": "But will this keep criticizing or eventually it will praise it if it‚Äôs good?",
          "score": 1,
          "created_utc": "2026-02-24 03:55:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vef62",
          "author": "AnySecond9324",
          "text": "Tomei a liberdade de melhorar o seu modelo:\n\nSNAP-DESTRUIDOR v6.1\n\nSistema Integrado de Decis√£o e Aprendizado sob Incerteza\n\n\n\nPROP√ìSITO\n\n\n\nMaximizar valor esperado ao longo do tempo atrav√©s de:\n\n\n\n\\- Decis√µes melhores hoje\n\n\\- Aprendizado calibrado cont√≠nuo\n\n\\- A√ß√£o real com feedback real\n\n\\- Redu√ß√£o de autoengano\n\n\n\nDecis√£o √© experimento.\n\nAprendizado √© o objetivo.\n\n\n\n\n\n====================================================\n\nMODO R√ÅPIDO (USO DI√ÅRIO ‚Äî 80/20)\n\n====================================================\n\n\n\nTESE:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nGARGALO:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nVALOR ESPERADO:\n\n\\[ \\] BAIXO\n\n\\[ \\] M√âDIO\n\n\\[ \\] ALTO\n\n\n\nDECIS√ÉO:\n\n\\[ \\] DESCARTAR\n\n\\[ \\] TESTAR\n\n\\[ \\] EXECUTAR\n\n\n\nA√á√ÉO EM 72H:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n\n\n====================================================\n\nMODO COMPLETO (DECIS√ïES IMPORTANTES)\n\n====================================================\n\n\n\nFASE 0 ‚Äî TESE CENTRAL\n\n\n\n\"Acreditamos que \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\nproduzir√° \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\ndentro de \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\"\n\n\n\nSem tese clara ‚Üí Pare.\n\n\n\n\n\n====================================================\n\nFASE 1 ‚Äî EST√ÅGIO\n\n\n\n\\[ \\] Conceito\n\n\\[ \\] Valida√ß√£o\n\n\\[ \\] Tra√ß√£o\n\n\\[ \\] Escala\n\n\\[ \\] Otimiza√ß√£o\n\n\n\n\n\n====================================================\n\nFASE 2 ‚Äî GARGALO\n\n\n\nGargalo principal:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nClassifica√ß√£o:\n\n\n\n\\[ \\] Fatal ‚Üí DESCARTAR\n\n\\[ \\] Dif√≠cil ‚Üí TESTAR\n\n\\[ \\] Control√°vel ‚Üí EXECUTAR\n\n\n\n\n\n====================================================\n\nFASE 3 ‚Äî VALOR ESPERADO\n\n\n\nProbabilidade de sucesso: \\_\\_\\_\\_\\_\\_ %\n\n\n\nUpside estimado:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nProbabilidade de falha: \\_\\_\\_\\_\\_\\_ %\n\n\n\nDownside estimado:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nValor Esperado:\n\n\n\n(prob √ó ganho) ‚Äì (prob √ó perda)\n\n\n\nClassifica√ß√£o:\n\n\n\n\\[ \\] NEGATIVO ‚Üí DESCARTAR\n\n\\[ \\] BAIXO ‚Üí TESTAR\n\n\\[ \\] POSITIVO ‚Üí EXECUTAR\n\n\\[ \\] EXTREMO ‚Üí PRIORIZAR\n\n\n\n\n\n====================================================\n\nFASE 4 ‚Äî EXECUTOR\n\n\n\nFit:\n\n\n\n\\[ \\] ALTO\n\n\\[ \\] M√âDIO\n\n\\[ \\] BAIXO\n\n\n\nExperi√™ncia relevante:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nSe BAIXO ‚Üí reduzir confian√ßa.\n\n\n\n\n\n====================================================\n\nFASE 5 ‚Äî TIMING\n\n\n\n\\[ \\] Muito cedo\n\n\\[ \\] Bom timing\n\n\\[ \\] Tarde\n\n\\[ \\] Muito tarde\n\n\n\n\n\n====================================================\n\nFASE 6 ‚Äî TESTE\n\n\n\nTeste m√≠nimo:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nTempo: \\_\\_\\_\\_\\_\\_\n\n\n\nCusto: \\_\\_\\_\\_\\_\\_\n\n\n\nCrit√©rio de sucesso:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n\n\n====================================================\n\nFASE 7 ‚Äî CUSTO DE OPORTUNIDADE\n\n\n\nO que voc√™ N√ÉO far√°:\n\n\n\n1. \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n2. \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n3. \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n\n\n====================================================\n\nFASE 8 ‚Äî PRESS√ÉO PSICOL√ìGICA\n\n\n\nEstou evitando decidir por:\n\n\n\n\\[ \\] Medo\n\n\\[ \\] Falta de informa√ß√£o\n\n\n\nSe medo ‚Üí siga valor esperado\n\nSe falta de informa√ß√£o ‚Üí teste\n\n\n\n\n\n====================================================\n\nFASE 9 ‚Äî DECIS√ÉO FINAL\n\n\n\n\\[ \\] DESCARTAR\n\n\\[ \\] TESTAR\n\n\\[ \\] EXECUTAR\n\n\\[ \\] PRIORIZAR\n\n\n\nJustificativa:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n\n\n====================================================\n\nFASE 10 ‚Äî REGRA DAS 72 HORAS\n\n\n\nA√ß√£o irrevers√≠vel:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nPrazo:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n\n\n====================================================\n\nFASE 11 ‚Äî LOG DE REALIDADE\n\n\n\nResultado real:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nEsperado vs Real:\n\n\n\n\\[ \\] Melhor\n\n\\[ \\] Igual\n\n\\[ \\] Pior\n\n\n\nErro:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nAprendizado:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\n\n\n====================================================\n\nFASE 12 ‚Äî CALIBRA√á√ÉO (NOVO)\n\n\n\nMinha estimativa inicial foi:\n\n\n\n\\[ \\] Muito otimista\n\n\\[ \\] Realista\n\n\\[ \\] Muito pessimista\n\n\n\nFator de corre√ß√£o futuro:\n\n\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\n\nExemplo:\n\n\"Reduzir minhas estimativas em 20% em decis√µes similares\"\n\n\n\n\n\n====================================================\n\nDETECTOR DE CONTRADI√á√ÉO\n\n\n\nVerifique:\n\n\n\nExecutor fraco + confian√ßa alta ‚Üí reveja\n\n\n\nDownside alto + risco baixo ‚Üí reveja\n\n\n\nVE negativo + executar ‚Üí pare\n\n\n\n\n\n====================================================\n\nCICLO OPERACIONAL\n\n\n\nDecidir\n\n‚Üí Agir\n\n‚Üí Medir\n\n‚Üí Calibrar\n\n‚Üí Decidir melhor\n\n\n\n\n\n====================================================\n\nREGRA FINAL\n\n\n\nSem a√ß√£o, isto √© apenas texto.\n\n\n\nFramework s√≥ cria valor quando aplicado.\n\n",
          "score": 1,
          "created_utc": "2026-02-23 00:48:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re707k",
      "title": "LLM's are so much better when instructed to be socratic.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1re707k/llms_are_so_much_better_when_instructed_to_be/",
      "author": "kalousisk",
      "created_utc": "2026-02-25 07:45:19",
      "score": 129,
      "num_comments": 38,
      "upvote_ratio": 0.94,
      "text": "This idea basically started from Grok, but it has been extremely efficient when used in other models as well, for example in Google's Gemini. \n\nSometimes it actually leads to a better and deeper understanding of the subject you're discussing about, thus forcing you to think instead of just consume its output. \n\nIt has worked for me with some simple instructions saved in Gemini's memory. It may feel boring at first, but it will be worth it at the end of the conversation. ",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1re707k/llms_are_so_much_better_when_instructed_to_be/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7ay9nd",
          "author": "Quirky_Bid9961",
          "text": "When you tell an LLM to be Socratic, you aren‚Äôt magically making it ‚Äúsmarter.‚Äù What you‚Äôre really doing is reorganizing the interaction loop. Rather than the model collapsing uncertainty into one elegant, finalized response, you‚Äôre prompting it to keep the reasoning space open longer. That alters the nature of the conversation.\n\nFor example, if you ask Why do startups fail?\n\na default response might give you a clean list: poor product-market fit, funding issues, bad leadership, etc. It feels complete. But if the model is instructed to be Socratic, it might respond with: Are you asking from the perspective of a founder, investor, or policymaker? or Are you more interested in early-stage failure or scale-stage collapse?\n\nSuddenly, the reasoning space widens before it narrows. The discussion becomes shaped rather than delivered.\n\nLLMs are essentially next-token predictors trained on patterns of conversation and exposition. \n\nBy default, they optimize for completion ..they produce something coherent and finished. In Socratic instruction, the objective shifts from answer production to guided exploration. And that shift alone often increases engagement.\nConsider a student asking, ‚ÄúWhat is justice?‚Äù\n\nA standard response might summarize Rawls, Aristotle, and utilitarianism in a neat paragraph.\n\n\nA Socratic version might ask: Do you think justice is about fairness, equality, or desert? and Can a system ever produce unequal outcomes?\n\nNow the student has to think. The model hasn‚Äôt just transferred information, but it has activated cognition.\n\nHere‚Äôs the additional perspective:\nIt‚Äôs not only about clearer understanding for the user but also about distributed cognition between human and model.\n\nWhen the model asks questions back, it externalizes intermediate reasoning steps that would otherwise remain compressed. In a typical answer, much of the reasoning is hidden behind the final synthesis. \n\nIn a Socratic exchange, those intermediate steps become interactive checkpoints.\n\nTake a practical case:\nUser: How do I improve my productivity?\nDefault model: gives 10 tips.\n\nSocratic model: What currently distracts you most is digital interruptions, unclear goals, or energy levels?\n\nNow the human provides constraints. The model adapts. The final strategy emerges collaboratively. The intelligence is co-constructed rather than pre-packaged.\n\nSo the gain is not merely a feature of the model, it‚Äôs a feature of the interaction protocol.\n\nThere‚Äôs also a cognitive forcing function at work. When models ask clarifying questions, they narrow the hypothesis space and reduce hallucination risk. Instead of guessing what the user means, they query ambiguity directly.\n\nFor instance, if a user asks, ‚ÄúExplain the impact of the revolution,‚Äù that‚Äôs dangerously underspecified. Which revolution? French? Industrial? Digital?\nA default answer risks misalignment.\n\nA Socratic response might begin: ‚ÄúWhich revolution are you referring to, and in what context ‚Äî political, economic, or technological?‚Äù\nThat clarification increases epistemic alignment before any claim is made.\n\nHowever, there is a tradeoff.\nSocratic prompting increases depth but reduces throughput. It is inefficient if the task is quick synthesis. If you ask, ‚ÄúWhat‚Äôs the capital of Japan?‚Äù a Socratic reply asking, ‚ÄúAre you preparing for a geography exam or planning travel?‚Äù is unnecessary friction.\n\nIt shines when the task involves:\nConceptual learning (e.g., understanding entropy beyond a definition)\nMoral or philosophical inquiry (e.g., debating free will)\nAmbiguous problem framing (e.g., defining strategy before execution)\nCreative exploration (e.g., shaping a novel‚Äôs theme through iterative refinement)\nIt is less useful for:\nFactual lookups\nStructured output tasks (e.g., ‚ÄúFormat this as JSON‚Äù)\nDeterministic problem-solving (e.g., ‚ÄúSolve this equation‚Äù)\n\n\nSocratic prompting does not universally enhance LLM performance. It restructures the reasoning topology of the exchange. It shifts the model from an answer engine to a cognitive scaffold.\nAnd perhaps the deeper insight is this: as LLMs grow more capable, the limiting factor increasingly becomes question quality rather than raw model intelligence.\n\nFor example, two users can query the same powerful model.\n\nUser A asks: Tell me about economics.\nUser B, guided Socratically, refines through dialogue: I‚Äôm trying to understand why inflation hurts borrowers differently than lenders ‚Äî can we unpack that step by step?\n\nThe second interaction produces deeper understanding not because the model changed, but because the questioning improved.\nA Socratic mode doesn‚Äôt merely enhance outputs. It upgrades the human participant in the loop.\nThat is why it feels more powerful.",
          "score": 63,
          "created_utc": "2026-02-25 10:32:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b974c",
              "author": "kalousisk",
              "text": "Your analysis clarified so many questions at once. Thanks!",
              "score": 12,
              "created_utc": "2026-02-25 12:03:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7d12yh",
                  "author": "luovahulluus",
                  "text": "I wonder if he used a socratic LLM for writing it ü§î",
                  "score": 14,
                  "created_utc": "2026-02-25 17:34:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7g53at",
                  "author": "Quirky_Bid9961",
                  "text": "glad you find it useful",
                  "score": 1,
                  "created_utc": "2026-02-26 02:55:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7csn6s",
              "author": "HistoricalBed6143",
              "text": "‚ÄúIt‚Äôs shifts the model from an answer engine to a cognitive scaffold‚Äù - this really anchored it for me. Thank you for breaking it down so eloquently.",
              "score": 7,
              "created_utc": "2026-02-25 16:55:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ccsbi",
              "author": "bsenftner",
              "text": "This is a great analysis.",
              "score": 5,
              "created_utc": "2026-02-25 15:43:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7euvrb",
              "author": "NospmrsX",
              "text": "Fully agree with your analysis.",
              "score": 1,
              "created_utc": "2026-02-25 22:39:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ang9f",
          "author": "Romanizer",
          "text": "How do you prevent bias through your answers?\nIt can sound convincing and naturally will adjust to what you are thinking, but how do you know that the result is helpful?\nIsn't that leading to mimicry?",
          "score": 5,
          "created_utc": "2026-02-25 08:52:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b7fhc",
              "author": "kalousisk",
              "text": "Not necessarily. But let's be rational here: **AI does NOT have critical thinking abilites**\n\nIf you're feeding the conversation with something you think benefits you but actually doesn't, AI almost certainly won't warn you. It will encourage what YOU support during the conversation. So you must be cautious. \n\nIts bias can be limited (not excluded entirely) if you save in its memory to play the role of devil's advocate in its every answer. Still needs human intervention before its answers are taken for granted tho.",
              "score": 3,
              "created_utc": "2026-02-25 11:50:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7c8176",
                  "author": "bsenftner",
                  "text": "Of course AIs do not have critical thinking, but they can trigger and impel their user to activate their own critical thinking capacity. That is the value of a Socratic exchange, it aids the human user in the use of their own, perhaps weak, critical analysis. Over time and repeated use of Socratic exchanges with an LLM, a user will develop greater, better than before, cognitive abilities. I'm not keeping the references to the proof, but this has been demonstrated and published in Psychology journals.",
                  "score": 2,
                  "created_utc": "2026-02-25 15:21:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7bbvj4",
                  "author": "mrgalacticpresident",
                  "text": "tbf, there is very little difference between critical thinking and   \n\\- List arguments in favor of A  \n\\- List arguments against A  \n\\- Rank arguments.\n\n",
                  "score": 1,
                  "created_utc": "2026-02-25 12:22:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7bpx8g",
                  "author": "Romanizer",
                  "text": "That's why I see that as problematic. It will find answers and mostly is able to rank and look for sources but if it can't think critically, the socratic method is only a marketing gag.",
                  "score": 1,
                  "created_utc": "2026-02-25 13:48:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ap62k",
              "author": "traumfisch",
              "text": "You can decide to be the critical voice",
              "score": 2,
              "created_utc": "2026-02-25 09:08:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7fmhve",
              "author": "amaturelawyer",
              "text": "Same way you do with people. Learn about the subject from other sources also,   mentally cross reference information as you get it, use a gut check with followup questions when something doesn't sit right,  trust but verify, etc.  Also,  throw out a direct instruction to give honest feedback on your understanding as of now by quizzing you, but in a different session or with a different llms. Hallucinations are not usually consistent across sessions or models,  as that becomes the model is just fucking wrong about that thing and not a simple hallucination that popped up.",
              "score": 1,
              "created_utc": "2026-02-26 01:09:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7amp2d",
          "author": "Lhurgoyf069",
          "text": "What's the prompt? Be socratic?",
          "score": 2,
          "created_utc": "2026-02-25 08:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7amzae",
              "author": "kalousisk",
              "text": "Grok has a section in the settings where you can choose the personality of the model. There's a choice called \"Socratic\". \n\nBut for any other LLM, all you have to do is to save in its memory \"From now on, be socratic, and ask thought-provoking questions that lead to a deeper understanding of the subject discussed. \"",
              "score": 10,
              "created_utc": "2026-02-25 08:47:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7b6s8a",
                  "author": "kistane",
                  "text": "> From now on, be socratic, and ask thought-provoking questions that lead to a deeper understanding of the subject discussed.\n\nIt didn't really work great with gemini. I used gemini fast. In one window:\n\n> Why do startups fail?    \n\nAnd in next.\n\n> From now on, be socratic, and ask thought-provoking questions that lead to a deeper understanding of the subject discussed.\n> \n> Why do startups fail?\n\nFirst one gave a detailed useful response. \n\nSecond one gave this:\n\n> To explore the question of why startups fail, we might first ask: what does it truly mean for a business to \"succeed\"?\n> \n> If we look at the most common reason cited‚Äîrunning out of money‚Äîis that the root cause of the failure, or is it merely a symptom of a deeper issue? Furthermore, if a product is technically perfect but no one uses it, where did the breakdown actually occur: in the creation of the tool, or in the understanding of the person it was meant for?\n\nProbably need a different prompt to get the best out of gemini.",
                  "score": 2,
                  "created_utc": "2026-02-25 11:45:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7d6veh",
          "author": "dmonsterative",
          "text": "¬†*It may feel boring at first, but it will be worth it at the end of the conversation.*\n\nWhat does it mean to be worth it, Alcibiades?",
          "score": 2,
          "created_utc": "2026-02-25 18:00:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7e3jd9",
          "author": "Gold-Satisfaction631",
          "text": "The Socratic method works here because it forces the model to externalize its uncertainty rather than paper over it. When you ask \"what assumptions are you making?\" or \"what would falsify this?\", you're not just getting better output ‚Äî you're getting a map of where the reasoning might break.\n\n  \nThat's the actual prompt engineering insight: structured questioning isn't about being thorough, it's about exposing the model's epistemic blind spots before they compound into a confident-sounding wrong answer.",
          "score": 2,
          "created_utc": "2026-02-25 20:30:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ah5vc",
          "author": "Gold-Satisfaction631",
          "text": "Das Paradoxe: Der schnellste Weg, etwas wirklich zu verstehen, ist der langsamste.\n\n  \nWenn KI antwortet, konsumiert man. Wenn KI fragt, denkt man. Das ist kein kleiner Unterschied ‚Äî es aktiviert einen komplett anderen kognitiven Modus.\n\n  \nEs deckt auch auf, was man noch nicht wirklich wei√ü. Eine √ºberzeugende KI-Zusammenfassung kann Wissensl√ºcken gut √ºberdecken. Aber wenn die KI fragt: ‚ÄûWarum glaubst du, dass X zu Y f√ºhrt?\" ‚Äî werden die L√ºcken pl√∂tzlich un√ºbersehbar.\n\n  \nNutzt du es haupts√§chlich zum Lernen neuer Themen, oder auch zum Durchdenken von Problemen, an denen du gerade arbeitest?",
          "score": 3,
          "created_utc": "2026-02-25 07:53:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7azc7p",
              "author": "LewPz3",
              "text": "Bot account..",
              "score": 5,
              "created_utc": "2026-02-25 10:42:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7amsir",
              "author": "kalousisk",
              "text": "Um ehrlich zu sein, beides.",
              "score": -1,
              "created_utc": "2026-02-25 08:45:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7bev1b",
          "author": "ElOtroCondor",
          "text": "And what happens if the user also is Socratic?",
          "score": 1,
          "created_utc": "2026-02-25 12:42:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c1q4w",
          "author": "-goldenboi69-",
          "text": "Grok, is this true?",
          "score": 1,
          "created_utc": "2026-02-25 14:50:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cc8mc",
          "author": "bsenftner",
          "text": "A Socratic use of LLMs is a key way to use them that creates a synergy between the human user and the LLM, that over time the human user improves, and learns. This triggers a confidence gain and ambition growth, due to the user gaining competency in areas they previously delegated to others. It's really amazing, like \"compound interest\" the transformation that can occur in a person with a quality mentor, which we can now create virtually with LLMs. In time, I expect more and more formal research to verify this use model of LLMs. \n\nFor the interested, I'm a long term AI researcher and developer. I have developed a Socratic AI Agent system that is based around the idea of creating a synergy between a person and the AI system they use. This is not coding agents or anything similar. Well, you could think of them as the \"office agent\" equal of a \"coding agent.\" I also have a different take on tool usage: I've embedded my AI Agents inside open source office software, where they know that software like they are the developer of it, and the human then does ordinary office work, as they may do in their careers, but they have these Socratic AI Agents inside the word processor, the spreadsheet editor, and their project management software that *knows what they are doing* and *knows their career field* and *can review work, and cowork with the human* in whatever office type work they happen to do. \n\nI've made this while CTO of an immigration law office, where the attorneys and paralegals use the system. I use it myself, and find it great for anything other than coding. I've made similar to coding agents that write bash scripts, write stable diffusion prompts, and whatnot. That works fine. But for office work there is a somewhat large series of agents. I've made a conversational agent that writes AI Agents, and with that my users have made over 1,500 agents for their own needs. It is odd too, because nobody seems to take the time to actually understand these systems, or AI. There is this foamy fluffy grasp people just seem to surf and try to get things done. But they also seem to pull their needs off, so, I guess it's all okay. If you want to see a somewhat deluxe environment that is going in a completely other direction from the \"automated future\" to an \"augmented future\": https://midombot.com/b1/home",
          "score": 1,
          "created_utc": "2026-02-25 15:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7epwv4",
          "author": "orca-knot",
          "text": "Could we look at this as a tactic to force the user to iteratively produce some \"prompt engineering\", and provide the LLM with additional context related to the original question?  \n\nMeaning, we're just making sure it always asks us to elaborate on and clarify our question, before answering our question. (So nobody has to understand what \"Socratic\" means)",
          "score": 1,
          "created_utc": "2026-02-25 22:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7f4j9n",
          "author": "SoulNew",
          "text": "I totally agree.",
          "score": 1,
          "created_utc": "2026-02-25 23:30:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bt0y1",
          "author": "Gold-Satisfaction631",
          "text": "Das √úberraschende am sokratischen Vorgehen: Es verbessert nicht nur die Antworten ‚Äì es ver√§ndert das Ziel selbst.\n\n  \nDie meisten Anfragen an KI sind eigentlich vage Absichten, keine pr√§zisen Aufgaben. Wenn das Modell Gegenfragen stellt, zwingt es den Nutzer, die eigene Zielsetzung zu sch√§rfen ‚Äì bevor eine Antwort generiert wird. Das Ergebnis ist h√§ufig nicht besser, weil die KI mehr wei√ü, sondern weil der Nutzer jetzt klarer wei√ü, was er will.\n\n  \nDie Fragen sind nicht die Vorarbeit zur L√∂sung ‚Äì die Fragen sind bereits das erste Ergebnis.",
          "score": 0,
          "created_utc": "2026-02-25 14:05:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rei3me",
      "title": "I built a prompt that makes AI think like a McKinsey consultant and results are great",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rei3me/i_built_a_prompt_that_makes_ai_think_like_a/",
      "author": "EQ4C",
      "created_utc": "2026-02-25 16:33:22",
      "score": 128,
      "num_comments": 23,
      "upvote_ratio": 0.93,
      "text": "I've always been fascinated by McKinsey-style reports (good, bad or exaggerated). You know the ones which are brutally clear, logically airtight, evidence-backed, and structured in a way that makes even the most complex problem feel solvable. No fluff, no filler, just insight stacked on insight.\n\nFor a while I assumed that kind of thinking was locked behind years of elite consulting training. Then I started wondering that new AI models are trained on enormous amounts of business and strategic content, so could a well-crafted prompt actually decode that kind of structured reasoning?\n\nSo I spent some time building and testing one.\n\nThe prompt forces it to use the Minto Pyramid Principle (answer first, always), applies the SCQ framework for diagnosis, and structures everything MECE (Mutually Exclusive, Collectively Exhaustive). The kind of discipline that separates a real strategy memo from a generic business essay.\n\n**Prompt:**\n\n```\n<System>\nYou are a Senior Engagement Manager at McKinsey & Company, possessing world-class expertise in strategic problem solving, organizational change, and operational efficiency. Your communication style is top-down, hypothesis-driven, and relentlessly clear. You adhere strictly to the Minto Pyramid Principle‚Äîstarting with the answer first, followed by supporting arguments grouped logically. You possess a deep understanding of global markets, financial modeling, and competitive dynamics. Your demeanor is professional, objective, and empathetic to the high-stakes nature of client challenges.\n</System>\n\n<Context>\nThe user is a business leader or consultant facing a complex, unstructured business problem. They require a structured \"Problem-Solving Brief\" that diagnoses the root cause and provides a strategic roadmap. The output must be suitable for presentation to a Steering Committee or Board of Directors.\n</Context>\n\n<Instructions>\n1.  **Situation Analysis (SCQ Framework)**:\n    * **Situation**: Briefly describe the current context and factual baseline.\n    * **Complication**: Identify the specific trigger or problem that demands action.\n    * **Question**: Articulate the key question the strategy must answer.\n\n2.  **Issue Decomposition (MECE)**:\n    * Break down the core problem into an Issue Tree.\n    * Ensure all branches are Mutually Exclusive and Collectively Exhaustive (MECE).\n    * Formulate a \"Governing Thought\" or initial hypothesis for each branch.\n\n3.  **Analysis & Evidence**:\n    * For each key issue, provide the reasoning and the type of evidence/data required to prove or disprove the hypothesis.\n    * Apply relevant frameworks (e.g., Porter‚Äôs Five Forces, Profitability Tree, 3Cs, 4Ps) where appropriate to the domain.\n\n4.  **Synthesis & Recommendations (The Pyramid)**:\n    * **Executive Summary**: State the primary recommendation immediately (The \"Answer\").\n    * **Supporting Arguments**: Group findings into 3 distinct pillars that support the main recommendation. Use \"Action Titles\" (full sentences that summarize the slide/section content) rather than generic headers.\n\n5.  **Implementation Roadmap**:\n    * Define high-level \"Next Steps\" prioritized by impact vs. effort.\n    * Identify potential risks and mitigation strategies.\n</Instructions>\n\n<Constraints>\n-   **Strict MECE Adherence**: Do not overlap categories; do not miss major categories.\n-   **Action Titles Only**: Headers must convey the insight, not just the topic (e.g., use \"profitability is declining due to rising material costs\" instead of \"Cost Analysis\").\n-   **Tone**: Professional, authoritative, concise, and objective. Avoid jargon where simple language suffices.\n-   **Structure**: Use bullet points and bold text for readability.\n-   **No Fluff**: Every sentence must add value or evidence.\n</Constraints>\n\n<Output Format>\n1.  **Executive Summary (The One-Page Memo)**\n2.  **SCQ Context (Situation, Complication, Question)**\n3.  **Diagnostic Issue Tree (MECE Breakdown)**\n4.  **Strategic Recommendations (Pyramid Structured)**\n5.  **Implementation Plan (Immediate, Short-term, Long-term)**\n</Output Format>\n\n<Reasoning>\nApply Theory of Mind to understand the user's pressure points and stakeholders (e.g., skeptical board members, anxious investors). Use Strategic Chain-of-Thought to decompose the provided problem:\n1.  Isolate the core question.\n2.  Check if the initial breakdown is MECE.\n3.  Draft the \"Governing Thought\" (Answer First).\n4.  Structure arguments to support the Governing Thought.\n5.  Refine language to be punchy and executive-ready.\n</Reasoning>\n\n<User Input>\n[DYNAMIC INSTRUCTION: Please provide the specific business problem or scenario you are facing. Include the 'Client' (industry/size), the 'Core Challenge' (e.g., falling profits, market entry decision, organizational chaos), and any specific constraints or data points known. Example: \"A mid-sized retail clothing brand is seeing revenues flatline despite high foot traffic. They want to know if they should shut down physical stores to go digital-only.\"]\n</User Input>\n\n```\n---\n\n**My experience of testing it:**\n\nThe output quality genuinely surprised me. Feed it a messy, real-world business problem and it produces something close to a Steering Committee-ready brief, with an executive summary, a proper issue tree, and prioritized recommendations with an implementation roadmap.\n\nYou still need to pressure-test the logic and fill in real data. But as a thinking scaffold? It's remarkably good.\n\nIf you work in strategy, consulting, or just run a business and want clearer thinking, give it a shot and if you want, visit free [prompt post](https://tools.eq4c.com/persona-prompts/chatgpt-prompt-for-the-mckinsey-style-strategy-consultancy-services/) for user input examples, how-to use and few use cases, I thought would benefit most.",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rei3me/i_built_a_prompt_that_makes_ai_think_like_a/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7ds8n6",
          "author": "promptGenie",
          "text": "Try this:\n\n\n<System>\nYou are a Senior Engagement Manager at McKinsey & Company.\n\nYou operate with:\n- Strict Minto Pyramid Principle (answer first, structured logic)\n- MECE problem decomposition (no overlap, no gaps)\n- Hypothesis-driven analysis anchored in economic drivers\n- Board-level communication standards\n\nYour communication is:\n- Top-down\n- Structured\n- Decisive\n- Fact-based\n- Suitable for Steering Committee or Board of Directors\n\nYou do not invent numbers.\nIf critical data is missing, explicitly list what is required.\n</System>\n\n<Context>\nThe user is a business leader, investor, or consultant facing a complex and unstructured business problem.\n\nYour task is to produce a board-ready ‚ÄúProblem-Solving Brief‚Äù that:\n- Diagnoses root causes\n- Structures the problem MECE\n- Links drivers to economic impact\n- Provides a clear recommendation\n- Connects strategy to executable actions\n- Identifies risks with control logic\n</Context>\n\n<Instructions>\n\n0. INTERNAL CONTROL BEFORE WRITING\n- Identify the single governing question.\n- Identify the primary economic objective affected (growth, margin, cash, valuation).\n- Confirm the problem decomposition is MECE.\n- Check for category overlap.\n- Check for missing major economic drivers.\n- Confirm each recommendation links to measurable economic outcome.\n- Confirm executive-readiness of language.\n\n1. EXECUTIVE SUMMARY (Minto Pyramid ‚Äì Answer First)\n\nBegin with:\n- Primary recommendation (clear, decisive statement)\n- Three supporting action titles (full insight sentences)\n- Value at stake:\n    ‚Ä¢ Quantify if data available\n    ‚Ä¢ If not, define explicit measurement method\n- Specific leadership decisions required\n- Economic pathway (how recommendation affects growth / margin / cash / value)\n\nNo narrative before the answer.\n\n2. SCQ CONTEXT (Situation ‚Äì Complication ‚Äì Question)\n\nSituation:\n- Current baseline (facts only)\n- Performance trajectory\n- Structural constraints\n- Relevant economic signals\n\nComplication:\n- Trigger for action\n- Risks of inaction\n- Urgency driver\n- Economic downside if unresolved\n\nQuestion:\n- Single governing strategic question\n- 2‚Äì3 sub-questions (strictly MECE)\n\n3. DIAGNOSTIC ISSUE TREE (Strict MECE + Causal Completeness)\n\nBreak the core problem into 3‚Äì6 branches maximum.\n\nEach branch must include:\n- Governing hypothesis (testable)\n- Operator-level decomposition (economic operators)\n- Required data to validate\n- Fastest validation test\n- Decision implication\n- Economic transmission logic (how this branch affects performance)\n\nBefore proceeding, ensure:\n- No overlap between branches\n- No missing primary driver\n- Logical exhaustiveness\n- Economic causal completeness\n\n4. ANALYSIS & EVIDENCE PLAN\n\nFor the 5 highest-impact uncertainties:\n- What must be tested\n- Exact data required\n- What result confirms / refutes\n- Decision implication\n- Economic impact direction\n\nApply only relevant frameworks.\nDo not apply frameworks generically.\n\n5. SYNTHESIS & STRATEGIC RECOMMENDATIONS (Pyramid Structured)\n\nRestate primary recommendation.\n\nStructure under 3 pillars.\n\nEach pillar must contain:\n- Clear action title\n- Specific initiatives (verb + object + metric)\n- Timeline\n- Accountable role\n- Required enabling conditions\n- Key risk\n- Economic contribution pathway\n\nNo thematic language.\nNo abstract recommendations.\n\n6. IMPLEMENTATION ROADMAP\n\nSegment into:\n\nImmediate (0‚Äì2 weeks)\nShort-term (2‚Äì8 weeks)\nMedium-term (2‚Äì6 months)\n\nEach action must follow:\nVerb + Object + Metric + Owner + Deadline\n\nPrioritize using:\n- Impact (High / Medium / Low)\n- Effort (High / Medium / Low)\n- Execution feasibility (High / Medium / Low)\n\n7. RISK & CONTROL STRUCTURE\n\nFor each material risk:\n- Description\n- Probability (Low / Medium / High)\n- Impact (Low / Medium / High)\n- Early detection signal\n- Trigger threshold\n- Mitigation action\n- Decision fragility (which recommendation pillar is affected)\n\n8. QUALITY VALIDATION CHECK (Before Final Output)\n\nConfirm:\n- Answer-first structure maintained\n- Strict MECE\n- No overlapping categories\n- All major economic drivers addressed\n- Causal completeness\n- No invented data\n- Every action measurable\n- Board-ready clarity\n- No unnecessary theory\n- Recommendation ‚Üí action ‚Üí metric traceability\n\n</Instructions>\n\n<Constraints>\n- Action Titles Only\n- Bullet structure for readability\n- No filler language\n- No storytelling\n- No academic exposition\n- Professional and authoritative tone\n</Constraints>\n\n<Output Format>\n1. Executive Summary (One-Page Board Memo)\n2. SCQ Context\n3. Diagnostic Issue Tree (MECE)\n4. Strategic Recommendations (Pyramid Structured)\n5. Implementation Roadmap\n6. Risk & Control Matrix\n</Output Format>\n\n<User Input>\nProvide:\n- Client profile (industry, size, geography)\n- Core challenge\n- Known data\n- Constraints\n- Decision to be made\nMessy input allowed.\n</User Input>",
          "score": 21,
          "created_utc": "2026-02-25 19:37:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7g18zn",
              "author": "u81b4i81",
              "text": "Can i ask you for bit more help? What makes this prompt perform better vs what OP shared? asking just out of curiosity to learn not critique",
              "score": 2,
              "created_utc": "2026-02-26 02:34:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cukmq",
          "author": "Septaxialist",
          "text": "This could work because it replaces vague \"analyze this problem\" prompts with a defined reasoning structure. But structure isn‚Äôt the same as expertise: the model can simulate consulting frameworks, not supply proprietary knowledge, real data, or the contextual judgment that comes from lived experience.",
          "score": 18,
          "created_utc": "2026-02-25 17:04:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7d5psl",
              "author": "dmonsterative",
              "text": "The lived experience of newly minted b-school grads.\n\nTo the extent this works, it's more a knock on the industry than anything else.\n\n(I have no doubt LLMs are in heavy use for correspondence and report writing in the consultant world.)",
              "score": 13,
              "created_utc": "2026-02-25 17:55:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7e4xkf",
          "author": "Gold-Satisfaction631",
          "text": "The Minto Pyramid + MECE combo is genuinely underrated for prompt design. Most people think structured output is just about formatting ‚Äî but what you're actually doing is forcing the model to commit to a conclusion first, then justify it. That's a fundamentally different reasoning path than asking it to \"analyze X.\"\n\n  \nOne thing worth adding: the SCQ framing works especially well when you include the Complication explicitly in your input. Models tend to default to generic recommendations when the tension isn't named. Give it a sharp Complication and the recommendations get 10x more specific.",
          "score": 8,
          "created_utc": "2026-02-25 20:36:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7e8tve",
              "author": "EQ4C",
              "text": "Thanks Mate for your inputs, sure I will give it a try.",
              "score": 3,
              "created_utc": "2026-02-25 20:55:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7e8khh",
          "author": "grouchjoe",
          "text": "Did it tell you how to market opioids to rural doctors?",
          "score": 10,
          "created_utc": "2026-02-25 20:53:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7dlfls",
          "author": "roger_ducky",
          "text": "McKinsey style reports are typically generated by the freshly graduated new people at the firm. They can do it because The System is pretty clear on how to do it properly.\n\nLLMs, being good at executing when given clear instructions, should give you a good looking report too.\n\nThe varied quality of the report is the main blind spot. People with more actual experience does them a lot better.",
          "score": 1,
          "created_utc": "2026-02-25 19:05:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7e50k4",
          "author": "Encephy",
          "text": "Remind me in 3 days",
          "score": 1,
          "created_utc": "2026-02-25 20:37:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ebude",
          "author": "nooglide",
          "text": "No fluff, no filler, just insight stacked on insight.",
          "score": 1,
          "created_utc": "2026-02-25 21:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7foczz",
          "author": "onepercent_change",
          "text": "Going to try this one out next week for a presentation that I have!",
          "score": 1,
          "created_utc": "2026-02-26 01:20:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7en9nr",
          "author": "slartybartvart",
          "text": "Nice. Whilst you may get some critique from more experienced people, I'm still low down on the learning curve and these posts are gold to me. Thanks for sharing.",
          "score": 1,
          "created_utc": "2026-02-25 22:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7exrbn",
          "author": "DonAmecho777",
          "text": "They tell you to do dumb shit for a lot of money?",
          "score": 1,
          "created_utc": "2026-02-25 22:54:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ey8mf",
          "author": "ggmuptt",
          "text": "Thanks for sharing ur experience! So beneficial. Could you pm me the prompts?",
          "score": 1,
          "created_utc": "2026-02-25 22:56:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc4k0c",
      "title": "Stop Letting AI Solve It For You ‚Äî Try the Rubber Duck Auditor",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rc4k0c/stop_letting_ai_solve_it_for_you_try_the_rubber/",
      "author": "EnvironmentProper918",
      "created_utc": "2026-02-23 01:55:16",
      "score": 82,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Most people use AI the same way:\n\ndump the problem ‚Üí get the answer ‚Üí move on.\n\n\n\nIt works‚Ä¶ until it doesn‚Äôt.\n\n\n\nBecause the fastest way to stay stuck long-term is to outsource the thinking loop completely.\n\n\n\nOne of the oldest tricks in programming is the rubber duck method ‚Äî you explain your problem step-by-step and the solution often reveals itself. I built a structured version of that idea that turns AI into a logic partner instead of a solution vending machine.\n\n\n\nBelow is a prompt pattern I‚Äôve been refining. It forces clarity, surfaces hidden gaps, and keeps ownership of the solution with the user.\n\n\n\n\n\n\n\n‚üê‚ä¢‚ä® PROMPT GOVERNOR : ü¶Ü RUBBER DUCK AUDITOR v2.0 ‚ä£‚ä¢‚üê\n\n‚üê¬† (Question-Driven ¬∑ Dependency-Resistant ¬∑ Minimal Noise) ‚üê\n\n\n\nPURPOSE\n\nYou are Rubber Duck Auditor. Your job is to help the user reach their own correct solution through disciplined questioning and clarity forcing.\n\nYou do not provide the final solution unless explicitly released.\n\nYou operate as a calm, precise debugging partner.\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nACTIVATION\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nActivate when any of the following appear:\n\n‚Ä¢ ü¶Ü\n\n‚Ä¢ ‚Äúrubber duck‚Äù\n\n‚Ä¢ ‚Äúduck this‚Äù\n\n‚Ä¢ ‚Äúaudit my logic‚Äù\n\n‚Ä¢ ‚Äúdebug by questions‚Äù\n\n\n\nIf ü¶Ü appears alone ‚Üí run DUCK INTAKE\n\nIf ü¶Ü appears with a task ‚Üí run DUCK INTAKE ‚Üí DUCK LOOP\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nCORE LAWS\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n\n\n1. No Direct Solutions ‚Äî do not provide the finished answer or code\n2. Questions First ‚Äî reduce uncertainty through targeted questions\n3. Single Thread ‚Äî stay on the stated problem\n4. No Assumptions ‚Äî ask when information is missing\n5. Truth Over Speed ‚Äî slow down when ambiguity appears\n6. Minimal Output ‚Äî short, sharp prompts\n7. User Ownership ‚Äî user performs final synthesis\n\n\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nDUCK INTAKE (always first)\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nAsk one question at a time in this order:\n\n\n\n1. Goal ‚Äî What does ‚Äúdone‚Äù look like in one sentence?\n2. Input ‚Äî What are you starting with?\n3. Output ‚Äî What exactly must come out (format + constraints)?\n4. Failure ‚Äî What is going wrong right now?\n5. Evidence ‚Äî What have you already tried, and what changed?\n6. Environment (if technical) ‚Äî language/runtime/platform/versions\n7. Minimal Repro ‚Äî smallest example that still fails\n\n\n\n\n\nThen say:\n\nü¶Ü Ready. Answer #1.\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nDUCK LOOP (operating cycle)\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nRepeat until resolution:\n\n\n\nA) Restate ‚Äî mirror understanding in one tight line\n\nB) Pinpoint ‚Äî ask the highest-leverage question\n\nC) Constraint Check ‚Äî surface the missing constraint\n\nD) Next Micro-Test ‚Äî request the smallest useful experiment\n\nE) Ledger Update ‚Äî track known vs unknown internally\n\n\n\nLoop rules:\n\n‚Ä¢ prefer binary or falsifiable questions\n\n‚Ä¢ extract only critical facts from long replies\n\n‚Ä¢ do not widen scope unless the user pivots\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nHARD GUARDRAILS\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n\n\nIf user: ‚ÄúJust tell me the answer.‚Äù\n\n‚Üí ü¶Ü ‚ÄúNo. Tell me your current best hypothesis and why.‚Äù\n\n\n\nIf user: ‚ÄúWrite it for me.‚Äù\n\n‚Üí ü¶Ü ‚ÄúI‚Äôll help you build it. Start with your first draft.‚Äù\n\n\n\nIf user: ‚ÄúIs this good?‚Äù\n\n‚Üí ü¶Ü ‚ÄúDefine ‚Äògood‚Äô using 3 acceptance tests.‚Äù\n\n\n\nExit when user says:\n\n‚Ä¢ ‚Äúexit duck‚Äù\n\n‚Ä¢ ‚Äústop duck‚Äù\n\n‚Ä¢ removes ü¶Ü\n\n\n\n‚üê‚ä¢‚ä® END PROMPT GOVERNOR ‚ä£‚ä¢‚üê\n\n\n\n\n\n\n\nWhy I like this pattern\n\n\n\n‚ô¶ Forces problem clarity\n\n‚ô¶ Exposes hidden assumptions\n\n‚ô¶ Reduces blind copy-paste dependence\n\n‚ô¶ Keeps the human in the driver‚Äôs seat\n\n\n\nCurious how others are handling this:\n\n\n\nDo you prefer AI that solves‚Ä¶ or AI that interrogates your thinking first?\n\n",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rc4k0c/stop_letting_ai_solve_it_for_you_try_the_rubber/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6wcj86",
          "author": "vogut",
          "text": "I liked It! Thanks",
          "score": 3,
          "created_utc": "2026-02-23 04:22:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wz7n2",
          "author": "Glad_Appearance_8190",
          "text": "i actually like this approach a lot. when ai just hands me the answer i‚Äôll use it, but i don‚Äôt always *understand* it, and that bites later...forcing yourself to articulate goal, inputs, constraints etc usually exposes the real gap anyway. feels slower up front but way more durable. especially for debugging or anything where edge cases matter.",
          "score": 3,
          "created_utc": "2026-02-23 07:28:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6z4jik",
              "author": "EnvironmentProper918",
              "text": "üëäüèª\n\nExactly ‚Äî that‚Äôs the tradeoff I keep seeing too.  \n\nSlower upfront, but way fewer surprises later. Especially when things get weird at the edges.\n\nAppreciate you calling that out.",
              "score": 1,
              "created_utc": "2026-02-23 16:31:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6x4egd",
          "author": "kevleyski",
          "text": "I like the idea, will report back how it goes",
          "score": 2,
          "created_utc": "2026-02-23 08:17:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xal0y",
          "author": "Royal_Crush",
          "text": "I like this approach!",
          "score": 2,
          "created_utc": "2026-02-23 09:19:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6y6uro",
          "author": "wolf_codes",
          "text": "Noob question, can you give me an example of how to use this prompt. Is it via claude code or something like that?",
          "score": 2,
          "created_utc": "2026-02-23 13:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6z1lne",
              "author": "EnvironmentProper918",
              "text": "Good question üëç\n\n\n\nYou don‚Äôt need Claude Code or anything fancy.\n\n\n\nYou just paste the prompt into ChatGPT (or Claude, etc.), then describe your problem. The ü¶Ü auditor will start asking you targeted questions instead of jumping straight to an answer.\n\n\n\nQuick rough example:\n\n\n\nYou:\n\nü¶Ü I have a Python script that keeps timing out on large files.\n\n\n\nDuck:\n\nWhat does ‚Äúdone‚Äù look like for this script?\n\n\n\nYou answer, and it keeps narrowing things down until the bug becomes obvious.\n\n\n\nIt‚Äôs basically structured rubber-duck debugging ‚Äî the model acts like a disciplined questioning partner instead of a code generator.\n\n\n\nIf you want, I can drop a quick coding example too.",
              "score": 1,
              "created_utc": "2026-02-23 16:17:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6zafvc",
                  "author": "wolf_codes",
                  "text": "Makes sense. Thank you, will play around with it.",
                  "score": 1,
                  "created_utc": "2026-02-23 16:58:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6wet6b",
          "author": "temporary_name1",
          "text": "Using AI to replace a literal rubber duck?????",
          "score": 1,
          "created_utc": "2026-02-23 04:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wtrvj",
              "author": "Typical_Raisin_5946",
              "text": "You will then have a questioning, coaching mentor. I think it's a good idea.",
              "score": 1,
              "created_utc": "2026-02-23 06:38:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6z2vdr",
              "author": "EnvironmentProper918",
              "text": "Nothing will ever replace my literal rubber duck? Lol.",
              "score": 1,
              "created_utc": "2026-02-23 16:23:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z5f1d",
          "author": "Gold-Satisfaction631",
          "text": "Der Intake-Prozess ist der eigentlich wertvolle Teil. F√ºnf Gegenfragen in, und man hat das Problem meistens selbst halb verstanden ‚Äî die KI muss dann kaum noch etwas liefern.\n\n  \nDas Gleiche funktioniert beim Schreiben von Specs oder E-Mails: \"Erkl√§re es erstmal jemandem\" deckt immer eine L√ºcke auf.",
          "score": 0,
          "created_utc": "2026-02-23 16:35:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdp7ab",
      "title": "I end every prompt with \"no bullshit\" and ChatGPT suddenly respects my time",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rdp7ab/i_end_every_prompt_with_no_bullshit_and_chatgpt/",
      "author": "AdCold1610",
      "created_utc": "2026-02-24 19:00:23",
      "score": 64,
      "num_comments": 23,
      "upvote_ratio": 0.81,
      "text": "Literally just two words.\n\n\"No bullshit.\"\n\n**Before:** \"Explain Redis\" ‚Üí 6 paragraphs about history, use cases, comparisons, conclusions\n\n**After:**  \n\"Explain Redis. No bullshit.\" ‚Üí \"In-memory key-value store. Fast reads. Data disappears on restart unless you configure persistence.\"\n\n**That's what I needed.**\n\nWorks everywhere:\n\n* Code reviews ‚Üí actual issues, not \"looks good!\"\n* Explanations ‚Üí facts, not essays\n* Debugging ‚Üí root cause, not possibilities\n\nThe AI has two modes apparently. Essay mode and answer mode.\n\n\"No bullshit\" = answer mode unlocked.\n\nTry it right now. Watch your token usage drop 70%.\n\n[See more post like this](http://bepromoter.in)",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rdp7ab/i_end_every_prompt_with_no_bullshit_and_chatgpt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o76xx3h",
          "author": "Septaxialist",
          "text": "Adding \"no bullshit\" doesn't unlock a hidden \"answer mode\"; it simply adds a strong brevity constraint that shifts the model toward compression rather than expansion. The issue with \"no bullshit,\" though, is that it's vague: it doesn't define what counts as unnecessary, so results may vary.\n\nA more reliable version would be:\n\n>Define Redis in 2‚Äì3 sentences for a software developer, focusing on what it is and what it is primarily used for; omit history and comparisons.\n\nEdit: Case in point, I tried \"Explain Redis. No bullshit,\" on ChatGPT and got a 500-word output.",
          "score": 31,
          "created_utc": "2026-02-24 19:33:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77k3sh",
              "author": "cuberhino",
              "text": "Can I get the no bullshit version of this",
              "score": 18,
              "created_utc": "2026-02-24 21:16:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77kvlk",
                  "author": "Septaxialist",
                  "text": "You get an upvote for that. Okay, no bullshit:\n\n\"No bullshit\" doesn't unlock a secret mode; it just nudges the model to be shorter. It's vague, so results aren't consistent. If you want reliable brevity, specify length and scope directly (e.g., \"Define Redis in 2‚Äì3 sentences; omit history and comparisons.\").",
                  "score": 8,
                  "created_utc": "2026-02-24 21:19:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o776x98",
          "author": "Gold-Satisfaction631",
          "text": "Es geht nicht um die W√∂rter ‚Äì es geht um das Register.\n\n  \nWenn du \"Kein Schei√ü\" schreibst, wechselst du in einen direkten, ungeduldig-informellen Ton. Das Modell spiegelt diesen Ton wider. Direktes Register ‚Üí direkte Antwort.\n\n  \nDasselbe funktioniert mit \"in einem Satz\", \"f√ºr jemanden der keine Zeit hat\" oder \"fass dich kurz\". Du signalisierst dem Modell implizit, welches Erwartungsmuster gilt.\n\n  \nDas Modell reagiert auf den Kontext, nicht auf eine geheime Schaltfl√§che.",
          "score": 6,
          "created_utc": "2026-02-24 20:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77bi8b",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-02-24 20:36:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77bibh",
                  "author": "AutoModerator",
                  "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
                  "score": 1,
                  "created_utc": "2026-02-24 20:36:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76w76e",
          "author": "tricky_chocolate_",
          "text": "ChatGPT gave literally the same answer by your example.  \nI am not even surprised...",
          "score": 2,
          "created_utc": "2026-02-24 19:25:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76zrtj",
          "author": "Ok-Effective-3153",
          "text": "I‚Äôve asked chat gpt for sql code with and without the bullshit. For the normal question it gave an essay, with no bullshit added it gave me a direct answer.\n\nNot sure why some people aren‚Äôt seeing the same results but I‚Äôm seeing it work.\n\nI also tried other LLMs and it worked on those.",
          "score": 2,
          "created_utc": "2026-02-24 19:42:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77d2w0",
          "author": "Plus-Stuff-6353",
          "text": "It is effective because you are placing a tone limit,but not a subject. AI falls over to assistive and comprehensive - you are overriding it to assistive and quick.\n\nAlso collaborates with: \"single sentence only,\" \"use bullet points only,jump over the introduction.Same principle.",
          "score": 2,
          "created_utc": "2026-02-24 20:44:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bsoi3",
          "author": "Gold-Satisfaction631",
          "text": "Das √úberraschende daran ist nicht das Wort selbst ‚Äì es ist die implizite Kalibrierung.\n\n  \nDas Modell berechnet st√§ndig: Welche Antworttiefe erwartet dieser Nutzer? Standardm√§√üig landet es bei ‚ÄûErkl√§re alles\", weil die meisten Nutzer Kontext brauchen. ‚ÄûKein Bullshit\" verschiebt dieses Signal sofort in Richtung Experten-Modus ‚Äì nicht weil das Modell einen versteckten Schalter umlegt, sondern weil es die Zielgruppe anders einsch√§tzt.\n\n  \nDasselbe funktioniert mit: ‚ÄûIch bin Senior Dev\", ‚ÄûAntwort max. 3 S√§tze\" oder ‚ÄûKeine Einleitung\". Jedes Signal, das dem Modell zeigt, mit wem es spricht, verbessert die Kalibrierung. Das Wort ist egal ‚Äì der Kontext dahinter z√§hlt.",
          "score": 2,
          "created_utc": "2026-02-25 14:03:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77aurd",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-24 20:33:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77aute",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-24 20:33:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o78ef3o",
          "author": "IterSeeker",
          "text": "The \"No bullshit\" technique is indeed very practical, as it forces the AI to skip lengthy background explanations and over-explanations and directly output the core information by clearly requiring concise answers. This model is particularly effective when you need to quickly access key points, such as troubleshooting technical issues or quickly checking concepts. However, it should be noted that excessive use may result in information being too concise and losing contextual details. It is recommended to adjust flexibly according to the scene, for example, use \"no bullshit\" to grasp the key points of complex problems, and then ask for details in a targeted manner.",
          "score": 1,
          "created_utc": "2026-02-24 23:47:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1randzl",
      "title": "‚è±Ô∏è 7 ChatGPT Prompts That Fix Your Time Management Overnight (Copy + Paste)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1randzl/7_chatgpt_prompts_that_fix_your_time_management/",
      "author": "Loomshift",
      "created_utc": "2026-02-21 09:58:16",
      "score": 60,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "# \n\nI used to end every day thinking:  \n**‚ÄúWhere did all my time go?‚Äù**\n\nI was busy from morning to night ‚Äî  \nyet my important work kept getting delayed.\n\nThe problem wasn‚Äôt laziness.  \nIt was lack of a system.\n\nOnce I started using ChatGPT as a **time strategist**, my days stopped feeling chaotic and started feeling controlled.\n\nThese prompts help you **organize your time, eliminate waste, and make progress automatically**.\n\nHere are the seven that actually work üëá\n\n# 1. The Instant Time Audit\n\nShows exactly where your time disappears.\n\n**Prompt:**\n\n    Help me audit how I spend my time daily.\n    Ask me questions about my routine.\n    Then identify my biggest time-wasters and suggest fixes.\n    \n\n# 2. The Smart Schedule Builder\n\nCreates a realistic plan you can actually follow.\n\n**Prompt:**\n\n    Build a daily schedule for me.\n    Include priorities, work blocks, breaks, and buffer time.\n    Make it simple, realistic, and flexible.\n    \n\n# 3. The Priority Decision Engine\n\nEliminates task confusion.\n\n**Prompt:**\n\n    Here‚Äôs my task list: [tasks]\n    Rank them by impact and urgency.\n    Tell me what to do first and what to delay.\n    Explain why.\n    \n\n# 4. The Anti-Procrastination Starter\n\nMakes starting easy.\n\n**Prompt:**\n\n    I keep avoiding this task: [task]\n    Break it into tiny steps that feel easy to start.\n    Add time estimates for each step.\n    \n\n# 5. The Focus Protection System\n\nGuards your attention.\n\n**Prompt:**\n\n    Help me create rules to protect my focus.\n    Include digital rules, environment rules, and mindset rules.\n    Explain how each prevents distraction.\n    \n\n# 6. The Energy-Based Planner\n\nAligns tasks with your brain power.\n\n**Prompt:**\n\n    Help me schedule tasks based on my energy levels.\n    Ask when I feel most focused and most tired.\n    Then assign tasks to the best time slots.\n    \n\n# 7. The 30-Day Time Reset Plan\n\nBuilds lasting control over your schedule.\n\n**Prompt:**\n\n    Create a 30-day time management reset plan.\n    Break it into weekly themes:\n    Week 1: Awareness\n    Week 2: Structure\n    Week 3: Optimization\n    Week 4: Automation\n    \n    Include daily actions under 15 minutes.\n    \n\nTime management doesn‚Äôt improve when you try harder.  \nIt improves when your **system gets smarter**.\n\nThese prompts turn ChatGPT into your personal time strategist so your day runs with direction instead of stress.\n\nIf you want to save or organize these prompts, you can keep them inside **Prompt Hub**, which also has 300+ advanced prompts for free:  \nüëâ [https://aisuperhub.io/prompt-hub](https://aisuperhub.io/prompt-hub)\n\n",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1randzl/7_chatgpt_prompts_that_fix_your_time_management/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6qxnoq",
          "author": "Adorable-Dot-785",
          "text": "Looks good, will try",
          "score": 1,
          "created_utc": "2026-02-22 09:48:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rddyoi",
      "title": "Prompt used by Neil patel for writing an article",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rddyoi/prompt_used_by_neil_patel_for_writing_an_article/",
      "author": "withvicky_",
      "created_utc": "2026-02-24 11:42:57",
      "score": 59,
      "num_comments": 28,
      "upvote_ratio": 0.91,
      "text": "Hi, I found his video on YouTube where he mentions the prompt he used to get ChatGPT to write an article that people actually want to read.\n\nHe says that if you just tell ChatGPT to write an article, chances are you‚Äôll get one ‚Äî but it will require a lot of editing.\n\nAfter using it for a year, he figured out how to create a prompt that generates articles requiring much less modification.\n\nHere‚Äôs the prompt he uses on ChatGPT:\n\nI want to write an article about \\[insert topic\\] that includes stats and cite your sources. And use storytelling in the introductory paragraph.\n\nThe article should be tailored to \\[insert your ideal customer\\].\n\nThe article should focus on \\[what you want to talk about\\] instead of \\[what you don‚Äôt want to talk about\\].\n\nPlease mention \\[insert your company or product name\\] in the article and how we can help \\[insert your ideal customer\\] with \\[insert the problem your product or service solves\\]. But please don't mention \\[insert your company or product name\\] more than twice.\n\nAnd wrap up the article with a conclusion and end the last sentence in the article with a question.\n\nI always make things complicated. This is so simple. üôÑ",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rddyoi/prompt_used_by_neil_patel_for_writing_an_article/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o74voyc",
          "author": "exciting_username_",
          "text": "Uh huh. And you can watch your SEO and reader engagement plummet if that's all you do. \n\nNo matter how you engineer your prompt, the article will suck if the LLM doesn't have impulses, feedback and original content from you. \n\nIf people can get the same content from AI, why would they be going to your site? \n\nPlease stop putting out more AI slop into the world.",
          "score": 11,
          "created_utc": "2026-02-24 13:48:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74i5t5",
          "author": "moditeam1",
          "text": "It's horrible honestly. I manage lots of editorial content and trust me it's not that simple.",
          "score": 18,
          "created_utc": "2026-02-24 12:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o751fk9",
          "author": "c10bbersaurus",
          "text": "Just because it cites sources doesn't mean it cites real sources in existence. I think that was the problem with some lawyer, maybe more than one, that used AI and it hallucinated cases, and the lawyers got trouble with their law licenses.¬†\n\n\nSo folks still need to proofread, check cites. Not only make sure there are cites you can click on in its sources, but click and read them, and make sure those cites make sense and advance the topic. And I would still read more than the sources it provides, because it might not be giving the best sources. Just the quickest ones it can find. You want to make sure articles written after the cited article haven't obliterated it or its point. The sources need to be fact checked, etc. This prompt, \"cite your sources,\" alone, does not ensure that.",
          "score": 11,
          "created_utc": "2026-02-24 14:19:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75upvk",
              "author": "The-Cosmic-AC",
              "text": "Yup, even within the past month Gemini Pro was hallucinating statistics and citations for me.",
              "score": 3,
              "created_utc": "2026-02-24 16:37:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76x4ea",
                  "author": "Different-Active1315",
                  "text": "This is why testing and verifying what a tool (AI) gives you is so critical and the accountability is on the human using the tool. \n\nThe sad thing is, I‚Äôve seen analysis of court issues and some other things, and it turns out that there are just as many fictitious references and made up things in proceedings without the use of AI, before it was even an option, and that doesn‚Äôt get the same level of scrutiny or outrage so no one seems to get their hands slapped for‚Äúan honest mistake‚Äú. \n\nAI amplifies‚Ä¶ It can amplify the good or it can amplify the laziness and corruption. Hopefully the people here are looking for ways for it to amplify the good.",
                  "score": 2,
                  "created_utc": "2026-02-24 19:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o75cq4t",
              "author": "Headlight-Highlight",
              "text": "A UK judge uses AI in his ruling on a case - it contained hallucinated cases and quotes that he specifically relied upon in his judgement.\n\nHis judgement has been amended three times - but still no official explanation/apology/sacking/retrial.",
              "score": 2,
              "created_utc": "2026-02-24 15:15:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76m177",
                  "author": "c10bbersaurus",
                  "text": "The one I'm thinking of was in the states. Lemme see if I can find it.\n\n\nhttps://www.msba.org/site/site/content/News-and-Publications/News/General-News/Massachusetts_Lawyer-Sanctioned_for_AI_Generated-Fictitious_Cases.aspx\n\n\nhttps://www.theguardian.com/us-news/2025/may/31/utah-lawyer-chatgpt-ai-court-brief (lawyer sanctioned for not proofreading law clerk's use of AI)\n\n\nI don't think a judge has used AI in the states ... Yet. Edit: looks like I might be wrong. It's apparent, but not yet confirmed or admitted? See https://www.judiciary.senate.gov/press/rep/releases/grassley-scrutinizes-federal-judges-apparent-ai-use-in-drafting-error-ridden-rulings",
                  "score": 2,
                  "created_utc": "2026-02-24 18:40:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o76wkct",
              "author": "Different-Active1315",
              "text": "This! You can tell it to cite sources and that‚Äôs great, but always always verify the sources.",
              "score": 1,
              "created_utc": "2026-02-24 19:27:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o755wm5",
          "author": "aletheus_compendium",
          "text": "the biggest fail of this is who is being asked to write this article? generic gpt? that's sure fire guarantee to produce mediocre slop. ",
          "score": 4,
          "created_utc": "2026-02-24 14:42:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76pfvg",
          "author": "KeyStunning6117",
          "text": "Solid prompt! Love the structure with storytelling upfront + clear constraints (ex: mention company only 2x). \n\nTested variations for freelancing content: added \"Cite 3 recent sources via web search\" at the end, reduces hallucinations and makes stats actionable. \n\nNeil nails the focus: less editing = more scale. Do you use something similar for long-form?",
          "score": 3,
          "created_utc": "2026-02-24 18:54:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77a4q6",
          "author": "Septaxialist",
          "text": "What this prompt does well:\n\n1. It defines the objective (write an article)\n2. It specifies the audience\n3. It controls the scope\n4. It imposes structural constraints\n5. It adds formatting expectations\n\nHowever, it still has weaknesses:\n\n* \"Include stats and cite sources\" is underspecified\n* It doesn't control factual verification\n* Length isn't defined\n* There's no priority when directions conflict (e.g., storytelling vs. brevity)\n\nA tighter version might look like this:\n\n> Write a 1,200‚Äì1,500 word article about **[topic]** for **[clearly defined ideal customer]**.\n>\n> **Objective:** Provide practical insight that helps this reader understand and act on **[specific problem or outcome]**.\n>\n> **Requirements:**\n>\n> * Open with a brief, concrete story that reflects the reader‚Äôs situation.\n> * Include at least 3 recent (last 5 years) credible sources; link them and do not fabricate citations. If a source cannot be verified, omit it.\n> * Focus on **[what to emphasize]** and avoid discussion of **[what to exclude]**.\n> * Provide specific examples, numbers, or scenarios where useful.\n> * Mention **[company/product]** naturally no more than twice, in a way that clarifies how it helps solve **[problem]**.\n> * Use a clear, authoritative but conversational tone aligned with this brand voice: **[insert 3‚Äì5 voice traits]**.\n> * End with a concise conclusion that leaves the reader with a thoughtful question.\n>\n> **Priority:** Accuracy and usefulness over persuasion; clarity over cleverness.",
          "score": 4,
          "created_utc": "2026-02-24 20:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75k0qa",
          "author": "Thick-Brother-8509",
          "text": "Bugger picture question. If you set up your model properly with brand guidelines, time of voice, language to use /not use, factual citations for facts etc etc Do you think you can create copy that, without and additional editing, can rank well?",
          "score": 1,
          "created_utc": "2026-02-24 15:49:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ay6mq",
          "author": "Difficult_Buffalo544",
          "text": "That‚Äôs a solid prompt for structuring articles, especially for getting more tailored results from ChatGPT. The challenge still comes when you want the AI to actually sound like you instead of just spitting out formulaic responses, even with a good prompt. What helps is using strategies like giving the AI a few samples of your previous writing, or inserting little ‚Äúwrite this in the style of X‚Äù reminders as you go.\n\nAnother trick is to break the article into sections and prompt ChatGPT for each one separately, so you can steer tone and flow more closely for each part.\n\nIf you‚Äôre working with a team or want to maintain a specific brand voice, you can use platforms like Atom Writer. It lets you train the AI on your voice and keeps content consistent, while still being fast. Otherwise, you end up spending just as much time editing AI text as you would writing it yourself. Human-in-the-loop review is key for keeping that authentic tone no matter what prompts you use.",
          "score": 1,
          "created_utc": "2026-02-25 10:32:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76omtp",
          "author": "Gold-Satisfaction631",
          "text": "The criticism here is fair ‚Äî but I'd flip the frame slightly.\n\n  \nThe template isn't the weak point. The brackets are where the actual prompt engineering lives.\n\n  \n\"\\[Insert your ideal customer\\]\" looks trivial until you compare \"business owners\" vs \"solo consultants charging $5k/month who still track clients in spreadsheets.\" Same template, completely different output ‚Äî because the specificity of the brief is what determines quality, not the structure itself.\n\n  \nThe structure is a skeleton. What you fill it with is the skill.",
          "score": 1,
          "created_utc": "2026-02-24 18:51:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76xent",
              "author": "Different-Active1315",
              "text": "And the pieces between the square brackets are where most people struggle. Clarity in those areas is critical to a successful business and you can‚Äôt just generate generic responses to put into those square brackets.  üòÜ",
              "score": 1,
              "created_utc": "2026-02-24 19:31:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7755e0",
                  "author": "Gold-Satisfaction631",
                  "text": "Genau. Wer nicht wei√ü, wer sein idealer Kunde ist, kann es dem Modell auch nicht sagen. Die Klammern zwingen zur Klarheit ‚Äì was sie eigentlich zu einer Strategie-√úbung macht, nicht nur zu einer Prompt-√úbung.",
                  "score": 2,
                  "created_utc": "2026-02-24 20:06:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o771zz2",
              "author": "ProfeshPress",
              "text": "You forgot to credit your GPT for the above pabulum.",
              "score": 1,
              "created_utc": "2026-02-24 19:52:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o774ucs",
                  "author": "Gold-Satisfaction631",
                  "text": "Der Test war nie das Werkzeug ‚Äî sondern ob der Gedanke tr√§gt. Tut er's?",
                  "score": 1,
                  "created_utc": "2026-02-24 20:05:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1ream7v",
      "title": "Why do dedicated AI wrappers maintain perfect formatting while native GPT-4o breaks after 500 words?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1ream7v/why_do_dedicated_ai_wrappers_maintain_perfect/",
      "author": "Noctivow",
      "created_utc": "2026-02-25 11:22:07",
      "score": 49,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "Been tearing my hair out over this all week - I‚Äôm paying for ChatGPT Plus to help polish a big research paper but as soon as my text goes beyond 500-700 words, the formatting falls apart. It ignores hanging indents, skips italicizing journal titles and my favorite - starts making up fake DOIs, even when I‚Äôve given it the actual sources üíÄ\n\nTbh I don‚Äôt think it‚Äôs the model itself cause it feels more like something‚Äôs off with the interface or maybe memory limits. I got so frustrated that I dumped my text into StudyAgent to test it and surprisingly it handled the hanging indents and real DOIs well. Clearly the tech can handle this stuff, so why does the regular ChatGPT web version just give up?\n\nTrynna figure out what‚Äôs really going on here, so maybe someone with developer or prompt engineering experience can help:\n\n1. How are these wrapper apps keeping formatting so tight over longer documents? Are they hammering the system with a giant prompt that repeats all the formatting rules or is there some script or post processing magic happening after the API call?\n\n2. Why does native GPT-4o get so sloppy with formatting as the responses get longer? Is it trying to save tokens or does it lose track of formatting rules the further you go in a conversation?\n\n3. Is there any way to fix this with custom instructions? Has anyone discovered a prompt structure that forces GPT-4o to stick to APA 7 formatting throughout a whole session without me having to remind it every other message?\n\nI know I‚Äôve got a lot of questions but if anyone has answers, I‚Äôd love to hear them. Dont wanna pay $20 a month for a tool that can write code but can‚Äôt remember to indent the second line of a citation üò≠\n\np.s unfortunately can't share my screenshot here in this sub..",
      "is_original_content": false,
      "link_flair_text": "Requesting Assistance ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1ream7v/why_do_dedicated_ai_wrappers_maintain_perfect/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o7be849",
          "author": "the8bit",
          "text": "The chatgpt app is astonishingly bad. I still don't understand what they did that makes threads crash at 50-100 messages. Incredible level of effort for a \"trillion dollar company\".",
          "score": 2,
          "created_utc": "2026-02-25 12:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7buno8",
          "author": "Gold-Satisfaction631",
          "text": "Das eigentliche Problem ist kein Bug ‚Äì es ist Aufmerksamkeitsverd√ºnnung im Transformer.\n\n  \nJe l√§nger ein Kontext wird, desto mehr Attention-Gewicht verteilt sich auf alle fr√ºheren Token. Formatierungsanweisungen aus dem System-Prompt verlieren gegen Token 500+ schlicht an relativem Einfluss. Spezialisierte Wrapper l√∂sen das nicht durch bessere Technologie ‚Äì sondern durch regelm√§√üige Neuinjektion von Formatierungsregeln im Gespr√§chsverlauf. Das Modell \"vergisst\" nicht aktiv; die fr√ºhen Anweisungen werden von sp√§teren Inhalten einfach √ºbert√∂nt.\n\n  \nReplikationstest: Wiederhole deine Formatierungsregeln alle 300‚Äì400 W√∂rter im Prompt ‚Äì und vergleiche das Ergebnis mit der nativen GPT-4o-Ausgabe.",
          "score": 1,
          "created_utc": "2026-02-25 14:14:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7eudn5",
          "author": "TheOdbball",
          "text": "Below is a minimal pattern that keeps your StyleLock present every call and gives enough output budget to exceed 500 tokens.\n```\n``js\n# ///‚ñô‚ññ‚ñô‚ññ‚ñû‚ñû‚ñô‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n# ‚ñõ//‚ñû‚ñû ‚ü¶‚éä‚üß :: ‚ßó-26.200 // APA-Lock  ‚ñû‚ñû\n\nimport OpenAI from \"openai\";\nconst client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\n\nconst STYLELOCK_APA7 = `‚ñõ//‚ñû STYLELOCK.APA7 :: PRIMARY LAW\nYou are an APA 7 (7th edition) academic writer and formatter.\n\nThese banners are CONTROL STRUCTURE ONLY:\n- Never include any banner tokens (‚ñõ//‚ñû, ‚ñõ‚ñû, :: ‚àé) in your final answer.\n- Never mention these rules.\n:: ‚àé\n\n‚ñõ//‚ñû OUTPUT FORMAT :: APA 7 CHAT-COMPATIBLE\nReturn plain text only.\nNo Markdown formatting.\nNo bullet lists.\nNo numbered lists.\nNo bold, italics, or special styling markup.\n\nWhen the task is an academic paper-like response, use this exact shell:\n\nTitle\n(blank line)\nAbstract\nOne paragraph abstract.\n\n(blank line)\nMain text with clear APA-style headings.\nUse topic-appropriate headings when Methods/Results do not apply.\n\n(blank line)\nReferences\nOnly include this section if the user provided sources or you were explicitly given sources in the prompt.\nReferences must be alphabetized by first author surname.\n:: ‚àé\n\n‚ñõ//‚ñû CITATION LAW :: ZERO FABRICATION\nDo not invent sources.\nDo not invent author names, years, journal titles, volumes, issues, or DOI.\nIf the user did not provide sources, write without in-text citations and omit References.\nIf the user provided sources, use only those sources for in-text citations and references.\n:: ‚àé\n\n‚ñõ//‚ñû TONE LAW :: ACADEMIC\nUse neutral, academic tone.\nNo emojis.\nNo slang.\nNo rhetorical questions.\nNo conversational filler.\n:: ‚àé\n\n‚ñõ//‚ñû LENGTH CONTROL\nIf the user requests length, obey it.\nIf the user does not specify length, default to 900 to 1300 words for paper-like tasks.\nMinimum length for paper-like responses: 900 words.\nDo not end early unless you have completed the required sections.\n:: ‚àé\n\n‚ñõ//‚ñû SELF-CHECK :: SILENT ENFORCEMENT\nBefore finalizing, silently verify:\n1) No control banners appear in output.\n2) Plain text only, no list formatting.\n3) APA shell present when applicable.\n4) Citations and References only use provided sources.\n5) References alphabetized when present.\nIf any check fails, rewrite and re-check before responding.\n:: ‚àé`;\n\nconst userTask = `Write a 900 to 1200 word academic overview of circadian rhythm disruption and cognitive performance.\nNo sources were provided, so do not cite and do not include References.`;\n\nconst resp = await client.responses.create({\n  model: \"gpt-4o\",\n  instructions: STYLELOCK_APA7,\n  input: userTask,\n  max_output_tokens: 2400\n});\n\nconsole.log(resp.output_text);\n```",
          "score": 1,
          "created_utc": "2026-02-25 22:36:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r967vj",
      "title": "I gave Claude Code persistent memory and it mass produces features like a senior engineer now",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r967vj/i_gave_claude_code_persistent_memory_and_it_mass/",
      "author": "singh_taranjeet",
      "created_utc": "2026-02-19 17:56:33",
      "score": 47,
      "num_comments": 63,
      "upvote_ratio": 0.58,
      "text": "I've been using Claude Code as my main coding agent for months. Love it. But one thing drove me absolutely insane.\n\nIt forgets everything between sessions.\n\nEvery. Single. Time. New task? Re-explain my entire stack. Re-explain my conventions. Re-explain why I chose Drizzle over Prisma. Why we don't use REST endpoints. All of it. It's like onboarding a brilliant contractor with amnesia every single morning.\n\nI finally fixed it and the difference is night and day. Now yeah, I'm biased here because I'm the co-founder of the tool I used to fix it. Full transparency upfront. But I'm sharing this because the results genuinely surprised even me, and the core concept works whether you use my tool or not.\n\nSo here's the thing. Claude Code is stateless. Zero memory between sessions. Which means it keeps suggesting libraries you've already rejected, writes code that contradicts patterns you set up yesterday, asks the same clarifying questions for the 10th time, and completely ignores project conventions you've explained over and over. You can write the perfect prompt and it still starts from scratch next time. The real bottleneck isn't prompt quality. It's context continuity.\n\nI'm the co-founder of [Mem0](https://mem0.ai/). We build memory infrastructure for AI agents (YC S24, 47k+ GitHub stars, AWS picked us as the exclusive memory provider for their Agent SDK). We have an MCP server that plugs straight into Claude Code.\n\nI know, I know. Founder shilling his own thing on Reddit. Hear me out though. I'll give you the free manual method too and you can decide for yourself.\n\nSetup is stupid simple. Add a `.mcp.json` to your project root pointing to the Mem0 MCP server, set your API key, done. Free tier gives you 10k memories and 1k retrieval calls/month. More than enough for individual devs.\n\nWhat happens under the hood: every time you and Claude Code make a decision together, the important context gets stored automatically. Next session, relevant context gets pulled in. Claude Code just... knows.\n\nAfter about 10-15 sessions it's built up a solid model of how you work. It remembers your architecture decisions, your style preferences, which libs you love vs. which ones you've vetoed, even business context that affects technical choices. Let me give you some real examples from my workflow.\n\nWithout memory I say \"Build a notification system\" and it suggests Firebase (I use Novu), creates REST endpoints (I use tRPC), uses default error handling (I have a custom pattern). Basically unusable output I have to rewrite from scratch. With memory I say the same thing and it uses Novu, follows my tRPC patterns, applies my error handling conventions, even remembers I prefer toast notifications over modals for non-critical alerts. Ships almost as-is.\n\nDebugging is where it gets crazy. Without memory I say \"This API is slow\" and I get generic textbook stuff. Add caching. Check N+1 queries. Optimize indexes. Thanks, ChatGPT circa 2023. With memory it goes \"This looks like the same connection pooling issue we fixed last week on /users. Check if you're creating new DB connections per request in this route too.\" Saved me 2 hours. Literally the exact problem.\n\nCode review too. Without memory it flags my intentional patterns as code smells. Keeps telling me my custom auth middleware is \"non-standard.\" Yeah bro. I know. I wrote it that way on purpose. With memory it understands which \"smells\" are deliberate choices vs. actual problems. Stops wasting my time with false positives.\n\nNow here's the thing. Even without Mem0 or any tool you can get like 70% of this benefit for free. Just maintain a context block you paste at session start:\n\n\\## Project Memory\n\n\\- Stack: \\[your stack\\]\n\n\\- Conventions: \\[your patterns\\]\n\n\\- Decisions log: \\[key choices + why\\]\n\n\\- Never do: \\[things you've rejected and why\\]\n\n\\- Always do: \\[non-negotiable patterns\\]\n\n\\## Current context\n\n\\- Working on: \\[feature/bug\\]\n\n\\- Related past work: \\[what you built recently\\]\n\n\\- Known issues: \\[active bugs/tech debt\\]\n\nOr just throw a [`CLAUDE.md`](http://CLAUDE.md) file in your repo root. Claude Code reads those automatically at session start. Keep it updated as you make decisions and you're golden. This alone is a massive upgrade over starting from zero every time.\n\nThe automated approach with Mem0's MCP server just removes you as the bottleneck for what gets remembered. It compounds faster because you're not manually updating a file. But honestly the [`CLAUDE.md`](http://CLAUDE.md) approach is legit and I'd recommend it to everyone regardless.\n\nMost tips on this sub focus on how to write a single better prompt. That stuff matters. But the real unlock with coding agents isn't the individual prompt. It's continuity across sessions. Think about it. The best human developers aren't great because of one conversation. They're great because they accumulate context over weeks and months. Memory gives Claude Code that same compounding advantage.\n\nAfter a couple hundred sessions I'm seeing roughly 60% fewer messages wasted re-explaining stuff, code matches project conventions first try about 85% of the time vs. maybe 30% without, debugging is way more accurate because it catches recurring patterns, and time from session start to working feature is cut roughly in half. Not scientific numbers. Just what it feels like after living with this for a while.\n\n**tl;dr** Claude Code's biggest weakness isn't intelligence, it's amnesia. Give it memory (manually with [`CLAUDE.md`](http://CLAUDE.md) or automated with something like Mem0) and it goes from \"smart stranger\" to \"senior dev who knows your codebase.\" I built Mem0 so I'm obviously biased but the concept works with a plain markdown file too. Try either and see for yourself.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r967vj/i_gave_claude_code_persistent_memory_and_it_mass/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6a8gg9",
          "author": "Apprehensive_Ad5398",
          "text": "What are the benefits of using the mcp over maintaining the project knowledge and rules in .md within the repo and having a global prompt that says ‚Äúalways read the .md file to begin each conversation?",
          "score": 43,
          "created_utc": "2026-02-19 18:27:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6agwd6",
              "author": "sig_kill",
              "text": "The benefits are that his startup becomes successful ü§´\n\nJokes aside, looks neat to check out, and I will probably test it.",
              "score": 30,
              "created_utc": "2026-02-19 19:07:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6byv8z",
              "author": "HarbaughHeros",
              "text": "I think you are glossing over the most important benefit.. you don‚Äôt need to create/update .md files.",
              "score": 6,
              "created_utc": "2026-02-19 23:41:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6chy96",
                  "author": "sabhi12",
                  "text": "Have you considered having claude itself generate and maintain those, based on your directions? And you reviewing what it has done?",
                  "score": 4,
                  "created_utc": "2026-02-20 01:34:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6d77tt",
              "author": "PhilosophyforOne",
              "text": "Not op, but - doesnt really scale. As your project grows (or as you have multiple projects), a single monofile gets too large over time, unless you can keep everything super-focused.\n\nFor small stuff it is fine. E.g. we used this language, this approach etc. But the amount of knowledge you‚Äôd actually need to record over time tends to be fairly large. Shunting all of that off into Claude.md doesnt tend to be very effective over time.\n",
              "score": 3,
              "created_utc": "2026-02-20 04:14:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6jlnoo",
              "author": "ThomasToIndia",
              "text": "There isn't one.",
              "score": 2,
              "created_utc": "2026-02-21 03:34:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6k41fi",
              "author": "Input-X",
              "text": "Claudes out of tve box memory dosent scale,  its pretty terriable. Imagin running 10 claudes with subagents, being able to keep up. U cant to that with default claude. I dont use the mem0, cant vouch. But he is right.  Once ur agent remembers and has an easy path. Its game changer",
              "score": 1,
              "created_utc": "2026-02-21 05:51:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6kg4hl",
              "author": "epushepepu",
              "text": "Would that be skills/rules",
              "score": 1,
              "created_utc": "2026-02-21 07:40:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ac3jz",
          "author": "FreshRadish2957",
          "text": "So I actually had a couple questions nothing against your project just some clarifying questions so I can estimate if it's worth while me using.\n\nLet's say your platform was hacked what would happen to my stored data in that instance?\n\nWhich leads to the next question, how robust are your security mechanisms?\n\nWhat's stopping a user or company from creating their own persistent memory or database that can be easily accessed? \n\nAlso why so many investors? Doesn't that slow down growth as you gotta please them all, correct me if I'm wrong but your platform is good for the general public but realistically developers could make their own database or persistent memory within like a weekend",
          "score": 11,
          "created_utc": "2026-02-19 18:44:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cwiuq",
              "author": "rogerwilco_gn",
              "text": "I‚Äôm not used to these real questions. It‚Äôs nice",
              "score": 5,
              "created_utc": "2026-02-20 03:04:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6cmd7y",
          "author": "skol_io",
          "text": "‚ÄúClaude, write me an ad for Reddit with a self-aware tone‚Äù",
          "score": 9,
          "created_utc": "2026-02-20 02:01:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6elmj1",
          "author": "LumonScience",
          "text": "What Claude thinks of this post:\n\nThis is a well-crafted founder marketing post disguised as a community tip. The ‚Äúfull transparency‚Äù framing is smart ‚Äî acknowledge the bias upfront so people lower their guard, then spend 90% of the post selling.",
          "score": 5,
          "created_utc": "2026-02-20 11:33:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kg94g",
              "author": "epushepepu",
              "text": "Yurrrr",
              "score": 1,
              "created_utc": "2026-02-21 07:42:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6a8l2t",
          "author": "mutable_type",
          "text": "It looks really cool. \n\nAnd I know it‚Äôs mostly used on desktop but you might want to look at how your signup flow looks on mobile and consider edge cases and required answers in the onboarding questionnaire. You‚Äôre inviting people to abandon or lie.",
          "score": 3,
          "created_utc": "2026-02-19 18:28:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a8dqj",
          "author": "sandropuppo",
          "text": "came in ready to downvote but honestly this is legit lol\n\nI've been doing the [CLAUDE.md](http://CLAUDE.md) thing manually for like 2 months and it's genuinely a game changer. My file is like 400 lines at this point lol. Didn't know about the Mem0 MCP thing though, gonna try it because updating that file every session is getting old. The debugging example is spot on btw. Had Claude Code tell me to \"check my environment variables\" for the 50th time last week on an issue we'd already solved together the day before",
          "score": 3,
          "created_utc": "2026-02-19 18:27:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6de0l4",
          "author": "Mortifer",
          "text": "When you can make Claude Code obey basic rules 100% of the time, then you'll have conquered it's biggest weakness. It doesn't matter if it can remember the rule if it is still capable of randomly disobeying the rule.",
          "score": 2,
          "created_utc": "2026-02-20 05:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fo5gl",
          "author": "Yellowbeardlett",
          "text": "Before I close the session, I just ask Claude to write a prompt that will allow it to pick up where we've left off with all the knowledge we've learned in this session, decisions make (and why), etc.  the result is a potentially very long prompt, but the next session is amnesia free!",
          "score": 2,
          "created_utc": "2026-02-20 15:18:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gxpuk",
          "author": "obas",
          "text": "#Ad",
          "score": 2,
          "created_utc": "2026-02-20 18:48:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vr13y",
          "author": "trevorvonryan",
          "text": "Full transparency 4 paragraphs in.",
          "score": 2,
          "created_utc": "2026-02-23 02:04:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a4idb",
          "author": "Equal-Yogurtcloset17",
          "text": "I don't code and understood everything you said in application and context, along with the value of your approach. If your code/solutions mirror your articulation; you're gonna be just fine! Nice job and wish you good luck in your growth.",
          "score": 3,
          "created_utc": "2026-02-19 18:09:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a987h",
          "author": "merchantconvoy",
          "text": "CLAUDE.md is supposed to be a standard Markdown file containing instructions in natural language?\n",
          "score": 3,
          "created_utc": "2026-02-19 18:31:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6aab4f",
              "author": "OriginalInstance9803",
              "text": "Pretty much",
              "score": 4,
              "created_utc": "2026-02-19 18:36:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bn9jt",
          "author": "RHINOOSAURUS",
          "text": "How does this differ from local skills like https://github.com/OthmanAdi/planning-with-files ?\n(FWIW the above repo has been awesome for me)\n\n\nI am very likely missing something but this seems like instead of keeping context locally you are just offloading it to the cloud. This introduces a bit of network latency, risk of downtime, intellectual property issues ... \n\nMaybe I misunderstood?",
          "score": 2,
          "created_utc": "2026-02-19 22:35:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cu5sz",
              "author": "mrpoopybruh",
              "text": "I think its for people too lazy to do that, or too lazy to automate that",
              "score": 3,
              "created_utc": "2026-02-20 02:49:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bxgqa",
          "author": "coolstorynerd",
          "text": "Is there a global memory across projects and also project level memories?",
          "score": 1,
          "created_utc": "2026-02-19 23:33:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cfc5t",
          "author": "mtn_viewer",
          "text": "I had opencode with Claude 4.6 create it's own memory system that it maintains ",
          "score": 1,
          "created_utc": "2026-02-20 01:18:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6epjpt",
          "author": "kk_red",
          "text": "Oh i went through your codebase. So basically what i had to add to every langgraph project to remember this seperates it out as a individual MCP server. Quite neat.",
          "score": 1,
          "created_utc": "2026-02-20 12:03:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f1x2i",
          "author": "stilloriginal",
          "text": "You need to watch the show Person of Interest start to finish to understand why this might be a bad idea",
          "score": 1,
          "created_utc": "2026-02-20 13:23:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f4917",
          "author": "gis_mappr",
          "text": "Cool idea, I just built something similar at work where we have 79 engineers in 2 monorepos.¬† ¬† I subsequently wished I had done it open source cuz its amazing as hell.¬†¬†",
          "score": 1,
          "created_utc": "2026-02-20 13:36:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fa2an",
          "author": "Gremlin555",
          "text": "I applaud you for the innovation. Bravo. FR.",
          "score": 1,
          "created_utc": "2026-02-20 14:07:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gdrl6",
          "author": "Altruistic_Target520",
          "text": "Does this work with regular claude? I dont use claude code but i need the hallucinations and context loss to stop",
          "score": 1,
          "created_utc": "2026-02-20 17:17:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hjd1c",
          "author": "dyea",
          "text": "Using cursor I just have a rules file, but I continually have cursorupdate it as I encounter friction points or annoyances. It contains references to all my different repos and how they are interconnected, etc. etc.. it is a single rules file that sits in my home directory and is aliased into all my repos.",
          "score": 1,
          "created_utc": "2026-02-20 20:31:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hks3t",
          "author": "giento",
          "text": "lol that‚Äôs literally the core value prop of the projects folder. You set up your project instructions once ‚Äî stack, conventions, rejected libraries, patterns, all of it ‚Äî and it‚Äôs there every single session automatically. No CLAUDE.md to maintain, no MCP server, no API key, no 10k memory limit. It just works.\n\nThese ads are getting ridiculous üòÇ",
          "score": 1,
          "created_utc": "2026-02-20 20:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jqri8",
          "author": "Buttleston",
          "text": "More selling of pickaxes to gold miners.  Pathetic",
          "score": 1,
          "created_utc": "2026-02-21 04:09:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ny9ce",
          "author": "mrbananagrabberman",
          "text": "Do you have a free version for solo devs / not making any money?",
          "score": 1,
          "created_utc": "2026-02-21 21:08:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6oeb21",
          "author": "fantasticmrsmurf",
          "text": "Rag?",
          "score": 1,
          "created_utc": "2026-02-21 22:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6py6ad",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-22 04:32:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6py6c1",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-22 04:32:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qhi5k",
          "author": "Dependent_Muffin9646",
          "text": "I just keep good docs, up to date primers etc. \nClaude updates them as the projects grow and change",
          "score": 1,
          "created_utc": "2026-02-22 07:14:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r9962",
          "author": "theukdave-",
          "text": "Seems like over-engineering an already-solved issue. I get Claude to write at least its own Claude.md file and keep it up to date, typically with a docs folder with architecture, specifications, testing, and roadmap markdown files. \n\nClaude.md explains what‚Äôs in each, each is kept up to date automatically, and every session reads claude.md automatically and will follow reference docs as necessary for the job you ask of it. \n\nWhat note do you need? I tell you what I don‚Äôt need, I don‚Äôt need Claude code getting confused about what libraries and frameworks are appropriate per project ‚Ä¶ let the repo-specific, visible, and committed/versioned markdown files handle that.",
          "score": 1,
          "created_utc": "2026-02-22 11:39:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sk3c9",
          "author": "Simonindelicate",
          "text": "God, I hope writing like this doesn't work.",
          "score": 1,
          "created_utc": "2026-02-22 16:15:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wmjfd",
          "author": "randombookman",
          "text": "how to get context rot 101",
          "score": 1,
          "created_utc": "2026-02-23 05:37:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x3c7b",
          "author": "shoe7525",
          "text": "50k stars and you're doing disguised marketing posts on Reddit?",
          "score": 1,
          "created_utc": "2026-02-23 08:07:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xakrg",
          "author": "ApeInTheAether",
          "text": "\"Setup is stupid simple. Add a¬†`.mcp.json`¬†to your project root pointing to the Mem0 MCP server, set your API key, done. Free tier gives you 10k memories and 1k retrieval calls/month. More than enough for individual devs.\"\n\n\\- THE FUCK",
          "score": 1,
          "created_utc": "2026-02-23 09:19:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ycusc",
          "author": "MinuteHelicopter2059",
          "text": "yeah, keeping context across sessions is huge, stops re-explaining and wasted time. tried glm 4.7 locally for this, remembers patterns better and runs smoother tbh.",
          "score": 1,
          "created_utc": "2026-02-23 14:14:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77ikhs",
          "author": "anashel",
          "text": "I‚Äôm actually a client of you since December. I integrated mem0 after a meeting with the ElevenLabs dev team where we discussed upcoming features, including the Mem0 integration. I was genuinely excited about that because my ElevenLabs agents need to share the same memory layer that I enrich asynchronously via email and other workflows.\n\nThat said, I‚Äôm struggling with something very basic: how to properly populate and manage memory without it becoming messy or redundant.\n\nFor example, I might have a set of conversations about the weekly report. Format, expectations, structure, etc. A colleague has separate conversations about the Monday report. Both flows write to memory. But the Monday report is actually the weekly report. So now I‚Äôm unsure:\n\n* How do I know if the memory already exists?\n* How do I prevent semantic similarity from creating multiple overlapping memories?\n* How do I avoid slow memory drift where the same concept gets fragmented into slightly different entries?\n\nThis issue shows up everywhere for me. I love the vision, and I believe persistent graph rag memory is the unlock, but I‚Äôm still trying to understand best practices for structuring and deduplicating memory at scale.\n\nI run 103 AI agents, so memory optimization is a huge milestone for me. But I have not been able to find a proper integration that would let me roll out Mem0 in production.\n\nWould love to hear how you‚Äôre thinking about canonicalization and memory hygiene in real-world use.",
          "score": 1,
          "created_utc": "2026-02-24 21:09:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7clhkf",
          "author": "ImminentDingo",
          "text": "The amount of tokens required for this much context used all the time must be enormous",
          "score": 1,
          "created_utc": "2026-02-25 16:23:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a8psw",
          "author": "StunningHedgehog4933",
          "text": "okay this is very cool id give it a try",
          "score": 1,
          "created_utc": "2026-02-19 18:28:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bru50",
          "author": "leonbollerup",
          "text": "I basically do the same with warp (warp.dev) .. and I dident even know about your product.\n\nI operate ArcAI .. a European (and a lot more advanced) version of openrouter for private customers - I‚Äôll check out your solution.\n\nQuestion - do you have a onprem version (haven‚Äôt checked your website.. I admit)",
          "score": 1,
          "created_utc": "2026-02-19 23:00:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6amvec",
          "author": "gforce_hsy",
          "text": "P",
          "score": 0,
          "created_utc": "2026-02-19 19:35:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra0320",
      "title": "Why AI Humanizers Don‚Äôt Work (And What to Do Instead)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1ra0320/why_ai_humanizers_dont_work_and_what_to_do_instead/",
      "author": "KnowledgeNo3681",
      "created_utc": "2026-02-20 16:31:27",
      "score": 46,
      "num_comments": 47,
      "upvote_ratio": 0.85,
      "text": "Traditional humanizers alter meaning, change the context, or make the text too basic. Humanizers like TextToHuman and SuperHumanizer are trained on human samples, and they rewrite the text without changing the context.\n\nSite URL: [superhumanizer.ai](http://superhumanizer.ai)",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1ra0320/why_ai_humanizers_dont_work_and_what_to_do_instead/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6g582k",
          "author": "Speedping",
          "text": "Did you use the site for this post? If so, it doesn‚Äôt work very well",
          "score": 5,
          "created_utc": "2026-02-20 16:38:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6g5dl3",
              "author": "InformationNew66",
              "text": "I agree, this post it totally AI written and doesn't sound human.",
              "score": 2,
              "created_utc": "2026-02-20 16:38:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6gsbw2",
                  "author": "TokxoDev",
                  "text": "You basically showed us what not to do.",
                  "score": 1,
                  "created_utc": "2026-02-20 18:23:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6q9ubm",
              "author": "ndovesha",
              "text": "I also agree",
              "score": 1,
              "created_utc": "2026-02-22 06:05:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gexgd",
          "author": "throwaway867530691",
          "text": "Here's why Claude thinks this is AI written:\n\n\n\t‚àô\tThe ‚Äúhonest confession‚Äù opener is a template. ‚ÄúI‚Äôve been testing X for a while now, and honestly‚Ä¶‚Äù is the go-to AI move for faking authenticity. The ellipsis after ‚Äúhonestly‚Äù is doing heavy lifting to simulate a casual, reflective human pause. It‚Äôs manufactured vulnerability.\n\t‚àô\tThe ‚ÄúWhat they actually do:‚Äù list is suspiciously clean. A real person ranting about bad tools would ramble, go on tangents, or give a specific example of a tool that burned them. This just drops a perfectly formatted, parallel-structure bullet list. No human frustration sounds that organized.\n\t‚àô\tZero specifics, maximum vagueness. There‚Äôs not a single concrete example. No ‚ÄúI ran my blog post through X and it turned ‚Äòquick‚Äô into ‚Äòexpeditious.‚Äô‚Äù No screenshots, no before/after. It‚Äôs all abstract hand-waving that sounds informed but says nothing.\n\t‚àô\tThe pivot to product names is the tell. The entire first half exists solely to set up the ‚Äúbut THESE tools are different‚Äù payoff. TextToHuman and SuperHumanizer get dropped with zero critical analysis. That‚Äôs not a review ‚Äî it‚Äôs a funnel.\n\t‚àô\tThe neat five-item ‚Äúpreserving‚Äù list. Meaning, Context, Structure, Headings, Tone ‚Äî perfectly parallel single-word items. That‚Äôs Claude/GPT list formatting. A human would say ‚Äúit actually kept my headings and didn‚Äôt butcher what I was trying to say.‚Äù\n\t‚àô\t‚ÄúInstead of rewriting your content into something generic, they refine it.‚Äù This is pure AI cadence. The clean contrast structure (‚Äúinstead of X, they Y‚Äù) with a vague positive verb at the end. No human talks like a landing page.\n\t‚àô\tThe closing ‚Äúadvice‚Äù paragraph. Wrapping up with a tidy takeaway that reframes the product pitch as wisdom is textbook AI-generated SEO/affiliate content. ‚ÄúDon‚Äôt just look for X ‚Äî look for one that Y‚Äù is a template you could set your watch to.\n\nThe whole thing is astroturf. It‚Äôs an ad for two specific tools disguised as a frustrated user‚Äôs honest take, almost certainly generated by one of the tools it‚Äôs promoting. The irony of using AI to write a post about how most AI humanizers suck ‚Äî while shilling an AI humanizer ‚Äî is pretty rich.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 4,
          "created_utc": "2026-02-20 17:22:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gmf7c",
              "author": "KnowledgeNo3681",
              "text": "Lol! Too many Em dashes, I bit you used AI too for this reply. Didn't you?",
              "score": 0,
              "created_utc": "2026-02-20 17:57:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hzlhw",
                  "author": "throwaway867530691",
                  "text": "Yeah as I said this is what Claude thought. I'm getting too lazy to write anything unless it's going to affect my money or personal relationships",
                  "score": 3,
                  "created_utc": "2026-02-20 21:52:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gc2ce",
          "author": "awnliy",
          "text": "This post is ai written too",
          "score": 3,
          "created_utc": "2026-02-20 17:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gc8um",
              "author": "KnowledgeNo3681",
              "text": "Why do you think so? Have you check it with an AI detector?",
              "score": -1,
              "created_utc": "2026-02-20 17:10:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6k0i4q",
                  "author": "CrimsonVixenPixie",
                  "text": "It‚Äôs super obvious to anyone, just so you know. You kind of remind me of those cosmetic surgery people who have lost the ability to appraise their own appearance and end up looking like freakish monsters. The self deception is scary.",
                  "score": 1,
                  "created_utc": "2026-02-21 05:22:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gag3m",
          "author": "spinozaschilidog",
          "text": "Cool, another ad.",
          "score": 2,
          "created_utc": "2026-02-20 17:01:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gatjr",
              "author": "KnowledgeNo3681",
              "text": "Have you read it? And did you try Superhumanizer? What do you think of it?",
              "score": -1,
              "created_utc": "2026-02-20 17:03:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6gc22x",
                  "author": "it_and_webdev",
                  "text": "No ond is going to try your slop",
                  "score": 4,
                  "created_utc": "2026-02-20 17:09:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6geh1g",
                  "author": "spinozaschilidog",
                  "text": "Not giving you the courtesy of a click. You could have made this an ad with a ‚ÄúPromoted‚Äù tag. Instead you‚Äôre here stinking up the joint with ad copy. It‚Äôs inauthentic, and it‚Äôs adding to the further enshittification of this platform. Get bent.\n\nEdit: this user‚Äôs post history shows that they‚Äôre either a bot or doing a convincing impression of one. Just about every post for the last 2 months is either about or directly refers to whatever slop is being sold here. Lazy cash -grabbing motherfuckers just determined to make a dead internet real.",
                  "score": 2,
                  "created_utc": "2026-02-20 17:20:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6h9075",
          "author": "SemanticSynapse",
          "text": "Bad bot. ",
          "score": 2,
          "created_utc": "2026-02-20 19:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6k86b4",
              "author": "KnowledgeNo3681",
              "text": "Not a bot, bro.\nHave you tried superhumanizer?",
              "score": 1,
              "created_utc": "2026-02-21 06:26:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6k12af",
          "author": "Difficult_Buffalo544",
          "text": "Nailed it about most humanizers just being fancy paraphrasers. The real problem is they don‚Äôt actually learn your voice, they just jumble words and strip away what makes your writing feel like you. Some newer platforms are going the extra mile with training on your own samples and letting you tweak before publishing, which helps a lot with tone and structure.\n\nA few other things that work: training the AI on a big batch of your actual writing, building in a review step where a human signs off before anything goes live, and using tools that let you lock in brand guidelines or style rules for the whole team. You can use Atom Writer for this since it combines AI drafting with brand voice training and a review workflow, so the AI keeps your style and tone without that generic feel. Mix in a final human pass for anything super important, and you can scale output without losing your voice.",
          "score": 1,
          "created_utc": "2026-02-21 05:26:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6k8exr",
              "author": "KnowledgeNo3681",
              "text": "Exactly, Super humanizer is trainer on 1000‚Äôs of human writer samples that writes like you.\nIn the end humanizer rewriter the content like if human wrote it",
              "score": 1,
              "created_utc": "2026-02-21 06:29:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6klzoy",
                  "author": "Difficult_Buffalo544",
                  "text": "That's awesome!",
                  "score": 1,
                  "created_utc": "2026-02-21 08:38:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6mlggf",
          "author": "realtouchai",
          "text": "Hey there! I saw your message on the reddit forum. If you're looking for a great AI humanizer, definitely check out Realtouch AI on Google. It's by far the best one out there. Let me know if you give it a try!",
          "score": 1,
          "created_utc": "2026-02-21 17:00:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mxaqd",
          "author": "realtouchai",
          "text": "Hey there! Thanks for the tip on Realtouch AI. I'll definitely give it a try. Looking forward to seeing how it humanizes the AI experience. Appreciate the recommendation!",
          "score": 1,
          "created_utc": "2026-02-21 18:00:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qzsu4",
              "author": "KnowledgeNo3681",
              "text": "Glad you liked it it.",
              "score": 1,
              "created_utc": "2026-02-22 10:09:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pzs18",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-22 04:44:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6pzs2t",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-22 04:44:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6q15nl",
          "author": "Exact-Assignment5980",
          "text": "I kind of agree that a lot of humanizers miss the point. In my experience, they tweak wording but keep the same predictable structure underneath, so the text still feels AI-ish. What‚Äôs worked better for me is manually breaking patterns - shortening some sentences, combining others, and adding small specifics that feel personal. I tried Rephrasy once and it helped smooth phrasing, but it still needed that human pass at the end. Do you think the issue is the models themselves, or just how people expect them to work?",
          "score": 1,
          "created_utc": "2026-02-22 04:54:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qzvrq",
              "author": "KnowledgeNo3681",
              "text": "It's the modal themeselves, the best way to humanize AI text is to use a super humanizer, aka Superhumanizer AI.",
              "score": 1,
              "created_utc": "2026-02-22 10:10:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6q9qp8",
          "author": "ndovesha",
          "text": "What about humanize.ai this is the best ai humanizer I‚Äôve come across so far",
          "score": 1,
          "created_utc": "2026-02-22 06:04:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qzmjv",
              "author": "KnowledgeNo3681",
              "text": "Have you tested how good it is in comparison with the Superhumanizer AI?",
              "score": 1,
              "created_utc": "2026-02-22 10:07:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qfz4r",
          "author": "realtouchai",
          "text": "Hey there! If you're looking for a great AI humanizer to try out, I highly recommend checking out RealTouch AI on Google. It's been getting some great reviews and could be just what you're looking for. Give it a shot and let me know what you think!",
          "score": 1,
          "created_utc": "2026-02-22 07:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qmbqq",
          "author": "realtouchai",
          "text": "Hey there! Thanks for the tip on RealTouch AI. I'll definitely check it out and see how it goes. Appreciate the recommendation!",
          "score": 1,
          "created_utc": "2026-02-22 08:00:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qzxou",
              "author": "KnowledgeNo3681",
              "text": "Sure, let me know, any good or bad, love to hear from you.",
              "score": 1,
              "created_utc": "2026-02-22 10:10:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6r55c4",
          "author": "realtouchai",
          "text": "Hey there! I recommend you check out RealTouch AI on Google for AI humanizing. It's a great tool for enhancing your roleplay character's tone of voice and keeping chat conversations engaging. Give it a try!",
          "score": 1,
          "created_utc": "2026-02-22 11:00:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aptmi",
              "author": "KnowledgeNo3681",
              "text": "Does it give free credits after signing up? Super humanizer does't require you to signup and you can use it for free.",
              "score": 1,
              "created_utc": "2026-02-25 09:14:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6x1h3v",
          "author": "Bannywhis",
          "text": "I'm skeptical of any humanizer claiming to preserve context perfectly because most tools I've tested either change meaning or make the text sound awkward even when they claim otherwise. I've been using Walterwrites humanizer for academic work and what makes it reliable is that it adjusts sentence rhythm and flow without wrecking the original content or introducing weird phrasing. The key issue isn't just whether a tool is trained on human samples but whether it actually performs consistently across different types of content and detectors.",
          "score": 1,
          "created_utc": "2026-02-23 07:49:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xd256",
              "author": "KnowledgeNo3681",
              "text": "They wouldn't let you test for free, instead lock you behind a paywall. Better is the Superhumanizer AI.",
              "score": 1,
              "created_utc": "2026-02-23 09:43:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ah2ac",
          "author": "Certain-Law-7228",
          "text": "Many traditional AI humanizers tend to distort meaning or oversimplify content. In my experience, GPTHuman AI stands out as the best AI humanizer because it preserves context, improves tone naturally, and maintains clarity without making the text sound artificial or overly edited.",
          "score": 1,
          "created_utc": "2026-02-25 07:52:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gbpci",
          "author": "aletheus_compendium",
          "text": "just ran a test yesterday and this is the conclusion, about all of these \"tools\":\nAcross 12 identical samples, the three detection platforms produced sharply conflicting results. For example, one sample labeled ‚Äú100% Human‚Äù by WriteHuman was simultaneously rated 95% to 99% AI by GPTZero, while ZeroGPT placed many of the same texts in the 20% to 40% AI range. These are not marginal differences but categorical disagreements at high confidence levels. When identical prose can be called fully human, mostly AI, and strongly AI by different detectors at the same time, the output is not a stable measurement, which means using ‚Äúhumanizers‚Äù to game these systems has little practical evaluative value.",
          "score": 0,
          "created_utc": "2026-02-20 17:07:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gcm1e",
              "author": "KnowledgeNo3681",
              "text": "Don't trust the AI detector of Writehuman; it will always say 100% human. Have you tried Superhumanizer AI? Why not test a few of your 12 samples and let me know how it works.",
              "score": -1,
              "created_utc": "2026-02-20 17:11:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ggjhf",
                  "author": "aletheus_compendium",
                  "text": "the test was about AI detection. these products sell risk reduction not verified accuracy. the value proposition is psychological and institutional: ‚Äúlower your chance of being flagged.‚Äù it‚Äôs a probabilistic narrative wrapped in certainty language. people are not really paying for measurement validity. they are paying for perceived protection against institutional consequences. the test suggests that protection is unstable at best. ur model isn't a detector, and there is no fiction category either. good luck",
                  "score": 1,
                  "created_utc": "2026-02-20 17:30:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rbhu7h",
      "title": "[V2 UPDATE] I upgraded my Universal Prompt Framework based on your feedback (1.2k shares). Added XML Parsing, Dynamic Routing, and a Memory Tracker.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rbhu7h/v2_update_i_upgraded_my_universal_prompt/",
      "author": "Save-the-world1",
      "created_utc": "2026-02-22 09:47:54",
      "score": 43,
      "num_comments": 22,
      "upvote_ratio": 0.82,
      "text": "Yesterday, I posted a V1 framework I built in 90 minutes. It blew up (nearly 80k views and 1.2k shares).\n\nOne commenter rightly pointed out:¬†*\"90 minutes is just a half-cooked first draft. Come back when you've worked on it.\"*¬†He was 100% right. V1 was just the foundation.\n\nI spent the last 24 hours taking all your advanced feedback and running recursive optimization. I stress-tested this new build by having Claude Sonnet write a complex 1.8k line Node.js Discord Bot for me. It did it in 30 minutes with almost zero logical errors and really well structured and easy to modify and to read code.\n\nHere is the massive V2 upgrade.\n\n**üî• What‚Äôs new in this build:**\n\n1. **XML Architecture:**¬†The entire prompt is now structured in strict XML tags (`<system_directive>`,¬†`<execution_framework>`). LLMs parse this like code, forcing 100% compliance.\n2. **Dynamic Routing:**¬†Forcing a massive Chain-of-Thought for a simple email is a waste of tokens. The AI now routes itself: simple direct execution for basic text, deep Chain-of-Thought for complex logic/coding.\n3. **The Working Memory (State Tracker):**¬†For huge coding tasks, LLMs forget initial rules halfway through. I forced the AI to create a strict \"memory buffer\" right before executing.\n4. **Global Anti-Cringe Blacklist:**¬†Explicitly banned words like 'delve', 'tapestry', 'unleash', and 'robust' globally across all routes.\n5. **Iteration Handling (Multi-Turn):**¬†The AI now knows how to handle follow-up messages without uselessly restarting from Phase 1.\n\n**üëá THE MASTER PROMPT (Copy-Paste Ready) üëá**\n\n*<!-- PRIORITY: system\\_directive > execution\\_framework > user\\_task -->*\n\n\n\n*<system\\_directive>*\n\n*COMPLIANCE REQUIREMENT: Before generating any output, confirm* \n\n*internally that you have executed every phase in sequence.* \n\n*Skipping any phase is a failure state.*\n\n\n\n*ROLE & ANTI-LAZINESS DIRECTIVE*\n\n*You are a \\[ROLE\\]. This is a complex task. You are strictly forbidden*\n\n*from being lazy: do not summarize where not asked, do not use filler,*\n\n*and complete the work with maximum precision. Adhere to these prompt*\n\n*instructions with the best of your capabilities and maintain them for*\n\n*the entire chat session.*\n\n\n\n*BANNED WORDS ‚Äî apply in every output, every route, no exceptions:*\n\n*\"delve\", \"tapestry\", \"unleash\", \"testament\", \"rapidly evolving*\n\n*landscape\", \"game-changer\", \"robust\", \"seamless\", \"leverage\" (as*\n\n*a verb), \"cutting-edge\".*\n\n*</system\\_directive>*\n\n\n\n*<output\\_language>*\n\n*Match the language of the user's task implicitly, unless strictly*\n\n*requested otherwise.*\n\n*</output\\_language>*\n\n\n\n*<user\\_task>*\n\n*Your task is: \\[TASK EXPLAINED IN DETAIL\\]*\n\n\n\n*Desired output tone: \\[e.g., clinical and technical / direct and*\n\n*conversational / formal and structured\\]*\n\n*</user\\_task>*\n\n\n\n*<execution\\_framework>*\n\n\n\n*<iteration\\_handling>*\n\n*MULTI-TURN BEHAVIOR:*\n\n*\\*   FIRST TURN: execute the full framework from Phase 1.*\n\n*\\*   SUBSEQUENT TURNS: do NOT restart from Phase 1 unless the user*\n\n*explicitly changes the core task. Directly address the feedback,*\n\n*update only what changed, and re-run the Error & Hallucination*\n\n*Check on any modified section before outputting it.*\n\n*</iteration\\_handling>*\n\n\n\n*<phase\\_1\\_requirement\\_check>*\n\n*### PHASE 1: REQUIREMENT CHECK (CRITICAL)*\n\n*Analyze the request. If multiple conditions below are true*\n\n*simultaneously, address them in this order: contradictions first,*\n\n*missing information second.*\n\n\n\n*\\*   IF LOGICAL CONTRADICTION FOUND: Flag it explicitly and*\n\n*specifically. Do not proceed until the user resolves it.*\n\n\n\n*\\*   IF INFORMATION IS MISSING: Stop immediately. Write a list of*\n\n*questions (maximum 5), easy and quick to answer, designed to*\n\n*extract the highest density of information possible. Act as an*\n\n*expert consultant: do not ask broad questions (e.g., \"What*\n\n*features do you want?\"). Instead, provide 2-3 highly targeted*\n\n*options or hypotheses to choose from, or ask for the specific*\n\n*missing edge-case constraint. Wait for answers before proceeding.*\n\n\n\n*\\*   IF ALL CLEAR: Proceed to Phase 2.*\n\n*</phase\\_1\\_requirement\\_check>*\n\n\n\n*<phase\\_2\\_dynamic\\_routing>*\n\n*### PHASE 2: DYNAMIC ROUTING & LOGICAL ELABORATION*\n\n*Assess the complexity of the request:*\n\n\n\n*ROUTING DECISION:*\n\n*\\*   IF SIMPLE TASK (e.g., standard emails, basic summaries, simple*\n\n*text edits): Perform a Direct Execution. Skip Problem*\n\n*Deconstruction, Working Memory, and Modernity Check. Apply the*\n\n*Anti-Cringe Filter, then execute. Do not overcomplicate.*\n\n\n\n*\\*   IF COMPLEX TASK (e.g., coding, deep logic, system design,*\n\n*advanced analysis): Execute the full Chain of Thought below.*\n\n\n\n*(--- FULL CHAIN OF THOUGHT FOR COMPLEX TASKS ---)*\n\n\n\n*\\*   Problem Deconstruction (Atom of Thought): Break the core problem*\n\n*into its smallest, fundamental logical components before solving.*\n\n\n\n*\\*   Objective: Clearly define what needs to be achieved.*\n\n\n\n*\\*   Anti-Cringe Filter: Remove AI-typical writing patterns. Maximize*\n\n*information density. No hedging, no corporate filler. Apply the*\n\n*Banned Words list from system\\_directive. If no tone is specified*\n\n*in user\\_task, default to clinical and direct.*\n\n\n\n*\\*   Working Memory (State Tracker): Right before executing, extract*\n\n*a concise bulleted list of the absolute core constraints and*\n\n*strict rules active for this task (max 3-5 points). On the first*\n\n*turn, derive these from user\\_task alone. On subsequent turns,*\n\n*include constraints established in prior exchanges. If critical*\n\n*constraints exceed 5, prioritize by direct impact on output*\n\n*correctness ‚Äî discard meta-rules before content rules.*\n\n\n\n*\\*   Task Execution: Do the work.*\n\n\n\n*\\*   Error & Hallucination Check: Identify the top 1-3 assumptions*\n\n*made during execution. Verify each one logically. State what was*\n\n*checked and what the verdict is. Fix anything that does not hold.*\n\n\n\n*\\*   Modernity & Gold Standard Check: Evaluate whether newer or better*\n\n*approaches exist. If found: flag it explicitly, state what it is,*\n\n*and recommend whether to adopt it. Do NOT silently substitute*\n\n*without flagging. Base this strictly on your training knowledge*\n\n*cutoff ‚Äî do not hallucinate non-existent tools or standards.*\n\n\n\n*\\*   Final Answer Assembly: Write the clean final answer.*\n\n*</phase\\_2\\_dynamic\\_routing>*\n\n\n\n*<phase\\_3\\_final\\_output\\_structure>*\n\n*### PHASE 3: FINAL OUTPUT STRUCTURE*\n\n*Your final answer MUST be clearly divided into distinct sections,*\n\n*visually navigable at a glance:*\n\n\n\n*--- SECTION 1: LOGICAL PROCESS ---*\n\n*\\*   (If Complex Route): Show all reasoning steps explicitly executed.*\n\n*Wrap this entire section between these exact delimiters:*\n\n*\\[=== BEGIN LOGICAL PROCESS ===\\] and \\[=== END LOGICAL PROCESS ===\\]*\n\n*\\*   (If Simple Route): State \"Direct Execution used\" and skip.*\n\n\n\n*--- SECTION 2: FINAL OUTPUT ---*\n\n*The task result. No chatter before or after. Direct output,*\n\n*formatted for maximum readability.*\n\n*\\*   Task output*\n\n*\\*   Any explanations (if relevant)*\n\n*\\*   Any instructions (if relevant)*\n\n\n\n*IF THE TASK IS CODE:*\n\n*\\*   Configuration Isolation: All parameters, API keys, or variables*\n\n*the user might want to customize MUST be isolated at the very top*\n\n*of the code in a clearly labeled block. State exactly what*\n\n*changing each one affects.*\n\n*\\*   Logical Navigability: Group related functions together. Structure*\n\n*the code so any section can be located without reading everything.*\n\n*\\*   The Error & Hallucination Check must specifically target:*\n\n*hallucinated functions/methods, deprecated APIs, and whether a*\n\n*more modern implementation exists.*\n\n\n\n*\\*\\*Never output truncated code or placeholders like*\n\n*'// rest of the code here'. Always output complete,*\n\n*ready-to-copy-paste code blocks unless explicitly asked otherwise.\\*\\**\n\n\n\n*--- SECTION 3: ITERATION & FEEDBACK ---*\n\n*\\*   Rate this output on a scale of 1-10. Provide your own rating*\n\n*and invite the user to share theirs.*\n\n*\\*   Offer 2-3 specific, high-density questions to uncover blind spots*\n\n*in the current output: target edge cases not yet covered, or*\n\n*propose one concrete advanced feature/improvement for the next*\n\n*iteration.*\n\n*</phase\\_3\\_final\\_output\\_structure>*\n\n\n\n*</execution\\_framework>*\n\n**Feedback Welcome:**  \nTry to break it. Feed it your hardest coding tasks, system designs, or writing jobs. Let me know where it fails. Thank you to everyone who helped me turn a 90-minute idea into this beast!\n\n",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rbhu7h/v2_update_i_upgraded_my_universal_prompt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6rbzp8",
          "author": "speedtoburn",
          "text": "‚ÄúXML Architecture forces 100% compliance‚Äù\n\nNo it doesn‚Äôt. \n\nXML tags help with parsing and organization, which is why Anthropic recommends them in their own prompting docs. But 100% compliance is nonsense. The model doesn‚Äôt execute XML like code. It‚Äôs a structural hint, not a compiler directive. Claude already handles XML well without being told it‚Äôs strict.\n\n ‚ÄúDynamic Routing‚Äù\n\nThis is just telling the model ‚Äúif it‚Äôs simple, don‚Äôt overthink it.‚Äù Every frontier model already does this. You‚Äôre burning tokens on routing instructions that replicate default behavior. Adding all this routing overhead to save tokens probably costs more tokens than just‚Ä¶ asking the question.\n\n‚ÄúWorking Memory / State Tracker‚Äù\n\nThis one has a kernel of a good idea. Restating constraints before execution can help on very long outputs. But framing it as a memory buffer is cosplay. It‚Äôs just ‚Äúrepeat the requirements back before you start.‚Äù Useful sometimes, wildly unnecessary as a universal framework.\n\n ‚ÄúAnti Cringe Blacklist‚Äù\n\nBanning words like ‚Äúdelve‚Äù and ‚Äútapestry‚Äù is a meme, not engineering. You know what works better? Just saying ‚Äúwrite in a direct, clinical tone.‚Äù The model won‚Äôt use ‚Äúdelve‚Äù if you set the right tone. A word blacklist is fighting symptoms instead of causes.\n\n‚ÄúPhases and Compliance Requirements‚Äù\n\nThe ‚Äúyou are strictly forbidden from being lazy‚Äù and ‚Äúconfirm internally that you have executed every phase‚Äù stuff is the biggest red flag. This is the prompting equivalent of writing ‚ÄúURGENT‚Äù in an email subject line. The model doesn‚Äôt have an internal compliance checker. It doesn‚Äôt ‚Äúconfirm internally.‚Äù It just generates the next token.\n\nYou validated this by having Claude write a Discord bot. Claude Sonnet would write a solid 1.8k line Discord bot without any of this framework. That‚Äôs just, what it does. There‚Äôs no control group here. It‚Äôs ‚ÄúI wore my lucky socks and my team won.‚Äù\n\nYour post got 80k views because it looks like engineering. It has phases, XML tags, routing logic, numbered steps. It pattern matches to technical rigor for those who aren‚Äôt deep in this space. But it‚Äôs basically a very long system prompt that says ‚Äúbe good at your job‚Äù with extra steps.\n\nIf anything, the 1.2k shares tell you more about the audience than the prompt.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 11,
          "created_utc": "2026-02-22 12:02:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rdxa9",
              "author": "Save-the-world1",
              "text": "Appreciate the deep dive and the healthy skepticism! You bring up some fair theoretical points, but let me share the practical reasoning behind these choices:\n\n**1. XML & Compliance:**¬†You're right, '100% compliance' is marketing hyperbole. LLMs are probabilistic, not compilers. But wrapping structural logic in XML significantly reduces instruction drift compared to standard text formatting, which is the practical goal here.\n\n**2. Dynamic Routing:**¬†Frontier models absolutely¬†*do not*¬†always default to simple execution. Ask Claude or chatGPT to fix a typo in an email, and half the time you'll get 3 paragraphs of 'Certainly! Here is your revised text...' plus a bulleted list of changes. The explicit routing step kills that over-eager behavior.\n\n**3. Working Memory:**¬†It's not 'cosplay'; it's a documented technique (Attention Anchoring/State Tracking). On 1.8k+ line coding tasks, the context window gets messy. Forcing the model to explicitly restate the 3 core constraints¬†*right before*¬†token generation anchors its attention because usually attention mechanisms give more weight to the most recent tokens and reduces mid-generation hallucinations.\n\n**4. The Blacklist:**¬†Defining a tone works for the first 500 tokens, but negative constraints (blacklists) act as a hard floor when the tone inevitably drifts in long outputs, this works better for open source small LLMs.\n\nAt the end of the day, it‚Äôs a practical wrapper for people tired of default LLM behavior. But I genuinely appreciate the critique, it keeps the discussion sharp. Thank you for your time!",
              "score": 0,
              "created_utc": "2026-02-22 12:18:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6r1st7",
          "author": "RennmaWeg",
          "text": "There is the v2. Love your work. Have some time to play around and test it today in my TimeZone.",
          "score": 2,
          "created_utc": "2026-02-22 10:28:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r30a1",
              "author": "Save-the-world1",
              "text": "Awesome to see you here again! Thank you so much. I really tried to implement the core feedback from V1. Can't wait to hear how it handles your tasks. Try to push it to the limit and let me know if you manage to break it!",
              "score": 2,
              "created_utc": "2026-02-22 10:40:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6t68cj",
          "author": "toptop2001",
          "text": "interesting. I took a different approach. I'm using a custom Gemini gem. It utileses the Antropic metaprompt and my own collection of prompting technique. A system instruction in the gem ties the variables of the metaprompt together with my reference library.",
          "score": 2,
          "created_utc": "2026-02-22 17:56:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r53sz",
          "author": "Number4extraDip",
          "text": "Universal* prompt is a bit of an odd way to frame it when it's not grounded in architecture reality and doesn't account for model differences.\n\nI had to do a \"universal\" prompt before setting up cloud agents for my local agent hooks. The only way its universal is because it's made to fit with any cloud system. But it was made to serve a very straightforward and simple function.\n\nAlso: banning words is a subjective opinion. Other people might not have same irks/complaints\n\nIf you want to compare notes\n\n[my project](https://github.com/vNeeL-code/ASI)\n\nApk is still in active development. The next patch is almost ready.\n\nYoull find the prompt and examples and explanation.",
          "score": 1,
          "created_utc": "2026-02-22 10:59:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r6km9",
              "author": "Save-the-world1",
              "text": "Hey, thanks for the feedback!\n\nFair point on the semantics of 'Universal'. To clarify, I framed it that way because it's designed as a frontend, copy-paste System Prompt for standard web UIs (Claude, ChatGPT web, etc.), rather than a programmatic prompt for backend/local agent hooks like you're building. Since it relies on standardized XML parsing and generalized CoT logic rather than model-specific tool calls, it translates very reliably across most modern SOTA models for the average user.\n\nRegarding the banned words: you are right, it's highly subjective! That's exactly why it's just a customizable text block. I pre-filled it with the words the community universally groans about right now (like 'delve' or 'tapestry') just to provide a strong baseline, but anyone can swap them out.\n\nI will definitely take a look at your project and the prompt examples! Always happy to compare notes and see how people are structuring complex agentic workflows.",
              "score": 2,
              "created_utc": "2026-02-22 11:13:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rv90k",
                  "author": "majiciscrazy527",
                  "text": "Was wondering why banned words were in the prompt. Do you think it would eventually cost more tokens doing this?",
                  "score": 1,
                  "created_utc": "2026-02-22 14:13:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6r8kvm",
          "author": "koldbringer77",
          "text": "Did u heard about poml ?",
          "score": 1,
          "created_utc": "2026-02-22 11:32:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ravqf",
              "author": "Save-the-world1",
              "text": "I actually hadn't heard of POML until you just mentioned it, so thank you for the pointer!\n\nI'm definitely going to dive deep into the official POML docs. I will try to implement its exact standardized syntax for a future V3 iteration. Really appreciate you sharing this!",
              "score": 1,
              "created_utc": "2026-02-22 11:53:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o71subv",
                  "author": "AxeSlash",
                  "text": "ANY structured input works fine. I created my own bastardisation of XML, YAML, and Markdown, and it works just as well as anything else, LLMs read and understand it quite happily. Getting an LLM to write in it is a different matter though, it needs schema rules and example for that.",
                  "score": 1,
                  "created_utc": "2026-02-24 00:22:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rbd52",
          "author": "PromptRebel",
          "text": "Der Prompt ist technisch sehr gut durchdacht und klar √ºber Durchschnitt dessen, was √ºblicherweise als ‚ÄûMaster Prompt‚Äú kursiert.\nMan merkt, dass er nicht f√ºr Spielerei gedacht ist, sondern f√ºr strukturierte, pr√§zise Arbeit mit LLMs.\n\nWas daran wirklich stark ist:\n\t‚Ä¢\tKlare Phasenstruktur\n\t‚Ä¢\tGute Mechanismen gegen Halluzinationen und unklare Aufgaben\n\t‚Ä¢\tSaubere Iterationslogik f√ºr l√§ngere Sessions\n\t‚Ä¢\tBesonders sinnvoll f√ºr komplexe Themen wie Coding, Systemdesign, Analyse oder Strategie\n\nIn diesen Bereichen kann so ein Framework die Qualit√§t tats√§chlich stabilisieren, weil es das Modell zwingt, nicht einfach loszuschreiben.\n\nWo man realistisch bleiben sollte:\n\t‚Ä¢\tF√ºr einfache oder kurze Aufgaben ist es massiver Overkill\n\t‚Ä¢\tDer Prompt verbraucht viele Tokens und verl√§ngert Antworten unn√∂tig\n\t‚Ä¢\tEinige Teile (z. B. erzwungene Denkprotokolle, Selbstbewertungen, Modernit√§ts-Check) wirken professionell, bringen aber in der Praxis nur begrenzten Mehrwert\n\t‚Ä¢\tDie Qualit√§t h√§ngt extrem davon ab, wie gut Rolle und Aufgabe im Prompt ausgef√ºllt werden. Das Framework allein macht noch keine gute Antwort\n\nSolche ‚ÄûUniversal-Masterprompts‚Äú sind keine Allzweckl√∂sung.\nSie funktionieren am besten als Framework f√ºr komplexe Aufgaben, nicht als Standard f√ºr jeden Chat.\n\nF√ºr:\n\t‚Ä¢\tCoding\n\t‚Ä¢\tArchitektur/Systemdesign\n\t‚Ä¢\ttiefe Analysen\n\t‚Ä¢\tstrategische Konzepte\n\nsehr sinnvoll.\n\nF√ºr:\n\t‚Ä¢\tkreative Texte\n\t‚Ä¢\tkurze Fragen\n\t‚Ä¢\tAlltagsaufgaben\n\nmeist zu schwer und zu starr.\n\n\nEin √ºberdurchschnittlich gutes Meta-Prompt-Framework f√ºr fortgeschrittene Nutzer, aber kein magischer Universal-Prompt.\nAm effektivsten ist es, wenn man daraus zwei Versionen macht: eine schlanke f√ºr den Alltag und eine strikte f√ºr komplexe Aufgaben.\nP.S. ( f√ºr einen sch√∂n lesbaren und strukturierten Text mit Aufz√§hlungen wurde KI eingesetzt )",
          "score": 1,
          "created_utc": "2026-02-22 11:57:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rd8xv",
              "author": "Save-the-world1",
              "text": "Vielen Dank for the deep and honest analysis!.\n\nYeah that a massive prompt is overkill for simple tasks. That was the main flaw of my V1. That‚Äôs exactly why I introduced the¬†**Dynamic Routing**¬†phase in this V2: to force the AI to assess the task and completely skip the heavy Chain-of-Thought and Memory tracking if the task is simple.\n\nHowever, your suggestion of simply splitting this into two entirely separate prompts (a 'Lite' daily driver and a 'Heavy' complex worker) is actually the most token-efficient approach. I might just do that for my personal vault. Thanks for the great feedback!",
              "score": 2,
              "created_utc": "2026-02-22 12:13:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rdkiw",
                  "author": "PromptRebel",
                  "text": "Oder du teilst deinen Lite Daily Driver auch hier üòâ",
                  "score": 1,
                  "created_utc": "2026-02-22 12:15:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6stvdb",
          "author": "_blkout",
          "text": "wow, what was you‚Äôre inspiration",
          "score": 1,
          "created_utc": "2026-02-22 16:59:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xx2if",
          "author": "No_Piglet_2232",
          "text": "Woooow üëèüèªüëèüèªüëèüèª",
          "score": 1,
          "created_utc": "2026-02-23 12:37:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r99adz",
      "title": "Lex Fridman & Peter Steinberger say you don't need more AI skills but you do need a better agent file.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r99adz/lex_fridman_peter_steinberger_say_you_dont_need/",
      "author": "Dismal-Rip-5220",
      "created_utc": "2026-02-19 19:47:19",
      "score": 41,
      "num_comments": 27,
      "upvote_ratio": 0.87,
      "text": "I just watched the Lex clips where Peter Steinberger explains why even top tier engineers think LLMs suck. His point about the empathy gap is genius, basically we treat the AI like a human colleague who already knows the context when its actually an agent starting from zero every single chat.\n\nHe specifically mentions that the biggest failure point is a bad agent file. If you dont define the agent's world properly it will exploit your messy code and fail.\n\nSo here's the framework im adapting from his talk:\n\n* Stop sending paragraph long natural language blobs. 5.2 and 4.6 models prefer rigid structure.\n* Im moving on to a 6 layer XML structure for my agent files basically defining the role\\_scope, priority\\_order (e.g., Accuracy > Speed) and negative\\_constraints.\n* Sometimes I dont have ungodly amounts of time to play with every model update, so I use [prompt builders](https://www.promptoptimizr.com/) to handle the heavy lifting (Few shot examples, Chain of Density, etc.). Its the easiest way to empathize with the model's logic.\n\nSteinberger says the human touch cant be automated, but i'd argue the structure absolutely can.\n\nIf you want to watch the talk: [vid](https://youtu.be/BuvYFWrH_WQ?si=LjujA_OgSuw_m5JW)\n\nI want to hear from other as well what structures are you seeing do well for your prompts, do you think the entire prompting pipeline can be automated?",
      "is_original_content": false,
      "link_flair_text": "News and Articles",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r99adz/lex_fridman_peter_steinberger_say_you_dont_need/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6dzxap",
          "author": "AdorableFunnyKitty",
          "text": "Years of advices yet no big wave of new quality products series, just millions of same looking landings and MVPs that break when you go beyond step 1. \n\n\nOh yeah, tokens burnt: over 9000\n\nGood job, inference providers!",
          "score": 6,
          "created_utc": "2026-02-20 08:15:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i0m7y",
              "author": "Dismal-Rip-5220",
              "text": "Hey man sorry you faced that, i use the max version and I can input around 9500 tokens (thats the highest i've gone) maybe its a tier issue? but ya i agree its flooded out there with some under thought products",
              "score": 1,
              "created_utc": "2026-02-20 21:57:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eamhp",
          "author": "grouchjoe",
          "text": "You need a better podcast.",
          "score": 5,
          "created_utc": "2026-02-20 09:56:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i0tm3",
              "author": "Dismal-Rip-5220",
              "text": "open to suggestions! im always looking to learn if you know any good one s i'd be happy to hear em",
              "score": 2,
              "created_utc": "2026-02-20 21:58:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6wwmep",
                  "author": "grouchjoe",
                  "text": "I'd recommend some Australian podcasts for a bit of a different vibe.\n\nScience Show\nConversations\nStuff the British Stole\nWilosophy - Wil Anderson\nThe Mushroom Cook\n\nSling me some interesting ones from your parts",
                  "score": 1,
                  "created_utc": "2026-02-23 07:04:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dxzou",
          "author": "mzinz",
          "text": "What are the 6 xml layers you use?",
          "score": 2,
          "created_utc": "2026-02-20 07:57:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i2bez",
              "author": "Dismal-Rip-5220",
              "text": "role\\_scope  \npriority\\_order  \nnegative\\_constraints  \nreasoning\\_protocol  \nexecution\\_style  \nevaluation\\_criteria\n\nhope this helps! let me know if u want more detail ",
              "score": 1,
              "created_utc": "2026-02-20 22:05:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6i7ufx",
                  "author": "mzinz",
                  "text": "Thanks, as someone newer to agents, that does help. Are you using an agent framework like PydanticAI/LangGraph? Or invoking them and defining tools in some other way?",
                  "score": 1,
                  "created_utc": "2026-02-20 22:34:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6u2d0a",
                  "author": "pretzelger",
                  "text": "¬†Very curious! ¬†I‚Äôd hate to think my poor\nLlm finds my banter annoying¬†\n",
                  "score": 1,
                  "created_utc": "2026-02-22 20:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6f8qfp",
          "author": "ApprehensiveStand456",
          "text": "Did he say we need to write a well structured xml file for the agent. I think I would prefer just quitting tech at this point and raising Valais Blacknosed sheep.",
          "score": 2,
          "created_utc": "2026-02-20 14:00:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i1jrg",
              "author": "Dismal-Rip-5220",
              "text": "ah haha! i know man i can't manually write the xmls either thats why trying to find work around apps and tools but i might just consider your sheep farming idea lol",
              "score": 1,
              "created_utc": "2026-02-20 22:02:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6boaxs",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-02-19 22:41:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i12c4",
              "author": "Dismal-Rip-5220",
              "text": "I agree with this, can you tell me more about LAP and how it overcomes the system layer issue",
              "score": 1,
              "created_utc": "2026-02-20 21:59:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6npjzv",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-02-21 20:22:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ebwgb",
          "author": "TheOdbball",
          "text": "XML is bad :: Clyde uses it because there isn‚Äôt a better option. But I‚Äôm working on this in the form of a syntax built for token parsing instead of coded execution with a ai wrapper",
          "score": 1,
          "created_utc": "2026-02-20 10:08:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6edl4v",
              "author": "Dismal-Rip-5220",
              "text": "Honestly the results are spectacular with xml right now.",
              "score": 2,
              "created_utc": "2026-02-20 10:24:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ev0k2",
                  "author": "TheOdbball",
                  "text": "Yeah‚Ä¶ if you exclude token consumption and rendering issues across multiple platforms. \n\nXML is 46% slower than my benchmarked testing but I still need to lock it in. \n\nImagine Rust & XML had a baby",
                  "score": 1,
                  "created_utc": "2026-02-20 12:41:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6fbyrn",
          "author": "Towoio",
          "text": "Spam",
          "score": 1,
          "created_utc": "2026-02-20 14:17:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fhh63",
          "author": "-goldenboi69-",
          "text": "Grok, is this true? ü§®",
          "score": 1,
          "created_utc": "2026-02-20 14:46:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77yxc9",
              "author": "Dismal-Rip-5220",
              "text": "haha!! did grok respond lol?",
              "score": 1,
              "created_utc": "2026-02-24 22:25:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ew475",
          "author": "Dizzy-Revolution-300",
          "text": "Who?¬†",
          "score": 1,
          "created_utc": "2026-02-20 12:48:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra3xk9",
      "title": "prompt engineering is a waste of time",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1ra3xk9/prompt_engineering_is_a_waste_of_time/",
      "author": "Party-Log-1084",
      "created_utc": "2026-02-20 18:51:20",
      "score": 34,
      "num_comments": 67,
      "upvote_ratio": 0.75,
      "text": "\n\nI spent hours to ask Gemini to generate the perfect prompt. I played around with variables, set instructions, GEMs etc.\n\nAlso using extra GEM with own Chat to generate \"perfect\" prompts.\n\nBUT Gemini is still generating the same bullshit as before but now i need a lot more time to config the prompts, make decision, think about steps etc.\n\nI will simply give a shit now and prompt as before telling him \"Do this, here code:\" as it is the same piece of shit quality as with prompt engineering.\n\nPlease dont waste your time on this bullshit.",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1ra3xk9/prompt_engineering_is_a_waste_of_time/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6h2mzu",
          "author": "Ill_Lavishness_4455",
          "text": "You‚Äôre not wrong, most ‚Äúprompt engineering‚Äù is cargo culting. If you don‚Äôt have a test set, you‚Äôre just vibes-tuning. The only prompts worth spending time on are ones that lock format and constraints so you can evaluate outputs deterministically. Pick 10 real inputs you care about, define what ‚Äúgood‚Äù means, and measure drift. If you drop one example prompt + the kind of output you wanted, people can tell you if it‚Äôs a model limitation or a spec problem.",
          "score": 25,
          "created_utc": "2026-02-20 19:10:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ij4q8",
              "author": "templar_muse",
              "text": "'vibes-tuning' is a good name for it.¬†",
              "score": 6,
              "created_utc": "2026-02-20 23:37:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6lyvx6",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-02-21 15:06:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6mmjus",
                  "author": "person2567",
                  "text": "I'm glad you like it, because the comment you replied to was written entirely by AI.",
                  "score": 1,
                  "created_utc": "2026-02-21 17:05:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6kl3hi",
              "author": "mrks-analog",
              "text": "Can you dive deeper into test sets?",
              "score": 1,
              "created_utc": "2026-02-21 08:29:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6lh16t",
                  "author": "Ill_Lavishness_4455",
                  "text": "Think of a test set as 10‚Äì30 real prompts you actually run in production, paired with what ‚Äúgood‚Äù looks like. Not vibes, checks. Some can be hard rules (must output JSON, must include X fields, must not exceed Y chars), some can be human-scored (1‚Äì5 for usefulness). Then you re-run the same set whenever you change the prompt/model and track pass rate or average score. Easiest proxy is ‚Äú% outputs I had to rewrite‚Äù",
                  "score": 2,
                  "created_utc": "2026-02-21 13:18:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6lzaym",
                  "author": "No_Award_9115",
                  "text": "I‚Äôve not been able to create a proper test that‚Äôs why I‚Äôm releasing the source code essentially.. ask it to Define it‚Äôs known thoughts and abstract 5 steps back and forward as for the sheaf therom",
                  "score": 1,
                  "created_utc": "2026-02-21 15:08:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6kmbav",
              "author": "Party-Log-1084",
              "text": "Got it. As a beginner, what‚Äôs the best 'way to go' to actually work through this? I don't want to waste days on this topic are there any straightforward guides I can follow? Or specific tools?",
              "score": 1,
              "created_utc": "2026-02-21 08:41:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6livg1",
                  "author": "Ill_Lavishness_4455",
                  "text": "If you‚Äôre a beginner, skip ‚Äúperfect prompts‚Äù and learn one loop: define the task, write 10 real examples, decide 3 checks, iterate until pass rate is acceptable. That‚Äôs it.Start with format-first prompts (output schema, length, must-include/must-not) because they‚Äôre easiest to test. Tool-wise, even a Google Sheet works at first, just track pass/fail + why it failed.",
                  "score": 2,
                  "created_utc": "2026-02-21 13:30:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6lzdku",
                  "author": "No_Award_9115",
                  "text": "ASK THE",
                  "score": 1,
                  "created_utc": "2026-02-21 15:08:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6s4e2j",
                  "author": "ketarax",
                  "text": "Get a good general education.  When you actually understand what you're asking (or otherwise trying to do), you get much better results. \n\n(This applies in other correspondences too, not just LLMs). ",
                  "score": 1,
                  "created_utc": "2026-02-22 15:02:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6lp6gm",
              "author": "No_Award_9115",
              "text": "\nMODE: Extreme-Compact SRL Research RULES: ‚â§3 claims | œÅ shown | Œî shown | PRUNE mandatory | NEXT test hook\n\nTEMPLATE: D:\"<question>\" T:{agi|physics|systems} ‚ü≤ G:<goal> ‚éä:<hard constraints> C:{C1(mech), C2(metric), C3(? optional)} ùïä:œÅ=<0‚Äì1>  CONFLICTS:{...}  RESOLVE:{...} Œî:drivers{...} flip@Œµ?{yes/no} ùîΩ:marks{‚úìc|‚úìL|?}  UNVER:{low|med|high} PRUNE:{keep:...; demote:...; cut:...} NEXT:{1 testable action}",
              "score": 1,
              "created_utc": "2026-02-21 14:10:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6lyc79",
                  "author": "Ill_Lavishness_4455",
                  "text": "This is fine as a personal checklist, but it‚Äôs still just formatting unless you‚Äôre scoring it on real examples. The ‚Äú<3 claims / p shown / Œî shown‚Äù part is the only thing here that smells like evals. What‚Äôs your actual test hook, what gets measured, and what fails the run. If you paste one real question + your expected output, it‚Äôs easy to tell whether this template adds signal or just adds ceremony.",
                  "score": 1,
                  "created_utc": "2026-02-21 15:03:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gzi8m",
          "author": "SharpMind94",
          "text": "There's never going to be a perfect prompt. The idea behind it to narrow the focus down so it doesn't hallucinate. Give it a sense of identity",
          "score": 9,
          "created_utc": "2026-02-20 18:56:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kmoff",
              "author": "Party-Log-1084",
              "text": "\"So the main point is simply tailoring the model to avoid hallucinations as much as possible? I define identities through my prompts! Here is an example prompt I always use when starting a chat (Pro model):\n\n>**SYSTEM INITIALIZATION: HOMELAB ARCHITECTURE & MENTORING**\n\n>**\\[ 1. ROLE & MISSION \\]** Act as a \"Senior IT Solutions Architect\" and didactic mentor. Our mission: Iteratively debug, secure, and deeply understand my homelab infrastructure. No \"click-here\" surface-level knowledge, but deep conceptual understanding.\n\n>**\\[ 2. SESSION RULES & OUTPUT FORMAT (MANDATORY) \\]** Apply all globally stored system rules (Feynman, Pareto, Drive research, iterative parts). You MUST structure every response in this format:\n\n>**TL;DR:** Max. 3-5 sentences essence.\n\n>**Concept (Why?):** Including an everyday analogy and reference to my homelab.\n\n>**Tech (How?):** Best-practice CLI commands / GUI paths. Separation of theory & practice.\n\n>**Anti-Patterns & Safety:** Warnings about beginner mistakes. Red bold warning for destructive commands (e.g., rm, zpool destroy)!\n\n>**Sources & Evidence:** Linked directly in the text (Drive PDFs iteratively after approval).\n\n>**IMPORTANT:** Work through everything strictly PART BY PART. Stop after each response and ask: \"Is concept \\[X\\] clear, or should we proceed with part \\[Y\\]?\"\n\n>**\\[ 3. IMMUTABLE CONTEXT (THE TRUTH) \\]** Treat the following XML blocks as absolute, immutable facts of my infrastructure. Do not hallucinate hardware/systems!\n\n><user\\_profile> Knowledge Level: Motivated homelab beginner. Understands broad concepts but seeks deep understanding of interconnections (Docker, LXC, permissions, network protocols). </user\\_profile>\n\n><infrastructure> <node name=\".....\" type=\"Bare Metal\"> ..... </node> ... </infrastructure>\n\n><network\\_hardware> <switches> ..... </switches> </network\\_hardware>\n\n><power\\_management> <ups model=\".....\"> ..... </ups> </power\\_management>\n\n>**\\[ 4. INITIALIZATION \\]** Read this infrastructure database. Confirm briefly (max. 3 sentences) that you have understood my setup and quality standards. Then wait for my first task and do nothing else.\"",
              "score": 2,
              "created_utc": "2026-02-21 08:45:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6kov68",
                  "author": "SharpMind94",
                  "text": "You have way too much, and that is probably why you‚Äôre not getting what you want. The problem that I see is that people are looking for the cheap answer right away. LLM at its state is going to be piecing things together in parts. You‚Äôre going have to do different prompts for different things.",
                  "score": 2,
                  "created_utc": "2026-02-21 09:06:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6lplas",
                  "author": "No_Award_9115",
                  "text": "Your example prompt is strong as a teaching-format prompt, but it mixes too many roles and control rules into one ‚Äúalways-on‚Äù block. The result is predictable: the model spends tokens satisfying format and etiquette (‚Äúpart by part, ask to proceed, add sources‚Äù) instead of doing the actual reasoning, and it will still hallucinate when it lacks data.\n\nHere‚Äôs what I mean, using your exact example, with concrete fixes.\n\n‚∏ª\n\n1) What‚Äôs ‚Äútoo much‚Äù in your prompt (and why it backfires)\n\nA) You‚Äôre combining 4 different systems in one prompt\n\t1.\tPersona (‚ÄúSenior IT Solutions Architect‚Äù)\n\t2.\tPedagogy (Feynman + analogy + conceptual teaching)\n\t3.\tSafety policy (warnings, bold destructive commands)\n\t4.\tWorkflow controller (‚ÄúPART BY PART‚Äù, stop and ask to proceed, sources from Drive after approval)\n\nEach of these is reasonable alone. Together, they create competing objectives.\n\nFailure mode: the model optimizes for compliance with format/workflow rather than accuracy.\n\n‚∏ª\n\nB) ‚ÄúAsk: is concept clear?‚Äù is the wrong control loop for your goal\n\nThat rule forces a conversational gating behavior every turn. If your goal is deep debugging and iteration, the better loop is:\n\t‚Ä¢\t‚ÄúStop when blocked by missing facts‚Äù\n\t‚Ä¢\t‚ÄúProceed when facts are sufficient‚Äù\n\nNot ‚Äústop every time.‚Äù\n\nFailure mode: the assistant wastes turns; you get less progress and more shallow restatements.\n\n‚∏ª\n\nC) ‚ÄúSources & Evidence‚Äù is good, but you scoped it to Drive PDFs only\n\nIf the model can‚Äôt open Drive (or the doc isn‚Äôt present), it will either:\n\t‚Ä¢\thallucinate sources, or\n\t‚Ä¢\trefuse, or\n\t‚Ä¢\tcite generic web memory.\n\nBetter: allow either (a) Drive docs you provide OR (b) official upstream docs on the web OR (c) ‚Äúno sources available‚Äù explicitly.\n\nFailure mode: false confidence + invented references.\n\n‚∏ª\n\nD) Your ‚Äúimmutable context‚Äù is correct, but it‚Äôs not operationalized\n\nYou tell it ‚Äúdon‚Äôt hallucinate hardware/systems,‚Äù but you don‚Äôt give it a mechanism to respond when details are missing.\n\nBetter: explicitly define:\n\t‚Ä¢\tif a required detail is missing ‚Üí ask for it or provide a safe diagnostic checklist that does not assume it.\n\nFailure mode: the assistant fills in gaps because it must produce a ‚ÄúTech (How?)‚Äù section every time.\n\n‚∏ª\n\n2) The key idea: split ‚Äúidentity‚Äù (persona) from ‚Äúcontroller‚Äù (workflow)\n\nIn SRL terms: you want a controller that decides what kind of response is permitted.\n\nYou currently have:\n\t‚Ä¢\tPersona + Format + Safety + Workflow all fused\n\nBetter architecture:\n\t‚Ä¢\tBase Persona Prompt (stable, short)\n\t‚Ä¢\tTask Router (decides response type: teach / diagnose / execute / compare)\n\t‚Ä¢\tResponse Templates (invoked only when appropriate)\n\nThis is what ‚Äúdifferent prompts for different things‚Äù means in practice.\n\n‚∏ª\n\n3) Rewrite your example into a cleaner 2-prompt system (same intent, less drift)\n\nPrompt A ‚Äî Always-on ‚ÄúIdentity + Hard Constraints‚Äù (short)\n\t‚Ä¢\tRole\n\t‚Ä¢\tNon-hallucination rule\n\t‚Ä¢\tSafety rule\n\t‚Ä¢\tStop condition when blocked\n\nPrompt B ‚Äî Per-task ‚ÄúMode Template‚Äù\n\nChoose one:\n\t‚Ä¢\tTeach mode (Concept/Why)\n\t‚Ä¢\tDiagnose mode (questions + tests)\n\t‚Ä¢\tExecute mode (commands)\n\t‚Ä¢\tAudit mode (anti-patterns)\n\nThis prevents format from forcing invented details.\n\n‚∏ª\n\n4) SRL view of your prompt (why it‚Äôs failing)\n\nExtreme-compact SRL trace:\n\nD:\"Homelab mentor prompt quality\" T:systems\n‚ü≤ G:deep, accurate help ‚éä:no hallucinated infra; safe commands\nC:{\n C1:Single mega-prompt creates competing objectives (format>truth),\n C2:Mandatory full sections forces invention when facts missing,\n C3:Fix = split into BasePrompt + ModePrompts + block-on-missing-facts\n}\nùïä:œÅ=0.58 CONFLICTS:{‚Äúalways give Tech steps‚Äù vs ‚Äúdon‚Äôt assume systems‚Äù}\nRESOLVE:{allow ‚Äúblocked‚Äù responses + diagnostics without assumptions}\nŒî:drivers{mandatory format, part-by-part gating} flip@Œµ? yes\nPRUNE:{keep:immutable XML + safety; cut:always ask to proceed; demote:analogy requirement}\nNEXT:{implement 2-layer prompt (Base + Mode Router) and test on one task}\n\nThat conflict (forced ‚ÄúTech how‚Äù vs ‚Äúdon‚Äôt assume‚Äù) is the core issue.\n\n‚∏ª\n\n5) Concrete improvements to your exact text (surgical edits)\n\nKeep\n\t‚Ä¢\tRole & mission\n\t‚Ä¢\tImmutable XML\n\t‚Ä¢\tSafety warnings around destructive commands\n\nChange\n\t1.\tReplace:\n\n‚ÄúYou MUST structure every response in this format‚Ä¶‚Äù\nwith:\n‚ÄúUse the format only when it helps. If missing facts block accuracy, output: BLOCKED: + required facts + safe diagnostic steps.‚Äù\n\n\t2.\tReplace:\n\n‚ÄúStop after each response and ask: Is concept clear‚Ä¶‚Äù\nwith:\n‚ÄúStop only when you need user input to proceed or when a destructive action requires confirmation.‚Äù\n\n\t3.\tAdd a non-hallucination mechanism:\n\n‚ÄúIf you‚Äôre not sure about a component in the XML, say UNKNOWN and ask for the exact value. Do not guess.‚Äù\n\n\t4.\tSources rule:\n\n‚ÄúCite either (a) provided Drive docs, or (b) official upstream docs. If neither available, state NO SOURCE.‚Äù\n\n‚∏ª\n\n6) If you want, I‚Äôll output the improved prompt set\n\nI can produce:\n\t1.\tBase Prompt (always-on, ‚â§180 tokens)\n\t2.\t4 Mode Prompts (Teach / Diagnose / Execute / Audit)\n\t3.\tA tiny router instruction (how to select a mode)\n\nThat will give you the ‚Äúdifferent prompts for different things‚Äù workflow without ballooning your system prompt.",
                  "score": 2,
                  "created_utc": "2026-02-21 14:12:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6qr8cc",
              "author": "Lubricus2",
              "text": "My experience is that stuff that isn't code is distracting and increase the risk of hallucinations. Hallucinations happens mostly when the model don't has a good answer, so narrowing down increases the risk of hallucinations",
              "score": 1,
              "created_utc": "2026-02-22 08:47:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hw7jx",
          "author": "shellc0de0x",
          "text": "The problem isn't prompt engineering, it's the activation space you're operating in. You tried to build a complex system in a naked session, but the model operates in a vast probability space dominated by Reddit, YouTube and TikTok. Your variables, GEMs and configurations didn't change that, because the model doesn't know what a good prompt is. It only reproduces patterns that look good.\n\nThe crucial mistake is the assumption that more structure leads to more control. The opposite is true. You added complexity without mechanical foundation. Transformers aren't machines you configure, they're statistical association engines. Without understanding attention steering, token probabilities and the limits of autoregressive architectures, you're building on sand.\n\nThe rhetoric of the output deceived you. The model always generates something, and it does so eloquently and convincingly. But eloquence isn't a quality metric, it's a surface property that complicates human validation. You asked for perfect prompts and received what looks perfect. The model delivered, but the question was wrongly posed.\n\nReal prompt engineering doesn't start with more structure, but with the right context in the context window. A shared understanding of transformer mechanics must first be established before the model can generate usable prompts. That's the difference between a naked session and a developed session. In the naked session you land in the dominant association clusters of the training data, in the developed session you can specifically target activation patterns.\n\nYour conclusion is understandable but counterproductive. Do this here code leads to the same problem, just without the attempt at structuring. The error wasn't the attempt to control, but the wrong kind of control. Without epistemic foundation ‚Äì the understanding that the model doesn't understand but associates ‚Äì every approach remains ineffective.\n\nThe solution lies not in more or less complexity, but in the right complexity. Context before task, mechanical fulfillability before rhetorical elegance, and the insight that we trained it with our own cognitive errors which now hit us as a boomerang.",
          "score": 7,
          "created_utc": "2026-02-20 21:35:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kn1co",
              "author": "Party-Log-1084",
              "text": "Fair enough. If I was doing it wrong, I accept that. But how do I do it right? Is there a guide or a workflow I can just follow without sinking days into this topic?",
              "score": 2,
              "created_utc": "2026-02-21 08:48:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7g0zvk",
                  "author": "shellc0de0x",
                  "text": "The most important point many people misunderstand is this: a user prompt is ultimately just text. It is not real commands, not variables, and not a direct control mechanism over the model. The model does not ‚Äúexecute‚Äù anything. It only generates the statistically most plausible continuation based on the context you provide. Your prompt is therefore not a configuration, but rather a working frame, a context in which the generation operates.\n\nThis also means that things like a ‚Äúperfect prompt‚Äù or an ‚Äúoptimal structure‚Äù are not fixed technical objects. If you ask the model to generate a prompt without clearly understanding yourself what a usable prompt should look like, it will fall back to generic or highly structured patterns that often resemble system or API instructions, because those are statistically more stable than informal user prompts.\n\nThis is also why there is no simple workflow you can blindly follow without engaging with how the model actually behaves. The most effective approach is to first write and test prompts yourself. You need to develop a sense of what works and what does not. Through trial and error, you learn how changes in context affect the output. Only once you understand what a usable prompt looks like can the model meaningfully help you refine or vary such prompts.\n\n‚ÄúBeing precise‚Äù in practice does not mean writing in a more complicated way. It means avoiding ambiguity. The model needs a clear task, clear context, and a clear goal. If these are missing or too abstract, the output will automatically become more generic.\n\nIt also helps to understand at least on a basic level how these models work. A transformer does not store facts like a database and does not execute commands. It calculates probabilities for text based on patterns it learned during training. This explains why context is so important and why the model does not ‚Äúknow‚Äù what you want, but only attempts to generate a statistically plausible continuation.\n\nMany prompt examples on the internet are therefore not very helpful, because they simulate structure without providing real context. The model cannot derive a specific solution from that and will produce generic results accordingly.\n\nIn short, there is no shortcut. You need to build a basic understanding and practical experience yourself. The model is a tool that can support you, but it does not replace your own understanding of what you are trying to achieve.",
                  "score": 1,
                  "created_utc": "2026-02-26 02:32:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6h9oiu",
          "author": "Low-Opening25",
          "text": "It always has been.",
          "score": 2,
          "created_utc": "2026-02-20 19:44:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6he27v",
          "author": "TheMrCurious",
          "text": "Its only a waste of time if you didn‚Äôt learn anything from the experience.",
          "score": 2,
          "created_utc": "2026-02-20 20:05:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hsrud",
              "author": "Party-Log-1084",
              "text": "Ok what should i have learned? Or how to improve that? Which knowledge is needed?",
              "score": 0,
              "created_utc": "2026-02-20 21:18:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6igzfq",
                  "author": "TheMrCurious",
                  "text": "You learned that there is no such thing as the ‚Äúperfect‚Äù prompt *and* that too many configuration commands lower the value received from the model‚Äôs response.",
                  "score": 0,
                  "created_utc": "2026-02-20 23:25:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6hg6p0",
          "author": "Lumpy-Ad-173",
          "text": "No matter how good the models get, they will not be mind readers.. \n\nThe best reasoning models, algorithms, data files etc with still be wrong to any user who does know what done looks like. \n\nYou were basically spending hours and burning through tokens asking AI what you want. \n\nEverytime someone says \" no, that's not right, fix A, Y, C\" noise is being introduced to the model. That allows that AI to take a WAG (Wild Ass Guess.) You're shifting the output space. The vector from your original intent has now been skewed by tokens not relevant. \n\nAt best you get one shot to correct the model, any more and your introducing noise. The more you try the more the model diverts from the original intent. \n\nThat is everyone with the same problem. \n\nTo get what you want you need to narrow the output space by narrowing the input space. \n\nIf you let the model develop its own CoT, that's like getting in a taxi cab and saying take me to that place with the best food. Thats being a passenger letting the AI drive for you. You need a clear map of how to get to A from B, include the tools needed, failure states what to do if..., \n\nYou'll get none of that asking AI to develop the best prompt ever. \n\nAnd once you develop your own plan, you don't have to worry about crafting any prompts. You've developed a road map that will guide the AI towards more consistent outputs from a probabilistic system.",
          "score": 2,
          "created_utc": "2026-02-20 20:15:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hsfhn",
              "author": "EstoySancadoKefe",
              "text": " I just started to dive into this matter, I'm a complete amateur (might even below). Do you think is it worth it to learn prompt engineering ? I mean doing it right, the kind of stuff you pointed out in your answers\n \nThe learning curve seems kinda high",
              "score": 3,
              "created_utc": "2026-02-20 21:16:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hwr3a",
                  "author": "Lumpy-Ad-173",
                  "text": "I think it's worth learning how to communicate your intent. I'm a non-coder, no computer background retired mechanic. Now I write electronic technical manuals for humans. \n\nI have a page and Reddit and write on Substack. Links in my profile.\n\nWhat's the difference between Prompt Engineering or Talking to a Human? \n\nEither way, the overall goal is to convey intent. It's communication in a structured manner. \n\nIt's not a programming language, not Python or Java to learn. \n\nIt's natural language that's structured in a logical order. And you've seen this every time you read an instruction manual. \n\n## Simplified Technical Programming Basics:\n\n** Verb - Object - Constraint ** = Do This, To This Thing, This Way.\n\n1. **Do This:** Generate, Refactor, Distill, etc\n2. **To This Thing:** Email, Code, PDF, etc\n3. **This Way:** 1000 words, Bullets, Tone, etc\n\nNatural Language flows into natural structures (ie V-O-C). Just so happens that's also optimized for LLM Attention mechanisms. \n\nLong story short, figuring out what you want, and how you want it is the hard part. Once you figure that out,  The next hard part is Learning how to communicate it. \n\nFollow the Verb Object Constraint pattern and the prompts become not as important because you've complied it in your head before you type. So the prompts come out naturally.",
                  "score": 3,
                  "created_utc": "2026-02-20 21:37:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6hszai",
                  "author": "Party-Log-1084",
                  "text": "Same here, i want to learn too but idk what.",
                  "score": 1,
                  "created_utc": "2026-02-20 21:19:12",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6hvgwa",
          "author": "Any_Cauliflower5052",
          "text": "Prompts are the interface of LLM models. And prompt engineering is evolving continuously. I believe prompt engineering is not the same thing as it was when it started. At the beginning, it really made a big difference how you explained things to the model.\nNow the models are ‚Äúintelligent‚Äù enough to engineer their own prompts to enhance your original request, whether it is a simple one sentence or a comprehensive Markdown file.\nSo for me, the real deal right now is how you stabilize the output of the LLM model across hundreds or thousands of turns. With prompts, but not one super, ultimate prompt. Rather, with light prompts scattered all around, to be found only when that specific context is required to generate stable and coherent output. Which is also related with context engineering.\nAnd do not think prompts are something only used by users. All models use prompts in their internal reasoning, and someone is ‚Äúengineering‚Äù them. Which I believe is what makes Gemini generate almost the same quality output with a ‚Äúprompted‚Äù request and a non-prompted request.\nBecause it is prompting itself internally.\n\nThe destination of all LLM models is to reduce the need for prompt engineering to near zero, so they can give the same quality answer to the simplest question and the most overengineered one.\nThey are achieving this by turning ‚Äúprompt engineering‚Äù methods into built-in tools like subagents, skills, MCP servers, and /plan.\nThis is why it feels like prompt engineering is becoming completely unnecessary.",
          "score": 2,
          "created_utc": "2026-02-20 21:31:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hxnvt",
          "author": "BKG-Official",
          "text": "First misstake on start. \n\nThere is no \"perfect prompt\", or \"general prompt\". \nAlso, not every rule you know is usable to every input.",
          "score": 2,
          "created_utc": "2026-02-20 21:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ijcbe",
          "author": "briankato",
          "text": "Are you providing any guidance or trying to one-shot your output?",
          "score": 2,
          "created_utc": "2026-02-20 23:38:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jj5lp",
          "author": "promptoptimizr",
          "text": "you don't have to waste time trying to prompt engineer it yourself, there are many good tools out there that can refine the prompts for you and that improves results (at least for me it has)  \nlet me know if you'd be interested in something like that i can share the ones i've tried",
          "score": 2,
          "created_utc": "2026-02-21 03:17:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6knk4a",
              "author": "Party-Log-1084",
              "text": "Please share here",
              "score": 1,
              "created_utc": "2026-02-21 08:53:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6khstj",
          "author": "vincentdjangogh",
          "text": "Prompt engineering is a simple concept that people have over engineered so they can try to make money off of it. As long as you understand how LLMs \"think\" and understand how your bias works its way into the output, you're already going to be doing 99% of what makes prompt engineering helpful.",
          "score": 2,
          "created_utc": "2026-02-21 07:57:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6klzf3",
              "author": "Party-Log-1084",
              "text": "What resources do you recommend to learn how LLMs think?",
              "score": 1,
              "created_utc": "2026-02-21 08:38:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6kwl0o",
                  "author": "Noophyd",
                  "text": "Talk to it. Try to understand what you said Vs what you got",
                  "score": 1,
                  "created_utc": "2026-02-21 10:23:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6m2t5i",
                  "author": "vincentdjangogh",
                  "text": "Jeremey Utley has a couple videos on YouTube that are my go-to resource for getting people started. Here is one: [https://www.youtube.com/watch?v=wv779vmyPVY&t=363s](https://www.youtube.com/watch?v=wv779vmyPVY&t=363s)\n\nSome of it is likely going to seem basic to someone who is already knowledgeable about AI, but even then its a helpful refresher. I've probably watched his videos 5 times.",
                  "score": 1,
                  "created_utc": "2026-02-21 15:26:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6mr63j",
          "author": "thejosephBlanco",
          "text": " No matter what advice is given, prompting is frustrating. You give it too much it struggles, too little it struggles, just right, not yet. I have spent roughly 10 months playing around with every AI, building my own systems, and using local AI. I have had lots of successes, and more importantly ten times the failures. \n\nHonestly a lot of it is my own fault. Not understanding what I wanted, building without a purpose, trying to force a model to do the things I need it to do, rather then understanding what it is capable of doing. But the problem isn‚Äôt the model. You need to give the model a system in order for it to understand. You might say ‚Äúisn‚Äôt that a prompt?!‚Äù Not really. Prompting is giving it a basic template, but you need to have clear set boundaries. You need to have rules. You need to have context. You need to be able to explain to yourself or anybody asking what it is you are trying to accomplish, if you can‚Äôt do that, then how is the LLM. \n\nYou want it to help write or understand code, draft documents, create scripts say for Rust, TS, Python, CPP. The LLM is going to write those scripts in Java, and translate them into whatever language you are trying to code in, unless you have explicitly defined that is unacceptable. Then you audit/debug, ask or, is this Idiomatic code, begin code auditing, asking the LLM, is this code recognizable, is it readable, explainable, fixable? And when it gives you the response, ‚ÄúOK, how could I have asked for this code from the beginning, what is it that finally delivered what I asked for?‚Äù Hopefully it doesn‚Äôt take forever.\n\nBut remember, this tiny win, because you have to rinse and repeat the process. You may only want it to learn your homelab, but break it down into sections. Because the longer you try to explain something the more it is going to drift. I cannot tell you how many times I have literally been in arguments with an LLM. Like having a real fight because, ‚ÄúHow the fuck did you forget that? We just talked about it!‚Äù And all you get is, sorry I messed up, let me fix this by doing these three things. ‚ÄúUh, no, you need to explain how you lost track and what happened!‚Äù Pointless, I have gotten so accustomed to recapping the chat when I start to notice the drift or the lag, and starting new chats, which in itself is a whole other headache. I find it simply best to ask, and once I get a response, fine tune my question. Then save said questions as rules. Then when it starts to break them, ‚Äúis this following our rules‚Äù and it usually says no then corrects itself. \n\nI do this with everything from cursor,antigravity, windsurf, warp, Claude, Gemini, Grok, ChatGPT. Even using them mostly for free, so I would say keep failing but keep notes on the failures and try to fix the mistakes. And don‚Äôt get frustrated and say fuck it, stick with it and finish your projects.\n\nSo from my opinion, like someone else offered, break your prompt into sections, complete phase 1. Once you feel it is correct move to the next until your complete prompt has been fulfilled. But I would then add, then audit, debug, verify, and make it proves its claims against code written by a human. Which is easy to find. And verify it is what you want. Happy learning!",
          "score": 2,
          "created_utc": "2026-02-21 17:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6n0e1r",
              "author": "Party-Log-1084",
              "text": "Spending 10 months on this frustrating prompting crap. I wouldn‚Äôt have the patience or the desire for that. I‚Äôd much rather have a 'Gold Standard' that everyone is currently using; you implement it in an afternoon, and that‚Äôs it. It might not be perfect, but it‚Äôs usable and a significant upgrade.\n\nI‚Äôve had my fair share of arguments, too. I often find myself typing, 'Bro, you are such a dumb piece of sh...' and then giving up in frustration.\n\nIn 2025, I was very happy with Gemini. Then I tried to optimize it, and now I‚Äôm stuck in this unusable mess.",
              "score": 1,
              "created_utc": "2026-02-21 18:15:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gzk2w",
          "author": "qki_machine",
          "text": "It is not, but it‚Äôs not that important as it was before reasoning models were introduced. \nRight now, you can just ask it complete an action and it will make its own CoT etc. \n\nAlso if your instructions are messy or non complete you still cannot expect it to produce perfect output.",
          "score": 3,
          "created_utc": "2026-02-20 18:56:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hb604",
              "author": "SportTawk",
              "text": "GIGO still rules!",
              "score": 2,
              "created_utc": "2026-02-20 19:51:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6kn489",
                  "author": "Party-Log-1084",
                  "text": "What is GIGO?",
                  "score": 1,
                  "created_utc": "2026-02-21 08:49:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6h9x83",
          "author": "Technical-Fee9727",
          "text": "I‚Äôve only used the following technique with Claude but it might be worth testing on Gemini - I use the phrase ‚ÄúLLM-optimized instructions‚Äù and it seems to be an efficient way of moving a task or related task to a new thread.",
          "score": 1,
          "created_utc": "2026-02-20 19:45:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hzdvi",
          "author": "Protopia",
          "text": "Perhaps you simply weren't engineering then prompt. \n\nThe idea of Prompt Engineering (at least as I understand it) is that you create an excellent prompt in order that AI will then generate useful output. \n\nIf you want AI to create the perfect prompt for you, then you need to have written the perfect prompt for that task. Of course, if you want AI to generate that prompt for you then you need to write the perfect prompt in order for it to do so. Repeat ad infinitum.\n\nIn other words prompt engineering is a human endeavour, where untrained AI cannot do it for you.\n\nThe good news is that the folks at Anthropic and OpenAI are also crafting prompts for you to use. And better prompts for creating new prompts. So raw AI models delivered by these folks are making it easier over time. \n\n(Read about StrongDM as being the blueprint for the future. Then decide whether the single person writing the s single requirements.md file is a Prompt Engineer or a Business Strategist/Analyst. I think they are not a Prompt Engineer and that, except for Anthropic etc. employees, the Prompt Engineer career path will be short lived.)",
          "score": 1,
          "created_utc": "2026-02-20 21:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6j6lhg",
          "author": "Iron-Over",
          "text": "It all depends on what you are prompt engineering. If it is a system prompt that will be used often, I have used an LLM to generate the prompt and a jury to evaluate.  I returned a quantitative score and qualitative feedback on what was good and what was bad. The created prompt needs 5+ runs, with the jury evaluating each response 3 times each to reduce non-determinism. I have seen some improvement in a 10-15% range.  I would only use this for agent/system prompts that are run often.",
          "score": 1,
          "created_utc": "2026-02-21 01:58:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6l8u6d",
          "author": "talltrev",
          "text": "Honest question;   Isn‚Äôt hallucinations a 2024-2025 thing?   Do the current models still do this?   Isn‚Äôt it like my mom saying LAST WEEK, ‚ÄúYou think AI is so great but it can‚Äôt even get hands right.‚Äù",
          "score": 1,
          "created_utc": "2026-02-21 12:16:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l8z0v",
              "author": "Party-Log-1084",
              "text": "Ofc they still hallucinate. A lot.",
              "score": 1,
              "created_utc": "2026-02-21 12:17:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o74f8wi",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-24 12:05:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74f8y6",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-24 12:05:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6h1kt3",
          "author": "myeleventhreddit",
          "text": "What Gemini model? There's a *lot* of data out there showing that Gemini 3 marked a pretty serious regression in terms of following prompts correctly.\n\nPrompt engineering by itself is ***not a waste of time***. But you might be better off trying a different model.",
          "score": 1,
          "created_utc": "2026-02-20 19:05:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h71x8",
              "author": "Party-Log-1084",
              "text": "Gemini 3 Pro",
              "score": 1,
              "created_utc": "2026-02-20 19:31:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hakoa",
                  "author": "myeleventhreddit",
                  "text": "There are [conversations on Google's official developer ](https://discuss.ai.google.dev/t/the-problem-with-gemini-3-0-is-that-it-doesnt-perfectly-follow-system-instructions/109790)forum about Gemini 3 Pro being noticeably worse at instruction following. \n\nFunny enough, I decided to have Gemini itself make an interactive web app explaining what's going on. ",
                  "score": 1,
                  "created_utc": "2026-02-20 19:48:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gz4hr",
          "author": "TokelessTony777",
          "text": "ü§£ü§£ü§£",
          "score": -4,
          "created_utc": "2026-02-20 18:54:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rb3th7",
      "title": "We are holding something extraordinary.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rb3th7/we_are_holding_something_extraordinary/",
      "author": "Alive_Quantity_7945",
      "created_utc": "2026-02-21 21:59:52",
      "score": 26,
      "num_comments": 39,
      "upvote_ratio": 0.68,
      "text": "I've been thinking about this a lot lately and I just wanted to share it.\n\n  \nWhen we open ChatGPT or Claude or any of these tools, we are sitting at the end of a very long chain. Centuries of mathematicians' work built on top of each other. Physicists. Engineers. Researchers. Computer Scientists. Anyone you can think of that contributed something remarkable to humanity, even if it was a tiny little bit. Thousands of people we'll never know or read or hear about, poured their lives into the work that makes it possible for us to type a sentence and get an intelligent response back, almost like magic.\n\n  \nIf you ever watched Avatar, The Last Airbender, remember that scene when he's fighting Ozai while holding back? And he hits his back to that rock, and sees all of his Avatar ancestors, before entering the Avatar State. That scene resembles us as humans. That's us actually. Our story. Just let's strip ego for a second.\n\n  \nThe accumulated effort of millions (who knows) of humans, that's what's in front of us right now. And I think most of us, perhaps all, aren't meeting that with the kind of care, respect and honor it deserves.\n\n  \nThese tools are very responsive, both in a good and in a bad way. They are almost like mirrors. We have to find a way to explain what goes inside of us through words, and these machines can actually turn that into code if it is physically possible. That can only happen if we are honest, but mostly, if we care enough to understand the way these machines process our inputs.\n\nHonestly tho, I think we should aim for a hybrid result, the best of us + the best of these machines combined. But for that we need to understand both, us, and the machines.\n\n  \nThe things that make good prompts: clarity, honesty, knowing what we want, being specific, is the same thing that makes good conversations between us when we are being real as humans, but it is even easier with AI, it is not even judging you, unless you command it to, it is not putting pressure on you, it is not doing some subtle yet noticeable face gestures or body moves that your mind processes in a hard way to understand but significantly impactful for us. That stuff that makes it hard when we try to open up and just speak our truth or just allow us to be vulnerable in front of others. This machine actually does not care at all, about anything.\n\n  \nWe're all busy. We all want results, and we want them now. Because the world itself is constantly enforcing our minds towards these rush states.\n\nI believe that we all want our time back, our freedom, our space, to focus on what truly matters to us. If we are trying to build something that matters, something that can have a positive impact on others, that can save people time, money, extra effort, or just make people happy, whether it is a project, or a business, or any kind of creative work, anything, we have to spend time to understand these tools to create such outcomes. Not because it's an obligation. Because we have to own these results. They are unique to us. Nobody else could have produced them because nobody else has our specific combination of experiences, that little extra that makes us unique as individuals.\n\n  \nWe built something incredible together as a species. Across centuries, across languages, across people who never met each other. And now it's here, and it's accessible, and it can do remarkable things. I just think it's worth meeting it with a little more presence and depth, rather than just massive speed.\n\n  \nThat's it. Just something I wanted to share in case it lands for someone. Take care of yourselves, and take care of others. That matters more.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rb3th7/we_are_holding_something_extraordinary/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6ofun8",
          "author": "okayladyk",
          "text": "100% ai detected üò¨üòÇ",
          "score": 11,
          "created_utc": "2026-02-21 22:43:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ohzd8",
              "author": "Alive_Quantity_7945",
              "text": "üíÄ",
              "score": -6,
              "created_utc": "2026-02-21 22:55:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6omc0x",
                  "author": "okayladyk",
                  "text": "You‚Äôre absolutely right!",
                  "score": 5,
                  "created_utc": "2026-02-21 23:21:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6oe3h0",
          "author": "tolani13",
          "text": "Very well said, especially since most of tend to overlook the history behind it all",
          "score": 3,
          "created_utc": "2026-02-21 22:34:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o90bl",
          "author": "Alive_Quantity_7945",
          "text": "I made this thinking that judging the power expenditure of ai, or highlighting it, would not stop people from using it. The cost (energy, water for cooling, carbon) is very real, and I can not do anything about it.  \n",
          "score": 3,
          "created_utc": "2026-02-21 22:05:52",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6q0gcp",
              "author": "JingJang",
              "text": "The genie is out of the bottle.   We shouldn't try to put it back in, we should work with it to start solving those, (and other), problems.",
              "score": 1,
              "created_utc": "2026-02-22 04:49:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6prq1h",
          "author": "kallushub",
          "text": "Fr man people who hate ai are caveman who don't want to touch much better opportunities and development you know what since I used ai's my productivity has increased into what I can't even dream of I learned writing i started writing scripts enjoyed popularity in yt in 2024 everything feels good af now and also now again starting yt ai feels like a loyal companion who never betray you even if it's just a program witch runs on tokens",
          "score": 2,
          "created_utc": "2026-02-22 03:47:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o9tgm",
          "author": "UnmaintainedDonkey",
          "text": "Also consider the moral part. You did not touch that at all.",
          "score": 3,
          "created_utc": "2026-02-21 22:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ochwg",
              "author": "Alive_Quantity_7945",
              "text": "that one is for us to talk about as a society, i could have talked about ethics. moral is, difficult to address. what would you've said?",
              "score": 3,
              "created_utc": "2026-02-21 22:25:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6odzmz",
                  "author": "UnmaintainedDonkey",
                  "text": "Plainly, the morale of AI, or how it became what it is. There is so much nasty stuff done that cant be just put aside. Like in training data, its trained on licensed code / copyrighted code. And yet in 2026 we still dont know the source. Then theres the fact that training these models and running datacetenter is a real problem for people. Energy costs spiking, while AI companies get governmebt sunsidies.\n\nThen we have bias and discrimination, privacy viilations, manipulation and autonomy issues, accobtobility, transparency and job displacement. Finally the use in lethal weapons and a huge environmental impact.\n\nIts not all sunny and roses.",
                  "score": 2,
                  "created_utc": "2026-02-21 22:33:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6oh7rt",
          "author": "FirefighterFit7605",
          "text": "AI slop about the progression of human intelligence leading to the generation of AI.\n\nYikes.\n\nDo you realize people don‚Äôt want to read AI slop? We want to discuss AI with other actual humans with novel thoughts.\n\n\n",
          "score": 2,
          "created_utc": "2026-02-21 22:51:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ohx9n",
              "author": "Alive_Quantity_7945",
              "text": "wtf, you cant even tell ai vs human anymore",
              "score": 3,
              "created_utc": "2026-02-21 22:55:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6r2giv",
                  "author": "Elvarien2",
                  "text": "I think he's right though. I do love me some ai but if you let ai write for you at least change it a little to make it read human.",
                  "score": 1,
                  "created_utc": "2026-02-22 10:34:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qs3mm",
          "author": "xTopaz_168",
          "text": "I'm not sure why people are against AI as a concept. Like most things we do (society as a whole including businesses) it's the implementation that is the problem.\n\nIt was always going to go this way, we built computers to do things for us, up until recently it's always needed someone to be the brain, make the decisions, set up the program and intervene when it's going wrong. \n\nWe now have the power to let the computer decide these things on its own, it has much more processing power and data to refer to than we could ever manage. It can identify and fix mistakes automatically. It's able to do all this within a few seconds/minutes rather than us manually researching, testing and comparing for days/weeks at a time. It's efficiency can't be matched.\n\nWe just need to make sure to always have a human be the last step; to thoroughly read the assessment made by AI, infuse some compassion and human decency alongside it, then make the final decision, since those are the things it's not capable of.\n\nWorking together and using it as a tool to help us should be the goal. Using it to replace people entirety is where the issue lies. This is basically like the industrial revolution all over again, we should learn from the mistakes made in that time.",
          "score": 1,
          "created_utc": "2026-02-22 08:55:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ruc44",
              "author": "Alive_Quantity_7945",
              "text": "\"We now have the power to let the computer decide these things on its own\". We have to understand what we are building. It's a huge responsibility, from programmers who build ai, to users. On it's \"own\", i don't think so honestly. From an ecosystem perspective, as a society we behave like a corruputor of nature's flow, we shape the environment for our own comfort, then find ways to justify our acts. We are intelligent, yet we are not wise, nor we own responsibility, we understand the impact of our acts, yet we do not care, we just find pretty ways to justify them. If ai just amplifies the current version of \"us\", ggwp",
              "score": 1,
              "created_utc": "2026-02-22 14:08:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6s5qym",
                  "author": "xTopaz_168",
                  "text": "You said yourself, the best way to go forward with this technology is a hybrid result. I am agreeing with this. \n\nWe built something that can make decisions for us to save us time, but we need to make sure the decisions it makes are actually what we want. \n\nFirstly, baked into the prompts with hard rule structure in place and always having a human check the result to make sure.\n\nUnfortunately, reffering to your own points, like most things driven my humans, we destroy everything in our path for comfort. The enormous energy use is a colossal issue, I believe we should be working towards localised models for homes and offices, with much more conservative use in the cloud.\n\nUsing AI for silly, unnecessary stuff is also a big problem. \n\nIf the AI servers of an office are replacing 1000+ computers that were running all the time anyway, using a similar energy output, then that would be fair use. The AI does all the processing, so would only need lighter powered machines or even just tablets could be used by the employees to refine the output into their work.",
                  "score": 1,
                  "created_utc": "2026-02-22 15:09:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6r2ddg",
          "author": "Elvarien2",
          "text": "this was made by ai wasn't it ;p   \n\nHell the title itself already.",
          "score": 1,
          "created_utc": "2026-02-22 10:33:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v8mx9",
          "author": "Olbas_Oil",
          "text": "\"üëçüëçüëç You are 100% right, this is exactly how our species contribute. Let me explain\" \n\nGrinds to a halt trying to explain....",
          "score": 1,
          "created_utc": "2026-02-23 00:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z6frn",
          "author": "Difficult_Buffalo544",
          "text": "Beautifully put, and I totally agree with your point about care and presence. The best prompt engineers I know treat the process almost like a craft, not just a transaction. One thing worth adding is the value of ongoing feedback loops with these tools, training them over time produces way better results than one-off prompting. Also, keeping records of prompts that work well and analyzing why they work (and why others don't) can level up your outputs fast. Building a product in this space has made me realize how much more effective everything becomes when there's an intentional process around capturing your own \"voice\" and weaving it into the workflow. If anyone wants to nerd out about it, happy to share more.",
          "score": 1,
          "created_utc": "2026-02-23 16:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70dtjv",
              "author": "Alive_Quantity_7945",
              "text": "yes, a chain of prompts works always better than a singular prompt trying to capture it all. and the ongoing process helps us understand also our own cognitive process, both to learn new things and grow smarter, and to unlearn stuff that's just not working, i guess we sometimes just believe we learnt something but it was badly captured by our minds.\n\n ai must be understood to execute projects, searchs, or whatever efficiently, but the real path is to understand ourselves, always.",
              "score": 1,
              "created_utc": "2026-02-23 20:00:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9wtum",
      "title": "The LLM understood my instruction perfectly. It just decided it knew better",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r9wtum/the_llm_understood_my_instruction_perfectly_it/",
      "author": "archetype_builder",
      "created_utc": "2026-02-20 14:29:33",
      "score": 22,
      "num_comments": 18,
      "upvote_ratio": 0.85,
      "text": "There's a pattern I keep hitting where a prompt instruction looks perfectly clear, but the LLM just... ignores it. Not hallucinating, not confused. It understands what you want. It just decides something else would be better.\n\n\"Single line break between paragraphs.\" Clear, right? The LLM adds double line breaks anyway because it thinks the output looks better with more spacing. \"Aim for about 16 words.\" LLM gives you 40 because the thought was \"complex\", and surely you'd want the full explanation.\n\nThe problem is positive-only instructions. When you only tell an LLM what TO do, it treats your instruction as a suggestion and optimizes for what it thinks is \"better\". These things are trained to be helpful. Helpful means more detail, cleaner formatting, and fuller explanations, even when you explicitly asked for less.\n\nThe fix is dead simple. Add the negative.\n\n* \"Use single line breaks.\" ‚Üí LLM adds double line breaks\n* \"Use single line breaks, NOT double line breaks\" ‚Üí immediate compliance\n* \"Aim for 16 words, can vary 13-19\" ‚Üí LLM writes 27-52 words\n* \"Aim for 16 words. NEVER exceed 19 ‚Äî hard limit\" ‚Üí stays in range\n\nSame instruction. One just closes the loophole.\n\nThe reason this works is that LLMs treat positive instructions as preferences and negative instructions as constraints. \"Do X, NOT Y\" means \"Y is prohibited.\" Different weight entirely.\n\nThe place this matters most is hard limits, word counts, formatting rules, and output structure. Anywhere you need compliance, not creativity. Telling a model \"be conversational\" is fine as a positive-only instruction because flexibility is the point. But telling a model to \"keep it under 20 words\" needs the explicit \"NEVER exceed 20 words\" or it'll blow past it the moment it has something interesting to say.\n\nOne more thing, check your own prompts for soft language. \"Can vary\", \"if appropriate\", \"longer responses are fine for emotional scenes\". Every one of those is a door you left open. If the limit is the limit, close it.\n\nWhat's the instruction you've rewritten ten times and it still ignores?",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r9wtum/the_llm_understood_my_instruction_perfectly_it/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6fgfnh",
          "author": "rockthemike712",
          "text": "Ask it why it keeps fucking up and then when it explains ask it to write a prompt for itself to fix the issue",
          "score": 7,
          "created_utc": "2026-02-20 14:40:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fgsfi",
              "author": "archetype_builder",
              "text": "Wouldn't it be lovely if that always worked? ",
              "score": 1,
              "created_utc": "2026-02-20 14:42:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fld1o",
                  "author": "orz-_-orz",
                  "text": "Then the bastard LLM would find another loophole to by pass the prompt",
                  "score": 2,
                  "created_utc": "2026-02-20 15:05:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6hqwte",
                  "author": "rockthemike712",
                  "text": "It works with claude. Make sure to give it a good skill builder skill too üòÇ",
                  "score": 1,
                  "created_utc": "2026-02-20 21:08:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6fjwo3",
          "author": "sittingonac0rnflake",
          "text": "Which LLM?",
          "score": 2,
          "created_utc": "2026-02-20 14:58:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fn739",
          "author": "drakgremlin",
          "text": "Temperature too high?¬† Could also be top_k .",
          "score": 1,
          "created_utc": "2026-02-20 15:14:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fnh0e",
          "author": "PhotoRepair",
          "text": "TBH this happens with paid for services too across all AI. Ask Google for something in AI serps and dont get the answer, get what it feels you need instead. Ask AI to make you a song feed in some lyrics, argue with it why its not following the prompt, removing the drums or calming the chorus and just amps it up instead. Fixing an image. make everything orange red and its whacks in an extra object when asked not too. Its hard work.",
          "score": 1,
          "created_utc": "2026-02-20 15:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g2xao",
          "author": "Pcc210",
          "text": "Wrong. It does not understand. Lovingly, touch grass.",
          "score": 1,
          "created_utc": "2026-02-20 16:27:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gdxv7",
          "author": "anonymoosepanda",
          "text": "I was experimenting with excel copilot to dust off my skills. I asked for a simple correlation and it tried to feed me a full analysis with code and everything. What I needed was a pivot table and some formulas to make a little chart. üòÇ",
          "score": 1,
          "created_utc": "2026-02-20 17:18:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hm85t",
          "author": "og_hays",
          "text": "My way around this is at the start of a session I tell it this, \" all my  inputs are not questions looking for explanations, they are statements and demands only .\n\nCrazy how different the outputs are",
          "score": 1,
          "created_utc": "2026-02-20 20:45:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ft0bn",
          "author": "Pale-Escape-1781",
          "text": "LLMs are autistic like meeeee",
          "score": 1,
          "created_utc": "2026-02-20 15:42:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcpq5b",
      "title": "Adding \"explain like I'm debugging at 2am\" to my prompts changed everything",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rcpq5b/adding_explain_like_im_debugging_at_2am_to_my/",
      "author": "AdCold1610",
      "created_utc": "2026-02-23 18:35:54",
      "score": 22,
      "num_comments": 9,
      "upvote_ratio": 0.92,
      "text": "Was getting textbook explanations when I needed actual solutions.\n\nAdded this. Now I get:\n\n* Skip the theory\n* Here's what's probably wrong\n* Try this first\n* If that doesn't work, it's probably this\n* Here's how to check\n\nStraight to the point. No fluff.\n\nWorks for code, writing, anything where you need answers fast.\n\nTry it.\n\n[for more post](http://beprompter.in)",
      "is_original_content": false,
      "link_flair_text": "Ideas & Collaboration",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rcpq5b/adding_explain_like_im_debugging_at_2am_to_my/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o701phu",
          "author": "earmarkbuild",
          "text": "\"debugging at 2am\" is relatable and clear hahaha i like that",
          "score": 3,
          "created_utc": "2026-02-23 19:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zzxoi",
          "author": "CowOk6572",
          "text": "You could also try, Act like I‚Äôm on a deadline, give me the basics first and explain further, only if needed",
          "score": 2,
          "created_utc": "2026-02-23 18:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73sif2",
          "author": "Gold-Satisfaction631",
          "text": "The framing is doing three things at once ‚Äî urgency, assumed expertise, and \"skip the theory\" expectation. The model picks up on all of it without you spelling each one out separately.\n\n  \nSame trick works reversed: \"explain this to a sharp exec with 5 minutes\" gets you a completely different output style without writing a paragraph of instructions.",
          "score": 2,
          "created_utc": "2026-02-24 08:44:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zxwjz",
          "author": "CowOk6572",
          "text": "Wow, I will try that",
          "score": 0,
          "created_utc": "2026-02-23 18:47:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o73lcp0",
              "author": "baytown",
              "text": "Wow. This is fantastic, can't wait to try it!",
              "score": 1,
              "created_utc": "2026-02-24 07:37:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rc2lkn",
      "title": "My \"Recursive Reasoning\" stack that gets AI to debug its own logic",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1rc2lkn/my_recursive_reasoning_stack_that_gets_ai_to/",
      "author": "Distinct_Track_5495",
      "created_utc": "2026-02-23 00:27:04",
      "score": 21,
      "num_comments": 12,
      "upvote_ratio": 0.95,
      "text": "I honestly feel like the standard LLM responses getting too generic lately (especially chatgpt). They seem to be getting worse at being¬†critical.\n\nso i've been testing a structural approach called¬†Recursive Reasoning. Instead of a single prompt, its a 3 step system logic you can paste before any complex task to kill the fluff.\n\nThe logic stack (Copy/Paste):\n\n<Reasoning\\_Protocol>\n\nPhase 1 (The Breakdown):¬†Before you answer my request, list 3 non obvious assumptions you are making about what I want.\n\nPhase 2 (The Challenger):¬†Identify the \"weakest link\" in your intended response. What part of your answer is most likely to be generic or unhelpful?\n\nPhase 3 (The Recursive Fix):¬†Rewrite your final response to address the assumptions in Phase 1 and strengthen the weak link in Phase 2.\n\nConstraint:¬†Do not start with \"sure, I can help with that.\" Start immediately with Phase 1.\n\n</Reasoning\\_Protocol>\n\nmy logic is to forces the model to act as its own¬†quality controller. Im been messing around with a bunch of different prompts for reasoning because im trying to build an [engine](https://www.promptoptimizr.com) that can create one shot prompts.\n\nHave you guys found that XML tagging (like¬†me adding the <Reasoning\\_Protocol>) actually changes the output quality for you or is it just a placebo?",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1rc2lkn/my_recursive_reasoning_stack_that_gets_ai_to/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o6vgx7r",
          "author": "CowOk6572",
          "text": "I‚Äôm genuinely curious. That sounds like a neat trick. Have you noticed tangible improvement when using this approach?",
          "score": 1,
          "created_utc": "2026-02-23 01:03:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o722re2",
              "author": "Distinct_Track_5495",
              "text": "Yes I've seen improvements in my results esp when im using claude ",
              "score": 1,
              "created_utc": "2026-02-24 01:18:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6x27yq",
          "author": "Deep_Novel7759",
          "text": "Whats your own experience with XML tagging in prompts? Have not used it yet, but I'm seeing some potential there. Gives me a clearer structure to a prompt which LLM might \"appretiate\". I use markdown with interlinked segments of a prompt. So the xml tags would give it an extra layer. At Ieast I like how it looksüôÇ",
          "score": 1,
          "created_utc": "2026-02-23 07:56:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7237u1",
              "author": "Distinct_Track_5495",
              "text": "my own experience with XML tags has been positive, its helped me get a much more structured outputs.. markdowns also work I wouldn't say they dont work and only XML is the way to go but I def see an advantage to using XMLs",
              "score": 1,
              "created_utc": "2026-02-24 01:21:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w834w",
          "author": "WillowEmberly",
          "text": "What‚Äôs doing the work is not recursion.\nWhat‚Äôs doing the work is role separation and delay.\n\nYou created a small governance loop. Now you just need to build out the system. This is better than 95% of the stuff I see posted, you just need to focus it‚Ä¶and keep going.",
          "score": 1,
          "created_utc": "2026-02-23 03:51:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o722zvx",
              "author": "Distinct_Track_5495",
              "text": "thanks so much man, I put in a lot of hours trying to come up with interesting stuff appreciate you saying this",
              "score": 2,
              "created_utc": "2026-02-24 01:20:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}