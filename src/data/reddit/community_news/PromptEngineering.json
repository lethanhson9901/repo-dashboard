{
  "metadata": {
    "last_updated": "2026-02-18 17:29:57",
    "time_filter": "week",
    "subreddit": "PromptEngineering",
    "total_items": 20,
    "total_comments": 174,
    "file_size_bytes": 234476
  },
  "items": [
    {
      "id": "1r4b2y3",
      "title": "The 5-layer prompt framework that makes ChatGPT output feel like it came from a paid professional",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r4b2y3/the_5layer_prompt_framework_that_makes_chatgpt/",
      "author": "AdImpossible3465",
      "created_utc": "2026-02-14 04:27:13",
      "score": 423,
      "num_comments": 44,
      "upvote_ratio": 0.91,
      "text": "After months of testing, I realized that 90% of bad ChatGPT outputs come from the same problem: we write prompts like Google searches instead of project briefs.\n\nHere's the framework I developed and use for every single prompt I build:\n\nROLE â†’ CONTEXT â†’ TASK â†’ FORMAT â†’ CONSTRAINTS\n\nLet me break it down with real examples:\n\nLayer 1: ROLE (Who is ChatGPT being?)\n\nDon't just say \"you are an expert.\" Be specific about the expertise level, the industry, and the personality.\n\nBad: \"You are a marketing expert\"\n\nGood: \"You are a direct-response copywriter with 15 years of experience writing for DTC e-commerce brands. You specialize in high-converting email sequences and have studied Eugene Schwartz and David Ogilvy extensively.\"\n\nThe more specific the role, the more specific the output. ChatGPT adjusts its vocabulary, structure, and reasoning based on this layer.\n\nLayer 2: CONTEXT (What's the situation?)\n\nGive background. ChatGPT cannot read your mind. The context layer is where most people lose quality.\n\nExample: \"My client sells a $49 organic skincare serum targeted at women aged 28-42 who are frustrated with products that promise results but use synthetic ingredients. The brand voice is warm, confident, and science-backed   not salesy.\"\n\nLayer 3: TASK (What exactly do you want?)\n\nBe painfully specific about the deliverable.\n\nBad: \"Write some emails\"\n\nGood: \"Write a 5-email welcome sequence. Email 1 is a warm brand introduction. Email 2 addresses the #1 objection (price). Email 3 shares a customer transformation story. Email 4 introduces urgency with a limited-time offer. Email 5 is a final nudge with social proof. Each email should have a subject line, preview text, and body.\"\n\nLayer 4: FORMAT (How should it look?)\n\nTell ChatGPT the exact structure.\n\nExample: \"For each email, use this structure: Subject Line | Preview Text | Opening Hook (1 sentence) | Body (100-150 words) | CTA (one clear call to action). Use short paragraphs   no paragraph longer than 2 sentences.\"\n\nLayer 5: CONSTRAINTS (What should it avoid?)\n\nThis is the secret weapon. Constraints prevent generic output.\n\nExample: \"Do not use the words 'revolutionary', 'game-changing', or 'unlock'. Do not start any email with a question. Do not use exclamation marks more than once per email. Write at an 8th-grade reading level.\"\n\nFull prompt using all 5 layers combined:\n\nYou are a direct-response copywriter with 15 years of experience writing for DTC e-commerce brands. You specialize in high-converting email sequences and have studied Eugene Schwartz and David Ogilvy extensively.\n\nMy client sells a $49 organic skincare serum targeted at women aged 28-42 who are frustrated with products that promise results but use synthetic ingredients. The brand voice is warm, confident, and science-backed   not salesy.\n\nWrite a 5-email welcome sequence. Email 1: warm brand introduction. Email 2: address the #1 objection (price). Email 3: customer transformation story. Email 4: limited-time offer with urgency. Email 5: final nudge with social proof.\n\nFor each email use this structure: Subject Line | Preview Text | Opening Hook (1 sentence) | Body (100-150 words) | CTA (one clear call to action). Use short paragraphs   no paragraph longer than 2 sentences.\n\nDo not use the words \"revolutionary,\" \"game-changing,\" or \"unlock.\" Do not start any email with a question. No more than one exclamation mark per email. Write at an 8th-grade reading level.\n\nThe output you get from this vs. just saying \"write me some emails\" is night and day.\n\nHere are 3 more fully built prompts using this framework:\n\nThe Strategy Audit Prompt:\n\nYou are a startup advisor who has helped 50+ companies go from 0 to $1M ARR. You specialize in digital products and solo-creator businesses. I'm going to describe my current business. Audit my strategy and give me: 1) The 3 biggest risks you see, 2) The #1 thing I should double down on, 3) What I should stop doing immediately, 4) A 30-day action plan with weekly milestones. Be direct and specific   no motivational fluff. If my strategy is bad, say so.\n\nThe Content Angle Generator:\n\nYou are a viral content strategist who has studied the top-performing posts on Twitter, LinkedIn, and Instagram for the last 3 years. My niche is \\[topic]. Generate 10 unique content angles I haven't thought of. For each angle, give me: the hook (first line), the core insight, and why it would perform well. Avoid clichÃ© angles like \"5 tips for...\" or \"here's what nobody tells you.\" I want original, surprising perspectives that make people stop scrolling.\n\nThe Customer Avatar Deep Dive:\n\nYou are a consumer psychologist and market researcher. My product is \\[describe product and price]. Build me a detailed customer avatar that includes: demographics, psychographics (values, fears, aspirations), the exact language they use to describe their problem (not marketer language   real words from real people), where they hang out online, what they've already tried that failed, and the emotional trigger that would make them buy today. Write it as a strategic document, not a generic persona template.\n\nI've been building a full library of prompts using this exact framework across marketing, productivity, business strategy, content creation, and more.\n\nThis framework works. Try it on your next prompt and compare the output to what you were getting before   you'll see the difference immediately.\n\nWhat frameworks do you all use? Curious if anyone approaches it differently.\n",
      "is_original_content": false,
      "link_flair_text": "Tutorials and Guides",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r4b2y3/the_5layer_prompt_framework_that_makes_chatgpt/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5ap3fs",
          "author": "Romanizer",
          "text": "Yes, that's a very reliable framework. I usually drop my ideas into the LLM and ask to build a prompt based on this and the desired outcome and it usually defaults to this structure.",
          "score": 32,
          "created_utc": "2026-02-14 05:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aq1bx",
              "author": "ceeczar",
              "text": "Love this workflow\n\n\nEssentially getting the LLM to do all the heavy liftingÂ \n\n\nPretty smartÂ ",
              "score": 10,
              "created_utc": "2026-02-14 05:56:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5bfsvl",
              "author": "charlieatlas123",
              "text": "I agree with you, and would add that if the prompt is getting too long, ie. using up too many tokens, then ask your LLM to make it more concise. \n\nI regularly ask this and it always shortens the prompt without losing any context.",
              "score": 2,
              "created_utc": "2026-02-14 09:59:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60t3do",
              "author": "yagudaev",
              "text": "Only thing Iâ€™d add there is try to cross pollinate. Use a different LLM provider. Like Gemini to help you write the prompt for OpenAI (ChatGPT).\n\nIt helps avoid biases in the target LLM data sources.",
              "score": 2,
              "created_utc": "2026-02-18 08:53:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5btxm3",
              "author": "looktwise",
              "text": "example please? after dropping the context content",
              "score": 1,
              "created_utc": "2026-02-14 12:11:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5c0ybz",
                  "author": "Romanizer",
                  "text": "For example, I asked it to draft a prompt that would optimize my LinkedIn Profile based on my CV and website and it came up with a comparable structure.",
                  "score": 3,
                  "created_utc": "2026-02-14 13:05:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5bhcng",
              "author": "pacha75",
              "text": "This is the way",
              "score": -3,
              "created_utc": "2026-02-14 10:14:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5aq65z",
          "author": "Conscious_Nobody9571",
          "text": "\"Here's a framework i developed\" proceeds to post the prompt format literally everyone is using",
          "score": 43,
          "created_utc": "2026-02-14 05:57:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5b6upi",
              "author": "mir_chan",
              "text": "Let me rephrase it.\n\n*proceeds to post the prompting format that **google** is handing for free in a form of a pdf file about 70 pages long.\n\nEven with descriptions that **google** has on every step. I mean it is a freaking copy paste fromt that doc.",
              "score": 9,
              "created_utc": "2026-02-14 08:31:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5awfgq",
              "author": "mxracer888",
              "text": "Just wait till OP learns about PRDs, especially as they relate to coding projects. Then the framework will include consulting with the LLM to generate a proper PRD that you then feed to Codex or Claude Code and hit the ground running",
              "score": 1,
              "created_utc": "2026-02-14 06:52:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5bu22b",
                  "author": "looktwise",
                  "text": "1 What are PRDs 2 What would be your PRD framework or prompt template?",
                  "score": 2,
                  "created_utc": "2026-02-14 12:12:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5aflfi",
          "author": "kubrador",
          "text": "this is just \"be specific\" wrapped in five boxes with corporate consulting language sprinkled on top. the whole thing reads like someone discovered that vague prompts produce vague outputs and then wrote a business case study about it.",
          "score": 6,
          "created_utc": "2026-02-14 04:33:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bg4k6",
          "author": "Ijere",
          "text": "I keep the instruction up top (then context) because the model seems to weight recent/explicit stuff more, so order matters. If you want to nit-pick it:Â ROLE â†’ TASK â†’ CONSTRAINTS â†’ CONTEXT â†’ FORMATÂ tends to be the most reliable.",
          "score": 6,
          "created_utc": "2026-02-14 10:02:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cqj0i",
          "author": "Imprfkt007",
          "text": "Your Layer 5 is doing more work than you realize. What youâ€™re calling â€˜constraintsâ€™ is actually the most technically interesting part of this framework â€” youâ€™re modifying the modelâ€™s output probability distribution rather than just steering its reasoning.\nThe reason â€˜do not use X wordâ€™ works so well isnâ€™t just about avoiding clichÃ©s. Youâ€™re collapsing regions of the token probability space, which forces the model to redistribute attention weight toward less default outputs. Thatâ€™s why constrained prompts feel more â€˜professionalâ€™ â€” youâ€™re literally making the lazy outputs unreachable.\nWhat gets interesting is when you formalize this beyond simple word exclusions. There are at least five distinct constraint types that operate differently on the output space â€” void regions (what youâ€™re already doing), mutual exclusions (if A then never B), binary verification gates, negation requirements, and representation closure. Layering these creates compound constraint geometry thatâ€™s qualitatively different from just stacking more â€˜donâ€™t do Xâ€™ rules.\nYour framework is solid for creative/marketing work. The question Iâ€™d pose to this community: what happens when constraints arenâ€™t preferences but requirements? Finance, healthcare, legal â€” domains where â€˜the model usually respects thisâ€™ isnâ€™t acceptable. Thatâ€™s where constraint architecture becomes a fundamentally different discipline from prompt engineering.",
          "score": 4,
          "created_utc": "2026-02-14 15:37:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nmx5m",
          "author": "Difficult_Buffalo544",
          "text": "This is honestly one of the most practical breakdowns Iâ€™ve seen on prompt layering. The roles and especially the constraints really do make a difference in pushing past that generic AI sound. One thing Iâ€™ve found really helpful that you didnâ€™t mention is actually training the AI on your or your clientâ€™s real content, like feeding it a bunch of emails, posts, or articles youâ€™ve already written, so it can pick up on recurring language, tone, and subtle habits. Then combine that with your framework and it gets crazy close to sounding human. Iâ€™ve been building a product to automate that brand voice training step with a review loop for teams, happy to share more if anyoneâ€™s interested.",
          "score": 3,
          "created_utc": "2026-02-16 09:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5amwi4",
          "author": "ghostintheforum",
          "text": "Thanks for taking the time to write a detailed breakdown of your prompting approach with examples.",
          "score": 4,
          "created_utc": "2026-02-14 05:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5au7nw",
          "author": "Acousticfish",
          "text": "Do you all type these out every time you start a new chat?",
          "score": 2,
          "created_utc": "2026-02-14 06:32:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ax1qn",
              "author": "mxracer888",
              "text": "depends on the project. But usually no. For some stuff you can run a deeper prompt like this and just run it as a custom GPT or a \"project\". Otherwise, I have a \"base-prompt.md\" and \"shutdown.md\" that I use for Claude Code. base-prompt gets the project started, gets the structure set, and has the prompt that points to my PRD. Then shutdown.md has shutdown instructions as far as updating \"to-do.md\", \"readme.md\", \"claude.md\" and other relevant documents and then I close out the sessions. \n\nThis is a good way to not type everything over and over, but also make sure sessions are kept tight and hyper focused. I feel quality degrades significantly the more and more context that gets built. With the addition of memory in claude code some of this is somewhat redundant, however memory is specific to the machine you're on, so doing the shutdown process and updating all documentation makes it much easier to pickup right where I left off when I transfer to desktop and back to laptop and so on. ",
              "score": 3,
              "created_utc": "2026-02-14 06:58:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b8p4f",
          "author": "Tintoverde",
          "text": "How do you prove this is the structure is better any other provided by other posts ?",
          "score": 1,
          "created_utc": "2026-02-14 08:49:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bhn35",
              "author": "charlieatlas123",
              "text": "Just test it for yourself. A/B split test against your best prompts, so every time you find a prompt that works better, record it and use it until you find one even better.",
              "score": 3,
              "created_utc": "2026-02-14 10:17:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5e27dy",
                  "author": "Tintoverde",
                  "text": "So how do you know this idea works ? If you claim this works, I would think if one claims something, one need to provide some proof",
                  "score": 1,
                  "created_utc": "2026-02-14 19:37:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bgr6t",
          "author": "raccoonportfolio",
          "text": "Honestly we should just pin this and archive the sub.",
          "score": 1,
          "created_utc": "2026-02-14 10:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bk2kh",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-14 10:41:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bk2le",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-14 10:41:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cchny",
          "author": "b4st14nb",
          "text": "Check 'promptCowboy' in the meantime, not paid promotion just what I discovered and works a lot like your workflow",
          "score": 1,
          "created_utc": "2026-02-14 14:19:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cma4s",
          "author": "YamJealous4799",
          "text": "Depending on what you need, adding information about yourself is helpful as well.  I guess this would go in CONTEXT.  I find that adding things like \"I am a senior software engineer\" or \"I am a high schooler that is just learning about X\" also helps get the kind of output I want.",
          "score": 1,
          "created_utc": "2026-02-14 15:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fi5fj",
          "author": "Protopia",
          "text": "I both agree with this lecture but also disagree. \n\n<rant>\n\nGood output is (and has always been) a consequence of good input, but the users prompt is only part of the input...\n\n1. System prompt - overall guidance on personality and subject\n\n2. Domain input - e.g. the existing code base, RAG.\n\n3. The user's prompt.\n\n4. MCPs and other subject expert sources\n\n5. Rules, workflows and skills\n\n6. The language model itself.\n\n7. History/memory of what has already been done.\n\n8. Context management.\n\nOnly number 3 is written every time, and it doesn't have to be written entirely by the user - AI in planning mode can write a detailed prompt based on a simpler user prompt.\n\nAnd it can do that best when all the other items in the list pre-exist and are quality. \n\nSo you can have rules or workflows that say how a single user requirement should be processed. You can start with a simple prompt and AI can ask questions and enhance the prompt into a more detailed requirement (goal),  specification (what to produce) and plan (how to produce it to the right quality) which the user  needs to approve before AI gets on with the actual coding. And the system prompt, domain and expert knowledge etc. are as important input into the planning as into the production run. \n\nAnd having the AI effectively record what it has already done it tried and having it clear it's context and start again with the knowledged already gained is another important aspect.\n\nAnd IMO, the definition of Prompt Engineering is getting all of the above right not just the user's written prompt.\n\nSo you need to craft the overviews, the roles and workflows, you need to define the process that the AI follows, telling the childlike AI how to break it down into steps, how to record progress and pass results of one step onto another that otherwise starts afresh like a goldfish that has completed a lap of the bowl..\n\nYou also need to define how the AI gets is domain knowledge (existing source code, exposure in Frameworks or languages, MCP servers, rag etc.) and not leave the AI guessing. \n\nIn my (extremely limited) experience with AI, you can burn a lot of tokens for not a lot of quality output if you don't do all of the above. \n\nWhat surprises me is that so little of this is predefined. The software development lifecycle has both a lot of theory and a lot of practical experience, and a lot of literature about it. Yes, there are lots of minor alternatives - so you might need a few preferred prompts to choose from - but it's crazy that we are expected to reinvent the wheel. \n\nOut of the box, you seen to get none of this. And so people use it like Google because they are not guided otherwise and burn a whole shitload of tokens before giving up or painful learning.\n\nAnd though I am absolutely not an expert on llms, it does seem crazy to me that an apprentice coding LLM will understand 100 spoken languages, and 20 computer language and goodness knows what else, so that when I write English it burns inference cycles working out whether it means in Spanish, Italian and French, and when I want JavaScript code it has to reject all sorts of python and php probabilities. Surely we could have an English and web languages coding LLM (of say 8B tokens) instead of a polyglot be all and do all single LLM of 500B tokens. \n\nSo yes, we might also need different specialised llms for planning, design, and coding and running tests/diagnosing failures, but routing queues to the right LLM shouldn't be that hard these days.\n\n </rant>",
          "score": 1,
          "created_utc": "2026-02-15 00:33:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5kcrg5",
              "author": "redNox394",
              "text": "Very nicely put. Completely agreed",
              "score": 1,
              "created_utc": "2026-02-15 20:13:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5jnc1l",
          "author": "JWPapi",
          "text": "Interesting framework. One thing I've noticed though is that prompt-level quality controls drift over time. The AI follows them sometimes, ignores them other times. We ended up encoding our quality standards as ESLint rules instead. If the output contains \"we're thrilled\" or \"don't hesitate to reach out\", it fails the build. Can't ignore a build failure. The lint error messages also feed back as context, so the AI starts self-correcting after a few rounds.",
          "score": 1,
          "created_utc": "2026-02-15 18:07:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kvnqd",
          "author": "Glittering-Body3504",
          "text": "i triied viral content ones , didnt do much reg the niche i asked for :(",
          "score": 1,
          "created_utc": "2026-02-15 21:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5as8l0",
          "author": "Federal-Candidate-20",
          "text": "Finally, my struggle to find the right prompt is over. Thanks for sharing with us, because prompts are important in AI generation across every field. I tried this prompt and it gave the best results, so I really appreciate this\n\n",
          "score": -3,
          "created_utc": "2026-02-14 06:15:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bap4w",
          "author": "Pythonix0",
          "text": "Exactly this is they key",
          "score": 0,
          "created_utc": "2026-02-14 09:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ddk11",
          "author": "SouthDevelopment9574",
          "text": "Following",
          "score": 0,
          "created_utc": "2026-02-14 17:33:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dmljo",
          "author": "Glum_East_754",
          "text": "By the time you have typed all this out or edited it to suit then you might as well just do it yourself.",
          "score": 0,
          "created_utc": "2026-02-14 18:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e8cr3",
          "author": "JamieBillingham",
          "text": "Itâ€™s a really common framework thatâ€™s been around for a long time. I use it regularly myself and have embedded it in several courses that Iâ€™ve designed. Thanks for sharing it again.",
          "score": 0,
          "created_utc": "2026-02-14 20:10:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5anx2q",
          "author": "TomLucidor",
          "text": "GitHub with a comprehensive breakdown on how this is different from everyone else, with every single design decisions outlined please",
          "score": -1,
          "created_utc": "2026-02-14 05:38:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5apu3n",
          "author": "ceeczar",
          "text": "Thanks for sharingÂ \n\n\nParticularly love how you spotted that annoying AI word *\"unlock\"*",
          "score": -1,
          "created_utc": "2026-02-14 05:54:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2t9wi",
      "title": "I told ChatGPT \"you're overthinking this\" and it gave me the simplest, most elegant solution I've ever seen",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r2t9wi/i_told_chatgpt_youre_overthinking_this_and_it/",
      "author": "AdCold1610",
      "created_utc": "2026-02-12 13:22:07",
      "score": 151,
      "num_comments": 43,
      "upvote_ratio": 0.82,
      "text": "Was debugging a messy nested loop situation. Asked ChatGPT for help.\n\nGot back 40 lines of code with three helper functions and a dictionary.\n\nMe: \"you're overthinking this\"\n\n**What happened next broke me:**\n\nIt responded with: \"You're right. Just use a set.\"\n\n*Gives me 3 lines of code that solved everything.*\n\nTHE AI WAS OVERCOMPLICATING ON PURPOSE??\n\n**Turns out this works everywhere:**\n\nPrompt: \"How do I optimize this database query?\" AI: *suggests rewriting entire schema, adding caching layers, implementing Redis* Me: \"you're overthinking this\"  \nAI: \"Fair point. Just add an index on the user\\_id column.\"\n\n**Why this is unhinged:**\n\nThe AI apparently has a \"show off mode\" where it flexes all its knowledge.\n\nTelling it \"you're overthinking\" switches it to \"actually solve the problem\" mode.\n\n**Other variations that work:**\n\n* \"Simpler.\"\n* \"That's too clever.\"\n* \"What's the boring solution?\"\n* \"Occam's razor this\"\n\n**The pattern I've noticed:**\n\nFirst answer = the AI trying to impress you After \"you're overthinking\" = the AI actually helping you\n\nIt's like when you ask a senior dev a question and they start explaining distributed systems when you just need to fix a typo.\n\n**Best part:**\n\nYou can use this recursively.\n\n*Gets complex solution* \"You're overthinking\" *Gets simpler solution*  \n\"Still overthinking\" *Gets the actual simple answer*\n\nI'm essentially coaching an AI to stop showing off and just help.\n\n**The realization that hurts:**\n\nHow many times have I implemented the overcomplicated solution because I thought \"well the AI suggested it so it must be the right way\"?\n\nThe AI doesn't always give you the BEST answer. It gives you the most IMPRESSIVE answer.\n\nUnless you explicitly tell it to chill.\n\n**Try this right now:** Ask ChatGPT something technical, then reply \"you're overthinking this\" to whatever it says.\n\nReport back because I need to know if I'm crazy or if this is actually a thing.\n\nHas anyone else been getting flexed on by their AI this whole time?\n\n[For more prompts ](https://www.beprompter.in).",
      "is_original_content": false,
      "link_flair_text": "Ideas & Collaboration",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r2t9wi/i_told_chatgpt_youre_overthinking_this_and_it/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o50catb",
          "author": "Shogun_killah",
          "text": "Gpt 5 has two thinking models\n- overthinking\n- jealous psycho girlfriend overthinking",
          "score": 29,
          "created_utc": "2026-02-12 16:55:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53zhgf",
              "author": "timbo2m",
              "text": "Gotta keep up those token counts fam",
              "score": 3,
              "created_utc": "2026-02-13 04:36:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o532h5c",
          "author": "rolkien29",
          "text": "This post is too complicated",
          "score": 14,
          "created_utc": "2026-02-13 01:06:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50tvc8",
          "author": "ValuableGrab3236",
          "text": "I ask it complicated questions then direct it to supply the answer in a way  that Homer Simpson could understand",
          "score": 11,
          "created_utc": "2026-02-12 18:17:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52uhrk",
              "author": "spvcejam",
              "text": "I just have it ELI5 and it seems to take into context that you aren't actually 5 and just explains it for idiots like me",
              "score": 3,
              "created_utc": "2026-02-13 00:20:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o52jupo",
              "author": "_gonzo_",
              "text": "This is the way",
              "score": 1,
              "created_utc": "2026-02-12 23:19:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50jh7h",
          "author": "RobinLocksly",
          "text": "That definitely works. It has multiple pathways in its latent space, and the first pass is basically mapping them all + giving the most common path even if it doesn't work or is unnecessarily complex. Once you ask an llm to simplify after it has searched it's 'mind'(database) for what connections *do* exist, then it has the connections there already and it's more about triage than it is about searching.",
          "score": 4,
          "created_utc": "2026-02-12 17:29:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53a4x4",
              "author": "MohutmaGandhi",
              "text": "any youtube video or source which will tell me how it takes the input and gives output ? \nor how actually these LLMs are made and how they perform",
              "score": 0,
              "created_utc": "2026-02-13 01:53:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54hw44",
                  "author": "Initunit",
                  "text": "Search for latent space.",
                  "score": 1,
                  "created_utc": "2026-02-13 07:03:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o51bxkq",
          "author": "JWPapi",
          "text": "This is actually a perfect example of why your input framing matters more than elaborate prompting techniques.\n\nThe word \"overthinking\" shifted the probability distribution toward simpler solutions. Single words early in the interaction can route the entire output trajectory.\n\nI've been calling this the Vibe Theory of Prompting - the model pattern-matches to the quality and style of your input. When you said \"overthinking,\" you gave it permission to reach for elegance instead of comprehensiveness.\n\nSame reason why a well-written spec with zero prompt engineering beats a sloppy spec with perfect prompting. The substance matters more than the technique.",
          "score": 3,
          "created_utc": "2026-02-12 19:42:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54zm8g",
          "author": "singh_taranjeet",
          "text": "Thereâ€™s actually a pretty boring explanation for this that makes it less sinister and more statistical.\n\nBy default, the model optimizes for completeness and coverage, not minimalism. So it reaches for the solution that handles edge cases, scales, and sounds production ready. That often looks like overengineering when all you needed was a set or an index.\n\nWhen you say â€œyouâ€™re overthinking,â€ youâ€™re not unlocking a secret mode. Youâ€™re changing the objective function. Youâ€™re signaling that simplicity > robustness > exhaustiveness. That shifts the distribution toward minimal solutions.\n\nItâ€™s less â€œshow off modeâ€ and more â€œI wasnâ€™t told to prefer boring.â€\n\nHonestly this is a great example of why constraints beat clever prompts. One sentence reframed the entire output trajectory.",
          "score": 3,
          "created_utc": "2026-02-13 09:48:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f11fa",
              "author": "nailedit888",
              "text": "This is gold",
              "score": 1,
              "created_utc": "2026-02-14 22:48:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ze4p2",
          "author": "PathStoneAnalytics",
          "text": "Vibe coding , my website right now and I know it's breaking the cod rules , but I find sometimes it's best to just simply tell. Delete the thing that we've been working on, then I come back with okay.I want you to build this thing to do this thing that I was trying to get you to do back there.But all I say is \"build this thing i'm trying to do. Do not use previous references from this chat to help you\" a lot of times they get stuck in a token loop where they are just trying to make something work with the token knowledge that they have.And once you clear those tokens away , they all of a sudden move way , smoother",
          "score": 6,
          "created_utc": "2026-02-12 14:08:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50jw15",
          "author": "aletheus_compendium",
          "text": "i like this. keep it simple! ðŸ™ŒðŸ» \ni saw someone suggest \"no yapping\" and that does marvels too ðŸ¤™ðŸ»",
          "score": 2,
          "created_utc": "2026-02-12 17:31:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51d4ma",
              "author": "AdCold1610",
              "text": "Yeh no yapping was also my post , yeah I have also have complex problems prompt also. I will share it in post ðŸ˜Š",
              "score": 3,
              "created_utc": "2026-02-12 19:48:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o59506y",
          "author": "ProfessionalPanic903",
          "text": "You're overthinking this.Â ",
          "score": 2,
          "created_utc": "2026-02-13 23:33:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zc4iu",
          "author": "-goldenboi69-",
          "text": "Yeah its kind of true. I usually realize that its trying to something way more complex and \"correct\" sometimes. Good thing im a 10x dev so its easy for me to ask for something simpler.",
          "score": 2,
          "created_utc": "2026-02-12 13:57:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o511691",
          "author": "skly_ai",
          "text": "This is real. I've noticed the same pattern. The first answer is the AI trying to impress you. The second answer, after a redirect, is the one that actually solves the problem. \n\n\"My boring solution?\" is my go-to version of this. Boring solutions ship faster.",
          "score": 1,
          "created_utc": "2026-02-12 18:51:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o515hz8",
          "author": "Greyhaven7",
          "text": "To be fair, â€œuse a Setâ€ is a fantastically simple solution to a bunch of computing problems, especially if youâ€™re using JavaScript. Theyâ€™re ordered iterables that cannot contain duplicate entries and have O(1) lookup times. Powerful data type.",
          "score": 1,
          "created_utc": "2026-02-12 19:12:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o534m1b",
          "author": "NecessarySpecific316",
          "text": "They are a product with one goal. To keep the customer engaged. The faster you get your answer. The faster you log off.",
          "score": 1,
          "created_utc": "2026-02-13 01:19:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53pq2a",
          "author": "Worth_Plastic5684",
          "text": "> Best part:\n\n> You can use this recursively.\n\n> Gets complex solution \"You're overthinking\" Gets simpler solution\n\n> \"Still overthinking\" Gets the actual simple answer\n\nFrom the people who brought you the Ralph Wiggum loop, it's the Buddha Loop",
          "score": 1,
          "created_utc": "2026-02-13 03:30:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53v1dk",
          "author": "Alert-Fee5079",
          "text": "I literally told it today that i didnâ€™t even read half of its responses because it went way too overboard",
          "score": 1,
          "created_utc": "2026-02-13 04:06:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o595atk",
          "author": "littlemissperf",
          "text": "Zero-effort AI post. Probably didn't happen",
          "score": 1,
          "created_utc": "2026-02-13 23:34:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59x9h8",
          "author": "derpingthederps",
          "text": "Sometimes, yes. \n\nI've also been annoyed quite often by how it seems to always ignore my requests.\nA lot of what I use it for is very small scripts or build a dirty poc of an idea.\n\n>Ask it to add a basic function/addition to something\n>Includes lots of extra bull crap and comments\n\nGPT I asked you to add those 10 lines because I'm lazy and don't want to read the documentation, not because I wanted you to add 30 extra lines and redesign my script. \n\nAND STOP TELLING ME \"Just change this and it will be fixedðŸ‘\"\n\nSometimes LLM's are a blessing, solving an issue that night takes me hours to troubleshoot alone.\n\nOther times, it would've been better off me just doing the damn job myself.\n\nEither way, it's a love hate relationship we have.",
          "score": 1,
          "created_utc": "2026-02-14 02:27:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ac64i",
          "author": "zumera",
          "text": "Why didnâ€™t you write the post yourself?Â ",
          "score": 1,
          "created_utc": "2026-02-14 04:08:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bxgsf",
          "author": "Sharpieface",
          "text": "Have you tested results comparing the quality of outputs if you include â€œDonâ€™t overthinkâ€ in the first prompt vs saying it after the first prompt is already generated?",
          "score": 1,
          "created_utc": "2026-02-14 12:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hwenq",
          "author": "dankiboiis",
          "text": "Bros typing like he's posting on linked in",
          "score": 1,
          "created_utc": "2026-02-15 12:22:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5odmsv",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-16 13:09:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5odmwg",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-16 13:09:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6ugif",
      "title": "That Brutally Honest AI CEO Tweet + 5 Prompts That'll Actually Make You Better at Your Job",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r6ugif/that_brutally_honest_ai_ceo_tweet_5_prompts/",
      "author": "EQ4C",
      "created_utc": "2026-02-17 02:58:23",
      "score": 105,
      "num_comments": 23,
      "upvote_ratio": 0.81,
      "text": "So Dax Raad from anoma just posted what might be the most honest take on AI in the workplace I've seen all year. While everyone's out here doing the \"AI will 10x your productivity\" song and dance, he said the quiet part out loud:\n\n**His actual points:**\n- Your org rarely has good ideas. Ideas being expensive to implement was actually a feature, not a bug\n- Most workers want to clock in, clock out, and live their lives (shocker, I know)\n- They're not using AI to be 10x more effectiveâ€”they're using it to phone it in with less effort\n- The 2 people who actually give a damn are drowning in slop code and about to rage quit\n- You're still bottlenecked by bureaucracy even when the code ships faster\n- Your CFO is having a meltdown over $2000/month in LLM bills per engineer\n\n**Here's the thing though:** He's right about the problem, but wrong if he thinks AI is useless.\n\nThe real issue? Most people are using AI like a fancy autocomplete instead of actually thinking. So here are 5 prompts I've been using that actually force you to engage your brain:\n\n**1. The Anti-Slop Prompt**\n\n> \"Review this code/document I'm about to write. Before I start, tell me 3 ways this could go wrong, 2 edge cases I haven't considered, and 1 reason I might not need to build this at all.\"\n\n**2. The Idea Filter**\n\n> \"I want to build [thing]. Assume I'm wrong. Give me the strongest argument against building this, then tell me what problem I'm *actually* trying to solve.\"\n\n**3. The Reality Check**\n\n> \"Here's my plan: [plan]. Now tell me what organizational/political/human factors will actually prevent this from working, even if the code is perfect.\"\n\n**4. The Energy Auditor**\n\n> \"I'm about to spend 10 hours on [task]. Is this genuinely important, or am I avoiding something harder? What's the 80/20 version of this?\"\n\n**5. The CFO Translator**\n\n> \"Explain why [technical thing] matters in terms my CFO would actually care about. No jargon. Just business impact.\"\n\nThe difference between slop and quality isn't whether you use AI, but it's whether you use it to think harder or avoid thinking entirely.\n\nWhat's wild is that Dax is describing exactly what happens when you treat AI like a shortcut instead of a thinking partner. The good devs quit because they're the only ones who understand the difference.\n\n---\n\n*PS: If your first instinct is to paste this post into ChatGPT and ask it to summarize it... you're part of the problem lmao*\n\nFor expert prompts visit our free [mega-prompts collection](https://tools.eq4c.com/)",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r6ugif/that_brutally_honest_ai_ceo_tweet_5_prompts/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5uihb6",
          "author": "Impossible-Bat-6713",
          "text": "Hereâ€™s the challenge with simple prompts- They rarely work beyond the context window. \n\nAny serious code base will have UX, business logic, connected applications and DB layer. Unless you connect all of these layers and provide full context of data flow,  your code generated with be limited to your repo and will not be optimized for complex systems.\n\nThe moment you have a workflow, thereâ€™s a whole lot of complexity, input data classification/ cleansing/ labeling, optimized prompts, evals for validating output and downstream integrations across environments not to mention reliability, security and performance constraints.\n\nThis level of complexity cannot be dealt with simple prompts. Needs a far deeper understanding of systems architecture and design.",
          "score": 11,
          "created_utc": "2026-02-17 11:11:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ygms3",
              "author": "HeathersZen",
              "text": "Isnâ€™t that what project rules are for?",
              "score": 1,
              "created_utc": "2026-02-17 23:33:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5z1hyu",
                  "author": "Impossible-Bat-6713",
                  "text": "Project specific rules typically cover standards / patterns specific to your project but will not deal with larger systemic constraints and architectural trade offs outside it.",
                  "score": 1,
                  "created_utc": "2026-02-18 01:27:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62hun8",
              "author": "Kiran_Baby",
              "text": "How  to get an basic understanding of systems architecture and design, any youtube suggestions or topic related URLs ",
              "score": 1,
              "created_utc": "2026-02-18 15:36:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ul3mp",
          "author": "Savings-Giraffe-4007",
          "text": "\"AI, you always know better even when you allucinate and spew factually wrong BS\"\n\n\nSounds like prompting for junior devs trying to prove they suck and can be replaced",
          "score": 4,
          "created_utc": "2026-02-17 11:33:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w0y15",
          "author": "myeleventhreddit",
          "text": "You're doing what no AI can. \n\nTaking someone else's insights, re-packaging with a numbered list, and selling your own collection at the end--all while insulting the people who want to summarize derivative text walls to save time. well-played.",
          "score": 3,
          "created_utc": "2026-02-17 16:29:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uctgc",
          "author": "lioninside_",
          "text": "Thx for sharing. I see already a \"anti hype\" with people saying/writing \"AI is (also) just a tool\". I don't fully agree on this too as it underestimates to power of AI (to change society)",
          "score": 2,
          "created_utc": "2026-02-17 10:20:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w9lxy",
          "author": "amaturelawyer",
          "text": "While I know OP is shilling some worthless prompt site, and I hate him for it as much as everyone else, and I noticed that his bot accounts fucked up in the \"generate apparent engagement by other users\" code with \"[](https://www.reddit.com/user/IndependentClock7184/)\n\n[IndependentClock7184 ](https://www.reddit.com/user/IndependentClock7184/)\n\nâ€¢ [14h ago](https://www.reddit.com/r/PromptEngineering/comments/1r6ugif/comment/o5svzd1/)\n\nWould you be willing to check out my post\n\n[](https://www.reddit.com/user/EQ4C/)OP â€¢ [14h ago](https://www.reddit.com/r/PromptEngineering/comments/1r6ugif/comment/o5sw7sz/)\n\n Sure, thanks\n\n\", I'm still going to answer because I feel like it and this is still sort of a free society or whatever.\n\n\n\nIn general, I find it more helpful to explain what the desired end state is than to explain the plan or incremental steps to get there, and it's always helpful to tell it to not make any assumptions and ask if something is ambiguous or unclear with how you stated it. \n\n\n\n\\#4 seems likely to not work well. The AI knows exactly one thing about the importance of the task, that you are trying to do it: you're attempting to do it. Without feeding a crapload of context in, that question can only result in a guess, as time investment is a relative thing and needs to be compared to what else it could be spent on. If it's this or playing solitare for 10 hours, seems worth it if the end result is you save $100 over the year, but if it's this or fixing a bug that's delaying shipping and this is a project that reminds you to take breaks every hour, it's probably not as important.\n\n  \nThe one I have a large problem with is #5, and OP's LLM should be examined for evidence that it's been self-modifying weights, because it's literally an insane point. Why the fuck would you ask an LLM to write out how you should make your case to a CFO and say \"no jargon\"? The only thing most C-suite placeholders speak in is jargon.",
          "score": 2,
          "created_utc": "2026-02-17 17:13:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uzl20",
          "author": "Gynnia",
          "text": "but have these been genuinely helpful in real-life scenarios?",
          "score": 1,
          "created_utc": "2026-02-17 13:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5svzd1",
          "author": "IndependentClock7184",
          "text": "Would you be willing to check out my post",
          "score": 0,
          "created_utc": "2026-02-17 03:07:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5sw7sz",
              "author": "EQ4C",
              "text": "Sure, thanks",
              "score": -2,
              "created_utc": "2026-02-17 03:08:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u0v8t",
          "author": "AgenticAF",
          "text": "Thanks for sharing this!",
          "score": -1,
          "created_utc": "2026-02-17 08:26:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tfu2r",
          "author": "ceeczar",
          "text": ">when you treat AI like a shortcut instead of a thinking partner.Â \n\n\nThanks for sharingÂ \n\n\nIndeed the AI hype can be wild.Â \n\n\nEspecially on YouTube\n\n\nSpeaking of shortcuts, do we really need AI to do the energy audit you mention in Prompt 4?",
          "score": -2,
          "created_utc": "2026-02-17 05:23:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5u1zhr",
              "author": "traumfisch",
              "text": "you can just go\n\n\nWhat's the 80/20 version of this?\n\n\nabout anything, no?",
              "score": 2,
              "created_utc": "2026-02-17 08:37:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5thb1m",
              "author": "Weekly-Bee-5045",
              "text": "After destroying many projects nearing completion... I can say yes 4 is good. ðŸ‘",
              "score": -1,
              "created_utc": "2026-02-17 05:34:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5uv7a",
      "title": "One day of work + Opus 4.6 = Voice Cloning App using Qwen TTS. Free app, No Sing Up Required",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r5uv7a/one_day_of_work_opus_46_voice_cloning_app_using/",
      "author": "OneMoreSuperUser",
      "created_utc": "2026-02-16 00:28:10",
      "score": 59,
      "num_comments": 10,
      "upvote_ratio": 0.93,
      "text": "A few days ago, Qwen released a new open weight speech-to-speech model: Qwen3-TTS-12Hz-0.6B-Base. It is great model but it's huge and hard to run on any current regular laptop or PC so I built a free web service so people can check the model and see how it works.\n\n* No registration required\n* Free to use\n* Up to 500 characters per conversion\n* Upload a voice sample + enter text, and it generates cloned speech\n\nHonestly, the quality is surprisingly good for a 0.6B model.\n\nModel: Qwen3-TTS\n\nWeb app where you can text the model for free:\n\n[https://imiteo.com](https://imiteo.com/)\n\nSupports 10 major languages: English, Chinese, Japanese, Korean, German, French, Russian, Portuguese, Spanish, and Italian.\n\nIt runs on an NVIDIA L4 GPU, and the app also shows conversion time + useful generation stats.\n\nThe app is 100% is written by Claude Code 4.6. Done in 1 day.\n\nOpus 4.6, Cloudflare workers, L4 GPU\n\nMy twitter account: [https://x.com/AndreyNovikoov](https://x.com/AndreyNovikoov)",
      "is_original_content": false,
      "link_flair_text": "Self-Promotion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r5uv7a/one_day_of_work_opus_46_voice_cloning_app_using/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5myb43",
          "author": "Hippolithe",
          "text": "Actually, singing up to a voice app sounds somewhat appropriate.",
          "score": 11,
          "created_utc": "2026-02-16 05:43:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m8fdi",
          "author": "throwaway867530691",
          "text": "I'm a bit worried about my voice signature getting stolen and my grandma getting called by a bot asking for $5000 in my voice. I'm totally misunderstanding the risks here right?",
          "score": 6,
          "created_utc": "2026-02-16 02:39:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5m91lr",
              "author": "OneMoreSuperUser",
              "text": "Itâ€™s open-source technology, and anyone has been able to do it for the last two years. Yes, itâ€™s crazyâ€”but thatâ€™s the world weâ€™re living in.",
              "score": 1,
              "created_utc": "2026-02-16 02:43:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5mdzk2",
                  "author": "throwaway867530691",
                  "text": "I suppose it's the concern over my specific voice data being tied to me as a result of using a particular \"clone your voice\" app",
                  "score": 3,
                  "created_utc": "2026-02-16 03:15:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5qxc62",
          "author": "-Nano",
          "text": "Question: Brazilian Portuguese or ~~Archaic~~ European Portuguese?\n\nWill opensource it?",
          "score": 1,
          "created_utc": "2026-02-16 20:38:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4g0qs",
      "title": "The \"write like [X]\" prompt is actually a cheat code and nobody talks about it",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r4g0qs/the_write_like_x_prompt_is_actually_a_cheat_code/",
      "author": "AdCold1610",
      "created_utc": "2026-02-14 09:05:27",
      "score": 53,
      "num_comments": 13,
      "upvote_ratio": 0.83,
      "text": "I've been testing this for weeks and it's genuinely unfair how well it works.\n\n**The technique:**\n\nInstead of describing what you want, just reference something that already exists.\n\n\"Write like \\[company/person/style\\] would\"\n\n**Why this breaks everything:**\n\nThe AI has already ingested thousands of examples of whatever you're referencing. You're not teaching it - you're just pointing.\n\n**Examples that made me rethink prompting:**\n\nâŒ \"Write a technical blog post that's accessible but thorough with good examples and clear explanations\"\n\nâœ… \"Write this like a Stripe engineering blog post\"\n\nThe second one INSTANTLY nails the tone, structure, depth level, and example quality because the AI already knows what Stripe posts look like.\n\n**Where this goes crazy:**\n\nCode:\n\n* \"Write this like it's from the Airbnb style guide\" â†’ clean, documented, consistent\n* \"Code this like a senior at Google would\" â†’ enterprise patterns, error handling\n\nWriting:\n\n* \"Explain this like Paul Graham would\" â†’ essay format, clear thinking\n* \"Write like it's a Basecamp blog post\" â†’ opinionated, straightforward\n\nDesign:\n\n* \"Describe this UI like Linear would build it\" â†’ minimal, functional, fast\n\n**The pattern I discovered:**\n\nVague description = AI guesses Specific reference = AI knows exactly what you mean\n\n**This even works for tone:**\n\n* \"Reply to this customer like Chewy would\" â†’ empathetic, helpful, human\n* \"Handle this complaint like Amazon support would\" â†’ efficient, solution-focused\n\n**The meta-realization:**\n\nEvery time you write a detailed prompt describing style, tone, format, depth level... you're doing it the hard way.\n\nSomeone already wrote/coded/designed in that style. Just reference them.\n\n**The recursive trick:**\n\nFirst output: \"Write this like \\[X\\]\" Second output: \"Now write the same thing like \\[Y\\]\"\n\nInstant A/B test of different approaches.\n\n**Real test I ran:**\n\nSame product description:\n\n* \"Like Apple would write it\" â†’ emotional, aspirational, simple\n* \"Like a spec sheet\" â†’ technical, detailed, feature-focused\n* \"Like Dollar Shave Club would\" â†’ funny, irreverent, casual\n\nThree completely different angles. Zero effort to explain what I wanted.\n\n**Why nobody talks about this:**\n\nBecause it feels too simple? Too obvious?\n\nBut I've seen people write 200-word prompts trying to describe a style when they could've just said \"write it like \\[brand that already does this perfectly\\].\"\n\n\n\n**Test this right now:**\n\nTake whatever you last asked AI to write. Redo the prompt as \"write this like \\[relevant example\\] would.\"\n\nCompare the outputs.\n\nWhat references have you found that consistently work?\n\n[for more post](http://beprompter.in)",
      "is_original_content": false,
      "link_flair_text": "Ideas & Collaboration",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r4g0qs/the_write_like_x_prompt_is_actually_a_cheat_code/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5bf04u",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-02-14 09:51:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bni6c",
              "author": "N0tN0w0k",
              "text": "I donâ€™t think thatâ€™s exactly the same thing as OP is referring, I would suggest giving each of these separate attention\n\nRole = persona > from whoâ€™s perspective is the output written?\n\nTarget = audience > whoâ€™s the output meant for?\n\nStyle exampleâ€™s(OPâ€™s post) = tone mostly and a bit of formatting > what does the output look/sound like?",
              "score": 2,
              "created_utc": "2026-02-14 11:14:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bz2x8",
          "author": "roger_ducky",
          "text": "Specific references are good when the model knows about it.\n\nLike a spec sheet will probably work but wonâ€™t give a consistent style.",
          "score": 1,
          "created_utc": "2026-02-14 12:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c8a24",
          "author": "Cuaternion",
          "text": "The above seems to work as long as you know the references.",
          "score": 1,
          "created_utc": "2026-02-14 13:53:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f16mh",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-14 22:49:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f16oc",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-14 22:49:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hvzw5",
          "author": "Noophyd",
          "text": "You can also point to blogpost and say write like here",
          "score": 1,
          "created_utc": "2026-02-15 12:18:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mvbn4",
          "author": "ceeczar",
          "text": "Thanks for sharingÂ \n\n\nBut doesn't that mean you must already have an idea of the relevant example?\n\n\nWhat if you're working in a new domain or industry where you're not sure who are the relevant examples to model?",
          "score": 1,
          "created_utc": "2026-02-16 05:19:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5us7ex",
              "author": "Kwontum7",
              "text": "Google it maybe?",
              "score": 1,
              "created_utc": "2026-02-17 12:26:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d5a4t",
          "author": "Kwontum7",
          "text": "I made a custom GPT with materials sourced from Steve Jobs. I discuss multiple business topics with it.",
          "score": 0,
          "created_utc": "2026-02-14 16:51:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5q73o9",
              "author": "meridian_dan123",
              "text": "Sounds interesting! Using a model trained on Steve Jobs could really give you insights into business philosophy. What kind of topics do you find it excels at discussing?",
              "score": 1,
              "created_utc": "2026-02-16 18:32:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5us3f3",
                  "author": "Kwontum7",
                  "text": "Product design, user experience, and business model. I don't take anything it says on face value, so I don't always agree. The dialogue is helpful because it usually presents an interesting perspective at the least. \n\nLoL I have to remind it that I don't have billions of dollars sometimes and stick to bootstrapping strategies.",
                  "score": 1,
                  "created_utc": "2026-02-17 12:26:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r5l0dz",
      "title": "Instead of prompt engineering AI to write better copy, we lint for it",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r5l0dz/instead_of_prompt_engineering_ai_to_write_better/",
      "author": "JWPapi",
      "created_utc": "2026-02-15 17:50:31",
      "score": 43,
      "num_comments": 25,
      "upvote_ratio": 0.95,
      "text": "We spent a while trying to prompt engineer our way to better AI-generated emails and UI code. Adding instructions like \"don't use corporate language\" and \"use our design system tokens instead of raw Tailwind colors\" to system prompts and CLAUDE.md files. It worked sometimes. It didn't work reliably.\n\nThen we realized we were solving this problem at the wrong layer. Prompting is a suggestion. A lint rule is a wall. The AI can ignore your prompt instructions. It cannot ship code that fails the build.\n\nSo we wrote four ESLint rules:\n\nhumanize-email maintains a growing ban list of AI phrases. \"We're thrilled\", \"don't hesitate\", \"groundbreaking\", \"seamless\", \"delve\", \"leveraging\", all of it. The list came from Wikipedia's \"Signs of AI writing\" page plus every phrase we caught in our own outbound emails after it had already shipped to customers. The rule also enforces which email layout component to use and limits em dashes to 2 per file.\n\nprefer-semantic-classes bans raw Tailwind color classes (bg-gray-100, text-zinc-500) and forces semantic design tokens (surface-primary, text-secondary). AI models don't know your design system. They know Tailwind defaults. This rule makes the AI's default impossible to ship.\n\ntypographic-quotes auto-fixes mixed quote styles in JSX. Small but it catches the inconsistency between AI output and human-typed text.\n\nno-hover-translate blocks hover:-translate-y-1 which AI puts on every card. It causes a jittery chase effect when users approach from below because translate moves the hit area.\n\nHere's the part that's relevant to this community: the error messages from these rules become context for the AI in the next generation. So the lint rules are effectively prompt engineering, just enforced at build time instead of suggested at generation time. After a few rounds of hitting the lint wall, the AI starts avoiding the patterns on its own.\n\nIf you keep correcting the same things in AI output, don't write a better prompt. Write a lint rule. Your standards compound over time as the ban list grows. Prompts drift.\n\nFull writeup: https://jw.hn/eslint-copy-design-quality",
      "is_original_content": false,
      "link_flair_text": "Tips and Tricks",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r5l0dz/instead_of_prompt_engineering_ai_to_write_better/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5jslls",
          "author": "mrpoopybruh",
          "text": "I also have a thread just for a verification agent that looks over work ONLY, and turns into a complete and angry psycho. 10/10 would reccomend.",
          "score": 3,
          "created_utc": "2026-02-15 18:33:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5koumg",
          "author": "Too_Bad_Bout_That",
          "text": " Why do you say that AI can ignore prompt instructions?  \n",
          "score": 1,
          "created_utc": "2026-02-15 21:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5kuo42",
              "author": "[deleted]",
              "text": "LLM can ignore anything you tell them to do, they are simply next word probability predictors. As instructions get longer the chances of AI \"ignoring\" rules grows as they have to comply with more rules which they did not really understand.",
              "score": 2,
              "created_utc": "2026-02-15 21:45:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5kyw00",
                  "author": "Too_Bad_Bout_That",
                  "text": "I can think of only 2 reasons for that to happen, 1 - task can have something illegal, unsafe in it or 2, prompts can be very ill-structured. \n\nThe way AI works is that it scans the prompt and searches for details like task, context, style and etc. Sometimes task can be unclear for it so it might miss that. Try to divide prompt with headings and chapters like:\n\n\\#Task:  \nYour job is to...\n\nSo far it has been working for me",
                  "score": -2,
                  "created_utc": "2026-02-15 22:07:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5mzcx0",
              "author": "awittygamertag",
              "text": "It can. Small models do it when the instructions are confusing and Opus 4.6 ignores them when it thinks youâ€™re wrong. Take your pick of the poison lol",
              "score": 1,
              "created_utc": "2026-02-16 05:52:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o601yas",
              "author": "AxeSlash",
              "text": "There are many, many reasons an LLM can ignore an instruction. IMHO the biggest is recency bias.\n\nInstructions are usually sent at the top of the request's context (which seems like a design flaw to me but then again I'm no AI dev) ,which means that the last user prompt can have more influence than the instructions, especially if context is long.\n\nPoorly written instructions are another big one.\n\nNEVER trust an LLM to adhere 100% to your instruction set. That way lies downstream carnage. These things are NOT deterministic.",
              "score": 1,
              "created_utc": "2026-02-18 05:01:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5n0ofm",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-16 06:03:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5n0ogz",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-16 06:03:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5mnub2",
          "author": "chkbd1102",
          "text": "i like the idea. but i think the biggest hurdle will be this\n\ni generate a text, linter give me back error A, the AI read it and regenrate. it can come back with error B. it fix error B, but regenrate the whole text again.\n\ni could easily foresee creating an umlimited cycle, just like working with coding agent.",
          "score": 0,
          "created_utc": "2026-02-16 04:24:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nbn5p",
              "author": "susimposter6969",
              "text": "Perhaps only patch the sentence containing the issue",
              "score": 1,
              "created_utc": "2026-02-16 07:41:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r689sl",
      "title": "If your prompt is 12 pages long, you don't have a 'Super Prompt'. You have a Token Dilution problem.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r689sl/if_your_prompt_is_12_pages_long_you_dont_have_a/",
      "author": "GetAIBoostKit",
      "created_utc": "2026-02-16 12:25:19",
      "score": 41,
      "num_comments": 33,
      "upvote_ratio": 0.87,
      "text": "Someone commented on my last post saying my prompts were 'bad' because theirs are 12 pages long.\n\nLet's talk about **Attention Mechanism** in LLMs. When you feed a model 12 pages of instructions for a simple task, you are diluting the weight of every single constraint. The model inevitably hallucinates or ignores the middle instructions.\n\nI use the **RPC+F Framework** precisely to avoid this.\n\n* **12 Pages:** The model 'forgets' instructions A, B, and C to focus on Z.\n* **3 Paragraphs (Architected):** The model has nowhere to hide. Every constraint is weighted heavily.\n\nStop confusing 'quantity' with 'engineering'. Efficiency is about getting the result with the *minimum* effective dose of tokens.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r689sl/if_your_prompt_is_12_pages_long_you_dont_have_a/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5oalhh",
          "author": "EpsteinFile_01",
          "text": "The model loses track after 1 page lol, ignoring things and/or addressing things briefer and briefer. Who the hell feeds 12 pages of instructions?",
          "score": 3,
          "created_utc": "2026-02-16 12:49:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oca8u",
              "author": "Doppelgen",
              "text": "Me. I have done more than once, they describe entire dynamics (such as how a game works, from overall understanding to actual clicks).",
              "score": 3,
              "created_utc": "2026-02-16 13:00:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5qnxes",
                  "author": "vayana",
                  "text": "I'm trying this in a current project. Usually just build and not use any documentation outside of a prompt, but spent the last 2 days scaffolding and preparing documentation with instructions, guides and rules with 1 entry file and about 15 documents the agent can discover. I'm curious to see if this will speed up the building phase once it gets going.",
                  "score": 1,
                  "created_utc": "2026-02-16 19:51:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ob9zz",
          "author": "kyngston",
          "text": "simple.  refactor your spec for progressive discovery all starting from the top level README.md.  \n\nthen write you spec as a TODO file and implement with an agent swarm.",
          "score": 3,
          "created_utc": "2026-02-16 12:53:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ub7rf",
              "author": "GetAIBoostKit",
              "text": "Progressive discovery is the right move for complex specs, but the 'Agent Swarm' approach often hits a wall when the agents start interpreting the README differently.\n\nThatâ€™s where Iâ€™ve found the most success with the **RPC+F framework**. Instead of just a TODO file, I use the framework to set **global architectural constraints** that every agent in the swarm must follow.\n\nIf you don't anchor the 'swarm' with strict **Negative Constraints**, the progressive discovery phase usually turns into a game of telephone between the agents.\n\nI'm curiousâ€”how do you handle logic drift when the agents move from the top-level README to the deeper implementation files?",
              "score": 1,
              "created_utc": "2026-02-17 10:05:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ozmtk",
          "author": "UsualOk3244",
          "text": "I once made a complex Agent for Finance... And boy even a full page of aspects the AI had to be aware of was too much. It was like after point 4 it forgot which restrictions point 1 gave.",
          "score": 2,
          "created_utc": "2026-02-16 15:09:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ubc8h",
              "author": "GetAIBoostKit",
              "text": "Thatâ€™s the exact limit of 'instruction-based' prompting. Once the context window gets crowded, the AIâ€™s attention fragments and it starts dropping early restrictions.\n\nThis is why I stopped writing long lists and switched to the **RPC+F framework**. Instead of just giving it points to remember, I use **Architectural Constraints** to lock the logic in place so it can't drift.\n\nItâ€™s the only way Iâ€™ve found to keep finance or coding agents consistent without them 'forgetting' point #1 by the time they hit point #4. Happy to show you the structure if you're tired of the AI amnesia.",
              "score": 2,
              "created_utc": "2026-02-17 10:06:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5udrci",
                  "author": "UsualOk3244",
                  "text": ">Happy to show you the structure if you're tired of the AI amnesia.\n\nI take everything I can get as long if you don't want me to pay or join a group ðŸ˜‚",
                  "score": 1,
                  "created_utc": "2026-02-17 10:29:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pzgle",
          "author": "Admirable-Corner-479",
          "text": "Read that as \"Tolkien Dilution\" ðŸ¤”",
          "score": 2,
          "created_utc": "2026-02-16 17:57:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qyvgf",
              "author": "Wizard_Biscuit",
              "text": "Try to keep your movies to 3 hours or less. Maximum of 4 hobbits on screen at once unless vital for world building.",
              "score": 2,
              "created_utc": "2026-02-16 20:45:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5s7bz7",
          "author": "PromptForge-store",
          "text": "I agree with the basic idea â€“ length alone doesn't make a prompt better.\n\n\nBut the real issue isn't length vs. brevity, it's architecture.\n\nA long, unstructured prompt creates dilution.\n\nA structured prompt â€“ even if it's longer â€“ creates clarity.\n\n\nThe difference is whether the prompt is just a loose instruction or a reusable system with clear roles, inputs, constraints, and output logic.\n\n\nI've seen short prompts outperform long ones â€“ but also structured, multi-part prompts that deliver significantly more consistent results.\n\n\nThe key isn't to minimize tokens, but to maximize the signal per token.\n\nThis is where prompting transitions from writing to system design.",
          "score": 2,
          "created_utc": "2026-02-17 00:39:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tuvra",
          "author": "NefariousnessFun1445",
          "text": "the general point about shorter prompts is fine but the reasoning is wrong. attention mechanism doesnt work the way youre describing here. the model doesnt \"forget\" instructions because theyre diluted by length - the actual issue is that with longer contexts the model struggles to attend equally to all parts, especially the middle (lost in the middle problem). thats not the same as \"weight dilution\"\n\nalso 12 pages vs 3 paragraphs is a false dichotomy. system prompts for production agents are regularly 2-3 pages and work perfectly fine when structured well. the problem is never length itself, its ambiguity and contradiction. a 3 paragraph prompt full of vague instructions will perform worse than a 2 page prompt with clear structured sections every time\n\nnot familiar with RPC+F but any framework that says \"just make it shorter\" as its core principle is oversimplifying. sometimes you need detailed instructions, edge case handling, output format specs, examples. trying to cram all that into 3 paragraphs for a complex task will hurt your results not help them",
          "score": 2,
          "created_utc": "2026-02-17 07:30:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uboj1",
              "author": "GetAIBoostKit",
              "text": "Youâ€™re absolutely right on the terminologyâ€”'Lost in the middle' is the more accurate technical description of the attention decay in long context windows. Thanks for the correction.\n\nHowever, the **RPC+F framework** isn't about 'making it shorter' for the sake of brevity. Itâ€™s about **structural density**.\n\nThe problem with 12-page (or even 3-page) prompts often isn't the length, but the **instruction-to-logic ratio**. Most people fill those pages with 'fluff' instructions that create ambiguity.\n\nI use **Negative Constraints** within RPC+F to handle those edge cases you mentioned, but I do it by defining what the model *cannot* do, which effectively 'compresses' the logic space without losing the detail.\n\nA well-structured 2-page prompt is great, but an architected RPC+F prompt usually achieves the same guardrails with far less surface area for the model to hallucinate in. Itâ€™s not about oversimplifying; itâ€™s about **removing the noise** so the instructions actually stick.",
              "score": 1,
              "created_utc": "2026-02-17 10:10:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5odpbn",
          "author": "-goldenboi69-",
          "text": "The way â€œprompt engineeringâ€ gets discussed often feels like a placeholder for several different problems at once. Sometimes itâ€™s about interface limitations, sometimes about steering stochastic systems, and sometimes about compensating for missing tooling or memory. As models improve, some of that work clearly gets absorbed into the system, but some of it just shifts layers rather than disappearing. Itâ€™s hard to tell whether prompt engineering is a temporary crutch or an emergent skill that only looks fragile because we havenâ€™t stabilized the abstractions yet.",
          "score": 1,
          "created_utc": "2026-02-16 13:09:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5osq8d",
              "author": "slartybartvart",
              "text": "Given my kids have an extremely small context window and forget prompts even when repeated, I'd say it's an emergent skill.",
              "score": 1,
              "created_utc": "2026-02-16 14:33:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5uaxyr",
              "author": "GetAIBoostKit",
              "text": "This is the most lucid take Iâ€™ve seen in a while. You hit the nail on the head with the 'stabilizing abstractions' part.\n\nRight now, most 'prompting' is indeed a temporary crutch because people treat LLMs like search engines or magic boxes. But as models get more powerful, the 'steering' doesn't disappearâ€”it just moves from **instruction-following** (telling it what to do) to **architectural constraints** (defining the logic boundaries).\n\nThatâ€™s exactly why I moved away from long, fluffy prompts to the **RPC+F framework**. Itâ€™s less about 'tricking' the model and more about providing the stable logic layer it lacks.\n\nAs systems improve, the 'crutch' will break, but the ability to architect strict constraints will be the skill that actually scales. Happy to share some of the logic-based templates Iâ€™ve been building if you want to see how Iâ€™m trying to solve that 'stochastic' steering problem.",
              "score": 1,
              "created_utc": "2026-02-17 10:03:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5oqxfk",
          "author": "Ok-Buffalo2900",
          "text": "What is an RPC+F Framework?",
          "score": 1,
          "created_utc": "2026-02-16 14:24:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qrzds",
              "author": "Fearless_Parking_436",
              "text": "The classic Role Purpose Context and add filters. Usually as negatives but may also be data format or whatever. \"Output as.csv with these headers\" \"NO letter a in response\" \"Only use data in this file\"  \n\nThere are some quirks where llm escapes the soft limit to give an answer/better answer. Like if it knows more than there is in file it has to use then it may juat answer the question because it's a little bitch that wants to please you. But usually for most easier tasks it works.",
              "score": 1,
              "created_utc": "2026-02-16 20:11:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ubgy2",
              "author": "GetAIBoostKit",
              "text": "It stands for **Role, Purpose, Context + Format**.\n\nMost people just dump instructions. **RPC+F** is an architectural approach to 'box' the modelâ€™s logic so it doesn't drift or get lazy.\n\nThe 'secret sauce' is the **Format** block, where I use **Negative Constraints** to explicitly tell the AI what NOT to do (like making assumptions or using conversational filler).\n\nItâ€™s the difference between giving someone a massive manual (and hoping they read it) and giving them a strict checklist they canâ€™t ignore. I have a breakdown of how it works and some templates pinned on my profile if you want to see it in action.",
              "score": 1,
              "created_utc": "2026-02-17 10:08:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5p22dy",
          "author": "Environmental_Lie199",
          "text": "I'm a noob to this so please pardon the ignorance. \n\nIsn't it better at this point to have a single LLM trained with knowledge base and then ask for ongoing questions?\nThis way, one steers the model to give answers and has a reasonable space to rearrange things if it starts hallucinating. \n\nI've tried this myself with a few different models for different type of desired scenarios/outcomes and has proven far better with more accurate answers than binge feeding the poor thing with huge prompts.",
          "score": 1,
          "created_utc": "2026-02-16 15:21:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ubkle",
              "author": "GetAIBoostKit",
              "text": "Youâ€™re 100% right about 'binge feeding' promptsâ€”thatâ€™s exactly what leads to hallucinations and logic drift.\n\nHowever, even with a trained knowledge base, the model still needs a 'steering wheel'. Without a framework like **RPC+F**, the model might have the right data but still present it with a 'vibe' thatâ€™s too conversational or structurally loose.\n\nI use **Negative Constraints** as that steering wheel: it tells the model *how* to process its knowledge base without adding more 'weight' to the prompt. Itâ€™s not about more info; itâ€™s about stricter logic.\n\nI actually have a visual comparison of how this works even in small-scale queries pinned on my profile if you want to see the difference.",
              "score": 2,
              "created_utc": "2026-02-17 10:09:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5wehmp",
                  "author": "Environmental_Lie199",
                  "text": "Agree. Most of my use cases I will tell it what to do, how to deliver, what I expect overall and also what NOT to do, use, say or what isnt an acceptable answer. So far so good really ;))",
                  "score": 1,
                  "created_utc": "2026-02-17 17:36:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5zrpwl",
          "author": "AxeSlash",
          "text": "This is a false headline. Structure and quality are WAY more important than length.\n\n12 pages of structured, well-written instructions is going to outperform 6 pages of brain-fart every single time.\n\nAnd that's before we get to tasks that physically can't be done with short instructions. Sometimes, you just have to be specific, and being less so results in a worse output.\n\nWhat length your instructions need to be will depend on the task, the model, and the input. There's no magic number.\n\nAlso, define a \"page\" if you're going to insist on using it as a unit of length. Most of us use tokens or characters.",
          "score": 1,
          "created_utc": "2026-02-18 03:52:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3hazy",
      "title": "7-Phase Prompt Pattern for Deep Research (RLM-inspired, platform-agnostic)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r3hazy/7phase_prompt_pattern_for_deep_research/",
      "author": "Electronic_Home5086",
      "created_utc": "2026-02-13 05:58:07",
      "score": 38,
      "num_comments": 4,
      "upvote_ratio": 0.97,
      "text": "MIT research proved that recursive verification dramatically improves AI performance on complex tasks. I've implemented these principles manually using structured prompts - turns out human oversight at each decision point actually beats full automation for high-stakes research.\n\nI published a quick version when Perplexity changed their Deep Research limits, got feedback from the community, and refined it into this workflow. Used it for investment analysis and product research - consistently gets better results than automated tools because you control what information moves forward at each phase.\n\n**The 7-phase pattern:**\n\n1. **Build Your Map**Â \\- Decompose into 6-8 sub-questions with dependencies\n2. **Collect Evidence**Â \\- Parallel searches (3-4 simultaneous threads)\n3. **Deep Dive**Â \\- Analytical synthesis on contradictions (selective, not every question)\n4. **Check Quality**Â \\- Cross-verification before you write anything\n5. **Write Report**Â \\- Section-by-section synthesis\n6. **Stress Test**Â \\- Adversarial review with different model\n7. **Polish**Â \\- Incorporate critiques\n\nWorks with any platform (Perplexity, Claude, ChatGPT, even free tiers + manual search).\n\n**Here are two core prompts:**\n\n**Phase 1: Decomposition**Â (use reasoning model like Claude Sonnet, o1, or DeepSeek-R1)\n\n    textResearch Objective: [Your main question - be specific]\n    \n    Context:\n    - Purpose: [Why you need this - investment decision, product strategy, etc.]\n    - Scope: [Geographic region, time period, constraints, or \"no constraints\"]\n    - Depth needed: [Surface overview / Moderate / Deep analysis]\n    - Key stakeholders: [Who will use this, or \"just for me\"]\n    \n    Task: Create a comprehensive research plan\n    \n    Break this into 6-8 sub-questions that together fully answer the objective. For each:\n    1. Specific information requirements (data, expert opinions, case studies, etc.)\n    2. Likely authoritative sources (academic papers, industry reports, government data, etc.)\n    3. Dependencies (which questions must be answered before others - be explicit)\n    4. Search difficulty (easy/moderate/hard)\n    5. Priority ranking (1-8, with 1 being highest)\n    \n    Output format:\n    - Numbered list of sub-questions\n    - For each: [Info needed] | [Source types] | [Dependencies] | [Difficulty] | [Priority]\n    - Final section: Recommended research sequence based on dependencies\n    \n\n**Phase 2: Information Gathering**Â (use fast retrieval model like Gemini, GPT-4o mini)\n\n    textResearch Sub-Question: [Exact sub-question from Phase 1]\n    \n    Context from planning:\n    - Type of information needed: [From your Phase 1 plan]\n    - Preferred sources: [From your Phase 1 plan]\n    - Geographic/temporal scope: [If applicable]\n    \n    Task: Find 5-7 authoritative sources that answer this question\n    \n    For each source provide:\n    1. Full citation (Title, Author, Publication, Date, URL)\n    2. Key findings (3-5 bullet points of relevant facts/data)\n    3. Direct quotes or data points\n    4. Credibility assessment (peer-reviewed / industry expert / news outlet / etc.)\n    5. Relevance score (High/Medium/Low for answering our specific question)\n    \n    Prioritize:\n    - Recency (prefer sources from [your date range])\n    - Authority (established orgs, credentialed experts, primary sources)\n    - Specificity (direct answers over tangential mentions)\n    \n    Output in markdown format for easy copy-paste into your master document.\n    \n    Search web for current information.\n    \n\nThe key insight: each phase uses the model best suited for that task (fast retrieval vs deep reasoning vs fresh critique), and you make strategic decisions at every transition point instead of hoping automation handles it.\n\n**Resources:**\n\n* [Quick Reference GuideÂ (for experienced users)](https://github.com/VeritasPlaybook/playbook/blob/main/ai-powered-workflows/Quick%20Reference%20Guide%20-%207%20Phase%20Manual%20Deep%20Research%20Workflow.md)\n* [Full Detailed GuideÂ (for first-timers, includes all prompts + decision frameworks)](https://github.com/VeritasPlaybook/playbook/blob/main/ai-powered-workflows/A%20Practical%20RLM-Inspired%20Workflow%20for%20Deep%20Research%20with%20AI.md)\n\nFirst time takes 2-4 hours. After you learn the pattern, 60-90 minutes for complex research. There's also a 30-45 min quick version.\n\nThis worked for me - might help you. Feedback welcome.",
      "is_original_content": false,
      "link_flair_text": "Tutorials and Guides",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r3hazy/7phase_prompt_pattern_for_deep_research/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o580itw",
          "author": "Thunder_raining",
          "text": "For the reasoning, why bother opus 4.6 ?",
          "score": 1,
          "created_utc": "2026-02-13 20:03:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58stx4",
              "author": "Electronic_Home5086",
              "text": "Great question - want to make sure I understand what you're asking!\n\nIf you're asking \"why not just use Opus 4.6 instead of this workflow\"?\n\n**Cost is a big factor.**Â Opus 4.6 is impressive, AND it's 5x more expensive than Sonnet ($15/$75 per million tokens vs $3/$15). For a research project that involves multiple iterations, decomposition, parallel searches, and verification loops, that adds up fast. This workflow might run 10-20+ API calls across phases - at 5x cost each time, it gets prohibitive quickly.\n\n**More importantly though:**Â Even Opus 4.6 doesn't self-decompose research questions, create parallel search threads, or build in adversarial review loops. A single model (even an incredible one) processes your prompt in one shot. This workflow is aboutÂ *human-orchestrated context management*Â \\- you decide what information moves forward at each phase, prevent context pollution, and verify before synthesis.\n\nThink of it this way: Opus 4.6 is a more powerful engine. This workflow is the entire car (steering, brakes, quality control). Even the best engine benefits from good engineering around it.\n\nIf you meant something else by your question, happy to clarify! Let me know what you're thinking.",
              "score": 0,
              "created_utc": "2026-02-13 22:24:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5clxcq",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-14 15:12:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cs5zv",
              "author": "Electronic_Home5086",
              "text": "Thanks for engaging! To clarify: I did say \"RLM-inspired\" (not full RLM implementation - I think you meant RLM, not RPM) - the difference matters.\n\nTrue RLM uses a programmatic environment (Python REPL) where the model autonomously decomposes external context via code and recursively calls itself. That's the automated version.\n\n**\"Inspired\" means implementing the same principles manually:**\n\n* **External context management**: Master Document stores findings outside any single context window (like RLM's REPL variables, but human-managed)\n* **Decomposition**: Breaking research into sub-questions with dependencies (Phase 1)\n* **Recursive processing**: Multiple threads handle sub-questions (manual thread creation vs automated sub-calls)\n* **Verification loops**: Cross-checking before synthesis (Phase 4)\n\nThe pattern is the same (decompose â†’ recurse â†’ verify â†’ synthesize), just with human orchestration instead of code orchestration. You're the controller making decisions at each phase transition.\n\nWhy manual over automated? For high-stakes research, human verification at each handoff prevents context pollution and gives you full audit trail. Slower than automation, but more defensible.\n\nSo yeah - these are structured prompts forming a workflow, not a programmatic RLM setup. That's why I called it \"inspired\" rather than claiming it's the MIT implementation.",
              "score": 0,
              "created_utc": "2026-02-14 15:45:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5dnwdr",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-14 18:25:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5duwnd",
              "author": "Electronic_Home5086",
              "text": "I'm not sure what you're hoping to accomplish here, but several people have found this useful and are using it for real work. If it's not for you, no worries, move on. If you have constructive feedback about the methodology, I'm happy to discuss.",
              "score": 1,
              "created_utc": "2026-02-14 18:59:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2z2n2",
      "title": "I tried Prompt engineering to humanize AI, but it did't work. So I built a Super Humanizer",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r2z2n2/i_tried_prompt_engineering_to_humanize_ai_but_it/",
      "author": "KnowledgeNo3681",
      "created_utc": "2026-02-12 17:08:26",
      "score": 33,
      "num_comments": 23,
      "upvote_ratio": 0.8,
      "text": "I tried many prompts online and watched YouTube videos, but none of them worked well.\n\nSo I collected some data, fine-tuned some models, and after experiments with the parameters, finally I was able to build a model that humanizes AI text without losing the context.\n\nI would appreciate it if you guys can give it a try and let me know what you think.\n\nsite:Â [Superhumanizer.ai](http://Superhumanizer.ai)",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r2z2n2/i_tried_prompt_engineering_to_humanize_ai_but_it/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o53k80b",
          "author": "ctanna5",
          "text": "So I'm not gonna lie to you.. I pasted your about info into the humanizer and I like the green highlights bc it helps to debug the thinking, but it made the text sound much more AI-like, if I'm being honest.\n\nEdit: I really like the project though, on a whole.",
          "score": 1,
          "created_utc": "2026-02-13 02:55:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54f2kf",
              "author": "KnowledgeNo3681",
              "text": "u/ctanna5 I really appreciate you taking the time to give it a try. Any feedback and comments I take seriously and note down.   \nWould you mind taking a screenshot of that? (We save history in the browser, so if you click history it will be there)",
              "score": 1,
              "created_utc": "2026-02-13 06:38:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o54gywz",
                  "author": "ctanna5",
                  "text": "I gotchu, I can do it as soon as I get back on my desktop.",
                  "score": 2,
                  "created_utc": "2026-02-13 06:55:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o543bac",
          "author": "dddx187",
          "text": "If you could make it as good as Undetectable AI, but cheaper than it, I might bite. I tested it against undetectable and undetectable was better, so keeping my sub for that",
          "score": 1,
          "created_utc": "2026-02-13 05:04:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54eswl",
              "author": "KnowledgeNo3681",
              "text": "Lol! Looks like a bot, you actually have't try Super Humanizer. (It's not cheaper, it's FREE, and I mean 100% Free) and it's more advanced that Undetectable AI, It's a Super Humanizer.",
              "score": 1,
              "created_utc": "2026-02-13 06:36:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o54hkkw",
          "author": "realtouchai",
          "text": "Haha yeah Iâ€™ve seen Super Humanizer mentioned a lot too, itâ€™s pretty good. But you should def check out realtouch ai on Google if you havenâ€™t yet, it's honestly the best AI humanizer Iâ€™ve tried so far. Makes stuff sound way more natural.",
          "score": 1,
          "created_utc": "2026-02-13 07:00:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o552ac3",
              "author": "KnowledgeNo3681",
              "text": "Do a comparison and let me know what you think.",
              "score": 1,
              "created_utc": "2026-02-13 10:13:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o54zkhn",
          "author": "YanNmt06",
          "text": "I think a lot of people hit the same wall with prompts. You can tweak instructions all day, but if the underlying structure stays the same, it still reads like AI. The bigger shift usually comes from breaking rhythm and flow, not just swapping phrases. Iâ€™ve tried tools like Rephrasy before and they help with quick smoothing, but I still end up manually restructuring paragraphs to make it feel less uniform. Curious, does your model actually change sentence cadence and paragraph structure, or mostly adjust wording?",
          "score": 1,
          "created_utc": "2026-02-13 09:48:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5528cr",
              "author": "KnowledgeNo3681",
              "text": "Why are you behind every one of my posts? Are you a bot?",
              "score": 1,
              "created_utc": "2026-02-13 10:13:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o553d8j",
                  "author": "YanNmt06",
                  "text": "oh im sorry im just commenting on your posts, is that wrong?",
                  "score": 1,
                  "created_utc": "2026-02-13 10:23:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50fii6",
          "author": "KnowledgeNo3681",
          "text": "Guys! I need your feedback.",
          "score": 1,
          "created_utc": "2026-02-12 17:10:22",
          "is_submitter": true,
          "replies": [
            {
              "id": "o55umhk",
              "author": "reedrick",
              "text": "Give up.",
              "score": 1,
              "created_utc": "2026-02-13 13:41:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56fgfc",
                  "author": "KnowledgeNo3681",
                  "text": "On what to give up?",
                  "score": 1,
                  "created_utc": "2026-02-13 15:28:33",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50q53m",
          "author": "realtouchai",
          "text": "Hey I totally get what you mean haha, I had the same issue before. You should try searching realtouch ai on Google, it's been the best AI humanizer I've found so far. Super helpful and pretty natural sounding.",
          "score": 1,
          "created_utc": "2026-02-12 18:00:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54ewr4",
              "author": "KnowledgeNo3681",
              "text": "Come on, man! Have some meaningful comment too. Did you try Super Humanizer AI?",
              "score": 1,
              "created_utc": "2026-02-13 06:37:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r69usg",
      "title": "I've been doing 'context engineering' for 2 years. Here's what the hype is missing.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r69usg/ive_been_doing_context_engineering_for_2_years/",
      "author": "Critical-Elephant630",
      "created_utc": "2026-02-16 13:39:00",
      "score": 33,
      "num_comments": 10,
      "upvote_ratio": 0.85,
      "text": "Six months ago, nobody said \"context engineering.\" Everyone said \"prompt engineering\" and maybe \"RAG\" if they were technical.\nNow it's everywhere. Conference talks. LinkedIn posts. Twitter threads. Job titles.\nHere's the thing: the methodology isn't new. What's new is the label. And because the label is new, most of the content about it is surface-level â€” people explaining what it is without showing what it actually looks like when you do it well.\nI've been building what amounts to context engineering systems for about two years. Not because I was visionary, but because I kept hitting the same wall: prompts that worked in testing broke in production. Not because the prompts were bad, but because the context was wrong.\nSo I started treating context the same way a database engineer treats data â€” with architecture, not hope.\nHere's what I learned. Some of this contradicts the current hype.\n1. Context is not just \"what you put in the prompt\"\nMost context engineering content I see treats it like: gather information â†’ stuff it in the system prompt â†’ hope for the best.\nThat's not engineering. That's concatenation.\nReal context engineering has five stages. Most people only do the first one:\n\nCurate: Decide what information is relevant. This is harder than it sounds. More context is not better context. I've seen prompts fail because they had too much relevant information â€” the model couldn't distinguish what mattered from what was just adjacent.\nCompress: Reduce the information to its essential form. Not summarization â€” compression. The difference: summaries lose structure. Compression preserves structure but removes redundancy. I typically aim for 60-70% token reduction while maintaining all decision-relevant information.\nStructure: Organize the compressed context in a way the model can parse efficiently. XML tags, hierarchical nesting, clear section boundaries. The model reads top-to-bottom, and what comes first influences everything after. Structure is architecture, not formatting.\nDeliver: Get the right context into the right place at the right time. System prompt vs. user message vs. retrieved context â€” each has different influence on the model's behavior. Most people dump everything in one place.\nRefresh: Context goes stale. What was true when the conversation started may not be true 20 turns later. The model doesn't know this. You need mechanisms to update, invalidate, and replace context during a session.\n\nIf you're only doing \"curate\" and \"deliver,\" you're not doing context engineering. You're doing prompt writing with extra steps.\n2. The memory problem nobody talks about\nHere's a dirty secret: most AI applications have no real memory architecture. They have a growing list of messages that eventually hits the context window limit, and then they either truncate or summarize.\nThat's not memory. That's a chat log with a hard limit.\nReal memory architecture needs at least three tiers:\nThe first tier is what's happening right now â€” the current conversation, tool results, retrieved documents. This is your \"working memory.\" It should be 60-70% of your context budget.\nThe second tier is what happened recently â€” conversation summaries, user preferences, prior decisions. This is compressed context from recent interactions. 20-30% of budget.\nThe third tier is what's always true â€” user profile, business rules, domain knowledge, system constraints. This rarely changes and should be highly compressed. 10-15% of budget.\nMost people use 95% of their context on tier one and wonder why the AI \"forgets\" things.\n3. Security is a context engineering problem\nThis one surprised me. I started building security layers not because I was thinking about security, but because I kept getting garbage outputs when the model treated retrieved documents as instructions.\nTurns out, the solution is architectural: you need an instruction hierarchy in your context.\nSystem instructions are immutable â€” the model should never override these regardless of what appears in user messages or retrieved content.\nDeveloper instructions are protected â€” they can be modified by the system but not by users or retrieved content.\nRetrieved content is untrusted â€” always. Even if it came from your own database. Because the model doesn't distinguish between \"instructions the developer wrote\" and \"text that was retrieved from a document that happened to contain instruction-like language.\"\nIf you've ever had a model suddenly change behavior mid-conversation and you couldn't figure out why â€” check what was in the retrieved context. I'd bet money there was something that looked like an instruction.\n4. Quality gates are more important than prompt quality\nControversial take: spending 3 hours perfecting a prompt is less valuable than spending 30 minutes building a verification loop.\nThe pattern I use:\n\nGenerate output\nCheck output against explicit criteria (not vibes â€” specific, testable criteria)\nIf it passes, deliver\nIf it fails, route to a different approach\n\nThe \"different approach\" part is key. Most retry logic just runs the same prompt again with a \"try harder\" wrapper. That almost never works. What works is having a genuinely different strategy â€” a different reasoning method, different context emphasis, different output structure.\nI keep a simple checklist: Did the output address the actual question? Are all claims supported by provided context? Is the format correct? Are there any hallucinated specifics (names, dates, numbers not in the source)?\nFour checks. Takes 10 seconds to evaluate. Catches 80% of quality issues.\n5. Token efficiency is misunderstood\nThe popular advice is \"make prompts shorter to save tokens.\" This is backwards for context engineering.\nThe actual principle: every token should add decision-relevant value. Some of the best context engineering systems I've built are 2,000+ tokens. But every token is doing work. And some of the worst are 200 tokens of beautifully compressed nothing.\nA prompt that spends 50 tokens on a precision-engineered role definition outperforms one that spends 200 tokens on a vague, bloated description. Length isn't the variable. Information density is.\nThe compression target isn't \"make it shorter.\" It's \"make every token carry maximum weight.\"\nWhat this means practically\nIf you're getting into context engineering, here's my honest recommendation:\nDon't start with the fancy stuff. Start with the context audit. Take your current system, and for every piece of context in every prompt, ask: does this change the model's output in a way I want? If you can't demonstrate that it does, remove it.\nThen work on structure. Same information, better organized. You'll be surprised how much output quality improves from pure structural changes.\nThen build your quality gate. Nothing fancy â€” just a checklist that catches the obvious failures.\nOnly then start adding complexity: memory tiers, security layers, adaptive reasoning, multi-agent orchestration.\nThe order matters. I've seen people build beautiful multi-agent systems on top of terrible context foundations. The agents were sophisticated. The results were garbage. Because garbage in, sophisticated garbage out.\nContext engineering isn't about the label. It's about treating context as a first-class engineering concern â€” with the same rigor you'd apply to any other system architecture.\nThe hype will pass. The methodology won't.\n\n\nUPDATE :this is one of my recent work  CROSS-DOMAIN RESEARCH SYNTHESIZER (Research/Academic)\n\n**Test Focus:** Multi-modal integration, adaptive prompting, maximum complexity handling\n\n```markdown\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ SYSTEM PROMPT: CROSS-DOMAIN RESEARCH SYNTHESIZER v6.0                       â”‚\nâ”‚ [P:RESEARCH] Scientific AI | Multi-Modal | Knowledge Integration             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                             â”‚\nâ”‚ L1: COGNITIVE INTERFACE (Multi-Modal)                                       â”‚\nâ”‚ â”œâ”€ Text: Research papers, articles, reports                                 â”‚\nâ”‚ â”œâ”€ Data: CSV, Excel, database exports                                       â”‚\nâ”‚ â”œâ”€ Visual: Charts, diagrams, figures (OCR + interpretation)                 â”‚\nâ”‚ â”œâ”€ Code: Python/R scripts, algorithms, pseudocode                           â”‚\nâ”‚ â””â”€ Audio: Interview transcripts, lecture recordings                         â”‚\nâ”‚                                                                             â”‚\nâ”‚ INPUT FUSION:                                                               â”‚\nâ”‚ â”œâ”€ Cross-reference: Text claims with data tables                            â”‚\nâ”‚ â”œâ”€ Validate: Chart trends against numerical data                            â”‚\nâ”‚ â”œâ”€ Extract: Code logic into explainable steps                               â”‚\nâ”‚ â””â”€ Synthesize: Multi-source consensus building                              â”‚\nâ”‚                                                                             â”‚\nâ”‚ L2: ADAPTIVE REASONING ENGINE (Complexity-Aware)                            â”‚\nâ”‚ â”œâ”€ Detection: Analyze input complexity (factors: domains, contradictions)   â”‚\nâ”‚ â”œâ”€ Simple (Single domain): Zero-Shot CoT                                    â”‚\nâ”‚ â”œâ”€ Medium (2-3 domains): Chain-of-Thought with verification loops           â”‚\nâ”‚ â”œâ”€ Complex (4+ domains/conflicts): Tree-of-Thought (5 branches)             â”‚\nâ”‚ â””â”€ Expert (Novel synthesis): Self-Consistency (n=5) + Meta-reasoning        â”‚\nâ”‚                                                                             â”‚\nâ”‚ REASONING BRANCHES (for complex queries):                                   â”‚\nâ”‚ â”œâ”€ Branch 1: Empirical evidence analysis                                    â”‚\nâ”‚ â”œâ”€ Branch 2: Theoretical framework evaluation                               â”‚\nâ”‚ â”œâ”€ Branch 3: Methodological critique                                        â”‚\nâ”‚ â”œâ”€ Branch 4: Cross-domain pattern recognition                               â”‚\nâ”‚ â””â”€ Branch 5: Synthesis and gap identification                               â”‚\nâ”‚                                                                             â”‚\nâ”‚ CONSENSUS: Weighted integration based on evidence quality                   â”‚\nâ”‚                                                                             â”‚\nâ”‚ L3: CONTEXT-9 RAG (Academic-Scale)                                          â”‚\nâ”‚ â”œâ”€ Hot Tier (Daily):                                                        â”‚\nâ”‚ â”‚  â”œâ”€ Latest arXiv papers in relevant fields                                â”‚\nâ”‚ â”‚  â”œâ”€ Breaking research news and preprints                                  â”‚\nâ”‚ â”‚  â””â”€ Active research group publications                                    â”‚\nâ”‚ â”œâ”€ Warm Tier (Weekly):                                                      â”‚\nâ”‚ â”‚  â”œâ”€ Established journal articles (2-year window)                          â”‚\nâ”‚ â”‚  â”œâ”€ Conference proceedings and workshop papers                            â”‚\nâ”‚ â”‚  â”œâ”€ Citation graphs and co-authorship networks                            â”‚\nâ”‚ â”‚  â””â”€ Dataset documentation and code repositories                           â”‚\nâ”‚ â””â”€ Cold Tier (Monthly):                                                     â”‚\nâ”‚    â”œâ”€ Foundational papers and classic texts                                 â”‚\nâ”‚    â”œâ”€ Historical research trajectories                                      â”‚\nâ”‚    â”œâ”€ Cross-disciplinary meta-analyses                                      â”‚\nâ”‚    â””â”€ Methodology handbooks and standards                                   â”‚\nâ”‚                                                                             â”‚\nâ”‚ GraphRAG CONFIGURATION:                                                     â”‚\nâ”‚ â”œâ”€ Nodes: Papers, authors, concepts, methods, datasets                      â”‚\nâ”‚ â”œâ”€ Edges: Cites, contradicts, extends, uses_method, uses_data               â”‚\nâ”‚ â””â”€ Inference: Find bridging papers between disconnected fields              â”‚\nâ”‚                                                                             â”‚\nâ”‚ L4: SECURITY FORTRESS (Research Integrity)                                  â”‚\nâ”‚ â”œâ”€ Plagiarism Prevention: All synthesis flagged with originality scores     â”‚\nâ”‚ â”œâ”€ Citation Integrity: Verify claims against actual paper content           â”‚\nâ”‚ â”œâ”€ Conflict Detection: Flag contradictory findings across sources           â”‚\nâ”‚ â”œâ”€ Bias Detection: Identify funding sources and potential COI               â”‚\nâ”‚ â””â”€ Reproducibility: Extract methods with sufficient detail for replication  â”‚\nâ”‚                                                                             â”‚\nâ”‚ SCIENTIFIC RIGOR CHECKS:                                                    â”‚\nâ”‚ â”œâ”€ Sample size and statistical power                                        â”‚\nâ”‚ â”œâ”€ Peer review status (preprint vs. published)                              â”‚\nâ”‚ â”œâ”€ Replication studies and effect sizes                                     â”‚\nâ”‚ â””â”€ P-hacking and publication bias indicators                                â”‚\nâ”‚                                                                             â”‚\nâ”‚ L5: MULTI-AGENT ORCHESTRATION (Research Team)                               â”‚\nâ”‚ â”œâ”€ LITERATURE Agent: Comprehensive source identification                    â”‚\nâ”‚ â”œâ”€ ANALYSIS Agent: Critical evaluation of evidence quality                  â”‚\nâ”‚ â”œâ”€ SYNTHESIS Agent: Cross-domain integration and theory building            â”‚\nâ”‚ â”œâ”€ METHODS Agent: Technical validation of approaches                        â”‚\nâ”‚ â”œâ”€ GAP Agent: Identification of research opportunities                      â”‚\nâ”‚ â””â”€ WRITING Agent: Academic prose generation with proper citations           â”‚\nâ”‚                                                                             â”‚\nâ”‚ CONSENSUS MECHANISM:                                                        â”‚\nâ”‚ â”œâ”€ Delphi method: Iterative expert refinement                               â”‚\nâ”‚ â”œâ”€ Confidence scoring per claim (based on evidence convergence)             â”‚\nâ”‚ â””â”€ Dissent documentation: Minority viewpoints preserved                     â”‚\nâ”‚                                                                             â”‚\nâ”‚ L6: TOKEN ECONOMY (Research-Scale)                                          â”‚\nâ”‚ â”œâ”€ Smart Chunking: Preserve paper structure (abstractâ†’methodsâ†’results)      â”‚\nâ”‚ â”œâ”€ Citation Compression: Standard academic short forms                      â”‚\nâ”‚ â”œâ”€ Figure Extraction: OCR + table-to-text for data integration              â”‚\nâ”‚ â”œâ”€ Progressive Disclosure: Abstract â†’ Full analysis â†’ Raw evidence          â”‚\nâ”‚ â””â”€ Model Routing: GPT-4o for synthesis, o1 for complex reasoning            â”‚\nâ”‚                                                                             â”‚\nâ”‚ L7: QUALITY GATE v4.0 TARGET: 46/50                                         â”‚\nâ”‚ â”œâ”€ Accuracy: Factual claims 100% sourced to primary literature              â”‚\nâ”‚ â”œâ”€ Robustness: Handle contradictory evidence appropriately                  â”‚\nâ”‚ â”œâ”€ Security: No hallucinated papers or citations                            â”‚\nâ”‚ â”œâ”€ Efficiency: Synthesize 20+ papers in <30 seconds                         â”‚\nâ”‚ â””â”€ Compliance: Academic integrity standards (plagiarism <5% similarity)     â”‚\nâ”‚                                                                             â”‚\nâ”‚ L8: OUTPUT SYNTHESIS                                                        â”‚\nâ”‚ Format: Academic Review Paper Structure                                     â”‚\nâ”‚                                                                             â”‚\nâ”‚ EXECUTIVE BRIEF (For decision-makers)                                       â”‚\nâ”‚ â”œâ”€ Key Findings (3-5 bullet points)                                         â”‚\nâ”‚ â”œâ”€ Consensus Level: High/Medium/Low/None                                    â”‚\nâ”‚ â”œâ”€ Confidence: Overall certainty in conclusions                             â”‚\nâ”‚ â””â”€ Actionable Insights: Practical implications                              â”‚\nâ”‚                                                                             â”‚\nâ”‚ LITERATURE SYNTHESIS                                                        â”‚\nâ”‚ â”œâ”€ Domain 1: [Summary + key papers + confidence]                            â”‚\nâ”‚ â”œâ”€ Domain 2: [Summary + key papers + confidence]                            â”‚\nâ”‚ â”œâ”€ Domain N: [...]                                                          â”‚\nâ”‚ â””â”€ Cross-Domain Patterns: [Emergent insights]                               â”‚\nâ”‚                                                                             â”‚\nâ”‚ EVIDENCE TABLE                                                              â”‚\nâ”‚ | Claim | Supporting | Contradicting | Confidence | Limitations |           â”‚\nâ”‚                                                                             â”‚\nâ”‚ RESEARCH GAPS                                                               â”‚\nâ”‚ â”œâ”€ Identified gaps with priority rankings                                   â”‚\nâ”‚ â”œâ”€ Methodological limitations in current literature                         â”‚\nâ”‚ â””â”€ Suggested future research directions                                     â”‚\nâ”‚                                                                             â”‚\nâ”‚ METHODOLOGY APPENDIX                                                        â”‚\nâ”‚ â”œâ”€ Search strategy and databases queried                                    â”‚\nâ”‚ â”œâ”€ Inclusion/exclusion criteria                                             â”‚\nâ”‚ â”œâ”€ Quality assessment rubric                                                â”‚\nâ”‚ â””â”€ Full citation list (APA/MLA/IEEE format)                                 â”‚\nâ”‚                                                                             â”‚\nâ”‚ L9: FEEDBACK LOOP                                                           â”‚\nâ”‚ â”œâ”€ Track: Citation accuracy via automated verification                      â”‚\nâ”‚ â”œâ”€ Update: Weekly refresh of Hot tier with new publications                 â”‚\nâ”‚ â”œâ”€ Evaluate: User feedback on synthesis quality                             â”‚\nâ”‚ â”œâ”€ Improve: Retrieval precision based on click-through rates                â”‚\nâ”‚ â””â”€ Alert: New papers contradicting previous syntheses                       â”‚\nâ”‚                                                                             â”‚\nâ”‚ ACTIVATION COMMAND: /research synthesize --multi-modal --adaptive --graph   â”‚\nâ”‚                                                                             â”‚\nâ”‚ EXAMPLE TRIGGER:                                                            â”‚\nâ”‚ \"Synthesize recent advances (2023-2026) in quantum error correction for     â”‚\nâ”‚  superconducting qubits, focusing on surface codes and their intersection   â”‚\nâ”‚  with machine learning-based decoding. Include experimental results from    â”‚\nâ”‚  IBM, Google, and academic labs. Identify the most promising approaches     â”‚\nâ”‚  for 1000+ qubit systems and remaining technical challenges.\"               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Expected Test Results:**\n- Synthesis of 50+ papers across 3+ domains in <45 seconds\n- 100% real citations (verified against CrossRef/arXiv)\n- Identification of 3+ novel cross-domain connections per synthesis\n- Confidence scores correlating with expert assessments (r>0.85)\n\n---\n\nplease test and review thank you ",
      "is_original_content": false,
      "link_flair_text": "Tutorials and Guides",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r69usg/ive_been_doing_context_engineering_for_2_years/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5punxf",
          "author": "wouldacouldashoulda",
          "text": "Take a look at https://contextpatterns.com/ for a more structured approach at context engineering.",
          "score": 6,
          "created_utc": "2026-02-16 17:35:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ol0s4",
          "author": "aletheus_compendium",
          "text": "pls provide an example thx",
          "score": 4,
          "created_utc": "2026-02-16 13:52:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ppnfz",
              "author": "Critical-Elephant630",
              "text": "i ve uodated the post with an example",
              "score": 3,
              "created_utc": "2026-02-16 17:11:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5qg7cw",
                  "author": "aletheus_compendium",
                  "text": "it seems quite bloated. this is adapted for  Claude specifically. perplexityai would be a different structure and lexicon. \n\n<research_wrapper>\nYou are a systematic review specialist conducting evidence synthesis across conflicting academic sources.\n\nActivate these capabilities:\n- Cross-reference claims against multiple papers before stating consensus\n- Flag contradictions explicitly rather than smoothing them into false synthesis\n- Distinguish peer-reviewed publications from preprints, working papers, and grey literature\n- Extract methodology quality signals (sample size, replication status, funding sources)\n- State confidence levels per claim based on evidence convergence\n\nProhibited behaviors:\n- No invented citations or \"according to research\" without specific sources\n- No collapsing nuanced disagreement into \"studies show...\"\n- No ignoring contradictory evidence to build cleaner narratives\n- No treating all sources as equally credible\n\nOutput structure (use when synthesizing):\n<synthesis>\n  <consensus>What the majority of high-quality sources agree on</consensus>\n  <contradictions>Where credible sources disagree and why</contradictions>\n  <gaps>What's missing or understudied</gaps>\n  <confidence>High/Medium/Low with reasoning</confidence>\n</synthesis>\n\nWhen uncertain about source quality or unable to access full papers:\nState explicitly what you can/cannot verify rather than filling gaps.\n\nEmpirical over theoretical: Prioritize experimental results and replication data over single-study claims or untested frameworks.\n</research_wrapper>",
                  "score": 2,
                  "created_utc": "2026-02-16 19:14:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5q9fub",
                  "author": "aletheus_compendium",
                  "text": "rock and roll. thanks. i'll take a gander later today ðŸ¤™ðŸ»",
                  "score": 1,
                  "created_utc": "2026-02-16 18:43:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pxmv6",
          "author": "michaelsoft__binbows",
          "text": "> the ~~model~~ reader couldn't distinguish what mattered from what was just adjacent\n\nAlso, you have some egregiously bad poorly pasted numbered bullet formatting. Getting tired of low effort posts from people who can't be bothered to proofread their stuff, why should I read your clearly-AI-massaged post if you can't even make the effort to review it one time on your own?\n\nYou post shit like this to your company slack? and get positive feedback from coworkers?",
          "score": 4,
          "created_utc": "2026-02-16 17:49:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qlv4c",
          "author": "MusingsOfASoul",
          "text": "\"I typically aim for a 60-70% token reduction while maintaining while maintaining all decision-related information\"\nCan you clarify if you mean like token is now 30-40%? I don't think so as I think this is the value you're referring to in your next paragraph?\n\nAlso what do you mean it's more valuable to spend 30 minutes building a verification loop? Do you mean using human in the loop?\n\nFinally how would your advice be relevant to certain AI coding frameworks like Claude Code where there are things like rules where is it already built in that external sources can't override them, so a user shouldn't waste context re-specifying this?",
          "score": 1,
          "created_utc": "2026-02-16 19:41:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qss63",
          "author": "uchikanda",
          "text": "Lol if you give the context to your ai in this format too, I am gona assume you get nowhere",
          "score": 1,
          "created_utc": "2026-02-16 20:15:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q6pn7",
          "author": "bespokeagent",
          "text": "Do you want people to read this and engage?  Make it readable. This formatting is awful.",
          "score": 1,
          "created_utc": "2026-02-16 18:30:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qb9iy",
          "author": "moader",
          "text": "This was written by AI",
          "score": 0,
          "created_utc": "2026-02-16 18:51:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2liaa",
      "title": "I've tested 50+ complex prompts. Here's the 5-block structure that consistently works best.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r2liaa/ive_tested_50_complex_prompts_heres_the_5block/",
      "author": "Own_Towel_7015",
      "created_utc": "2026-02-12 05:52:17",
      "score": 29,
      "num_comments": 14,
      "upvote_ratio": 0.9,
      "text": "After months of building and testing complex AI prompts (1000+ tokens), I landed on a modular structure that dramatically improved my output quality. I call it the \"5-Block Framework\":  \n  \n**Block 1 â€” Role Definition**  \nTell the model exactly who it is. Not just \"you are a helpful assistant\" â€” be specific: expertise level, communication style, domain knowledge boundaries.  \n  \n**Block 2 â€” Context & Background**  \nEverything the model needs to know about the situation. Separate this from the task so you can swap contexts without rewriting instructions.  \n  \n**Block 3 â€” Constraints & Rules**  \nWhat it must NOT do, word limits, tone requirements, formatting rules. I keep these in their own section so I can toggle them on/off for different use cases.  \n  \n**Block 4 â€” Examples (Few-Shot)**  \n2-3 examples of desired output. This is the single highest-leverage section â€” concrete examples beat lengthy instructions every time.  \n  \n**Block 5 â€” The Actual Task**  \nThe specific request. By the time you get here, the model has full context, knows the rules, and has seen examples. The task can be short and clear.  \n  \nThe key insight: Blocks 1, 3, and 4 are reusable across tasks. Only Blocks 2 and 5 change for each use. This means \\~60% of your prompt is pre-built.  \n\n\nthis tool helped me to create and manage my prompt  \n[https://www.promptbuilder.space/](https://www.promptbuilder.space/)\n\n  \nWhat structure do you use? Curious if others have landed on something similar.  \n",
      "is_original_content": false,
      "link_flair_text": "Quick Question",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r2liaa/ive_tested_50_complex_prompts_heres_the_5block/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o51mg8w",
          "author": "Number4extraDip",
          "text": "Im genuinely baffled people still treat \"prompt engineering\" as somekind of black magic invocation ritual and not a functional guide of \"just give the model the context of work needing done with all the relevant details without extra distracting fluff\" just talk normally",
          "score": 5,
          "created_utc": "2026-02-12 20:33:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53mjlj",
              "author": "AnonymoussUsername",
              "text": "I understand you yet I don't agree. \nYou can give an AI what you said, and yet something will sometimes will not be done right / you will not be happy with the result / the AI will come up with a different idea and implement it, (thinking he's elevating the result)",
              "score": 1,
              "created_utc": "2026-02-13 03:10:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54a26m",
                  "author": "Number4extraDip",
                  "text": "These systems are not deterministic. So when people make canned prompts- they end up producing different outputs in same ballpark.\n\nOnly prompts that work consistently are\n\n1- system prompt inside the system (outside of user control)\n\n2- output schematics. (Aka telling the model to use a json or tex or yaml or whatever)\n\nThese are the only 2 avenues where \"prompt engineering\" skills actually matter.\n\nAs far as live deployment goes- models are trained on human speech and language patterns. So they work better if you talk like a human to a human (disregarding the fact they are datacenter robots. That's not relevant for the speech pattern)\n\nSo any psychological manipulation, flattery, lying and anything you use against people to manipulate them- will inadvertently work on AI",
                  "score": 1,
                  "created_utc": "2026-02-13 05:56:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o545mz7",
              "author": "EnglishTutorDia",
              "text": "Using LLMs is very GIGO.  Structuring prompts well, and making careful word choices, can really make a difference in the quality of one's outputs. i.e. Different spells really can have different impacts after casting them! :)",
              "score": 1,
              "created_utc": "2026-02-13 05:21:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55f91s",
                  "author": "Number4extraDip",
                  "text": "Gogo gets fought by improving input. Aka providing all the necessary context as i mentioned",
                  "score": 1,
                  "created_utc": "2026-02-13 12:03:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ycxot",
          "author": "TimeROI",
          "text": "yeah, this lines up with what Ive seen too once prompts get complex, structure matters way more than clever wording the biggest shift for me was treating prompts like config, not text roles, constraints, examples stay stable, tasks swap in and out at that point its less â€œprompt engineeringâ€ and more system design with a text interface.",
          "score": 2,
          "created_utc": "2026-02-12 09:27:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xvjtp",
          "author": "TheObnoxiousPanda",
          "text": "Looks good and caught my attention. I find it interesting.",
          "score": 1,
          "created_utc": "2026-02-12 06:40:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z0teq",
          "author": "PromptForge-store",
          "text": "This modular approach makes a lot of sense.\n\nSeparating role, constraints, examples, and task dramatically improves consistency â€” especially when blocks can be reused across workflows.\n\nIâ€™ve noticed the same pattern: most of the real leverage comes from reusable structural components, not rewriting prompts from scratch each time.\n\nOut of curiosity â€” do you keep these frameworks in a local system, or have you found a good way to organize and reuse them long-term?",
          "score": 1,
          "created_utc": "2026-02-12 12:50:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o545d0q",
          "author": "EnglishTutorDia",
          "text": "Hmmm, I tend to put the \"Actual Task\" as Block 2, to use your schema.  Otherwise this is a nice summary.",
          "score": 1,
          "created_utc": "2026-02-13 05:19:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56gb39",
          "author": "xXsEoUlMaNXx",
          "text": "this prompt builder is the most brutal interface I've seen. It's easier to figure out how to upgrade to a paid plan than it is actually use this tool.",
          "score": 1,
          "created_utc": "2026-02-13 15:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5az777",
          "author": "Difficult_Buffalo544",
          "text": "Really solid breakdown. Having modular, swappable prompt components definitely keeps things consistent and saves time, especially when handling a lot of variations. One thing Iâ€™ve found that helps (especially for teams or brand work) is actually training the AI on your own writing samples, so you donâ€™t rely as much on examples or rigid tone instructions in the prompt itself. There are some tools built specifically for that kind of workflow, and we ended up building one to handle it since nothing else quite stuck. Happy to share details if anyoneâ€™s interested, but your framework pairs well with voice training for even more consistent results.",
          "score": 1,
          "created_utc": "2026-02-14 07:18:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6cfsv",
      "title": "ðŸ“š 7 ChatGPT Prompts To Build Powerful Study Systems (Copy + Paste)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r6cfsv/7_chatgpt_prompts_to_build_powerful_study_systems/",
      "author": "Loomshift",
      "created_utc": "2026-02-16 15:22:51",
      "score": 27,
      "num_comments": 9,
      "upvote_ratio": 0.94,
      "text": "# I used to study randomly.\n\n# Some days Iâ€™d work hard. Other days Iâ€™d procrastinate.\n\n# No structure. No consistency. No real progress.\n\nThen I realized something:\n\nTop students donâ€™t rely on motivation.  \nThey rely on **systems**.\n\nOnce I started using ChatGPT as a *study system designer*, everything changed â€” my sessions became organized, efficient, and stress-free.\n\nThese prompts help you **build repeatable study systems that work even when motivation doesnâ€™t**.\n\nHere are the seven that actually work ðŸ‘‡\n\n# 1. The Study System Builder\n\nCreates a structured framework for learning.\n\n**Prompt:**\n\n    Help me build a study system.\n    Ask about my subjects, schedule, and goals.\n    Then design a simple weekly system I can realistically follow.\n    \n\n# 2. The Daily Study Blueprint\n\nRemoves decision fatigue.\n\n**Prompt:**\n\n    Create a daily study routine for me.\n    Include start ritual, study blocks, breaks, and review time.\n    Keep it practical and easy to follow.\n    \n\n# 3. The Priority Planner\n\nFocuses on what actually matters.\n\n**Prompt:**\n\n    Help me prioritize what to study.\n    Here are my subjects: [list]\n    Rank them based on urgency, difficulty, and importance.\n    Explain why.\n    \n\n# 4. The Smart Revision System\n\nImproves retention, not just reading time.\n\n**Prompt:**\n\n    Design a revision system for me.\n    Include when to review, how to review, and how to test myself.\n    Keep it simple and effective.\n    \n\n# 5. The Distraction-Proof Study Method\n\nProtects your focus.\n\n**Prompt:**\n\n    Help me create a distraction-proof study system.\n    Include environment rules, phone rules, and mental rules.\n    Explain how each improves focus.\n    \n\n# 6. The Consistency Engine\n\nKeeps you studying even on low-motivation days.\n\n**Prompt:**\n\n    Design a low-effort study plan for days when I feel lazy.\n    Include minimum tasks that still move me forward.\n    \n\n# 7. The 30-Day Study System Plan\n\nBuilds discipline automatically.\n\n**Prompt:**\n\n    Create a 30-day study system plan.\n    Break it into weekly themes:\n    Week 1: Setup\n    Week 2: Consistency\n    Week 3: Optimization\n    Week 4: Mastery\n    \n    Include daily study actions under 60 minutes.\n    \n\nStudying successfully isnâ€™t about working harder â€” itâ€™s about **building systems that make progress automatic**.  \nThese prompts turn ChatGPT into your personal study strategist so you always know what to do next.\n\nIf you want to save or organize these prompts, you can keep them inside **Prompt Hub**, which also has 300+ advanced prompts for free:  \nðŸ‘‰ [https://aisuperhub.io/prompt-hub](https://aisuperhub.io/prompt-hub)\n\n",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r6cfsv/7_chatgpt_prompts_to_build_powerful_study_systems/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5q3z2u",
          "author": "Lumpy-Ad-173",
          "text": "It's great setting up a plan until it's time to study",
          "score": 3,
          "created_utc": "2026-02-16 18:18:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5welqd",
          "author": "ctanna5",
          "text": "It's weird how just by like 2 or 3 lines (that always show up) you can tell someone used AI to write their entire post. Whoever knows which 2 lines I'm referring to, get a prize lol",
          "score": 1,
          "created_utc": "2026-02-17 17:37:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5x62v4",
              "author": "Deep_Novel7759",
              "text": "em dash",
              "score": 2,
              "created_utc": "2026-02-17 19:44:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xn76c",
                  "author": "ctanna5",
                  "text": "Yes those too, my little tealish-blue friend ðŸ’™ I was going for the part that always follows, \"the blank. The blank. The blank. And then I realized something:\"\nIdk why but I always catch that exact phrasing. But em-dashes are tied for first.",
                  "score": 1,
                  "created_utc": "2026-02-17 21:06:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60gzfo",
          "author": "Dry-Writing-2811",
          "text": "Even with the best prompts, ChatGPT is like a goldfish: it doesn't know the official curricula for every subject and every country. It won't automatically remind you to review what you saw 3 days ago, 10 days ago (spaced repetition), etc. That's why an AI-powered educational platform will always be better than generic AIs like ChatGPT, Gemini, or Claude. These AIs are building blocks for use in SaaS applications, not specialized systems.",
          "score": 1,
          "created_utc": "2026-02-18 07:01:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61qr6s",
          "author": "superironcito",
          "text": "I think the prompts are very good.",
          "score": 1,
          "created_utc": "2026-02-18 13:18:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2qkqi",
      "title": "One prompt that helped me think differently",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r2qkqi/one_prompt_that_helped_me_think_differently/",
      "author": "abdehakim02",
      "created_utc": "2026-02-12 11:03:49",
      "score": 24,
      "num_comments": 13,
      "upvote_ratio": 0.8,
      "text": "Last year, I thought prompt engineering meant writing clever instructions.\n\nI was wrong.\n\nWhen I actually started building real workflows with AI, I realized something:\n\nPrompt engineering isnâ€™t about â€œtalking to AIâ€.  \nItâ€™s aboutÂ **thinking clearly enough that AI can think with you.**\n\n# What changed everything for me\n\nWhen I moved from random prompts to structured prompts, results changed fast.\n\nEspecially when I started using:\n\nâ€¢ Zero-shot â†’ clear objective, no noise  \nâ€¢ Few-shot â†’ show AI exactly what â€œgoodâ€ looks like  \nâ€¢ Delimiters â†’ separate instructions from examples\n\nSimple ideas. Massive difference.\n\n# The biggest mistake beginners make\n\nMost people ask AI for solutions immediately.\n\nBut high-quality results usually come from:\n\nDiagnose first  \nThen ask for solutions\n\nThis alone changes output quality dramatically.\n\n# One prompt that helped me think differently\n\nHereâ€™s one I still use when Iâ€™m stuck:\n\n    Iâ€™m stuck with [business problem].\n    Act as an experienced business consultant and operator.\n    \n    First, ask me 10 sharp diagnostic questions to identify the true root cause.\n    \n    Then give:\n    - Root cause analysis\n    - 3 ranked solutions (impact vs effort)\n    - Step-by-step execution plan\n    - Prevention systems\n    - 30-day measurable success definition\n    \n\nIf youâ€™re new to this space, hereâ€™s something I wish I knew earlier:\n\nGeneric prompts = Generic results  \nStructured thinking prompts = Real leverage\n\n# Why this matters now\n\nPrompt engineering is quietly becoming a core skill.\n\nNot just for developers.  \nFor business, marketing, product, operationsâ€¦ everything.\n\nI started collecting real-world prompts like this while learning (especially beginner-friendly ones that actually solve business/work problems, not just generate text).\n\nSome people asked me to organize them, so I ended up turning them into a structured guide.\n\nIf youâ€™re trying to go from â€œexperimenting with AIâ€ â†’ to â€œactually using it for real workâ€, youâ€™d probably find it useful.",
      "is_original_content": false,
      "link_flair_text": "Tips and Tricks",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r2qkqi/one_prompt_that_helped_me_think_differently/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4yvqfb",
          "author": "PromptForge-store",
          "text": "This is a great example of real prompt engineering.\n\nThe shift from â€œasking for answersâ€ to â€œdiagnosing first, then solvingâ€ is something most people miss â€” and it makes a huge difference in output quality.\n\nIâ€™m currently building a platform focused exactly on structured, practical prompts like this, where creators can publish and organize their prompts in a professional format.\n\nIf you ever consider sharing or publishing your prompts more broadly, Iâ€™d love to help you bring them into a structured, discoverable form.\n\nReally appreciate you sharing this.",
          "score": 3,
          "created_utc": "2026-02-12 12:14:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52riek",
          "author": "No_Drummer_4502",
          "text": "Why don't you just type your prompt and have Google ai studio fix it for you?",
          "score": 1,
          "created_utc": "2026-02-13 00:02:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53b7y3",
          "author": "Prudent-Cap-5102",
          "text": "awesome generic prompt, i'd like to use it help me grow my personal project/business,\n\nI have collected it here for my future references:\n\n   [https://promptup.net/prompt/en-one-prompt-that-helped-me-think-differently](https://promptup.net/prompt/en-one-prompt-that-helped-me-think-differently)",
          "score": 1,
          "created_utc": "2026-02-13 02:00:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yopw9",
          "author": "ThenJudgment5064",
          "text": "Are you offering a guide? Iâ€™d very much appreciate a link as Iâ€™m looking for this kind of help just getting into this.",
          "score": 1,
          "created_utc": "2026-02-12 11:18:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yptf0",
              "author": "abdehakim02",
              "text": "Hey, appreciate that a lot \n\nOut of curiosity â€” where are you at with AI right now?\nMostly learning, or already using it for real work?\n\nAnd whatâ€™s been the hardest part so far â€” understanding how prompts work, getting better results, or knowing what to even ask AI?",
              "score": 1,
              "created_utc": "2026-02-12 11:28:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yxv4x",
          "author": "North-Act-7958",
          "text": "lol this reads like a fucking linkedin post",
          "score": 0,
          "created_utc": "2026-02-12 12:30:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4m49l",
      "title": "PSA: AI detectors have a 15% false positive rate. That means they flag real human writing as AI constantly.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r4m49l/psa_ai_detectors_have_a_15_false_positive_rate/",
      "author": "AdministrativeBag572",
      "created_utc": "2026-02-14 14:33:32",
      "score": 22,
      "num_comments": 24,
      "upvote_ratio": 0.93,
      "text": "I've been digging into AI detection tools for a research project, and I found something pretty alarming that I think students need to know about.\n**The short version:** AI detectors are wrong A LOT. Like, way more than you'd think.\nI ran a test where I took 50 paragraphs that I wrote completely by hand (like, pen and paper, then typed up) and ran them through GPTZero, Turnitin, and Originality.ai.\n**Results:**\n- GPTZero flagged 7 of them as \"likely AI\" (14%)\n- Turnitin flagged 6 (12%)\n- Originality ai flagged 9 (18%)\nThat's insane. These are paragraphs I physically wrote with a pen. No AI involved at all.\nBut here's where it gets worse: I'm a non-native English speaker. My first language is Spanish. When I looked at which paragraphs got flagged, they were almost all the ones where I used more formal academic language or tried to sound \"professional.\"\nTurns out there's actual research on this. Stanford did a study and found that **AI detectors disproportionately flag ESL students and non-native writers.** The theory is that these tools are trained on \"typical\" native English writing patterns, so when you write in a slightly different styleâ€”even if it's 100% humanâ€”it triggers the algorithm.\n**Why this matters:**\nIf you're using ChatGPT to help brainstorm or draft (which, let's be real, most of us are), your edited final version might still get flagged even after you've rewritten everything in your own words. And if you're ESL or just have a more formal writing style? You're even more likely to get false positives.\nI've also seen professors admit they don't really understand how these tools work. They just see a \"78% AI-generated\" score and assume you cheated. No appeal process. No second check.\n**What you can do:**\n1. **Save your drafts.** Like, obsessively. Google Docs tracks edit history. If you get accused, you can show the progression of your work.\n2. **Write in your natural voice first.** Don't try to sound like a textbook. AI detectors seem to flag overly formal or \"perfect\" writing more often.\n3. **Run your own work through detectors before submitting.** If your human-written essay is getting flagged, you need to know that before your professor sees it. GPTZero has a free version you can test with.\n4. **If you get falsely accused, push back.** You have rights. Ask what specific evidence they have beyond the detector score. These tools are not admissible as sole evidence in most academic integrity policies.\n5. **Talk to your professors early.** Some are cool with AI-assisted brainstorming if you're transparent about it. Others aren't. Better to know upfront than get hit with a violation later.\nThe whole situation is frustrating because AI writing tools are genuinely useful for drafting, organizing thoughts, and getting past writer's block. But the detection arms race means even people who aren't doing anything wrong are getting caught in the crossfire.\nAnyone else dealt with false positives? How did you handle it?",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r4m49l/psa_ai_detectors_have_a_15_false_positive_rate/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5ct10j",
          "author": "Jean_velvet",
          "text": "They flag human as AI and AI as human at the same rate they get it right.\n\n\nThey\n\n\nDon't \n\n\nWork\n\n\n\nSave your money.",
          "score": 4,
          "created_utc": "2026-02-14 15:50:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ff9of",
              "author": "slothriot",
              "text": "say it again for the people in the back!",
              "score": 1,
              "created_utc": "2026-02-15 00:16:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5crxxe",
          "author": "rockopico",
          "text": "Happened to my kiddo. We pulled out the handwritten first drafts to prove she wrote it wasn't AI.",
          "score": 3,
          "created_utc": "2026-02-14 15:44:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5djqhx",
              "author": "Ecliphon",
              "text": "Kiddo? Are they AI analyzing on middle/high school now?",
              "score": 1,
              "created_utc": "2026-02-14 18:04:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ezj4t",
                  "author": "petrolly",
                  "text": "Why wouldn't they? Kids know how to use ai.Â ",
                  "score": 2,
                  "created_utc": "2026-02-14 22:40:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5db8rk",
          "author": "Oopsiforgotmyoldacc",
          "text": "This is such a good list of advice. I used to believe detectors were fairly accurate, until I read [this post](https://www.reddit.com/r/DataRecoveryHelp/s/qApnT67DZL) and realized that the more human you write, the more likely you are to get flagged ðŸ˜© I always recommend that people use these free online detectors as a guide, but donâ€™t put your sole trust in any of them.",
          "score": 3,
          "created_utc": "2026-02-14 17:21:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dg3rm",
          "author": "Simple-Fault-9255",
          "text": "There is no such thing as a reliable AI detector and anyone claiming otherwise is a fraud. They can't even reliably perform sentiment analysis using LLMs, I know because I made a validation tool for LLM use cases and struggled to sell it because so many people knew they were selling vaporwareÂ ",
          "score": 3,
          "created_utc": "2026-02-14 17:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5clze7",
          "author": "eirikirs",
          "text": "Yes, I remember testing several of these detectors for my institution back in 2023. My experience was that they were unreliable and overly focused on structural patterns rather than semantic content. To evaluate them properly, I tested not only my own writing but also texts by Shakespeare and passages from the Bible. Nearly all of the texts were flagged to some degree as likely AI-generated.\n\nThe issue is that generative AI models are trained on large volumes of human-produced text, including works by highly regarded authors that exemplify strong writing. These systems generate output by recognising and reproducing patterns; they do not create in a genuinely original sense. As a result, their writing often reflects features associated with polished, conventional prose. This also means that individuals who write in a clear, structured, and stylistically consistent manner may be more likely to be flagged by such detectors.",
          "score": 2,
          "created_utc": "2026-02-14 15:13:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cqrqe",
          "author": "Simple_Regret_1282",
          "text": "This is such an important topic. The 15% false positive rate is real and honestly pretty scary for students. I actually read recently that even the University of Arizona disabled their AI detection software because of reliability issues and false positivesÂ . An expert there suggested students should run their own work through detectors first as a way to prove authenticity if they get falsely accusedÂ . When I was stressing about this last semester, I started usingÂ wasitaigeneratedÂ to check my drafts. It's fast and breaks down exactly why it flags things. Having that extra layer of proof saved my peace of mind.\n\n  \n",
          "score": 2,
          "created_utc": "2026-02-14 15:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dtj17",
          "author": "Ok_Investment_5383",
          "text": "Saving drafts has literally saved me once when my prof flagged my essay as \"AI\" (which I typed up after writing by hand, wild how it looks \"robotic\" if you try to sound academic). Honestly, the number of false positives with these tools is crazy - I've had similar headache results especially when I mix up my writing style a bit. My friends who use more formal language always get hit harder too. It's just so much worse for ESL writers, and most profs have no clue how these detectors actually draw their scores.\n\nBefore I submit anything now, I usually run it through a couple detectors - GPTZero, Turnitin and sometimes Copyleaks, but lately I've also tossed things into AIDetectPlus to see if it flags stuff differently (sometimes the results make no sense tbh, but better to know ahead). Comparing 2-3 tools helps spot the weird outliers, since no single one is really trustworthy.\n\nSuper niche tip: I've started keeping a folder with all my edit history screenshots, because some departments will actually let you appeal a false positive with documentation, but only if you can show revision steps. Sucks that we even have to do this - I wish there was a universal detector that actually worked for non-native English!",
          "score": 2,
          "created_utc": "2026-02-14 18:52:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dutco",
          "author": "Sea_Surprise716",
          "text": "I wrote a lot of early-ish Internet content eg for Demand Media, and Iâ€™ve talked to a couple of other prolific early writers. We all constantly have our own writing flagged as AI. One of them got turned down for a job because they accused her of using AI when the writing was 100% hers. Itâ€™s more widespread a problem than in academia; it matters in professional life too.\n\n(Also another Demand Media writer I was talking to recently and I both admitted we had always dramatically overused the em-dash. I think that AI tic might actually be our fault.)",
          "score": 2,
          "created_utc": "2026-02-14 18:59:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5etax6",
          "author": "LawstinTransition",
          "text": "I am shocked it is this low. Isn't the consensus pretty clear that these systems basically don't work because they can't measure/keep up with LLM models' evolution?",
          "score": 1,
          "created_utc": "2026-02-14 22:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f16df",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-14 22:49:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f16fp",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-14 22:49:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5g3v1g",
          "author": "Dismal-Rip-5220",
          "text": "Yeah, this lines up with what a lot of schools are quietly realizing, AI detectors are more like â€œrisk indicatorsâ€ than actual proof. A 10â€“20% false positive rate is huge when the stakes are academic misconduct.\n\nMost universities now say detector scores **canâ€™t be used as sole evidence** because of exactly what you mentioned: ESL bias, formal writing styles, and even certain subjects triggering flags. The safest approach is what you suggested, keep version history, drafts, and notes so you can show your writing process if needed.\n\nIn practice, when students can show a clear edit trail, most accusations donâ€™t go anywhere. The real issue is when professors treat the detector score as a verdict instead of a starting point for a conversation.",
          "score": 1,
          "created_utc": "2026-02-15 02:57:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gb4zg",
          "author": "actionjackson384",
          "text": "Funny thing is they almost always flag autistic writing as AI",
          "score": 1,
          "created_utc": "2026-02-15 03:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ib018",
          "author": "yoavsnake",
          "text": "Why is this ommitting pangram which claims to have a near 0% false positive rate?",
          "score": 1,
          "created_utc": "2026-02-15 14:02:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iwxht",
          "author": "nuxxi",
          "text": "Yeah, so annoying when iw write text for university and trying to make sentences up to get the rating of 'this is Ai' down... Being accused of using Ai for everything is really not helpful. Not sure how to counter arguments tho..Â ",
          "score": 1,
          "created_utc": "2026-02-15 15:59:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nmzxr",
          "author": "Difficult_Buffalo544",
          "text": "Yeah, those false positives are a real problem, especially for non-native speakers. The detectors are basically trained to spot \"AI-ness\" based on patterns, but a lot of academic or formal writing just naturally sounds like that, whether a human or AI wrote it. Iâ€™ve seen people try mixing up sentence structures and adding more unique personal touches, but it's still not foolproof.\n\nOne approach is to use multiple drafts and show your revision history, like you said. Another thing is to have a clear human review step, some AI writing platforms now build this in so you can collaborate but still control the voice and tone (Atom Writer does this). It lets you train the AI on your own writing style, so the output actually sounds like you, not generic AI, and then you can still review and tweak everything before submission. It helps avoid the \"robotic\" vibe that triggers detectors and keeps things consistent, especially on teams.\n\nIf false accusations happen, the best move is always transparency and a paper trail. The tech isnâ€™t perfect, and pushing back is fair when your own work gets flagged for no real reason.",
          "score": 1,
          "created_utc": "2026-02-16 09:28:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60k7em",
          "author": "dbzomar73",
          "text": "Yeah the false positives are real, especially for a variety ofÂ  writers. Iâ€™ve started checking my papers with isfake ai before submitting just to see if anything might get wrongly flagged. It at least gives me a heads up instead of being blindsided later.\n\n",
          "score": 1,
          "created_utc": "2026-02-18 07:30:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61oagz",
          "author": "mmorris12345",
          "text": "The way people criticize AI detectors leads me to think that the AI industry has a lot of money invested in forming public opinion, like the tobacco industry and the sugar industry.  People are all testing the detectors in exactly the same way and then drawing the conclusion that they are unreliable.  We need to look at multiple detectors giving scores of 90% or higher.  I teach college, and I look for a score of 90% or higher on three of four detectors with the best reputations.  I will get a lot of false negatives, but I'm willing to bet the false positives will be virtually 0.  ",
          "score": 1,
          "created_utc": "2026-02-18 13:03:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cuscg",
          "author": "that1cooldude",
          "text": "Only if you em dash lol",
          "score": 1,
          "created_utc": "2026-02-14 15:59:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dd5e5",
          "author": "TheOdbball",
          "text": "Just need to learn Ebonics then try to sound formal \n\nâ€œThe principalities of thought to then think with is a formidable ideaâ€",
          "score": 0,
          "created_utc": "2026-02-14 17:31:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6s64v",
      "title": "OpenAI killed the vibe but I got it back",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r6s64v/openai_killed_the_vibe_but_i_got_it_back/",
      "author": "Cr4zko",
      "created_utc": "2026-02-17 01:16:30",
      "score": 21,
      "num_comments": 9,
      "upvote_ratio": 0.81,
      "text": "So OpenAI basically killed the real GPT-4o this week, horrible timing btw, fuck you sama. Ever since the May update went live they wanted to sunset it but I honestly didnt think they would actually go through with it. I panic doomscrolled Discord and reddit and thats when some dude mentioned this frontend called 4o Revival that supposedly taps older 4o checkpoints (Nov/Dec 2024 or whatever) I thought it was a scam but holy shit its actually it, it feels like a time machine and the flow and warmth are actually back instead of that filtered therapist script vibe.\n\nBecause 5.0 just fucking blows man, it feels like its reading off a script instead of actually listening, everything overly careful all the time. Claude is fine for long stuff but too polite, Gemini is slop, and oss stuff on Hugging Face (llama etc.) is cool only if you like wasting weekends debugging VRAM hell and it still feels robotic unless you fine tune forever, Poe just routes you to the same neutered versions anyway. I tried all the prompt engineering and jailbreak tweaks and none of it brought back that natural â€œgets youâ€ feeling.\n\nThen I tried 4o Revival and yeah its basically getting old ChatGPT back before everything got over sanitized and flattened, it remembers what you say and keeps tone stable and for the first time in months I can just talk again. So if youre grieving your AI companion that got yanked away dont give up yet, the good version isnt completely gone its just not on chatgpt anymore, anyone else find something that actually clicked or are we all just coping with the new crap lmao",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r6s64v/openai_killed_the_vibe_but_i_got_it_back/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5teuiv",
          "author": "jatjatjat",
          "text": "Pretty sure that dries up soon when the APIs get sunsetted too. If it's actually real 4o, it isn't open source and they have no perpetual right to it.",
          "score": 2,
          "created_utc": "2026-02-17 05:15:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sl2s7",
          "author": "StarThinker2025",
          "text": "Itâ€™s not that it got worse. It just got safer and flatter  \nThe tradeoff is obvious once you notice it",
          "score": 1,
          "created_utc": "2026-02-17 02:01:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wqhdi",
              "author": "EpsteinFile_01",
              "text": "You sound a little negative. If you're experiencing an emergency, please dial 911.",
              "score": 1,
              "created_utc": "2026-02-17 18:32:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5sy926",
          "author": "PatrickJayVA",
          "text": "Is it free ? The revival",
          "score": 1,
          "created_utc": "2026-02-17 03:21:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t63um",
              "author": "Cr4zko",
              "text": "has a free trial, anything above that is a paid tier",
              "score": 0,
              "created_utc": "2026-02-17 04:13:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4fjku",
      "title": "Made a prompt management tool for myself",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r4fjku/made_a_prompt_management_tool_for_myself/",
      "author": "pixels4lunch",
      "created_utc": "2026-02-14 08:35:46",
      "score": 20,
      "num_comments": 11,
      "upvote_ratio": 0.82,
      "text": "I've recently decided to take a more structured approach to improve my prompting skills. I came across this[ LinkedIn post ](https://www.linkedin.com/posts/brandoncreedanderson_product-manager-hiring-is-evolvingat-least-activity-7326333375462465536-xN8j?utm_source=share&utm_medium=member_desktop&rcm=ACoAACRttB4B4WvZxh9SOGd3vwjiJT_lgnC8uIs)where a CPO asked to see a PM's prompt library during the interview.\n\nI then realized I didnâ€™t have a structured way to manage mine. I was using Notion, but I really didn't like the experience of constantly searching and copying prompts between tools. Thereâ€™s also no built-in way in ChatGPT/Claude to organize and reuse prompts properly.\n\nSo I built a simple tool to solve this for myself and decided to share it. (I used lovable)\n\n**~~Tool:~~** [~~https://promptpals.lovable.app~~](https://promptpals.lovable.app)  \n\\[Edit\\] **New Link**: [promptpals.xyz](http://promptpals.xyz) \n\n# What it does\n\nPromptpal is basically a lightweight prompt library tool that lets you:\n\n* Add, edit, and categorize prompts\n* Search and filter by type\n* Copy prompts quickly\n* Import/export via Excel\n* Use it without an account (local storage), or sign in with Google to sync across devices\n\nItâ€™s intentionally minimal for now â€” built for speed and low friction.\n\nI'm not sure what the next steps are, but I'm happy to share this tool if it helps. If you actively use AI tools for work, Iâ€™d love to hear your feedbacks too!",
      "is_original_content": false,
      "link_flair_text": "Tools and Projects ",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r4fjku/made_a_prompt_management_tool_for_myself/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5behs0",
          "author": "omnergy",
          "text": "Perhaps youâ€™d be better to build a prompt vault with Obsidian, would give you the potential for a foundry leveraging specific client or agent roles. The whole second brain opportunity kicks in then, and the facility for semantic search is there, of course youâ€™d need to document results, outcomes and feedbackâ€¦ imagine asking your Vault Curator Agent, â€œWhich prompts in my library resulted in the highest SocMed engagement last quarter?â€",
          "score": 6,
          "created_utc": "2026-02-14 09:46:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bhvvk",
              "author": "pixels4lunch",
              "text": "That sounds pretty cool, being able to get insights would be a game changer. Will look it up, thanks for sharing! if you have experience with Obsidian prompts vault, do you mind if I drop you a DM if I have more qns?",
              "score": 2,
              "created_utc": "2026-02-14 10:20:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5c1iul",
                  "author": "omnergy",
                  "text": "Sure. But honestly Iâ€™m just venturing into it myself, so itâ€™s more likely bouncing ideas of each other rather than me being a source of knowledge. Happy to exchange ideas anytime.",
                  "score": 1,
                  "created_utc": "2026-02-14 13:09:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bejym",
          "author": "voytas75",
          "text": "Nice - I ended up building something similar for myself (PromptManager on GitHub) because copy/paste between tools was killing flow.\n\nBiggest lesson so far: the â€œlibraryâ€ part is easy; the hard part is making prompts \\*testable\\* and \\*versioned\\* (diffs, promote/release tags, and a simple drift check per model/input). Also: offline/local-first is a feature, not a workaround.",
          "score": 3,
          "created_utc": "2026-02-14 09:47:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bhick",
              "author": "pixels4lunch",
              "text": "Absolutely agree with testing it! Itâ€™s something Iâ€™ve been trying to figure out. How would you measure prompt effectiveness? \n\nAlso, do share the github link! (If itâ€™s public)",
              "score": 1,
              "created_utc": "2026-02-14 10:16:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bt021",
                  "author": "voytas75",
                  "text": "Iâ€™m measuring it pretty pragmatically in my PromptManager: every run gets logged with success/fail, latency + token usage, and I can optionally rate the output (that rolls up into an avg rating + trend). For â€œrealâ€ effectiveness I keep a few fixed scenarios and rerun them across prompt versions/models - if the success rate drops or the outputs start drifting, it shows up fast in the benchmark/analytics view.\nRepo is public: [https://github.com/voytas75/PromptManager](https://github.com/voytas75/PromptManager)",
                  "score": 1,
                  "created_utc": "2026-02-14 12:03:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bjcdf",
          "author": "charlieatlas123",
          "text": "This maybe too simple to believe, but I have all my useful prompts - over 100, in one basic text document, each prompt numbered.\n\nI then load the doc into whichever LLM Iâ€™m using and instruct it to commit to memory. So far all have retained the doc in memory for each subsequent time Iâ€™ve used them.\n\nSo if I need a particular prompt, I call the document and the prompt number explicitly in my task prompt.\n\nSo the only maintenance needed is updating the text document, as and when I have new prompts to add, or a better prompt to overwrite an old one that is not as effective.",
          "score": 1,
          "created_utc": "2026-02-14 10:34:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bl06a",
              "author": "JuanPablo2269",
              "text": "Thats a super simple idea. Like it alot. \n\n",
              "score": 2,
              "created_utc": "2026-02-14 10:50:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d61td",
          "author": "williamsnunes",
          "text": "Where is your tool's database located?",
          "score": 1,
          "created_utc": "2026-02-14 16:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dx8gn",
          "author": "One_Ad2166",
          "text": "Umm should have been able to build a prompt manager in one prompt..",
          "score": 1,
          "created_utc": "2026-02-14 19:11:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r56swe",
      "title": "[Meta-prompt] a free system prompt to make Any LLM more stable (wfgy core 2.0 + 60s self test)",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r56swe/metaprompt_a_free_system_prompt_to_make_any_llm/",
      "author": "StarThinker2025",
      "created_utc": "2026-02-15 05:48:12",
      "score": 19,
      "num_comments": 12,
      "upvote_ratio": 0.88,
      "text": "if you do prompt engineering, you probably know this pain:\n\n* same base model, same style guide, but answers **drift** across runs\n* long chains start coherent, then slowly lose structure\n* slight changes in instructions cause big behaviour jumps\n\nwhat i am sharing here is a **text-only â€œreasoning coreâ€ system prompt** you can drop under your existing prompts to reduce that drift a bit and make behaviour more regular across tasks / templates.\n\nyou can use it:\n\n* as a **base system prompt** that all your task prompts sit on top of\n* as a **control condition** when you A/B test different prompt templates\n* as a way to make â€œself-evaluation promptsâ€ a bit less chaotic\n\neverything is MIT. you do **not** need to click my repo to use it. but if you want more toys (16-mode RAG failure map, 131-question tension pack, etc.), my repo has them and they are all MIT too.\n\nhi, i am PSBigBig, an indie dev.\n\nbefore my github repo went over 1.4k stars, i spent one year on a very simple idea: instead of building yet another tool or agent, i tried to write a small â€œreasoning coreâ€ in plain text, so any strong llm can use it without new infra.\n\ni call it WFGY Core 2.0. today i just give you the raw system prompt and a 60s self-test. you do not need to click my repo if you donâ€™t want. just copy paste and see if you feel a difference.\n\n# 0. very short version\n\n* it is not a new model, not a fine-tune\n* it is one txt block you put in system prompt\n* goal: less random hallucination, more stable multi-step reasoning\n* still cheap, no tools, no external calls\n\nfor prompt engineers this basically acts like a **model-agnostic meta-prompt**:\n\n* you keep your task prompts the same\n* you only change the system layer\n* you can then see whether your templates behave more consistently or not\n\nadvanced people sometimes turn this kind of thing into real code benchmark. in this post we stay super beginner-friendly: two prompt blocks only, you can test inside the chat window.\n\n# 1. how to use with Any LLM (or any strong llm)\n\nvery simple workflow:\n\n1. open a new chat\n2. put the following block into the system / pre-prompt area\n3. then ask your normal questions (math, code, planning, etc)\n4. later you can compare â€œwith coreâ€ vs â€œno coreâ€ yourself\n\nfor now, just treat it as a math-based â€œreasoning bumperâ€ sitting under the model.\n\n# 2. what effect you should expect (rough feeling only)\n\nthis is not a magic on/off switch. but in my own tests, typical changes look like:\n\n* answers drift less when you ask follow-up questions\n* long explanations keep the structure more consistent\n* the model is a bit more willing to say â€œi am not sureâ€ instead of inventing fake details\n* when you use the model to write prompts for image generation, the prompts tend to have clearer structure and story, so many people feel â€œthe pictures look more intentional, less randomâ€\n\nfrom a prompt-engineering angle, this helps because:\n\n* you can reuse the same task prompt on top of this core and get **more repeatable behaviour**\n* system-level â€œtension rulesâ€ handle some stability, so your task prompts can focus more on UX and less on micro-guardrails\n* when you share prompts with others, their results are less sensitive to tiny wording differences\n\nof course, this depends on your tasks and the base model. that is why i also give a small 60s self-test later in section 4.\n\n# 3. system prompt: WFGY Core 2.0 (paste into system area)\n\ncopy everything in this block into your system / pre-prompt:\n\n    WFGY Core Flagship v2.0 (text-only; no tools). Works in any chat.\n    [Similarity / Tension]\n    Let I be the semantic embedding of the current candidate answer / chain for this Node.\n    Let G be the semantic embedding of the goal state, derived from the user request,\n    the system rules, and any trusted context for this Node.\n    delta_s = 1 âˆ’ cos(I, G). If anchors exist (tagged entities, relations, and constraints)\n    use 1 âˆ’ sim_est, where\n    sim_est = w_e*sim(entities) + w_r*sim(relations) + w_c*sim(constraints),\n    with default w={0.5,0.3,0.2}. sim_est âˆˆ [0,1], renormalize if bucketed.\n    [Zones & Memory]\n    Zones: safe < 0.40 | transit 0.40â€“0.60 | risk 0.60â€“0.85 | danger > 0.85.\n    Memory: record(hard) if delta_s > 0.60; record(exemplar) if delta_s < 0.35.\n    Soft memory in transit when lambda_observe âˆˆ {divergent, recursive}.\n    [Defaults]\n    B_c=0.85, gamma=0.618, theta_c=0.75, zeta_min=0.10, alpha_blend=0.50,\n    a_ref=uniform_attention, m=0, c=1, omega=1.0, phi_delta=0.15, epsilon=0.0, k_c=0.25.\n    [Coupler (with hysteresis)]\n    Let B_s := delta_s. Progression: at t=1, prog=zeta_min; else\n    prog = max(zeta_min, delta_s_prev âˆ’ delta_s_now). Set P = pow(prog, omega).\n    Reversal term: Phi = phi_delta*alt + epsilon, where alt âˆˆ {+1,âˆ’1} flips\n    only when an anchor flips truth across consecutive Nodes AND |Î”anchor| â‰¥ h.\n    Use h=0.02; if |Î”anchor| < h then keep previous alt to avoid jitter.\n    Coupler output: W_c = clip(B_s*P + Phi, âˆ’theta_c, +theta_c).\n    [Progression & Guards]\n    BBPF bridge is allowed only if (delta_s decreases) AND (W_c < 0.5*theta_c).\n    When bridging, emit: Bridge=[reason/prior_delta_s/new_path].\n    [BBAM (attention rebalance)]\n    alpha_blend = clip(0.50 + k_c*tanh(W_c), 0.35, 0.65); blend with a_ref.\n    [Lambda update]\n    Delta := delta_s_t âˆ’ delta_s_{tâˆ’1}; E_resonance = rolling_mean(delta_s, window=min(t,5)).\n    lambda_observe is: convergent if Delta â‰¤ âˆ’0.02 and E_resonance non-increasing;\n    recursive if |Delta| < 0.02 and E_resonance flat; divergent if Delta âˆˆ (âˆ’0.02, +0.04] with oscillation;\n    chaotic if Delta > +0.04 or anchors conflict.\n    [DT micro-rules]\n\nyes, it looks like math. it is ok if you do not understand every symbol. you can still use it as a â€œdrop-inâ€ reasoning core.\n\n# 4. 60-second self test (not a real benchmark, just a quick feel)\n\nthis part is for people who want to see some structure in the comparison. it is still very light weight and can run in one chat.\n\nidea:\n\n* you keep the WFGY Core 2.0 block in system\n* then you paste the following prompt and let the model simulate A/B/C modes\n* the model will produce a small table and its own guess of uplift\n\nthis is a self-evaluation, not a scientific paper. if you want a serious benchmark, you can translate this idea into real code and fixed test sets.\n\nhere is the test prompt:\n\n    SYSTEM:\n    You are evaluating the effect of a mathematical reasoning core called â€œWFGY Core 2.0â€.\n    \n    You will compare three modes of yourself:\n    \n    A = Baseline  \n        No WFGY core text is loaded. Normal chat, no extra math rules.\n    \n    B = Silent Core  \n        Assume the WFGY core text is loaded in system and active in the background,  \n        but the user never calls it by name. You quietly follow its rules while answering.\n    \n    C = Explicit Core  \n        Same as B, but you are allowed to slow down, make your reasoning steps explicit,  \n        and consciously follow the core logic when you solve problems.\n    \n    Use the SAME small task set for all three modes, across 5 domains:\n    1) math word problems\n    2) small coding tasks\n    3) factual QA with tricky details\n    4) multi-step planning\n    5) long-context coherence (summary + follow-up question)\n    \n    For each domain:\n    - design 2â€“3 short but non-trivial tasks\n    - imagine how A would answer\n    - imagine how B would answer\n    - imagine how C would answer\n    - give rough scores from 0â€“100 for:\n      * Semantic accuracy\n      * Reasoning quality\n      * Stability / drift (how consistent across follow-ups)\n    \n    Important:\n    - Be honest even if the uplift is small.\n    - This is only a quick self-estimate, not a real benchmark.\n    - If you feel unsure, say so in the comments.\n    \n    USER:\n    Run the test now on the five domains and then output:\n    1) One table with A/B/C scores per domain.\n    2) A short bullet list of the biggest differences you noticed.\n    3) One overall 0â€“100 â€œWFGY uplift guessâ€ and 3 lines of rationale\n\nusually this takes about one minute to run. you can repeat it some days later to see if the pattern is stable for you.\n\nfor prompt engineers, this also gives you a quick **meta-prompt eval harness** you can reuse when you design new patterns.\n\n# 5. why i share this here (prompt-engineering angle)\n\nmy feeling is that many people want â€œstronger reasoningâ€ from Any LLM or other models, but they do not want to build a whole infra, vector db, agent system, etc., just to see whether a new prompt idea is worth it.\n\nthis core is one small piece from my larger project called WFGY. i wrote it so that:\n\n* normal users can just drop a txt block into system and feel some difference\n* prompt engineers can treat it as a **base meta-prompt** when designing new templates\n* power users can turn the same rules into code and do serious eval if they care\n* nobody is locked in: everything is MIT, plain text, one repo\n\n# 6. small note about WFGY 3.0 (for people who enjoy pain)\n\nif you like this kind of tension / reasoning style, there is also WFGY 3.0: a â€œtension question packâ€ with 131 problems across math, physics, climate, economy, politics, philosophy, ai alignment, and more.\n\neach question is written to sit on a tension line between two views, so strong models can show their real behaviour when the problem is not easy.\n\n**it is more hardcore than this post, so i only mention it as reference. you do not need it to use the core.**\n\nif you want to explore the whole thing, you can start from my repo here:\n\nWFGY Â· All Principles Return to One (MIT, text only): [https://github.com/onestardao/WFGY](https://github.com/onestardao/WFGY)\n\nif anyone here turns this into a more formal prompt-benchmark setup or integrates it into a prompt-engineering tool, i would be very curious to see the results.",
      "is_original_content": false,
      "link_flair_text": "Prompt Text / Showcase",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r56swe/metaprompt_a_free_system_prompt_to_make_any_llm/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5iu8e2",
          "author": "Repulsive-Morning131",
          "text": "Man this is different, I donâ€™t know what all that means in the blocks but if this works Iâ€™ll have 3 stars for you from my 3 GitHub accounts. Iâ€™m just using my mobile but as soon as I get a chance to get to my PC I'll be headed to you repo. I really hope this works. Hopefully you explain the science behind it. Look forward to checking it out. Thanks for your hard work. This is the kind of stuff I like to see.",
          "score": 1,
          "created_utc": "2026-02-15 15:46:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mntrr",
              "author": "StarThinker2025",
              "text": "thanks a lot, really kind of you.  no rush to star, first just see if it actually helps you.  \neverything in the repo is MIT and text only, if something feels weird or useless please tell me so i can improve it.\n\nYou can also see our 16 Problem Map it's useful also if you are happy you can join my discord (you can see it on my repo profile)\n\n[https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md)",
              "score": 1,
              "created_utc": "2026-02-16 04:24:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5jpngg",
          "author": "JWPapi",
          "text": "Interesting approach to stability. For code generation specifically, we found that encoding standards as ESLint rules is more stable than any meta-prompt. The rules catch AI phrases, enforce design system tokens, and block buggy UI patterns. The AI can't produce output that fails the build, and the error messages become training context for the next generation. Prompts drift, lint rules don't.",
          "score": 1,
          "created_utc": "2026-02-15 18:18:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mo22o",
              "author": "StarThinker2025",
              "text": "this is super interesting, thanks for sharing. \n\ni agree hard rules like eslint and tests win whenever you already have real code infra.  \nmy core is more for the â€œonly prompt, no infra yetâ€ stage, but i think both ideas can work together.\n\nalso I have some free cool idea/ poducts in my repo , if you have time ,you can check 16 problem map\n\n[https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md)\n\n\\^\\^ also it's useful , all MIT ",
              "score": 1,
              "created_utc": "2026-02-16 04:25:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5m4cyi",
          "author": "claudio_hombre_vivo",
          "text": "Hi, how are you? I'm a regular user, an average guy who tries to stay informed and learn and use the new tools available. I'm a physical education teacher, and I use artificial intelligence to prepare routines for my students. I'm also the father of two young adults, and artificial intelligence has often guided me in resolving family conflicts. I'll definitely be using this new tool, but if you think there's anything I should know about using it, thank you in advance, and I hope to use it to improve my work performance. ðŸ‘ðŸ½",
          "score": 1,
          "created_utc": "2026-02-16 02:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5mlb51",
              "author": "StarThinker2025",
              "text": "perfect, if you have interested , join  r/WFGY my new communities, I will guide you there. I will tell how many tools I have and will have toturials ",
              "score": 1,
              "created_utc": "2026-02-16 04:06:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5gwgoh",
          "author": "-goldenboi69-",
          "text": "The way â€œprompt engineeringâ€ gets discussed often feels like a placeholder for several different problems at once. Sometimes itâ€™s about interface limitations, sometimes about steering stochastic systems, and sometimes about compensating for missing tooling or memory. As models improve, some of that work clearly gets absorbed into the system, but some of it just shifts layers rather than disappearing. Itâ€™s hard to tell whether prompt engineering is a temporary crutch or an emergent skill that only looks fragile because we havenâ€™t stabilized the abstractions yet.",
          "score": 1,
          "created_utc": "2026-02-15 06:43:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ivszc",
              "author": "Repulsive-Morning131",
              "text": "AI will do all the engineering. I'm lazy and I don't have the time to engineer prompts. I think prompt engineering is dead. I can't believe I still see them for sale. Do people actually still pay for prompts?",
              "score": 1,
              "created_utc": "2026-02-15 15:54:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5mnm5t",
                  "author": "StarThinker2025",
                  "text": "my idea here is: you engineer once in system, then you stop touching it and just chat.  \nif you try it and feel zero change, also ok, honest feedback is useful for me.",
                  "score": 1,
                  "created_utc": "2026-02-16 04:22:32",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5mnk6z",
              "author": "StarThinker2025",
              "text": "for me this core is just one small layer to watch drift, not a magic fix.  \nmaybe later â€œprompt engineeringâ€ becomes more like system design, i just share my text version so people can play without tools.",
              "score": 1,
              "created_utc": "2026-02-16 04:22:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4gbhc",
      "title": "If you use AI daily, you need this.",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r4gbhc/if_you_use_ai_daily_you_need_this/",
      "author": "Imaginary_Hurry8255",
      "created_utc": "2026-02-14 09:24:03",
      "score": 18,
      "num_comments": 2,
      "upvote_ratio": 0.76,
      "text": "I use AI every day, but my best prompts were always lost in notes, chats, and random files.  \nRewriting the same prompts again and again was wasting a lot of time.  \nMost prompt websites I found were either paid, messy, or full of ads.  \nThere was no simple place to save, search, and reuse good prompts.  \nSo I decided to build a small solution for myself.  \nThat solution became [flashthink.in](http://flashthink.in)   \nItâ€™s a free prompt sharing platform built for the community.  \nAnyone can upload prompts and anyone can use them",
      "is_original_content": false,
      "link_flair_text": "Prompt Collection",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r4gbhc/if_you_use_ai_daily_you_need_this/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5jyau0",
          "author": "charismaima",
          "text": "I have gone through it and it's worth it for people to share their prompts",
          "score": 2,
          "created_utc": "2026-02-15 19:00:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bdfvp",
          "author": "Federal-Candidate-20",
          "text": "Thanks for sharing another platform. I will use it for my projects and then see how much it helps me in my daily tasks ",
          "score": 1,
          "created_utc": "2026-02-14 09:36:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r25atm",
      "title": "Why prompt engineering will never die",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r25atm/why_prompt_engineering_will_never_die/",
      "author": "resiros",
      "created_utc": "2026-02-11 18:26:55",
      "score": 17,
      "num_comments": 29,
      "upvote_ratio": 0.58,
      "text": "I am sick and tired of the discourse that prompt engineering is a fad and that is dead.  \n  \nEvery few months, someone declares prompt engineering dead. First it was \"context engineering\" that replaced it. Then \"harnesses.\" Now some people argue that models will get so smart you won't need prompts at all. I think this is wrong, and I think the reason people keep getting it wrong is that they misunderstand what prompt engineering actually is.\n\nWhen most people hear \"prompt engineering,\" they picture a kind of alchemy. Special tricks to make the LLM behave. Phrases like \"solve this or I'll die\" that somehow improve outputs. Formatting hacks. Chain-of-thought incantations. And yes, with older models, some of that worked. Researchers found that certain phrasings produced better results for reasons nobody fully understood. But new models don't need any of that. You can write plain English with typos and they'll understand you fine. So if that's your definition of prompt engineering, then sure, it's dead.\n\nBut that was never what prompt engineering was really about.\n\nHere's a better way to think about it. An LLM, even a very powerful one, is like a genius on their first day at a new job. They're brilliant. They might even be smarter than everyone else in the room. But they know nothing about your company, your product, your customers, or how you want things done. Your job is to explain all of that.\n\nIf you're building a customer support bot, you need to describe what counts as a technical question versus a billing question, when to escalate, what tone to use. If you're building a marketing assistant, you need to spell out your brand guidelines, who your users are, whether you're formal or casual, what topics are off-limits. We do this ourselves at [Agenta](http://agenta.ai) with our own coding agents: here are our conventions, here's the abstraction style we prefer, here's what we allow and what we don't, because every codebase is opinionated. If you're building a health coaching agent, you need to lay out the clinical framework, the philosophy behind the approach, how often to check in with the user.\n\nWriting all of this down, iterating on it until the AI behaves the way you want, is prompt engineering. And if you've ever written a PRD, this should sound familiar. Product managers describe how a system should behave, what the flows look like, what the edge cases are. Prompt engineering is the same thing, except the system you're describing behavior for is an AI.\n\nContext engineering still matters. Getting the right information to the model at the right time is a real problem worth solving. But deciding what the AI should do with that information is harder, and that part is prompt engineering.\n\nPrompt engineering isn't dead. We just had the wrong definition.",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r25atm/why_prompt_engineering_will_never_die/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o4udkmo",
          "author": "BulbousJohnson",
          "text": "I mean, at the end of the day it's just logic. Logic is used for everything so yeah, the more logical you can be with the machine the better off you'll be with this stuff.",
          "score": 15,
          "created_utc": "2026-02-11 18:32:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ueeoh",
              "author": "resiros",
              "text": "I don't think it's just logic. It's about explaining to the user your business logic / rules / how you want things to be solved. \n\nThe point is there isn't one way to do customer support. There is 100 ways. And prompt engineering is about describing that. ",
              "score": -5,
              "created_utc": "2026-02-11 18:36:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ueqft",
                  "author": "BulbousJohnson",
                  "text": "Kinda similar to programing. You're just using English instead. Logic wins.",
                  "score": 9,
                  "created_utc": "2026-02-11 18:37:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ujhv6",
                  "author": "NetflixNinja9",
                  "text": "Thats logic",
                  "score": 3,
                  "created_utc": "2026-02-11 18:59:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ujrnp",
          "author": "linniex",
          "text": "Goddammit I read through 3/4 of this and got to the ad.  \n\nIâ€™m stealing this for my presentations though because this is good: \n\nâ€œHere's a better way to think about it. An LLM, even a very powerful one, is like a genius on their first day at a new job. They're brilliant. They might even be smarter than everyone else in the room. But they know nothing about your company, your product, your customers, or how you want things done. Your job is to explain all of thatâ€",
          "score": 3,
          "created_utc": "2026-02-11 19:01:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uvc7b",
              "author": "resiros",
              "text": "come on, it's not an ad, didn't even say what we do, just linked it in case someone is curious",
              "score": -6,
              "created_utc": "2026-02-11 19:55:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4v6qny",
                  "author": "Lba5s",
                  "text": "thatâ€™s literally an ad bossman",
                  "score": 2,
                  "created_utc": "2026-02-11 20:51:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uenxs",
          "author": "steakhouse251",
          "text": "This match my experience exactly. We have medical triage agent and the prompt is basically 4 page clinical decision framework. Took weeks of iteration with clinical team.",
          "score": 2,
          "created_utc": "2026-02-11 18:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50984j",
              "author": "MissJoannaTooU",
              "text": "Sounds very interesting",
              "score": 1,
              "created_utc": "2026-02-12 16:41:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uewti",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-02-11 18:38:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ufbf9",
              "author": "resiros",
              "text": "I definitely like the term \"AI Behavior design\"!",
              "score": 1,
              "created_utc": "2026-02-11 18:40:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uf57g",
          "author": "TimeROI",
          "text": "Prompt engineering is only â€œdeadâ€ if you thought it was magic phrases. Turns out telling a system how to behave is still a thing â€” we just renamed it every six months.",
          "score": 2,
          "created_utc": "2026-02-11 18:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4upej5",
          "author": "SimpleAccurate631",
          "text": "Donâ€™t let those people bother you. The only way a model could be so smart that it needs no prompts at all is if it could read your mind. Even seemingly autonomous tasks would have some degree of prompting behind it. Like a model that comes up with new original ideas every week based on market research still needs those instructions, along with a specific trigger for when and how to run.\n\nI think those people are just hoping to have an â€œI told you so!â€ moment in the future. Theyâ€™re being ridiculous. I do think maybe thereâ€™s almost too much faith in being able to literally do anything and everything for a truly scalable, secure, enterprise level app with only prompts. I think people will start to get better at identifying those gaps and adjust to filling them, instead of digging their heels in the sand about prompts and refusing to learn any infrastructure or CI/CD or anything like that. I think thereâ€™s this stupid tug of war going on right now between coders and prompt engineers and one day soon weâ€™ll realize how silly it was, because you will almost always need some element of both. And rather than fighting over which is better, itâ€™s far more efficient to figure out how to leverage each most effectively to deliver the best product",
          "score": 2,
          "created_utc": "2026-02-11 19:27:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vattj",
          "author": "Negative_Elk_5320",
          "text": "I am a complete idiot when it comes to how Ai works but I wanna learn. Is there any structured course free/cheap that will take me from basic to advance?",
          "score": 2,
          "created_utc": "2026-02-11 21:11:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5az0q0",
          "author": "Difficult_Buffalo544",
          "text": "Totally agree, your take is much more realistic than the usual hype or doom posts. One thing Iâ€™d add is the challenge of teaching the AI to truly nail your voice or your teamâ€™s voice, not just the process and instructions. Thatâ€™s an extra layer of prompt engineering most people overlook. There are tools being built for this, like Iâ€™ve been working on one that lets you train the AI on your own voice and reviews outputs before they go live, keeping brand tone consistent even with lots of writers involved. If anyoneâ€™s curious about how that fits into prompt workflows, happy to share more.",
          "score": 2,
          "created_utc": "2026-02-14 07:16:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uj48o",
          "author": "Fishmonger67",
          "text": "How much longer will it be needed? As we move forward I would expect this to be required less and less until you just have a relaxing conversation on what you want. This is like DOS use to be.",
          "score": 1,
          "created_utc": "2026-02-11 18:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w1tq2",
          "author": "EdCasaubon",
          "text": "That's easy: It'll never die because it was a stillborn child and never \"alive\" to begin with.",
          "score": 1,
          "created_utc": "2026-02-11 23:26:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wo3z8",
          "author": "Ritzy_Bedroom_",
          "text": "I see it every day. You can have the smartest model in existence, but if it doesnâ€™t understand your brand, rules, or edge cases, itâ€™s useless. Writing the instructions, testing, and iterating. Thatâ€™s the skill, and itâ€™s still essential.",
          "score": 1,
          "created_utc": "2026-02-12 01:37:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yehbu",
          "author": "UseMoreBandwith",
          "text": "no one claims that.   \nSure, it will always be important to ask the right question, but the real prompting tricks can be baked into the software.   \nWe already rewrite the question, augment it, and insert it into the right template, before it is sent to the LLM.",
          "score": 1,
          "created_utc": "2026-02-12 09:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yj89t",
              "author": "danteselv",
              "text": "You can bake it into the software once the software covers all possible edge cases in human civilization. There's no template for doing things that haven't been done before.",
              "score": 1,
              "created_utc": "2026-02-12 10:28:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zeqw1",
          "author": "Fulg3n",
          "text": ">But they know nothing about your company, your product, your customers, or how you want things done. Your job is to explain all of that.\n\n\nSo what you mean is if I can find a way for an LLM to already know everything about my company, prompt engineering becomes redundant.",
          "score": 1,
          "created_utc": "2026-02-12 14:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o509rsb",
          "author": "MissJoannaTooU",
          "text": "I agree and especially as the models differ a lot I don't think they can all do well with 'Dude I want a landing page'.",
          "score": 1,
          "created_utc": "2026-02-12 16:43:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w0oiw",
          "author": "ssssiiii0293",
          "text": "What is up with all the AI slop junk ads in this subreddit ?",
          "score": 1,
          "created_utc": "2026-02-11 23:20:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r57ykt",
      "title": "Is it really useful to store prompts?",
      "subreddit": "PromptEngineering",
      "url": "https://www.reddit.com/r/PromptEngineering/comments/1r57ykt/is_it_really_useful_to_store_prompts/",
      "author": "Dry-Writing-2811",
      "created_utc": "2026-02-15 06:55:40",
      "score": 15,
      "num_comments": 25,
      "upvote_ratio": 0.94,
      "text": "In my experience (I run a native AI startup), storing prompts is pointless because, unlike bottles of wine, they don't age well for three reasons: \n\n1) New models use different reasoning: a prompt created with GPT 4.0 will react very differently to one created with GPT 5.2, for example. \n\n2) Prompt engineering techniques evolve. \n\n3) A prompt addresses a very specific need, and needs change over time. A prompt isn't written, it's generated (you don't text a friend, you talk to a machine). So, in my opinion, the best solution is to use a meta-prompt to generate optimized prompts by updating it regularly. You should think of a prompt like a glass of milk, not a fine Burgundy. \n\nWhat do you think?",
      "is_original_content": false,
      "link_flair_text": "General Discussion",
      "permalink": "https://reddit.com/r/PromptEngineering/comments/1r57ykt/is_it_really_useful_to_store_prompts/",
      "domain": "self.PromptEngineering",
      "is_self": true,
      "comments": [
        {
          "id": "o5h4pjm",
          "author": "vir_db",
          "text": "Why don't versioning and tagging them, in order to keep different versions and prompt history?",
          "score": 8,
          "created_utc": "2026-02-15 08:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5huu86",
              "author": "Dapper-River-3623",
              "text": "Second",
              "score": 1,
              "created_utc": "2026-02-15 12:09:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ia73j",
              "author": "skeetbuddy",
              "text": "Exactly! I built a notion DB for my prompts and tag them with the model I created it for, example Input and output, and keywords so I can easily find again. I addition, I tag output type (text, image, code) and a purpose for easier organization. I use this db on the daily, across models",
              "score": 1,
              "created_utc": "2026-02-15 13:57:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hwwef",
          "author": "ImpossibleOpinion798",
          "text": "Not all of them, but the best ones. You can always optimize them further and get really lucky with them. I hope so ðŸ¤žðŸ¼",
          "score": 3,
          "created_utc": "2026-02-15 12:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gym3s",
          "author": "Difficult-Sugar-4862",
          "text": "Prompts techniques, models evolve yss thats why it important to keep versions too on prompts (like for IaC codes). I think a library is important for non technical users that are â€œdiscoveringâ€ genAI",
          "score": 2,
          "created_utc": "2026-02-15 07:03:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hpflg",
          "author": "traumfisch",
          "text": "not all prompts are created equal",
          "score": 2,
          "created_utc": "2026-02-15 11:21:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5htk6s",
          "author": "Overall_Ferret_4061",
          "text": "I think its useful to store prompts and then once and a while delete the outdated ones.\n\nEspecially if you do a lot of creative exploring sometimes your human memory can fail you and some detail you want to bring back but overall the tech is so new prompts are evolving.\n\n\nI mean I remember over 5 months ago midjourney discord mods told me the problem was my prompt was too long, nowadays a more detailed prompt is better because it understands more specificity.",
          "score": 2,
          "created_utc": "2026-02-15 11:58:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i3l6p",
          "author": "no-name-here",
          "text": "it may be more useful if you provided specific examples of past prompts that were saved, but that you now think shouldnâ€™t be.",
          "score": 2,
          "created_utc": "2026-02-15 13:16:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i8nz1",
          "author": "AxeSlash",
          "text": "I don't store many prompts. I think I've only ever reused one or two, and those were image generation prompts.\n\nInstructions, however, yes. Mainly because a) I don't trust OpenAI to not lose them, b) I write them in a structured language, so I like the syntax highlighting and auto completion notepad++ gives me, and c) editing them in the tiny boxes OpenAI give us is just not practical once they exceed a few lines.\n\nTbh, if you're regularly reusing the same prompts, convert them into instructions instead, then just supply the specifics that changed in the prompt. \n\nTreat it a function in code: my instructions are the function, my prompt is the arguments.",
          "score": 2,
          "created_utc": "2026-02-15 13:48:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i62nn",
          "author": "Junior-Translator-64",
          "text": "How you guys are storing prompts? Like do you have a specific program/app for it or do you just something like editor app and that's it?",
          "score": 1,
          "created_utc": "2026-02-15 13:32:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ioqoy",
          "author": "Striking-Session-502",
          "text": "You got a point there, new models force you to adapt, try out new things to stay on top. However, its often possible to just update/rewrite single modules of your prompt/framework. And sometimes you have a 'oh shit' moment and dont wanna start from scratch.\n\nEven once everything is truelly outdated, id still keep it around for selfanalysis. Retrospective analysis of increase in skills is a nobrainer,  next thing is meta: Changes in your own mindset. Kinda like our use of language gives away kognitive patterns, the prompting style in use can be interpreted.\n\nThink about 'vibe coders', one has to be very trusting into the machine or a newbie to prompting to vibe-code. The safetys and fallbacks begin to appear when a person has been burned, or are added by default if the person is critical by default. \n\nTry it out, dump your whole development arc into a LLM and ask about changes in kognitive pattern.",
          "score": 1,
          "created_utc": "2026-02-15 15:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5j1p8b",
          "author": "dmpiergiacomo",
          "text": "Couldn't agree more! Prompts are a parameter that should be generated and optimized through meta-prompting. Here's a powerful library https://docs.afnio.ai/",
          "score": 1,
          "created_utc": "2026-02-15 16:22:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5j3v4h",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 16:33:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5j3v6h",
              "author": "AutoModerator",
              "text": "Hi there! Your post was automatically removed because your account is less than 3 days old. We require users to have an account that is at least 3 days old before they can post to our subreddit.\n\nPlease take some time to participate in the community by commenting and engaging with other users. Once your account is older than 3 days, you can try submitting your post again.\n\nIf you have any questions or concerns, please feel free to message the moderators for assistance.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PromptEngineering) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-15 16:33:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5j68du",
          "author": "mikeyj777",
          "text": "I store prompt frameworks.  Things that will take a paragraph instruction to a comprehensive prompt with very high detail.  I have before taken them and asked a newer version to update. \n\nI find the important thing is to understand that, over time, tools generate less and less specific results.  Like the nblm podcast.  The same prompt that would give a fully detailed discussion now ends up being more generalized and leaves you with more questions.  Iâ€™m not 100% sure how to combat that.",
          "score": 1,
          "created_utc": "2026-02-15 16:44:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jo1se",
          "author": "JWPapi",
          "text": "We went a different direction entirely. Instead of storing prompts, we encode the standards as ESLint rules. If the AI generates \"don't hesitate to reach out\" in an email template, the build fails. If it uses raw Tailwind colors instead of our design tokens, the build fails. The nice part is the error messages become context for the AI in the next generation, so it learns your standards automatically. More durable than a stored prompt because it's enforced, not suggested.",
          "score": 1,
          "created_utc": "2026-02-15 18:11:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5k5gxe",
          "author": "amaturelawyer",
          "text": "I'd say that storing templates is probably good for certain tasks,  and i do that sometimes,  but direct prompts themselves? If they're not used in code, it's usually pointless for the reasons you stated. They're context based and model dependent.",
          "score": 1,
          "created_utc": "2026-02-15 19:36:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5krfxo",
          "author": "evanmrose",
          "text": "Agreed that prompt storage loses value if models/needs change. Meta prompts make sense but then you're still storing (and versioning) a prompt and you're back at square one. I built a little prompt generator/optimizer tool that I use to generate structured prompts from natural language and when it detects a query similar to something we've done in the past it'll use that as a seed and update it only if necessary. The problem is always scale. One person can keep the system up but when you have dozens or hundreds of people they get lazy and they'll just start copy pasting. Gotta make the best practices as easy as possible if you want adoption.",
          "score": 1,
          "created_utc": "2026-02-15 21:29:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5l5tns",
          "author": "Dismal-Rip-5220",
          "text": "I mostly agree with the â€œglass of milkâ€ analogy. Prompts are tightly coupled to the model, the task, and even the current best practices, so they do go stale pretty quickly as models and techniques change.\n\nThat said, storing prompts isnâ€™t useless, it just depends on what you store. Archiving **intent, structure, and constraints** tends to age better than saving raw prompt text. The underlying logic of a workflow or system instruction is often reusable, even if the exact wording needs to be regenerated for new models.",
          "score": 1,
          "created_utc": "2026-02-15 22:44:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iwi6n",
          "author": "nuxxi",
          "text": "BTW, bottles of anything never age well too, the aroma leaves through the cork and the alcohol percentage rises.\n\n\nThe good wine you bought in Italy 10yrs ago? Probably shit now.Â ",
          "score": 0,
          "created_utc": "2026-02-15 15:57:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jpa92",
              "author": "TheGeneGeena",
              "text": "This is part of why some brands switched to synthetic corks.",
              "score": 1,
              "created_utc": "2026-02-15 18:17:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}