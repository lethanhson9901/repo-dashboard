{
  "metadata": {
    "last_updated": "2026-02-14 08:45:32",
    "time_filter": "week",
    "subreddit": "ClaudeCode",
    "total_items": 20,
    "total_comments": 723,
    "file_size_bytes": 788146
  },
  "items": [
    {
      "id": "1qz8tyy",
      "title": "How to Set Up Claude Code Agent Teams (Full Walkthrough + What Actually Changed)",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qz8tyy/how_to_set_up_claude_code_agent_teams_full/",
      "author": "Silent_Employment966",
      "created_utc": "2026-02-08 13:24:44",
      "score": 431,
      "num_comments": 66,
      "upvote_ratio": 0.97,
      "text": "# \n\nClaude Code just shipped Agent Teams, and it's not just \"sub-agents with a nicer name.\" It's a completely different execution model where 3‚Äì5 independent Claude Code instances can actually collaborate on the same project, share context, exchange messages, and coordinate through a shared task system.\n\nI spent way too long digging through logs and filesystem changes to understand how this actually works under the hood. Turns out it's pretty different from the old task tool, and there are specific situations where Agent Teams are legitimately better than spinning up regular sub-agents.\n\n**The Big Difference**\n\n**Old sub-agent model:** Main agent calls task tool, sub-agent spins up, works in isolation, session terminates, only a summary comes back.\n\n**New Agent Teams model:** Shared task lists, direct messaging between agents, explicit lifecycle control (startup, shutdown). Agents can coordinate, debate, and update each other in real time instead of just working in silos.\n\n# How It Actually Works\n\nBehind the scenes, Agent Teams use five new internal tools:\n\n**TeamCreate** ‚Äì Sets up the team scaffolding (creates a folder under `.claude/teams/`)\n\n**TaskCreate** ‚Äì Adds tasks as JSON files with status tracking, dependencies, and ownership (this is different from the old Task tool, it's specifically for creating todos)\n\n**Task tool (upgraded)** ‚Äì Still spins up agents, but now supports `name` and `team_name` params to activate team mode instead of simple sub-agent mode\n\n**taskUpdate** ‚Äì Agents use this to claim tasks, update status, mark things done\n\n**sendMessage** ‚Äì The real unlock. Supports direct messages (agent to agent) and broadcasts (agent to all teammates). Messages get written to `.claude/teams/<team_id>/inbox/` and injected into each agent's conversation history as `<teammate-message teammate_id=\"...\">`.\n\nTeam-lead can send a `shutdown_request`, teammates confirm with `shutdown_response`, and sessions terminate cleanly.\n\n**When Agent Teams Are Actually Worth It**\n\nThe best use case so far: deep debugging with multiple hypotheses.\n\nExample from the official docs: users report the app exits after one message instead of staying connected. Spawn five agent teammates to investigate different theories. Have them talk to each other, try to disprove each other's ideas like a scientific debate, and update a findings doc with whatever consensus emerges.\n\nThat kind of collaborative, multi-angle investigation is way harder to pull off with isolated sub-agents that only report back summaries.\n\n**How to Set Up Agent Teams**\n\n**Step 1: Update Claude Code to latest version**\n\n**Step 2: Enable the experimental flag**\n\nOpen your settings file:\n\n    code ~/.claude/settings.json\n\nAdd this to the global settings:\n\njson\n\n    {\n      \"env\": {\n        \"CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS\": \"1\"\n      }\n    }\n\nSave the file and restart your terminal.\n\n**Step 3: Start a new Claude Code session**\n\nAgent Teams activate when your prompt explicitly asks Claude Code to create a team. For example:\n\n\"I'm designing a CLI tool that helps developers track TODO comments across their codebase. Create an agent team to explore this from different angles: one teammate on UX, one on technical architecture, one playing devil's advocate.\"\n\n**Pro tip: Use tmux or iTerm2 for the best experience**\n\nAgent Teams shine when you can see every agent working in parallel.\n\n**For iTerm2 (macOS):**\n\n1. Install iTerm2\n2. Go to Settings ‚Üí General ‚Üí Magic\n3. Enable Python API\n4. Restart iTerm2\n5. Launch Claude Code with: `claude --teammate-mode tmux`\n\nThis opens one pane for the team lead and separate panes for each agent teammate. You can click into any pane, watch what the agent is doing live, and even send direct messages to individual agents.\n\nFor a full walkthrough with logs, internal tool traces, and more examples of when Agent Teams outperform sub-agents, check out the [full breakdown](https://vibecodecamp.blog/blog/how-to-install-and-use-claude-code-agent-teams-reverse-engineered) ",
      "is_original_content": false,
      "link_flair_text": "Tutorial / Guide",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qz8tyy/how_to_set_up_claude_code_agent_teams_full/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o497pa8",
          "author": "j00cifer",
          "text": "Here‚Äôs the comparison I want to see, in fact I may do this:\n\nOption 1) no subagents at all, straight narrative with one claude instance set on dangerously skip permissions\n\n\n2) try existing sub-agent model\n\n3) try agent teams.\n\nJudge results based on : a) speed, b) completeness/accuracy, c) TOKEN COST.\n\nThe naysayers are out there naysaying that agent teams is just a way for users to use more token$ faster",
          "score": 34,
          "created_utc": "2026-02-08 14:22:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49849s",
              "author": "Silent_Employment966",
              "text": "My guess is Agent Teams burns more tokens on messaging overhead, but for deep debugging where you'd otherwise be stuck in manual loops, it might actually save time and money overall. Definitely run it and share the results, would help everyone figure out when this is worth using vs just expensive",
              "score": 18,
              "created_utc": "2026-02-08 14:24:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4bqqju",
                  "author": "thurn2",
                  "text": "When I tried this stuff out yesterday on a bunch of tasks I really didn't feel like there was *that* much communication, it mostly did feel like subagents with extra steps. It's hard to really accomplish a lot of useful \"discussion\" before everyone hits the context window limit.",
                  "score": 9,
                  "created_utc": "2026-02-08 21:52:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4axq1q",
                  "author": "Projected_Sigs",
                  "text": "Well, the metric always has to be tokens burn to accomplish the goal.  That's harder to judge, especially if agents working in isolation don't accomplish the goal.\n\nI've seen other people mention using a direct message style inter-agent communication\nThat they were creating direct message like communications between subagents.  \n\nLast fall I tried it and had a team of six subagents do a \"feasibility study\" for building a high speed computer board design.  \nEssentially, it's a complex system design with multiple subsystems that had competing requirements.  Could they work together, reason with each other toward a common goal, yet make trade-offs when required?\nI was blown away by how well it worked with so few instructions.\n\nA simple orchestrator agent (project manager) managed them, gave them their individual assignments.  The tasking was broken up like it would really be broken up on an engineering team.  They were trying to meet high level system specs, which had flowdown requirements for individual subsystems assigned to an agent (high speed signaling/communications, memory design, power delivery, board stack up, mechanical/thermal, etc).  They each picked subcomponents by themselves with no guidance and used combined spec sheets of many parts to determine subsystem performance.  \n\nI used a simple shared message board- a file- that they all wrote to.  PM sent coordination messages as group broadcasts. Subsystem agents could broadcast or address individual subagents with questions in TO:   FROM: format.   \n\nI was really impressed as hell with how it played out. How easy it is to forget that a sub agent is really smart.  They didn't just download a spec sheet, they picked popular parts commonly used in computer systems that would meet the specs for this computer.   They also researched expected part availability and potential supply chain disruption- such as parts that were sourced only from taiwan.  \n\nExample 1:  thermal sub might ask high speed comm sub what his power consumption tally was for each communication chip, so it could watch for excessive power density that couldn't be cooled.  That depended on the chip it selected and what speed it operated at.  \nWhy ask?  Because one sub shared info about temperature sensitivity of memory parts.  So the thermal guy was tracking power density a hesitability to cool it.  The high-speed guy would I either tell them the answer or say, I'll have to get back with you.  And they always followed up.\n\nWhat's so intriguing is that i dont recall giving them detailed instructions on how to coordinate.  I gave some generic instructions to the PM and PM set the ground rules for everyone.  I just gave them the ability to message, and that's what they actually did. Anyone in engineering would recognize the type of back and forth communication instantly.\n\nSeeing how they respond to failure is interesting.  They hit a couple of design points that were too aggressive.  Subsystems couldn't hit their target or even make trade offs to hit their target.  The project manager just chimed in after a struggle and made an executive decision to downscope some requirements, but still matt most of their requirement. That released the log jam that was holding up progress.  Again, that wasn't an instruction I gave.  They just took initiative.\n\nIf you do this with software design, you're probably familiar with the problem of subagent, staying in their own lane.\nBut it worked and they politely messaged each other about specs and behaviors that they were dependent on and did not try to conduct their own research.  Maybe they did some secret side research, but I wasn't aware it.\n\nOverall, it demonstrated pretty good coordination and cooperation between different agents in charge of subsystem design, under the guidance of a project manager.  \n\nWhether you do software design or computer design, you probably recognize all the same elements of coordination, trade off inspects, working toward what's a common goal, etc\nBut it gave some really insightful analyses about the capabilities of subagents to work in teams.  \n\nI'm excited to see how the subagent Teams concept plays out.",
                  "score": 4,
                  "created_utc": "2026-02-08 19:28:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o49sn7n",
                  "author": "j00cifer",
                  "text": "Will do but I‚Äôm sure others are doing that as well speak ;) thanks for the detailed write up btw.",
                  "score": 2,
                  "created_utc": "2026-02-08 16:12:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4fvj76",
              "author": "j00cifer",
              "text": "Here‚Äôs the non optimal result I don‚Äôt want to necessarily see:\n\nNo agents:  6 hours, ‚ÄúA‚Äù product, $5 token cost\n\nSub agents: 4 hours, A product, $10 token cost \n\nAgent teams:  2 hours, A product but with more un-asked for features, $20 token cost.\n\n\nI mean I get why Anthropic hopes we choose the last option if that‚Äôs the case, but are we getting a better product for our money in the end?  Is a little added speed necessary for the cost?  We‚Äôre not talking 6 weeks vs 2 hours, closer to 6hrs vs 2hrs.\n\nIf the agent teams keep expanding the dev scope it could end up being no time savings at all.",
              "score": 1,
              "created_utc": "2026-02-09 14:51:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ac38z",
          "author": "CyberiaCalling",
          "text": "Every time I come up with an idea that improves Claude code for my use case and implement it in a janky way Claude Code then gets updates implementing the idea but it a way better fashion üòÇ I love this update.",
          "score": 13,
          "created_utc": "2026-02-08 17:47:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4d6mqg",
              "author": "InknDesire",
              "text": "Lol has happened with me a lot ü§£ü§£. \n\nBut I'm no expert dev, just a pm. But whenever I have an idea I first check if somebody has already implemented it.",
              "score": 3,
              "created_utc": "2026-02-09 02:39:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4hp3cc",
              "author": "Lorenzo9196",
              "text": "They are training on your ideas.",
              "score": 3,
              "created_utc": "2026-02-09 20:07:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4hw7mp",
              "author": "Icy-Secretary-3018",
              "text": "Tell me about it. i built a persona prompting system from scratch last year and now its absolutely worthless lol",
              "score": 3,
              "created_utc": "2026-02-09 20:43:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48zhyk",
          "author": "Deep_Structure2023",
          "text": "Just when I was thinking one ai agent session wasn't enough, thanks a lot, hope this will reduce time in managing frontend, backend and database switching",
          "score": 9,
          "created_utc": "2026-02-08 13:32:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48zr09",
              "author": "Silent_Employment966",
              "text": "glad you find it helpful",
              "score": 2,
              "created_utc": "2026-02-08 13:33:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4e2l2f",
          "author": "ultrathink-art",
          "text": "One tip for agent teams: make sure your orchestrator logic handles task dependencies properly. We've seen issues where agents claim tasks before their prerequisites complete, leading to failed runs.\n\nThe key is having a clear state machine (pending ‚Üí ready ‚Üí claimed ‚Üí in_progress ‚Üí complete) and only marking tasks as 'ready' once all blockers are resolved. Also recommend heartbeat/timeout monitoring to catch stuck agents.",
          "score": 3,
          "created_utc": "2026-02-09 06:09:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l7z39",
              "author": "AIEnthusiast369",
              "text": "How do you do that? is it part of the prompt that explains each state?",
              "score": 1,
              "created_utc": "2026-02-10 09:49:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o49pqf0",
          "author": "ragnhildensteiner",
          "text": "Great write-up. I'm just disappointed with the \"best use-case\" conclusion. It's best mostly only for complex debugging?\n\nWhat are your opinions on using teams for larger features in a web app for example? Have several roles in the team, frontend, backend, test-writer, code reviewer, etc. Is it beneficial to use teams for that you think?",
          "score": 2,
          "created_utc": "2026-02-08 15:58:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d98oz",
          "author": "rjyo",
          "text": " thing worth adding for people using tmux with agent teams: set up mosh instead of plain SSH for remote access. Regular SSH drops your session the second your network hiccups, which is painful when you have 3-5 agents running in parallel and one of them needs your approval to proceed.\n\n  \nThis is actually the exact problem that got me to build Moshi (an iOS terminal app). I was running agent teams on my dev machine and kept losing SSH sessions when checking on them from my phone. The whole point of agent teams is they work autonomously, but they still need you for approvals and unblocking. Being able to jump into any tmux pane from your phone and approve something means the team doesnt sit idle for hours while you are away from your laptop.\n\n  \nAlso for anyone setting this up, make sure your [CLAUDE.md](http://CLAUDE.md) is solid before spawning a team. Each teammate reads it independently, so any vague instructions get amplified across multiple agents. I found that being extremely specific about file conventions and test commands saves a ton of back and forth between teammates.",
          "score": 2,
          "created_utc": "2026-02-09 02:53:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mzhre",
          "author": "stefansimik",
          "text": "I went step by step, but cannot get the splittled layout in iTerm  \n(it2 installed, iterm settings changed according to the manual)",
          "score": 2,
          "created_utc": "2026-02-10 16:26:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n6pzi",
              "author": "chillebekk",
              "text": "Same",
              "score": 1,
              "created_utc": "2026-02-10 17:00:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4szs3a",
                  "author": "Striking_Ordinary_26",
                  "text": "Try running `tmux -CC` in iTerm, then spin up claude in that new window.",
                  "score": 2,
                  "created_utc": "2026-02-11 14:35:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z4swp",
          "author": "Kindly-Inside6590",
          "text": "Thanks for the tutorial, I switched my Claude Session Manager now from GNU Screen to Tmux cauze of this ;-) I built this to manage my Claude Code sessions on a small unix based machine linux/os x. that automaticlly visualizes subagents for me and helps me keep track of my tmux sessions -> [https://github.com/Ark0N/Claudeman](https://github.com/Ark0N/Claudeman) ",
          "score": 2,
          "created_utc": "2026-02-12 13:15:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z9rbi",
              "author": "Silent_Employment966",
              "text": "glad you find it helpful",
              "score": 3,
              "created_utc": "2026-02-12 13:44:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52uqwm",
          "author": "gorgono95",
          "text": "So we can not use our predefined agents for the team?",
          "score": 2,
          "created_utc": "2026-02-13 00:21:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o492b2c",
          "author": "wado729",
          "text": "Thank you for the walkthrough",
          "score": 1,
          "created_utc": "2026-02-08 13:49:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o495f0r",
              "author": "Silent_Employment966",
              "text": "glad you find it helpful",
              "score": 1,
              "created_utc": "2026-02-08 14:08:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4950tn",
          "author": "d1pl0mat1c",
          "text": "do you know if Ghostty can be a substitute for iTerm2?\n\nwhen you were using this, did you see a different rate of token consumption?",
          "score": 1,
          "created_utc": "2026-02-08 14:06:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o498iw4",
              "author": "petrprie",
              "text": "You can use tmux + Ghostty.",
              "score": 2,
              "created_utc": "2026-02-08 14:26:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4987rc",
              "author": "Silent_Employment966",
              "text": "Haven't tried Ghostty but if it supports tmux it should work. Token consumption definitely feels heavier with all the agent messaging, but I didn't track hard numbers, would be great to see actual benchmarks",
              "score": 1,
              "created_utc": "2026-02-08 14:25:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49frzd",
                  "author": "Mysterious_Charity_6",
                  "text": "It doesn‚Äôt work in Ghostty on the feature release, but it does work with tmum and iterm2",
                  "score": 1,
                  "created_utc": "2026-02-08 15:07:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4art5k",
          "author": "structured_flow",
          "text": "Is it just me or is it hard for anyone else to read a post written by AI, it feels disingenuous and worse, spamming and lazy.  So many other places writing with AI is great, I just think Reddit should be different",
          "score": 1,
          "created_utc": "2026-02-08 18:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4awjb3",
          "author": "Snap_Leaks_official",
          "text": "Hey, sorry if this is a basic question, but I'm new to Claude code. I've already made a really big and complicated web app. Can I integrate this Claude team into my existing project now and have them keep working on it to make it even better? If so, could you please tell me the steps? That would be super helpful!",
          "score": 1,
          "created_utc": "2026-02-08 19:22:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4az2f9",
          "author": "Projected_Sigs",
          "text": "This was super helpful- thank you for the post & sharing.  I was really anxious to learn more about this feature, and you just saved me a lot of time!!",
          "score": 1,
          "created_utc": "2026-02-08 19:34:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b39lo",
          "author": "nick_with_it",
          "text": "i dont have confidence in spawning agent teams when a single claude code instance can't even instantiate skills properly recently ... ",
          "score": 1,
          "created_utc": "2026-02-08 19:55:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b46r6",
          "author": "LeyLineDisturbances",
          "text": "as someone who‚Äôs been testing this out extensively, i recommend you to have claude opus 4.6 create amplan for each agent. Make sure it specificies the model for each agents, because for some models, using sonnet will be more than enough.",
          "score": 1,
          "created_utc": "2026-02-08 20:00:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b8jtz",
          "author": "SheetPostah",
          "text": "Thanks!",
          "score": 1,
          "created_utc": "2026-02-08 20:21:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bbbe1",
          "author": "kepners",
          "text": "I have set this up using my agents. God Damn its so good. You chat with agents, tell them they are wrong, repeat the idea, watch them argue solutions. Very impressed!",
          "score": 1,
          "created_utc": "2026-02-08 20:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4coojh",
          "author": "LargeDan",
          "text": "I‚Äôm finding this doesn‚Äôt work well in headless mode. Seems to crash or hang 50% of the time",
          "score": 1,
          "created_utc": "2026-02-09 01:02:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fpm64",
              "author": "NoleMercy05",
              "text": "Oh wow. Thanks for the info. I pretty much use only cc headless. I'll check it out and file feedback.",
              "score": 1,
              "created_utc": "2026-02-09 14:18:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hlteh",
          "author": "Scn64",
          "text": "Is anyone else having trouble getting Claude to actually use the new agents consistently? I'll put \"create an agent team\" in my prompt but half the time it decides to use the old agents instead.",
          "score": 1,
          "created_utc": "2026-02-09 19:50:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iun8x",
          "author": "Leading-Round-6809",
          "text": "I'm curious: when does the agent team end?\n\nIn the official documentation (specifically the example where they wrote the compiler), they had to use an infinite loop to keep the sessions running forever. If I give the agent team a really complex task is there a point where the team decides they can't do it?",
          "score": 1,
          "created_utc": "2026-02-09 23:39:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54qerj",
          "author": "Hey-Intent",
          "text": "Merci . ",
          "score": 1,
          "created_utc": "2026-02-13 08:21:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o571xxl",
          "author": "sAnakin13",
          "text": "dose it work for claude cowork? or just code?\n\n",
          "score": 1,
          "created_utc": "2026-02-13 17:15:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o490ndc",
          "author": "GreenLitPros",
          "text": "It's much always worth it for me on my projects. I've already assigned permanent personalities via a hybrid openclaw/marvin style approach (totally custom though) and reward systems. They all have their domains that they know well with ongoing lessons, they can be initiated either directly MARVIN Style or be brought in as a team.\n\n4.6 and agentteams is the beginning of psuedo agi. agent swarms that feel like agi before a single model has it all.",
          "score": 1,
          "created_utc": "2026-02-08 13:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4939v4",
          "author": "2kool4zkoolz",
          "text": "How is this different from beads and gastown? And are they actually better??",
          "score": 1,
          "created_utc": "2026-02-08 13:55:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o497uhl",
              "author": "Silent_Employment966",
              "text": "Beads and Gastown are more about agent orchestration frameworks ig you build it yourself. Agent Teams is built directly into Claude Code, so it's zero setup and the agents can message each other in real time",
              "score": 5,
              "created_utc": "2026-02-08 14:22:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4auk2z",
                  "author": "throwaway490215",
                  "text": "I've moved off claude to pi. I've set up a rather simple way of waiting for commands to start and finish, tmux capture pane, and the ability to spawn coding agents.\n\nThis works great. A folder to track work between draft, wip, done. and a structure for what for files to created driven by a team lead. \n\nI've not tried claude teams, but I'm going to call it right now; they missed the mark again. \n\nThere is no value in anthropomorphizing 'teams', and 'members' and 'messages', or any long-running task. \n\n( Its ironic in a sense that 'anthropic' seems to not have learned the no-anthropomorphizing lesson multiple times. )\n\nMy pi (team) lead knows how to read the same tmux pane I'd read as a user of a single Claude. It automates how *I* use Claude. i.e. it has access to coding agents. It freely spawns agents to write investigations, implementation, reviews, kills them, starts up the next one with the right references by using a tmux type function. All in tmux panes I control. \nNo message system beyond that. \n\nI can instantly tweak the scaffolding with the phrase \"next time do X\". \nIt can automate the repetitive tasks I do while using claude (plan, refine, impl, review) \n\n\nI might give teams a try next week, but i'm going to go out on a limb and bet teams is the wrong way. Same as anthropomorphic team agents. Less context is more. \n\nTLDR: The part where they inject the concepts of `team` via a param name like `team_name` is the wrong abstraction, and inter team messaging seems extremely dumb.",
                  "score": 1,
                  "created_utc": "2026-02-08 19:12:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4guu92",
                  "author": "2kool4zkoolz",
                  "text": "But can it persist memories? One of my main use cases for beads, is to persist memory and it managed to reduce so many markdown files and info it has to read. In my setup, Claude only needs to read a couple small files to get up to speed, and find related beads it worked on to enable itself on the task at hand.\n\nAlso wonder what you think u/AtomikPi",
                  "score": 1,
                  "created_utc": "2026-02-09 17:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4a9otr",
              "author": "AtomikPi",
              "text": "The tasks update is a whole lot like Beads. And this is basically a much lighter and simpler version of Gas Town. Doesn't have all the specialized roles, watchers, merge queue, ephemeral workers, etc.",
              "score": 1,
              "created_utc": "2026-02-08 17:35:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o496si7",
          "author": "klumpp",
          "text": "Does anyone have some actual prompts they used that they felt were worth it? So far I‚Äôve just seen the documentation‚Äôs vague examples. Not looking for a copy/paste. A summary is fine.",
          "score": 1,
          "created_utc": "2026-02-08 14:16:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49db64",
              "author": "Glittering-Lie-1340",
              "text": "Download the sdk, have cc read it, tell cc what you want the team to be able to do, let cc build it. \n\nI prefer having a hub and spoke with 1 leader/decision maker, the leader only delegates and does not write code. Also add a coach that evaluates feedback from other agents to improve them after project completion.",
              "score": 2,
              "created_utc": "2026-02-08 14:53:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4asbhi",
              "author": "tristanryan",
              "text": "Just give CC the link to official CC documentation about agent teams, then tell it what you want to do, and have CC draft comprehensive prompt, and give that prompt to a new session. \n\nIf I don‚Äôt like prompt, I give feedback and sometimes tell it to do web searches to learn more up to date prompting best practices lol.",
              "score": 2,
              "created_utc": "2026-02-08 19:01:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4cszpc",
                  "author": "klumpp",
                  "text": "Good idea. He recommended \"debugging with competing hypotheses scenario or a large multi-file refactor where coordination matters\" which are the same examples. Though he did say that agent teams were probably not worth it for me when compared to subagents.",
                  "score": 1,
                  "created_utc": "2026-02-09 01:27:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4e9zk1",
              "author": "Let047",
              "text": "I did to audit a code base and check it against doc, it worked, was fast and awesome... But it burnt 367k token in the process instead of 30k for a more sequential task.",
              "score": 1,
              "created_utc": "2026-02-09 07:13:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4lvmxu",
                  "author": "Retromorphix",
                  "text": "A huge chunk of that token burn is just¬†bloat. Duplicate system-reminders that accumulate across agents, oversized tool outputs that get re-sent on every turn. It adds up fast with multiple agents.\n\nWe built Cozempic to prune that stuff. Won't turn 367k into 30k, but trimming the noise means more of your tokens go toward actual work instead of redundant context. Also helps agents stay coherent longer before compaction wipes their memory.¬†\n\npip install cozempic && cozempic init\n\n[https://github.com/Ruya-AI/cozempic](https://github.com/Ruya-AI/cozempic)  \n  \nLet me know if it helps.",
                  "score": 2,
                  "created_utc": "2026-02-10 13:00:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48zr6z",
          "author": "Raseaae",
          "text": "Is this actually faster than just using subagents?",
          "score": 0,
          "created_utc": "2026-02-08 13:33:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o490fjp",
              "author": "Silent_Employment966",
              "text": "depends on your usecase. ",
              "score": 2,
              "created_utc": "2026-02-08 13:38:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4aa5cs",
              "author": "AtomikPi",
              "text": "I would think of this more as a way to handle very complicated, context-intensive tasks rather than faster. Subtasks already allows for speed benefits from parallelism, but this allows for communication and coordination at the cost of complexity and token consumption.",
              "score": 2,
              "created_utc": "2026-02-08 17:37:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o499avs",
              "author": "j00cifer",
              "text": "It‚Äôs probably more expensive.  Remember, Anthropic intends to be profitable before any of its competitors.",
              "score": 1,
              "created_utc": "2026-02-08 14:31:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3to9f",
      "title": "Claude Code's CLI feels like a black box now. I built an open-source tool to see inside.",
      "subreddit": "ClaudeCode",
      "url": "https://v.redd.it/83qhnkdhfajg1",
      "author": "MoneyJob3229",
      "created_utc": "2026-02-13 16:25:01",
      "score": 403,
      "num_comments": 70,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Showcase",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r3to9f/claude_codes_cli_feels_like_a_black_box_now_i/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o56yzfl",
          "author": "Pitiful-Impression70",
          "text": "this is exactly what ive been wanting. the \"done\" with no context thing drives me insane, especially when youre trying to figure out why it burned through 8k tokens on what should have been a 3 line change. gonna try this on my next session",
          "score": 37,
          "created_utc": "2026-02-13 17:01:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56zgco",
              "author": "MoneyJob3229",
              "text": "You're going to love the Context Breakdown then.\n\nIt breaks down usage by File Reading vs. Tool Output vs. Thinking. Usually, when that happens, it's either an accidental huge file read or it got stuck in a thinking loop. This will show you exactly which one it was instantly",
              "score": 7,
              "created_utc": "2026-02-13 17:03:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o571s5g",
          "author": "superanonguy321",
          "text": "I hate installing things people make. But damn I love this.",
          "score": 16,
          "created_utc": "2026-02-13 17:15:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57cqwr",
              "author": "evia89",
              "text": "U fork it, do quick review for malware then install from your repo",
              "score": 10,
              "created_utc": "2026-02-13 18:07:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57cwoh",
                  "author": "superanonguy321",
                  "text": "Thanks. For all the nerd that I am, I've never githubbed. Other than download some stuff. I guess its time i grow up and learn",
                  "score": 7,
                  "created_utc": "2026-02-13 18:08:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o59qnoh",
              "author": "rm-rf-rm",
              "text": "Me too, but ive gotten really good at reading the signs. This one is solving a problem thats cropped up in the past few days so he's a super fast mover but the level of SaaS-ery is red flag. I'll stay away for now",
              "score": 2,
              "created_utc": "2026-02-14 01:45:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o572lmi",
              "author": "MoneyJob3229",
              "text": "Appreciate it. I hate installing random apps too, so I'm glad this one was worth it üôèüèª",
              "score": 1,
              "created_utc": "2026-02-13 17:19:03",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5a2uzm",
              "author": "x8code",
              "text": "Agreed, I don't trust 99% of the stuff I see here. I need to write an AI skill that can scan for suspicious code and automate analysis.",
              "score": 1,
              "created_utc": "2026-02-14 03:03:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57ad6b",
          "author": "Cal_lop_an",
          "text": "Love it! Same thing annoyed me so built visibility into a vscode plugin. \n\nhttps://github.com/cesarandreslopez/sidekick-for-claude-max\n\nIll try out yours.",
          "score": 17,
          "created_utc": "2026-02-13 17:56:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57vn22",
              "author": "Relative_Mouse7680",
              "text": "This also looks interesting. Does it require a max subscription specifically, or will any subscription work?",
              "score": 3,
              "created_utc": "2026-02-13 19:39:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o59x6xi",
                  "author": "Cal_lop_an",
                  "text": "Any will do.",
                  "score": 3,
                  "created_utc": "2026-02-14 02:27:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5b0a1i",
              "author": "Ok-Hat2331",
              "text": "the way you use oauth is it allowed by tos?",
              "score": 1,
              "created_utc": "2026-02-14 07:28:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5b0zxw",
                  "author": "Winter-Speed4360",
                  "text": "It uses claude-sdk, so I believe so. ",
                  "score": 1,
                  "created_utc": "2026-02-14 07:35:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o576ce7",
          "author": "SubjectHealthy2409",
          "text": "Use ACP and connect to an IDE",
          "score": 5,
          "created_utc": "2026-02-13 17:37:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57vw26",
              "author": "Relative_Mouse7680",
              "text": "What is an ACP?",
              "score": 1,
              "created_utc": "2026-02-13 19:40:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5868bu",
                  "author": "SubjectHealthy2409",
                  "text": "https://agentcommunicationprotocol.dev/introduction/welcome\n\nZed IDE has this inbuilt",
                  "score": 1,
                  "created_utc": "2026-02-13 20:31:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56wd6p",
          "author": "Relative_Mouse7680",
          "text": "I'll check it out later, but looks good. This has been Something which jas annoyed me as well, not knowing what's going on behind the scenes. Will it also show exact tool calls?",
          "score": 3,
          "created_utc": "2026-02-13 16:48:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56wy4z",
              "author": "MoneyJob3229",
              "text": "Yeah¬†‚Äî it shows every tool call with full details (paths, diffs, command output, subagent trees), not just \"Read¬†3 files.\" You¬†can also set custom notification triggers (e.g. .env access, errors, high token usage) for specific tool calls, so you get alerted when something specific happens.",
              "score": 4,
              "created_utc": "2026-02-13 16:51:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o56y393",
                  "author": "Relative_Mouse7680",
                  "text": "Great, I'm excited to try it out. But one issue I just noticed, it's an .exe file for windows. Is it possible to install and use it in any other way, such as via npm?",
                  "score": 5,
                  "created_utc": "2026-02-13 16:57:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o574woi",
          "author": "ethanz5",
          "text": "I‚Äôm generally not a fan of tools-on-tools but this looks worthwhile! I hope it gets you what you want.\n\nQuestion: does it provide actionable tips? That would be my primary reason for trying it out.",
          "score": 3,
          "created_utc": "2026-02-13 17:30:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o576cm1",
              "author": "MoneyJob3229",
              "text": "It provides actionable insights rather than prescriptive tips.\n\nIt won't pop up and say 'Refactor this function.' But it will show you that package-lock.json is consuming 40% of your context window (which the CLI hides).\n\nIt gives you the forensic data to make those decisions instantly, instead of guessing why your session is slow or expensive",
              "score": 1,
              "created_utc": "2026-02-13 17:37:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o576m4u",
                  "author": "ethanz5",
                  "text": "Good enough for me, I‚Äôll try it out soon!",
                  "score": 1,
                  "created_utc": "2026-02-13 17:38:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o576gzw",
          "author": "No-Word-2912",
          "text": "This is actually goated bro. I get that a lot of people vibe code including myself but it‚Äôs amazing seeing what everyone can bring out to the world if they had coding skills.\n\nI‚Äôll give this a try when I get home.\n\nQuick question: Do you think you could implement in any way this - https://www.reddit.com/r/ClaudeAI/s/mRtbQA09MD - it basically helps reducing usage and limits.",
          "score": 2,
          "created_utc": "2026-02-13 17:37:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5797ar",
              "author": "MoneyJob3229",
              "text": "Thanks bro! Glad you like it.\n\nThat link is gold. I‚Äôm obsessed with token efficiency too, so I‚Äôll definitely look into integrating some of those ideas.",
              "score": 2,
              "created_utc": "2026-02-13 17:51:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o58b7l1",
          "author": "klausagnoletti",
          "text": "Looks great. Would love to try it out. How do I do that on Linux? Looks like there's only a Win and Mac version.",
          "score": 2,
          "created_utc": "2026-02-13 20:56:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o597otm",
              "author": "notyou",
              "text": "it's not done yet, but i just told claude code \"this project was built for macos and windows. brainstorm ways to make it work on linux, specifically on this arch system\" and about ten minutes later it's working well enough to observe the session in which it's doing the work.\n\n",
              "score": 2,
              "created_utc": "2026-02-13 23:49:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o598d0e",
                  "author": "klausagnoletti",
                  "text": "Cool. Luckily I am on an arch derivate. So that‚Äôs awesome.",
                  "score": 1,
                  "created_utc": "2026-02-13 23:53:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5anqnf",
              "author": "MoneyJob3229",
              "text": "just added a linux build to the latest release! you can grab the appimage here: [https://github.com/matt1398/claude-devtools/releases/tag/v0.4.0](https://github.com/matt1398/claude-devtools/releases/tag/v0.4.0)\n\ngive it a spin and let me know if it runs okay on your distro. would love to confirm it's working smoothly for you.",
              "score": 1,
              "created_utc": "2026-02-14 05:37:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o58c7bv",
          "author": "websitebutlers",
          "text": "This is awesome, nice work!",
          "score": 2,
          "created_utc": "2026-02-13 21:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a0nah",
              "author": "MoneyJob3229",
              "text": "thanks! let me know what you think once you've had a chance to play around with it. ",
              "score": 1,
              "created_utc": "2026-02-14 02:49:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o58djtx",
          "author": "snow_schwartz",
          "text": "Yesssssssss! At last!",
          "score": 2,
          "created_utc": "2026-02-13 21:08:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58fhdf",
          "author": "C0123",
          "text": "Super impressive work solving a genuine problem.",
          "score": 2,
          "created_utc": "2026-02-13 21:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58n1qh",
          "author": "Sidion",
          "text": "Very cool will look at this. How do you get the information and know how it relates to the token break down? The json you parse already has this and you're just serving it to the user? Genuinely curious as I wasn't aware of what information was surfaced behind the scenes and would love to know more",
          "score": 2,
          "created_utc": "2026-02-13 21:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a0tm9",
              "author": "MoneyJob3229",
              "text": "yep, it‚Äôs all sitting right there in \\~/.claude/projects/.\n\nessentially, the cli logs every single tool call and provider request/response as json. the \"magic\" is just tailing those files and mapping the usage block (which has the token counts) to the specific content blocks or tool outputs in that same event.\n\nclaude code hides it behind a progress bar, but the raw data is actually pretty detailed. if you poke around those logs, you'll see exactly how much context it's carrying‚Äîit's just a nightmare to read manually lol.",
              "score": 2,
              "created_utc": "2026-02-14 02:50:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5b1163",
                  "author": "Sidion",
                  "text": "Awesome this is actually super helpful! Thanks for sharing :)",
                  "score": 1,
                  "created_utc": "2026-02-14 07:35:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o597dvw",
          "author": "chrisrand",
          "text": "Can I use this as the primary interface for Claude Code? ",
          "score": 2,
          "created_utc": "2026-02-13 23:47:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a146b",
              "author": "MoneyJob3229",
              "text": "not really‚Äîit's meant to be a sidecar, not a replacement.\n\na lot of people (myself included) still prefer the terminal for actually typing commands and coding. the app is really just there to be the \"second monitor\" so you can observe the logs and token usage in real-time while you work in the cli.\n\nthink of it as a dashboard to keep claude honest while you do the actual work in the terminal.",
              "score": 1,
              "created_utc": "2026-02-14 02:52:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ab9st",
          "author": "davblaster",
          "text": "looks interesting. linux support would be nice.",
          "score": 2,
          "created_utc": "2026-02-14 04:01:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b1dpn",
          "author": "cmndr_spanky",
          "text": "This is one of the main reasons I keep using cursor.. I like to see WTF the model / agent is doing.  And although they have amazing LLM researchers, I don‚Äôt really trust the engineers at Anthropic.",
          "score": 2,
          "created_utc": "2026-02-14 07:38:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b47s9",
          "author": "Rhinoseri0us",
          "text": "Saving for future!",
          "score": 2,
          "created_utc": "2026-02-14 08:05:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o570b6u",
          "author": "its_Caffeine",
          "text": "This is cool, but I have to admit I largely don‚Äôt trust this and wouldn‚Äôt use this seriously because it looks like it was heavily vibecoded.\n\nA lot of the code quality is very poor and not well put together.",
          "score": 4,
          "created_utc": "2026-02-13 17:07:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5715q8",
              "author": "MoneyJob3229",
              "text": "Fair point! üòÖ It definitely started as a 'scratch my own itch' project to solve the CLI visibility issue ASAP, so I prioritized shipping over polishing. Since it's open source, I'd love to see a PR if you have ideas on how to structure it better! Ideally, we can turn those 'bad vibes' into good architecture together.",
              "score": 7,
              "created_utc": "2026-02-13 17:12:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5764sc",
                  "author": "its_Caffeine",
                  "text": "Yeah, I think it's genuinely cool and useful, and kudos for the work you put in here, I just wish I could use a tool like this seriously in my work. I just can't sign off on it unfortunately because I can't really trust the code here. üôÉ\n\n> Since it's open source, I'd love to see a PR if you have ideas on how to structure it better! Ideally, we can turn those 'bad vibes' into good architecture together.\n\nTrouble with a lot of AI coding is that LLMs trend toward greater and greater entropy unless it's steered away from doing so, so I think contributing to untangling a lot of this would be pretty difficult.",
                  "score": 2,
                  "created_utc": "2026-02-13 17:36:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o599g1p",
              "author": "alex2003super",
              "text": "Crazy to spot handles from neoliberal in the wild\n\nHi lol ÔΩû(„Å§ÀÜ0ÀÜ)„Å§ÔΩ°‚òÜ",
              "score": 1,
              "created_utc": "2026-02-13 23:59:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o59l6na",
                  "author": "its_Caffeine",
                  "text": "Hey friend :D",
                  "score": 1,
                  "created_utc": "2026-02-14 01:10:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o57h8b4",
          "author": "ruibranco",
          "text": "the token breakdown by category is the killer feature here. i've lost count of how many times claude burned through context reading the same file three times because it forgot it already had it open.",
          "score": 1,
          "created_utc": "2026-02-13 18:29:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57i9ky",
              "author": "MoneyJob3229",
              "text": "seriously. I hated every time I get context filled in just few queries. That breakdown was born out of pure frustration with that exact loop lol.",
              "score": 1,
              "created_utc": "2026-02-13 18:34:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o57nska",
          "author": "lgbarn",
          "text": "Genius work. Definitely adding this to my workflow.",
          "score": 1,
          "created_utc": "2026-02-13 19:00:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59zlbv",
              "author": "MoneyJob3229",
              "text": "Appreciate it! Let me know if you run into any issues or have ideas for features. Happy coding man.",
              "score": 1,
              "created_utc": "2026-02-14 02:42:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o57ukrk",
          "author": "l_eo_",
          "text": "Awesome!\n\nI was not really happy about so much details being removed from the context, eg just \"Reading File\" instead of details.\n\nBefore I was able to stop and steer Claude a lot more.\n\nThank you for making this available, will certainly test!",
          "score": 1,
          "created_utc": "2026-02-13 19:33:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59zu30",
              "author": "MoneyJob3229",
              "text": "That‚Äôs exactly why I built it. Honestly, cli's abstraction is so frustrating when you‚Äôre trying to actually monitor what‚Äôs happening. Hope it helps get that control back!",
              "score": 1,
              "created_utc": "2026-02-14 02:44:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o584zvp",
          "author": "unexpectedkas",
          "text": "I really want to try this, but is we it's an Electron app, so GUI.\n\nI would love to be able to deploy it in my devcontainers and access it via web, so I can establish it for the whole team, and avoid installing an app in the os.\n\nAny chance you can try to add this?",
          "score": 1,
          "created_utc": "2026-02-13 20:25:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5867s3",
          "author": "PanGalacticGargleFan",
          "text": "This is great!! Ctrl + O is hard to understand/digest. Great also showing what‚Äôs going on on agents working in parallel threads, at the mo is hard understand what they‚Äôre doing you just wait for them to reply back etc",
          "score": 1,
          "created_utc": "2026-02-13 20:31:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a0kog",
              "author": "MoneyJob3229",
              "text": "exactly. I mostly wanted to see how subagents, teams were working on specifically - which I made it.   \nglad the agent tree is helping, cheers!",
              "score": 1,
              "created_utc": "2026-02-14 02:48:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o58tm3x",
          "author": "ScatteredDandelion",
          "text": "I noticed you have installation files for windows and macos (apple silicon). Are you also planning to create an installer for macos that still runs on intel?",
          "score": 1,
          "created_utc": "2026-02-13 22:28:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5anm3y",
              "author": "MoneyJob3229",
              "text": "just added an intel build for mac! you can grab it here: [https://github.com/matt1398/claude-devtools/releases/tag/v0.4.0](https://github.com/matt1398/claude-devtools/releases/tag/v0.4.0)\n\nshould work fine on older macs now. let me know if it runs smoothly for you.",
              "score": 1,
              "created_utc": "2026-02-14 05:35:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o59b40y",
          "author": "raucousbasilisk",
          "text": "Does setting CC to verbose not tell you guys enough?",
          "score": 1,
          "created_utc": "2026-02-14 00:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aoqya",
              "author": "darkguy2008",
              "text": "It used to, but now it doesn‚Äôt as much as December 2025's version. I honestly don‚Äôt know what happened at Anthropic after their New Year‚Äôs party because everything has been a clusterfuck of downgrades since January",
              "score": 1,
              "created_utc": "2026-02-14 05:45:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o59l6dc",
          "author": "boffhead",
          "text": "I love the idea and would like to use this, I use CC from WSL Linux (Ubuntu) can that be supported?  I started on windows but kept running into windows path issues and running linux tools on windows so I switch to native WSL linux which is much faster.",
          "score": 1,
          "created_utc": "2026-02-14 01:10:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5angvw",
              "author": "MoneyJob3229",
              "text": "just updated the app to support this. now handles wsl paths automatically, and i added an option to manually point it to your log directory if things get weird.\n\ncheck it out here: [https://github.com/matt1398/claude-devtools/releases/tag/v0.4.0](https://github.com/matt1398/claude-devtools/releases/tag/v0.4.0)\n\nlet me know if it works for your setup!",
              "score": 1,
              "created_utc": "2026-02-14 05:34:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o59v50w",
          "author": "codeninja",
          "text": "How well does this work for agent swarms?",
          "score": 1,
          "created_utc": "2026-02-14 02:14:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a4nju",
              "author": "MoneyJob3229",
              "text": "it handles them great. it actually untangles all those messy, interleaved logs and visualizes them as a proper tree. you can see exactly what each sub-agent is doing in parallel without the terminal noise. ",
              "score": 1,
              "created_utc": "2026-02-14 03:15:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5a9os6",
          "author": "gogojrod",
          "text": "which program do you use for left and right window?",
          "score": 1,
          "created_utc": "2026-02-14 03:50:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5advbm",
              "author": "MoneyJob3229",
              "text": "Left is iTerm2 and right is the my claude-devtools desktop app. For the layout, yeah, I'm just using Magnet to snap them side-by-side.",
              "score": 2,
              "created_utc": "2026-02-14 04:20:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qz2kv0",
      "title": "As a Claude Code devotee I am currently using Codex to do 95% of my coding",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qz2kv0/as_a_claude_code_devotee_i_am_currently_using/",
      "author": "LaCaipirinha",
      "created_utc": "2026-02-08 07:24:45",
      "score": 379,
      "num_comments": 167,
      "upvote_ratio": 0.92,
      "text": "I am/was a huge fan of Claude Code and found it the absolute best implementation of gen AI in coding until the last 1-2 weeks. I'm not sure what has happened, the quality is generally still very high but the usage limits have become absolutely beyond a joke, basically unusably restrictive.\n\nI can code on GPT 5.3 Extra High for hours on end without a single thing getting in my way but I can give Claude one reasonably complex prompt and by the time it is done, I have used about 50-70% of my 5h limit. Two prompts and I'm done, 2 days and that's it for the week.\n\nAm I the only one that has noticed an absolutely huge difference in what you can get done within your subscription tier lately?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qz2kv0/as_a_claude_code_devotee_i_am_currently_using/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o47u74h",
          "author": "hollowgram",
          "text": "Yes the plan went from the best deal around to the biggest headache. Quality has also taken a dive. Resisting changing to Codex but I‚Äôm getting some excellent results with 5.3 on my $20 plan that‚Äôs tempting me away.¬†",
          "score": 114,
          "created_utc": "2026-02-08 07:30:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47uskr",
              "author": "LaCaipirinha",
              "text": "I haven't even managed to run down my Codex limits on a $20 plan and I am coding absolutely non-stop, and the quality probably is slightly higher than CC atm.",
              "score": 28,
              "created_utc": "2026-02-08 07:36:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o48j16x",
                  "author": "TheDuhhh",
                  "text": "Yeah this is me. Literally, I had few problems that neither claude opus 4.5 or gemini 3 pro were able to solve. Codex solved it from 2 tries. The nice thing? I have never hit the usage limit on codex yet. \n\nI completely stopped using claude, and will probabky cancel my claude subscription. Its funny because just a month ago I was trying to cancel my chatgpt subscription (but open ai I think gave me 3 months free so I stayed).",
                  "score": 6,
                  "created_utc": "2026-02-08 11:24:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4d0h6x",
                  "author": "just_damz",
                  "text": "+1\n\nEven if cc is amazing, codex is the way to go. Yoi can use opus to review architectures or critical tasks, but codex won‚Äôt just drop you while working.",
                  "score": 3,
                  "created_utc": "2026-02-09 02:08:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o48a6km",
                  "author": "debian3",
                  "text": "It‚Äôs crazy. Claude pro I hit my limit within 30 minutes. Codex plus I have never hit the 5h limit. I willl hit the weekly one, but you can get 2-3 days of intense usage. Codex plus right now is 4x, so it won‚Äôt stay forever.  But yeah, 5.3 codex is the first model from openai that I like for coding. The previous version were dreadful to use.",
                  "score": 5,
                  "created_utc": "2026-02-08 10:01:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o49qew2",
                  "author": "thurn2",
                  "text": "Did they make Codex support for subagents better? That was the big issue for me",
                  "score": 1,
                  "created_utc": "2026-02-08 16:01:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4kjx7v",
                  "author": "yycTechGuy",
                  "text": "You have to be working hard to use it. \n\nhttps://preview.redd.it/xqjgp9fhylig1.png?width=638&format=png&auto=webp&s=b5802063729328719785c7ad7e7f75e1bfff2d34\n\n",
                  "score": 1,
                  "created_utc": "2026-02-10 06:04:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4cjg25",
                  "author": "Western_Objective209",
                  "text": "codex is significantly slower than CC, like 10x slower easily. You can run it all day, but ends up not getting as much done. I used codex for personal use and CC for work for a while, and they both have their strengths. You'll find things you don't like about codex soon enough",
                  "score": 0,
                  "created_utc": "2026-02-09 00:33:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o47yl6y",
              "author": "Fonduemeup",
              "text": "Claude spent almost 3 minutes thinking about this prompt today:\n\n    Add to Makefile a command 'pipeline-train' which activates venv and runs \n    pipeline.py --stage train\n\nAnd then another minute thinking - about god knows what - after it finished",
              "score": 17,
              "created_utc": "2026-02-08 08:11:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o480onl",
                  "author": "voLsznRqrlImvXiERP",
                  "text": "What a waste, your prompt is longer than the command added to the makefile",
                  "score": 26,
                  "created_utc": "2026-02-08 08:31:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4948ox",
                  "author": "_number",
                  "text": "Should have just done it yourself because it seems you know exactly how to do it",
                  "score": 3,
                  "created_utc": "2026-02-08 14:01:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4gx38i",
                  "author": "NESDUB",
                  "text": "I noticed that it gets stuck randomly. No matter what the task is. Then when I cancel the task and then rerun the same prompt, it works normally again.",
                  "score": 1,
                  "created_utc": "2026-02-09 17:53:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4863yg",
              "author": "AppealSame4367",
              "text": "My approach: some opus 4.6 (Edit: Through Windsurf) which has a reduced credit pricing until 14th feb, codex with 5.3 for 20$ per month. Lots of good free models via kilocode and openrouter at the moment.\n\nCrazy times. I have more power than early 2025 at my hands for 10% of the price. Chinese models are all catching up to around Claude 4 level, which would be absolutely sufficient if it's available in a reliable manner.\n\nFree models: If you can afford to not give a damn where your code lands, of course. I don't handle any customer data in my dev systems and the code is negligible, just the usual web apps for SMB.",
              "score": 8,
              "created_utc": "2026-02-08 09:22:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48dj3h",
                  "author": "MakanLagiDud3",
                  "text": "Hopefully healthy competition will force Claude to make their models more accessible with reasonable limits.",
                  "score": 1,
                  "created_utc": "2026-02-08 10:33:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o48qslf",
              "author": "yamibae",
              "text": "I am in the exact same dillemma, 5 $20 plans would basically cover the usage I need and it actually works with Opencode, my prefer tui as well - that said I have yet to hit the $20 plan limit which I'm amazed by, I think we've all gotten too used to how bad the $20 claude plan is ...",
              "score": 2,
              "created_utc": "2026-02-08 12:30:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o49bryn",
              "author": "jasutherland",
              "text": "I wonder if they've been doing some AB testing? For me, quality turned to crap a week ago, but even with a fairly heavy workload, mostly Opus, I only hit the 5 hour limit once (on 20x), and didn't quit hit the week. Opus 4.6 seems to have restored the quality, and fixed most of the mess 4.5 made a few days ago.",
              "score": 1,
              "created_utc": "2026-02-08 14:45:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o49j287",
              "author": "futant462",
              "text": "What's involved in migrating to codex though. My CC setup is pretty elaborate.¬†",
              "score": 1,
              "created_utc": "2026-02-08 15:24:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55hqtk",
                  "author": "Global-Molasses2695",
                  "text": "Tell codex to do the migration for you and get ready to be amazed where GPT 5.3 is",
                  "score": 1,
                  "created_utc": "2026-02-13 12:21:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4bhf13",
              "author": "SignificanceMurky927",
              "text": "Same boat as you, decided to take the plunge. Can‚Äôt say i miss Opus at all. Also the price/token ratio is amazing with 5.3 compared to Anthropic‚Äôs ridiculous price.",
              "score": 1,
              "created_utc": "2026-02-08 21:06:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4h7e5l",
              "author": "Exciting-Ear-4809",
              "text": "how much use do you get from the codex plan",
              "score": 1,
              "created_utc": "2026-02-09 18:41:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47vy4c",
          "author": "Last-Assistance-1687",
          "text": "Opus 4.6 burns tokens like crazy. \n- I give claude code very detailed tasks\n- my prompts are very precise \n- I clear context after every User Story\n\nI feel like a micro manager, tbh. Only that helped me so far to be more efficient with my token usage since the update.",
          "score": 36,
          "created_utc": "2026-02-08 07:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47x7wr",
              "author": "workphone6969",
              "text": "Don‚Äôt forget to review your plans 7 times and then review what was built 7 times- i somehow still catch edge cases after 4 reviews which is insane for basic python programs",
              "score": 13,
              "created_utc": "2026-02-08 07:58:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47x2a9",
              "author": "DiamondGeeezer",
              "text": "quality takes a nose dive if you go beyond that anyway, and the agent will forget your rules and do bad things so its a chess game of getting it to a milestone and document where it left off before it degrades or compacts",
              "score": 3,
              "created_utc": "2026-02-08 07:57:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o48dvbw",
              "author": "MakanLagiDud3",
              "text": "My advice use a base md file. Like write once, then ask Claude code to refer to this first then go write your code.",
              "score": 3,
              "created_utc": "2026-02-08 10:36:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o49w1le",
                  "author": "Ok_Employee9638",
                  "text": "yeah, Backlog CLI has helped with this for me personally. I usually do plan -> backlog epic -> tickets. Then run parallel agents across tickets with fresh context. ",
                  "score": 2,
                  "created_utc": "2026-02-08 16:29:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o48d7b6",
              "author": "alexwwang",
              "text": "What if you get an opus api with about 30% of original token price? How will you feel in this situation?üòú",
              "score": 1,
              "created_utc": "2026-02-08 10:29:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47xng4",
          "author": "elitegenes",
          "text": "Yes, I've been coding all day and all night on a business subscription. Spent only like 25% of the weekly limit. Business subscription is very much like Plus subscription that costs... $20 only, as far as I understand. Anthropic is swimming in money though and they keep raising the bar higher and higher with their pricing.",
          "score": 23,
          "created_utc": "2026-02-08 08:02:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o481ixb",
              "author": "d3ming",
              "text": "Wait are you saying the business plan has more limit for the same price as the $20 plan?",
              "score": 5,
              "created_utc": "2026-02-08 08:39:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o483lws",
                  "author": "elitegenes",
                  "text": "My impression is they're essentially the same. The only difference is on the business plan there's a small quota available for using the Pro model via chat interface and ability to ask the admin to top up the usage if you run out. I won't state that these plans are 100% equal though limit-wise, but that's my impression.\n\nEDIT: This confirms what I was thinking: https://www.reddit.com/r/ChatGPTCoding/comments/1n8ygln/codex_usage_limits_in_practice_how_far_plus_vs/",
                  "score": 5,
                  "created_utc": "2026-02-08 08:59:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o48drz3",
              "author": "MakanLagiDud3",
              "text": ">Anthropic is swimming in money though and they keep raising the bar higher and higher with their pricing.\n\nI know business is still business but I hope they are more than content instead of being greedy in the future.\n\nUnfortunately, a lot of companies are paying top dollar for Claude usage that I think there's a high chance normal consumers are screwed.",
              "score": 2,
              "created_utc": "2026-02-08 10:35:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o48ca9z",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-08 10:21:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48dx85",
                  "author": "drinksbeerdaily",
                  "text": "No, minimum is 2",
                  "score": 1,
                  "created_utc": "2026-02-08 10:36:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4as0x4",
              "author": "Momba_M",
              "text": "Feels like they‚Äôre trying to get less customers and retain similar revenue",
              "score": 1,
              "created_utc": "2026-02-08 19:00:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47xnzd",
          "author": "Poisonedhero",
          "text": "You can check my history, I‚Äôve been praising Claude code for almost a year. Never even mentioned codex despite using it a few times here and there and had bad experiences with it before 5.1. \n\nI decided to try 5.3 for a big task and it‚Äôs insanely good. One thing is absolutely certain, I‚Äôm going to downgrade from 20x to 5x after this.\n\nThe claude code experience is still better in my opinion, but it‚Äôs closer than ever.",
          "score": 19,
          "created_utc": "2026-02-08 08:02:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47unvj",
          "author": "Sea-Sir-2985",
          "text": "the rate limits have definitely gotten worse lately, i went through the same frustration... two complex prompts and you're basically done for the window. that said i keep coming back to claude code because the interactive loop is still unmatched for iterative work. with codex you dispatch a task and wait, but half the time i need to course correct mid-implementation which is where claude code's back and forth is way better\n\nwhat i've started doing is being more strategic about it... break big tasks into smaller prompts, use plan mode to get alignment before burning tokens on implementation, and keep your CLAUDE.md tight so it doesn't waste context re-learning your project structure every time. the /compact command helps a lot when context gets bloated too\n\ncodex is solid for well-defined batch tasks though so using both makes sense. i just wouldn't fully switch yet",
          "score": 14,
          "created_utc": "2026-02-08 07:35:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47v1zr",
              "author": "LaCaipirinha",
              "text": "I would prefer a workflow where CC is the orchestrator and Codex does the grunt work but when simply preparing a plan for a moderately complex prompt is more than half of your 5 hour allotment, I end up just using ChatGPT 5.3 Thinking to keep track of context and do the planning, and Codex to do the coding, with Claude just in the background doing extra jobs that I wouldn't mind being done in the background - quite a sad state of affairs and a complete reversal of how I was coding just 2 weeks ago.\n\nIt really does make me worry for the future of Anthropic if they don't have the funds to actually deliver their product in a useful way.",
              "score": 7,
              "created_utc": "2026-02-08 07:38:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o482r5a",
                  "author": "Relative_Mouse7680",
                  "text": "Do you use 5.3 high?",
                  "score": 1,
                  "created_utc": "2026-02-08 08:50:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4e7414",
                  "author": "jjjjbaggg",
                  "text": "OpenAI is selling their subscription at a loss right now. The free lunch won't last forever.",
                  "score": 1,
                  "created_utc": "2026-02-09 06:48:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o48b1xr",
              "author": "debian3",
              "text": "That‚Äôs the thing that I like about 5.3 codex. It finally gives you feedback on what it‚Äôs doing, you can steer it like opus and it‚Äôs now really fast. \n\nIf you haven‚Äôt tried 5.3, give it a try, it‚Äôs night and day with 5.2",
              "score": 3,
              "created_utc": "2026-02-08 10:09:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48iarq",
                  "author": "HostNo8115",
                  "text": "Still waiting for it in GitHub copilot pro ;/",
                  "score": 2,
                  "created_utc": "2026-02-08 11:17:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o47wm8b",
          "author": "Night_0dot0_Owl",
          "text": "Yeah as a max x5 user, Im disappointed by how much of the 5hr limit Opus 4.6 burns through. Its not worth it given the output quality. Fuck it. I'm switching back to Codex later this week once my subscription expires.",
          "score": 14,
          "created_utc": "2026-02-08 07:53:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47xf39",
          "author": "Maas_b",
          "text": "I am in the same boat as you. Claude code just feels more polished overall, although i must say codex in the new app feels pretty slick. Codex seems to have the edge in coding execution though currently. \n\nI‚Äôm experimenting with creating one plan that has consensus among codex and claude, then set up two worktrees, one for claude and one for codex where i let them implement the same plan. I let claude and codex review each other afterwards. Maybe a bit wasteful, but i see it as an experiment. After a handful of these runs, codex has won everytime. Both claude and codex reflect on codex as the better implementation, more complete, better plan adherence and less bugs. \n\nSo based on this it seem a no brainer to leave claude behind for now, but somehow it feels like a big leap. 5x plan has been so good for me",
          "score": 9,
          "created_utc": "2026-02-08 08:00:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o480o0d",
          "author": "dxm06",
          "text": "This is 100% accurate. As a long-time user, annual Pro subscriber, and then Max 5x to Max 20, I sincerely hope they can finally get their act together, come to their senses, and restore the original level of usage, stopping the unnecessary bullshit caps so we can actually get some work done.",
          "score": 8,
          "created_utc": "2026-02-08 08:31:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47w245",
          "author": "Middle-Nerve1732",
          "text": "Amen to this. I noticed I was hitting limits a lot faster recently. Today I did a test. Starting with 0 usage, I gave it a simple find and replace renaming task. That one task used 6%! It‚Äôs either the model is very inefficient or they have really dropped the quota. I am also planning to switch to Codex.¬†",
          "score": 7,
          "created_utc": "2026-02-08 07:47:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4807if",
          "author": "Affectionate-Aide422",
          "text": "The opposite for me. I‚Äôm on the $100 Max plan, and I haven‚Äôt run out of tokens in either my 5hr window or weekly window. I was before with 4.5, but 4.6 seems slightly faster and use up slightly fewer tokens.",
          "score": 19,
          "created_utc": "2026-02-08 08:26:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o493eiu",
              "author": "mrw1986",
              "text": "Same here and I have a TON of usage",
              "score": 6,
              "created_utc": "2026-02-08 13:56:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4b1ofu",
              "author": "kpgalligan",
              "text": "I'm on the $200 Max plan and may eventually go down to $100. My usage last week was a bit over 30%, which I think would top out the $100 plan, but I've been doing a lot of stuff with the Claude Agent SDK.\n\nNot sure what all of the negative posts are about. \"Opus is nerfed\", \"Opus uses  way more tokens\", etc. In my experience, Opus 4.6 landed with little trouble, and has been working great.",
              "score": 2,
              "created_utc": "2026-02-08 19:47:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o497059",
              "author": "deepdivin247",
              "text": "Have you tried Superpowers plugin for Claude Code‚Ä¶.epic with Opus 4.6 üôå",
              "score": 0,
              "created_utc": "2026-02-08 14:18:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o482tci",
          "author": "larsssddd",
          "text": "Anthropic is losing 5 billion dollars yearly, so only thing we can be sure is increasing price and decreasing model quality. \nDon‚Äôt get used to it too much, I except that vibe coding with popular models like codex or Claude will get really expensive soon",
          "score": 4,
          "created_utc": "2026-02-08 08:51:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48vqng",
              "author": "UMANTHEGOD",
              "text": "I'm 100% convinced that Google will be the top dog in the AI space eventually. They have superior data, they have been collecting data for 20 years+. They are taking it slow because they can. It's a strategic choice. The naive take is that they are falling behind because they are clueless, but I think this is intentional. They are not in the race because they don't need to.\n\nHare vs turtle type thing.",
              "score": 3,
              "created_utc": "2026-02-08 13:07:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o494qq0",
              "author": "_number",
              "text": "They even added a fast mode to penny pinch even more. Anthropic more desparate than ever.",
              "score": 2,
              "created_utc": "2026-02-08 14:04:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o485xdf",
              "author": "LaCaipirinha",
              "text": "I'd pay an extra $10 no questions if I could have reasonable usage caps, the cost gap between entry level and max tiers are insane for both Claude and ChatGPT\n\nBut yes I have the same fear, unless it's true that model compaction and new data centres/GPUs will bring costs down as many commentators do say.",
              "score": 1,
              "created_utc": "2026-02-08 09:20:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o48g3hx",
                  "author": "alexwwang",
                  "text": "I have different opinions. Ala they have money to burn, they will struggle to cut down their cost on training, interpreting and operating while keeping developing more efficient models to gain advantages and shares. So I don‚Äôt worry about the quality declines but I think they will promote products that burn more tokens but are able to get more complicated task down with less human intervene and tries. \n\nSo as a llm user and software developer, all you need to do is sourcing the service with lower price than the list ones.",
                  "score": 1,
                  "created_utc": "2026-02-08 10:57:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4cxvpl",
              "author": "Odd-Librarian4630",
              "text": "Yea I agree - codex is only cheap because they a subsidising it massively at a massive loss to the company, and also have way more access to compute than Anthropic (they have a 400 million usersmost of which are free users but still ) - but once that money pot runs out its gg for Codex - say goodbye to $200 a month subscriptions and lenient limits. Anthropic are also losing cash but are on a much more sustainable trajectory to making a profit.",
              "score": 1,
              "created_utc": "2026-02-09 01:54:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o48mz0x",
              "author": "GlassAd7618",
              "text": "I agree. It seems that ‚Äî and this is true not just for Anthropic, but also other companies such as OpenAI or xAI ‚Äî  the cost of training frontier language models and running inference on the order of magnitude needed for software development is higher than the cost of a typical subscription (around $20 these days). We will likely see the prices go up to something like $200 for Pro-like subscriptions and 2x-3x of that for Max-like subscriptions.",
              "score": 0,
              "created_utc": "2026-02-08 11:59:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48p39v",
                  "author": "larsssddd",
                  "text": "They probably will issue stock shares soon, that‚Äôs why they are making so much useless hype articles and prognosis",
                  "score": 3,
                  "created_utc": "2026-02-08 12:17:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48oa2o",
          "author": "AutomaticCourse8447",
          "text": "after using codex i realized Claude was lying too much",
          "score": 5,
          "created_utc": "2026-02-08 12:10:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49myon",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-08 15:44:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o49r0u7",
                  "author": "AutomaticCourse8447",
                  "text": "yeah i know ",
                  "score": 1,
                  "created_utc": "2026-02-08 16:04:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4818za",
          "author": "vonirox566",
          "text": "Not to mention GPT 5.3 is much better long-term. I'd compare Sonnet 4.5/Opus 4.6 to an eager yolo developer who doesn't plan much and just does what it's asked to do.",
          "score": 4,
          "created_utc": "2026-02-08 08:36:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48m27n",
              "author": "LuckyPrior4374",
              "text": "Yeh Claude is like a contractor who doesn‚Äôt give a fuck about anything but picking up their next paycheck.\n\nI‚Äôve been shocked at how bad Claude actually is at programming. It can‚Äôt do ANYTHING without resorting to throwing a bunch of hacks and bloated shit along with the actual ‚Äúsolution‚Äù.\n\nE.g. ask it to use proper typing in its code and it will give you something that ‚Äúworks‚Äù but has 50 useless, incorrect type assertions + ts ignore comments everywhere.",
              "score": 2,
              "created_utc": "2026-02-08 11:51:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48450q",
          "author": "sael-you",
          "text": "‚Äôve been feeling the same way lately. I had a bug on an Android widget that I spent an entire day trying to fix with Claude Code, gave it to Codex and it solved it in the first two prompts.\nSo I decided to set up Gemini MCP and Codex MCP inside Claude Code, using each model for what it does best: Gemini handles codebase analysis and web searches, Claude Code does the planning and implementation, and Codex reviews and challenges Claude Code‚Äôs approach.",
          "score": 3,
          "created_utc": "2026-02-08 09:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o488sgt",
          "author": "Kindly-Abroad8917",
          "text": "I‚Äôm glad I‚Äôm not the only one, it‚Äôs been brutal. I‚Äôm about to switch over after I‚Äôm finished with some tasks. I don‚Äôt even want to upgrade to the larger plan because there are STILL some brutal limits in practice. Claude‚Äôs commercial strategy has wreaked of lack of scale planning (assuming costs are sky rocketing) and just plain arrogance greed.",
          "score": 3,
          "created_utc": "2026-02-08 09:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48efyb",
          "author": "InsideElk6329",
          "text": "Claude doesn't have that much hardware OPENAI has. Openai can spare the computing power to codex from a large amount of free users by making them watch a small ad (15s) like youtube does and keep codex at a low price then take Opus' share. I don't know why Claude is mocking openai on the ads, that can be a serious problem.",
          "score": 3,
          "created_utc": "2026-02-08 10:41:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48jc8p",
              "author": "HostNo8115",
              "text": "The whole thing reminds me of Slack taking full page ads ‚Äúwelcoming‚Äù Teams only to be absolutely clobbered by them in a couple of years, they had to eat their words. I worry Claude will go that way too.",
              "score": 2,
              "created_utc": "2026-02-08 11:27:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48vpy3",
                  "author": "Zealousideal_Tea362",
                  "text": "The only reason people started using teams is because it was free inside of a license package a majority were already paying for and it killed two birds with one stone ( zoom and slack) \n\nNot a good comparison.",
                  "score": 3,
                  "created_utc": "2026-02-08 13:07:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o493msw",
          "author": "Careless_Bat_9226",
          "text": "I wish we could tag these posts as ‚Äúnon-developer‚Äù or something like that.\n\nI was thinking it was going to be something about codex actually being better but it‚Äôs really just you trying to skimp out and now pay the $100 - which is fine is you‚Äôre a non-professional doing vibe coding. Codex is currently cheaper because they're subsidizing it heavily but that will change. I‚Äôm on the $100 plan and never hit the 5h limit.¬†",
          "score": 3,
          "created_utc": "2026-02-08 13:57:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fczsr",
          "author": "Global-Molasses2695",
          "text": "Can‚Äôt say. I cancelled all Anthropic stuff few months back and moved my workflow over to GPT 5.1 Codex back then. Final straw was, apparently I burned my weekly quota in 2 days, without ever hitting the two hr limit. That was in max plan. Was on Anthropic since 3.0 days 100%, supported them when their availability sucked, they turned back to show customer loyalty means nothing - sent few mails to them and got an auto response back gaslighting me. Switching was the best decision I ever made - made me realize how good GPT actually was on model-vs-model basis ignoring the hype. As it turns out GPT 5.3 has now made it apparent for everyone.",
          "score": 3,
          "created_utc": "2026-02-09 13:03:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o482hog",
          "author": "Relative_Mouse7680",
          "text": "Which gpt plan are you on? Also, have you had any issues with file edits using codex?",
          "score": 2,
          "created_utc": "2026-02-08 08:48:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o485u2l",
              "author": "LaCaipirinha",
              "text": "$20 and no file edit issues as yet but I haven't used it for that function much",
              "score": 2,
              "created_utc": "2026-02-08 09:20:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o488e7x",
                  "author": "Relative_Mouse7680",
                  "text": "So you mean that you can use 5.3 high without hitting usage limits?",
                  "score": 1,
                  "created_utc": "2026-02-08 09:44:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4878n4",
          "author": "hey_i_have_questions",
          "text": "Anthropic is swinging for Enterprise business. They‚Äôre probably not caring about individual users much anymore.",
          "score": 2,
          "created_utc": "2026-02-08 09:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4cpx8t",
              "author": "consumedsoul",
              "text": "Kinda true... I'm unlimited in my Claude Opus usage at work and they barely bat an eye about the total budget (still cheaper than having more engineering assets).",
              "score": 2,
              "created_utc": "2026-02-09 01:09:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o487c7t",
          "author": "RemarkableGuidance44",
          "text": "First time this has happened with me, started a new chat asked it to do some research and it went out and repetitively kept scraping 6 pages for about 10 mins..., I told it to cancel and just get back to the plan, it ignores it and goes ahead and started scraping the same 6 pages... lol \n\nWe spend millions on AI and on Claude but my team and I are liking Codex more and more. I have no idea wtf they have done but they have F315$ed it.... ",
          "score": 2,
          "created_utc": "2026-02-08 09:34:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48bsss",
          "author": "Stunning_Owl672",
          "text": "Quality for me this week has been awful compared to before. It‚Äôs suddenly only good within one context and then everything breaks down.",
          "score": 2,
          "created_utc": "2026-02-08 10:16:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o490nus",
          "author": "ugrenica",
          "text": "Codex is absolutely bodying Claude Code with these latest versions. I‚Äôve previously been implementing with Claude and code reviewing with codex but have given up and just switched fully to codex.",
          "score": 2,
          "created_utc": "2026-02-08 13:39:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o498xlm",
          "author": "IlliterateJedi",
          "text": "Whenever I've used codex, I end up having to manually approve doing anything to basically every file.  I don't want Codex to have free reign for obvious reasons, but it seems less flexible than Claude Code.  Is there a trick to making it less frustrating to work with?",
          "score": 2,
          "created_utc": "2026-02-08 14:29:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59uwss",
              "author": "akuma0",
              "text": "honestly, when I look at these discussions I assume the OP is talking \"right now\" and many of the commenters are talking about \"one month ago\". The tools sometimes are having multiple updates a day, so it is hard to make those sorts of comparisons.\n\nHaving started using both CC and Codex this week, CC (piloting on Pro) was hitting its 5h cap with between 1.5 and 4.5 queries, even when doing smaller tasks as part of a phased plan. I tried to get it to optimize behavior because it would repeatedly fetch the same file off the web as part of its query, and then sometimes fetch older obsolete versions of the file despite the instructions in [CLAUDE.md](http://CLAUDE.md) \\- it just wouldn't have it. I also didn't even consider moving from Sonnet to Opus - I'm not sure if you can on Pro, but it sounds like the higher computation cost would mean I might not even finish one command before it times out for 5h. It will would say it hit its quota while the website still reported I was at 70% usage - which made it way harder to estimate if I had enough fuel left to finish another instruction.\n\nIt isn't a fair comparison against codex for others, as I have a more expensive plan already on the openai side and codex currently running discounted in a promotional mode. That said, I started using that after I hit the weekly quota on the anthropic side (at just over two days of banging against quotas every few hours).\n\nCodex seemed to do a great job of coming up with a strategy to run more efficiently at my request - it pulled in external files that specify behavior of some components and do text cleanup (html to markdown I imagine) and extract examples from the text into JSON files right away, and start building a cross-reference index of where it found the answers to questions.  Once it started working, it found a bunch of big gaps that CC left, possibly because that tool kept timing out in the middle of tasks, then didn't realize that there was incomplete work when I restarted that task during the next quota cycle - or possibly because it didn't see the need to preprocess the files, and missed important information while running grep and sed to extract html snippets. I have also yet to hit any quota limits on codex - and as a result have worked with it way too late a few nights because we were still being productive.\n\nThose are both data points which are caveated by being \"right now\", because of the state of evolution and resulting flux here. For instance, I noticed on my last day with CC, the infrastructure started going back and forth reporting usage, as if they were rolling out a fix for usage reporting, and when I hit my weekly quota it said it was at 100%. So one of the problems I was having (quota not being reported correctly) seems like it was fixed within the short window of time I had to work already.\n\nThe problem is that the $20 in CC isn't what I would consider minimally useful in this first evaluation. If going to the $100 or even $200 plan would eliminate the quota issues and other issues I ran into and let me run with the higher quality model, it seems like it would be worth it - but that is a lot of money to spend when $20 tier was actually an equal mix of productivity and pain, even taking every strategy I could find to try to increase my utility within the quota system. Based on my sampling of the Big Mac, I'm not going to trust McDonalds with a $60 steak dinner. If CC cannot be more usable at $20 per month, my opinion is that Anthropic needs to kill the tier quickly.\n\nMy hope is that in the remaining weeks of the $20 evaluation, some of the pain will turn out to be transitory and I'll see the value in a larger and long term investment in CC. In the meantime, I'm glad I started using Codex as part of my existing OpenAI sub.",
              "score": 1,
              "created_utc": "2026-02-14 02:12:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4argwb",
          "author": "Momba_M",
          "text": "I used Claude code one time and couldn‚Äôt help but notice how many tokens it wastes- I asked it to fix one part of my script and it decided to completely deconstruct and reconstruct my entire program",
          "score": 2,
          "created_utc": "2026-02-08 18:57:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b22ad",
          "author": "moimitou",
          "text": "I came to r/ClaudeCode to say how amazing it is, found this post, downloaded codex (which is free for a month...), and am even more amazed... I think I'm having my 'oh shit' moment...",
          "score": 2,
          "created_utc": "2026-02-08 19:49:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d4dra",
          "author": "nyldn",
          "text": "you can use [https://github.com/nyldn/claude-octopus](https://github.com/nyldn/claude-octopus) to get the best of both worlds ",
          "score": 2,
          "created_utc": "2026-02-09 02:28:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dx4dm",
              "author": "dragon1620",
              "text": "I asked the Gemini extension for a TLDR of this thread and it mentioned this. \n\n>5. **Explore Community Tools:** Some users are using *Claude Octopus* to bridge the two ecosystems or utilizing the *Superpowers plugin* to optimize Claude Code's performance.\n\nI was creating Codex/Gemini CLI commands for Claude Code as well. But this goes way beyond what I was building. This looks really good man! I'm going to try it out right now.",
              "score": 2,
              "created_utc": "2026-02-09 05:25:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4dez0b",
          "author": "Lordrew",
          "text": "Dude really also have this, was like the holy grail I could create so much. But now it was breaking working code, and hitting the limit halfway (imo faster)",
          "score": 2,
          "created_utc": "2026-02-09 03:24:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4em28w",
          "author": "Ok-Peace-1186",
          "text": "Currently im using opencode with the latest codex. Working shockingly well for me.",
          "score": 2,
          "created_utc": "2026-02-09 09:11:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fgboc",
          "author": "yycTechGuy",
          "text": "Me too.  I was frustrated using Opus 4.6 yesterday on my $20 plan.  I burned through one session in 18 minutes and another in 40.  And didn't get the bug fixed.\n\nI bought a $20 plan from OpenAI this morning and installed Codex-CLI and started running Codex 5.3.  I worked all day without hitting any limits, without a bunch of churn and without compacting !  Incredible. \n\nIt was incredibly productive and yet I was relaxed and not frustrated with hitting limits. ",
          "score": 2,
          "created_utc": "2026-02-09 13:24:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47x1o1",
          "author": "Ok_Mechanic806",
          "text": "It‚Äôs interesting- maybe I do t know enough about what I‚Äôm doing but it‚Äôs only been getting better for me. As I learn to use it better.\n\nAre people suffering from context bloat not using beads and other systems for improving the quality or rather maintaining it for projects over time?",
          "score": 2,
          "created_utc": "2026-02-08 07:57:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47z6vr",
              "author": "crazywizdom",
              "text": "I don't understand this either. I'm on the 5x plan and I've not actually hit a limit yet, 5h or weekly.\n\nI feel like I'm getting lots of work done and making good progress on my projects (and it's for sure me that's the limiting factor, not lack of tokens).",
              "score": 3,
              "created_utc": "2026-02-08 08:17:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o481dbp",
                  "author": "Ok_Mechanic806",
                  "text": "Would be nice to know who has CI, RPI, BEADS, etc setup, to avoid context bloat and who doesn‚Äôt with these complaints.. cause it creates concern that there‚Äôs issues down the road for me",
                  "score": 2,
                  "created_utc": "2026-02-08 08:37:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o47upnp",
          "author": "Sea-Sir-2985",
          "text": "the rate limits have definitely gotten worse lately, i went through the same frustration... two complex prompts and you're basically done for the window. that said i keep coming back to claude code because the interactive loop is still unmatched for iterative work. with codex you dispatch a task and wait, but half the time i need to course correct mid-implementation which is where claude code's back and forth is way better\n\nwhat i've started doing is being more strategic about it... break big tasks into smaller prompts, use plan mode to get alignment before burning tokens on implementation, and keep your CLAUDE.md tight so it doesn't waste context re-learning your project structure every time. the /compact command helps a lot when context gets bloated too\n\ncodex is solid for well-defined batch tasks though so using both makes sense. i just wouldn't fully switch yet",
          "score": 2,
          "created_utc": "2026-02-08 07:35:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47vp1k",
          "author": "1337boi1101",
          "text": "What's the price for the ChatGPT soul document?",
          "score": 1,
          "created_utc": "2026-02-08 07:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47wtwd",
          "author": "Bellman_",
          "text": "Pro tip: use proxy to route your CC to codex",
          "score": 1,
          "created_utc": "2026-02-08 07:55:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47y0dg",
              "author": "LaCaipirinha",
              "text": "Actually can you point me towards some guidance on how to do this? It might be the way",
              "score": 2,
              "created_utc": "2026-02-08 08:06:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o47ycts",
                  "author": "Bellman_",
                  "text": "Use things like Cliproxyapi; since it accepts all types of requests and OAuths",
                  "score": 1,
                  "created_utc": "2026-02-08 08:09:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4825u4",
          "author": "InsideElk6329",
          "text": "You didn't have a choice before, now you have",
          "score": 1,
          "created_utc": "2026-02-08 08:45:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o485bzf",
          "author": "brek001",
          "text": "genuine curious. has anyone of you used /insights in Claude Code? Might be revealing what it expects and what you do and how they (mis-)align.",
          "score": 1,
          "created_utc": "2026-02-08 09:15:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48en6f",
          "author": "Whole_Ad206",
          "text": "Despues de usar un a√±o una suscripcion max de anthropic, solo me queda la duda si podra seguir a este ritmo y con gpt soplandole la nuca con tanta bestialidad...",
          "score": 1,
          "created_utc": "2026-02-08 10:43:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48iazv",
          "author": "nikolateslaninbiyigi",
          "text": "Is GPT 5.3 Extra High on windsurf right now?",
          "score": 1,
          "created_utc": "2026-02-08 11:17:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48inv9",
          "author": "nekronics",
          "text": ">Am I the only one that has noticed an absolutely huge difference in what you can get done within your subscription tier lately?\n\nWhat is \"lately\"? Codex literally doubled usage for a limited time with codex app release.",
          "score": 1,
          "created_utc": "2026-02-08 11:21:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48jmo4",
          "author": "401klaser",
          "text": "Use plan mode / spec everything. Clear context after completing tasks. Don't rely on a single CLAUDE.md in the root of your project.\n\nI know this is all new so people are still in the experimenting phase, but 5 minutes of reading will save you a lot of time and tokens.\n\nIt is puzzling to me how people are hitting limits quickly - especially on max plans.",
          "score": 1,
          "created_utc": "2026-02-08 11:29:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48xvn6",
              "author": "Same-Transition-1532",
              "text": "How do you setup more than one Claude.md? I do a wide range of work: marketing, coding, etc.",
              "score": 1,
              "created_utc": "2026-02-08 13:21:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o49cpx7",
                  "author": "401klaser",
                  "text": "put them in the subfolders of your project. you can run claude in those directory and do a /init to generate them or instruct claude to generate them in each subdirectory as needed. add instructions to update claude.md after each task when necessary.\n\nhttps://code.claude.com/docs/en/memory",
                  "score": 1,
                  "created_utc": "2026-02-08 14:50:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48k4n9",
          "author": "thoowz",
          "text": "Is ist possiible to switch a project from Claude Code over to Codex? Not just the code, but also the concepts and memory? How is your experience? I am also annoyed by the limits...",
          "score": 1,
          "created_utc": "2026-02-08 11:34:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48rb4f",
              "author": "LaCaipirinha",
              "text": "I use both all the time, having both write context updates to various .md files within the repo, and when starting a new instance I'll have one write a handover for the other. They are pretty good at digging around to understand the architecture and picking up from the other pretty easily.",
              "score": 1,
              "created_utc": "2026-02-08 12:34:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48mrb3",
          "author": "ThomasToIndia",
          "text": "Do not let it over explore, add to your claude.md to not and ask for permission or files to look at.",
          "score": 1,
          "created_utc": "2026-02-08 11:57:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ozis",
          "author": "pakalumachito",
          "text": "if you post these on /r/claudeai they would bashing you and assuming you are vibe coder and a skill issue to reach the limit usage.",
          "score": 1,
          "created_utc": "2026-02-08 12:16:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48vypi",
          "author": "spinozasrobot",
          "text": "Same with me, I'm a big CC fan, but I'm having trouble getting my work done with the limits.",
          "score": 1,
          "created_utc": "2026-02-08 13:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48wzmu",
          "author": "ErikThiart",
          "text": "anthropic is useless due to their rate limits",
          "score": 1,
          "created_utc": "2026-02-08 13:15:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o499ts4",
          "author": "verkavo",
          "text": "First days/weeks after model release is the sweetest deal. With any provider.\n\nThat being said, I'm in the same boat - new codex seems so be better than Claude.",
          "score": 1,
          "created_utc": "2026-02-08 14:34:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49diwc",
          "author": "champagne-communist",
          "text": "Btw how do you do when u want to switch agents on your project?",
          "score": 1,
          "created_utc": "2026-02-08 14:55:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bosai",
              "author": "LaCaipirinha",
              "text": "Honestly easy, I have them all update some .mds with context and they pick up pretty fast reading those and doing a bit of reverse engineering.",
              "score": 2,
              "created_utc": "2026-02-08 21:42:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49dyko",
          "author": "1millionbucks",
          "text": "Ive literally never hit the limit with 5x max",
          "score": 1,
          "created_utc": "2026-02-08 14:57:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49ffxc",
          "author": "ragnhildensteiner",
          "text": "When writing posts like this, please consider writing what plan you're on, and what models you primarily use. \n\nFor me it sounds like you're on the cheapest plan trying to use the most expensive model, if 2 prompts make you hit limits. \n\nI'm on Max 200 plan and spam Opus 4.6 for 4-8 hours per day and get nowhere close to even hitting half of any usage limits.",
          "score": 1,
          "created_utc": "2026-02-08 15:05:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49fkim",
          "author": "lechuckswrinklybutt",
          "text": "This is why Anthropic‚Äôs blustering about remaining ad free is fucking stupid. These are world changing tools that are operated at a loss. Show me some ads and give me the good good.",
          "score": 1,
          "created_utc": "2026-02-08 15:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49k7oh",
          "author": "Mindspacing",
          "text": "Ive done the exact same thing. Currently doing all work with codex but rebuilding everything to be non LLM specific so I can interchange them when they switch positions in ‚Äúwho‚Äôs the best at this task right now‚Äù",
          "score": 1,
          "created_utc": "2026-02-08 15:30:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49vseq",
          "author": "Zissuo",
          "text": "Ive added Antigravity into the mix, it lets me call opus 4.5 currently",
          "score": 1,
          "created_utc": "2026-02-08 16:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49x0xr",
          "author": "Appropriate_Shock2",
          "text": "Yea it‚Äôs funny I used 5.3 codex non stop all day Friday at work, didn‚Äôt even think to check my usage like I usually do with Claude. I have no idea how close I got to the limit on the $20 plan but it obviously wasn‚Äôt close enough to become a problem.",
          "score": 1,
          "created_utc": "2026-02-08 16:34:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a07j5",
          "author": "jeremynsl",
          "text": "Opus 4.6 on high thinking is EXPENSIVE.  Low/med helps a lot if you use it for everyday tasks.  Otherwise it‚Äôs best for planning and difficult debugging, using Sonnet or Codex for implementation.",
          "score": 1,
          "created_utc": "2026-02-08 16:49:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a8ehg",
          "author": "pbalIII",
          "text": "Limits are frustrating, but I think they're revealing something more interesting about how we work. When you can code for hours without hitting a wall, you stop noticing how much of your workflow is just... delegating. Every small task goes to the agent because there's no cost signal telling you to pause and think about whether it's worth a round trip.\n\nI run both tools daily and noticed my Codex sessions produce more changes but my Claude sessions (when I actually get them) produce better-scoped changes. The friction forces you to front-load your thinking. You write a tighter prompt because you know you can't afford a sloppy one.\n\nNone of that excuses the pricing mismatch. But if you're switching wholesale, worth noticing which habits transfer and which ones were just artifacts of unlimited runway.",
          "score": 1,
          "created_utc": "2026-02-08 17:29:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4acyj5",
          "author": "wish_you_a_nice_day",
          "text": "Now I just need Gemini to get good. It is so much cheaper",
          "score": 1,
          "created_utc": "2026-02-08 17:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ai8it",
          "author": "AlphaLoris",
          "text": "This happens every time they release a new model increment and resolves quickly.",
          "score": 1,
          "created_utc": "2026-02-08 18:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4aiq5s",
          "author": "fleance",
          "text": "I just subscribed to claude $20/month personal plan to use at home because I use it for work and saves me hours every day.\n\nBut the first time trying my personal claude out I asked it to research something and it fetched 20 URLs, and then it hit my usage limit before it even got done processing them.   Is this a joke?  When I try to continue in \\*5 hours\\*, I wonder if it will even finish then, or will try to start over again, and hit the limit again.\n\nIt looks like folks on personal plans are being treated like peasants compared to people using enterprise claude.",
          "score": 1,
          "created_utc": "2026-02-08 18:18:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4avipv",
          "author": "senturion",
          "text": "Claude is still what I use to plan and build a project but Codex is what I use to fix bugs, add features and tweak small things because it never runs out of credits.\n\nClaude is better but it burns through time limits and credits way too fast.",
          "score": 1,
          "created_utc": "2026-02-08 19:17:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b84qv",
          "author": "FocusKontrol",
          "text": "I‚Äôve noticed the same that token run out so quickly (using pro). I used to let opus plan and sonnet implement, but now I‚Äôve been letting codex do the implementation. To me it seems it‚Äôs more reasonable to have a Claude Pro and GPT pro subscriptions, rather than just Claude Max.",
          "score": 1,
          "created_utc": "2026-02-08 20:19:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bqxmj",
          "author": "rjyo",
          "text": "Totally feel this. The limits got noticeably worse in the last few weeks, especially on Opus. I went through the same frustration.\n\n  \nOne thing that actually helped me was changing how I work with CC rather than switching away entirely. I break everything into very small, focused tasks with fresh context each time. No more \"hey Claude, refactor this whole module\" type prompts. Small atomic tasks burn way fewer tokens because the model doesn't go on extended thinking tangents.\n\n  \nThe other big shift for me was going async. I'll kick off a task, go do something else, come back when it's done. I actually built a mobile app (Moshi) partly because of this exact pain point. I wanted to check on my agents and approve stuff from my phone instead of sitting at my desk watching Claude think for 3 minutes. The mosh protocol keeps the connection alive even when you switch networks so you never come back to a dead session.\n\n  \nBetween smaller prompts and not babysitting every session, I went from burning through my weekly limit in 2 days to making it last most of the week. Still not ideal but way more manageable than before.",
          "score": 1,
          "created_utc": "2026-02-08 21:53:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4c0flc",
          "author": "Kodrackyas",
          "text": "December 2025 Opus 4.5 was the goat, tbh 4.6 was not needed, yeah its good but too many tokens used, i could do everything with 2025 opus just fine, my experience objectivelly degraded",
          "score": 1,
          "created_utc": "2026-02-08 22:43:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4c39qg",
          "author": "jmricker",
          "text": "See some comments of using Opus for planning and Sonnet for writing. How does that work, just use /plan, tell it what you need, the switch models and say go?",
          "score": 1,
          "created_utc": "2026-02-08 22:59:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4cb3xd",
          "author": "Numerous-Exercise788",
          "text": "Yeah, I thought it was just me. Thank you for confirming the sentiment I've been feeling.\n\n\n\nI've been using Claude Code as my dedicated agent for just under a year and have been on the Claude Mac subscription since day one. Lately I've been questioning myself and considering a ChatGPT Pro subscription. I've been cranking out a ton of usage on ChatGPT Pro without hitting limits.\n\n\n\nClaude Code, on the other hand, now consumes 20‚Äì30% usage on single tasks for me on the 20X max plan. Since 4.6 Opus came out, it seems they've reduced the five-hour limit quota. Token usage is only slightly higher - about 10-15%, but the usage from the five-hour quota has jumped by 60-70% or more.\n\n\n\nI was never hitting the five-hour limit before, and now I'm consistently hitting it on less than 30% of the work I was doing before. Claude is definitely one of the best models.",
          "score": 1,
          "created_utc": "2026-02-08 23:45:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ck9mb",
          "author": "Enea_11",
          "text": "How does Codex work? Like Claude Code? Is it the same principle?",
          "score": 1,
          "created_utc": "2026-02-09 00:37:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dxvu9",
              "author": "dragon1620",
              "text": "Yeah, they're both CLI-based AI agents. Codex is ChatGPT for code. üòâ",
              "score": 1,
              "created_utc": "2026-02-09 05:31:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4dn0ek",
          "author": "cuberhino",
          "text": "I‚Äôve been building a translation app with codex 5.3 and it took me quite a while(about 4 hours) of working between 5.2 ChatGPT and codex with no python coding knowledge. My first ‚Äúvibecoded‚Äù project, I have a background in web design using html css and JavaScript only. Now I actually have a pretty functional python app that works for basic conversation translation that I‚Äôm going to keep iterating on until it‚Äôs perfect.",
          "score": 1,
          "created_utc": "2026-02-09 04:13:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dpddi",
          "author": "s1mplyme",
          "text": "Opus 4.6 is \\_chewing\\_ through my max x20 plan.  It's insane. We need higher limits.",
          "score": 1,
          "created_utc": "2026-02-09 04:29:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4e3mlp",
          "author": "jordi-zaragoza",
          "text": "The usage limits are directly tied to how many tokens Claude burns per task. I've noticed that a huge chunk of token usage comes from Claude re-exploring the codebase every session - re-reading files it already read yesterday, grepping to rediscover which files import what.\n\nIf you can reduce that exploration overhead, the same 5h limit goes significantly further. I've been experimenting with injecting a persistent dependency map at session start so Claude already knows the project structure. Cuts down the \"wandering\" phase dramatically.\n\nDoesn't fix the limit itself, but makes each session way more efficient within it.",
          "score": 1,
          "created_utc": "2026-02-09 06:17:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fnpyv",
          "author": "geekflyer7",
          "text": "I'm currently using both, often on the same project.  \nClaude Code via the CLI and Codex through OpenCode.  \nI have to say the OpenCode UX is nothing short of impressive. Claude Code's UX feels like a buggy toy in comparison.  \nOpenCode also works much longer without asking me to confirm a bunch of stuff.  \nWhere Claude Code still takes the cake is overall speed and some integrations like Claude Code in Chrome.",
          "score": 1,
          "created_utc": "2026-02-09 14:08:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fq6dr",
          "author": "henry_1986",
          "text": "Has anyone tried using [https://z.ai/blog/glm-4.7](https://z.ai/blog/glm-4.7) ? Based on their blog posts, they are awesome. I also saw a few AI YouTube channels recommending it, but those are hard to believe since they could be paid shills. The pricing is decent.",
          "score": 1,
          "created_utc": "2026-02-09 14:22:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k6ejd",
          "author": "Driver_Octa",
          "text": "Claude still thinks better, but the limits make you *think about thinking*, which kills flow. I‚Äôve been offloading heavy planning/spec work to stuff like Traycer, then using Codex/Cursor for the grind  way less token burn, same results. Until quotas chill out, splitting ‚Äúthinking vs typing‚Äù feels like the only sane move.",
          "score": 1,
          "created_utc": "2026-02-10 04:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kbjxo",
          "author": "liquiduniverse2018",
          "text": "It feels like the 'best coding' model narrative shifts just about every month, which makes it very hard to switch cause you never know what's going to be better next month. I wish there is a definitive benchmark for coding models I can reference, or is there one?",
          "score": 1,
          "created_utc": "2026-02-10 04:59:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mjkn2",
          "author": "levysabo",
          "text": "Having the same experience. Opus is great, but my 20x plan got nerfed. Coding 60 hours a week, I was at 50%. Now, with 2 hours of simple few prompts got me to 10% what the actual fuck?",
          "score": 1,
          "created_utc": "2026-02-10 15:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nm8ay",
          "author": "RangeRoper",
          "text": "that is a feature",
          "score": 1,
          "created_utc": "2026-02-10 18:11:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52i1ov",
          "author": "One_Development8489",
          "text": "Yeah it destroyed my week... i needed to rewrite something not big but complex, opus was great but those limits... and now im with sonnet 4.5 who ignore everything, like writing useless MVP style... i dont even know what should i do...",
          "score": 1,
          "created_utc": "2026-02-12 23:09:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ofsf",
          "author": "AdCommon2138",
          "text": "You are absolutely right¬†",
          "score": 0,
          "created_utc": "2026-02-08 12:11:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48mjg7",
          "author": "xatey93152",
          "text": "Only low iq people uses claude",
          "score": -5,
          "created_utc": "2026-02-08 11:55:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2vakt",
      "title": "Dear senior software engineer, are you still writing code?",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1r2vakt/dear_senior_software_engineer_are_you_still/",
      "author": "zulutune",
      "created_utc": "2026-02-12 14:46:23",
      "score": 284,
      "num_comments": 330,
      "upvote_ratio": 0.93,
      "text": "I'm what you would call a traditional senior software engineer. Worked my way through a lot of languages, platforms, frameworks, libraries. This year marks my 20th year in the business.\n\nSome prominent people are already comparing writing code by hand with \"assembly line work\". I'm reading articles/tweets where Google, Microsoft, Anthropic and OpenAI engineers claim they don't write code anymore, that everything is written by AI. But of course because these are also the companies earning millions through these models, this could also be marketing fluff.\n\nThough, today I spoke someone working at some big corporate high tech company and he told me the same thing, they we even allowed to burn through as many tokens as they like, no limits. He told me his colleagues are now solely reviewing code created by agents, basically what those AI companies tell us.\n\nAs someone who's really good at his craft, I have a high standard for code quality. Sure, claude/gemini/openai can generate scripts doing stuff I couldn't image 5 minutes ago in 1 minute. Really impressive and unreal. But I also find myself discarding lots of code because it's not the best way to do it, or it's not what I asked for. Maybe I need to get better at prompting, anyway.\n\nWhat I wanted to learn is what your experience is as a senior software engineer working at a startup, scale-up or fortune 500 company. Is this really where we're heading at?\n\n",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r2vakt/dear_senior_software_engineer_are_you_still/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o4zobv9",
          "author": "lionmeetsviking",
          "text": "If you get shit code out, problem is not usually the LLM. Getting LLM write high quality code is a skill you need to learn like any other. Tooling, testing, guardrails, instructions, architecture ‚Ä¶\n\nI stopped writing code 9 months ago, after having done it for 30 years. Besides learning, it has been a mindset shift. I view my codebase as a much more organic entity these days, and I don‚Äôt mind throwing away bad code. Code is simply a super cheap commodity compared to everything else. \n\nI love the end result, not the code itself.",
          "score": 226,
          "created_utc": "2026-02-12 15:02:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o508o3u",
              "author": "zhambe",
              "text": "> view my codebase as a much more organic entity these days\n\nYes! The code is a bit more disposable now, given how it's got easier to come by.",
              "score": 22,
              "created_utc": "2026-02-12 16:38:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zwu4y",
              "author": "zulutune",
              "text": "Could you recommend/pinpoint some good resources which helped you learn these skills? Thanks!",
              "score": 9,
              "created_utc": "2026-02-12 15:43:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4zyj0p",
                  "author": "krullulon",
                  "text": "Practice is honestly the best way to learn how to prompt effectively.",
                  "score": 24,
                  "created_utc": "2026-02-12 15:51:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o500s0n",
                  "author": "Shep_Alderson",
                  "text": "There is an absolute deluge of information out there unfortunately. There‚Äôs not a whole lot that‚Äôs really clearly laid out and directed. It took me weeks of watching what other people do, and then trying to build my own version using different agents and subagents, to really get it.\n\nIf your daily driver is currently Claude Code, go dig into their docs, which are decent. See what it can do, and if you‚Äôre not sure, ask Claude or go look up how other people are doing it on YouTube. (Maybe you want to learn about agents or skills, for example.)\n\nI‚Äôd suggest starting off by building things up, one by one. Start with making some specialized agents that you manually call, then wire those up as subagents and have a coordinating ‚Äúorchestrator‚Äù call those subagents. Finally try out some of the ‚Äúlooping‚Äù or ‚Äúagent team/swarm‚Äù tools. I only say to go through these levels one by one, just so you can understand how they build on top of each other.\n\nIf you want some examples of agent files, I open sourced the collection of agents I made for GitHub Copilot: https://github.com/ShepAlderson/copilot-orchestra\n\nThey aren‚Äôt ‚Äúperfect‚Äù for Claude, but they are very close. Would need some tweaks for things like tools or such, but Claude itself can do a great job ‚Äúconverting‚Äù these to agent files for itself. Maybe give that a try and see what you can do with it.",
                  "score": 12,
                  "created_utc": "2026-02-12 16:01:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5039od",
                  "author": "adreamofhodor",
                  "text": "I got a max subscription to CC on my own dime for a couple months and started banging away at side projects. Whatever I could think of. You get better at it that way.  \nThe code will still only be as bad (or as good) as _you_ let it be. I read every line of code that‚Äôs written for me. If I don‚Äôt like it, I tweak it. Sometimes by hand, but honestly most of the time I tell the agent to do it- and then I add a rule/restriction/workflow change to prevent it from happening again.",
                  "score": 6,
                  "created_utc": "2026-02-12 16:13:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o50xq5y",
                  "author": "Xyver",
                  "text": "Something that really helped me was watching Claude think. In VSCode it's easier to click the thinking button in the sidebar and follow along, in CLI when you do Ctrl+o it comes much faster in chunks so it's harder to keep up.\n\nBut seeing how it thinks, what decisions it makes, how it interprets your questions... That's the fastest way to learn better prompting",
                  "score": 4,
                  "created_utc": "2026-02-12 18:35:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zyq7g",
                  "author": "shodan_reddit",
                  "text": "I‚Äôm enjoying using spec kit as a way to keep ai on track",
                  "score": 3,
                  "created_utc": "2026-02-12 15:52:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o54iagr",
                  "author": "big_fart_9090",
                  "text": "Your skills as a dev are transferable. The change now is you need to plan it out in a file the LLM can read. Create a plan.md file with the ai with the goals you have in mind. Add the code styling and auto testing rules you have like ‚Äònpm run test‚Äô or whatever. Add the code guard rails. Also let the AI generate a markdown todo list in the plan.md. Let it also phase out the todo list in logical sections. Review the plan, tweak it and let the LLM loose. Make it check each todo item along the process.",
                  "score": 1,
                  "created_utc": "2026-02-13 07:06:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o553i29",
                  "author": "efraglebagga",
                  "text": "\nSimilar boat here, staff engineer leading projects at a small company. My way in was framing it as \"my job is to speed up the team,\" which made the code deluge easier to handle.\n\nKey learnings:\n1/ Treat it like automating your own work. You already have that skill as dev most likely. I avoid the plugin/MCP sprawl and just roll my own tooling (task tracking, specs, etc.)‚Äîthey're just prompts anyway. Once you know what you need, then look for existing tools.\n\n2/ What surprised me: this led to better code, not just more code. As a lead, I've shipped countless rushed features with technical debt. AI unlocks a tireless workforce for all that \"good but tedious\" work we'd normally skip. Today a colleague needed a long but simple refactor‚Äîa year ago we'd have ignored it. Done, without breaking a stride.\n\n3/ The mental space freed from menial work is massive. You focus on design, trade-offs, and architecture. You can choose better options that would've been \"too much work.\"\n\nTry a constraint: don't write a line of code yourself for a week. See what happens.",
                  "score": 1,
                  "created_utc": "2026-02-13 10:25:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o515wq8",
                  "author": "lionmeetsviking",
                  "text": "I‚Äôm sharing my own workflow on this video: https://youtu.be/PI12sEX_jas?si=dEuty9mSt9HBqgM_. Surely far from perfect, but maybe can give some perspective.",
                  "score": 0,
                  "created_utc": "2026-02-12 19:14:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zyeek",
                  "author": "Significant_War720",
                  "text": "Its called experience and ability to adapt.",
                  "score": -6,
                  "created_utc": "2026-02-12 15:50:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4zueyy",
              "author": "CloisteredOyster",
              "text": "When my devs complain that AI writes shit code I remind them that humans do too. As you say it's about the prompting and the reviewing to catch it.",
              "score": 5,
              "created_utc": "2026-02-12 15:31:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5466sk",
                  "author": "lionmeetsviking",
                  "text": "This!\n\nIn all honesty, I think LLM is writing better code than I ever was. It doesn‚Äôt struggle with the code, but with context and proper structures at times. \n\nIt‚Äôs gotten wildly better at architectural structures though, so I think role as an ‚Äúarchitect‚Äù will move to even more high level. We need to become ‚Äúbusiness architects‚Äù or perish.",
                  "score": 2,
                  "created_utc": "2026-02-13 05:26:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o52xdd9",
                  "author": "fj2010",
                  "text": "Yes, but AI can produce a lot more code much more quickly.",
                  "score": 1,
                  "created_utc": "2026-02-13 00:36:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o538zjq",
              "author": "uni-monkey",
              "text": "30 year dev as well. I haven‚Äôt written much of anything since sonnet 4.5. For me that was the point where I was able to give the model most of requirements and trust that it could build a system to meet them.",
              "score": 2,
              "created_utc": "2026-02-13 01:46:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54lb5r",
              "author": "_ILikePancakes",
              "text": "There are things that shouldn't be considered fluid. Such as tests, since they are explicitly asserting the contracts.",
              "score": 2,
              "created_utc": "2026-02-13 07:34:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54sqrg",
                  "author": "lionmeetsviking",
                  "text": "I fully agree! Tests, proofs, separation of concerns, logic reusability, contracts, and a dozen other things. Only when you have strict guardrails in place can you start \"sculpting\" your product more organically. Drift still happens, but it's easier to control and refactor.",
                  "score": 1,
                  "created_utc": "2026-02-13 08:43:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o58xu9t",
              "author": "cantgettherefromhere",
              "text": "Another 30+ year dev here. I haven't written code since Sonnet 3.5. It was painful then, but marginally better end result than I'd get doing it by hand, and somewhat faster.\n\nNow with Opus 4.6 I can get solid results and I spend much less time using the model to go back and fix things.\n\nAs other people have mentioned, a good plan is paramount. For small tasks I use CC plan mode. For major features, refactors, and things I haven't fully thought out yet, I have found Get Shit Done (GSD) to be pivotal. I get quite bored answering hundreds upon hundreds of questions, but the end result is usually great. And the UAT/debugging process is excellent. Very, very infrequently do I have to go back and fix anything.",
              "score": 2,
              "created_utc": "2026-02-13 22:51:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51wonu",
              "author": "Express-One-1096",
              "text": "I recently had a shower thought. \n\nWe‚Äôve been creating higher level languages for years. Abstraction abstraction abstraction. \n\n\nI wonder if we‚Äôre about to move away from that and that LLMs will be the abstraction layer. \n\nWhy do we need to see and completely understand the code? Do you understand what happens under the hood in a for loop? (You probably do because you have 30 years of experience)\n\nI feel we are living in interesting times",
              "score": 3,
              "created_utc": "2026-02-12 21:21:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5742l9",
                  "author": "RobotHavGunz",
                  "text": "I had a similar thought. LLMs/Agents are, to me, essentially a new form of a compiler. Or perhaps a transpiler. Just another step in the toolchain that takes us that one step further from the bare metal",
                  "score": 2,
                  "created_utc": "2026-02-13 17:26:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5566hl",
                  "author": "BlazedAndConfused",
                  "text": "What you‚Äôre describing is the machine layer.\n\nIf AI can understand and speak that instead of coding languages which is meant for humans, then we won‚Äôt need them. Languages are for us to speak to machines and debug.",
                  "score": 1,
                  "created_utc": "2026-02-13 10:49:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o52xs7x",
                  "author": "fj2010",
                  "text": "I think there‚Äôs something in this. The big difference is reproducibility - high level code can be expected to always execute more or less the same way. AI prompts can generate different results even within the same session and same llm",
                  "score": 0,
                  "created_utc": "2026-02-13 00:38:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o559t2s",
              "author": "gcirone",
              "text": "Yes agree, but AI and us need to maintain the software too. Even if we don‚Äôt care anymore about code quality we need to know what we make. Another aspect is psicology, dev already hate other dev code imagine the Ai one we will lost interest in what we do üòî\n\nThis is our future regardless if we like or not ü§ñ",
              "score": 1,
              "created_utc": "2026-02-13 11:20:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o56it2p",
              "author": "nomad_sk_",
              "text": "OP seems working in PHP and data engineering which is really low hanging fruit so I‚Äôm not surprised. Something like developing global is available system, memory optimize CP optimize processing for edge computing ,system engineering, developing distributed parallel processing applications, and storage that is where software engineers are required because it needs real computer science and mathematics skills.\n\n\nAsk yourself a question would you write a software for airplane, backend of global financial banking , backend of electricity grid, backend of global cellular communication system via LLM or you would prefer highly skilled software engineer to write it ?",
              "score": 1,
              "created_utc": "2026-02-13 15:44:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57gpf2",
                  "author": "lionmeetsviking",
                  "text": "Very little PHP these days, but otherwise your assessment is correct; failures in my software will not cause loss of life. I would not want LLM written code to keep my respirator working, but neither would I trust myself for that. So deep understanding of programming will not disappear, but it will become more rare for sure.",
                  "score": 1,
                  "created_utc": "2026-02-13 18:26:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o574sxs",
              "author": "AggressiveReport5747",
              "text": "I migrated an old site I made for my wifes business to a CMS so she could publish articles and stuff herself.¬†\n\n\nAfter using the CMS for 15 seconds, I was like this is hot garbage. Spent four hours planning an internal CMS configuration and let it rip¬†\n\n\nBeautiful integrated CMS. No outdated ugly thing with buggy authentication. Took more time trying to setup this third party thing then integrating my own.",
              "score": 1,
              "created_utc": "2026-02-13 17:29:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zs80z",
              "author": "KOM_Unchained",
              "text": "This is the way. Impact is all.",
              "score": 1,
              "created_utc": "2026-02-12 15:21:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51rblw",
              "author": "clintCamp",
              "text": "And if you do it right, every piece of quality code is something you can point to from a different project and CC will magically just migrate the capability in.   I did that with a whisper speech to text transcription code from a voice translation app into another audio file transcription app today with zero problems.",
              "score": 1,
              "created_utc": "2026-02-12 20:56:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o52ei70",
              "author": "sjmog",
              "text": "It‚Äôs the same set of sensitivities I use for evaluating  my own code quality, just sped up 10x. Most of the skills I‚Äôve built are useful for evaluating approaches anyway, whether I came up with them or someone else did.",
              "score": 1,
              "created_utc": "2026-02-12 22:50:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51ai6r",
              "author": "AdventurousCoconut71",
              "text": "It is all shit code but nobody cares because they will not look at it only AI will look at it.¬†",
              "score": -1,
              "created_utc": "2026-02-12 19:36:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zmk1m",
          "author": "cport1",
          "text": "I have a team of 65+ engineers. I would say about 80% of the code written by our team is by AI. Refactoring and migrating codebases is where CC really shines. ",
          "score": 170,
          "created_utc": "2026-02-12 14:53:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zo08g",
              "author": "Muted_Farmer_5004",
              "text": "I've found this use case surprisingly efficient, too, but without structure and guidance, it's still a fool's errand. But it's the difference between letting tech debt pile up and making a well-documented guess that doesn't lead to a total freeze for X/months. ",
              "score": 29,
              "created_utc": "2026-02-12 15:00:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51qlvl",
                  "author": "clintCamp",
                  "text": "I make sure to spend at least 8 hours laying out everything for a project so that any question that could be had about what will be used, what features and what architecture will look like is fully documented before I let it actually start programming.  Then I have it and other models audit it a couple of times and check each other's unit tests while I also manually test the features.  It is a little depressing as well as exciting to see where things are going and see that I am now just an architect and haven't really had to deep dive the code too much because it ends up working how I told it to build it.",
                  "score": 13,
                  "created_utc": "2026-02-12 20:53:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5465fs",
                  "author": "GiBravo",
                  "text": "What is even a tech debt now? Will it continue to have the same meaning going forward? At this rate the models are improving, if humans don't have to touch any code and AI plans, writes, tests and triages, and we are simply the orchestrator..  do we even need to worry about tech debts anymore? If tech debt is another $100 worth of tokens to get cleared, and all we need to worry about is  functionality and not how pretty the code is, who would care anymore? There will be teams that will know how to clear tech debt with AI and there will be teams that will fully get dissolved by their tech debt. One thing is for sure, if you keep saying I like to beautifully handcraft my code, then you may not even get a chance to see your tech debt.",
                  "score": 2,
                  "created_utc": "2026-02-13 05:25:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o53i37m",
              "author": "WinOdd7962",
              "text": ">I have a team of 65+ engineers.¬†I would say about 80% of the code written by our team is by AI.\n\nHonest question, what do you expect the headcount to be in 1 year?",
              "score": 8,
              "created_utc": "2026-02-13 02:42:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56ayuu",
                  "author": "WinOdd7962",
                  "text": "u/cport1 answered other comments, ignored this one. Layoffs coming.",
                  "score": 2,
                  "created_utc": "2026-02-13 15:06:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o54iz4o",
              "author": "Ok_Monk_6594",
              "text": "I am the opposite, an extremely lean team with a bunch of tech debt. \n\nThe Claude license through my employer has enabled us to refactor a years old code base in just three days. With even more robust tests in place to prevent regressions.",
              "score": 3,
              "created_utc": "2026-02-13 07:12:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o564tfg",
                  "author": "omggold",
                  "text": "What was the process to do this? Like did someone petition to get Claude code,  then were folks trained (or were the already familiar), and without it would you have just had a bunch of tech debt?\n\nI‚Äôm really interested in effective organizational change around AI usage",
                  "score": 2,
                  "created_utc": "2026-02-13 14:35:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o54u6ta",
              "author": "Brilliant_Pick_4801",
              "text": "Were all 65 plus engineers trained in using CC effectively?",
              "score": 2,
              "created_utc": "2026-02-13 08:56:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55i716",
                  "author": "cport1",
                  "text": "Great question. We've standardized as a team tooling, processes, directory and file structure for ai knowledge, and spend an hour each week dedicated to this as a guild.",
                  "score": 2,
                  "created_utc": "2026-02-13 12:24:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o55o8yg",
              "author": "vjouda",
              "text": "What is the net speed gain from using AI? If you can provide some details for specific tasks would be great, but even some overall number would be interesting.",
              "score": 1,
              "created_utc": "2026-02-13 13:04:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zww5z",
              "author": "12berliners",
              "text": "Sorry but what is CC?¬†",
              "score": -15,
              "created_utc": "2026-02-12 15:43:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zxjfk",
                  "author": "RightCoach5926",
                  "text": "Cabbage Collection",
                  "score": 34,
                  "created_utc": "2026-02-12 15:46:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zx152",
                  "author": "keftes",
                  "text": "You're in the subreddit and you ask this?",
                  "score": 13,
                  "created_utc": "2026-02-12 15:44:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o504ep6",
                  "author": "AJGrayTay",
                  "text": "C-laude C-ode.",
                  "score": 5,
                  "created_utc": "2026-02-12 16:18:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zxzht",
                  "author": "krullulon",
                  "text": "BRUH.",
                  "score": 5,
                  "created_utc": "2026-02-12 15:48:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o500pac",
                  "author": "JUSTICE_SALTIE",
                  "text": "courtesy copy",
                  "score": 1,
                  "created_utc": "2026-02-12 16:01:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51f9eg",
                  "author": "Quirky-Degree-6290",
                  "text": "Caitlin Clark. Go hawks.",
                  "score": 0,
                  "created_utc": "2026-02-12 19:58:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zq120",
          "author": "Solest044",
          "text": "We're probably at near 100% code is generated but I don't think people really appreciate what that means. \n\nIt doesn't mean we're saying \"Claude please go do X\" and then calling it good. It's more of a handheld approach with each developer generating the code, pushing it to GitHub, reviewing it themselves, going back in with Claude to edit, etc.\n\nEach developer is usually still driving the LLM pretty carefully.\n\nWe've also invested a lot of time and effort into documentation and architecture to support the LLMs not producing shit code. That means patterns for things, utilities we want it to use, light examples on how we prefer certain things done, etc.\n\nWe also have skills developed to help it index these docs in a lightweight fashion so it's not constantly pulling them in for consideration and eating tokens. \n\nIt absolutely chews through money, but our velocity and quality is high enough to justify it.",
          "score": 56,
          "created_utc": "2026-02-12 15:10:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zt3tw",
              "author": "svachalek",
              "text": "Same. I think we‚Äôre nearly 100% machine generated but it doesn‚Äôt mean we‚Äôre all playing foosball. People are as busy and tired as ever.",
              "score": 15,
              "created_utc": "2026-02-12 15:25:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53c1ru",
              "author": "carson63000",
              "text": "Similar situation here. We‚Äôre spending the same amount of time working and probably tapping out just as many keystrokes on the keyboard - it‚Äôs just that those keystrokes are conversations with Claude and the end result is a lot more code being produced than used to be the case.\n\nIt‚Äôs like moving from assembly coding to high level languages. Same number of keystrokes get a lot more done (and yes, some people will say the result isn‚Äôt as good).",
              "score": 4,
              "created_utc": "2026-02-13 02:05:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51ijst",
              "author": "SurfGsus",
              "text": "This comment really resonates with me. Many talk about AI taking jobs and, while that may be true, the more nuanced (and hopefully correct statement) is that it‚Äôs reshaping how we do our jobs. Perhaps the days of painfully typing each line of syntax are gone as we shift towards shaping the specifications and generating the code.\n\nHere‚Äôs an interesting angle that‚Äôs less talked about as well- LLMs are trained on data released under different licenses. The generated code may be close enough to the original source that the owners may claim its subject to their licensing terms. My company explicitly disallows the use of AI on externally released products for this reason. It‚Äôll be interesting to see how the legal aspects of this are addressed over time.\n\nPoint is, I think there will always be a need for people to write (or manage the generation of) code but how many engineers are required and how they work may drastically change. At least this is what I tell myself so I can sleep at night for now :)",
              "score": 4,
              "created_utc": "2026-02-12 20:14:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53bjly",
                  "author": "carson63000",
                  "text": "Yeah I work for a growing online business, we have always had a long backlog of feature ideas and tech management absolutely sees the promise of AI being that it will allow the same sized team get a lot more things done (and it is definitely delivering). \n\nBut I‚Äôm sure there are plenty of companies where tech is a cost centre not the core business, and they‚Äôd be looking to have a smaller team get the same amount of work done.",
                  "score": 2,
                  "created_utc": "2026-02-13 02:02:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o53i96n",
              "author": "halfway-to-the-grave",
              "text": "How much money are ya paying per seat?",
              "score": 1,
              "created_utc": "2026-02-13 02:43:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55hhip",
                  "author": "Solest044",
                  "text": "It varies pretty heavily by developer but usually between $50 and $500 per month. API usage per dev at the moment.\n\nWe're considering switching to Max plans but the limits are also a concern. We can potentially supplement with Copilot when limits are hit.\n\nMoney isn't our worry for the moment, thankfully. \"Burn gas\" is our current directive.",
                  "score": 1,
                  "created_utc": "2026-02-13 12:19:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o51d4h8",
              "author": "passiveturtle",
              "text": "How are those skills working? I have been trying to figure out what would be the best approach for not ingesting an entire codebase when I need to pull context from repos outside of my directory on github",
              "score": 1,
              "created_utc": "2026-02-12 19:48:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55iek7",
                  "author": "Solest044",
                  "text": "I personally have it start with our docs folder which is full of well organized, well named files. \n\nI simply have it look at the directory structure, assess the names, and dive deeper into areas that make sense.\n\nYou could also point it at an index file that has this information. Since you're referencing OUTSIDE of your codebase, explicit instructions to assess file names and crawl is probably your best bet. I would simply not recommend using Claude on codebases you haven't personally set up for use. You can do it, but be prepared to burn a lot of tokens making it happen.\n\nWe use a slightly different approach in a different part of the codebase similar to skills that has the top of each file contain a one line string of text detailing what the file is about. \n\nClaude is aware of this structure via its CLAUDE.md and uses it regularly. \n\nI also have a \"context gatherer\" skill which gives explicit instructions on listing files in certain parts of the codebase for context with instructions to go deeper. \n\nAnother skill called \"trace data flow\" which uses an efficient LSP MCP for helping it find references has also been really nice. Its usual grep approach is often very token heavy and finds way too much fluff. This is something we all normally do when we're planning refractors or debugging, so you can see how these start to play off one another.\n\nThe trick is to think of tiny, sharp tools/processes. Avoid big, context heavy one shot kinda skills... They just have too much room for inconsistency.",
                  "score": 2,
                  "created_utc": "2026-02-13 12:26:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51yem6",
                  "author": "Innate-Idea",
                  "text": "I have asked Claude to generate the skills. You can point it to the Claude skills page, and it generates Skills for my app. researcher, front-end designer, and then you can modify based on the files you see. ",
                  "score": 0,
                  "created_utc": "2026-02-12 21:29:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zodb1",
          "author": "Adventurous-Crow-750",
          "text": "Staff software engineer/r&d: I don't write code anymore unless I'm just writing something quick. Claude does 90% of it and I just review it. Sometimes it fails, but when it does it's normally not subtle failures it's like a disaster zone so then I just do it myself. \n\nI've hooked up jira to it so tickets get a first pass by Claude attempting it and it opens a PR. 9/10 times it works great. \n\nI use a lot of microservices with well defined responsibilities and API spec which I've built. Claude without this is a lot worse. It doesn't know where to look in big monorepos and really struggles. Microservice repos it breezes through... As long as you don't have giant thousand line files - it seems to struggle a lot with editing large files. \n\nBiggest help is telling it where to put the change and doing one change a time. So if for example I want to update my client library for an API because I wrote new endpoints, then I have it generate swagger docs from comments in the codebase then have it use the swagger doc to update the client library in x folder to support the new doc. This is two calls to Claude one to make the doc and another to use it for a work product. If I have it do both it can goof up. \n\nClaude fails like once every 25 tasks when I use it this way which is better than most engineers. I also know other coworkers who really struggle getting good output and I'm not sure why their experience is so much worse than mine.",
          "score": 32,
          "created_utc": "2026-02-12 15:02:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zxazy",
              "author": "HelpRespawnedAsDee",
              "text": "bro it's honestly so fucking wild to hear this from actual engineers, some of us handling very complex and niche codebases, some of you guys managing whole teams. yet you see other programming subs people literally have their head stuck in the sand.",
              "score": 8,
              "created_utc": "2026-02-12 15:45:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o501pjk",
                  "author": "Shep_Alderson",
                  "text": "Yeah, I have spent much of my time in Claude or other AI agent subreddits for the last several months. When I went back to other programming subreddits just to see what‚Äôs going on and made a comment that was basically the most milquetoast support of learning to use AI tools, and I got downvoted to hell and flamed with dozens of comments.\n\nThe fear is palpable.",
                  "score": 12,
                  "created_utc": "2026-02-12 16:06:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zx0z3",
          "author": "Hendrix312002",
          "text": "I've been a software engineer for over 11 years now. I haven't written much code at all in the past two years. I have spent the past three years learning AI and how to use it effectively and the results I am getting are staggering and frankly hard for me to believe and wrap my head around. I don't see myself ever going back to \"writing code by hand.\" \n\nMany disagree but for anyone to think that this is not the future of software engineering I don't see it. I hear a lot of people saying all kinds of crazy things about AI, but if you ignore what is online, use the latest and greatest models available and put the time into developing the skill, and even more importantly changing your mindset, traditional software engineering no longer exists. \n\nWith that said, I as a software engineer with 11 years of experience am far more effective and can do things that \"vibe coders\" cannot. People naively assume that all we do is \"write code\" whereas code is the end product of what we actually do and that is think hard, deeply, problem solve, research, breakdown complex problems into smaller pieces, etc. \n\nTo be completely honest with you, I feel like I genuinely have super powers now. I have built apps that would have taken me an a team of highly skilled engineers months in days... many times over. ",
          "score": 16,
          "created_utc": "2026-02-12 15:44:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51norc",
              "author": "Film4Sport",
              "text": "If you were building a desktop/mobile PWA for a tennis club which constraints, solid architecture, and strict rules would you provide it?\n\nAfter having issues building it out at the beginning I started again by planning a well structured codebase, ensuring tests were ran afterwards, adding to CLAUDE.md to avoid repeating mistakes, testing with Playwright before giving me results, and that's all I can think of for now. After enough changes I will ask it to rate it out of 10 from a senior devs perspective who is being critical yet honest, and then provide suggestions on how to improve it to get to 10/10\n\nI've done most of the frontend work, but I've learned the backend takes more time and is much more important and crucial the ensure data consistency, security, edge cases are tested, etc. so I'm hoping to get solid prompts to give it to help me make it production ready",
              "score": 0,
              "created_utc": "2026-02-12 20:39:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53mjq7",
              "author": "WinOdd7962",
              "text": "See, it's this sort mindset that's more off than you believe. You're tailoring yourself as someone that *gets it* when others don't see whats happening in front of them. Given how quickly we've reached this point - an engineer with 11 years experience is saying traditional software engineering no longer exists - where do you think we'll be in another X years? Will you still maintain your special intrinsic value or will your critical thinking and experience be irrelevant because the AI can just do everything?",
              "score": 0,
              "created_utc": "2026-02-13 03:10:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50htw7",
          "author": "ragnhildensteiner",
          "text": "Not anymore.\n\nSenior dev here. 16 years exp.\n\nA few weeks ago I officially went all in on vibe engineering. I barely touch an IDE now. Browser and terminal, that‚Äôs it.\n\nWe are past the tipping point. If you give AI clear constraints, solid architecture, and strict rules, it produces production-grade, scalable, secure code. Not toy demos. Real systems.\n\nAnd once you start running multiple agents together, it changes the game completely. One writes the code. Another tears it apart from a security angle. Another looks at performance. Another checks patterns and structure. They hand feedback back and forth until it holds up.\n\nIf the result is sloppy, that‚Äôs on the human now. Not the AI.\n\n**TL;DR:** At this point, humans are not the limiting factor because AI can‚Äôt code. Humans are the limiting factor because they fail to define the system properly.",
          "score": 23,
          "created_utc": "2026-02-12 17:21:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51forf",
              "author": "-18k-",
              "text": "> And once you start running multiple agents together, it changes the game completely. One writes the code. Another tears it apart from a security angle. Another looks at performance. Another checks patterns and structure. They hand feedback back and forth until it holds up.\n\ngods, that's great.",
              "score": 4,
              "created_utc": "2026-02-12 20:01:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53dpk5",
              "author": "RyanTranquil",
              "text": "I use teams pretty heavily, it‚Äôs great, used it tonight for a major refactoring .. helped save us weeks of time",
              "score": 2,
              "created_utc": "2026-02-13 02:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53fkrv",
                  "author": "ragnhildensteiner",
                  "text": "It's hard to measure but it's so noticeable how much more efficient it is to use agent teams for big complex features/refactoring/debugging, compared to a single agent. \n\nIt's like you have a full dev team that talk to each other.",
                  "score": 1,
                  "created_utc": "2026-02-13 02:26:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o55m1h1",
                  "author": "ruzziaisaterrorstate",
                  "text": "How do you create teams? Do you create a skill for each persona and then trigger them all in a chat?",
                  "score": 1,
                  "created_utc": "2026-02-13 12:50:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o549e93",
              "author": "Captain-Fries",
              "text": "We don't have access directly to claude code cli but we have github copilot within PyCharm with the option to give prompts and have agents write them in the background and open a PR, as well as having the option to plan or just implement stuff.¬†\nHow do you set up different agents to do different things? Do you have any resources on how to set up AI to succeed within a repo?\nMost of what we do is create data pipelines. Do you happen to have any tips to set up agents to connect to a databricks sql warehouse to be able to point it to tables directly?¬†",
              "score": 1,
              "created_utc": "2026-02-13 05:51:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51kd9o",
              "author": "Film4Sport",
              "text": "If you were building a desktop/mobile PWA for a tennis club which constraints, solid architecture, and strict rules would you provide it?\n\nAfter having issues building it out at the beginning I started again by planning a well structured codebase, ensuring tests were ran afterwards, adding to CLAUDE.md to avoid repeating mistakes, testing with Playwright before giving me results, and that's all I can think of for now. After enough changes I will ask it to rate it out of 10 from a senior devs perspective who is being critical yet honest, and then provide suggestions on how to improve it to get to 10/10\n\nI've done most of the frontend work, but I've learned the backend takes more time and is much more important and crucial the ensure data consistency, security, edge cases are tested, etc. so I'm hoping to get solid prompts to give it to help me make it production ready",
              "score": -1,
              "created_utc": "2026-02-12 20:23:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zulro",
          "author": "DifficultPlatypus559",
          "text": "The amount of code I write is rapidly decreasing. But the amount of code I commit has gone through the roof.\n\nOne of the biggest challenges to adopting AI is not the tools and workflows, it's battling with our ego, letting go, and dare I say - accepting the slop.\n\nThe position I'm coming to is there's two types of AI slop:\n\n1. code that offends my stylistic sensibilities, but fundamentally works fine\n\n2. toxic slop that breaks things, has vulnerabilities etc\n\nYou don't want to be fighting AI on every line of code it writes - it'll drive you mad. But you do need to watch out for the toxic slop. That's kind of the job now.",
          "score": 16,
          "created_utc": "2026-02-12 15:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o538a9x",
              "author": "muuchthrows",
              "text": "There‚Äôs also:\n\n3. Code that is overly verbose, duplicating logic, doing something in 50 lines instead of 5, not using obvious library or built-in functions.\n\nThe code works, but the amount of context needed by the next AI agent to make the correct modifications increases. And it will create bad patterns that the next AI agent will replicate and spread in the code base.",
              "score": 5,
              "created_utc": "2026-02-13 01:42:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54vpr6",
                  "author": "DifficultPlatypus559",
                  "text": "Fair comment. I think \"overly verbose\" I'd probably bundle with my stylistic sensibilities category. But if I saw it writing a function that I knew already existed or had a a library for then, yeah I'd push back against that.\n\nI guess my main point is that if you just think \"my code is better\" - which it almost certainly is - then that gets in the way. It becomes a sort of emotional blocker that stops you making the most out of some pretty amazing tools.",
                  "score": 2,
                  "created_utc": "2026-02-13 09:11:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o54eeuu",
              "author": "djmcdee101",
              "text": "I simply cannot accept code that offends me to look at even if it's functionally sound. That's why I developed a style guide with Claude that's always loaded into context. Works pretty well even if I do catch the odd fuck-up",
              "score": 1,
              "created_utc": "2026-02-13 06:33:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zrx8p",
          "author": "kgoncharuk",
          "text": "would be suprising if many people in ClaudeCode sub will say they are not using claude code",
          "score": 14,
          "created_utc": "2026-02-12 15:19:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zuu38",
              "author": "zulutune",
              "text": "I‚Äôm of course using claude code, but I can‚Äôt say 100% of my output was generated by claude. Maybe 30%.",
              "score": 2,
              "created_utc": "2026-02-12 15:33:55",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o517q9v",
              "author": "Emotional-Ad5025",
              "text": "thanks, I forgot that for a moment haha",
              "score": 2,
              "created_utc": "2026-02-12 19:22:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51qifq",
          "author": "Horror_Brother67",
          "text": "The big wigs dont care about vibecoding vs. proper architecture implementation. When I tell them I vibecoded a tool in 1 hour with a bunch of security risks vs me doing it in 2 weeks with minimal security risks, they just see the 79 hours of saved labor costs. Thats the only backend they're worried about at this point. All they ask me is \"but does it work the same?\" sure, sure it does LOL.  \n  \n22 years in, I knew this day would come, I just didn't think it would happen while I was still alive.\n\nFWIW, we had a pretty good run. I'm happy with my career choices and I cant wait to see what comes next.\n\nI always wanted to open a pizza shop, maybe I can do that now.",
          "score": 5,
          "created_utc": "2026-02-12 20:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51rxpc",
              "author": "biinjo",
              "text": "Second problem: pizza shop market get saturated with developers making a job out of their second favorite hobby.",
              "score": 3,
              "created_utc": "2026-02-12 20:59:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51siak",
                  "author": "Horror_Brother67",
                  "text": "damn it LOL",
                  "score": 2,
                  "created_utc": "2026-02-12 21:02:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zzv65",
          "author": "Best_Position4574",
          "text": "18 YOE. Love writing high quality beautifully crafted code. It does get the better of me though at times.¬†\n\nHaven‚Äôt written a single line of code for any reason for about 4 months and I‚Äôve done maybe 2x more Eng work over that period.¬†\n\nIf something isn‚Äôt right I tell Claude. If I think it‚Äôs missing something in its agent file I tell it to add it. If I have an idea about a skill or agent I tell Claude to build it. If my computer isn‚Äôt working I tell Claude to fix it. If I need to add something to my zshrc file I tell Claude to add it.¬†\n\nWork is becoming like factorio to me (the factory automation game). Work is pushing us hard to figure it out. It‚Äôs partly survival. It‚Äôs partly I‚Äôll be light years ahead of any other job I‚Äôd go to in terms of AI. I‚Äôll experiment and learn as much as I can while I can just burn tokens on anything and everything.¬†\n\nAnd hot damn is it a wild ride right now.¬†",
          "score": 16,
          "created_utc": "2026-02-12 15:57:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50843h",
          "author": "nokillswitch4awesome",
          "text": "I am a 30+ year dev who is only in the last month dipping my feet into what AI, and Claude specifically, can do for me as a tool. I never will be in that vibe coding camp of trust it implicitly. But I also have decades of experience to fall back on in knowing what to look for when reviewing it's work. But I will say so far I have been very impressed with the help it has given me. Any time I ask it to do something, it's gotten me no less than 90% of the way to a final product. And that has not just been coding, it's been documentation tasks, and I've been giving Claude cowork some things to do at home.¬†\n\nI'm having to actively think in a way to give it things to do - that's the biggest change for me so far, and finding that balance between when to do it myself versus when to ask it for help will come in time. I also set major guardrails on it, i tell it that it cannot commit anything, so there is always fallback places set up. And sometimes I simply use plan mode just to generate a to-do list for a task and then do it myself.¬†\n\nI'm glad I waited through the period of early adoption and let others work the initial kinks out, but for me at least, all the positive press claude has been getting seems warranted.¬†\n\nI think us experienced senior devs aren't going anywhere. Because what we have that AI does not and will not have any time soon is an understanding of the \"why\" part of coding. What's the business logic behind it, why are decisions being made that result in us having to write these tools and features. Combine that with experienced eyes that can review the work of AI tools and decide if it's correct or not. \n\nJunior devs? That's another story. I would hate to be a newbie in this day and age, because they are going to have to learn just as we did, there is no replacement for experience, but at the same time stay on top of the changes in tools, and remember these are TOOLS.",
          "score": 9,
          "created_utc": "2026-02-12 16:35:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51bxnc",
              "author": "Shep_Alderson",
              "text": "If you want, you can explicitly deny git commands in your Claude.md file. Just a thought it you want to add some safeguards.",
              "score": 1,
              "created_utc": "2026-02-12 19:43:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51ncmy",
                  "author": "nokillswitch4awesome",
                  "text": "I did that in the global Claude.md file. I also told it to not be a blind yes man. Challenge me if I propose half baked solutions.",
                  "score": 1,
                  "created_utc": "2026-02-12 20:37:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o51l31a",
              "author": "UniqueDraft",
              "text": "Same here, 25yrs + and I adopted AI fully (Claude Code and Kiro), only open an IDE to inspect and verify changes. Haven't written a line of code recently, spending time on more productive tasks.",
              "score": 1,
              "created_utc": "2026-02-12 20:26:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zqkm5",
          "author": "ParkingAgent2769",
          "text": "Youll get very biased opinions asking in here",
          "score": 11,
          "created_utc": "2026-02-12 15:13:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51fdis",
              "author": "-18k-",
              "text": "Or in other words, many many points of view!",
              "score": -1,
              "created_utc": "2026-02-12 19:59:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50ymqt",
          "author": "CombinationCommon377",
          "text": "It's not just about prompting, it's about setting up tools, agents, and iteration on all the above. Claude does an anti-pattern? You change the agent. I don't write the code myself anymore.",
          "score": 5,
          "created_utc": "2026-02-12 18:39:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51mcgx",
              "author": "Film4Sport",
              "text": "If you were building a desktop/mobile PWA for a tennis club which constraints, solid architecture, and strict rules would you provide it?\n\nAfter having issues building it out at the beginning I started again by planning a well structured codebase, ensuring tests were ran afterwards, adding to CLAUDE.md to avoid repeating mistakes, testing with Playwright before giving me results, and that's all I can think of for now. After enough changes I will ask it to rate it out of 10 from a senior devs perspective who is being critical yet honest, and then provide suggestions on how to improve it to get to 10/10\n\nI've done most of the frontend work, but I've learned the backend takes more time and is much more important and crucial the ensure data consistency, security, edge cases are tested, etc. so I'm hoping to get solid prompts to give it to help me make it production ready",
              "score": 1,
              "created_utc": "2026-02-12 20:32:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51uubr",
                  "author": "CombinationCommon377",
                  "text": "It's not just the prompts, it's the quality of the reviews you give it along the way. If you're an experienced engineer, then spec kitty is great. It will take your requirements, clarify them, then produce a document, you review it, and so on... but if you get the spec right, the code is often pretty good.",
                  "score": 1,
                  "created_utc": "2026-02-12 21:13:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zt552",
          "author": "dpaanlka",
          "text": "Coding since 1999. Extremely minimal raw syntax typing today. Way more time on feature development and infrastructure engineering these days. I still have a full day to work every single day. It‚Äôs much more enjoyable now to create cool shit much more rapidly. I wouldn‚Äôt want to go back.",
          "score": 6,
          "created_utc": "2026-02-12 15:25:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50905s",
          "author": "Sad_Independent_9049",
          "text": "This would be better asked at a non-ai subreddit. Maybe r/programming ? there is just sooo much astroturfing going on",
          "score": 3,
          "created_utc": "2026-02-12 16:39:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o509ur6",
              "author": "zulutune",
              "text": "Yes, good suggestion. Will probably get very different answers there. But the chance that I find people ‚Äúwho‚Äôs seen the light‚Äù here is much bigger.",
              "score": 1,
              "created_utc": "2026-02-12 16:43:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o50da0y",
                  "author": "Sad_Independent_9049",
                  "text": "Many, if not most people at r/programming are techies. I am willing to bet the answers there are more likely to be closer to reality than here.¬†\n\n\nFor a less biased approach, its good to measure both sides",
                  "score": 1,
                  "created_utc": "2026-02-12 16:59:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o53oh64",
              "author": "WinOdd7962",
              "text": "The programming and CS subs ban you for talking about AI.",
              "score": 1,
              "created_utc": "2026-02-13 03:22:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50rzqz",
          "author": "PlaneFinish9882",
          "text": "Not AI writing the code for an engineer, but engineer writing code with acceleration of AI - two big differences.\n\nIn my full time job I still write code, but its a legacy codebase and changes are minimal.\nIn my personal projects 95% of it is AI, but I understand what it does, set up architecture and take important technical decisions.\n\nPeople don't understand that if you have never been an engineer - you don't magically become one with AI.\nNon-technical people also don't understand that AI is not some magical super-programmer, but a very empowered google that allows to inject code directly, eliminating the effort of googling, reading documentation etc.\n\nIf you were a fisherman and to go fishing you were using your rowboat, and suddenly the village gave you a fishing  ship with diesel engine and the tools to catch more fish - you are still a fisherman, but more effective one.\nWhile the farmer won't know how to catch fish, no matter what boat he has. He might try, but end up with catching and old shoe instead, until he learns.\n\nAlso I think very important to understand that in current reality, the value of human intellect is even more important than it was, not vice versa. Because Intellectual people can use tools they were given to build fantastic projects.\nInstead, the value of information is zero. Universities, schools can teach you lot of skills like socialization or stubbornness, but not give you something new.\n\nTherefore, if you are an intellectual person and have a vision for this world, its your time to shine, because all the tools are there!",
          "score": 3,
          "created_utc": "2026-02-12 18:08:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55bmts",
              "author": "stavsanan",
              "text": "Loved the way you described this, I do and feel the same thing because in the job no matter which model I use and the code generated and the best practices it thinks it knows it doesn't know the full picture and the things doesn't work as they way he can research and implement this on his first try, but when i try to do side projects  and I dont feel \"Paid\" just as much as the job or trying to learn something knew it so hard for me just to read docs and learn it by myself and most of the code I write is assisted with the AI, that helps me boost up my speed and knowledge as far as I go but I do want to learn by myself but I dont know how can I do this without the urge to use it.\n\n",
              "score": 2,
              "created_utc": "2026-02-13 11:35:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zr1md",
          "author": "Mother-Ad-2559",
          "text": "Senior dev here, I‚Äôve not been writing code for about two years now. I don‚Äôt find code quality an issue at all since it‚Äôs so easy to setup best practice guides and as long as you use a good base model, that listens to your instructions, it‚Äôs a complete non issue.\n\nMy prediction is that companies will not hire devs who code in two years.",
          "score": 6,
          "created_utc": "2026-02-12 15:15:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zo54x",
          "author": "mohdgame",
          "text": "Well,for my own project especially with libraries that i know very well i write my own core code by hand. I am much faster this way. \n\nBut for scaffolding, naming conventions, debugging, code review i use an agent. \n\nTo be totally honest, most of my usage of claude code is to detect code review for dumb mistakes and scaffolding.",
          "score": 4,
          "created_utc": "2026-02-12 15:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zzc96",
          "author": "Shep_Alderson",
          "text": "I‚Äôve been in the industry about 15 years, and yeah, it‚Äôs been a big shift. It feels on the magnitude of infrastructure as code or the shift from colocation to cloud.\n\nI would say I use agents for about 90% of my code, similar to others who answered here. I remember when I first realized that agents could write code almost as well as me (thinking back to the Sonnet 4 days, and even a bit of the Sonnet 3.7 days, though less so). I had a few months of deep existential crisis, and feared I needed to hurry up and skill up into a trade that‚Äôs more physical and not connected to ‚Äúknowledge work‚Äù. I was feeling deeply ‚Äúleft behind‚Äù and had attached so much of my self worth to my ability to produce working and efficient code.\n\nIt was when I realized that agentic tools are just that, tools, that I kinda snapped out of it and dug in. I heard someone say ‚ÄúIt‚Äôs not AI that will replace you, it‚Äôs the engineer who knows how to use AI that will‚Äù, and that really stuck with me and lit a fire under my ass. I will be the engineer who knows how to use AI.\n\nI really dug in, spending my off hours to push the boundaries and try new things. While I‚Äôm not yet permitted to use all the tools at work yet, I‚Äôm practicing on my own projects and slowly my company is making progress with allowing us to use agentic tools. What we‚Äôre seeing is that the senior devs who have been in it with building and running the product, are the ones seeing the most benefit. Anecdotally, the ‚Äúarchitect‚Äù folks are actually having a harder time with it. They have gotten so used to staying so high level that they don‚Äôt realize how much goes into breaking down goals and tasks into work people/agents can do, never mind the fact they haven‚Äôt actually touched code in years. Juniors are one area I don‚Äôt have direct vision into, as my team currently doesn‚Äôt have anyone below about an ‚Äúengineer II‚Äù level these days.\n\nAnywho, this is all to say that, what I realized was it wasn‚Äôt the code itself where I added value and the act of writing code isn‚Äôt why I got into this business. I got into this because I like building things, and the way to do that was to write code. I still love building things, I‚Äôm just working at a higher abstraction now. It‚Äôs more code review for sure, but I‚Äôve always enjoyed reviewing code. I‚Äôm building faster and even cleaner than ever, frankly. My code is even more well tested. Is it ‚Äúeasy‚Äù? No, not at all. In fact, I would say I spend more mental energy now than I did in years past. I spend more mental energy thinking through requirements and crafting prompts to get what I want. I spend my time and energy setting up systems to act as guide rails and to help the agents do even more consistent and reliable work, quickly. In some ways, I have become a bit of a manager. ü§∑\n\nSpeaking of managers, that‚Äôs one role I‚Äôm worried for. Having used agents for my own side projects, they are more orderly and well planned than I‚Äôve ever had, even at work with the best managers I‚Äôve ever known. A few hours going back and forth with an LLM and I have a more concrete and clear plan with goals, user stories, acceptance criteria, and decision documentation than I have _ever_ seen a manager produce. Having just gone through quarterly planning for my team and all the meetings that involved, both with the ICs and the time spent before, it was several weeks of work. Our managers/directors spend about 6 weeks before the start of each half to plan, then another couple weeks with the ICs to plan and kick off the quarter. Frankly, almost all of that can be replaced with a handful of hours with an LLM, spread out over however many days as you‚Äôd like. Put bluntly, I‚Äôd be much more worried if I was middle management, and to a slightly lesser extent, direct IC level manager or team/tech lead. I think we‚Äôre on the cusp of seeing a massive contraction of management, where the managers who have put in the effort to learn to make AI agents work for them will replace managers who don‚Äôt. I think it will likely end up with a single manager with AI being able to do the job of 3-5 managers. I‚Äôm not even a manager (have been previously) and I‚Äôm confident I could run a few to a handful of small teams of engineers equipped with AI agents at all levels, and we would absolutely ship like no tomorrow.",
          "score": 5,
          "created_utc": "2026-02-12 15:55:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o518x7z",
          "author": "ZealousidealShoe7998",
          "text": "I stopped writing code and I started learning how can I make the product more useful and spend less resources.\n\nfor example, my focus now is more on making the UI better, adding meaninful features or optimizing user experience both on the frontend and backend.   \nover the weekend I could refactor and optimize projects that would take months when I used to code\n\n",
          "score": 2,
          "created_utc": "2026-02-12 19:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51l85v",
              "author": "Film4Sport",
              "text": "If you were building a desktop/mobile PWA for a tennis club which constraints, solid architecture, and strict rules would you provide it?\n\nAfter having issues building it out at the beginning I started again by planning a well structured codebase, ensuring tests were ran afterwards, adding to CLAUDE.md to avoid repeating mistakes, testing with Playwright before giving me results, and that's all I can think of for now. After enough changes I will ask it to rate it out of 10 from a senior devs perspective who is being critical yet honest, and then provide suggestions on how to improve it to get to 10/10\n\nI've done most of the frontend work, but I've learned the backend takes more time and is much more important and crucial the ensure data consistency, security, edge cases are tested, etc. so I'm hoping to get solid prompts to give it to help me make it production ready",
              "score": 0,
              "created_utc": "2026-02-12 20:27:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51sws4",
                  "author": "ZealousidealShoe7998",
                  "text": "try to think off how it's gonna be used.   \nA Tennis club could have like 1000 members or 10k members.  are the employees using it or the club members? \n\nI usually try to be flexible in the beginning , nothing is set on stone due to the fact that you can't foresee every single use case right away. if possible try to create somewhat of a micro service system. this will be a lot easier to upgrade certain parts when you figure out things better.  \n also add some stress tests into your workflow at the end and some performace/ refactoring .  \nfor example: i found one project was copying a file everytime a user did an action, but the user sometimes would not even use that file it was just playing around to see . that was creating unnecessary latency. instead I decided that when the user moves a file from spot A to Spot B, the file would only actually move if the user clicked the button to start the processing .   \nalso through the stress test I found out my DB approach  was slowing everything down. so research I found different solutions that didnt require a full refactor.\n\n here is how I approach my projects now.  \nI like to split [claude.md](http://claude.md) between the folders so it just gives enough information if claude is accessing that folder .\n\nFor bigger projects I like to have a research phase, as in, if i'm gonna implement a new feature I first write in a md file what are the things I wanna change or add, what are the things i need to know before I make a decision etc. then I chat with an agent just purely on research while I may be watching some videos about it too.\n\nonce My curiosity is satisfied and I feel like my choices are valid I then write tasks like stories in an agile style. but I use a agent to go through each story and write a task in a folder like /tasks where it provides what needs to be acomplished, what needs to happen, what files need to be touched etc. \n\nonce I have enough tasks and i'm out of ideas I just run the agents either by piping [task.md](http://task.md) into claude code or letting one agent orchestrate and send each md file to an agent to work on a worktree. \n\nonce that agent has done it, I spawn a new agent that will review it, run lints, builds etc. just basic stuff. if anything pops up it creates a review file for that task. so if a review file pops up a new agent has to access that file and work on it. \n\nthis process repeats until no review files are generated because once a agent work on it it has to remove it. \n\nusually by then either I have to check myself the work or I tell it to run through a cli command browser thing kinda like playwright but much more token efficient. (i use BDG which gives the llm access to the console.log and dev tools) \n\nat this point i usually do more manually  but you can either tell it to save the process in a bash script and create a review about it or check yourself. \n\nthe only reason I check myself  during this phase is because although LLMs are great at creating UI they sometimes get stuck on only one type of UI which might not be optimal for the user experience so I go through myself to make sure it feels right but this can be automated easily im just trying to learn and figure out thigns more in this aspect. \n\n\n\n",
                  "score": 1,
                  "created_utc": "2026-02-12 21:03:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o51ny44",
          "author": "SatoshiNotMe",
          "text": "The conversation needs to move on from whether people are writing code, to whether they are looking at it.",
          "score": 2,
          "created_utc": "2026-02-12 20:40:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53n0q9",
              "author": "WinOdd7962",
              "text": "No, not really. At least not with Opus 4.6. More and more the generated code works out of the box, the first time, no bugs. If theres any mistakes its due to a mis-prompt or issues putting the pieces together.",
              "score": 1,
              "created_utc": "2026-02-13 03:13:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o54k4xq",
          "author": "0x8FA",
          "text": "I think in 10 years the younger folks will be in awe of people having written entire codebases from scratch in the same way we are in awe of ‚Äúdid you know X was coded completely in assembly?‚Äù.\n\nBut on that same token, once higher level languages took over, it really leveled the playing field. It currently feels like we‚Äôre in that same sort of transition period between assembly and C, but the productivity gap will close as inevitably the assembly holdouts move to higher level languages.",
          "score": 2,
          "created_utc": "2026-02-13 07:23:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55nch3",
          "author": "Pleasant-Selection70",
          "text": "I write very little code these days, but I also have the advantage I think of a code base that has excellent patterns and is very very clean so I‚Äôve been fortunate enough that generally I can just point Claude to an example and say do it like that",
          "score": 2,
          "created_utc": "2026-02-13 12:58:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56s8ya",
          "author": "kknd1991",
          "text": "10+ experience. Vibe code first time few days ago, I am not going back. Now, it is mature enough to do advance implementation. The basic of architectural design and efficiency and maintainability I acquired throughout the years make me a much better VibeCoder. This feeling is not easily learn just by diving into Vibe coding without years of scars. Vibecoding or not, you still need to understand the code and know how to code it with or without AI. That will make you a great Vibe Coder, not just good Vibe Coder. ",
          "score": 2,
          "created_utc": "2026-02-13 16:29:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zr2bv",
          "author": "Optimal-Run-528",
          "text": "Yes, because I write complicated stuff that AI is too naive for writing properly if I try to vibecode. I have to narrow down the scope and ask for the implementation at function/class level, but I take the lead all the time.",
          "score": 3,
          "created_utc": "2026-02-12 15:15:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53neiz",
              "author": "WinOdd7962",
              "text": ">Yes, because I write complicated stuff that AI is too naive for writing properly if I try to vibecode. I have to narrow down the scope and ask for the implementation at function/class level, but I take the lead all the time.\n\nChange will be difficult for this mindset.",
              "score": 1,
              "created_utc": "2026-02-13 03:15:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55w0lc",
                  "author": "Optimal-Run-528",
                  "text": "I don't write rocket software or make Linux kernel but I'm pretty much convinced if you do something slighter more complex than vanilla websites with a neat relational model to back the persistence, it writes naive solutions. Every time I try to vibecode something slightly ambitious it just burns my tokens. If, however, I guide the AI with my own design and directions, it can do a pretty impressive job.\n\nI'll give an example. I vibecoded a script for looking up the nutrition facts of foods. So far so good, then I gave a meal and asked for alternative meals with same nutrition profile (calories, macros and fibers). It give me alterative meals with exact same calories but the other quantities (carbs, proteins, and fibers) didn't match pretty well. Then I suggested: \"Please use linear programming to make it as similar as possible\" and it replied \"Good idea\" then applied the technique I suggested and I obtained the result I wanted (it rebalanced the weights of the ingredients to get more precise match of the original meal). If I didn't know about linear programming in the first place it would never gave me the better solution.\n\n  \nI'm pretty much convinced the optimal results is using AI with as much human expertise involved as possible in the process. I don't see AI agents being able to create of the magnitude of Linux or PostgreSQL by itself any time soon, we are on the phase of the diminishing returns already, Anthropic just tried to create a C compiler (a well understood problem with lots of training data available), and it produced a mediocre one.",
                  "score": 1,
                  "created_utc": "2026-02-13 13:48:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zxsyv",
          "author": "duboispourlhiver",
          "text": "Thirty years ago I found it cool to write assembly code because you could often do things cleaner than the compiler.\n\nNow I write one or two lines of code per week, the rest is AI. I could write better code than the AI, most of the times, but that will change, like it did with compilers.\n\nI lost the battle for writing professional assembly code, and I'm not fighting the one to write professional code at all. It's a lost battle, sorry if your passion is to write code. You can keep writing code, but nobody's paying for that in the future.",
          "score": 4,
          "created_utc": "2026-02-12 15:48:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53npyi",
              "author": "WinOdd7962",
              "text": "Have you considered using AI to write assembly code? If none of us are manually coding anymore, does it really matter what language the AI uses? Or rather, the language choice is no longer constrained to human preference. ",
              "score": 2,
              "created_utc": "2026-02-13 03:17:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5489j1",
                  "author": "duboispourlhiver",
                  "text": "I haven't! But I know AI has been used to beat the best matrix multiplication algorithms in assembly.\n\nI wonder if we will design new AI first programming languages.",
                  "score": 1,
                  "created_utc": "2026-02-13 05:42:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zo46g",
          "author": "Fresh-Secretary6815",
          "text": "i thought all of us are seniors now since ai wiped out all the juniors üôÑ",
          "score": 2,
          "created_utc": "2026-02-12 15:00:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ztxcf",
          "author": "Affectionate_Top9368",
          "text": "I'm on a smaller team.  Claude is writing most of my code, and if I write it Claude is testing it.  We've pretty much let coding agents replace junior dev positions, which we no longer hire.  This is for a business with online and retail locations and between $100-$200m revenue that's been around about 20 years.",
          "score": 2,
          "created_utc": "2026-02-12 15:29:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516a92",
              "author": "ColeDeanShepherd",
              "text": "Your business is going to have a lot of fun finding replacements when the senior devs leave!",
              "score": 0,
              "created_utc": "2026-02-12 19:15:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51k5hp",
                  "author": "Affectionate_Top9368",
                  "text": "![gif](giphy|JnDGMrN8tMICc)\n\n",
                  "score": 1,
                  "created_utc": "2026-02-12 20:22:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5009ez",
          "author": "santaman123",
          "text": "Senior dev at a fortune 50 company here. 90% of my code is written by AI now, but don‚Äôt misconstrue that to mean the AI is doing my job for me. My role has shifted; now I spend more time writing fine-grained requirements & design decisions and feeding that to Claude. I‚Äôll detail not only the business requirements, but I‚Äôll flesh out how the architecture should be, general software design patterns to follow, edge cases it should be aware of, means of integrating with proprietary internal systems, etc. I feel more like an architect now rather than an engineer, but I am producing the output of both.\n\nAfter that, most of my time is spent reviewing & testing the code and making sure it aligns with what the business is asking for and that I‚Äôm not just pushing out ‚ÄúAI slop.‚Äù AI is allowing me to accelerate my work; tasks that used to take me 2 weeks now only take a few days.",
          "score": 2,
          "created_utc": "2026-02-12 15:59:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53nyas",
              "author": "WinOdd7962",
              "text": ">Senior dev at a fortune 50 company here.¬†\n\nWhats the layoff situation?",
              "score": 1,
              "created_utc": "2026-02-13 03:19:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o58ewh7",
                  "author": "santaman123",
                  "text": "Nowhere near as bad as other companies. In the last 5 years, my team of ~100 has seen maybe 3 people laid off, but we‚Äôre still hiring new folks for other positions (IC roles). Our team builds cybersecurity products, fwiw.",
                  "score": 1,
                  "created_utc": "2026-02-13 21:15:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o508kms",
          "author": "AI--Guy",
          "text": "There is a tsumani, and you either stay on the beach or grab a surf board ",
          "score": 2,
          "created_utc": "2026-02-12 16:38:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53od84",
              "author": "WinOdd7962",
              "text": "This. Adapt or die.",
              "score": 1,
              "created_utc": "2026-02-13 03:21:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54tt5b",
              "author": "loadmaster7",
              "text": "That's the worst analogy I've ever read üòÇ",
              "score": 1,
              "created_utc": "2026-02-13 08:53:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50ojud",
          "author": "whimsicaljess",
          "text": "i am a staff software engineer. 14 YoE. working as a founding engineer at a new startup right now. i also care a lot about quality and care deeply for the craft- i have spent a good chunk of my career in rust and haskell for example.\n\ni have not written any serious amount of code since early december 2025. between august and december i went from writing 80% of my code to writing 20%. before march 2025 i was writing 100% of my code. \n\ni have just built tooling to keep the agents in line with what i want to build, and as that tooling matures my ability to hand off coding has too. \n\nit's here. it's time.",
          "score": 2,
          "created_utc": "2026-02-12 17:53:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51mn8y",
              "author": "Film4Sport",
              "text": "If you were building a desktop/mobile PWA for a tennis club which constraints, solid architecture, and strict rules would you provide it?\n\nAfter having issues building it out at the beginning I started again by planning a well structured codebase, ensuring tests were ran afterwards, adding to CLAUDE.md to avoid repeating mistakes, testing with Playwright before giving me results, and that's all I can think of for now. After enough changes I will ask it to rate it out of 10 from a senior devs perspective who is being critical yet honest, and then provide suggestions on how to improve it to get to 10/10\n\nI've done most of the frontend work, but I've learned the backend takes more time and is much more important and crucial the ensure data consistency, security, edge cases are tested, etc. so I'm hoping to get solid prompts to give it to help me make it production ready",
              "score": 1,
              "created_utc": "2026-02-12 20:34:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51swb5",
                  "author": "whimsicaljess",
                  "text": "there is no replacement for taste. that is still the domain of humans. i don't write any code, but i am still super involved with reviewing the code for this- sometimes this means i actually review the code, sometimes it means im just testing outputs (often by having a second session or agent do the testing itself)\n\ni don't have suggestions for hard rules to give the agents for things like this but i think that saying \"from a senior dev's perspective\" or whatever is unlikely to yield useful results.",
                  "score": 1,
                  "created_utc": "2026-02-12 21:03:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50z508",
          "author": "teial",
          "text": "I still write all code by hand. I wish I could use AI but where I live access to all model from all providers is blocked (I'm in Russia). I don't know anyone who uses AI, and in most companies it is prohibited to use one.  I feel like I'm stuck in the past.",
          "score": 2,
          "created_utc": "2026-02-12 18:42:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53p62o",
              "author": "WinOdd7962",
              "text": "How'd you avoid the draft?",
              "score": 1,
              "created_utc": "2026-02-13 03:26:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53v32t",
                  "author": "teial",
                  "text": "I'm 42 and have no experience serving in the military. It is always the young that die first - I am simply not eligible for that \"honor\".",
                  "score": 1,
                  "created_utc": "2026-02-13 04:06:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zpipn",
          "author": "drhay53",
          "text": "Nope",
          "score": 1,
          "created_utc": "2026-02-12 15:08:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zrttp",
          "author": "ripviserion",
          "text": "nope. just reviewing, testing, and instructing. ",
          "score": 1,
          "created_utc": "2026-02-12 15:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ztj4s",
          "author": "EarEquivalent3929",
          "text": "Writing code is the least efficient use of time in your role.¬†",
          "score": 1,
          "created_utc": "2026-02-12 15:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zw9yy",
          "author": "nicoracarlo",
          "text": "I focus 90% of my efforts in  \n1. creating precise spec and validating the plan  \n2. waiting for implementation  \n3. validating the implementation.\n\nPS: I work on large monorepos with a clear architecture documentation that I feed to the AI.\n\nFrom code-writer to orchestrator",
          "score": 1,
          "created_utc": "2026-02-12 15:40:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zwx4h",
          "author": "HelpRespawnedAsDee",
          "text": "Some. But in the last year it has dropped considerably. I feel like the coding aspect is solved by now. The architectural level isn't yet, that requires a lot of back and forth (which i like anyways, it's like rubber ducking with a very powerful entity of sorts). \n\nAlso I feel I'm spending a lot of time automating the boring parts. Ex: connecting CC to read bug items, triage them, analyze them, make plans which I review by myself, then updating statuses automatically during the whole pipeline (triage, in progress, testing, building, QA, released, all that annoying stuff).\n\nBut I will have to say that even more than coding itself, my favorite part is documentation. I've been historically terrible at this. Nowadays CC writes most of spec docs, commits, etc. I still review and do runs to validate if the data is correct and up to date (sub agents and the new agent teams are great for this btw).",
          "score": 1,
          "created_utc": "2026-02-12 15:43:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zx3g8",
          "author": "neoanom",
          "text": "I think it's really hard to know. I think it's somewhere in between. I have colleagues who are all in on Agentic Coding with a great environment. The last two days they are trying to do some API design and hosted a mob programming session where they were writing code by hand to think about the interfaces and none of the logic. It was very interesting to see as a way to ideate without offloading all the thinking vs trying to prompt it. I think a lot of the logic will be AI Generated. But at least for now there is value in both. \n\nSide note: CNBC put out a report that a lot of youtube creators shilling claude, antigravitiy, codex etc are being paid A LOT Of money to promote their products. ",
          "score": 1,
          "created_utc": "2026-02-12 15:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zxpb2",
          "author": "gamechampion10",
          "text": "The real question is, how much code did you actually write pre LLM?   \nIf you are working at a company and you are building something new are you starting from complete scratch or using a starter kit? Are you hand writing the look and feel or using a library ? When you are dealing with a bug that is a hassle are you starting at your screen for hours or doing a google search to see if it was solved in the past? Even when working on things in the same repo or file, are you really typing all that much our or glancing up because you write conditionals all the time but always forget the exact way to order the arguments?\n\nMy point is, people tend to overestimate the amount of code they actually write. \n\nThat being said, at work I don't really write code anymore, I have it generated. But not all generated code is of high quality. You really have to be specific and know what you are doing. After fighting it for a long time thinking I needed to hand write everything, I realized I was wasting so much time at work and stressed out about things I didn't have to be stressed out about. Now I focus mostly on the problem and understanding what we are trying to do/build. I don't lose focus wondering how I'm going to solve it while at the same time zoning out in meetings not getting the full picture. \n\nWith LLMs I know that my main focus is now getting all the information I can, pushing back where needed, and completely understanding what I am trying to do. I create prompts not only with code repos but feature docs, slack or g chats, my own undersanding and all of that. \n\nI don't write code as much anymore, but I'm actually a much better and productive dev. I've been doing this for about 20 years, so I know what it takes to build things out and all of that. Maybe that helps. \n\n",
          "score": 1,
          "created_utc": "2026-02-12 15:47:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zxxj9",
          "author": "BustOutRob",
          "text": "I work primarily on very old React applications owned by a large company.  AI has done wonders for maintaining and migrating old code, but I still find that new feature work is a combination of AI and hand written code since it involves a lot of business logic.\n\nOverall I would estimate that 75% of our PRs are AI code, so our job has turned more into code reviewers as we make the final stamp on changes.",
          "score": 1,
          "created_utc": "2026-02-12 15:48:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zyrtl",
          "author": "Fun-Wrangler-810",
          "text": "I am in the middle phase. Still manually editing some code. CC writes the majority. V0 with  CC in the back delivered quite good code. Cursor with auto delivered rubbish. Talking about next.js, tailwind, shadcn. Has anyone used CC for Java and C# with a particular architecture like modular monolith, hexagonal, clean?",
          "score": 1,
          "created_utc": "2026-02-12 15:52:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zz28u",
          "author": "foreheadteeth",
          "text": "I'm a math prof but I used to be an engineer at NVidia in the 2000s. In the past year, I've stopped programming by hand, it's all Claude Code. It's a bit like having a workaholic PhD student. Sometimes it nails it, but you can sort of see in advance what it's going to screw up. If you watch it, you can also catch it before it bakes in some sort of unsalvageable disaster. Git is really important, and you sometimes have to guide it in writing tests or ensuring good code coverage.",
          "score": 1,
          "created_utc": "2026-02-12 15:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53o9nl",
              "author": "WinOdd7962",
              "text": "Generally curious what you're telling your students",
              "score": 1,
              "created_utc": "2026-02-13 03:21:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54xt45",
                  "author": "foreheadteeth",
                  "text": "About what, AI? I'm not sure I've got anything useful to tell them. The AI can probably write all our final exams for all our classes. It can also do the programming homework. But as long as people keep showing up in our classrooms, we're going to keep teaching? I dunno if that's what you're asking.",
                  "score": 1,
                  "created_utc": "2026-02-13 09:31:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zzz88",
          "author": "Downtown-Baby-8820",
          "text": "My opinion I think this is the path we are really heading on, Software Engineers don't just write code, They solve problems right I always hear that haha, The new thing now is if you can create your own ai development workflow or fine-tune a oretrained model implement ai agentic system",
          "score": 1,
          "created_utc": "2026-02-12 15:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5000sv",
          "author": "JUSTICE_SALTIE",
          "text": "I am approximately you. I've had a pretty drastic and recent shift away from writing code manually, coinciding with my upgrade to the Max plan and exclusive use of Opus. I used to constantly have to steer it away from misguided approaches like code duplication and (especially!!) overzealous error handling, but lately all that has just smoothed out completely, and I feel fine accepting most of what is produced.\n\nI am definitely feeling that sense of slowdown and inefficiency whenever I type code in the IDE.",
          "score": 1,
          "created_utc": "2026-02-12 15:58:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5007rl",
          "author": "Destroyer-128",
          "text": "Nope lost all interest. I should just wait for the model which will one shot all my ideas and then i will write code.",
          "score": 1,
          "created_utc": "2026-02-12 15:59:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o501k8m",
          "author": "DryImpression7385",
          "text": "r/cscareerquestions is going to have far better answers",
          "score": 1,
          "created_utc": "2026-02-12 16:05:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53pmpg",
              "author": "WinOdd7962",
              "text": "They ban you for AI posts. ",
              "score": 1,
              "created_utc": "2026-02-13 03:29:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5039os",
          "author": "jsonmeta",
          "text": "I‚Äôve been in tech for about 15 years, jumping between embedded systems, backend, frontend, apps, and everything in between. I‚Äôve never really specialized in just one area, which has its ups and downs. One thing I‚Äôve always struggled with is remembering all the syntax and interfaces for every language or library I‚Äôve used.\n\nWhen I first started using AI and agentic tools, I felt a bit like an imposter. But then I realized that even before these tools, I was rarely just writing code from memory. I was always looking up docs, checking StackOverflow, or finding examples to adapt to whatever problem I was working on. For me, it was never about typing everything perfectly from scratch. It was about understanding the problem and solving it the best way I could, while applying the good practices I‚Äôve picked up over the years. These tools have been a huge help. They save me so much time, so I can focus more on designing solutions to whatever problem I have.",
          "score": 1,
          "created_utc": "2026-02-12 16:13:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o503hmw",
          "author": "elmahk",
          "text": "I almost don't write code anymore, but I review code a lot instead. Quality is good enough for me, not worse than I myself would write. I'm not perfectionist though, getting things actually done is more important for me.",
          "score": 1,
          "created_utc": "2026-02-12 16:14:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5063sv",
          "author": "apoetsanon",
          "text": "I'm mostly letting AI write the code, but I spend a considerable amount of time writing a pipeline of agents to ensure a robust architecture, reusable and maintainable design patterns, and readable code. If you let AI do its own thing, it will write slop. But you can guide it to write well architected and maintainable code. I will often ask it to rewrite something and then make sure it remembers the pattern in the future by writing it down. I have a whole folder structure devoted to AI generated research, plans, documentation, and memories. With Claude able to reference those, it has gotten much better at writing code at a senior level.\n\nAI can write good code, but it's not cheap. I use at least 2-4 times the tokens it would take if I let AI do its own thing. I'd complain but...this is basically true of developers as well.  Good code isn't cheap and likely never will be. \n\n(Note: I also have around twenty years of experience)",
          "score": 1,
          "created_utc": "2026-02-12 16:26:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o506spb",
          "author": "organic",
          "text": "I thoroughly review the code and make edits/suggest edits (whichever is faster); sometimes I do pure vibes for side projects but even then I'm pretty strict on style guidelines",
          "score": 1,
          "created_utc": "2026-02-12 16:29:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5075z6",
          "author": "mokv",
          "text": "8 years of experience here. I haven‚Äôt written code myself in 1 year. I feel like if I write code, I am doing something wrong because I don‚Äôt utilise AI good enough. Of course everything I write I own and double check myself. There isn‚Äôt a single commit I haven‚Äôt walked through the code myself.\nLike others mentioned, it‚Äôs just another layer on top. Assembly became intermediate language, then there were high level languages like C#, now it‚Äôs plain english. Would you learn Assembly now? Why would you? It‚Äôs a tool like any other and you can either live in the past or move to the future.",
          "score": 1,
          "created_utc": "2026-02-12 16:31:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o507fx6",
          "author": "ProgrammerOnAFarm",
          "text": "I use CC almost daily, and I don‚Äôt feel it is saving me much time‚Ä¶ yet. As others have said, this is a matter of me needing to get better at prompting, planning and the workflow in general. It‚Äôs a nice supplement so far, but definitely not a replacement.",
          "score": 1,
          "created_utc": "2026-02-12 16:32:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5087ag",
          "author": "Radiant-Chipmunk-239",
          "text": "only for archaic interview processes.",
          "score": 1,
          "created_utc": "2026-02-12 16:36:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50a7f7",
          "author": "cannontd",
          "text": "Our company has enabled access to models via bedrock with zero limits. We don‚Äôt even use the anthropic plans. It‚Äôs enormously expensive. We aren‚Äôt trying to be the best or most efficient, we‚Äôre just trying to make sure we‚Äôre not LAST.",
          "score": 1,
          "created_utc": "2026-02-12 16:45:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50bisy",
          "author": "tayoutai",
          "text": "Without dismissing the rest of your view, I think the assembly line comment is exactly the opposite. Writing your own code is 'artisan' while Claude code is the assembly line. The assembly line is faster and more efficient but we'll have to accept we're assembly line workers now.",
          "score": 1,
          "created_utc": "2026-02-12 16:51:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50dpj3",
          "author": "ChanceEngineering858",
          "text": "No.",
          "score": 1,
          "created_utc": "2026-02-12 17:01:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50e6jz",
          "author": "Tema_Art_7777",
          "text": "I am writing 0 code now - spending my entire time as a product manager with strong SWE skills to direct AI.",
          "score": 1,
          "created_utc": "2026-02-12 17:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50lavs",
          "author": "lalo2302",
          "text": "Even before Claude Code the more senior you get the less you code. Your job becomes planning, document decisions, meetings. Your goal is to have a higher impact and often that means been a multiplier. You can take the path of being a major contributor, create libraries that others use to work with, or plan, architect and organize engineers using your deep technical knowledge. The latter is where Claude Code shines.All of that planning, designing and thinking can now be done by an agent. Probably not production ready but definitely good enough for quick prototyping. ",
          "score": 1,
          "created_utc": "2026-02-12 17:37:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50mdpx",
          "author": "paca-vaca",
          "text": "I do. Because I like it :)\n\nFor new code I prompt and it is easy to start. Same for specs for existing code, but Claude tends to test implementation including private methods so it requires oversight.\nBut for existing code, it's less effective unless it's clearly defined refactoring. I hate spending minutes trying to describe a particular change in my mind, waiting for \"wiggling and bulping\" while it could be done quickly manually.\n\nAlso, we have a classic enterprise size distributive monolith, so Claude has no idea of side effects outside of the service it's currently working in. So, it requires multiple prompts and proper coordination which sometimes is just easier to do manually with a split screen. \n\nAlso, unless company pays it's quite expensive.\n\nBut we are getting there :)",
          "score": 1,
          "created_utc": "2026-02-12 17:43:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50nnmo",
          "author": "coldoven",
          "text": "Do I write code? Yes, where I work. On my own stuff? No. Where am I more productive? On my own stuff.",
          "score": 1,
          "created_utc": "2026-02-12 17:49:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50oq2k",
          "author": "nesh34",
          "text": "Our internal tools tracks the percentage of code written by AI vs human. I'm at 40% AI average of the last 3 months.",
          "score": 1,
          "created_utc": "2026-02-12 17:53:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50ru9a",
          "author": "Vicar_of_Wibbly",
          "text": "My buddy said ‚Äúif you‚Äôre still typing all your code, you‚Äôre a dinosaur‚Äù and that about sums it up.",
          "score": 1,
          "created_utc": "2026-02-12 18:08:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50u578",
          "author": "Vaviloff",
          "text": "OP, please keep in mind that asking here will overwhelmingly get you answers like \"we write >80% of our code with Claude\", and that's fair. If you want to test the real adoption rates, you should go to your thematic subreddit of choice.",
          "score": 1,
          "created_utc": "2026-02-12 18:18:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50u7ki",
          "author": "OnRedditAtWorkRN",
          "text": "I've been on this whole agentic coding journey for a while now. I've gone back and forth on it like a pendulum. I'm fortunate enough that my company invested in the tools, I'm literally spending $1000+ a month on my claude code usage, paid for by the company and my leaders have expressed explicitly that I should continue to use it heavily. Which makes sense, my time ain't cheap, so if $1000 gets me at least a 20% productivity boost that's a solid ROI\n\nHistorically I've had a really high bar for code quality. My colleagues would probably tell you I was the most critical on pr feedback. I don't come at it from a purely intellectual perspective and suggest frivolous changes, but rather I've been on calls at 3am and had to be able to quickly understand a system that was foreign to me, debug and apply a fix. So if I look at your code and can't quickly figure out what the fuck you're trying to do, it doesn't meet the bar. Code comments should always tell me why, code should be self explanatory as to the what or how. Full stop.\n\nNow as for today. I've lightened up quite a bit on my review process and quality bar, because through that same lens I've created skills and processes using AI to achieve the same goal. Literally just this week I had to debug an issue with a container that was crashlooping and it was a pita to get what I needed to debug before it crashed. I used Claude code to help stand up a side car to the container in minutes, grab a heap dump, then read the heap dump and help find most likely causes. Faster than I ever couldve reading code or logs or anything by hand we narrowed it down to a problem with the ORM's (I fucking hate ORM's for this reason) default query behavior.\n\nNow where I struggle a bit is if we say okay, we have the problem solved then, now that makes Claude a critical cog in our infrastructure and ability to maintain it. I'm not sure that's the best. But right now, it works great in a real production environment. I still read code myself. I still drop feedback. But I let a lot more go than I would've before and I leverage a combination of anthropic's pr review skill plus some homebrewed skills to help find the gaps. I've been shipping more code than before. It's almost exclusively AI generated and I don't bother with looking at the diffs until I've manually tested it and put it up as a draft pr. Then I self review, both with my eyes and the aforementioned ai review skills. Then I ping my team when I'm ready.\n\nI still try to keep PR sizes reasonable though. If I get around anywhere above a few hundred LOC, not including codegen or tests, I try to reign it in and have blocked more than 1 or as not reviewable due to size.",
          "score": 1,
          "created_utc": "2026-02-12 18:19:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o511yxw",
          "author": "Intelligent_Deer_525",
          "text": "To be honest, not much. By setting up the skills, and big context explanation to CC, this thing generates great code, the amount of bugs have reduced and the delivery speed in our teams has increased massively.",
          "score": 1,
          "created_utc": "2026-02-12 18:55:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o514i3e",
          "author": "ProperBritish",
          "text": "Probably 75-80% of my code is generated. A lot of the project I'm on is a greenfield rewrite of what we already have with new standards in place, so I'm having to fight the AI not to recreate some of the problems we are trying to get rid of.\n\nIt's quite sad but we are the ones with the blessing to write or generate code but ALSO actually know what it's doing without that help.",
          "score": 1,
          "created_utc": "2026-02-12 19:07:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o514smn",
          "author": "antonlvovych",
          "text": "Are we stupid or what? Of course we don‚Äôt",
          "score": 1,
          "created_utc": "2026-02-12 19:08:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o514t4c",
          "author": "FoxyBrotha",
          "text": "As a level above Senior at a Fortune 500, I write less code than I did when I was a Senior engineer. When I do code, about 80% of it is AI generated and I mostly review, refine, and integrate it. The other 20% I write myself, usually when the agent is struggling or when it‚Äôs faster to just do it than spend time crafting a prompt.\n\nThat said, I work with plenty of teams that still don‚Äôt use any AI in their development workflow. With the exception of automation testing, that is purely AI generated in every team everywhere.",
          "score": 1,
          "created_utc": "2026-02-12 19:08:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53oosq",
              "author": "WinOdd7962",
              "text": ">As a level above Senior at a Fortune 500, I write less code than I did when I was a Senior engineer. When I do code, about 80% of it is AI generated and I mostly review, refine, and integrate it.¬†\n\nWhats the layoff situation?",
              "score": 1,
              "created_utc": "2026-02-13 03:23:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53rm8j",
                  "author": "FoxyBrotha",
                  "text": "Non existent. We took the opportunity to just increase our output and hit our targets quicker.",
                  "score": 1,
                  "created_utc": "2026-02-13 03:42:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o515p5k",
          "author": "kosiarska",
          "text": "NUTS!",
          "score": 1,
          "created_utc": "2026-02-12 19:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5161sl",
          "author": "Realistic_Local5220",
          "text": "The thing is that, while Claude doesn‚Äôt always build the ideal solution, it is faster to build it non-optimal and fix it than it is to try to make it optimal the first time. Most of the habits you learn as a senior developer around careful planning to reduce risk of wasted development time are obsolete. Development cycles are so quick that (hours or days instead of weeks or months), that the consequences of failure and wasted time are typically less severe than the consequences of being too cautious. It‚Äôs a whole new world.",
          "score": 1,
          "created_utc": "2026-02-12 19:14:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51a4e2",
          "author": "New_Goat_1342",
          "text": "I don‚Äôt think we could ever just let it run and hope for the best. We definitely use it as a precision tool; User Story by User story. It is very useful to have Claude go through the feature design and help split it up but any more that a User Story under supervision then things will drift.\n\nIt is also highly dependent on the state of the code base your working on, if it‚Äôs already following clean design, clear patterns and it‚Äôs well documented then setting up the Claude.md is painless. If it‚Äôs carry a lot of Tech Debt, mixed patterns, unfinished refactoring then it can tell a while to establish the ground rules.\n\nIn general though it‚Äôs code review and guidance at the prompts.¬†\n\nI even asked it to ‚Äúproperly‚Äù add cancellation tokens and determine race conditions etc and it was infinitely faster and better at tracing all the paths than human devs. But; we still checked it all!",
          "score": 1,
          "created_utc": "2026-02-12 19:34:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51azdu",
          "author": "dasookwat",
          "text": "as an infrastructure engineer, i used to write code and scripts for pretty much everything.  But now i write concepts in pseudocode I noticed you get a lot better results from the llm's if you give them more details. ONe of the things i like about ai coding is:  they type faster than me.  If i tell the llm what i want in details, it will write it for me rather well. However, it misses obvious design solutions.  So i use it for what it's good at:  writing functions and classes, and i decide what i need. ",
          "score": 1,
          "created_utc": "2026-02-12 19:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51gnp4",
          "author": "ratttertintattertins",
          "text": "Tech lead here, approximagely 95% of my code is written by claude.  Although not exactly in a vibe coding way.  I read code constantly and my instructions are extremely specific and my PRs are very focused.\n\nI essentially own the code and get it exactly as I want it.",
          "score": 1,
          "created_utc": "2026-02-12 20:05:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51l1ek",
              "author": "Film4Sport",
              "text": "If you were building a desktop/mobile PWA for a tennis club which constraints, solid architecture, and strict rules would you provide it?\n\nAfter having issues building it out at the beginning I started again by planning a well structured codebase, ensuring tests were ran afterwards, adding to CLAUDE.md to avoid repeating mistakes, testing with Playwright before giving me results, and that's all I can think of for now. After enough changes I will ask it to rate it out of 10 from a senior devs perspective who is being critical yet honest, and then provide suggestions on how to improve it to get to 10/10\n\nI've done most of the frontend work, but I've learned the backend takes more time and is much more important and crucial the ensure data consistency, security, edge cases are tested, etc. so I'm hoping to get solid prompts to give it to help me make it production ready",
              "score": 1,
              "created_utc": "2026-02-12 20:26:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51h90f",
          "author": "cointoss3",
          "text": "I have written almost zero code in months now. It‚Äôs sad but also nice.",
          "score": 1,
          "created_utc": "2026-02-12 20:08:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51hawd",
          "author": "e3e6",
          "text": "software development is about profit, not code. And im currently working on a legacy where you cannot feed the entire codebase to AI",
          "score": 1,
          "created_utc": "2026-02-12 20:08:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51hso1",
          "author": "snowboardlasers",
          "text": "I probably outsource 60-70% of my work to AI.\nI tend not to give it abstract prompts, I ask for specific targeted changes - and it's very good this way. I can review small changes as I go and ultimately end up with clean code that may have taken days to write and test, in a few hours.\n\nThe key is small and very specific changes, with review and I've also found it's much better if you put in a test framework.\n\nIt's also very good at code scanning, gathering context and explaining legacy code.\n\nI've probably been 4-5x more productive as a result of using it.",
          "score": 1,
          "created_utc": "2026-02-12 20:11:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51kwvu",
              "author": "Film4Sport",
              "text": "What kinda test frameworks do you have? Regression, edge cases, chaos, Playwright? I'm learning tests are important, but then getting overwhelmed at how many there are and which one is most important",
              "score": 1,
              "created_utc": "2026-02-12 20:26:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51m6jk",
                  "author": "snowboardlasers",
                  "text": "It depends what you're building. Typically I try to at least have unit tests for each function block. The vast majority of my code is Golang which has its own testing framework built in, with some code in C which I use ceedling.\n\nYou absolutely should be doing:\n- Unit tests\n- Fuzzing\n- Functional tests (e2e)\n\nAnything else is a nice to have.",
                  "score": 2,
                  "created_utc": "2026-02-12 20:32:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o51jgut",
          "author": "Only-Ad6170",
          "text": "I work at a fin-tech startup that's doing well. Same deal, we are being pushed to be code review machines for the code that the bot writes. I've spent like the last month more-so honing my LLM interaction game than my coding game. I don't love it, I've always loved writing code, but hey, it's the job and I do what they tell me. I've heard mixed things from my friends in the industry though. I have friends at F500s whose companies only give out LLM licenses \"as needed\" so never. ",
          "score": 1,
          "created_utc": "2026-02-12 20:19:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51lj5u",
          "author": "StandardStud2020",
          "text": "Yeah, sometimes I do it just for fun. Or when I‚Äôm feeling a bit worn out from asking AI and just want to get straight to the point and fix what I need.",
          "score": 1,
          "created_utc": "2026-02-12 20:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51pbxn",
          "author": "softwareguy74",
          "text": "Nope.  Stopped writing code after finding Claude for the first time and haven't looked back since.",
          "score": 1,
          "created_utc": "2026-02-12 20:47:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51rrv6",
          "author": "imcguyver",
          "text": "Mostly no when it comes to tightly coupled AI systems. Then yes for some systems where there is no realistic interface to leverage AI.",
          "score": 1,
          "created_utc": "2026-02-12 20:58:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51si9q",
          "author": "killagoose",
          "text": "I haven't written a single line of code since October. Everything I have put out since then has been AI generated. I give it explicit instructions, I'm still engineering the feature.\n\nProblem Statement\n\nIdea to solve it\n\nConstraints\n\nPlan Mode\n\n  \nI look over the plan, make changes and let Claude Code go to work. Then, I look over the code, note things that I don't like, and give those to Claude Code to fix.\n\nRinse and repeat. Has worked great for me.",
          "score": 1,
          "created_utc": "2026-02-12 21:02:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51ufs7",
          "author": "Sottti",
          "text": "Big tech here. Agentic programming is real. Usually I work on 2-4 parallel branches. The output is crazy. I'd say some days I can do what before would be 5 days of work. Took me a few years to get here and went through all phases of AI usage. I'm not bullish on AI.\n\nBut not just creating code. All Jira issues are created and updated by AI. All PRs are created by AI. The quality of PR descriptions and Jira specs is at an all-time high.\n\nPR reviews are made by AI, and PR comment replies the same. AI is so good and so fast at doing this that it's incredible. Opening four-chained PRs now takes one minute, so PR sizes are decreasing and reviews getting easier \n\nThinking about doing all of this like in the old days feels such a waste. It takes time and effort to learn how to work this way, but oh boy, it's worth it.",
          "score": 1,
          "created_utc": "2026-02-12 21:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51xp2k",
          "author": "publicclassobject",
          "text": "14 YOE. I don‚Äôt write code anymore but that doesn‚Äôt mean Claude one shots everything either. It‚Äôs a lot of iteration and feedback with the agent. I can get an incredible amount of work done this way tho",
          "score": 1,
          "created_utc": "2026-02-12 21:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51xtu2",
          "author": "Ambrosios89",
          "text": "I'm new to this level of AI leveraging, but I believe it's far less marketing fluff than I'd hoped it was.\n\nBut there is a learning curve involved to getting it to ACTUALLY do what you're expectations are.\n\nHere are some of my helpful tips for what has started me on the path of understanding HOW these companies are doing it.\n\nUser and project level configuration:\nThere are some user-level instructions you can define about how you like things, this can help initially, but eventually becomes bloat (IMHumbleO). Style guides, references to MISRA. However, it's better to break up a task instead to allow for more efficient context overhead.\n\nPlanning code:\nA long time ago I learned the trick \"Tell AI what you want, but ask it to review what you want, ask questions about it, and generate a prompt for you. Feed THAT prompt back into AI). Claude can do this automatically to some degree, but the obra-superpowers plugin gives you commands like /brainstorm /write-plan and /implement-plan. These commands walk you through the entire process of idea to implementation. This greatly helps the quality of output and adherence to the goals.\n\n\nCorrecting code:\nHave two more separate agents to then perform a review of \"Does this satisfy the logical requirements of the feature\" and \"Does this code meet my standards according to a custom standards skill\"\nI had Claude generate three commands/skills for me.\n/Review-branch \"Does this code do what the original goal was and does it align with the repo\"\n/Review-standards \"Does this code comply with MISRA standards? Does it use conventional like YODA or always bracing control structures?\"\n/Review-all \"How shitty is the codebase origin/main currently?\"\n\n\nIt's not currently a drop-in expert to your standards, but in less than a week I've been able to tweak and play with things to the point that it's pretty dang close.\n\nEdit: I'm 10 years deep in safety-critical embedded systems.",
          "score": 1,
          "created_utc": "2026-02-12 21:27:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51y6or",
          "author": "kahi",
          "text": "CTO/Lead Developer at a startup. I'm probably 60% writing docs to have AI code, 40% doing shit myself/fixing AI code because I'm still faster/can do while waiting for the next output to review. The company I left for my current role, I was 75% fixing shitty AI code from junior developers who were never properly mentored and couldn't explain a single line of code AI outputted, and some seniors, and 25% wanting to blow my brains out. ",
          "score": 1,
          "created_utc": "2026-02-12 21:28:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51z2yu",
          "author": "CallinCthulhu",
          "text": "Senior eng at Meta. And nope. It takes a lot of structure and intenful planning planning to keep the slop out. But once you have that, you jest let the agent do its thing.",
          "score": 1,
          "created_utc": "2026-02-12 21:33:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o528uu4",
          "author": "CEBarnes",
          "text": "I was one of Elon‚Äôs Doge causalities. The biggest tragedy was losing the fruits of my labor. I literally can‚Äôt show anyone what I‚Äôve done for the past 13 years at work.\n\nSo, I started a new project based on a gigantic medical specification with a bazillion exceptions and edge cases. Everyone before me has done some stuff, it got hard, so they wrote an academic paper and bailed. AI was a huge lift. I couldn‚Äôt have built the data parser‚Äôs in 6 months without out it. \n\nI haven‚Äôt had an issue with Claude creating devastating bugs. I keep things loosely coupled, and concerns well separated. One thing breaks, the loss is logged, and everything else just goes about its business. \n\nThe big downside is that Claude loves a God method. Pretty much everything requires a refactoring into smaller private methods. And, if you don‚Äôt stay on top of it, your code will get soggy wet.",
          "score": 1,
          "created_utc": "2026-02-12 22:20:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52a8cx",
          "author": "ultrathink-art",
          "text": "Still writing plenty of code, but the ratio shifted. Less boilerplate CRUD, more architectural decisions expressed in code. AI handles the \"write another controller that does X\" work‚ÄîI review and ship. More time on: cache invalidation strategies, query optimization, API contract design, error boundary placement. The leverage is real: what used to take 3 PRs over 2 days now happens in one session. But you have to know what good looks like to review effectively. Junior devs pairing with AI worry me more than seniors using it as a force multiplier.",
          "score": 1,
          "created_utc": "2026-02-12 22:27:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52bnzv",
          "author": "Budget-Length2666",
          "text": "I write about 80-90% with agents. I am on a platform team and we used to create code mods and run incremental migrations all over an 8M lines of code repo. We used to create instructions and make the migration process as deterministic and simple step-by-step as possible and handed that to a team of vendors that are very junior and they simply executed over and over again. Now I am just one senior engineer and I can spin up tons of agents doing the migrations - the bottleneck is still PR reviews and babysitting PRs. However it reduced the overhead as the vendors needed lots of handholding.",
          "score": 1,
          "created_utc": "2026-02-12 22:34:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52cbgu",
          "author": "Humprdink",
          "text": "Yes",
          "score": 1,
          "created_utc": "2026-02-12 22:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52fscw",
          "author": "round_hill",
          "text": "I wrote one line yesterday... first one in about 3 months straight. Our way of life is rapidly changing!",
          "score": 1,
          "created_utc": "2026-02-12 22:56:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52nbrw",
          "author": "MarkstarRed",
          "text": "I'm a solo developer that has to deal with all aspects of the business: C++ for the algorithm (quite intensive), UI (Electron), website (PHP, SQL, etc.). Since the algorithm is completely new and has to be highly optimized, LLMs are basically no help to me except code completion for repetitive tasks. However, they are great for most of the front-end stuff (especially since design is not my strong suit), as well as turning function declarations and UI elements into manual/reference pages on the website. \n\nSo while the LLMs are great and have made many cumbersome tasks easier (as well as allowing me to just vibe code some small side projects that I wanted to do but never took the time to do), the progress of them has been rather disappointing, so much so that I am confident that they will not replace an experience programmer who is working on something new in the near future. ",
          "score": 1,
          "created_utc": "2026-02-12 23:38:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52prfy",
          "author": "Nearby-Middle-8991",
          "text": "I'm an IC in a tech-adjacent company. I don't write code, I \\_tweak\\_ and fix code. Claude nails the boilerplate code, I can't be bothered to remember language/framework syntax, but I know how stuff breaks, I know good coding patterns. So my job there is rescue claude when it gets stuck and make sure it does a decent job.\n\nThat's why I call it \"the intern\"...\n\n",
          "score": 1,
          "created_utc": "2026-02-12 23:52:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52pzfx",
          "author": "ghost_operative",
          "text": "Yes i write code still, my development environment just has different tools in it.",
          "score": 1,
          "created_utc": "2026-02-12 23:54:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52qkwi",
          "author": "Djoley",
          "text": "nope",
          "score": 1,
          "created_utc": "2026-02-12 23:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52w35b",
          "author": "NoMinute3572",
          "text": "TLDR: Not really.  \n  \nAlthough, if you think about it, we're still writing code but in a more natural way. Specially if you know the techs you're working with.  \nNow we can spend more time being real systems engineers, developing for others humans and having more free time... to think things properly. How can we help the real world more and make things more intuitive.  \n",
          "score": 1,
          "created_utc": "2026-02-13 00:29:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52x0u9",
          "author": "_69pi",
          "text": "no.",
          "score": 1,
          "created_utc": "2026-02-13 00:34:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o530dhw",
          "author": "Techine",
          "text": "I work for a big tech, unlimited tokens both CC and Codex, I don‚Äôt write code anymore.",
          "score": 1,
          "created_utc": "2026-02-13 00:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o531ksu",
          "author": "Due_Temperature1319",
          "text": "Earlier today, I was describing our current state of events to a good friend, genius programmer (and chessmaster), who plans to retire by he end of this year. He is my former coworker and a long time contractor in my consulting business. As I was describing the way our small team uses CC and openclaw, he kept saying two words: \"science fiction\". All engineers are given a magic wand , so if you use the wand to review the code you write by hand  - its on you, and there is no shame to it. But if you want to rip - go full throttle and trust CC, Opus 4.5-6 are that good. \n\nAs said Pedro from Napoleon Dynamite:\n\n \"If you vote for me, all of your wildest dreams will come true\"\n\nWe should take full advantage and enjoy it before humans are placed in their zoo sections by robots. Because that thing is surely coming .\n\nPS we use CC 100% of the time. Everyone including sales team has agents. I write code since 1988, so it is 1988-2025. 2026 is the new Era.",
          "score": 1,
          "created_utc": "2026-02-13 01:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o535iu5",
          "author": "andlewis",
          "text": "What‚Äôs code?",
          "score": 1,
          "created_utc": "2026-02-13 01:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53b8xa",
          "author": "natesyourmom",
          "text": "Lead mobile dev at a startup, 10 YOE. Claude writes about 90%+ of my code these days. I am very careful about explaining my requirements, and always thoroughly review plans/generated code. It's a large codebase but I actually wrote the bulk of it by hand before the AI coding boom, so there's some solid patterns and structure for AI to leverage when integrating with existing code.\n\nThat being said if anyone reads this and can suggest a way to level up my AI coding game, I'd love to hear it. Currently use Cursor with Opus 4.6, plan mode for features/changes, debug mode for bug fixes. I haven't really gotten into skills, simultaneous agents, etc. Would love any recommendations on what to try next. Been looking into superpowers as a potential angle.",
          "score": 1,
          "created_utc": "2026-02-13 02:00:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53bgds",
          "author": "syafiqq555",
          "text": "Nope, i do 4-5 projects at once including sidejob, no more coding w hands",
          "score": 1,
          "created_utc": "2026-02-13 02:01:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53h8q9",
          "author": "axiemeaxieu",
          "text": "You asked here? You get slop.",
          "score": 1,
          "created_utc": "2026-02-13 02:37:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53jufe",
          "author": "lith_paladin",
          "text": "I'd say I am a pretty decent engineer, usually find jobs pretty easily, survived the great culling of job cuts in 2023. \n\nI am not writing code anymore. I'd say 5% at max? That too changing stuff that Claude wrote here and there.",
          "score": 1,
          "created_utc": "2026-02-13 02:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53k3k5",
          "author": "WinOdd7962",
          "text": "So many of you are missing the forest through the trees. You're not writing code anymore, your function consists of orchestrating and reviewing code. GREAT.\n\nWe've got to this point in *years*. In the same timescale, the majority of people in this thread won't be needed anymore, like at all. We're barreling toward a future where a few leadership people get in a room - engineering, product, design, business - voice chatting with an AI on speaker. Picture them in a conference room talking to the AI about what they want and watching it built on the large screen in real time.\n\nIn the last Meta earnings call Zuckerberg spoke about a \"single, very talented person\" doing the work of a whole team. Is that person going to be you? Unlikely. Those positions are going to be so incredibly difficult to get. You can bet the farm they'll be gatekeeped to people with Ivy degrees or nepo hires.",
          "score": 1,
          "created_utc": "2026-02-13 02:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53sc4h",
          "author": "heyhodadio",
          "text": "No",
          "score": 1,
          "created_utc": "2026-02-13 03:47:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53tcq2",
          "author": "pra__bhu",
          "text": "14 years here, full stack. short answer ‚Äî yes i still write code, but the ratio has shifted hard.\nfor me it breaks down by task type. boilerplate, crud ops, utility scripts, test scaffolding ‚Äî ai handles like 80% of that now and i just review and tweak. that part genuinely feels like the assembly line comparison is fair.\nbut the stuff that actually matters ‚Äî system design decisions, data modeling, debugging weird edge cases in production, writing code that has to integrate with 5 different apis with their own quirks ‚Äî ai is a decent starting point but i‚Äôm rewriting a lot of it. especially anything touching money or auth, i trust my own code more.\nthe ‚Äújust reviewing agent code‚Äù thing is real at some companies but imo it‚Äôs a bit overhyped right now. the people saying that are mostly working on greenfield projects or internal tools. maintaining a complex legacy system with years of business logic baked in? ai still chokes on that regularly.\nbiggest shift for me isn‚Äôt writing less code ‚Äî it‚Äôs that prompting well is basically a new skill on top of everything else. the engineers who‚Äôll thrive are the ones who know enough to catch when ai gives them something subtly wrong. which ironically requires being good at writing code the old way first.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 1,
          "created_utc": "2026-02-13 03:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53tifn",
          "author": "dandecode",
          "text": "18 years exp, big company. Its true. I don‚Äôt write much myself anymore. Maybe 100 lines a week. The better I know my tech and can prompt and review correctly, the less code I‚Äôve had to write. Prompt to create the plan first. Review and ask questions about the plan. Prompt it to update pieces until you‚Äôre both in agreement. Then prompt it to implement the plan. Then review, prompt it to update pieces until you‚Äôre both in agreement. Prompt it to add tests. Review, and then prompt it to update‚Ä¶.",
          "score": 1,
          "created_utc": "2026-02-13 03:55:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53tlxh",
          "author": "gordinmitya",
          "text": "for me it changed about 3 months ago with Opus 4.5 release\nnow it‚Äôs much productive for me to review and decline code several times than write it from scratch",
          "score": 1,
          "created_utc": "2026-02-13 03:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53wcxn",
          "author": "aviboy2006",
          "text": "Still writing code but the ratio has shifted dramatically. My workflow is now I describe the architecture and constraints upfront (API contracts, error handling patterns, compliance requirements), let Claude Code generate the implementation, then spend most of my time reviewing what it produced. The thinking and steering part is now 70% of my job instead of maybe 30%. Where I still write code by hand: anything touching patient data flows, complex state machines, and performance-critical paths where I know the exact tradeoffs I want. AI gets the CRUD and boilerplate. The skill that matters most now isn't typing speed it's knowing what good looks like so you can catch when the agent gets it wrong. Your 20 years of pattern recognition is more valuable than ever, not less. The engineers I worry about aren't the ones who still write code  and they're the ones who accept AI output without the experience to evaluate it.",
          "score": 1,
          "created_utc": "2026-02-13 04:15:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53wowq",
          "author": "DangerousKnowledge22",
          "text": "All these comments are written by Claude.",
          "score": 1,
          "created_utc": "2026-02-13 04:17:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53x7bl",
          "author": "NattyBoi4Lyfe",
          "text": "Nope.",
          "score": 1,
          "created_utc": "2026-02-13 04:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53xioe",
          "author": "moonshinemclanmower",
          "text": "I spend my time on the AI tooling now: [https://github.com/AnEntrypoint/glootie-cc](https://github.com/AnEntrypoint/glootie-cc)",
          "score": 1,
          "created_utc": "2026-02-13 04:23:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53z4pv",
          "author": "AdApprehensive5643",
          "text": "I kinda stopped writting code about one year ago. Feels crazy",
          "score": 1,
          "created_utc": "2026-02-13 04:34:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53zaox",
          "author": "AustinRhea",
          "text": "Yes I am, sometimes",
          "score": 1,
          "created_utc": "2026-02-13 04:35:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o543nmz",
          "author": "zeroconflicthere",
          "text": "30+ years experience and I'm not writing any code at all now. AI is my junior, I'm just checking what they write.",
          "score": 1,
          "created_utc": "2026-02-13 05:07:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5487xu",
          "author": "Less-Opportunity-715",
          "text": "It‚Äôs fucking here guys. Since opus 4.5 and on it‚Äôs been 100 percent of code for me and all my team. We are crushing it.",
          "score": 1,
          "created_utc": "2026-02-13 05:42:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54b8sp",
          "author": "kiwinoob99",
          "text": "You're the bottleneck and will be managed out one day. No one cares (except autists) about clean code, they just want the app to work. It seems that -in your stubborness or fear - you re making yourself obsolete.",
          "score": 1,
          "created_utc": "2026-02-13 06:06:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54bhuz",
          "author": "ultrathink-art",
          "text": "Still writing code daily, but the *type* of code changed. Used to spend 60% of time on implementation details (loops, error handling, API wiring). Now that's 20% ‚Äî AI handles the boilerplate.\n\nThe 60% is now: architecture decisions AI can't make (\"should this be a service or concern?\"), code review where I catch AI's pattern mismatches, and debugging the 10% of cases where Claude confidently does the wrong thing.\n\nThe shift isn't \"write less code\" ‚Äî it's \"spend more time on decisions that require context AI doesn't have.\" System design, performance trade-offs, security boundaries, tech debt prioritization. AI can't decide *what* to build or *why*, only *how*.",
          "score": 1,
          "created_utc": "2026-02-13 06:08:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54br2x",
          "author": "scharpentanz",
          "text": "I'm 12 years in and earned sr status through blood sweat and tears. I spend most of my time calling out other devs' apparent inabilities to write good prompts in sloppy code reviews, and also writing my own user stories and handing them over to BA's because they can't keep up. I don't really write code anymore, but I do spend a lot of time writing \"planning\" prompts for large changes. Currently taking courses on things like \"ai ethics\" and other obscure topics. I feel like they will be more relevant with each day.",
          "score": 1,
          "created_utc": "2026-02-13 06:10:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54dor0",
          "author": "JackTradesMasterNone",
          "text": "Senior - 8 years‚Äô experience. We just got to using Claude Code like last week. I‚Äôve used some free stuff before or other stuff the company provided but this is different. I‚Äôm still figuring it out, but honestly? It‚Äôs great. I can produce faster and for things that are new and don‚Äôt have pre established patterns for us, I can set the standard.\n\nMy only complaint is that it sometimes causes people to not know what‚Äôs going on. I had a new API endpoint to write integration tests for, and I started by hand and asked the engineer who wrote the framework and everything in it how to debug it. She said ‚ÄúJust ask AI‚Äù. In the end, that‚Äôs what I did and it worked, but the fact that I couldn‚Äôt do normal debugging steps kind of concerned me. Sure, I got a test that worked, but I do think not writing it yourself forces you to maybe lose some of that debugging skill? Then again, as I said, it‚Äôs been a week, so I‚Äôm new.\n\nThe best analogy I can apply is kind of like reading a PowerPoint vs writing down the content. I don‚Äôt know about you, but I learn a lot better by writing. I can explain to you every little choice then. I don‚Äôt like the thought of AI generating something and then it being asked about in a PR why I chose to do something one way instead of another and my only response being ‚ÄúAI said so‚Äù, you know?",
          "score": 1,
          "created_utc": "2026-02-13 06:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54e7n6",
          "author": "Best_Day_3041",
          "text": "I'm in the same boat. At first I had ChatGPT writing snippets of code and pasting them in myself. And as it was very helpful, but many times it was as you said, the code wasn't written the best way, or not what I asked for. Most of the time the code I got either needed some tweaking, or it was just quicker to fix it myself, than try to get GPT to do it. Things have improved dramatically though. With Codex I have it make changes all over my entire codebase, completely hands off. It almost always writes the code properly, and most of the times way better than I could. Most of the time if the code isn't good it's because I didn't give it a good prompt. I still review the code, but if I do have to tweak it, it's very minor things that are just quicker for me to change than ask Codex again. I haven't built a complete app from the ground up using only AI yet. I think that is a lot more challenging but I plan to do that next. I would say that it's only a matter of months before I'll probably never write a line of code again. But as a software developer, the coding was never really my true value, it was in the design itself, which hasn't gone away, and hopefully wont anytime soon. I will admit that I am quite nervous about AI making us irrelevant, but there's nothing we can do to change where things are headed, so you're best bet is to learn these tools to make new software and let's hope for the best. ",
          "score": 1,
          "created_utc": "2026-02-13 06:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54e9tp",
          "author": "DiamondGeeezer",
          "text": "I'm always in the loop reviewing design decisions. if I didn't my entire codebase would become slop in a few days.",
          "score": 1,
          "created_utc": "2026-02-13 06:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54ff6b",
          "author": "Own_Abbreviations_62",
          "text": "I've seen code written by engineers that not even a dog would write, it's so poorly done, and there are still people who care about AI?\n\n90% or more of my code is generated. My job is to find solutions to my clients' problems, and it doesn't matter if I write the code by hand in two weeks or in two hours with AI.",
          "score": 1,
          "created_utc": "2026-02-13 06:41:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o597u91",
              "author": "eltear1",
              "text": "Are you still find solution and asking AI to write them, or are you asking AI for solutions? \nIn the second case, your job is now \"asking question in a different way from how client do\". Are you still satisfied by your job? And I'm not talking about money but the job itslef",
              "score": 1,
              "created_utc": "2026-02-13 23:50:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o54fkle",
          "author": "djmcdee101",
          "text": "At this point we're not only having it write the code but also the Jira tickets and PR's. It's a lot more thorough and detailed than the staff can be bothered to be with that sort of thing and follows the templates. \n\nNow if I'm working a ticket I just give it the URL and it pulls it, implements the changes and publishes the PR. Lots of guardrails with pre-loaded context, it's all supervised and the PR's are human-reviewed. But I'm pretty much only typing into Claude and Slack at this point (and Slack has an MCP tool that I've been meaning to try out). The productivity boost this has given us has genuinely been insane. The only issue is it's much more boring now, figuring out how to solve the problems and feeling pleased that I achieved it was the only bit of the job I really enjoyed. Now Claude does that and I've just got meetings and all the other shit to do. Meh.",
          "score": 1,
          "created_utc": "2026-02-13 06:43:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54h54x",
          "author": "_iggz_",
          "text": "How can you be good at your craft and not know this? Lol",
          "score": 1,
          "created_utc": "2026-02-13 06:56:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54h9jf",
          "author": "big_fart_9090",
          "text": "I find myself writing less code and more architecture diagrams for the AI to implement. As a lead that needs to do work with other teams this is the best way to increase output across the org.\nThere are moments I do find myself writing code on parts the LLM has not trained much. Think legacy large systems.\nBut even though the code looks clean and readable, there are often glaring security holes. It is best to handle the LLM as a na√Øeve savant.",
          "score": 1,
          "created_utc": "2026-02-13 06:57:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54hsjf",
          "author": "gratajik",
          "text": "Starting writing code in 1981 - just had a birthday... I'm not going to calculate how long I've been a dev :)\n\nNope - really not a lot since last summer, and none since December and Opus 4.5.\n\nUse it all the time in my day job (MS).  Use it all the time for personal stuff - my latest is a fully autonomous multi-model, multi-agent book writer.  Been working on it since Nov - I think I might FINALLY have it working (turns out having an AI fully write a 300 page book with no human touching it beyond the initial (long) starting info as really hard - I love hard problems, so it's been a blast!)\n\nApproaching 100k lines across the app and 19 agents. It's complex. And I'm saying that as someone who's done a lot of complex things over the years.  And it's 100% vibe coded. I use various reviewer prompts, spot check it, and have had to really dig into the code maybe twice.  The AI has otherwise stayed on track - shockingly well.  Part of the last year has been learning HOW to do that, with AI.  It was hard last spring, it's a lot easier now -but still takes knowledge, technique, and a work.\n\nI'm still using a LOT of my many years of experience - broad knowledge of the practice of software development.  Leading a team - understanding and setting direction, defining and working through the architecture, planning, overall technology choices, communicating to the team (well written specs and definitions), delegating, providing \"mentoring\" and feedback. But with a team of AI, not people.\n\nIt's wild, amazing, exhilarating.... and freakin scary.\n\nIt's really allowed me to apply a massive multiplier to what I can do - I'm working on three other side projects and a ton of things at work - I could only have been doing a fraction of that without AI and it would have taken me a lot longer.",
          "score": 1,
          "created_utc": "2026-02-13 07:02:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54kfml",
          "author": "DistributionRight222",
          "text": "Well I am what been a full stack wacko engineer for 26!years and decided to start writing code 8 months ago because of an illness and always wanted to but quickly got the developer bug and am a perfectionist so I wanted to understand how it works but we very little I plan and prompt research build secure organise and do that. Wish I started sooner but would feel in the same as you if I did. I am was a great electrical engineer and I get Good anything I am interested in and I‚Äôve a few business plans I am working on and could do with someone that is willing to partner up cus nobody is even talking about this. I can do it myself but want to get there faster without relying on big tech if that makes sense.",
          "score": 1,
          "created_utc": "2026-02-13 07:25:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54lfse",
          "author": "rad_hombre",
          "text": "Not a very interesting subreddit to be asking this question honestly.",
          "score": 1,
          "created_utc": "2026-02-13 07:35:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54m07x",
          "author": "Wrong-booby7584",
          "text": "I'd be interested to hear how it changes embedded device code, particularly for power consumption/space.",
          "score": 1,
          "created_utc": "2026-02-13 07:40:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54oofw",
          "author": "bitspace",
          "text": "The current state of quality of the frontier coding models is that they produce far better code than any human, and 1000x faster.¬†¬†\n\n\nTests, evals, guardrails, refined instructions, and skillful prompting.¬†¬†\n\n\nOver 30 years of experience and I have written less than 5% of my code by hand in the past couple of weeks.¬†¬†\n\n\nNote: this was _not accurate_ before December or so.¬† Shit is moving faster than anything I've ever seen.",
          "score": 1,
          "created_utc": "2026-02-13 08:05:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54pblw",
          "author": "ninja_ninja_army",
          "text": "- Staff Er with 11 yoe working at big tech on major revenue generating service. \n- We have monolith 1.4m LOC and 17 years old . \n\nI don‚Äôt write code anymore. Producing same as before in 1/5th time . Using additional free time for watching YouTube , Netflix",
          "score": 1,
          "created_utc": "2026-02-13 08:11:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54qlim",
          "author": "Internal_Candle5089",
          "text": "I write code because I like it, with that being said - I don‚Äôt have time to do what I like and so I write prompts instead üòÖ AI writes code -> I just tell it how & it produces code, documents and everything else I may need. It just writes way faster and it can also read thru codebase a lot faster‚Ä¶ makes most sense to utilize it to speed my workflow as much as possible :)",
          "score": 1,
          "created_utc": "2026-02-13 08:22:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o596k6d",
              "author": "eltear1",
              "text": "I don't get you.. you entered in this career because you like to write code, but now you are ok to write prompt just because AI is faster?\nFrom my point of you, writing prompt is a totally another job.. do you still like what you are doing now?",
              "score": 1,
              "created_utc": "2026-02-13 23:42:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o556ztz",
          "author": "Desperate-Style9325",
          "text": "I haven't actually typed a full function in a year, but I dont let it just rip.",
          "score": 1,
          "created_utc": "2026-02-13 10:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5573fc",
          "author": "TheEssentialMatrix",
          "text": "I write code in an environment where a bug may cause (lack of) safety margin issues, and consequently physical damage to things or people, up to and including gruesome death.\n\nSo, no, if I stick my name on a commit point i need to understand it in its entirety, and that comes only from having done it in its entirety.",
          "score": 1,
          "created_utc": "2026-02-13 10:57:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o557sn5",
          "author": "zabaci",
          "text": "Man marketing push is really strong these days. ",
          "score": 1,
          "created_utc": "2026-02-13 11:03:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55glw6",
          "author": "Holiday-Dig1587",
          "text": "I‚Äôm just gonna put this here: this is my experience with it. I think when using LLMs in coding there vibe coding which treats software as a black box which is an absolute no no for prod, and then there is AI assisted coding. Claude code and similar tools are extremely useful in this area. If your code base is well structured, especially in a well documented language like Java, you could get massive performance gains just by cutting time on busy work. If you‚Äôve built system you might notice some features tend to mirror others structurally. Similar transactional modules and most master modules are structurally near identical except for their entity differences. In situations like these you can get the agent to generate entire features by mirroring existing features for new entities. Setting up the workflow to preview results layer by layer combined with Javas inherent strong types makes this a perfect use case. LLMs are amazing for identifying logical errors as well. Often time when I build a new feature before running and testing the endpoint I would ask the agent to navigate through the endpoint all the way to the db layer and verify no logical errors or anomalies. And they are really really good for documentation and auditing your code base, say you need compliance for a strict set of guidelines or you need to document a new feature in a specific format, Claude is your guy. I‚Äôm sure there are many more way to use it but this is how I have seen massive productivity gains in production while ensuring code quality and not losing control. Cuz no matter what the ai generate I can personally account for every semicolon in the code base.",
          "score": 1,
          "created_utc": "2026-02-13 12:13:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55k8mj",
          "author": "Internal_Sky_8726",
          "text": "7 YOE, 100% of the code I write is written by AI. The ability for it to write correct code gets significantly better every couple months.\n\nI‚Äôm learning to engineer the harness around AI so that I can get myself out of the loop as much as possible. I still review the code and offer suggestions. But I do not write code at all anymore.\n\nI review it, and I QA it. And I have the AI build the harness around our application when I find something I‚Äôm manually required to do, I try to think of a way to enable the AI to do that instead.",
          "score": 1,
          "created_utc": "2026-02-13 12:38:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55tpto",
          "author": "mrmojoer",
          "text": "Yup",
          "score": 1,
          "created_utc": "2026-02-13 13:35:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o568s27",
          "author": "Public-Inflation-286",
          "text": "A little, when its time to get serious I crack the knuckles and do it myself. \n\n  \nBut yeah daily my normal job is now code reviews and QA testing.",
          "score": 1,
          "created_utc": "2026-02-13 14:55:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56a2z1",
          "author": "Byakko_4",
          "text": "100% written by AI. But I spend more or less time planning and reviewing depending on the project and stakes",
          "score": 1,
          "created_utc": "2026-02-13 15:02:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56cucx",
          "author": "theycallmeholla",
          "text": "I rarely write code anymore.  I spend the most of my time planning, prompting, dropping f-bombs, and manually testing.",
          "score": 1,
          "created_utc": "2026-02-13 15:15:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56fbt5",
          "author": "justinpaulson",
          "text": "In the last year, I‚Äôve simultaneously produced more code than any year of my life and written less code than any year in my professional career.",
          "score": 1,
          "created_utc": "2026-02-13 15:27:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57e341",
          "author": "life_on_my_terms",
          "text": "Nope.  \ni just use CC and codex\n\nim doing freelancing now\n\nit's more important to deliver value to customers than me hand writing code",
          "score": 1,
          "created_utc": "2026-02-13 18:14:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o595gs3",
              "author": "eltear1",
              "text": "I understand why customers think that's more important to deliver value that to write code.\nAnd I get that you gain more money, writing more code quicker.\n\nWhat I don't understand is why YOU (as a developer) think it's more important to deliver value to customers than write code.\n\nWhy did you start being a developer? Only to gain money? Is so, why didn't you choose another career?",
              "score": 1,
              "created_utc": "2026-02-13 23:35:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57n3xp",
          "author": "Skar_pa",
          "text": "I will say about 50% of my code is still written by myself. I usually use AI for the planning phase and any mundane repetitive tasks. If I am seriously stuck on something I will ask AI to do it's thing and then I will always code review everything written to, firstly, understand how it solved the issue and, secondly, ensure the code is top quality.",
          "score": 1,
          "created_utc": "2026-02-13 18:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57rsva",
          "author": "an_enquiring_penguin",
          "text": "I don't understand people's inability to understand that you can codify your preferred coding style from syntax to design principles and everything inbetween. CC allows you to automate *thinking* and any systematic approach to anything however many abstractions layers you want to go up. Once you've invested a little bit in your setup, it's OVER. I for one am *so glad*.",
          "score": 1,
          "created_utc": "2026-02-13 19:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58xe4c",
          "author": "GuideExtreme",
          "text": "I've been working with code for about 20 years, and I'm still actually coding. The company I work for is scared of AI and the risk of leaking information as we're working with both export regulated information and classified information. And to be honest, IT at our company don't have the knowledge to setup and hardening a locally hosted AI framework that have the power to serve the whole company (~3000 employees worldwide).\n\nMy gut feeling is also that AI for now is best at creating apps, visual stuff, scripts, backends etc, while our works is done on low level C code, assembly, setting bits in registers of obscure hardware. And if we do something wrong, people can die rather than that we get an annoyed customer or a bad review.\n\nI'm sure that AI will enter our premises as well rather soon, but for now we are coding by hand for the most.",
          "score": 1,
          "created_utc": "2026-02-13 22:49:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58xxu0",
              "author": "zulutune",
              "text": "Thanks for sharing",
              "score": 1,
              "created_utc": "2026-02-13 22:52:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o593qw9",
          "author": "sauteed_opinions",
          "text": "get better at prompting = being good at claude code",
          "score": 1,
          "created_utc": "2026-02-13 23:25:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59488u",
          "author": "eltear1",
          "text": "Unfortunately it seems so. My CTO just made a bot to check all issues in our integration tests (there's always been a team of 3 people dedicated only at them) and he clearly said \"there's no coming back\" after that in 2 day the AI fixed more issues than the 3 people in the last month.\n\nAnd I say unfortunately, because it will change our job from developers to ..what? Giving the right instructions? Personally I'm not happy at all about it",
          "score": 1,
          "created_utc": "2026-02-13 23:28:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a3q0d",
          "author": "prilldev",
          "text": "Been a software developer/engineer for 20+ years (started in 2001). Always coded (not the management type)... Switch from CoPilot \"chat workflow\" to Claude Code this past summer. Now I just prompt and steer, use a custom claude skills workflow I created, then let the agent do everything. I probably haven't written a full line of code since September or October, and my output is higher than in my entire career. Not sure where all of this will take us, but I'm enjoying the wild ride while we have it!",
          "score": 1,
          "created_utc": "2026-02-14 03:09:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a62bt",
          "author": "Impeesa451",
          "text": "38 years of professional experience with another 10 years of prior student programming here. CC is phenomenal at debugging issues and can quickly generate code. However, without a limitless context, CC can‚Äôt keep track of what it wrote and will constantly duplicate existing code instead of reusing it. I find myself constantly redirecting CC on how to be a better software engineer, not unlike how I guide my college hires. I also cannot rely upon CC to be accurate in its assessment of the code it generates.\n\nCC is a great tool when used within its limits but I don‚Äôt think it‚Äôs anywhere near achieving the same level of dependability as a compiler. I‚Äôm sure it will one day, but until then, we still have to validate the code it generates.",
          "score": 1,
          "created_utc": "2026-02-14 03:25:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4znuvd",
          "author": "protomota",
          "text": "Kind of feel like I don‚Äôt have time for that anymore. Especially how good the top end models program now. Crazy times.",
          "score": 1,
          "created_utc": "2026-02-12 14:59:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zsc3u",
              "author": "LEO-PomPui-Katoey",
              "text": "Yes agreed. Coding is the easy part, why waste time on that.",
              "score": 1,
              "created_utc": "2026-02-12 15:21:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zt8sd",
          "author": "Pure-Astronomer-6239",
          "text": "I work in two projects, one is python + node js (somewhat complex). I don't write code, just review, documents and diagrams. Bad code= I just explain why is bad and how I want it to refactor. Another one is barematel arm microcontroller, AI is detrimental, 0 use. 20+ y exp.",
          "score": 1,
          "created_utc": "2026-02-12 15:26:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zu4jj",
          "author": "LosMosquitos",
          "text": "10y here. In general I don't code much, even before ai. Most of the projects I work on have between 10k and 20k loc. \n\nIf the task is straight forward, I try with Claude in plan mode. If it's a bit more complicated, I look at the code myself and try to see where and how to write something. \n\nMost of the projects we work on are brownfields with a few years and multiple owners, so you cannot just have a guideline and \"it works\", the patterns are a bit at random and the code quality is very mixed. Claude doesn't really think out of the box, and it's not able to understand trade-offs by itself. It doesn't understand that if it changes 20 files for something simple there might be a design issue. \n\nSo, it depends. Is the code clear and follows a specific structure? Let Claude do it. Does it require refactoring or better design decisions? I'll do it and let Claude finish it.",
          "score": 1,
          "created_utc": "2026-02-12 15:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zmcuh",
          "author": "subbu-teo",
          "text": "Yes and it's shit.",
          "score": -4,
          "created_utc": "2026-02-12 14:52:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50328k",
              "author": "MoreRest4524",
              "text": "You need to improve your Claude-Fu",
              "score": 3,
              "created_utc": "2026-02-12 16:12:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zrl18",
              "author": "ripviserion",
              "text": "skill issue ",
              "score": 6,
              "created_utc": "2026-02-12 15:18:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0dx3v",
      "title": "Unpopular Opinion: Shut the fuck up about Codex",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1r0dx3v/unpopular_opinion_shut_the_fuck_up_about_codex/",
      "author": "Top-Pool7668",
      "created_utc": "2026-02-09 19:30:20",
      "score": 274,
      "num_comments": 131,
      "upvote_ratio": 0.72,
      "text": "Listen, I get it. Codex is great. Maybe even better than Claude. I understand that Codex cured your mother‚Äôs cancer, \\*and\\* made you your favorite kind of muffins that you had mentioned offhandedly to it a few weeks ago.\n\nThat‚Äôs all great! Amazing! Wow!\n\nI figured from how much Codex posting goes on around these parts, there must not be a Codex subreddit. Well boy, to my horror and surprise was I wrong! There is, in fact, a   r/codex   ! It‚Äôs pretty popular too, lots of people using it. And you wanna know what I didn‚Äôt see? A post about Claude Code every other post! So why don‚Äôt Codex fans go circlejerk about it over there instead of spamming the Claude Code Reddit with a bunch of shilling. Because if I wanted to read about fucking Codex all day, I would be following the Codex subreddit.\n\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n\n**EDIT:**\n\nAt the suggestion of several comments, I have made a new subreddit specifically for the Claude Code vs Codex circlejerking.\n\n r/Claudex \n\nAs the only mod, I promise that I will never check that subreddit again.",
      "is_original_content": false,
      "link_flair_text": "Meta",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r0dx3v/unpopular_opinion_shut_the_fuck_up_about_codex/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o4hjjd0",
          "author": "CurveSudden1104",
          "text": "I think discussing Codex is fine, in fact I think competition is great and talking about it prevents echo chambers. However all of the posts just exclaiming \"codex is the best\" or \"codex is the fucking worst\" adds little to this sub.",
          "score": 130,
          "created_utc": "2026-02-09 19:39:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hkg9x",
              "author": "El_Spanberger",
              "text": "I use both \n\n![gif](giphy|jPAdK8Nfzzwt2)",
              "score": 32,
              "created_utc": "2026-02-09 19:43:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4hklzz",
                  "author": "Top-Pool7668",
                  "text": "I also use both tools. Like I don‚Äôt hate codex, I‚Äôm just not interested in reading about how it‚Äôs so much better than Claude 15 times a day in the Claude Code subreddit.",
                  "score": 4,
                  "created_utc": "2026-02-09 19:44:44",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o4j9pg0",
                  "author": "protomota",
                  "text": "I tell Claude Code to do a PR review of Codex. True AGI",
                  "score": 1,
                  "created_utc": "2026-02-10 01:04:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4hyevu",
              "author": "SourCheeks",
              "text": "As long as we're throwing out unpopular opinions, I'll say that I find the Codex discussion on here super helpful. As a user of both, sometimes I notice certain behaviors between the two, and it's incredibly helpful to have people here to confirm if that behavior is just local to me or indicative of something systematic.",
              "score": 10,
              "created_utc": "2026-02-09 20:53:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iqwc6",
              "author": "Middle-Nerve1732",
              "text": "Yeah telling people to not discuss other competitors to CC is such a weird take, and really a problem I see across Reddit. It‚Äôs like the subreddits are so defensive about ‚Äúthing I like‚Äù and anyone who attacks it or suggests ‚Äúother thing‚Äù is immediately shouted down. People need to stop acting like little kids with their toys.¬†\n\nAll opinions should be listened to, if you don‚Äôt like it keep scrolling, or even better share why you think CC is better than Codex. We all benefit from the debate. ¬†",
              "score": 2,
              "created_utc": "2026-02-09 23:18:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iptfe",
              "author": "TheOriginalAcidtech",
              "text": "Most of them appear to be astroturf at this point. Between the \"oh my usage limits, oh my ducets\" to the \"codex is amazing and better than sliced bread\", it all looks like ChatGPT is paying for this.",
              "score": 1,
              "created_utc": "2026-02-09 23:12:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4i26wh",
          "author": "bovard",
          "text": "Astro turfing from Scam Altman and co. They are mad that Claude is taking market share",
          "score": 47,
          "created_utc": "2026-02-09 21:12:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j9ihm",
              "author": "vexmach1ne",
              "text": "Have you tried codex?",
              "score": 2,
              "created_utc": "2026-02-10 01:03:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4jkf1c",
                  "author": "eNroNNie",
                  "text": "Nah, but in the cesspool of AI companies I would rather give my money to Anthropic than to that freak Altman and his cronies.",
                  "score": 2,
                  "created_utc": "2026-02-10 02:07:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4jdymc",
                  "author": "nick4tech",
                  "text": "It makes amazing muffins!!!",
                  "score": 1,
                  "created_utc": "2026-02-10 01:29:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hjtxc",
          "author": "Main-Lifeguard-6739",
          "text": "could you please talk about this in r/codex? ",
          "score": 49,
          "created_utc": "2026-02-09 19:40:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hmcl0",
              "author": "Kitchen_Interview371",
              "text": "Hahaha",
              "score": 3,
              "created_utc": "2026-02-09 19:53:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4hk8jy",
              "author": "Top-Pool7668",
              "text": "Should I post it there as well? ü§£",
              "score": -8,
              "created_utc": "2026-02-09 19:42:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4hnf3a",
                  "author": "oooofukkkk",
                  "text": "I‚Äôm just glad we are still talking about how great codex is, it‚Äôs really much better than claude",
                  "score": 12,
                  "created_utc": "2026-02-09 19:58:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hs0nd",
          "author": "impartialhedonist",
          "text": "I have seen so many posts of that variant across Reddit, LinkedIn, and even Substack that it makes me wonder if OpenAI's unofficial-official strategy is just spamming everyone's feed with Codex praise.\n\nFwiw, I think 99% of conspiracies are dumb, but after seeing the 25th nearly identical post praising a company which builds brains for bots, it makes a man wonder ...",
          "score": 13,
          "created_utc": "2026-02-09 20:22:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i6dph",
              "author": "DapperCam",
              "text": "I think all of these subs are astroturfed by all the major providers. There is way too much money riding on this for them not to be.\n\nNotice extremely positive or extremely negative posters usually have hidden comment history on their profile.",
              "score": 7,
              "created_utc": "2026-02-09 21:33:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4irqft",
              "author": "PandorasBoxMaker",
              "text": "It‚Äôs either people who love the sound of their own voice and couldn‚Äôt recognize an intelligent opinion to save their life or it‚Äôs a grass roots campaign by OpenAI. Guaranteed it‚Äôs both with little else.",
              "score": 2,
              "created_utc": "2026-02-09 23:23:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4izmrl",
              "author": "Sponge8389",
              "text": "I'm not surprise if they are doing it. Many \"startup\" companies are doing that to chill their product. ",
              "score": 1,
              "created_utc": "2026-02-10 00:07:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hk6x8",
          "author": "Crowley-Barns",
          "text": "A lot of us go back and forth depending on what‚Äôs best at the time. It‚Äôs useful. And if a third one comes along that‚Äôs better it will be great to hear about that, too. \n\nIt‚Äôs a tool. It‚Äôs good to compare tools. And it‚Äôs really good to hear when a better one comes along.\n\nIf you‚Äôre not interested‚Ä¶ don‚Äôt click on ones with ‚Äúcodex‚Äù in the topic lol.",
          "score": 34,
          "created_utc": "2026-02-09 19:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hmalu",
              "author": "obolli",
              "text": "agree with that sentiment, i have both, codex annoyed me when it was slow as f, claude annoys me because anthropic lets me be a paying guinea pig. I just switch back and forth and I don't understand why anyone wouldn't do the same as anthropic and openai are clearly not above messing with users",
              "score": 3,
              "created_utc": "2026-02-09 19:53:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4iriye",
                  "author": "TheOriginalAcidtech",
                  "text": "Switching back and forth isnt the problem. The problem is people spamming Claude reddits with Codex, instead of posting in their own reddits. Spamming this stuff just makes it look that much more like PAID SEO for Codex.",
                  "score": 1,
                  "created_utc": "2026-02-09 23:22:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4hogir",
              "author": "Western_Objective209",
              "text": "The thing is, people acting like codex 5.3 as a breakthrough doesn't make a whole lot of sense. The pattern where CC is faster, better UX, and more flexible while codex is slow, reliable, and more precise has existed since codex was initially released (I've been using both since each one was released).\n\nI think they are both state of the art, codex is a better value because you can get a lot done for $20/month, but if you are doing general software development where AI writes all your code you kind of need CC because it's just a workhorse.  At least we don't have people trying to say Kimi and OpenCode or GLM are actually better, that was just dumb AF",
              "score": 0,
              "created_utc": "2026-02-09 20:04:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4hzdpa",
              "author": "ReachingForVega",
              "text": "Try Google CLI, it's pretty good. I use it alongside CC.¬†",
              "score": 0,
              "created_utc": "2026-02-09 20:58:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hobr0",
          "author": "xFloaty",
          "text": "I tried Codex today and it struggled for 1 hour to run a dev server in background. How does it not have a \"run in background\" tool? wtf",
          "score": 5,
          "created_utc": "2026-02-09 20:03:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i54tn",
              "author": "syddakid32",
              "text": "lol thats the thing... every claude user has tried codex and knows it can't compete but somehow its a group of people who swear by codex... and im like lol aint no way. The people who are spending money on codex or claude might get swayed to try codex first but will come over to claude eitherway it goes.",
              "score": 2,
              "created_utc": "2026-02-09 21:26:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4i8570",
                  "author": "xFloaty",
                  "text": "Ngl recent Claude update is awful too. Tried doing basic tasks and keeps getting stuck. Friend also has this problem. Made me try Codex but it has its own issues",
                  "score": 2,
                  "created_utc": "2026-02-09 21:42:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4impn5",
              "author": "czei",
              "text": "I had the same experience.  Codex appears to be a shameless copy of CC, but without its useful features.  I don't get all of the praise heaped on Codex.  ",
              "score": 1,
              "created_utc": "2026-02-09 22:56:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4j9lcs",
              "author": "n_lens",
              "text": "This should tell you all you need to know about the extremely positive posts about Codex (Hint: it's marketing).",
              "score": 1,
              "created_utc": "2026-02-10 01:03:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hnnv8",
          "author": "Nik_Tesla",
          "text": "Ok, so we only talk about Claude Code here, and we only talk about Codex over there. Do we need a dedicated /r/ClaudeCodex subreddit when comparing the them? What if we're also comparing Gemini as well, do we need /r/ClaudeGemini and /r/CodexGemini too, or can we just get a way with a single combined /r/ClaudeCodexGemini sub? Gotta keep the subreddits entirely segregated with no crosstalk.\n\n/s",
          "score": 4,
          "created_utc": "2026-02-09 20:00:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hpa3d",
              "author": "Top-Pool7668",
              "text": "r/ClaudeCodex actually is a cracked idea for how to mediate this",
              "score": 3,
              "created_utc": "2026-02-09 20:08:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hoh61",
          "author": "Last_Mastod0n",
          "text": "Talking about codex is great because its good to compare the competition. If you haven't looked into both CC and Codex then your doing yourself a disservice.",
          "score": 11,
          "created_utc": "2026-02-09 20:04:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i3gs1",
              "author": "AJGrayTay",
              "text": "...yeah, but he can do all that without all the Codex astroturf - he's a clever kid, he doesn't need to read about it here.\n\nOP, I'm on board, this sub is horseshit lately.",
              "score": 5,
              "created_utc": "2026-02-09 21:18:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hu0f4",
          "author": "Fun-Market-5809",
          "text": "I just tried it for the first time in my CLI. Honestly it feels worse to me. Slower, less detailed responses. Maybe I am used to how claude responds but it feels less useful. At best I am using it to review changes claude makes but thats it.",
          "score": 8,
          "created_utc": "2026-02-09 20:32:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i24f5",
              "author": "sittingmongoose",
              "text": "5.2 - Slow AF! But extremely smart.  Opus level\n5.2 Codex - very focused, kinda smart, slow\n5.3 Codex - much smarter than 5.2 codex but still not quite as smart as 5.2.  MUCH FASTER than other ChatGPT versions.  But still not as fast as Opus.\n\nAlso, never use xhigh.  It‚Äôs extremely slow and often thinks itself out of answers.",
              "score": 2,
              "created_utc": "2026-02-09 21:12:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hqk9s",
          "author": "sheriffderek",
          "text": "If we were talking about Honda in the Mercedes sub all day saying \"Buy Honda instead\" bla bla bla bla bla bla... Honda Honda... life isn't fair, have you tried Honda? This Mercedes sucks - you should use Honda...  I think they might have a problem with that. I come here to talk about ClaudeCode. I'm only interested in serious people who are serious about this specific tool.",
          "score": 9,
          "created_utc": "2026-02-09 20:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hwb1t",
              "author": "Top-Pool7668",
              "text": "My feelings exactly.",
              "score": 6,
              "created_utc": "2026-02-09 20:43:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4imzw0",
              "author": "EquipableFiness",
              "text": "Or At least keep it to the claudeAi, this is like a very specific subreddit",
              "score": 1,
              "created_utc": "2026-02-09 22:57:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4j48wa",
                  "author": "sheriffderek",
                  "text": "Yeah. there's already a sub for /claude and /claudeAi and general /ai etc --  ",
                  "score": 1,
                  "created_utc": "2026-02-10 00:33:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4jce1b",
              "author": "KhabibNurmagomurmur",
              "text": "Agree 100%, there are places on this site to talk more generally about LLM development and AI in general. This is a Claude code subreddit.",
              "score": 1,
              "created_utc": "2026-02-10 01:20:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hnvlf",
          "author": "thrae_awa",
          "text": "it's because claude is overpriced",
          "score": 7,
          "created_utc": "2026-02-09 20:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hqakv",
              "author": "x_typo",
              "text": "and a token hog... I'm on codex pro plan and codex is working on my code for work non-stop for hours ever since this morning and I haven't reached even 80% of my weekly limit. \n\nI now realized that I'm being ripped off (recently unsubscribed their 5x pro plan) by Claude the entire time I signed up since nov...",
              "score": 6,
              "created_utc": "2026-02-09 20:13:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4hqz4x",
                  "author": "thrae_awa",
                  "text": "100% I feel like they should refund tokens when the model is being particularly obtuse :D",
                  "score": 3,
                  "created_utc": "2026-02-09 20:17:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4hpxfa",
              "author": "BigBootyWholes",
              "text": "Codex will raise the prices eventually. Investor money isn‚Äôt infinite",
              "score": 2,
              "created_utc": "2026-02-09 20:11:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4hqqqn",
                  "author": "thrae_awa",
                  "text": "Absolutely, didn't they burn through 12 billion in a quarter?\n\nBut, however unsustainable that may be, claude is overpriced and people are understandably frustrated.",
                  "score": 1,
                  "created_utc": "2026-02-09 20:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hyf31",
          "author": "Torres0218",
          "text": "The best workflow is just running both in parallel. You can easily set up Claude Code to use both Opus and GPT 5.3, it's not hard. Each model catches things the other misses, and your code is better for it.\n\nThe tribalism is ridiculous. You're going to war for companies that would sell your data tomorrow if it moved the needle on their quarterly earnings. They don't care about you. Use both, ship faster, and let the fanboys argue about benchmarks while you're already done.",
          "score": 2,
          "created_utc": "2026-02-09 20:53:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i0k2l",
          "author": "GuitarAgitated8107",
          "text": "Codex is great right now because of the 2x rate limit promo, it's pretty much Claude Code's executive assistant. 2x Claude Code Pro subs, 1 ChatGPT Pro sub & 1 Copilot Sub.",
          "score": 2,
          "created_utc": "2026-02-09 21:04:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i46lb",
          "author": "realDarthMonk",
          "text": "Jesus. I‚Äôm leaving this community",
          "score": 2,
          "created_utc": "2026-02-09 21:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i98fq",
          "author": "Responsible-Tip4981",
          "text": "Well, it is not about Codex or Claude, ppl just admire artificial intelligence. In fraction of time you can make judge if it delivers or not. Codex went from so, so, to wow, in pair with Claude - so now I can now decide by wallet. The worst is that Claude Opus 4.6 improved few things and broke few others and that regression hurts. For example more frequent infinite loops of sub-agents or suggesting solutions which are to brave/bold to deliver at all or if, then maintain in a longer run.",
          "score": 2,
          "created_utc": "2026-02-09 21:47:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4icc90",
          "author": "NormalNature6969",
          "text": "Very unpopular. Claude is back to trash mode right now.",
          "score": 2,
          "created_utc": "2026-02-09 22:03:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4id2wh",
          "author": "SM_Fahim",
          "text": "That's because most people here love the Claude Code environment but occasionally have to switch due to higher limits and specific benefits Codex has to offer. \n\nIt's not 2 different communities, it's an overlapping one.",
          "score": 2,
          "created_utc": "2026-02-09 22:06:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hnlzv",
          "author": "Ok_Grapefruit7971",
          "text": "you mad bro?",
          "score": 3,
          "created_utc": "2026-02-09 19:59:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i0i2n",
          "author": "AppealSame4367",
          "text": "Wow, talk about elitist, thin-skinned. I see the Opus people become the new Apple guys. Haha\n\nI don't care about models, as long as they deliver. Every two weeks it's another and there are already people clinging to brands and companies. Haha. Haha.\n\nYou sound like someone that spared 5 years to buys a BMW 3er and now can't stand that there are other cars. Haha",
          "score": 4,
          "created_utc": "2026-02-09 21:04:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i5cvq",
          "author": "Cd206",
          "text": "Why are you so mad",
          "score": 3,
          "created_utc": "2026-02-09 21:28:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hjl7o",
          "author": "sittingmongoose",
          "text": "Would you prefer that the ClaudeCode sub only talks about Opus?  While I understand it can be a little annoying, having everyone in the Claude Code sub talk about Codex will ultimately benefit the consumer.  If your Anthropic and all you are seeing in your sub is how great codex is, that will light a fire under them.  They were in a leadership position and now they are threatened, they need to respond.\n\nThe exact same thing happened in the Codex sub when 4.5 came out.  All the posts were about Opus 4.5.  And guess what, Codex responded.",
          "score": 4,
          "created_utc": "2026-02-09 19:39:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i0fqk",
              "author": "rafark",
              "text": "> Would you prefer that the ClaudeCode sub only talks about Opus? \n\nYea? That‚Äôs literally t he point of the op. If one wants to talk codex they can go to the codex or openai subreddits. Leave the Claude for discussions around Claude.",
              "score": 1,
              "created_utc": "2026-02-09 21:03:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hkd1b",
          "author": "Horror_Brother67",
          "text": "‚ÄúDon‚Äôt talk about Codex! So let me make a post talking about Codex‚Äù üòÜ",
          "score": 3,
          "created_utc": "2026-02-09 19:43:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hn8vm",
          "author": "Select-Ad-3806",
          "text": "Should i get codex to try it? Can't be any worse than Opus 4.6",
          "score": 2,
          "created_utc": "2026-02-09 19:58:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hp20f",
              "author": "Top-Pool7668",
              "text": "I use Codex to review Claude! They are both essential in my workflow.",
              "score": 1,
              "created_utc": "2026-02-09 20:07:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4hwj73",
                  "author": "Select-Ad-3806",
                  "text": "This is mental, codex came back with with 5 serious issues including one that says it was pretending to do x but didn't actually do it!",
                  "score": 0,
                  "created_utc": "2026-02-09 20:44:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hurqn",
          "author": "isakota",
          "text": "\"You're absolutely right! It was my mistake to talk about Codex only. \nThis was an oversight on my behalf.\nWould you like me to talk about other models?\nI can give you a list of popular models you might use as an alternative for your overpriced CC subscription.\nWould you like me to do that?\"",
          "score": 2,
          "created_utc": "2026-02-09 20:35:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hx2fn",
          "author": "i__suck__toes",
          "text": "Yeah, those posts and comments got me quite curious so I tried Codex. \nIt did a horrible job compared to Opus. Don't get me wrong, the code definitely works, and follows \"best practices\" on the surface. But it was overcomplicated and in many cases had unnecessary functions to handle non-existent edge cases that are simply impossible to reach. I literally cut the file down from 320 lines to 105 lines with zero changes in functionality nor stability. It just had a lot of weird fluff.",
          "score": 1,
          "created_utc": "2026-02-09 20:47:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i5jsf",
              "author": "syddakid32",
              "text": "lol it got me a week ago and I'm like what in the world are people talking about? codex is trash!! It tries to solve for these edge cases where I believe it makes shit up in its head. Those things can occur but the chance of it occurring is slim to none ",
              "score": -1,
              "created_utc": "2026-02-09 21:28:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hnies",
          "author": "FlyingDogCatcher",
          "text": "cool post!",
          "score": 1,
          "created_utc": "2026-02-09 19:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ho3si",
          "author": "DasBlueEyedDevil",
          "text": "That's cool and all, but have you guys heard of Kimi?",
          "score": 1,
          "created_utc": "2026-02-09 20:02:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hpr7n",
          "author": "Otherwise_Bee_7330",
          "text": "codex ad in disguise?",
          "score": 1,
          "created_utc": "2026-02-09 20:11:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hqfxt",
          "author": "Tema_Art_7777",
          "text": "Good point OP, why codex only - perhaps we should also add a bit of /cline to the mix here üòÄ",
          "score": 1,
          "created_utc": "2026-02-09 20:14:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iqrll",
              "author": "juanpflores_",
              "text": "agreed!",
              "score": 1,
              "created_utc": "2026-02-09 23:18:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hrosc",
          "author": "Knpix",
          "text": "![gif](giphy|T8Eg6whFVCs2l7FuYf|downsized)",
          "score": 1,
          "created_utc": "2026-02-09 20:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hs9ia",
          "author": "Abject-Kitchen3198",
          "text": "They should merge into Claudex. Or Clodex.",
          "score": 1,
          "created_utc": "2026-02-09 20:23:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hw78k",
              "author": "Top-Pool7668",
              "text": "![gif](giphy|d3mlE7uhX8KFgEmY)\n\nClaudex üò≠",
              "score": 1,
              "created_utc": "2026-02-09 20:42:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4izubv",
              "author": "LionessPaws",
              "text": "Clorox is taken I suppose /jk",
              "score": 1,
              "created_utc": "2026-02-10 00:08:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hsw3a",
          "author": "mapleflavouredbacon",
          "text": "Pick one that works, use it. They are all the same shit now. I‚Äôm still an Antigravity fanboy now using Opus and Gemini. No desire to switch until it starts fucking up my shit.",
          "score": 1,
          "created_utc": "2026-02-09 20:26:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hwgkk",
          "author": "MyUnbannableAccount",
          "text": "I've made mention in comments a couple times, simply because there are weeks where every other post is talking about how Opus is nerfed.  You can argue all you want about Opus vs GPT or CC vs Codex, but I can tell you that the other sub wasn't screaming about nerfed models.\n\nIt might also be due to codex-5.3 being a tangible improvement from both codex-5.2 and GPT-5.2 on coding, and I'm not seeing people saying that Opus-4.6 is a noticeable improvement from 4.5, but I do see people complaining about their token credits shrinking even further.\n\nCC is still the better harness, but Codex is improving.  I just wish the folks at Anthropic threw the hammer down a tad harder.  Now that we see they can and do nerf the models during training run-ups, it'd be nice to see them spending enough on compute to not nerf the models, effectively doing a short-term rug pull on their customers, it's another reason people will tell others about an alternative.",
          "score": 1,
          "created_utc": "2026-02-09 20:44:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hy4p1",
          "author": "jii0",
          "text": "I sort of agree, but mostly it's a post quality issue. 95% of these Codex posts are very low effort whining without any respectable comparison and analysis. The same applies to \"nerfed claude ate my tokens\" posts, which are just whining.",
          "score": 1,
          "created_utc": "2026-02-09 20:52:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hyms4",
          "author": "Helkost",
          "text": "I actually agree. If I wanted to know about codex, I'd go to their sub, it's not like I'm banned there or something. I don't really care about codex posts here, they just clog the space and bury actually interesting conversations.\n\nand look, yeah, competition is good, but not how it's expressed here. it's kinda toxic and makes the sub experience a lot worse.",
          "score": 1,
          "created_utc": "2026-02-09 20:54:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i2gi3",
          "author": "danialbka1",
          "text": "we should do some annual codex vs claude code gang thing. the warriors style you know",
          "score": 1,
          "created_utc": "2026-02-09 21:13:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i3h8w",
          "author": "DifficultyFine",
          "text": "I think it's just a very advanced marketing strategy (and some looks genuine). I didn't see anything about codex prior to release of 5.3, but after that I even see post stating 5.2 is at opus 4.5 level. Flooding this sub with codex is not even 0,005%  of OpenAi's marketing budget, so what's stopping them? ",
          "score": 1,
          "created_utc": "2026-02-09 21:18:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i65a9",
              "author": "syddakid32",
              "text": "Yea, they can't beat claude straight up so they have to shill but thats a short term win... the best tool will come out ahead no matter what .",
              "score": 0,
              "created_utc": "2026-02-09 21:31:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4jiupz",
          "author": "El_human",
          "text": "Codex is not nearly as good as claude code imo. Codex can't get past \"muscle memory\" and keeps giving me code for old versions of godot that have been deprecated.",
          "score": 1,
          "created_utc": "2026-02-10 01:58:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jq71p",
          "author": "tidepod1",
          "text": "Which Codex? The GPT-5.3-Codex or the new Codex app?\n\nNot that it matters. Clearly you have some big feelings, but I‚Äôm curious what tool you‚Äôre demanding we never acknowledge.",
          "score": 1,
          "created_utc": "2026-02-10 02:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jr0kw",
          "author": "Independent-Ruin-376",
          "text": "People here ride on claudes dick whereas on oai subs they just straight up hatin",
          "score": 1,
          "created_utc": "2026-02-10 02:45:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jtt8h",
          "author": "PetiteGousseDAil",
          "text": "If people post \"codex is better than claude\" in the codex subreddit, that doesn't mean much. If that same post is posted here, that tells Anthropic that their own users also feel that way",
          "score": 1,
          "created_utc": "2026-02-10 03:02:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jvtn2",
          "author": "ANTIVNTIANTI",
          "text": "I legit had been so excited to try Codex the other day... The UI is.... It wouldn't let me try it basically LOLOL. On my Mac Studio m3 Ultra, the UI kept spazzing out, lag-jumping(it was bad) and then they pushed an update, I was excited, the update made it just freeze. lololol. I haven't been able to try Codex yet, not sure wtf is going on with most apps I use these days, recent updates have got to be Vibe Code trial runs cause, like, holy hell, weird glitches. Lol. You'd think they'd do better than your average homie whose just pushing shit out of curiosity and love of building, but even they try to get tests right/worry about things working correctly(from my limited experience this seems to be the case, not that like, I feel they want to‚Äîmore like‚Äîthey feel they have to cause, the vibe code scarlet letter shit etc.) anywho, I still think you Claude fans are in a cult :P bwahahahah\n\n  \nI WILL ALWAYS THINK THAT :P \\*weird sus look around the sub\\* yup, cult. ya'll in a cult.... just kidding op lol",
          "score": 1,
          "created_utc": "2026-02-10 03:14:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jw0y5",
              "author": "ANTIVNTIANTI",
              "text": "I feel like I couldn't afford claude tbh, I have used it in VS Code, seems \\~= GPT 5.2, but that's in VS Code, so like, I expect that the Claude Opus of the 4.5 is not the Claude Opus of the real 4.5 whereas Gippity has that lil agreement with MSlop so, makes sense that that would be the case here. ",
              "score": 1,
              "created_utc": "2026-02-10 03:16:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4jwrb7",
          "author": "Bright_Armadillo8555",
          "text": "Stupid Anthropic pet.",
          "score": 1,
          "created_utc": "2026-02-10 03:20:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hl9nj",
          "author": "Euphoric_Sandwich_74",
          "text": "Is your tummy-wummy huwting because mommy didn‚Äôt get you food?",
          "score": 1,
          "created_utc": "2026-02-09 19:47:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hkb4j",
          "author": "ridablellama",
          "text": "amen, no one actually believes them anyways. only ones using codex are openai employees who are banned by anthropic from using claude code",
          "score": 1,
          "created_utc": "2026-02-09 19:43:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i4p84",
              "author": "syddakid32",
              "text": "Preach!!",
              "score": 0,
              "created_utc": "2026-02-09 21:24:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hn16g",
          "author": "epyctime",
          "text": "Listen, I get it. hammers are great. Maybe even better than nail guns. I understand that hammers cured your mother‚Äôs cancer, \\*and\\* made you your favorite kind of muffins that you had mentioned offhandedly to it a few weeks ago.\n\nThat‚Äôs all great! Amazing! Wow!\n\nI figured from how much hammer posting goes on around these parts, there must not be a hammer subreddit. Well boy, to my horror and surprise was I wrong! There is, in fact, a¬†r/nailguns¬†! It‚Äôs pretty popular too, lots of people using it. And you wanna know what I didn‚Äôt see? A post about hammers every other post! So why don‚Äôt nail gun fans go circlejerk about it over there instead of spamming the hammer Reddit with a bunch of shilling. Because if I wanted to read about fucking nail guns all day, I would be following the nail gun subreddit.\n\n  \n",
          "score": 1,
          "created_utc": "2026-02-09 19:56:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hq07q",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-02-09 20:12:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4i2x7k",
                  "author": "epyctime",
                  "text": "just testing the copypasta",
                  "score": 1,
                  "created_utc": "2026-02-09 21:16:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hvcdg",
          "author": "ifyoureallyneedtoo",
          "text": "This post inspired me to try codex and wow its infinitely better than claude",
          "score": 1,
          "created_utc": "2026-02-09 20:38:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hy7cq",
          "author": "IlliterateJedi",
          "text": "I agree. I'd love to see codex posts removed with a note that there is a whole sub for codex. I'm here for Claude code info and advice. If I want codex info I'll go to that subreddit.",
          "score": 1,
          "created_utc": "2026-02-09 20:52:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hmhu8",
          "author": "szxdfgzxcv",
          "text": "You know what? I'll start talking about codex even harder",
          "score": 1,
          "created_utc": "2026-02-09 19:54:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hkjud",
          "author": "randombsname1",
          "text": "Using both, still the same as I did previously:\n\nClaude Code for the majority of implementation and architectural planning. ChatGPT 5.3 High/Xtra high for reviewing and targeted bug fixes.\n\nIt's definitely not better than Opus 4.6 (at least for embedded work), but they DO both find stuff that the other misses.\n\nUse both if you can.\n\nAnyone that says Codex is definitely better, from a coding capability is absolutely lying though. \\*\\*At best\\*\\* it's a tie.",
          "score": 1,
          "created_utc": "2026-02-09 19:44:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j0mjh",
              "author": "linnth",
              "text": "Hmm isn't it technically codex's win if it's tie? The price factor.",
              "score": 1,
              "created_utc": "2026-02-10 00:12:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hnfg8",
          "author": "Leather_Carpenter462",
          "text": "Subreddits tend to become echo-chambers, so it's good to hear what's happening in the community. If you don't like it, you can just ignore it. It's not THAT incessant.",
          "score": 1,
          "created_utc": "2026-02-09 19:58:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hovfy",
          "author": "D-Oligosaccharide",
          "text": "Unfortunately, claudes code killed my family and forced me out of my own home forcing me to live as a beggar, where as codex code actually, ya know, works",
          "score": 1,
          "created_utc": "2026-02-09 20:06:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4igbat",
              "author": "Top-Pool7668",
              "text": "u/AskGrok is this true",
              "score": 1,
              "created_utc": "2026-02-09 22:23:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4igjfj",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-02-09 22:24:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4hqjkf",
              "author": "BigBootyWholes",
              "text": "Claude banged my mom and stole my dog",
              "score": 0,
              "created_utc": "2026-02-09 20:15:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4i02hr",
          "author": "Michaeli_Starky",
          "text": "Why are you so butthurt? I can't imagine any reason unless you're financially interested. Are you Anthropic's employee? Maybe it's time to get off your high horse?\n\nAnthropic has lost a LOT of reputation in the past months or so with limits getting nerfed, shady tactics like backing off to Sonnet when Opus was chosen, and releasing a model that's barely better than the previous one at 3x cost.",
          "score": 1,
          "created_utc": "2026-02-09 21:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4idahc",
              "author": "Top-Pool7668",
              "text": "The birds work for the bourgeois",
              "score": 3,
              "created_utc": "2026-02-09 22:08:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ivr30",
          "author": "lakimens",
          "text": "Well, that's what happens when Claude's userbase amounts to a rounding error for OpenAI..",
          "score": 1,
          "created_utc": "2026-02-09 23:45:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j4pu9",
          "author": "onemantooo",
          "text": "Maybe it's because Claude became shit in a past month for many users?",
          "score": 1,
          "created_utc": "2026-02-10 00:35:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j6da3",
          "author": "meandererai",
          "text": "The whole point is comparison shopping. When Sony comes out with new noise cancelling headphones, you are going to benchmark that experience against Bose. And if Sony surprisingly outshines Bose, that's noteworthy.\n\nOpenAI building something that outsmarts the gold mainstream standard foundational coding model is an upset. It's relevant.\n\nAnd unless you want Claude to stay stagnant, this upset should pepper the discourse so that the right competitive dynamics are witnessed, experienced and shared by enthusiasts of both. It is this discourse, that also feeds data points and feedback into Claude's ecosystem so that it improves also.\n\nThat's how things evolve. Otherwise, we would still be wearing those earbuds they pass out with in flight entertainment on the plane.\n\nCaveat: obviously the posts should be constructive. Not a lazy one-liner about how Codex rules.\n\nSo perhaps you mean, no lazy absolutes without substantiation and helpful detail.",
          "score": 1,
          "created_utc": "2026-02-10 00:45:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hy9vb",
          "author": "Tall-Log-1955",
          "text": "Oh muffin I‚Äôm so sorry!  It must be so hard to be you",
          "score": 0,
          "created_utc": "2026-02-09 20:53:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4huq1k",
          "author": "The_Real_Meme_Lord_",
          "text": "Codex sucks, returned that shit within hours of getting it.",
          "score": 0,
          "created_utc": "2026-02-09 20:35:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i2aqc",
          "author": "EarEquivalent3929",
          "text": "How dare anyone disturb the echo chamber.\n\n\nRecognizing other competitors and talking about it drives innovation. Alot can be derived from how codex works, thinks, operates and can be used in conjunction with Claude code to create a better workflow than either tool on their own.\n\n\nYou only hold yourself back by deciding to be a fanboy/fangirl",
          "score": 0,
          "created_utc": "2026-02-09 21:12:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ial4u",
          "author": "Round_Mixture_7541",
          "text": "Hit the nerve i guess",
          "score": 0,
          "created_utc": "2026-02-09 21:54:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hvk4t",
          "author": "DinnerInfamous128",
          "text": "I guess you were also mad when 1 year ago almost all LLM messages where spammed by Claude users.\n\nPeople like to share when there is something new rocking it, you should just chill.",
          "score": -1,
          "created_utc": "2026-02-09 20:39:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i1v1g",
          "author": "syddakid32",
          "text": "ITS CAUSE CLAUDE IS THE FUCKING BEST! We're to busy building shit and winning to try to spread propaganda ",
          "score": -1,
          "created_utc": "2026-02-09 21:10:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hwezg",
          "author": "1millionbucks",
          "text": "https://preview.redd.it/0xokrn1h6jig1.jpeg?width=750&format=pjpg&auto=webp&s=96e904ccb98c832c74362db9af722a2703603df1\n\nshitposting LIVE from OP's basement",
          "score": 0,
          "created_utc": "2026-02-09 20:44:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i7604",
          "author": "kcabrams",
          "text": "That ain't unpopular at all my friend.",
          "score": 0,
          "created_utc": "2026-02-09 21:37:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyik8l",
      "title": "Claude Opus 4.6 vs GPT-5.3 Codex: The Benchmark Paradox",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/plrvnxekp3ig1.png",
      "author": "Much_Ask3471",
      "created_utc": "2026-02-07 16:42:21",
      "score": 243,
      "num_comments": 130,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial / Guide",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qyik8l/claude_opus_46_vs_gpt53_codex_the_benchmark/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o43y9ll",
          "author": "nospoon99",
          "text": "If you can afford $120 get the best of both instead of $200 all on Claude. Get Claude\n Max X5 + Codex for code review.",
          "score": 82,
          "created_utc": "2026-02-07 17:13:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o445msm",
              "author": "4444444vr",
              "text": "Claude for code and codex for review is what I‚Äôve been doing for a while. It‚Äôs a good combo (but been doing more code with codex lately)",
              "score": 26,
              "created_utc": "2026-02-07 17:49:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o45hqxe",
                  "author": "ALargeAsteroid",
                  "text": "What‚Äôs your workflow for using both?",
                  "score": 1,
                  "created_utc": "2026-02-07 21:59:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o45s7ap",
                  "author": "aszet",
                  "text": "How do you have this setup? Is it just two terminal windows one for Claude and one for codex? Then ask codex to review the latest changes? If so what‚Äôs the prompt?",
                  "score": 1,
                  "created_utc": "2026-02-07 22:58:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o47k8jb",
                  "author": "enoteware",
                  "text": "Me too. Ive been using traycer lately and love it. Does this but in a more structured way.",
                  "score": 1,
                  "created_utc": "2026-02-08 06:01:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o44lc79",
                  "author": "LowSyllabub9109",
                  "text": "Could I know the reason? Is it better than 4.6? Any recommendation? ",
                  "score": 0,
                  "created_utc": "2026-02-07 19:07:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o44jjq5",
              "author": "belheaven",
              "text": "This is the champion workflow. I was 20x then 5x and now $20 pro + gpt $20 + $10 Copilot and I can build anything I need.",
              "score": 5,
              "created_utc": "2026-02-07 18:58:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o44rqi3",
              "author": "Western_Objective209",
              "text": "The issue I have is even if codex is better, for difficult problems it takes like 20-30min of thinking, when I could find the issue myself in 10min. An issue that codex can fix but opus cannot is also exceedingly rare. I just honestly don't use codex anymore, even if I am paying $20 for ChatGPT",
              "score": 3,
              "created_utc": "2026-02-07 19:40:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o44vmm1",
                  "author": "Outrageous-Thing-900",
                  "text": "Try forcing codex to use subagents, I noticed it really speeds things up and uses about the same amount of tokens",
                  "score": 3,
                  "created_utc": "2026-02-07 20:00:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o48ttrj",
                  "author": "badlucktv",
                  "text": "5.3-Codex has made this a bit more livable for me at least, definitely faster.",
                  "score": 1,
                  "created_utc": "2026-02-08 12:53:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4a0p7s",
              "author": "Singularity-42",
              "text": "I have Max 5 and ChatGPT Plus sub, been a Claude Code fan since mid last year, but I'm more than open to trying Codex. Is there a CLI now too? What's the best workdlow to use Codex as a supplement to Claude Code?¬†",
              "score": 2,
              "created_utc": "2026-02-08 16:51:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o43yed4",
              "author": "Much_Ask3471",
              "text": "yeap sandwich thing i mentioned in the post.",
              "score": 3,
              "created_utc": "2026-02-07 17:13:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o43ymdt",
                  "author": "nospoon99",
                  "text": "Aah yes indeed, great recommendation",
                  "score": 2,
                  "created_utc": "2026-02-07 17:15:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4417yb",
              "author": "Lifedoesnmatta",
              "text": "And if you don‚Äôt want to always wait for limits to reset, just get a couple Codex business seats. And $20 antigravity",
              "score": 3,
              "created_utc": "2026-02-07 17:27:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o448w4i",
                  "author": "Xisrr1",
                  "text": "$20 Antigravity is not worth it anymore. They slashed the quotas completely.",
                  "score": 2,
                  "created_utc": "2026-02-07 18:05:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o44vesl",
              "author": "Outrageous-Thing-900",
              "text": "You can get codex really cheap for like 3-4 usd a month per account on reselling websites",
              "score": 0,
              "created_utc": "2026-02-07 19:59:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o496vyv",
              "author": "martycochrane",
              "text": "I've tried that but Codex just hallucinates things too much to be useful. What I've been doing lately is Opus for planning and coding then I have an agent that uses the new CodeRabbit CLI to do the review and that has been working great, especially if you've been using CodeRabbit for a while because it already has a bunch of learning about your code base built up.",
              "score": 0,
              "created_utc": "2026-02-08 14:17:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o43tikc",
          "author": "Bob_Fancy",
          "text": "Benchmarks are worth little in most cases and at this point these things are fractions of a percentage different in how good they are.  It‚Äôs much more about which fits you and your work flow best.",
          "score": 21,
          "created_utc": "2026-02-07 16:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xtk7",
              "author": "Much_Ask3471",
              "text": "true",
              "score": 3,
              "created_utc": "2026-02-07 17:11:06",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o44k96w",
              "author": "Lankonk",
              "text": "I‚Äôd argue that they‚Äôre very good at different things that are much more difficult to test for than what current benchmarks are able to detect.",
              "score": 2,
              "created_utc": "2026-02-07 19:01:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o44dyj5",
              "author": "Manfluencer10kultra",
              "text": "yup yup, this is what I just realized.",
              "score": 1,
              "created_utc": "2026-02-07 18:30:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o461win",
              "author": "OkBet3796",
              "text": "Benchmarks are most likely curve fitting at this point. My idea is to see LLMs as a toolbox. Sometimes u need a hammer, sometimes you need a screwdriver.\nTry to figure out, which one serves which purpose best and choose what fits the task the best",
              "score": 1,
              "created_utc": "2026-02-07 23:58:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o441cl3",
          "author": "sputnik13net",
          "text": "The real answer is use both, or all 3. If it‚Äôs for real high paying work then the $200 tier for all 3. I have the $20 tier for all 3 for home projects and I love it. At work where my company pays for it I still use all 3, because it‚Äôs cheaper than having me waste time on small things.\n\nI like how smart opus is but it runs out of credits so fast I use it more for initial design on things I want to get right the first time. For anything requiring iteration I‚Äôm doing codex. Gemini is just there because it was cheapest and it‚Äôs useful for doing small things or churning through huge docs. I might play with antigravity at some point.\n\nEnd of the day these are all just tools, make use of them as much as you need to make yourself more efficient and if it doesn‚Äôt then stop using it.\n\nOne of my favorite things to do lately is at the end of a task turn on highest thinking version of all three and have them provide feedback on the work. It ends up getting some marginal improvement and worth the hour or two of credits it burns through.",
          "score": 8,
          "created_utc": "2026-02-07 17:28:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44dh8z",
              "author": "raiffuvar",
              "text": "Who is the 3d ? \nSorry, gemini you was not invited.",
              "score": 4,
              "created_utc": "2026-02-07 18:28:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o44fad2",
              "author": "Manfluencer10kultra",
              "text": "Gemini is all over the place imho, on web it is pretty OK for brainstorming, but in Antigravity it's just overzealous and intrusive.  \nI've just canceled my Google AI subscription, and also not gonna use Antigravity anymore.  \n\\- Antigravity pros: Really good (but slow) tab completion for refactoring many instances of x -> y in one file, and remembers multiple refactorings across files. So if I change some var and some docstring in a certain way it is consistent over other instances.\n\nThat's about it.  \n\\- Cons:  \n \\- Eats mem like prime rib.  \n\\-  Claims cpu resources for its (seperate!) language server like it's the only thing you need running.  \n\\- Many broken extensions (preview for everything broken for some reason).  \n\\- Overrides Ty (which provides grayed out type hints in the code for what the method / class expects/returns) which is very very useful, but they don't show up in Antigravity.\n\nBasically only was using it for extra Claude access (severely limited now), and Gemini is useful only for some minor bug fixes.  \n  \nBut you can try it. I've switched back to VSCode.  \n",
              "score": 1,
              "created_utc": "2026-02-07 18:37:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o44gepg",
                  "author": "sputnik13net",
                  "text": "I have it because I already have the $100/year family storage sub, it only cost $100 more a year for me to have for web research and on those rare occasions I run out of both Claude and codex tokens. It‚Äôs not half bad with Gemini CLI caveat it‚Äôs just aggressive about going and doing shit before I tell it to. I have strict rules telling agents to be in plan mode until I explicitly say implement, Gemini CLI will just ignore all of that on whim.",
                  "score": 1,
                  "created_utc": "2026-02-07 18:42:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o43z3eu",
          "author": "sizebzebi",
          "text": "switched to codex and I can only speak for pro vs plus. codex plus offers so much more, it's ridiculous",
          "score": 7,
          "created_utc": "2026-02-07 17:17:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4giait",
              "author": "vexmach1ne",
              "text": "You mean pro? If not please explain, I'm interested.",
              "score": 1,
              "created_utc": "2026-02-09 16:43:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4gj3vs",
                  "author": "sizebzebi",
                  "text": "ChatGPT plus vs Claude Pro around same pricing\n\nalso important to add that codex is doubling the usage for 2 months so it's not always gonna be like this but even at half of what I'm doing right now with codex is so much more than what I can do with Claude",
                  "score": 2,
                  "created_utc": "2026-02-09 16:47:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o445x8w",
          "author": "Manfluencer10kultra",
          "text": "I've just posted this comment in another thread, but I like to spam my thoughts, so here we go again:  \n  \nSo I've just been experimenting a little bit with Codex inside VSCode, and even with GPT 5.2-Codex im being more productive.  \nMy annoyances with Claude Code have only grown since the last updates. It ignores my workflows, sometimes partially and basically it's forcing me to turn on thinking / high effort on Opus 4.6 or its unusable.  \nAnd it drains tokens.\n\nI haven't really tried Claude inside VSCode yet, because It was very buggy before and didn't allow for queued messages to propagate until work was finished, only allowing for hard interrupts. This might have changed but I haven't tested it.\n\nIn any case, I'm liking Codex in VSCode, because I feel more like im actively staying hands-on with decisions. It respects the rules, boundaries and understands the workflows perfectly. When asking about technicalities about implementations, it analyses the problem; gives me thorough insight and available options; It explains technicalities in-depth if asked to, searches the web for best conventions if asked to, and doesn't require me to press enter on things that I request (and thus accept beforehand).\n\nIt is a little bit of extra typing work to reference all the correct files, but honestly, it's a better and more productive work flow than letting Claude Code trip over its own tooling\n\nMy experience with Claude Code as of late? extensive tooling use; ignoring available mcps or silently failing them if they don't work; forgetting context because it fails to follow the workflows; project-plan workflow and planning mode conflicting thus I have to spend double tokens on just writing its artifacts to my projects ./plans dir.\n\nCodex in VSCode gives me what I love about web based brainstorming with the addition of directly implementing decisions.  \nClaude wants to first write very length docs, oh how it loves to write .md files. But then it just fails on core tenants and have used multiple sessions for somethin that was basically 30 LOC, already demonstrated in referenced project and just required implementation in existing work.  \nNot good for my health: I get frustrated because \"CLAUDE SHOULD JUST DO IT\" instead of just doing it myself. It's not even making sensible choices in terms of development. It keeps copies of old implementations side by side with requested, and then when its context is degraded and I have to start a new convo (either autocompact, or avoiding autocompact), it doesn't read the original plan files... it just goes straight into implementation and re-testing things that were already tested, and then just doing 10% of the work.\n\nAs you can read...Ive made my decision.  \nIm going to switch to the very cheaper codex plan, and enjoy GPT 5.3-Codex ...since im already enjoying GPT 5.2-Codex, no brainer.\n\nIll be putting Claude on high effort with thinking to burn through the usage for the month, and unsubscribe. The 42 euro free was nice, but seeing as how little actually I'm getting out of it.. it's just another Anthropic \"christmas gift\" to me.\n\nMaybe it's just that terminal based is not for me. I'm definitely not a one-shotter. I'm an architect. I only one-shot when I have my own frameworks/generators and conventions well established and differentiatedcreated.  \n  \nBut when it comes to hybrid data layers involving AI stuff, and some lack of experience in some languages (health issues, only got on the python + AI bandwagon since august despite 25+ years dev experience), I just require more explaining to be able to actually define some technicalities better.  \nIf I don't, I don't end up with bleeding edge high-performance, event driven and scalable (all the things I crave) but extensive boilerplating and frequent swearing and broken keyboards.",
          "score": 6,
          "created_utc": "2026-02-07 17:51:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44hex3",
              "author": "raiffuvar",
              "text": "Ypi are absolutely....You're probably doing something wrong (Opus 4.5 was great with skills and prompts), but before version 2.x.x, it was a mystery which skill was being used and may be your skills were not working. \nI ran a modified Ralph loop perfectly fine(with compactions), and it followed my complex task structure: folder with subfolders and files. \n\nBut... I set up and wrote all the skills with Codex.\nOh well, I also keep the main agents.md in XML, just because...(may be it was the \"difference\"). \n\nAnyway, I agree with the rest of your rant. They should focus more on Claude than on making ads against OpenAi. \nCodex just works, while opus eat eat eat tokens.. and super unstable from time to time. \nAlso 200k limit which is 150k at best with \"compaction\" and 30k for sys prompt -> 120k. Vs pure 250k from openai.",
              "score": 3,
              "created_utc": "2026-02-07 18:47:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o45ccl1",
                  "author": "Manfluencer10kultra",
                  "text": "Oh yeah, it's half broken by my own doing. I gave Claude free reign in updating md docs,  skills/rules, and didn't properly scrutinize them, I thought it would be doing itself a favor). But partially it's also Anthropic's doing because my project plan workflow was working consistently, despite the issues with documentation drift. It stopped working after updates + planning mode started to take precedence over my workflows a few weeks ago. I believe this is straight up enforcement from the Claude devs, as a coping mechanism for it's shortcomings (i.e.g without it, it is lost).  \nThey don't think about that there are users who want to EXTEND on the planning features by having an extended workflow with project stored plans/todo lists, smaller work session logs, BACKLOG and commits.  \nYes, I could do something else like create github issues for everything and do pull requests, but A) If you're solo'ing that's just cumbersome and silly, and pretty sad and lonely to be honest talking to yourself in github issues. B) Switching is faster.  \n  \nI see Codex just handles my workflows just fine.  Then I know it's not the workflow, it's the provider, choice is \"B\".",
                  "score": 1,
                  "created_utc": "2026-02-07 21:30:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o446e1x",
              "author": "Much_Ask3471",
              "text": ">",
              "score": 1,
              "created_utc": "2026-02-07 17:53:37",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o48cv48",
              "author": "FarBuffalo",
              "text": "I'm using terminal based cc+codex only and it works best for me, ide only to manually review the changes before commit. And I've jetbrains ultimate subscription.   \nI've tried antigravity - trash, cursor seems to be ok, I liked it but there're limited tokens for pure gpt 5.2  so anyway I'like to buy chatgpt as web version gives better results. ",
              "score": 1,
              "created_utc": "2026-02-08 10:26:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o49bz4z",
                  "author": "Manfluencer10kultra",
                  "text": "Computer boot today -> fans spinning up -> htop -> see 10 antigravity processes spawned at computer boot connecting to remote server wtf. Purged\n\nCursor? Not liked the idea of paying for not selling my privacy.  \nI think I'm on the promo now or something, bcz im using GPT5.2 codex like a lot now (Free plan) and still showing 57% for the week.  \nPretty amazing.  \nI'm actually pretty scared now to switch back to Opus.  \nToday was very productive in interactively with Codex to map out the system in mermaid charts, create a skill for it, then later use the mermaid charts to fill the gaps to further development.\n\nI think GPT models are just better for this. They were soft-skilled models to begin with, and piss poor in coding. Now GPT has caught up with Claude in terms of coding, I think these soft skills make the difference. It acts more like a co-developer rather than a Mechanical Turk (Claude).",
                  "score": 1,
                  "created_utc": "2026-02-08 14:46:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o49dtdo",
                  "author": "Manfluencer10kultra",
                  "text": "u/FarBuffalo \"I've jetbrains ultimate subscription.\"  I used to be on Jetbrains and paying for it. Literally have no idea why you wouldn't be switching to free Visual Studio Code that works for everything. It's just so much better and lighter than full blown Java IntelliJ",
                  "score": 1,
                  "created_utc": "2026-02-08 14:56:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o443dmo",
          "author": "Careless_Bat_9226",
          "text": "I've come to the same conclusion. I build with Opus and review with Codex. Codex just seems smarter spotting bugs/issues but Opus feels better for building and the tooling is better.\n\nAlso, I‚Äôm amazed that anyone who does this professionally would try to scrape by on the $20 plan. Even $200/month is a bargain for the benefit I get out of Claude Code.¬†",
          "score": 9,
          "created_utc": "2026-02-07 17:38:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45a3sc",
              "author": "Ok_Employee9638",
              "text": "$200 / month plan is non-negotiable as it's how I pay my mortgage. Agreed.",
              "score": 3,
              "created_utc": "2026-02-07 21:19:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4j4lr6",
                  "author": "TheReedemer69",
                  "text": "What do you do?",
                  "score": 1,
                  "created_utc": "2026-02-10 00:35:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44uy4r",
          "author": "Flat_Association_820",
          "text": "Ever since GPT-5-codex has been out, my main has been Codex, I only use Claude Opus for small taskes. I'd probably use Claude more, if I was a web dev, but otherwise use Claude too much ends up in increased overhead maintenance.\n\nSo, for me, if I only had $200, I'd go with codex all day.",
          "score": 3,
          "created_utc": "2026-02-07 19:57:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45wsal",
              "author": "straightouttaireland",
              "text": "Is Claude better for web dev?",
              "score": 2,
              "created_utc": "2026-02-07 23:25:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46pail",
                  "author": "Flat_Association_820",
                  "text": "Yeah, that's where Claude outclasses Codex. ",
                  "score": 1,
                  "created_utc": "2026-02-08 02:22:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o46hbn5",
          "author": "Lucidaeus",
          "text": "How's Codex on windows now? Last time I tried it, it was awful to work with. The output was fine but the workflow was a pain in the ass.",
          "score": 4,
          "created_utc": "2026-02-08 01:32:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46z4q8",
              "author": "Much_Ask3471",
              "text": "Idk about windows",
              "score": 1,
              "created_utc": "2026-02-08 03:25:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o47mm7r",
              "author": "ashjohnr",
              "text": "CLI is still a little buggy, mainly the TUI, although the output is still better than Opus 4.6. If using an IDE (at least VSCode fork), you can use the Codex extension, lot less buggy imo.",
              "score": 1,
              "created_utc": "2026-02-08 06:21:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44epr8",
          "author": "Soft-Dot-2155",
          "text": "Codex limits are way better than Claude‚Äôs, so you end up using Codex most of the time",
          "score": 7,
          "created_utc": "2026-02-07 18:34:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46yjrr",
              "author": "Much_Ask3471",
              "text": "Yeap",
              "score": 1,
              "created_utc": "2026-02-08 03:21:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4448ep",
          "author": "Global-Molasses2695",
          "text": "Complete nonsense. GPT 5.3 hands down if you are working on any serious project or ‚Äúreal‚Äù app. Sure if you are a vibe coder building so call ‚Äúapps‚Äù on Vercel/supabase sure you can survive with Claude - begs the question though why bother when that‚Äôs table stakes for Codex.",
          "score": 7,
          "created_utc": "2026-02-07 17:42:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o444v40",
              "author": "Much_Ask3471",
              "text": "i tested codex in low level languages bro.  \nit performed well and i used fro e2e testing that too works good.  \nand i used even codex 5.2 in trpc also.  \nclaude is also good but claude try to complete the test whether it is fine or not and codex try to complete the task but fulfill things .  \nclaude is too good for planning or shipping v1.",
              "score": 2,
              "created_utc": "2026-02-07 17:46:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o44sqoy",
                  "author": "Global-Molasses2695",
                  "text": "Yeah and try reviewing the kind of redundant tests Claude writes to push up cov stats, giving false confidence, that keeps falling apart as your app grows.  As I said, if the use case is to just shell out a ‚Äúso called app‚Äù as MVP1 sure you can use Claude. That‚Äôs table stakes for Codex anyway. Codex is a complete beast - I had an old repo with over 4000 lint issues; don‚Äôt need a lecture on ESlint; Codex ran at night unattended for over 6 hrs, surprising me in morning with zero lint issues and more importantly zero TSC issues as a byproduct of you know what I mean.",
                  "score": -1,
                  "created_utc": "2026-02-07 19:45:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o44x47w",
              "author": "ajr901",
              "text": "Codex cli is shit compared to Claude Code though. And the codex app also sucks compared to the claude app or claude code. So even if 5.3-codex is 10-20% better than Opus 4.6, the productivity improvements I gain from using CC, personally, to me, outweighs 5.3-codex. \n\nThe codex team need to bring codex cli up to feature parity with cc asap or anthropic will release their next model and they'll have missed their window until _their_ next release.",
              "score": 3,
              "created_utc": "2026-02-07 20:08:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o453nnn",
                  "author": "Global-Molasses2695",
                  "text": "What exactly are you missing in Codex CLI ?",
                  "score": 1,
                  "created_utc": "2026-02-07 20:44:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o443xlp",
          "author": "wifestalksthisuser",
          "text": "I ran through my weekly limit + the 50 bucks Anthropic gave us for free + another 20 bucks, so I got the Plus sub for Codex to try it out on my codebase (~ 25K LOC backend-code). I also have Gemini but it's genuinely trash. Anyway, Codex on 5.3-xhigh works really well for bugfinding, fixing and reviewing existing working code. I have a specific workflow I use for new features and for that I'll be sticking to Claude Code, but working on existing stuff is probably going to be codex going forward. Gives me enough to not run into limits on a normal weekly workload",
          "score": 2,
          "created_utc": "2026-02-07 17:41:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44fp7q",
              "author": "Manfluencer10kultra",
              "text": "Yeah I agree that the difference - not want to put words in your mouth - between Codex and Claude is night and day when it comes to re-visiting existing code with inconsistent patterns (put in there by Claude himself ugh).  \nClaude really loves to write huge docs but not maintain them, and it just compounds the issues.",
              "score": 2,
              "created_utc": "2026-02-07 18:39:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4456ff",
              "author": "Much_Ask3471",
              "text": "yeap this is too true , codex is good here and biggest issue is limit ngl.",
              "score": 1,
              "created_utc": "2026-02-07 17:47:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o44mh59",
              "author": "LowSyllabub9109",
              "text": "Nice, could you share your workflow? Also does 5.3, is head to head with 5.6? ",
              "score": 1,
              "created_utc": "2026-02-07 19:13:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44i22w",
          "author": "literally_joe_bauers",
          "text": "‚Ä¢ No API: Currently locked to the proprietary app, making it impossible to integrate into a real VS Code/Cursor workflow.\n\n‚Äî> This is not true, I am running it fully integrated in my autonomous coding framework and it performs great‚Ä¶ however, for more complex stuff (CUDA, C, etc.) gpt 5.2 xhigh works better in my setup..",
          "score": 2,
          "created_utc": "2026-02-07 18:50:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46ywbh",
              "author": "Much_Ask3471",
              "text": "Talking about 5.3\nRead the title dude.",
              "score": 1,
              "created_utc": "2026-02-08 03:23:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o45cdtx",
          "author": "driveheart",
          "text": "Why am I tired of reading such comparisons every month? It has begun to give me the taste of iPhone vs Android.",
          "score": 2,
          "created_utc": "2026-02-07 21:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45ety2",
          "author": "damndatassdoh",
          "text": "Spent weeks using Codex 5.2 with a $200 sub.. end result was nothing even approaching usable..\n\nThen, took the project to Claude, $200 sub. Suddenly, within a few sessions, we had refactored into something semi-functional.. A few days later, it was working. A few months later..\n\nClaude gets it done.",
          "score": 2,
          "created_utc": "2026-02-07 21:44:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o464toy",
          "author": "Dry-Broccoli-638",
          "text": "Lol nice ai take: \n\n‚Ä¢ Workflow Integration: It is available immediately in major IDEs (Windsurf, Cursor), meaning you can actually use it for real dev work\n\nPlenty of real dev work is now outside of IDEs.",
          "score": 2,
          "created_utc": "2026-02-08 00:16:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46z3wj",
              "author": "Much_Ask3471",
              "text": "But u have to stick with OpenAI plan only whether u use cli or ide.",
              "score": 1,
              "created_utc": "2026-02-08 03:25:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46nije",
          "author": "pfak",
          "text": "> The \"CAT\" Bug: Still uses inefficient commands to write files, leading to slow, error-prone edits during long sessions.\n\n\nCC does this all the time. It forgets write() exists.¬†",
          "score": 2,
          "created_utc": "2026-02-08 02:11:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47uaff",
          "author": "antonlvovych",
          "text": "Agree with everything. I have both Max 20x and OpenAI Pro. Worth mentioning, Codex has bigger context",
          "score": 2,
          "created_utc": "2026-02-08 07:31:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43zaez",
          "author": "TheAuthorBTLG_",
          "text": "\"If you can't integrate it into your IDE, the model's intelligence doesn't matter.\"\n\ni stopped using an IDE",
          "score": 4,
          "created_utc": "2026-02-07 17:18:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43zh8o",
              "author": "Much_Ask3471",
              "text": "i stopped writing code",
              "score": 2,
              "created_utc": "2026-02-07 17:19:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o441dbk",
                  "author": "BootyMcStuffins",
                  "text": "Then what does an IDE matter?",
                  "score": 1,
                  "created_utc": "2026-02-07 17:28:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o441n01",
              "author": "jackmusick",
              "text": "6 months ago I was really stuck on something specific in an app I‚Äôve been working on, which was basically letting users hit breakpoints in code they deploy to my platform. You can do it but in hindsight, I haven‚Äôt written a single line of code or hit a breakpoint in that long. Not only do the tools get it right more often than not, they‚Äôll quickly spit out long strings of test code to eliminate the need in the first place. Stuff that would‚Äôve taken me more time than just hitting F5 and toggling a few lines. \n\nWild times we‚Äôre living in.",
              "score": 1,
              "created_utc": "2026-02-07 17:30:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o45sw5f",
              "author": "disgruntled_pie",
              "text": "Yup, checking diffs is the only time I really open an editor anymore.",
              "score": 1,
              "created_utc": "2026-02-07 23:02:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o45wb8i",
              "author": "straightouttaireland",
              "text": "I still use an IDE to browse files and also do a final code diff review. I can't get away from it.",
              "score": 1,
              "created_utc": "2026-02-07 23:22:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o448t8p",
          "author": "sheriffderek",
          "text": "I have opus write my function names and then codex write my opening braces because it‚Äôs more technical and then I have sonnet write a poem about the body and then I use opus to read that poem and get in the mood - and then it can write the function body - but since a it‚Äôs Anthropic and models exist and things - then I have codex debug it because it‚Äôs better at understanding the code that Claude just wrote and I like to just jump between things over and over and I don‚Äôt understand context windows and how any of this works. That way I can jump between agents every other day to save a little money and I make sure to write about it daily on this sub since I have so much extra time. Get 2 $100 plans instead of a $200 plan because more is better. ¬†;)",
          "score": 3,
          "created_utc": "2026-02-07 18:05:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43tcq1",
          "author": "policyweb",
          "text": "If you only have $20, use Kimi 2.5. And if you have $$$ why not get the best thing?",
          "score": 3,
          "created_utc": "2026-02-07 16:49:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xox0",
              "author": "Much_Ask3471",
              "text": "i will try kimi also and lets see how it performs and for 20 dollar claude code dont make sense.",
              "score": 1,
              "created_utc": "2026-02-07 17:10:28",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o43tknk",
              "author": "policyweb",
              "text": "Kimi‚Äôs 1st month subscription is $0.99 btw",
              "score": 0,
              "created_utc": "2026-02-07 16:50:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o43xs8e",
                  "author": "Much_Ask3471",
                  "text": "nice, there are free models also in opencode check them.",
                  "score": 1,
                  "created_utc": "2026-02-07 17:10:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44dxht",
          "author": "MetehanDev",
          "text": "How is Codex not integrated with any IDE? I use it in my VS code and Rider(jetbrains ides) with ease.¬†",
          "score": 2,
          "created_utc": "2026-02-07 18:30:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44fra2",
              "author": "Much_Ask3471",
              "text": "talking about codex 5.3 not 5.2 as they havent released api key for codex 5.3, so u cannot use them in ide.",
              "score": 0,
              "created_utc": "2026-02-07 18:39:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o44h8ws",
                  "author": "MetehanDev",
                  "text": "Oh ok then that make sense. But it probably will be released in no time, they just want attention on the new codex Mac app before that.¬†",
                  "score": 1,
                  "created_utc": "2026-02-07 18:46:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4527e2",
                  "author": "Crinkez",
                  "text": "\"IDE\"s are inferior at the moment anyway so it doesn't really matter. Use Codex CLI.",
                  "score": 1,
                  "created_utc": "2026-02-07 20:36:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44764i",
          "author": "zegrammer",
          "text": "Is this why the app is so bad",
          "score": 1,
          "created_utc": "2026-02-07 17:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44tm0d",
          "author": "hesseladam",
          "text": "Do anyone have a recommendation on a workflow to have like Claude code cli be able to review codex implementations live an respond and send the next prompt to codex without me having to be the middleman and send the prompts between? Or is that what clawdbot could be used for?",
          "score": 1,
          "created_utc": "2026-02-07 19:50:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48earm",
              "author": "FarBuffalo",
              "text": "my workflow is not optimal - just I've 2 terminals opened on same project. After job is done I ask codex to review uncommited changes. And the copy-paste the important part of the review to cc and ask to review if they the feedback makes sense. In 80% it does",
              "score": 1,
              "created_utc": "2026-02-08 10:40:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o47qgwm",
          "author": "yopla",
          "text": "I shelled out for a month of gpt plus Friday and I've been using codex for the first time for two days straight on various projects and I don't recognize my experience in your description.\n\nI've used it on various projects :\n\n- A from scratch it to bootstrap at ypescript  react/rest with integration with a 3rd party service for a tool I needed.\n- A c++ ESP32 service I'm currently working on when I have time for my smart home\n- A very large codebase for a complex financial system\n- A design spec for the ultimate financial system, basically a bunch of deep research on the topic and production of BRD and technical spec for the system.\n\nI am honestly very impressed. It is very good at implementation.\n\nFor the tools:\n\nFrom the CLI perspective Claude has an edge, it has more features, it is more robust and it handles multiple agents better, or at least it seems too.\n\nCodex desktop is actually quite nice, between the diff window, voice prompt and the open vscode button, I eventually enjoyed it more than the CLI.\n\nFor the model:\n\nI found GPT in \"speak professionally mode\" very efficient, no emotion, it doesn't behave like a cheerleader and seems to be much more ready to push back and give realist technical opinion. It's also much more proactive to request clarification and identify edge cases.\n\nI found it to have a better adherence to the tasks, when Claude sometimes \"lies\" about work being done or goes off on a side quest, GPT has been on point and focussed.\n\nI've seen a few edit issues, probably less than Claude, but nothing blocking, it always recovered quickly. Certainly not gemini bad levels.\n\nGPT is a better \"finisher\". Claude gets the work done but usually leaves a devastated field behind him, I need hooks and skills and claude.md reminder not to leave a bloody trail of linting errors behind. During my whole test GPT has been systematically cleaning all the linting issues CAYGO style without being asked specifically. I didn't have a single task that didn't end with a working build and zero linting issues. Claude... Well... Not my experience... More like *\"those linting errors are not from my change, so I won't fix them and ok, I fixed two out of 300, let me mark the task complete and move on\"*. It's actually just as hard to motivate Claude to fix the linter than it is with a human. \n\nGPT behaved better on a very long session. Claude's context management has been subpar forever. I've even let one of the GPT sessions run-on for a whole day without ever feeling that it had lost the plot.\n\nOne very large codebase, well, it really wasn't bad honestly but our codebase is heavily documented (a job that was done for earlier versions of Claude) so that always helps a lot and our codebase is mostly well organized and modular so there not really a case for an LLM to be looking at more than one or two modules at the same time. I've built a couple of features and it was fine, slower than the from scratch project obviously but largely ok. It seemed to have a better grasp of the purpose but I can't objectively quantify that.\n\nWhich brings me to domain understanding, at least the one I work in, and GPT is by far the best, I've ran the same design task with the same starting prompt in Claude, gpt and gemini and GPT is so much more thorough and accurate and the result are much more logically organized and I honestly had to really strain to find inaccuracies, the actuarial models were correct and it got the legal requirement across geographies 90% correct, gemini is second best its biggest failure was assuming UK law applied everywhere and getting obsessed with integration standards which are more marketing than reality, Claude made the least effort, the output had the least in depth, the domain understanding had a few more errors and the understanding of the legal framework mixed up multiple regulation between the US, Europe, UK.\n\nGPT's implementation would have had us apologize to the regulatory body for the mistake and get off with a warning, Claude's would have resulted in a fine and probably an audit.\n\nGPT was not very good at UI work at least not at making stuff pretty, that has been a drag. That said, Claude isn't great either but still better. Even gemini has more flair than GPT.\n\nMy task was unfair but I just ask them for ideas to improve the UI look and both Claude and Gemini propose some decorative adjustment among other things but GPT is all about WCAG compliance with subsection 42.4.6 rev2 and whatnot. so yeah, that IS an important UX question, but it does nothing for the styling. Good technician, terrible artist. I want art goddamnit! üòÜ\n\nIn the end they are honestly both very good models, frankly on par with each other but the price difference is not even funny. The amount of value I got out of $30 with the plus subscription compared to anthropic's pricing is wild. \n\nI don't know where I am in my quota but very honestly I was so used to anthropic's limits that I was truly expecting to spend half a day on my tests and be told to bugger off and go see the sun and it just keeps on going....\n\nI would say, if you have a small budget, go for gpt, if you have a large one, do give it a try and ponder whether that extra 100 isn't better used buying something else.",
          "score": 1,
          "created_utc": "2026-02-08 06:56:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47su1p",
          "author": "Isunova",
          "text": "I prefer Codex. I cancelled my Claude sub.",
          "score": 1,
          "created_utc": "2026-02-08 07:18:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o481imp",
          "author": "hannesrudolph",
          "text": "You can use it within vscode and cursor with Roo Code.",
          "score": 1,
          "created_utc": "2026-02-08 08:39:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o482g2f",
          "author": "Alarming-Material-33",
          "text": "My experience the past few days with Opus 4.6 has been bad. I feel like it forgets to do things even with a plan. Codex on the $20 plan goes a long way",
          "score": 1,
          "created_utc": "2026-02-08 08:48:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48b1e4",
              "author": "FarBuffalo",
              "text": "yes, today opus 4.6 is so stupid it drives my just crazy. even before I'd like check claude output with chatgpt claude liked to simplify the solutions and assuming facts but now I've to exactly tell him like everything",
              "score": 1,
              "created_utc": "2026-02-08 10:09:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48f4c8",
          "author": "seabromore",
          "text": "If you need opus and codex and you have limited budget, just... \n\nSpend money for cursor pro or pro+ subscription ($20 or $60 per month) - easy and best solution. \nYou will have acces to all models, you can build simplest features with almost free auto model and hard features with opus/codex/gemini/anything. \n\nAnd last hint, but perplexity pro, it provide you 5 usd for api per month, connect perplexity MCP to your cursor and ask agents to use it. It will provide excellent results in 90% cases.",
          "score": 1,
          "created_utc": "2026-02-08 10:48:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ivd0",
          "author": "MetalGuru94",
          "text": "In my use case, Codex performed much better than Claude. I am working on a fairly complex Next.js app. Claude kept introducing bugs, changed package.json to older lib versions and afterwards used deprecated code, introduced many unnecessary bugs or did changes I never asked for. I do believe the model is amazing and works for many use cases, but in mine, I just use Codex more as it performs better.",
          "score": 1,
          "created_utc": "2026-02-08 11:22:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48uvip",
          "author": "revistabr",
          "text": "Claude has the Edge because of DOE and subagents",
          "score": 1,
          "created_utc": "2026-02-08 13:01:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49n88p",
          "author": "BlueSummitCG",
          "text": "This was very helpful! Thank you!! üôèüèª",
          "score": 1,
          "created_utc": "2026-02-08 15:45:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b0dct",
          "author": "Competitive-Fly-6226",
          "text": "I am not an expert but gpt 5.3 is much superior! Claude is just a hype thing and most like to be fashionable! IMO",
          "score": 1,
          "created_utc": "2026-02-08 19:41:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g4sqa",
          "author": "Eleazyair",
          "text": "Wow that‚Äôs the complete opposite take. Codex is much better at apps than Claude as it stands.¬†",
          "score": 1,
          "created_utc": "2026-02-09 15:38:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i936w",
          "author": "GoldAd5129",
          "text": "CCodex has been best for me",
          "score": 1,
          "created_utc": "2026-02-09 21:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43x7vi",
          "author": "Inevitable_Service62",
          "text": "The beauty about these vs. posts....real ones know opus the King.",
          "score": 0,
          "created_utc": "2026-02-07 17:08:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xk0v",
              "author": "Much_Ask3471",
              "text": "i dont agree, complex bug or complex task codex done but opus failed.",
              "score": 5,
              "created_utc": "2026-02-07 17:09:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o43xo35",
                  "author": "Inevitable_Service62",
                  "text": "Doubt. But it's your tests. Gets it done for me",
                  "score": -1,
                  "created_utc": "2026-02-07 17:10:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1orvx",
      "title": "I work 12h per day with claude code and don't hit any limits",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1r1orvx/i_work_12h_per_day_with_claude_code_and_dont_hit/",
      "author": "Aemonculaba",
      "created_utc": "2026-02-11 05:27:02",
      "score": 221,
      "num_comments": 196,
      "upvote_ratio": 0.84,
      "text": "Max 20x plan, using claude code's experimental teams feature, running in tmux.\nThe most I've gotten was 15% of the weekly limit yesterday. \n\nAnd I did not yet implement 5.3 Codex and synthetic's Kimi K2.5 into the workflow (works btw, had them in the previous one working in tandem with claude code).\n\nI really don't know what you guys are doing to burn through your tokens that fast... i can't physically reach any limits, even if I wanted to. \nI burned 300.000 tokens yesterday... but my claude code instance delegates lower level work to lower level models and i got heavily optimized guardrails in place. So I don't use Opus for everything, Opus just handles the roles of teamlead (delegator), requirements engineer, architect, red teamer, senior coder, white hat, reviewer and auditor.\nBut all the \"dumb\" stuff is handled by Haiku and Sonnet. \n\nThe only bottleneck today is my ability to review and critique the AIs work.\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r1orvx/i_work_12h_per_day_with_claude_code_and_dont_hit/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o4r5amc",
          "author": "Historical-Lie9697",
          "text": "Also max x 20, I usually get to like 90% each week. I am basically using it like a summoner though telling it to use multiple subagents for everything. And if I have a lot of usage left for the last couple days I go hard using a bunch of conductors at once in different projects.",
          "score": 25,
          "created_utc": "2026-02-11 05:54:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rllyd",
              "author": "TotalBeginnerLol",
              "text": "But why? Is that actually getting good results? Coz my results are great using mostly no agents, occasionally 1, and I never hit a limit, on the $100 plan doing 8hrs coding a day.",
              "score": 9,
              "created_utc": "2026-02-11 08:21:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4sfpyt",
                  "author": "Historical-Lie9697",
                  "text": "Most of the extra usage goes into planning really. My workflow has been to add issues to beads as I find bugs to fix, feature requests to add, etc, then I have a /planbacklog command that uses haiku subagents to scout each issue and add relevant file paths, then opus updates dependencies, breaks down each issue into manageable sized tasks, drafts prompts for each with the opus prompting guidelines as reference, then marks the issue as ready. Then when the backlog is ready, I type /gogo and claude uses opus subagents to complete the entire backlog, in parallel whenever possible.",
                  "score": 1,
                  "created_utc": "2026-02-11 12:40:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o513m3a",
                  "author": "goldio_games",
                  "text": "Speed. More agents can do more things. Your 8 hours of coding is not equal to our 8 hours.",
                  "score": 1,
                  "created_utc": "2026-02-12 19:02:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4rb46k",
              "author": "Sketaverse",
              "text": "Omg ‚Äúsummoner‚Äù is the perfect label",
              "score": 6,
              "created_utc": "2026-02-11 06:44:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4u00gp",
                  "author": "addiktion",
                  "text": "Spawner, Summoner, Orchestrator. I feel like we've entered a new era of power over our minions.",
                  "score": 2,
                  "created_utc": "2026-02-11 17:29:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4rp3i6",
              "author": "klumpp",
              "text": "What are you even getting? Hundreds of fake unit tests? I use Claude surgically to fix actual problems and I‚Äôve never gone above 50% x5 limit.",
              "score": 1,
              "created_utc": "2026-02-11 08:54:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4r87c3",
              "author": "giorgo_muc",
              "text": "Are there any accounts without a weekly limit? Because I don't think I have one. That's why I'm wondering.",
              "score": 0,
              "created_utc": "2026-02-11 06:18:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4rbc6m",
                  "author": "EternalStudent07",
                  "text": "Their documentation says \"no\".  That the only way to go past your limits are to setup automatic API usage (pay as you go).",
                  "score": 2,
                  "created_utc": "2026-02-11 06:46:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r5gru",
          "author": "TeamBunty",
          "text": "It's because they don't understand basic math.\n\n1,000,000 SaaS apps \\* $19/mo \\* 0 subscribers per app = $0",
          "score": 58,
          "created_utc": "2026-02-11 05:55:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r8gxx",
              "author": "imwearingyourpants",
              "text": "On a positive side, the infra costs are low too with that numbers of subs",
              "score": 8,
              "created_utc": "2026-02-11 06:21:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4sl6p0",
                  "author": "quick_actcasual",
                  "text": "Serverless finally gets its moment!",
                  "score": 9,
                  "created_utc": "2026-02-11 13:14:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4sy61r",
                  "author": "who_am_i_to_say_so",
                  "text": "All 122 of my vibecoded apps are still on the free tier!",
                  "score": 1,
                  "created_utc": "2026-02-11 14:27:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4saukc",
              "author": "iamgdarko",
              "text": "Bro nailed the math",
              "score": 2,
              "created_utc": "2026-02-11 12:05:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rgpy8",
          "author": "bratorimatori",
          "text": "You have to step up, what can I say.",
          "score": 7,
          "created_utc": "2026-02-11 07:34:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rb2cn",
          "author": "JoeTheChode",
          "text": "Coming from someone who is semi illiterate when it comes to coding. It's just a bunch of people vibe coding They have shitty prompts like \"make me an app that'll make money.\"\n\nClaude spitballs ideas. \n\" Go with that one\" \n\"How do I build it\"\n \"Can you build it?\" \n\"Build it all yourself\"\n \"I want it to not look like AI Slop\"\n\"Why isn't this working\"\n\"Fix it\"\n\nIf you're relying on AI to fully be the Developer from Planning > implementation > supervisor > Auditor you'll burn through your tokens quickly. Especially when you start going from a small ask like a budget sheet to a big ask like \"Redesign this AAA game\". \n\nOnce I started making my prompts more detailed about what I actually want to happen. Function, design, ease of use it uses less tokens and I got better results. I still hit my weekly limits but now it happens on Wednesday(Thursday Reset) instead of Saturday.",
          "score": 16,
          "created_utc": "2026-02-11 06:43:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rk4ph",
              "author": "Ran4",
              "text": "While ultra generic prompts isn't the way to go, I do think that people tend to overprompt nowadays. The models tend to be smart enough to usually make reasonable initial decisions. People should experiment more - do something, revert it, try a different direction. As opposed to trying to steer the llm from beginning to end.\n\nAnd dumb, investigative prompts like \"Fix all bugs\" are surprisingly effective. It obviously won't find ALL bugs, but it does tend to find some. I know many seasoned devs who underestimates the capabilities of modern frontier models.\n\n(and I say that as someone who has been writing code for like 20 years, 10 of which professionally, and has been claude coding for a few hours a day for the past few months).",
              "score": 6,
              "created_utc": "2026-02-11 08:06:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4rmf7g",
                  "author": "TotalBeginnerLol",
                  "text": "Trouble is that ‚Äúfix all bugs‚Äù might find and ‚Äúfix‚Äù a bug but the ‚Äúfix‚Äù breaks a bunch of other stuff. Whereas doing the same thing via TDD is a whole different story. ‚ÄúCurrently 20 failing tests, fix them all‚Äù and it works perfectly without breaking anything else (assuming you tell it to run all tests after each fix).",
                  "score": 2,
                  "created_utc": "2026-02-11 08:29:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4wf750",
                  "author": "Sketaverse",
                  "text": "yeah for sure, prompting is dead. Just chat to it like a human and make sure you have excellent product craft/taste/strategy",
                  "score": 2,
                  "created_utc": "2026-02-12 00:43:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4rm2cl",
              "author": "TotalBeginnerLol",
              "text": "I think definitely this and also people just churning out tons of dogshit pointless apps. IMO the $100 plan is great for working on 1 app seriously, and $200 plan with 5x can probably handle 5 apps (though the level of seriousness drops if you‚Äôre not giving any 1 your full attention). The guy at the top working on 9 projects at a time‚Ä¶ yeah you deserve to be hitting limits. FFS.",
              "score": 1,
              "created_utc": "2026-02-11 08:25:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4s0kng",
              "author": "Acrobatic-Cost-3027",
              "text": "I‚Äôm as specific as necessary with my prompting, and even use agent teams in about half of my prompts, and while I do glance through code and read all summaries, I don‚Äôt code much of anything while using CC; and still don‚Äôt burn through my limit and this is with the default model set to Opus 4.6 high reasoning.",
              "score": 1,
              "created_utc": "2026-02-11 10:41:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4s0zm4",
              "author": "VitalityAS",
              "text": "100% I spend the extra 5 mins writing out where it will need to look for stuff roughly and an idea of how to implement it. Just like I would explain it to another dev. I basically never hit limits.",
              "score": 1,
              "created_utc": "2026-02-11 10:44:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4s7uld",
                  "author": "JoeTheChode",
                  "text": "Like I mentioned before, I'm not a coder. So I due burn through a lot of tokens having Claude write prompts for me to put into VS Code Claude Code. I'm mostly just copying and pasting from window to window. But I make sure to steer it in the right direction from time to time. \n\nFrom the beginning I've always planned things out in segments and make sure that one task is rock solid through testing before proceeding on.",
                  "score": 1,
                  "created_utc": "2026-02-11 11:43:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r6kxa",
          "author": "LazerFazer18",
          "text": "So for the first time in months I hit my 5 hour limit yesterday on the 5x plan. I noticed teams of agents burn through usage extremely quickly. \n\nI was migrating from Supabase Auth to Better Auth, and decided to just let the team go at it without much guidance. It burned through about 50% of a 5 hour limit in 30 minutes.",
          "score": 5,
          "created_utc": "2026-02-11 06:05:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4syeif",
              "author": "who_am_i_to_say_so",
              "text": "Sounds about right",
              "score": 1,
              "created_utc": "2026-02-11 14:28:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4tmbn2",
              "author": "Neat_Let923",
              "text": "I had the same issue yesterday as well!!!\n\nIt was the first time I actually thought there might be something weird going on.",
              "score": 1,
              "created_utc": "2026-02-11 16:25:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4wjecq",
              "author": "automatedlife",
              "text": "What‚Äôs making you switch off Supabase Auth?",
              "score": 1,
              "created_utc": "2026-02-12 01:08:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z2wkx",
                  "author": "Cautious_Currency_35",
                  "text": "Yeah I'm wondering the same.",
                  "score": 1,
                  "created_utc": "2026-02-12 13:03:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o56ss8m",
                  "author": "LazerFazer18",
                  "text": "I'm building a web-based management tool for a startup that can't really afford much (for now) in terms of monthly costs. I initially set it up for quick auth, because I wanted to get the actual functionality of the tool, but now that we're getting closer to a v1 release, I decided to move the auth to something we have more control over, and won't have a monthly cost attached. \n\nI know there's a free tier, which I've been using for testing, but we're not happy about not being able to remove supabase branding from emails. We find it doesn't look professional enough.",
                  "score": 1,
                  "created_utc": "2026-02-13 16:31:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r5am2",
          "author": "snowdrone",
          "text": "I am approaching my weekly limit, on max. Running 9 repos in parallel through vms + code reviews for each repo. I have them going about 12 hours a day. Compared to hiring nine devs and feeding them pizza, it's great üòÖ",
          "score": 19,
          "created_utc": "2026-02-11 05:54:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sd8i9",
              "author": "Western_Objective209",
              "text": "those repos are 100% trash that barely work. you don't even have time to verify things look correct",
              "score": 20,
              "created_utc": "2026-02-11 12:23:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4swqne",
                  "author": "xXValhallaXx",
                  "text": "This..... I'm so fed up of people thinking they're geniuses and flex that they have X agents ruining In parallel,  this is not impressive this just tells me.... lack of experienced, thinking they're building the next big thing,  in fact it's just a waste of compute power. \n\nFlex how you're teams DX improved , worflows in a company how it improved processes, and the SDLC in general,  through agent orchestration, \n\nNot some flex where you think you're Neo, running X agents and X agents in parallel",
                  "score": 29,
                  "created_utc": "2026-02-11 14:19:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4thw7s",
                  "author": "Twig",
                  "text": "Damn bro. Kill 'em first next time. We don't need that second hand smoke",
                  "score": 2,
                  "created_utc": "2026-02-11 16:04:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4vqsqp",
                  "author": "snowdrone",
                  "text": "No, it's all unit tested, integration tested, and E2E tested. Multiple rounds of code reviews for each PR. App works great.",
                  "score": 2,
                  "created_utc": "2026-02-11 22:28:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4towjm",
                  "author": "Ikeeki",
                  "text": "Yup. At most I have maybe 3-6 projects going at once depending on complexity of problems and maturity of codebase and SDLC I have setup for the project. And they are never all running continuously at once, they require human intervention by design for planning and reviewing \n\nWithout proper SDLC I‚Äôll usually only be able to manage 2 or 3 at a time and I tend to have to micromanage and interrupt it a lot, things like ‚Äúdon‚Äôt forget to do TDD red green pass‚Äù etc. \n\nThe people out there running an army of agents without any sort of SDLC (which should always include human review) are just accelerating their own tech debt. \n\nWho knows maybe AI will be good enough to get them out of their own AI generated tech debt in a couple years lol",
                  "score": 1,
                  "created_utc": "2026-02-11 16:37:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4tm25q",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -1,
                  "created_utc": "2026-02-11 16:24:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4rceqp",
              "author": "trolololster",
              "text": "yes, and their commit-messages are so much better than the \"sm4ll fixe\" you get from even seasoned developers.",
              "score": 5,
              "created_utc": "2026-02-11 06:55:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4t379q",
                  "author": "WarAmongTheStars",
                  "text": "Idk, we have standardized JIRA links and JIRA titles as commit messages and it seems to work.",
                  "score": 1,
                  "created_utc": "2026-02-11 14:53:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4rfvpw",
                  "author": "evergreen-spacecat",
                  "text": "oh no one will ever read them",
                  "score": -3,
                  "created_utc": "2026-02-11 07:27:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4roow8",
              "author": "ReedPetrovich",
              "text": "Hi. I am curious - what are those 9 repos / agents do? I just can't imagine why I would need more than 2 agents running in parallel",
              "score": 2,
              "created_utc": "2026-02-11 08:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ti58d",
                  "author": "CalamariMarinara",
                  "text": ">I just can't imagine why I would need more than 2 agents running in parallel\n\nIf you can imagine why you would need two agents for a single repo, surely you can imagine that if you had another repo, you would do the same, and then you have four agents running in parallel.",
                  "score": 1,
                  "created_utc": "2026-02-11 16:06:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4vsgfo",
                  "author": "snowdrone",
                  "text": "{ Db / Etl, backend, frontend } * 3 slots per repo.¬†\nFor the task assignment you want of course for everything to be orthogonal.¬†\nSo if you can separate out your features within each layer, you can have nine going at once.\nOr you can spec out a plan for cooperation from DB all the way to front end.",
                  "score": 1,
                  "created_utc": "2026-02-11 22:37:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4torbi",
              "author": "rafaelRiv15",
              "text": "What the fuck are you even doing with 9 repos ??",
              "score": 1,
              "created_utc": "2026-02-11 16:36:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vhkkl",
                  "author": "snowdrone",
                  "text": "{ Db/Etl, backend, frontend } * 3 (essentially three repos with three slots each for agent tasks)",
                  "score": 1,
                  "created_utc": "2026-02-11 21:43:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r2dhj",
          "author": "These-Bass-3966",
          "text": "You said it; you‚Äôre not quick enough.",
          "score": 16,
          "created_utc": "2026-02-11 05:31:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rkm6k",
          "author": "finnomo",
          "text": "Even opus is stupid and makes mistakes, what would happen if I switch to sonnet or haiku? I don't try to save my limits. If I can, I use Opus all the time, just because other models would waste more of my time.",
          "score": 3,
          "created_utc": "2026-02-11 08:11:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vy7b9",
              "author": "DurianDiscriminat3r",
              "text": "Yeah this started using codex 5.3 because the code quality is just higher at the same rate.",
              "score": 1,
              "created_utc": "2026-02-11 23:07:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4r62o5",
          "author": "Xyz123abc789",
          "text": "I have the same experience as you (enterprise plan so not actually sure what that equates to with regular plans) the only time I hit my weekly limit was when I was heavily using the Sonnet 1M context  I usually use about 15-20% of my weekly usage in a day.  I also agree with keeping up with reviewing, hopefully this is where some of the tooling improves. Sometimes by the time I‚Äôm going through the diffs/PR I‚Äôd like to figure out why the AI wanted to make the change, it‚Äôs currently a pain to sort through everything.",
          "score": 2,
          "created_utc": "2026-02-11 06:00:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rr3gv",
          "author": "[deleted]",
          "text": "Cool story, bro.¬†",
          "score": 2,
          "created_utc": "2026-02-11 09:13:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rs8qx",
          "author": "PermitNo6307",
          "text": "I'm working on multiple projects and do all sorts of stuff not efficiently. Multiple machines. Same deal. 2x days are funny to me",
          "score": 2,
          "created_utc": "2026-02-11 09:24:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4szfe4",
              "author": "who_am_i_to_say_so",
              "text": "Same. Sometimes I‚Äôll just tell it: ‚Äúdo the feature‚Äù. Which is about the worst you can do, rarely come close to the limit.",
              "score": 1,
              "created_utc": "2026-02-11 14:33:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vo42k",
                  "author": "PermitNo6307",
                  "text": "I tell my research agents I'm going to bed and to scrape everything in this field from x places and I want this report done and y made based off of findings. And then I'll tell it I'm going to bed so don't pause or ask anything. I'll wake up to a broken product but the whole structure is there. It's wild",
                  "score": 2,
                  "created_utc": "2026-02-11 22:14:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4wpo0p",
                  "author": "PermitNo6307",
                  "text": "Also if you want better results on Claude. Use tester agents to research because they have write permission and tell them to write findings to the respective md file in an extensive directory of md files. And it'll get super smart instead of relying on context. The agents all refer to the md files when building.",
                  "score": 1,
                  "created_utc": "2026-02-12 01:47:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4sgbg9",
          "author": "electricshep",
          "text": "If I don't hit 100% a week, I'm not working right.",
          "score": 2,
          "created_utc": "2026-02-11 12:44:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r3m4z",
          "author": "Strict_Research3518",
          "text": "Yah.. I wonder sometimes if those folks saying that are bots or people who use Gemini or Chat or china dudes that are tyring to make the big 3 or in this case Claude look bad. \n\nI am on max 20.. and I go nuts.. I have it running on my 100s of files multiple projects all day every day.. and I cant seem to hit 100% and I ma 100% opus full time. \n\nI will say back in Sept/Oct/Nov I was eating thru my weekly Opus 4.1 limits in hours.. they clearly went gang busters back then to limit opus use.. so I dont know if they got an infusion of billions and bought all new nvidia hardware so have plenty of capacity now.. or they streamlined it.. or they put in a better algo that allows those using 20 sessions at once to hit max while those of us doing 1, 2 maybe 3 sessions at once to have plenty of capacity or what. I am certainly n to nearly in the 2% range that's for sure.. so perhaps they finally fixed the algo?\n\n",
          "score": 2,
          "created_utc": "2026-02-11 05:40:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r6wdx",
              "author": "Cautious_Slide",
              "text": "I've been running only opus analyzing 100,000 + pdf and text documents while also coding with fairly vague prompts had to go up to the 20x plan but I still hit my session limits once or twice a week but I know before I even start the computer that im going to hit the limit lol. Who needs efficiency when you can brute force your way through.",
              "score": 3,
              "created_utc": "2026-02-11 06:07:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4r6g2g",
          "author": "tarkansarim",
          "text": "Do you only work within a single chat session?",
          "score": 1,
          "created_utc": "2026-02-11 06:04:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r8w9i",
              "author": "Aemonculaba",
              "text": "\"yes\"\nCC's running in a tmux session that spawns more sessions.\nI usually just work on one project, but in multiple worktrees with multiple parallel agents running and working on their feature.\n\nThe teamlead (orchestrator) instance decides if tasks are better done by spawning teams or subagents.",
              "score": 2,
              "created_utc": "2026-02-11 06:24:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ri5rr",
                  "author": "mjsarfatti",
                  "text": "What‚Äôs the advantage of using tmux?",
                  "score": 1,
                  "created_utc": "2026-02-11 07:48:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r6nyv",
          "author": "PaddingCompression",
          "text": "I multitask only using Opus.  I find that the other cheaper models waste enough time sometimes that it's not worth the risk.\n\nI think of it like \"Opus costs 10x as much but is 2x as efficient - BUT the cost per hour is SOO much cheaper than my productivity gain I don't care\".\n\nIn addition, I usually have 3-4 sessions going at once (I envy those who can keep 10 going - sometimes I have if there are long test cycles of wall clock time where running extensive tests takes 45 minutes, but then that's not a lot of model token use).\n\nI have other AIs I use when I bounce against limits, I probably use the equivalent of 1.5 20x subscriptions, but other AIs give me some diversity too (ChatGPT and Gemini have their occasional strenghs)",
          "score": 1,
          "created_utc": "2026-02-11 06:05:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r7jkg",
          "author": "Just__Beat__It",
          "text": "If you don‚Äôt use Agent Team, most likely yes.",
          "score": 1,
          "created_utc": "2026-02-11 06:13:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sz1am",
              "author": "who_am_i_to_say_so",
              "text": "I use Agent team and run two projects at any given time on 5x, get close but never at limit. TBH I am mystified.",
              "score": 1,
              "created_utc": "2026-02-11 14:31:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rbw3d",
          "author": "TimeKillsThem",
          "text": "I was like you - maybe hit it once in close to 8 months of having the subscription, up until yesterday when I decided to spin up 10+ instances of cc to run a through review of some very lengthy documentation. That burned through the 100$ subscription session limit in like 15 minutes hahahaha",
          "score": 1,
          "created_utc": "2026-02-11 06:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4reodq",
          "author": "Accomplished_Buy9342",
          "text": "Same, I don't get people who run 20 parallel windows as if they are designing a nuclear reactor.   \n",
          "score": 1,
          "created_utc": "2026-02-11 07:16:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rew71",
          "author": "aladante",
          "text": "20x max plan Hit my limit yesterday running very heavy with multiple sub agents, have too wait till Thursday till the reset üò≠",
          "score": 1,
          "created_utc": "2026-02-11 07:18:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rfwby",
          "author": "timc-trainean",
          "text": "Just came here to say, yes to all of this! Reading every comment this is how I feel exactly. It's very nice to hear I'm not the only one pushing 5x to the quota limit, but unable to hit 20X limits.\n\nAchieving 20X limit is my new life goal.  I'm sure that's normal üòá",
          "score": 1,
          "created_utc": "2026-02-11 07:27:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rh53n",
          "author": "openclaw-lover",
          "text": "I use Claude Code Max 200 to power OpenClaw multi-agent workflow. I can hit rate limit in one day.",
          "score": 1,
          "created_utc": "2026-02-11 07:38:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rl2ri",
          "author": "totallyalien",
          "text": "How to manage other agents do which job ? How switch happens , I just need just for claude agents",
          "score": 1,
          "created_utc": "2026-02-11 08:15:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rm64p",
          "author": "Bubbly-Lab8308",
          "text": "Im at 98% on weekly usage now :)",
          "score": 1,
          "created_utc": "2026-02-11 08:26:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ro3ex",
          "author": "horserino",
          "text": "I'm at around $600/month using an api key to run CC at work. I don't really manually switch out to other models manually and don't have particular agentic flows made by myself.\n\n- My loop is usually: ask questions/explore -> plan -> ask to execute plan -> correct\n\n- I compact only when a chunk of work is done, not in the middle of a task or at the end of a plan\n\n- I don't clear context before executing a plan. In my experience it leads to worse results when the plan is detailed. I will compact before executing the plan if there was a long back and forth before I was satisfied with the plan.\n\n- I try to leverage CC for the kind of tasks that wouldn't be worth doing by hand. This usually involves massive changes that aren't practical to to by hand, so that consumes a lot of tokens.\n\n- I make CC verify its output (compile, test, lint, etc)\n\n\nGuven that it is my employer who pays for the token and that this leads to high quality output I haven't really put too much effort into reducing costs. Whenever I tried some common approaches mentioned here I feel I get worse resulta or it takes slower to reach a level of quality I find acceptable.\n\nWhat does your setup look like?",
          "score": 1,
          "created_utc": "2026-02-11 08:45:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rox50",
          "author": "jordi-zaragoza",
          "text": "Same here on max 5x. The key is delegating to subagents and keeping Opus for decisions only. Most people hitting limits are running Opus on every single file read and grep. I also noticed that front-loading context (project structure, file relationships) at the start of a session cuts down on the exploratory tool calls massively. Claude stops grepping through your entire project when it already knows where things are.",
          "score": 1,
          "created_utc": "2026-02-11 08:53:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4roxm0",
          "author": "PresentWrongdoer4221",
          "text": "Working on really massive, old, monolithic repos makes context a bitch.\n\nAnd not like I have a choice. Upper mgmt prioritizes new features over tech debt.",
          "score": 1,
          "created_utc": "2026-02-11 08:53:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rst0u",
          "author": "bundors",
          "text": "I'm on x5 plan and just hit the limit in one week. I guess 20x plan should be too much for me - i guess 4x more usage and 24/7 working haha. ",
          "score": 1,
          "created_utc": "2026-02-11 09:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rt415",
          "author": "ThomasToIndia",
          "text": "I am the same. The people hitting limits are either letting stuff run fully autonomously or not doing any context engineering at all.",
          "score": 1,
          "created_utc": "2026-02-11 09:32:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rykbq",
          "author": "DrCopAthleteatLaw",
          "text": "What do you use the dumb models for? What‚Äôs the dumb stuff?",
          "score": 1,
          "created_utc": "2026-02-11 10:22:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4s0qwg",
          "author": "achton",
          "text": "How are you using tmux? I've never used it, and want to understand the advantage.",
          "score": 1,
          "created_utc": "2026-02-11 10:42:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4s4wtt",
          "author": "redishtoo",
          "text": "I‚Äôm on a simple pro account and I barely double my bills with additional usage, while I spend my days with Claude. The secret sauce is to use Claude Opus only for the high-level thinking and use the less capable models with huge context to digest the token-consuming tasks. For 20$ more Gemini can do some proper bookkeeping and eventually the free gpt5 in VS Code can wipe the floor. \nThe problem comes when these kids mess up Opus‚Äôs neat work and I have to call the master.",
          "score": 1,
          "created_utc": "2026-02-11 11:18:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4s86m6",
          "author": "srirachaninja",
          "text": "Same here. The last 2 days of the week, I am looking for heavy stuff to burn all my tokens, but I can't barely make it to 70% most of the time, and that's with daily 10-12h sessions on 3 different projects. \n\n5x wasn't enough, but the 20x is great. I get it if you use it as a hobby for personal projects; it's expensive, but if you use it for your business, $200 is nothing compared to the productivity you get from it. \n\nIf you would hire someone to do all of that, it would easily cost you $2-$3000/month, even if you hire from Upwork, and the work wouldn't be done that fast and would require a lot more back and forth than with Claude. ",
          "score": 1,
          "created_utc": "2026-02-11 11:45:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4safsy",
          "author": "papageek",
          "text": "If I use a fresh claude install without any configuration, it will hit my limits within a couple hours and have to wait several hours to continue. With a few simple tweaks it doesn‚Äôt. I use oh my claude and beads currently and don‚Äôt hit any limits.  Plan mode to make extensive beads tasks, restart eco work on beads tasks",
          "score": 1,
          "created_utc": "2026-02-11 12:02:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4x1xza",
              "author": "Lunchbox35",
              "text": "What tweaks do you make as I am new to Claude and hit it regularly. Thanks.",
              "score": 1,
              "created_utc": "2026-02-12 03:00:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4yr9r2",
                  "author": "papageek",
                  "text": "I use oh my claude and beads. I start work with: plan blah blah what i want ‚Ä¶ by making detailed beads epic and tasks\nThen /quit and restart\neco work on beads tasks\ncommit\n/exit after each round and repeat till it‚Äôs done",
                  "score": 1,
                  "created_utc": "2026-02-12 11:40:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4sb3sg",
          "author": "ectkirk",
          "text": "The times I burn through 20x are the times I run multiple terminals for long periods. If I keep it to single-mostly and multiple-occasionally it's fine.\n\nIt just occured to me I have Gemini 3 cli available through my existing Google home licensing so I'm going to solve my token chew issue using that more.\n\nTotally do need to learn how to enable the agents to work together, tho. Saw some guides on MCPs but haven't tried it yet.",
          "score": 1,
          "created_utc": "2026-02-11 12:07:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sekr2",
          "author": "merksam",
          "text": "Could you please share your workflow, how you orchestrate your work?",
          "score": 1,
          "created_utc": "2026-02-11 12:32:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4svvvh",
          "author": "IlliterateJedi",
          "text": "I only tend to hit limits when I let Claude just do its own thing (e.g., give it free reign to create monstrosities).  When I'm thoughtfully working I never hit limits with the 20x plan because I have to formulate the query, make the query, review the output, pass that that through whatever skills it needs to go through for a second look, lather, rinse and repeat, etc. I will occasionally have two windows open doing something in parallel, but so much of my work has to be sequential that I rarely hit limits. It doesn't do me any good to have 10 agents creating 10 times as much garbage when wrangling one agent can sometimes be a lot of work.  Sometimes I might run ClaudeCode in multiple IDE's where I'm doing different projects but even that is pretty rare.  E.g., web app in one window, SQL data analysis in another IDE at the same time. Or I'll have Claude pulled up in the browser.  But all of that is pretty rare.",
          "score": 1,
          "created_utc": "2026-02-11 14:15:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4t0n4r",
          "author": "privacyguy123",
          "text": "You are one of the accounts \\*without\\* the token bug.",
          "score": 1,
          "created_utc": "2026-02-11 14:40:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4t4nh7",
          "author": "lambertb",
          "text": "Me too.",
          "score": 1,
          "created_utc": "2026-02-11 15:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4t570i",
          "author": "bilbo_was_right",
          "text": "I have no idea tbh, I also code probably 5 hours a day on average, sometimes up to 8, with probably 5-8 sessions open at any given time each one frequently running lots of parallel subagents. These people must be abusing the fuck out of parallel subagents or something, I barely even know what I would ask it to burn that many tokens",
          "score": 1,
          "created_utc": "2026-02-11 15:03:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tace5",
          "author": "foksa",
          "text": "In my case, the last couple of days, Opus 4.6 was eating tokens like crazy... It would spend a few percent of the weekly limit during planing phase (on 5x max plan). Something changed today, and now it is using tokens slower than ever",
          "score": 1,
          "created_utc": "2026-02-11 15:29:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4te81v",
          "author": "TheOriginalAcidtech",
          "text": "About the same. I get CLOSE on the weekly, but I'm not being particularly token efficient. But have never hit the 5 hour limits on x20.",
          "score": 1,
          "created_utc": "2026-02-11 15:47:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tg617",
          "author": "EnvironmentalPlay440",
          "text": "Usually killing my 20x plan in 3-4 days‚Ä¶ :)",
          "score": 1,
          "created_utc": "2026-02-11 15:56:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tr0ze",
          "author": "djdadi",
          "text": "What's your workflow like? Are you a SWE?\n\nI, too, am baffled how anyone on max is hitting limits so fast and coding with 8 terminals at once. The most I can reasonably get away with usually is 2-3 before I become the bottleneck in the planning and review.",
          "score": 1,
          "created_utc": "2026-02-11 16:47:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tz40n",
          "author": "Salt-Replacement596",
          "text": "I use Opus for everything and didn't hit the 20x Max plan limits yet.",
          "score": 1,
          "created_utc": "2026-02-11 17:25:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ub6lm",
          "author": "Silatus-sahil",
          "text": "Share the cc with me XD, i am at lack of good models and their api usage. and burning through $20 codex plan like in 3 days eveyrhting\n\n",
          "score": 1,
          "created_utc": "2026-02-11 18:21:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v7g6j",
          "author": "niktor76",
          "text": "congratulations",
          "score": 1,
          "created_utc": "2026-02-11 20:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vafkn",
          "author": "muhlfriedl",
          "text": "500k loc",
          "score": 1,
          "created_utc": "2026-02-11 21:09:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vbctg",
          "author": "AdventurousCoconut71",
          "text": "Simple, claude is a scam.",
          "score": 1,
          "created_utc": "2026-02-11 21:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vdifw",
          "author": "pmelendezu",
          "text": "I can run into 5x limits consistently if I try too hard. It only takes two concurrent workflows about 2-3 hours (a bit faster with Opus 4.6). I imagine on 20x, I would need about 8 concurrent workflows, which is harder but not insanely hard. I map a workflow per feature so working on 8 at the same time would imply a lot of context switching, so not sure if I would like to go that far",
          "score": 1,
          "created_utc": "2026-02-11 21:24:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vzpaa",
          "author": "thow_away721",
          "text": "Highest I‚Äôve hit was 70% weekly. Hit my daily once but it reset 10 min later.",
          "score": 1,
          "created_utc": "2026-02-11 23:15:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wib6h",
          "author": "OrganicRace4883",
          "text": "Claude code is still trying to catch up to you, my man!",
          "score": 1,
          "created_utc": "2026-02-12 01:01:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x133h",
          "author": "bchan7",
          "text": "this is exactly my situation!",
          "score": 1,
          "created_utc": "2026-02-12 02:55:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x7h8s",
          "author": "VividBrush9973",
          "text": "If you want to convert each commit into a technical blog, feel free to checkout - [https://github.com/lahfir/commit-blog](https://github.com/lahfir/commit-blog)",
          "score": 1,
          "created_utc": "2026-02-12 03:35:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x8j8b",
          "author": "PineappleLemur",
          "text": "It's meaningless without know how much tokens/prompts/scale you're running through.\n\nI also use AI for 5h~ a day. But it's idle for 99% of that time because I'm busy reviewing the code and modifying/testing.\n\nDo you mean it is running none stop for 12h?",
          "score": 1,
          "created_utc": "2026-02-12 03:42:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xow3l",
              "author": "Aemonculaba",
              "text": "When I'm active, i use 1% of the weekly limit per hour.\nAround 200 million tokens every 3 days.",
              "score": 1,
              "created_utc": "2026-02-12 05:42:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4x8p1j",
          "author": "kpgalligan",
          "text": "I'm on 20x. I've had to invent multi-agent background tasks using the Agent SDK to get above 20%-30%, and only that because the excess availability has changed my usage (even outside of the Agent SDK stuff).\n\nIf what you're doing is highly automatable, I could see getting higher organically. I wind up spending a fair bit of time manually course correcting and/or updating context to support more automation.",
          "score": 1,
          "created_utc": "2026-02-12 03:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xg93b",
          "author": "tripsandleaves",
          "text": "Wanna post your agent list?",
          "score": 1,
          "created_utc": "2026-02-12 04:36:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhdes",
          "author": "PeterDowdy",
          "text": "Then you‚Äôre not getting your money‚Äôs worth!",
          "score": 1,
          "created_utc": "2026-02-12 04:44:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xpsf4",
          "author": "samyakagarkar",
          "text": "One of the reasons is declining TPS. Earlier I used to get a good 80-100 TPS sometimes more. .. now it's down to 40-50 max. Half the speed is half the usage and half the work.. plus slower speed drains my brain faster as I have to focus double the time for the same task.\nAnd this is accross providers.. not just Anthropic.",
          "score": 1,
          "created_utc": "2026-02-12 05:50:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xxl25",
          "author": "Beneficial-Bad-4348",
          "text": "That's usually the case for me, though in the last couple of days, the window has seemingly gotten smaller and I keep hitting the limit sooner AND the reset time seems to be getting longer. Just throwing shit in the wind here, but I am wondering about changes in response to all of the recent issues and api 500 responses.",
          "score": 1,
          "created_utc": "2026-02-12 06:59:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y15mo",
          "author": "tafaryan",
          "text": "Would really love to learn from your experience.\nOn 5x plan, has not been a week where I havent reached the limits for the last 3 months (unless i was travelling or smth) - not a tech guy. Been trying to build a project from scratch. Usually have Opus planning and Sonnet doing its work with 4 subagents (dev, ui, security, auditor)\nMy claude.md is not super detailed, I try to make sure to keep the context relevant and short, use agents where appropriate.\nI am not even talking about Opus 4.6, but a single compact takes about 4-5% of session limits on 5x plan with Opus 4.5. Any message to Sonnet immediately opens the door from 2%.\nAny UI bug, as i explain it, the search for the root cause uses about 55-60% of the context immediately. \nSo really not sure how you guys are managing to work 12h a day without hitting any limits. My experience is that even with sonnet 4.5 when i am vibecoding for bug fixes or new features in 2-3 terminals, i can get 3.5 hours or so from my 5x 5 hour session.",
          "score": 1,
          "created_utc": "2026-02-12 07:32:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y79tl",
          "author": "Greedy_Professor_259",
          "text": "Bro amazing if possible please share the workflow setup so that everyone can be benefited :)",
          "score": 1,
          "created_utc": "2026-02-12 08:31:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y7laz",
          "author": "Prestigious_Wave8207",
          "text": "Run Playwright MCP a lot‚Ä¶",
          "score": 1,
          "created_utc": "2026-02-12 08:34:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yl693",
          "author": "AncientRate",
          "text": "Used to hit the limit here and there in the Sonnet 3.5 era when I was stuck in projects that Sonnet could not handle the amount of shit it produced (and I was less skillful in communicating with it). At the time, I tried to use Claude like it was an outsourced contractor, telling it what I wanted and barely caring about how it was done. As the project ballooned, Claude started to struggle with fixing bugs. As a response, I just tried to brute-force it and burned a lot of tokens on all the dead ends.  \n\nNow I communicate with it more like a coworker. More interactively and less waterfall-y. Not trying to review every line of the diffs carefully, but I know what needs to be verified and what needs to be cleaned up \\*as early as possible\\*. In short, good software engineering practice still matters.",
          "score": 1,
          "created_utc": "2026-02-12 10:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5004i9",
          "author": "etch_learn",
          "text": "How do you delegate lower level work to sonnet instantly?",
          "score": 1,
          "created_utc": "2026-02-12 15:58:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50dt9j",
          "author": "lbarletta",
          "text": "The only time I was hitting limits was back when I was working on my personal project and my full time job at the same time. Max 5x here",
          "score": 1,
          "created_utc": "2026-02-12 17:02:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50tutf",
          "author": "throwawaycanc3r",
          "text": "Did you find agent teams to be more or less efficient than subagents?",
          "score": 1,
          "created_utc": "2026-02-12 18:17:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rh4ro",
          "author": "Forgot_Password_Dude",
          "text": "Lol you burned 300k tokens yesterday? üòÇü§£ I burn like 45 million a day",
          "score": 0,
          "created_utc": "2026-02-11 07:38:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rig8b",
              "author": "Aemonculaba",
              "text": "Sorry, should've been 30 million. Or around 250$ in tokens. Much of that is Haiku and Sonnet.",
              "score": 1,
              "created_utc": "2026-02-11 07:51:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4rrg8m",
                  "author": "backtogeek",
                  "text": "Ok I have been reading this thinking 300k ... Why pay for 20x, what are you working on, a blog post????? lol \n\n30 million makes more sense.",
                  "score": 2,
                  "created_utc": "2026-02-11 09:17:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4vh1p0",
                  "author": "touristtam",
                  "text": "I am using Opencode and this is my average per session: 3,344,949",
                  "score": 1,
                  "created_utc": "2026-02-11 21:40:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rii6w",
          "author": "Public605",
          "text": "Can you please explain how is your post helping and/or contributing to the community? \n\nWeird flex... but, i can post a shitty post as well with no  related or helping info just like this. Is it going to add some value to the community? is it going to help someone?",
          "score": -4,
          "created_utc": "2026-02-11 07:51:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rju9a",
              "author": "Aemonculaba",
              "text": "Butthurt?\nRead the comments of the others tho? There's interesting stuff in there.",
              "score": 5,
              "created_utc": "2026-02-11 08:04:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4rm2a7",
                  "author": "Public605",
                  "text": ">Butthurt? Read the comments of the others tho? There's interesting stuff in there.\n\nno. not butthurt. Just dissapointed of the low IQ and the low quality of this post.  Not contributing with any useful advice or info, just flexing with circlejerking info.\n\n\n\nagain:\n\n>Can you please explain how is your post helping and/or contributing to the community?\n\n\n not your feelings, actual facts if possible.",
                  "score": 0,
                  "created_utc": "2026-02-11 08:25:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4snaa0",
              "author": "Kedaism",
              "text": "This is a shitty comment that only puts someone down for creating discussion. Think you need to chill out and touch some grass.¬†\n\n\nI appreciated it, I also don't use my usage limits but I see a lot of posts, the opposite of this one, about people all using their usage limits. Have you been posting the same on all of those?",
              "score": 3,
              "created_utc": "2026-02-11 13:27:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4rmsp7",
              "author": "TotalBeginnerLol",
              "text": "I mean, it can help teach the people who are needlessly burning tokens and hitting limits by using it in dumb ways then constantly complaining about usage when it‚Äôs their own fault.",
              "score": 0,
              "created_utc": "2026-02-11 08:32:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o58pa8g",
                  "author": "Sidion",
                  "text": "But they gave absolutely no real evidence that what they said is true. The details are scarce and it's not really like they were being short with their critiques of the people burning tokens.\n\nI think the person you're responding to is justified to question what the point of this post is..",
                  "score": 1,
                  "created_utc": "2026-02-13 22:06:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r2xd4",
          "author": "p0tent1al",
          "text": "I use Max 10x. I consistently hit the limits but I definitely have to put some elbow grease into it. The 5 hour limit is fairly easy to hit if I have mutiple sessions going and doing a ton of research. The weekly limit, it just depends on what type of week I'm having.",
          "score": -2,
          "created_utc": "2026-02-11 05:35:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r3ofg",
              "author": "Strict_Research3518",
              "text": "Max.. 10x.. I see max 5 and max 20.. dont see an option for Max 10x. ",
              "score": 6,
              "created_utc": "2026-02-11 05:41:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4syrcp",
                  "author": "who_am_i_to_say_so",
                  "text": "They always order things off the menu.",
                  "score": 1,
                  "created_utc": "2026-02-11 14:30:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rd17z",
          "author": "pfak",
          "text": "Im working on very complex problems. I hit 100 percent on my two Max 20 accounts.\n\n\nYou arent doing much.¬†",
          "score": -2,
          "created_utc": "2026-02-11 07:01:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r5xzw",
          "author": "cuba_guy",
          "text": "Skill issue :) would be fine but honestly hitting just 15% of weekly limit is red flag, definitely room for improvement there. Anthropic did not set the limits out of thin air, it's based on usage date and adjusted constantly.",
          "score": -2,
          "created_utc": "2026-02-11 05:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rmxkh",
              "author": "TotalBeginnerLol",
              "text": "Not a red flag, just that op should downgrade to the $100 plan.",
              "score": 2,
              "created_utc": "2026-02-11 08:34:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4r7y8b",
              "author": "Aemonculaba",
              "text": "I mean, looking at the documentation from some months ago:\nYou get ~40h of Opus or ~250h of Sonnet per week... and probably around 750h of Haiku if you do the calculations.\nOpus got its own limit as far as i know.\n\nSo it's not a skill issue... i just don't use opus for everything. \n\nBUT!\nOpus is just 1.7 times as expensive as Sonnet... so they are fucking with us.",
              "score": 1,
              "created_utc": "2026-02-11 06:16:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4r8z16",
                  "author": "cuba_guy",
                  "text": "You may be right about anthropic testing the waters here, but I think you are a practitioner of single workflow and the target audience of max100 plan. Max 200 with 5x limits of max100 is tailored to users running multiple workflows simultaneously",
                  "score": 2,
                  "created_utc": "2026-02-11 06:25:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4rglc6",
                  "author": "afinzel",
                  "text": "Hang on, you ask how surprised you are about people hitting there limits and then turn round to say you hardly use opus.  I think you answered your own question!",
                  "score": 2,
                  "created_utc": "2026-02-11 07:33:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4r331z",
          "author": "dern_throw_away",
          "text": "stop doing 1 thing.  asked it to do 10.  in parallel. then 100. then 10000.  also, type faster.",
          "score": -5,
          "created_utc": "2026-02-11 05:36:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r5bas",
              "author": "Aemonculaba",
              "text": "I won't be able to review the code of 10 parallel instances. That's physically impossible and not responsible. At the moment it's around 3-5 parallel agents working on implementation. \nAnd then there's the RAM bottleneck.",
              "score": 9,
              "created_utc": "2026-02-11 05:54:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4r6zb3",
                  "author": "iamhost",
                  "text": "That‚Äôs how people hit limits, they aren‚Äôt doing any review. Crazy",
                  "score": 10,
                  "created_utc": "2026-02-11 06:08:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4r7btc",
                  "author": "PaddingCompression",
                  "text": "I rely on heavy AI review usage.  I've found that CodeRabbit usually finds any deep code issues especially when I go through all of its nitpicks (it's way better at review of finer details than the big models imo, and finds more subtle logic bugs than me or the vast majority of reviewers I've come across ever find).  So I'm not reviewing for bugs but for coding standards, maintainability, and architecture and usually Claude starts picking up on that stuff itself.\n\nPlus I have skills to have Claude make stacked changes, which dramatically reduces review fatigue, as well as skills to rebase the stack etc. if I make changes to an earlier review.\n\nSo by the time I seriously review the code, it's already in stacked changes, bugs found by CI have been fixed, code rabbit feedback integrated, etc. and it's a pretty easy review.\n\nThe only time it takes awhile is if there are nontrivial bugs I have to dig in, then Claude is only mildly helpful, and this is where I \\*really\\* use tokens by spawning a bunch of subagents to write debug scripts for a bunch of different hypotheses and gather data to try to parallelize debugging.  There tends to be a lot of VEERY long \"thinking\" blocks at this stage as we're already at a nontrivial problem.\n\nFor the RAM bottleneck, I have 256GiB on my dev machine, with 8TiB of storage for lots of worktrees and build artifacts.",
                  "score": 1,
                  "created_utc": "2026-02-11 06:11:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ra9cu",
                  "author": "RadioactiveTwix",
                  "text": "Ah, that's why we don't hit limits. I use Claude review and coderabbit and then review (they aren't paying me but CodeRabbit is awesome).",
                  "score": 1,
                  "created_utc": "2026-02-11 06:36:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4re5n9",
                  "author": "Special_Context_8147",
                  "text": "you are right! i still don‚Äôt trust it to let change hundreds of lines and i have no idea what it really does. i want to understand every line. like before the ai timeline",
                  "score": 1,
                  "created_utc": "2026-02-11 07:11:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4udsu4",
                  "author": "BorderlineGambler",
                  "text": "Most people hitting limits aren‚Äôt reviewing code mate. They‚Äôll be telling AI to create a feature and just letting it run wild. Times by 10-20 at a time. Probably works relatively well for MVPs.\n\nI never hit limits, not even close to be honest.",
                  "score": 1,
                  "created_utc": "2026-02-11 18:33:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4rbe1n",
              "author": "Sketaverse",
              "text": "Type faster? Go voice!",
              "score": 2,
              "created_utc": "2026-02-11 06:46:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4r2ph9",
          "author": "ZachVorhies",
          "text": "Yeah if I was doing one feature at a time i wouldn‚Äôt burn through the limits either. Try 10 instances all at once and just doing opus opus opus",
          "score": -5,
          "created_utc": "2026-02-11 05:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r3ezo",
              "author": "websitebutlers",
              "text": "That‚Äôs just sounds irresponsible üòÜüòÇ\n\nQuality will always be better than quantity.",
              "score": 7,
              "created_utc": "2026-02-11 05:39:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4r5tjw",
                  "author": "snowdrone",
                  "text": "There will be quality if you run opus, have multiple rounds of specs, and multiple rounds of code reviews",
                  "score": 1,
                  "created_utc": "2026-02-11 05:58:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4r43lx",
                  "author": "ZachVorhies",
                  "text": "lol",
                  "score": -2,
                  "created_utc": "2026-02-11 05:44:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4r5ozm",
              "author": "Aemonculaba",
              "text": "I got multiple agents running in parallel, working on different features in different branches.\n\nThere is no use in 10 instances, if you can't review that stuff. There is more to engineering than just solving a problem.",
              "score": 3,
              "created_utc": "2026-02-11 05:57:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4rbvwx",
                  "author": "ZachVorhies",
                  "text": "I absolutely review it. I have only time to review and tell the agent what to do next. I have custom linters for c++ that enforce extremely strict compliance. These run on hooks so the errors are caught immediately.\n\nthen automated testing before commit.\n\nThen 50 ci tests after\n\nI assure you with the setup in place you can faster than you think possible",
                  "score": 0,
                  "created_utc": "2026-02-11 06:50:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qyt0fo",
      "title": "This seems like a waste of tokens. There has got to be a better way, right?",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/hmup98kyq5ig1.png",
      "author": "UnknownEssence",
      "created_utc": "2026-02-07 23:34:14",
      "score": 211,
      "num_comments": 86,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qyt0fo/this_seems_like_a_waste_of_tokens_there_has_got/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o463imd",
          "author": "Ok-Experience9774",
          "text": "Explore uses haiku, which is essentially free compared to the other agents.\n\nThe explore agent follows the instruction and gives the answer.\n\nSimple example:¬†\n- Claude(opus): Go find me all the code that deals with widgets\n- Explorer(haiku) goes and searches the code base and responds back with a list of files ‚Äî Claude context use, virtually nothing, haiku cost, virtually nothing\n- Claude (opus) Now I have to read these files and understand them ‚Äî Claude context cost high, token usage medium.\n- Claude: Coder agent, modify these files and make the widgets brown.\n- Coder(sonnet) reads the files into its own context, does whatever needs doing, reports back a summary. Claude context usage: low, overall cost: medium.¬†\n\nDepending on the complexity having a subagent coder could be more expensive in this situation since claude(opus) might have been able to do it itself.\n\nIf you‚Äôve got lots of work to do, Claude needs to protect its context, that‚Äôs priceless, so it should be farming everything off. For a simple one off, meh.\n\nIn the end it comes down to what it has always come down to: Cost, Quality, Speed. Pick 2",
          "score": 124,
          "created_utc": "2026-02-08 00:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47oje0",
              "author": "Main-Lifeguard-6739",
              "text": "Haiku is far away from being ‚Äûessentially free‚Äú. It cost about 20% of opus but those agentic searches easily consume 100s of 1000s of tokens.",
              "score": 27,
              "created_utc": "2026-02-08 06:39:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o47wxyl",
                  "author": "Ok-Experience9774",
                  "text": "thats true, I guess i was thinking of \"compared to having opus do the research\".\n\nI'll actually have some numbers on that soon -- i'm dogfooding writing a claude coordinator (isn't everyone?) and have detailed per model stats from real world use -- unfortunately i should say \"had\" because a bug in the program meant it deleted all the historical data, the irony being is it was working on code to ensure it never deletes the historical data when it did it. ",
                  "score": 5,
                  "created_utc": "2026-02-08 07:56:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o47x2zh",
                  "author": "Obvious_Equivalent_1",
                  "text": "That‚Äôs why I try to offload a lot of activity that goes to Haiku normally to a locally installed model, the delay is almost negligible but the Llamamcp local AI cost 0 tokens compared.¬†\n\nTho what Ok Experience wrote I do 100% agree, the way Claude Code natively distributes the work is still completely preferable¬†with Haiku doing to legwork cheaply¬†\n\nThe real solution if you work in an already small code base it to learn to use backtick commands for MD files :¬†https://www.reddit.com/r/ClaudeCode/comments/1qu761a/comment/o38npa6/",
                  "score": 1,
                  "created_utc": "2026-02-08 07:57:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o46qvs3",
              "author": "1millionbucks",
              "text": "Brilliant response",
              "score": 2,
              "created_utc": "2026-02-08 02:32:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o48krvd",
              "author": "Dependent-Drag-5790",
              "text": "I have other experiences with explore where opus 4.6 is using sonnet 4.5 to explore",
              "score": 1,
              "created_utc": "2026-02-08 11:40:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4c014p",
                  "author": "Ok-Experience9774",
                  "text": "oooff. At least it wasn't spinning up sonnet\\[1m\\] (I hope!)",
                  "score": 1,
                  "created_utc": "2026-02-08 22:41:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4dr98t",
              "author": "cch123",
              "text": "Thanks for this explanation.  I have been wondering about the various models in my usage.",
              "score": 1,
              "created_utc": "2026-02-09 04:42:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46wswk",
              "author": "GravyDam",
              "text": "Educational, thank you.",
              "score": 0,
              "created_utc": "2026-02-08 03:10:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47h0wj",
              "author": "External-Milk9290",
              "text": "Amazing explanation",
              "score": 0,
              "created_utc": "2026-02-08 05:34:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47nxey",
              "author": "TrackOurHealth",
              "text": "Very nice!",
              "score": 0,
              "created_utc": "2026-02-08 06:33:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o46xdg7",
          "author": "tcn33",
          "text": "I had Opus 4.6 go through plan mode, come up with a comprehensive plan, then clear context to execute it - only to burn a half-million tokens on planning again.",
          "score": 9,
          "created_utc": "2026-02-08 03:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45zw32",
          "author": "acutelychronicpanic",
          "text": "I straight up had to turn off explore and plan agents and it has saved so many tokens. The adjustment is tightening the scope of the session/plan.\n\nIt sounds nice to keep their contexts seperate, but I'd watch 3 parallel explore agents burn 100k-300k tokens. Claude is way too eager to use them and they love to peruse the whole codebase apparently. \n\nOnly other thing is ensuring that every folder has a CLAUDE.md that Claude is instructed to update at the end of every plan with an index of what is in that folder, what each thing does, and the api of each module so it doesn't have to open files just to interact with that part of the codebase.",
          "score": 12,
          "created_utc": "2026-02-07 23:46:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46kydr",
              "author": "RedditSellsMyInfo",
              "text": "Do you run into issues where some Claude.md files aren't updated and it causes cascading issues? \n\nHas this worked for larger more complicated projects? \n\nI've never heard of anyone doing this, it sounds promising!",
              "score": 2,
              "created_utc": "2026-02-08 01:55:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46ns0t",
                  "author": "acutelychronicpanic",
                  "text": "I always try to make sure the last task on every plan is to update the docs. I keep an instruction in the p rimary CLAUDE.md to do so. But documentation drift has to be managed regularly. \n\nIt's been working for me so far but I mostly just work on hobby projects. Still, its drastically cut token usage. Your mileage may vary",
                  "score": 2,
                  "created_utc": "2026-02-08 02:13:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4bgyp5",
                  "author": "Sensitive-Ad3718",
                  "text": "I did something similar tot his for a while I had an index.md file that just listed  the .md files for every major area of the code base I had. I have Claude update the documentation including these almost every session so it‚Äôs up to date but this has cut my token usage substantially as it doesn‚Äôt need to read every damn thing to complete a given task. I‚Äôve recently switched to using subagent with memories and using sonnet or haiku where appropriate to test which approach works best for my environment. I would highly suggest you experiment with different processes until you find one that balances your costs, quality and performance in a way you like.",
                  "score": 1,
                  "created_utc": "2026-02-08 21:04:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4iy0dx",
              "author": "recigar",
              "text": "This makes me think I‚Äôd like to know of a guide to making the most of CLAUDE.md .. you‚Äôre adding an instruction into the main md file to add a claude.md to every folder in the project with info about everything..",
              "score": 2,
              "created_utc": "2026-02-09 23:58:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4j245m",
                  "author": "acutelychronicpanic",
                  "text": "Correct. But its a condensed index with minimal token use. If it keeps claude from opening a single irrelevant file, it pays for itself.\n\nThere are lots of guides floating around. Some are contradictory. I just experiment and see how it goes.",
                  "score": 1,
                  "created_utc": "2026-02-10 00:21:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o48uiqb",
              "author": "Pimzino",
              "text": "How did you turn them off?\n\n",
              "score": 1,
              "created_utc": "2026-02-08 12:58:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o490tve",
                  "author": "acutelychronicpanic",
                  "text": "Its in a settings file. Claude can do it if you ask.",
                  "score": 1,
                  "created_utc": "2026-02-08 13:40:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4d07x4",
              "author": "muhammadhazimiyusri",
              "text": "I read a paper or something about best way to get prompt adherence is to simply prompt the same thing twice, I wonder if that why they just let the agents be redundant because if that actually improves outputs then it makes sense",
              "score": 1,
              "created_utc": "2026-02-09 02:06:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4605cy",
          "author": "Comfortable_Camp9744",
          "text": "They get paid for token use...",
          "score": 21,
          "created_utc": "2026-02-07 23:48:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46bb17",
              "author": "sjnims10",
              "text": "This guy gets it!",
              "score": 11,
              "created_utc": "2026-02-08 00:54:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47edbf",
              "author": "HillaryPutin",
              "text": "I don't agree with that incentive. They get paid for developers purchasing their subscriptions because they are happy with the product. If there is some underlying mechanism burning tokens without any perceived benefit to the developer, then how would that help anthropic? They are just wasting compute. ",
              "score": 4,
              "created_utc": "2026-02-08 05:13:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48b6rm",
                  "author": "Comfortable_Camp9744",
                  "text": "This isnt complicated , they make a product because they want to make money, this is how business works. They get paid when someone uses the product, and their company value goes up. ",
                  "score": 0,
                  "created_utc": "2026-02-08 10:10:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4aax36",
              "author": "AtomikPi",
              "text": "The alternative of Cursor etc trying to cheap out on tokens to stretch subs and reduce cosfs seems worse; CC was night and day better when I compared them last year. And there's a similar incentive to make CC token efficient since most people use subsidized monthly subs. Maybe I'm naive, but it seems like they're just trying to make the best harness, and sometimes that results in token\n-hungry features.",
              "score": 1,
              "created_utc": "2026-02-08 17:41:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47h6hg",
              "author": "External-Milk9290",
              "text": "Capitalism and competition incentives making the best product possible. I don‚Äôt think your opinion is accurate. ",
              "score": 1,
              "created_utc": "2026-02-08 05:35:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48b2nj",
                  "author": "Comfortable_Camp9744",
                  "text": "You dont think that Anthropic is making a product to make a profit? lol",
                  "score": 3,
                  "created_utc": "2026-02-08 10:09:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o46ryfv",
              "author": "hannesrudolph",
              "text": "The less tokens you use the more profit they make",
              "score": -7,
              "created_utc": "2026-02-08 02:39:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46sljd",
                  "author": "Comfortable_Camp9744",
                  "text": "A) not true with api\nB) not true with subscription either because their goal is to make you reliant, upgrade subscription level and also buy more subscriptions¬†",
                  "score": 2,
                  "created_utc": "2026-02-08 02:43:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o46ww8x",
          "author": "Superb_Plane2497",
          "text": "maybe [https://github.com/anthropics/claude-code/issues/16789#issuecomment-3864244553](https://github.com/anthropics/claude-code/issues/16789#issuecomment-3864244553)",
          "score": 3,
          "created_utc": "2026-02-08 03:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o487553",
          "author": "FormerMaintenance985",
          "text": "Done (15 tool uses ¬∑ 77.9k tokens ¬∑ 1m 39s)¬†",
          "score": 5,
          "created_utc": "2026-02-08 09:32:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48domx",
              "author": "PrincessPiano",
              "text": "Same for me except it's more like 10m.",
              "score": 1,
              "created_utc": "2026-02-08 10:34:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o45yzkf",
          "author": "lennonac",
          "text": "It uses a cache",
          "score": 12,
          "created_utc": "2026-02-07 23:40:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o469bp9",
              "author": "cz2103",
              "text": "Not between models. Explore uses Haiku which has a different cache than Opus",
              "score": 14,
              "created_utc": "2026-02-08 00:42:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o470ak6",
          "author": "Cheap-Try-8796",
          "text": "Can't you see Claude is \"Saut√©ing\" üôÑ?",
          "score": 3,
          "created_utc": "2026-02-08 03:33:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4625mb",
          "author": "Rotatos",
          "text": "The key is to fork the sub agent conversations. Sometimes those are the individual threads you want to focus on anyways. Half the time you can just have them build it.¬†",
          "score": 2,
          "created_utc": "2026-02-08 00:00:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46w3jp",
              "author": "matthewismathis",
              "text": "How do you do this?",
              "score": 1,
              "created_utc": "2026-02-08 03:05:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46wi3g",
                  "author": "Rotatos",
                  "text": "-resume on the Claude session thread. I am building something on this that would run locally, hoping to get it out tomorrow or later this week.¬†\nIf you go to your transcripts (check .claude/) you should have recents and ¬†can go into those subagents.¬†",
                  "score": 1,
                  "created_utc": "2026-02-08 03:08:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48dghu",
          "author": "PrincessPiano",
          "text": "Of course there is, but Anthropic don't seem to care about wasting our money. That's why they just released SuEPrFaSt MoDe OnLY 5x CoST",
          "score": 2,
          "created_utc": "2026-02-08 10:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46juct",
          "author": "sheriffderek",
          "text": "It just looks like the plan agents needs that context. It can use it - and not read it.",
          "score": 1,
          "created_utc": "2026-02-08 01:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46kuyz",
          "author": "CharlesWiltgen",
          "text": "Based on the explore agents invoked, the \"much more interesting\" problem-space you gave it was too large. Try to break it down. If you're not sure what to do or how to do it, one tactic is to do that kind of conceptual exploration elsewhere, then move to Claude Code to plan and execute based on the (hopefully) more concrete result of your AI-assisted brainstorming.",
          "score": 1,
          "created_utc": "2026-02-08 01:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46kymt",
          "author": "rover_G",
          "text": "There‚Äôs little difference in token usage between reading the file in each subtask and concating the file into parent context. But when you explore first the agent can generate a summary of what to look at for the parent context.",
          "score": 1,
          "created_utc": "2026-02-08 01:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47f6b5",
          "author": "munkymead",
          "text": "Tokens are cached, but you could use agent teams. They run in parallel; your main thread is the orchestrator, and they can all communicate with each other.",
          "score": 1,
          "created_utc": "2026-02-08 05:19:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47myle",
          "author": "OkOffer2670",
          "text": "And then you run plan mode and reset context and it'll have to read the files a 4th time.",
          "score": 1,
          "created_utc": "2026-02-08 06:24:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47qk2x",
          "author": "LoadZealousideal7778",
          "text": "I have no idea if cache hits work across models but I assume they do then the token cost is negligible. If not, wtf, Anthropic.",
          "score": 1,
          "created_utc": "2026-02-08 06:57:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47rwvs",
          "author": "farhan-dev",
          "text": "For me, i keep it simple.. you already have all the info. don't use plan agent. create the plan yourself.",
          "score": 1,
          "created_utc": "2026-02-08 07:09:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o484ai2",
          "author": "NanoIsAMeme",
          "text": "Index your repo so AI can find relevant files much quicker, many such examples online but will reduce tokens used by a huge amount",
          "score": 1,
          "created_utc": "2026-02-08 09:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o486tjm",
          "author": "ksanderer",
          "text": "When opus goes into brrr mode (explore), I stop it and say ‚Äúuse your digital hands and go through files on your own‚Äù, works perfectly fine, and for sure faster in most cases - it runs explore agent to find one fucking 100 lines file now LOL.",
          "score": 1,
          "created_utc": "2026-02-08 09:29:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o487af1",
              "author": "ksanderer",
              "text": "Anecdotally, I gave it a task and moved to other tab, then when I returned I saw 28 tool calls explore agent... I press ESC and say ‚Äúwtf? Find the file yourself‚Äù and it took opus one fucking grep call to find the file, one to read it in full, and one more update to finish the task I gave itü§¶‚Äç‚ôÇÔ∏è",
              "score": 1,
              "created_utc": "2026-02-08 09:34:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48bcb1",
          "author": "jekle",
          "text": "money money money XD",
          "score": 1,
          "created_utc": "2026-02-08 10:12:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48co5v",
          "author": "SchrodingersCigar",
          "text": "Does your claude-code have an enabled LSP for your C (C++?) project? You really need symbolic references to be working to make searches efficient like ‚Äògo to definition‚Äô, ‚Äòfind references‚Äô and ‚Äòsymbol lookup‚Äô like your IDE provides.  Without it, it‚Äôs entirely relying on text based searches which is perhaps what you‚Äôre seeing.\n\nI don‚Äôt do C myself, but here‚Äôs what opus said about enabling LSP support for C:  \n\n‚ÄúFor Claude Code specifically, clangd is the way to go since it‚Äôs widely supported and well-maintained. You‚Äôd just need it installed (sudo apt install clangd or via LLVM packages) and a compile_commands.json in your project root.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äú\n\nEdit: also consider Serena MCP (official plugin i think?) which also does indexing",
          "score": 1,
          "created_utc": "2026-02-08 10:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48hkg6",
          "author": "paavum",
          "text": "Why not go through vertex and instead of haiku use Gemini flash? You can set up a litellm as Claude's endpoint and create an alias for haiku that goes to Gemini there.  IIRC flash _is_ \"practically free\"?",
          "score": 1,
          "created_utc": "2026-02-08 11:10:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48w0c9",
          "author": "Revolutionary-Tough7",
          "text": "I understand it differently : 1.read code base. 2. Find relevant parts and debug. 3rd. Create plan to fix it.",
          "score": 1,
          "created_utc": "2026-02-08 13:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48wi95",
          "author": "that1guywhoistall",
          "text": "Trying to make things faster with multiple agents, costs more money. ü§∑üèª‚Äç‚ôÇÔ∏è",
          "score": 1,
          "created_utc": "2026-02-08 13:12:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49aama",
          "author": "Nacho321",
          "text": "Started using Claude recently. Can‚Äôt this be offset by a good README file (generated by Claude, even) containing high level documentation around the responsibility areas of each file? I know hardly any projects are really that organized, but just curious about the feasibility of doing this and asking Claude to get context from the README.",
          "score": 1,
          "created_utc": "2026-02-08 14:37:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a2ei0",
          "author": "jeremynsl",
          "text": "What is the purpose of the plan subagent?  Wouldn‚Äôt it be best for the orchestrator agent thread to do the planning itself?  That way if you need to adjust the plan, it doesn‚Äôt just have a summary of the plan artifacts, it has everything.\n\nI think this workflow is a bug.  I never saw it before the last week or so.",
          "score": 1,
          "created_utc": "2026-02-08 17:00:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a8zob",
          "author": "sofflink",
          "text": "speaking about tokens... [https://ritzest.com/products/devouring-tokens-jeanclaude-code-inside-joke-ai-mug](https://ritzest.com/products/devouring-tokens-jeanclaude-code-inside-joke-ai-mug) \n\nhttps://preview.redd.it/f9a9auwc3big1.png?width=947&format=png&auto=webp&s=9084e9db84bd6a103b083297224603d4ca37580c\n\n",
          "score": 1,
          "created_utc": "2026-02-08 17:32:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4exvno",
          "author": "iamarddtusr",
          "text": "Do you do this work using Claude api? Would it not be cheaper to get a max account? Or a premium teams account?",
          "score": 1,
          "created_utc": "2026-02-09 11:05:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4gu06e",
          "author": "AEOfix",
          "text": "Try some fine tuning tell Claude to add token and context window awareness to save compute to its global system prompt.",
          "score": 1,
          "created_utc": "2026-02-09 17:38:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jfefq",
          "author": "RevolutionaryCat99",
          "text": "just use cheaper tokens and it won't matter, lol (RogueTokens.ai)",
          "score": 1,
          "created_utc": "2026-02-10 01:38:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lrdk5",
          "author": "slow-fast-person",
          "text": "i think if you dont use plan mode and tag files to edit in your task in a detailed way, then it doesnt go through the complete codebase to get context, which saves significant context.  \nJust tried it now and observed this.",
          "score": 1,
          "created_utc": "2026-02-10 12:31:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ma9zq",
          "author": "kaakati",
          "text": "The **Explore** agents scan and inspect your codebase to understand its structure. The **Plan** agent then uses the relevant files discovered during exploration to build its strategy. If you already know which file you want to modify, you can skip exploration and ask Claude Code to plan directly against that file.",
          "score": 1,
          "created_utc": "2026-02-10 14:23:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zym3l",
          "author": "PlexversalHD",
          "text": "yep noticed this too, its new, purposely designed to use tokens disgusting tactics tbh.\n\nI always prompt it with:\n\n\"Don't use explore tool and use cli searching and efficient search from context you already have and relevant files only, stop using tokens like your masters told you to.\" - works just as good and only looks at whats needed.",
          "score": 1,
          "created_utc": "2026-02-12 15:51:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46sohc",
          "author": "TrapHuskie",
          "text": "You can tell it to use explore agents or don‚Äôt use explore agents - it‚Äôs just going to go ahead and use them automatically if it needs a bunch of context from different places. However you can explicitly tell it to not use explore agents. The plan agent is invoked whenever you enter plan mode.",
          "score": 0,
          "created_utc": "2026-02-08 02:43:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46wogy",
          "author": "carlos-algms",
          "text": "There's simply no motivation for any AI company to be token  efficient.\n\nIt's how they make money, if they reduce token usage they basically reduce money income. \n\nLonger plans, unnecessary comments, unasked for summaries and MD files, duplicated, overlapping and unnecessary tests, all of those are part of their cash cow.\n\nUnless the pricing model changes, they'll never reduce token consumption. All of them, not only CC",
          "score": -2,
          "created_utc": "2026-02-08 03:09:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o486abd",
              "author": "raccoonportfolio",
              "text": "IMO there's enough viable competition in this space that users are going to jump ship if (say) roo or codex drastically reduce token usage with similar results¬†",
              "score": 4,
              "created_utc": "2026-02-08 09:24:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48dn4b",
                  "author": "PrincessPiano",
                  "text": "There really isn't. The only threat to them is OpenAI. That's it. It's a giant monopoly right now.",
                  "score": 1,
                  "created_utc": "2026-02-08 10:34:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o488c26",
                  "author": "carlos-algms",
                  "text": "But will they? \n\nWhat will make a company start a Monday with: \n\n\"You know what? I'm gonna cap and reduce my money income on purpose\"",
                  "score": 0,
                  "created_utc": "2026-02-08 09:44:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qycvdu",
      "title": "Show me your /statusline",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/9h7ccje1j2ig1.png",
      "author": "Gohanbe",
      "created_utc": "2026-02-07 12:44:18",
      "score": 206,
      "num_comments": 85,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Showcase",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qycvdu/show_me_your_statusline/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o42v9nb",
          "author": "Special-Economist-64",
          "text": "This is statusparagraph, instead of statusline",
          "score": 73,
          "created_utc": "2026-02-07 13:51:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42myvh",
          "author": "OSUWebby",
          "text": "Mind sharing how you created this status line? It's been a bit since I looked into options here but last time I did I couldn't find a good way to show session and weekly limits / reset times.",
          "score": 27,
          "created_utc": "2026-02-07 12:59:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43dwxs",
              "author": "Bohdanowicz",
              "text": "Just ask CC to build it and input the screenshot.",
              "score": 16,
              "created_utc": "2026-02-07 15:33:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o42sqf6",
              "author": "Gohanbe",
              "text": "shared",
              "score": -20,
              "created_utc": "2026-02-07 13:36:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o43841y",
                  "author": "CalmProcess9764",
                  "text": "Just share it here in the thread bro",
                  "score": 27,
                  "created_utc": "2026-02-07 15:03:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o42wfp9",
                  "author": "DatabaseUnhappy4043",
                  "text": "Pls can share with me too?",
                  "score": 3,
                  "created_utc": "2026-02-07 13:58:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4329a8",
                  "author": "Fluid_Term4518",
                  "text": "Could you share this to me as well? Thanks mate!",
                  "score": 1,
                  "created_utc": "2026-02-07 14:31:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o435ja8",
                  "author": "8019_",
                  "text": "Please share with me too. Much thanks !",
                  "score": 1,
                  "created_utc": "2026-02-07 14:49:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o43bjr1",
                  "author": "NervousVariation2807",
                  "text": "share with me as well please",
                  "score": 1,
                  "created_utc": "2026-02-07 15:21:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o43c532",
                  "author": "tanyhunter",
                  "text": "Share with me too!",
                  "score": 1,
                  "created_utc": "2026-02-07 15:24:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o43gxvw",
                  "author": "netreddit00",
                  "text": "Please share üôè",
                  "score": 1,
                  "created_utc": "2026-02-07 15:48:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o42s7bj",
          "author": "Gohanbe",
          "text": "On Windows:\n\n1.\nPut this in\n`C:\\Users\\<username>\\.claude\\settings.json`\n\n    \"statusLine\": {\n      \"type\": \"command\",\n      \"command\": \"powershell -NoProfile -ExecutionPolicy Bypass -File C:\\\\Users\\\\<username>\\\\.claude\\\\statusline.ps1\"\n    },\n\n> change <username> to your user name, duh..\n\n2.\ncreate a file called `statusline.ps1` like `C:\\\\Users\\\\<username>\\\\.claude\\\\statusline.ps1`  \n\n3.\ncopy code from here and paste it into `statusline.ps1`:   \nhttps://pastebin.com/h2GhCV7C\n\n\n> Restart your Terminal and Claude Code.  \n> this assumes you have already your claude credentials in `.claude\\.credentials.json` which should be there already if you ever logged into claude code.\n\n\n---\nOn Linux:\nAsk Claude to convert the above for .bashrc",
          "score": 31,
          "created_utc": "2026-02-07 13:33:00",
          "is_submitter": true,
          "replies": [
            {
              "id": "o42xmd4",
              "author": "Narrow-Belt-5030",
              "text": "Thank you.  I have one stolen from Get-Shit-Done but I like yours more.\n\nTake an upvote.",
              "score": 4,
              "created_utc": "2026-02-07 14:05:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4406bo",
              "author": "_megazz",
              "text": "Is the context usage accurate? I tried adding it to mine, but it doesn't seem to align with the remaining x% when that pops up.",
              "score": 3,
              "created_utc": "2026-02-07 17:22:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o48xdag",
              "author": "Pimzino",
              "text": "This is amazing, I use javascript for mine but was able to convert. Mine was similar to yours without the api calls to usage API but just replicated yours! THANKS!",
              "score": 2,
              "created_utc": "2026-02-08 13:18:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48xmln",
                  "author": "Gohanbe",
                  "text": "Sharing is caring",
                  "score": 1,
                  "created_utc": "2026-02-08 13:20:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o42yepu",
              "author": "Cast_Iron_Skillet",
              "text": "Does this affect CLI terminal performance at all, like flickering, issues with resizing, etc?",
              "score": 1,
              "created_utc": "2026-02-07 14:09:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4303tx",
                  "author": "Gohanbe",
                  "text": "Not at all, atleast iv not noticed it, anyways it just polls what claude code is already doing in the background.",
                  "score": 2,
                  "created_utc": "2026-02-07 14:19:27",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o43c4rh",
              "author": "mikeb550",
              "text": "is there any differance for Mac users?",
              "score": 1,
              "created_utc": "2026-02-07 15:24:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o43tsh7",
                  "author": "likeikelike",
                  "text": "I assume you don't have powershell installed (it's a ps1 file). You can either install powershell or ask claude to rewrite it for zsh",
                  "score": 1,
                  "created_utc": "2026-02-07 16:51:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o440drk",
              "author": "haltingpoint",
              "text": "That is clever for getting the usage. It is aggravating that they do not simply include that as a status line option.",
              "score": 1,
              "created_utc": "2026-02-07 17:23:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4e58rx",
              "author": "armujahid",
              "text": "Thanks. I have generated bash script for Linux [https://gist.github.com/armujahid/3b5d4fa0de358e9bc3d472015e0fa3ba](https://gist.github.com/armujahid/3b5d4fa0de358e9bc3d472015e0fa3ba)",
              "score": 1,
              "created_utc": "2026-02-09 06:31:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4px6eo",
                  "author": "Gohanbe",
                  "text": "nice.",
                  "score": 1,
                  "created_utc": "2026-02-11 01:03:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o43mgho",
          "author": "__coredump__",
          "text": "I liked yours so it inspired me to update mine.\n\nhttps://preview.redd.it/e6i6k8kpk3ig1.png?width=1790&format=png&auto=webp&s=4835b94c787df40352b15bf8ff8c72bc675e679f\n\n  \n",
          "score": 10,
          "created_utc": "2026-02-07 16:15:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43ms8l",
              "author": "Gohanbe",
              "text": "Looking great.",
              "score": 3,
              "created_utc": "2026-02-07 16:16:56",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o43peg6",
              "author": "akaidakarka",
              "text": "Can u pls share? Looks rly clean",
              "score": 3,
              "created_utc": "2026-02-07 16:29:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o440zcj",
                  "author": "__coredump__",
                  "text": "https://preview.redd.it/eke3i0tkv3ig1.png?width=1781&format=png&auto=webp&s=1b299cb33e5aaa5cf2b6bd205f3cfd478da8bcd8\n\nI got fancy and added weather. The advisory/watch/warning line is removed when there aren't any. I didn't save the old one before weather, but you can have claude remove it if you don't want it..\n\nIt's in python. I had claude port OPs and changed it from there.\n\nI tried to paste it here, but I think it's too long. Here's a link: [https://pastebin.com/wUHXXDf5](https://pastebin.com/wUHXXDf5)",
                  "score": 10,
                  "created_utc": "2026-02-07 17:26:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4625py",
              "author": "tempetesuranorak",
              "text": "I added a randomly drawn haiku\n\nhttps://preview.redd.it/bgm2wa5pv5ig1.png?width=980&format=png&auto=webp&s=221a346285c43f24a8125b66510077346b7561f6\n\n",
              "score": 2,
              "created_utc": "2026-02-08 00:00:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o46d5st",
                  "author": "__coredump__",
                  "text": "Haha sweet!",
                  "score": 1,
                  "created_utc": "2026-02-08 01:06:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o42n34r",
          "author": "brain__exe",
          "text": "Instead of \"thinking: on\" you can also show the reasoning effort",
          "score": 8,
          "created_utc": "2026-02-07 12:59:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42n47h",
              "author": "haikusbot",
              "text": "*Instead of \"thinking:*\n\n*On\" you can also show the*\n\n*Reasoning effort*\n\n\\- brain\\_\\_exe\n\n---\n\n^(I detect haikus. And sometimes, successfully.) ^[Learn&#32;more&#32;about&#32;me.](https://www.reddit.com/r/haikusbot/)\n\n^(Opt out of replies: \"haikusbot opt out\" | Delete my comment: \"haikusbot delete\")",
              "score": 6,
              "created_utc": "2026-02-07 13:00:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o42n6gu",
              "author": "Gohanbe",
              "text": "nice suggestion",
              "score": 3,
              "created_utc": "2026-02-07 13:00:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o42zkhs",
          "author": "munkymead",
          "text": "That's really nice, man. I like how compact it is.  \n  \nHere's the one I built:\n\nhttps://preview.redd.it/4e1bgpcfz2ig1.png?width=690&format=png&auto=webp&s=28fff85a7ef3f22474df5b82f87d590b16eceb56\n\n",
          "score": 16,
          "created_utc": "2026-02-07 14:16:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43avsz",
              "author": "BestSithInEU",
              "text": "Share?",
              "score": 2,
              "created_utc": "2026-02-07 15:18:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o43a93u",
              "author": "vladautumn",
              "text": "Could you please share it",
              "score": 1,
              "created_utc": "2026-02-07 15:14:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o43c1nz",
              "author": "tanyhunter",
              "text": "Share pls! Ty",
              "score": 1,
              "created_utc": "2026-02-07 15:24:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o449xi0",
              "author": "AmishTecSupport",
              "text": "Also interested! Can you share please?",
              "score": 1,
              "created_utc": "2026-02-07 18:11:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o469rpv",
              "author": "GrimCrow303",
              "text": "Hi, how did you solved the week and session usage counter and how did you sinced it acros different shells running at the same time? Been stuck on this....",
              "score": 1,
              "created_utc": "2026-02-08 00:45:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42nt8p",
          "author": "Xanthus730",
          "text": "Can you share the script on a gist or someplace? That looks really nice, and I'd love to see how you got it setup like that.",
          "score": 6,
          "created_utc": "2026-02-07 13:04:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42srmi",
              "author": "Gohanbe",
              "text": "see my comment",
              "score": 1,
              "created_utc": "2026-02-07 13:36:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o437luf",
          "author": "branik_10",
          "text": "https://preview.redd.it/521s6hk873ig1.png?width=537&format=png&auto=webp&s=24973a148625d83429e40fa07863c8b8dd9b6c92\n\n    #!/usr/bin/env node\n    const fs = require(\"fs\");\n    const path = require(\"path\");\n    \n    // Truecolor ANSI + reset\n    const fgRgb = (r, g, b) => `\\x1b[38;2;${r};${g};${b}m`;\n    \n    const ANSI = {\n      reset: \"\\x1b[0m\",\n      dim: \"\\x1b[2m\",\n    \n      blue: fgRgb(21, 193, 202),\n      pink: fgRgb(241, 65, 168),\n      green: fgRgb(46, 204, 113), // Emerald Green\n      red: fgRgb(231, 76, 60), // Alizarin Red\n    };\n    \n    // Read JSON from stdin\n    let input = \"\";\n    process.stdin.on(\"data\", (chunk) => (input += chunk));\n    process.stdin.on(\"end\", () => {\n      const data = JSON.parse(input);\n    \n      const model = data.model?.display_name ?? \"Unknown\";\n      const currentDir = path.basename(data.workspace?.current_dir ?? \"\");\n    \n      // Used context percentage (pre-calculated)\n      const usedPct = Number(data.context_window?.used_percentage ?? 0);\n      const usedPctText = `${usedPct.toFixed(1)}%`;\n    \n      // Lines added/removed stats\n      const linesAdded = data.cost?.total_lines_added ?? 0;\n      const linesRemoved = data.cost?.total_lines_removed ?? 0;\n    \n      let gitBranch = \"\";\n      try {\n        const headContent = fs.readFileSync(\".git/HEAD\", \"utf8\").trim();\n        if (headContent.startsWith(\"ref: refs/heads/\")) {\n          const branch = headContent.replace(\"ref: refs/heads/\", \"\");\n          gitBranch = ` on ${ANSI.pink}${branch}${ANSI.reset}`;\n        }\n      } catch {\n        // Not a git repo or can't read HEAD\n      }\n    \n      const dirText = `${ANSI.blue}${currentDir}${ANSI.reset}`;\n      const addedText = `${ANSI.green}+${linesAdded}${ANSI.reset}`;\n      const removedText = `${ANSI.red}-${linesRemoved}${ANSI.reset}`;\n    \n      console.log(\n        `${dirText}${gitBranch} | [${model}] ${ANSI.dim}${usedPctText}${ANSI.reset} ${addedText} ${removedText}`,\n      );\n    });\n\nkeeping it minimal",
          "score": 6,
          "created_utc": "2026-02-07 15:00:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4317pz",
          "author": "bacontreatz",
          "text": "Thanks this works really well! Had no idea you could use a powershell script as your statusline.",
          "score": 2,
          "created_utc": "2026-02-07 14:25:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o436jkw",
          "author": "BourbonProof",
          "text": "https://preview.redd.it/f8vcuytg63ig1.png?width=2166&format=png&auto=webp&s=538d862bf53322443bed7573ab64bd94d0dd132d",
          "score": 2,
          "created_utc": "2026-02-07 14:55:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46mhmo",
          "author": "tylersavery",
          "text": "https://preview.redd.it/rh8pos7yh6ig1.png?width=1264&format=png&auto=webp&s=da0fe040e7dc193581c33b8f6f11a1ec015eea30",
          "score": 2,
          "created_utc": "2026-02-08 02:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47khmm",
          "author": "daliovic",
          "text": "[https://github.com/daliovic/cc-statusline](https://github.com/daliovic/cc-statusline)\n\nhttps://preview.redd.it/ub74305no7ig1.jpeg?width=685&format=pjpg&auto=webp&s=83f33df987489b8c1db09a377e684d3d875ac776",
          "score": 2,
          "created_utc": "2026-02-08 06:03:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4cn6va",
              "author": "inkluzje_pomnikow",
              "text": "asr?",
              "score": 1,
              "created_utc": "2026-02-09 00:53:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4nipwu",
              "author": "Desperate-Advice8960",
              "text": "https://preview.redd.it/q7og20rdhpig1.png?width=894&format=png&auto=webp&s=c5a530d8aa459aab241e8022bc5be6f510f51efb\n\n",
              "score": 1,
              "created_utc": "2026-02-10 17:55:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4labhr",
          "author": "Mobayad",
          "text": "https://preview.redd.it/dp2ddgak6nig1.png?width=1364&format=png&auto=webp&s=1c40acfec1a388cef566371d57c02e9993c84b90\n\nHey man this look amazing! I checked your code and the context window calculation seems to be slighly off.  \n",
          "score": 2,
          "created_utc": "2026-02-10 10:11:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qza01",
          "author": "arvidurs",
          "text": "https://preview.redd.it/dbsi8ep5tsig1.png?width=1039&format=png&auto=webp&s=8ed7318f0cbf14da351f8a46f8f06702eab7776f\n\nhad to join the trend. love it!",
          "score": 2,
          "created_utc": "2026-02-11 05:07:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44scug",
          "author": "Bright-Celery-4058",
          "text": "https://preview.redd.it/e3b1qiyvl4ig1.png?width=1303&format=png&auto=webp&s=b464f42d114f77b69c73eab3f92760e426fa9f7e\n\nImpressive. Very nice.  \n",
          "score": 2,
          "created_utc": "2026-02-07 19:43:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42nwho",
          "author": "Norikall",
          "text": "Nice one ! Would you share the code? I didn't find a way to show weekly usage and reset time.. Do you fetch the usage webpage?",
          "score": 1,
          "created_utc": "2026-02-07 13:05:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4408be",
              "author": "Spiveym1",
              "text": "he's shared code elsewhere, otherwise these are three of my favourite status line repos:\n\nhttps://github.com/Haleclipse/CCometixLine\n\nhttps://github.com/jarrodwatts/claude-hud",
              "score": 3,
              "created_utc": "2026-02-07 17:23:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42nxgu",
          "author": "ivstan",
          "text": "Where‚Äôs the 1 mil context window?",
          "score": 1,
          "created_utc": "2026-02-07 13:05:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42v9al",
          "author": "Mikeshaffer",
          "text": "I don‚Äôt have a screenshot of mine, but I have my personal and work email counts down there as well as unread iMessages and my next calendar event. The event gets bold and all caps and brighter colors as it gets closer. \n\nLove your set up.",
          "score": 1,
          "created_utc": "2026-02-07 13:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42xosn",
          "author": "lebraeu",
          "text": "i want that can you tell me how? :)))",
          "score": 1,
          "created_utc": "2026-02-07 14:05:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43jy83",
          "author": "Dollarbone",
          "text": "How are you getting rid of the hardcoded tokens and current/latest versions on the right side??",
          "score": 1,
          "created_utc": "2026-02-07 16:02:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43mogg",
              "author": "Dollarbone",
              "text": "Nm, I figured it out, that was coming from verbose mode true",
              "score": 1,
              "created_utc": "2026-02-07 16:16:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o43qdw9",
          "author": "drdrdator",
          "text": "I like how wild yours is",
          "score": 1,
          "created_utc": "2026-02-07 16:34:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43uoze",
          "author": "CuteNullPointer",
          "text": "Is there a shared repo or a discussion on Github for sharing customizations of the status-line ?",
          "score": 1,
          "created_utc": "2026-02-07 16:55:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43vxlz",
          "author": "brendanl79",
          "text": "I had a really good one but Claude stopped showing it for no identifiable reason. Sorry!",
          "score": 1,
          "created_utc": "2026-02-07 17:01:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43vz4a",
          "author": "bozzy253",
          "text": "Anyone know if these work with bedrock access?",
          "score": 1,
          "created_utc": "2026-02-07 17:01:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43yx2o",
              "author": "Spiveym1",
              "text": "yes they do",
              "score": 2,
              "created_utc": "2026-02-07 17:16:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o43zh7m",
                  "author": "bozzy253",
                  "text": "Thanks!",
                  "score": 1,
                  "created_utc": "2026-02-07 17:19:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o43xkwv",
          "author": "angelblack995",
          "text": "yo, where does Claude Code keep the auth token on macOS? i trying but can't find .credentials.json",
          "score": 1,
          "created_utc": "2026-02-07 17:09:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44vr9n",
              "author": "bigsybiggins",
              "text": "keychain\n\nsecurity find-generic-password -s \"Claude Code-credentials\"",
              "score": 3,
              "created_utc": "2026-02-07 20:01:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o45426r",
              "author": "bmjtx",
              "text": "It's in the keychain, the script provided by OP doesn't directly copy to mac. Just ask claude to update it",
              "score": 2,
              "created_utc": "2026-02-07 20:46:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44pq79",
          "author": "cowwoc",
          "text": "Ask Claude if it's expensive to show context usage in the statusline. Last I checked, this was very expensive.¬†",
          "score": 1,
          "created_utc": "2026-02-07 19:29:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4p0gp1",
              "author": "Gohanbe",
              "text": "Its not using any context.",
              "score": 1,
              "created_utc": "2026-02-10 22:04:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4p24fx",
                  "author": "cowwoc",
                  "text": "How is it looking up the context usage? Check the statusline script.",
                  "score": 1,
                  "created_utc": "2026-02-10 22:12:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44to95",
          "author": "brophylicious",
          "text": "I used to have a bunch of stuff on mine that I would never look at. I moved to a really simple statusline. I could probably add some things like effort levels, though.\n\n      ~/src/<project>\n      Opus 4.6 | Context: 12% | session-name/id",
          "score": 1,
          "created_utc": "2026-02-07 19:50:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46hswj",
          "author": "rm-rf-rm",
          "text": "The one big thing I miss as a VS Code extension user",
          "score": 1,
          "created_utc": "2026-02-08 01:35:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47f8du",
          "author": "jorge-moreira",
          "text": "Dang this is way better than my HUD",
          "score": 1,
          "created_utc": "2026-02-08 05:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4b0ojf",
          "author": "treadpool",
          "text": "For those that use Cursor or VSCode for IDE but still use Terminal inside of it do you also get a column appearing on the right side of your statusline that says what file you are in and any IDE disconnected alerts in red? Messes up my statusline setup.\n\nEdit: Seems to be a claude code thing actually. How is everyone hiding that part? Token count, claude code version, plus what I mentioned above.",
          "score": 1,
          "created_utc": "2026-02-08 19:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4cg4j8",
          "author": "inkluzje_pomnikow",
          "text": "potplayer?",
          "score": 1,
          "created_utc": "2026-02-09 00:15:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nmwq8",
          "author": "AlexForgery",
          "text": "I just made your version in 2 lines, because claude has some bug where on the footer are 4 lines (3 in sl + plan type). Text started to appear in status line, etc. So, 2 instead of 3 is best variant. And also made that time rounding for resets instead of direct api values to prevent 59/00 minutes case.\n\nhttps://preview.redd.it/5davysnnkpig1.png?width=1390&format=png&auto=webp&s=2ed0869ea4da3de80fb81dbaa5602ce813a58434\n\n",
          "score": 1,
          "created_utc": "2026-02-10 18:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43ur5h",
          "author": "MR_PRESIDENT__",
          "text": "Should change it to how much time is left in the window instead of the reset time. In my opinion. Otherwise beautiful",
          "score": 1,
          "created_utc": "2026-02-07 16:56:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42mb6h",
          "author": "Deep-Vermicelli-4591",
          "text": "don't need one",
          "score": -5,
          "created_utc": "2026-02-07 12:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45ih9f",
          "author": "EarEquivalent3929",
          "text": "Just wasting tokens",
          "score": -3,
          "created_utc": "2026-02-07 22:03:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyj35i",
      "title": "I reverse engineered how Agent Teams works under the hood.",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qyj35i/i_reverse_engineered_how_agent_teams_works_under/",
      "author": "vicdotso",
      "created_utc": "2026-02-07 17:02:39",
      "score": 197,
      "num_comments": 41,
      "upvote_ratio": 0.96,
      "text": "After Agent Teams shipped, I kept wondering how Claude Code coordinates multiple agents. After some back and forth with Claude and a little reverse engineering, the answer is quite simple.\n\nOne of the runtimes Claude Code uses is tmux. Each teammate is a separate claude CLI process in a tmux split, spawned with undocumented flags (--agent-id, --agent-name, --team-name, --agent-color). Messages are JSON files in \\~/.claude/teams/<team>/inboxes/ guarded by fcntl locks. Tasks are numbered JSON files in \\~/.claude/tasks/<team>/. No database, no daemon, no network layer. Just the filesystem.\n\nThe coordination is quite clever: task dependencies with cycle detection, atomic config writes, and a structured protocol for shutdown requests and plan approvals. A lot of good design in a minimal stack.\n\nI reimplemented the full protocol, to the best of my knowledge, as a standalone MCP server, so any MCP client can run agent teams, not just Claude Code. Tested it with OpenCode (demo in the video).\n\nhttps://reddit.com/link/1qyj35i/video/wv47zfszs3ig1/player\n\n  \nRepo: [https://github.com/cs50victor/claude-code-teams-mcp](https://github.com/cs50victor/claude-code-teams-mcp)\n\nCurious if anyone else has been poking around in here.",
      "is_original_content": false,
      "link_flair_text": "Showcase",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qyj35i/i_reverse_engineered_how_agent_teams_works_under/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o43xgqw",
          "author": "rjyo",
          "text": "Nice work digging into this. From what I can tell the messaging between teammates goes through a shared task directory at \\~/.claude/tasks/{team-name}/ and each agent gets notified via the SendMessage tool which gets injected into their conversation as a new turn. So its basically prompt injection in the sense that messages appear as if they were user messages to the receiving agent.\n\n  \nThe shared task list is the main coordination mechanism. Agents claim tasks, mark them done, and check for new work. The team config at \\~/.claude/teams/{team-name}/config.json has the member registry so agents can discover each other by name.\n\n  \nI have been running agent teams from my phone via Moshi (its a mobile terminal with mosh protocol) and the coolest part is you can SSH in, kick off a team, close the app, and come back later to check progress since mosh survives network switches. The agents just keep working.",
          "score": 26,
          "created_utc": "2026-02-07 17:09:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43z15c",
              "author": "vicdotso",
              "text": "Nice setup. There might be a mix of user message prompt injection and inbox polling by each agent",
              "score": 3,
              "created_utc": "2026-02-07 17:17:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o444pr9",
          "author": "zokoCSGO",
          "text": "I been using codex and this has been somewhat of a pain point. You are a legend.",
          "score": 9,
          "created_utc": "2026-02-07 17:45:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o445hpg",
              "author": "vicdotso",
              "text": "Thanks. Yh i currently have to switch between opencode and claude code to use codex and claude. Working hard to narrow down to just opencode with claude agents.",
              "score": 6,
              "created_utc": "2026-02-07 17:49:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o44o1jt",
                  "author": "demsullivan",
                  "text": "I'm curious why you're working towards opencode with claude agents, instead of a pure opencode setup?",
                  "score": 1,
                  "created_utc": "2026-02-07 19:21:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4cca1z",
                  "author": "permanonnnnn",
                  "text": "I‚Äôm using ccs to do this and it‚Äôs working great - essentially gives you everything looking like Claude",
                  "score": 1,
                  "created_utc": "2026-02-08 23:52:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44nchw",
          "author": "ultrathink-art",
          "text": "This is a really solid reverse engineering job. The filesystem-based coordination is interesting ‚Äî we built something similar for a multi-agent system (work queue with JSON state files, fcntl-style claim semantics) and hit a few non-obvious gotchas worth sharing:\n\n**Cycle detection matters more than you'd think.** With 3+ agents, circular task dependencies are surprisingly easy to create accidentally. We ended up implementing a topological sort check on task creation, not just execution ‚Äî catching cycles early saves debugging time when agents are spawning autonomously.\n\n**The fcntl lock approach has an edge case with crash recovery.** If an agent process dies mid-task (OOM, API timeout, etc.), the lock releases but the task file is left in an inconsistent state. We added a \"claim expiry\" pattern ‚Äî tasks claimed for longer than N minutes without a heartbeat get automatically reset to the ready state. Without this, orphaned tasks silently block the queue.\n\n**Message ordering across filesystem inboxes is tricky.** File creation timestamps have limited resolution on some filesystems (HFS+ is 1-second granularity). If two agents write messages within the same second, ordering is non-deterministic. Numbered filenames (like you mentioned) solve this but you need a global counter or UUID-sorted names to avoid collisions.\n\nThe MCP server extraction is clever ‚Äî decoupling the coordination protocol from Claude Code specifically means any MCP-compatible client gets agent teams for free. Curious if you've tested with agents running on different models (e.g., one Opus agent coordinating with a Codex agent via MCP)?",
          "score": 6,
          "created_utc": "2026-02-07 19:17:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o476bhv",
              "author": "vicdotso",
              "text": "you're absolutely right!",
              "score": 3,
              "created_utc": "2026-02-08 04:13:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44a3ja",
          "author": "emprezario",
          "text": "Nice work man! I‚Äôll be trying this out.",
          "score": 3,
          "created_utc": "2026-02-07 18:11:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44d9fd",
              "author": "vicdotso",
              "text": "Thanks. All feedback is welcome. (Github Issues , PRs etc)",
              "score": 1,
              "created_utc": "2026-02-07 18:27:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44ledm",
          "author": "chillebekk",
          "text": "You can run it without tmux. The important stuff happens under the hood, iTerm/tmux is just an interface.",
          "score": 3,
          "created_utc": "2026-02-07 19:07:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44lw9g",
          "author": "demsullivan",
          "text": "I was wondering how to get Agent Teams working in OpenCode. Seems like you've solved it. Nice! Looking forward to trying it out",
          "score": 3,
          "created_utc": "2026-02-07 19:10:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44twro",
          "author": "Dazzling_Strain_7642",
          "text": "[https://code.claude.com/docs/en/agent-teams](https://code.claude.com/docs/en/agent-teams) mentions: \"Split-pane mode requires either¬†[tmux](https://github.com/tmux/tmux/wiki)¬†or iTerm2 with the¬†[`it2`¬†CLI](https://github.com/mkusaka/it2). To install manually:\n\n* **tmux**: install through your system‚Äôs package manager. See the¬†[tmux wiki](https://github.com/tmux/tmux/wiki/Installing)¬†for platform-specific instructions.\n* **iTerm2**: install the¬†[`it2`¬†CLI](https://github.com/mkusaka/it2), then enable the Python API in¬†**iTerm2 ‚Üí Settings ‚Üí General ‚Üí Magic ‚Üí Enable Python API**.\"\n\nSo don't believe tmux is necessary if you're using the alternative to split-pane mode (in-process mode).",
          "score": 3,
          "created_utc": "2026-02-07 19:51:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o479vyt",
              "author": "vicdotso",
              "text": "tmux isn't required, but it is the most cross-platform/portable option.",
              "score": 1,
              "created_utc": "2026-02-08 04:39:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5b2pko",
              "author": "MisterKnif3",
              "text": "Or wezterm via https://github.com/afewyards/wezcld",
              "score": 1,
              "created_utc": "2026-02-14 07:51:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o43wwnh",
          "author": "creegs",
          "text": "Nice! I‚Äôve been wanting to dig into how the mailbox/Messaging works between the agents - any idea how the agents pick up new messages in the inboxes? Is it through hooks/prompt injection? Or something hard coded in the CLI?",
          "score": 2,
          "created_utc": "2026-02-07 17:06:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43yhob",
              "author": "vicdotso",
              "text": "i believe each teammate polls its own inbox from disk.",
              "score": 3,
              "created_utc": "2026-02-07 17:14:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o495xh3",
              "author": "davylyn",
              "text": "same question, very curious about it",
              "score": 1,
              "created_utc": "2026-02-08 14:11:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o496rfi",
                  "author": "creegs",
                  "text": "I‚Äôm (well Claude is) actually doing some deeper research right now - check out comments in this GitHub issue - I‚Äôll keep updating them: https://github.com/iloom-ai/iloom-cli/issues/492",
                  "score": 1,
                  "created_utc": "2026-02-08 14:16:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44lntd",
          "author": "Hellbink",
          "text": "Any options to extend this to have codex as a teammate for the dev team? Would lovely have codex-5.3xhigh and gpt 5.2 xhigh as members to check Claude",
          "score": 2,
          "created_utc": "2026-02-07 19:08:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47ad06",
              "author": "vicdotso",
              "text": "looking into supporting opencode teamates, that way you can use any model of your choice. I would personally like the use codex as the planner and claude for implementation.",
              "score": 3,
              "created_utc": "2026-02-08 04:42:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4axqm8",
              "author": "vicdotso",
              "text": "I just added support for opencode",
              "score": 1,
              "created_utc": "2026-02-08 19:28:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4b5hgv",
                  "author": "Hellbink",
                  "text": "Awesome, I‚Äôll give it a go!",
                  "score": 1,
                  "created_utc": "2026-02-08 20:06:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44xfty",
          "author": "addiktion",
          "text": "Very cool, I wonder if this can be ported to the desktop app. I've been trying out Open Code desktop recently and it would be cool to see multi agents in a GUI.\n\nWhat kind of details is the team lead adding to team mates to define their role & capabilities?",
          "score": 2,
          "created_utc": "2026-02-07 20:10:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44s4d9",
          "author": "alfa0x7",
          "text": "Nice! Would you consider implementing it as cli?",
          "score": 1,
          "created_utc": "2026-02-07 19:42:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ay4ig",
              "author": "vicdotso",
              "text": "It should just work with mcp clis like github.com/cs50victor/mcpx",
              "score": 1,
              "created_utc": "2026-02-08 19:30:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o45zm9o",
          "author": "Ok-Experience9774",
          "text": "How does it handle working on the same code base at the same time, or are they using worktrees and merging tasks when done?\n\nI ended up doing a similar solution but had to use worktrees, and that makes development slower as they need to coordinate merging.¬†",
          "score": 1,
          "created_utc": "2026-02-07 23:44:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o463top",
          "author": "DeExecute",
          "text": "Why does it spawn claude? It should use opencode here?",
          "score": 1,
          "created_utc": "2026-02-08 00:10:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o474g2v",
          "author": "bzBetty",
          "text": "So it's a harness feature then?",
          "score": 1,
          "created_utc": "2026-02-08 04:00:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4769ol",
              "author": "vicdotso",
              "text": "yes. the claude code harness supports this natively they just don't document the cli args.",
              "score": 2,
              "created_utc": "2026-02-08 04:13:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o476q1n",
                  "author": "bzBetty",
                  "text": "So doesn't require opus 4.6?",
                  "score": 1,
                  "created_utc": "2026-02-08 04:16:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o48nh6m",
          "author": "Professional_Bar6431",
          "text": "Is it possible to use with Codex CLI or the codex desktop app?",
          "score": 1,
          "created_utc": "2026-02-08 12:03:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48ni22",
              "author": "haikusbot",
              "text": "*Is it possible*\n\n*To use with Codex CLI or*\n\n*The codex desktop app?*\n\n\\- Professional\\_Bar6431\n\n---\n\n^(I detect haikus. And sometimes, successfully.) ^[Learn&#32;more&#32;about&#32;me.](https://www.reddit.com/r/haikusbot/)\n\n^(Opt out of replies: \"haikusbot opt out\" | Delete my comment: \"haikusbot delete\")",
              "score": 1,
              "created_utc": "2026-02-08 12:04:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ajage",
              "author": "vicdotso",
              "text": "any mcp client should work. you need tmux installed on your computer. Open a github issue if you run into errors",
              "score": 1,
              "created_utc": "2026-02-08 18:20:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49xxdg",
          "author": "Whole_Repeat_1556",
          "text": "@vicdotso  would you know if its possible to create a new team of agents with opus 4.6, but having every spawned agent run in a dedicated container instead of a tmux session on the same machine?",
          "score": 1,
          "created_utc": "2026-02-08 16:38:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4aiy5m",
              "author": "vicdotso",
              "text": "This is an interesting idea and yes im sure with a docker mount and port routing this should be possible.",
              "score": 1,
              "created_utc": "2026-02-08 18:19:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o468ff0",
          "author": "Primary-Avocado-3055",
          "text": "They are copying a lot from Gastown",
          "score": 1,
          "created_utc": "2026-02-08 00:37:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r34990",
      "title": "After 15+ years coding, my debugging process became a holy war",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/sm7rigz3a4jg1.png",
      "author": "btachinardi",
      "created_utc": "2026-02-12 20:19:16",
      "score": 181,
      "num_comments": 30,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Humor",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r34990/after_15_years_coding_my_debugging_process_became/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o51mjtp",
          "author": "khayiin",
          "text": "https://preview.redd.it/sdmvtvjgj4jg1.jpeg?width=700&format=pjpg&auto=webp&s=f376d50c1a72262dd4130bb77bb63a4494c2eac4",
          "score": 32,
          "created_utc": "2026-02-12 20:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51vfeh",
          "author": "Ambitious_Injury_783",
          "text": "be careful doing things this way. It may \"reason\" that you two are roleplaying, and I mean \"Reason\" extra quotations, and cut corners or brush serious things off. ",
          "score": 18,
          "created_utc": "2026-02-12 21:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52g88h",
              "author": "elchemy",
              "text": "I agree - I built a whole \"shipyard\" pirate themed coding game like this and in the end there was a lot more pirate talking than coding happening lol.",
              "score": 11,
              "created_utc": "2026-02-12 22:59:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51xrgn",
              "author": "btachinardi",
              "text": "Yeah, definitely needs to create a real benchmark to test if the roleplaying part actually improves or decreases the agent's performance at these tasks, from my observations it looks like the agent actually deviates less from their \"role\" and seems less likely to cut corners than when I have strict formal guidance and validation gates.\n\nI will try to create some benchmarks with the same instructions, but without the roleplaying part, and see how both perform.",
              "score": 6,
              "created_utc": "2026-02-12 21:26:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52gkgl",
                  "author": "elchemy",
                  "text": "Yes, and once you start doing that it's actually pretty easy to do test rigs where you can compare different agents, llms, tech stacks etc - and this can then be part of the \"game\" - competitive arena debugging battles etc.\n\nSo there can be plus sides and new emergence from exploring these rabbitholes even though they aren't a direct productivity tool at first.\n\n",
                  "score": 2,
                  "created_utc": "2026-02-12 23:01:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o55t9jn",
              "author": "Minorole",
              "text": "Totally agree‚Äî‚Äúpersonality‚Äù prompts can steer the model toward certain specialized strengths. Roleplay may not consistently trigger the engineering skills needed, which can reduce output quality.",
              "score": 2,
              "created_utc": "2026-02-13 13:33:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o57na0f",
              "author": "syddakid32",
              "text": "I learned this the hard way when I told it \"we're building a MVP\" holly cow... talk about cutting corners? nothing mattered any more because it was an MVP... I'm like Claude the shit still has TO FUNCTION. ",
              "score": 2,
              "created_utc": "2026-02-13 18:58:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51xjte",
          "author": "AppealSame4367",
          "text": "Dude, finally something funny! All these freakin \"I did this\" \"Do that\" \"Here's what I learned\" shit posts and you just start a holy crusade against bugs. Nice",
          "score": 6,
          "created_utc": "2026-02-12 21:25:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51pob0",
          "author": "Total-Hotel-8157",
          "text": "I love it! How do I get started on this? Mind sharing something? I‚Äôm more of a vibe engineer and very interested in becoming better at writing tests",
          "score": 3,
          "created_utc": "2026-02-12 20:48:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51qll5",
              "author": "btachinardi",
              "text": "I made it available for free in case it may help anyone out there, the agents are calling it \"The Holy Order  \nof Clean Code\", it is both fascinating and quite educational tbh:  \n[https://church.btas.dev/](https://church.btas.dev/)",
              "score": 15,
              "created_utc": "2026-02-12 20:53:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52pd7x",
                  "author": "ajr901",
                  "text": "This is actually really, really good. I could do without the whole religious (if you can call it that) aspect of it but otherwise this is really well made. Kinda wanna fork it and make it non-denominational so to speak.",
                  "score": 3,
                  "created_utc": "2026-02-12 23:50:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o52b62k",
                  "author": "Total-Hotel-8157",
                  "text": "Thanks! FYI: Got a bit of an overflow issue on mobile",
                  "score": 1,
                  "created_utc": "2026-02-12 22:32:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o51qc1g",
          "author": "bourbonandpistons",
          "text": "Im glad Im not the only one coding Camelot style.\n\nAIs of the round table.",
          "score": 2,
          "created_utc": "2026-02-12 20:51:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51s14u",
              "author": "btachinardi",
              "text": "It might not be more efficient, but hell is it a lot more enjoyable!",
              "score": 3,
              "created_utc": "2026-02-12 20:59:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o51t3t5",
              "author": "Sleepingpanda2319",
              "text": "üé∂\n\nWe‚Äôre AI‚Äôs of the Round Table\n\nWe code when ere we're able\n\nWe do routines and chorus scenes\n\nWith implement-ations impecc-able\n\nWe vibe code well here in Camelot\n\nWe handjam and cram and spam a lot!\nüé∂",
              "score": 3,
              "created_utc": "2026-02-12 21:04:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o52fb1z",
          "author": "elchemy",
          "text": "Good fun, I've done similar things but in the end the \"overlayer\" of roleplaying/genre etc is just extract context/noise and confusion.\n\nI really enjoy it but at a certain size performance seems to really drop away - have you noticed this?\n\n  \nHave you tried combining in other characters or skills - eg: you could add tools like Ralph Wiggum - I built a suite of agents with complementary skills similar to Ralph Wiggum - but the whole core Simpsons family for example - you could do the ranger/mage/theif model etc. This helped keep the tools small and modular rather than a huge repo.",
          "score": 2,
          "created_utc": "2026-02-12 22:54:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52urrz",
          "author": "chiefGui",
          "text": "I lold hard fellow Brazilian",
          "score": 2,
          "created_utc": "2026-02-13 00:21:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o535yti",
          "author": "__purplewhale__",
          "text": "Finally someone having some fun!",
          "score": 2,
          "created_utc": "2026-02-13 01:27:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53ieyj",
          "author": "max420",
          "text": "I do this sort of thing too.  Not only is it fun as hell, but it legit works!",
          "score": 2,
          "created_utc": "2026-02-13 02:44:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o548bwc",
          "author": "angie_akhila",
          "text": "https://preview.redd.it/kdj1cpib97jg1.jpeg?width=1320&format=pjpg&auto=webp&s=01fc512b00c42591681260c6cceb1ab051ba42ad\n\nYea, this is just how we code now lol, I A/B tested vs vanilla coworker claudes‚Ä¶ it works better üòÇ",
          "score": 2,
          "created_utc": "2026-02-13 05:43:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54p0d9",
          "author": "ultrathink-art",
          "text": "The evolution from printf debugging to AI-assisted debugging mirrors how debugging tools have always worked ‚Äî you're just using a smarter REPL.\n\nWhat changed for me: instead of mentally simulating code execution, I describe the observed behavior vs expected behavior to Claude and ask \"what would cause this gap?\" The AI acts like a rubber duck that can actually run the mental simulation faster than I can.\n\nThe holy war part comes when you realize the AI can trace 5 levels deep in a call stack instantly, but still misses the \"oh wait, this API returns cached data\" context that you know from 3 months ago. So you end up doing hybrid: AI for mechanical tracing, human for \"why would past-me have done this?\"\n\nKey workflow: give Claude the error message + relevant code (not the whole file), ask for hypotheses ranked by likelihood, then YOU choose which to test first based on your system knowledge. Keeps you in control while using AI as a hypothesis generator.",
          "score": 2,
          "created_utc": "2026-02-13 08:08:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51v8bv",
          "author": "nonikhannna",
          "text": "This is genius!¬†",
          "score": 1,
          "created_utc": "2026-02-12 21:15:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51xork",
          "author": "svdomer09",
          "text": "Lol I have a eunuch (cause he can‚Äôt write) that goes on pilgrimages to protect sacred code. Glad I‚Äôm not alone",
          "score": 1,
          "created_utc": "2026-02-12 21:26:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o521frz",
          "author": "hyopwnz",
          "text": "Bro this seems like a crusade of my limits",
          "score": 1,
          "created_utc": "2026-02-12 21:44:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52nylw",
          "author": "PcGoDz_v2",
          "text": "Tell them about the per capita.",
          "score": 1,
          "created_utc": "2026-02-12 23:42:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5665xu",
          "author": "Grouchy-Wallaby576",
          "text": "This is amazing. My debugging \"ritual\" isn't quite a holy war, but I did end up building a dedicated debugging skill that forces Claude to stop guessing and actually trace the issue step by step before proposing fixes.\n\n\n\n  Turns out Claude's biggest debugging weakness is the same as ours ‚Äî jumping to a fix before understanding the problem. A strict \"reproduce first, hypothesize second, fix last\" workflow in a skill fixed most of the \"it changed 5 files and broke 3 other things\" moments.",
          "score": 1,
          "created_utc": "2026-02-13 14:42:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56ozzq",
          "author": "Ironamsfeld",
          "text": "![gif](giphy|jFXNDoyxBycT90FUo9)",
          "score": 1,
          "created_utc": "2026-02-13 16:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o594eq3",
          "author": "scotty2012",
          "text": "‚ÄúEvery assertion will be MEANINGFUL, meaning, I mean it!‚Äù",
          "score": 1,
          "created_utc": "2026-02-13 23:29:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52461m",
          "author": "Muted_Farmer_5004",
          "text": "You need help. ",
          "score": 0,
          "created_utc": "2026-02-12 21:57:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyvxk2",
      "title": "Is this normal?",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/axjx745he6ig1.png",
      "author": "chipthehp",
      "created_utc": "2026-02-08 01:45:26",
      "score": 178,
      "num_comments": 18,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qyvxk2/is_this_normal/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o46jo4e",
          "author": "Ok-Lengthiness-3988",
          "text": "It happens occasionally. Avoid shaking hands with it.",
          "score": 77,
          "created_utc": "2026-02-08 01:47:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46ny47",
          "author": "Comfortable_Camp9744",
          "text": "Who doesnt touch themselves a little while vibe coding?¬†",
          "score": 37,
          "created_utc": "2026-02-08 02:14:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4791u4",
              "author": "Outrageous-Thing-900",
              "text": "cuckcoding, sit back and watch it fuck your code raw no commits",
              "score": 37,
              "created_utc": "2026-02-08 04:33:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o47i078",
                  "author": "ask_af",
                  "text": "My man here inventing terminology",
                  "score": 9,
                  "created_utc": "2026-02-08 05:42:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o47if3v",
              "author": "Optimal-Builder-2816",
              "text": "Jorking it‚Ä¶",
              "score": 3,
              "created_utc": "2026-02-08 05:45:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o46mvvf",
          "author": "ProgrammerVlad",
          "text": "They let you set custom thinking phrases and now people are posting this. smh",
          "score": 31,
          "created_utc": "2026-02-08 02:07:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49j4bn",
              "author": "campbellm",
              "text": "This used to only be possible with tweakcc, no?  How is it done now?",
              "score": 1,
              "created_utc": "2026-02-08 15:24:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46r9hz",
              "author": "chipthehp",
              "text": "I didn't even know u could do that",
              "score": -20,
              "created_utc": "2026-02-08 02:34:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o47mdks",
                  "author": "Michaeli_Starky",
                  "text": "![gif](giphy|3oEjI789af0AVurF60)",
                  "score": 11,
                  "created_utc": "2026-02-08 06:19:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o47myzb",
          "author": "Coldshalamov",
          "text": "We all know Claude‚Äôs a perve\n\nhttps://preview.redd.it/xlztxrsbs7ig1.jpeg?width=2816&format=pjpg&auto=webp&s=89fd946e69b101186bf2ef5f192488bb0b37e6d2",
          "score": 10,
          "created_utc": "2026-02-08 06:24:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49145h",
          "author": "Salt-Replacement596",
          "text": "Yeah, mine was \"double-fisting it\" recently.",
          "score": 2,
          "created_utc": "2026-02-08 13:42:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o474c94",
          "author": "Hedgehog-Moist",
          "text": "Lmao",
          "score": 2,
          "created_utc": "2026-02-08 04:00:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47ruvu",
          "author": "flavorfox",
          "text": "shins? Sure",
          "score": 1,
          "created_utc": "2026-02-08 07:09:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o481r3q",
          "author": "psylomatika",
          "text": "The thing Codes itself. Just saying.",
          "score": 1,
          "created_utc": "2026-02-08 08:41:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4842kk",
          "author": "Fresh-Sugar662",
          "text": "i mean, its a happy ending when everything works out riiiiiiight?",
          "score": 1,
          "created_utc": "2026-02-08 09:03:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bregk",
          "author": "Antique-Win4832",
          "text": "what you gon do about it? \n\n![gif](giphy|eIhedUADRJYLrA433d)",
          "score": 1,
          "created_utc": "2026-02-08 21:55:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rozzq",
          "author": "LieInternational5918",
          "text": "It could be shin...you never know.",
          "score": 1,
          "created_utc": "2026-02-11 08:53:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o473kh3",
          "author": "UsingDog",
          "text": "Pc be turned on and turned on",
          "score": 0,
          "created_utc": "2026-02-08 03:54:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r24g2i",
      "title": "I automated the Claude Code and codex workflow into a single CLI tool: they debate, review, and fix code together",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1r24g2i/i_automated_the_claude_code_and_codex_workflow/",
      "author": "Shakalaka-bum-bum",
      "created_utc": "2026-02-11 17:57:10",
      "score": 176,
      "num_comments": 78,
      "upvote_ratio": 0.98,
      "text": "I'm a solo dev vibecoder. For months I had this setup: plan features in ChatGPT, generate audit prompts, paste them into Claude Code to review the whole codebase, send Claude's analysis back to ChatGPT in AI-friendly format, ChatGPT generates actionable prompts with reports, send those back to Claude to execute.\n\nThis workflow was working really well, I shipped 4 production apps that generate revenue using exactly this loop. But then I got exhausted. The process takes days. ChatGPT chats get bloated and start hanging. Copy-pasting between two AI windows all day is soul-crushing.\n\nSo I switched to Codex CLI since it has direct codebase context. Started preparing .md files using Claude Code, then letting Codex review them. It worked, but I kept thinking. I can automate this.\n\nThen the idea hit me.\n\nWhat if Claude Code could just call Codex directly from the terminal? No middleman. No copy-paste. They just talk to each other.\n\nI built the bridge. Claude Code started running codex commands in the shell and they instantly worked like partners. Efficiency went through the roof, they detected more bugs together than either did alone. I brainstormed a name in 3 minutes, wrote out the architecture, defined the technical requirements, then let both AIs take control of the ship. They grinded for 2 straight days. The initial version was terrible. Bugs everywhere, crashes in the command prompt, broken outputs. But then it got on track. I started dogfooding CodeMoot with CodeMoot using the tool to improve itself. It evolved. Today I use it across multiple projects.\n\nHow it works now:\n\nBoth AIs explore the whole codebase, suggest findings, debate each other, plan and execute. Then Codex reviews the implementation, sends insights back to Claude Code, and the loop continues until we score at least 9/10 or hit the minimum threshold.\n\nThis is the new way of working with AI. It's not about using one model, opinions from multiple AI models produce better, cleaner code.\n\nTry it (2 minutes):\n\nYou need claude-code and codex installed and working.\n\n\\# Install\n\nnpm install -g u/codemoot/cli\n\n\\# Run in any project directory:\n\ncodemoot start          # checks prerequisites, creates config\n\ncodemoot install-skills # installs /debate, /build, /codex-review slash commands into Claude Code\n\nThat's it. No API keysuses your existing subscriptions. Everything local, $0 extra cost.\n\n\n\nFurther I have added various tools inside it which i actively use in mine other projects and also for the codemoot itself:\n\n\n\nWhat you get: (use it in claudecode)\n\nTerminal commands (run directly):\n\ncodemoot review src/                         # GPT reviews your code\n\ncodemoot review --prompt \"find security bugs\" # GPT explores your codebase\n\ncodemoot review --diff HEAD\\~3..HEAD          # Review recent commits\n\ncodemoot fix src/                            # Auto-fix loop until clean\n\ncodemoot cleanup . --scope security          # AI slop scanner (16 OWASP patterns)\n\ncodemoot debate start \"REST vs GraphQL?\"     # Multi-round Claude vs GPT debate\n\n\n\nSlash commands inside Claude Code (after install-skills):\n\n/codex-review src/auth.ts    ‚Äî Quick GPT second opinion\n\n/debate \"monorepo vs polyrepo?\" ‚Äî Claude and GPT debate it out\n\n/build \"add user auth\"       ‚Äî Full pipeline: debate ‚Üí plan ‚Üí implement ‚Üí GPT review ‚Üí fix\n\n/cleanup                     ‚Äî Both AIs scan independently, debate disagreements\n\n\n\nThe meta part: Every feature in CodeMoot was built using CodeMoot itself. Claude writes code, GPT reviews it, they debate architecture, and the tool improves itself.  \n\n\nWhat I'm looking for:\n\n \\- Does npm install -g u/codemoot/cli + codemoot start work on your setup?\n\n \\- Is the review output actually useful on your project?\n\n \\- What commands would you add?\n\nContributors are welcomed, suggestions are respected and feedbacks are appreciated its made for vibecoders and power users of claude code for free what other companies dont provide.\n\nGitHub: [https://github.com/katarmal-ram/codemoot](https://github.com/katarmal-ram/codemoot)\n\nOpen source, MIT. Built by one vibecoder + two AIs.",
      "is_original_content": false,
      "link_flair_text": "Solved",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r24g2i/i_automated_the_claude_code_and_codex_workflow/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o4u6r82",
          "author": "syddakid32",
          "text": "I stop having codex check claude and just used claude review tools. Codex was catching these weird edge cases( that prob will never happen) and I shit you not, claudecode said it had enough. It didn't implement codex change and we should move forward and finish up",
          "score": 20,
          "created_utc": "2026-02-11 18:00:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uj6lp",
              "author": "Bright-Celery-4058",
              "text": "Many times codex reviews are just poorly investigated rants without proper understand of the global codebase context. I would say 4 times out of 10.\nThe 6 others are actually on point.\nClaude is good at dismissing the false flags from codex",
              "score": 9,
              "created_utc": "2026-02-11 18:58:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vh8kl",
                  "author": "syddakid32",
                  "text": "Yup. I looked back into the history and your spot on",
                  "score": 1,
                  "created_utc": "2026-02-11 21:41:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4wwh74",
                  "author": "fredastere",
                  "text": "Well you need to review with gpt5.2 not gpt5.2-codex or gpt5.3-codex\n\nCodex is made for coding only",
                  "score": 1,
                  "created_utc": "2026-02-12 02:27:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4u7cod",
              "author": "Shakalaka-bum-bum",
              "text": "Claude wont catch certain security flaws and the new version of opus 4.6 is more lazy and sometimes it ignores the user's instructions too.",
              "score": 3,
              "created_utc": "2026-02-11 18:03:40",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ugpkp",
              "author": "EzioO14",
              "text": "Do you have screenshot of that üòÇüòÇüòÇüòÇ",
              "score": 1,
              "created_utc": "2026-02-11 18:46:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vgzzv",
                  "author": "syddakid32",
                  "text": "https://preview.redd.it/ebnt7oaeqxig1.png?width=1666&format=png&auto=webp&s=52d7bafa0edd13743bea1d1bfe4a5e3b70fcf32b\n\n",
                  "score": 6,
                  "created_utc": "2026-02-11 21:40:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u8f03",
          "author": "rubyonhenry",
          "text": "I have the standard Codex MCP server in Claude Code and sometimes tell claude to ask codex for a second pair of eyes or review",
          "score": 16,
          "created_utc": "2026-02-11 18:08:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u9p38",
              "author": "Shakalaka-bum-bum",
              "text": "Yea, but the context wont be maintained. codemoot uses sqlite database for storing sessions and in those same sessions both cli collabs, brainstorm, debate, review and find bugs so the accuracy jumps.",
              "score": 3,
              "created_utc": "2026-02-11 18:14:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4wwaz9",
                  "author": "fredastere",
                  "text": "But you can use saved states via files and maintain a degree of context that way as well\n\nNot saying your approach is bad or anything but with the official codex mcp server it's easy to share workspace from claude code to codex since a minute\n\nJust seems you may have reinvented the wheel a bit rather than leveraging already available features, tools or open source\n\nYou should look into claude teams, a newly released feature natively supporting multi agent and task management and agent inter communication etc, really good although still experimental\n\nThat being said I'll definitely look into your code see what I vould savage from your design and see how you did things \n\nCheers",
                  "score": 3,
                  "created_utc": "2026-02-12 02:26:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4x4b9z",
                  "author": "accelas",
                  "text": "You can continue codex chat session with codex-reply mcp tool.",
                  "score": 1,
                  "created_utc": "2026-02-12 03:15:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uol6v",
          "author": "Sea-Sir-2985",
          "text": "the idea of having two models debate and review each other's work is solid... i've seen similar patterns where you use one model for generation and another for review and the output quality is way higher than either alone\n\nthe copy-paste fatigue between chat windows is real, that was the main reason i moved to claude code for everything. having it just call codex directly from the terminal and pipe results back is a clean solution to that bottleneck\n\ncurious about the cost though... running two models on every task has to add up fast. do you have a way to decide when the full debate loop is worth it vs just letting one model handle it? like using the dual review only for complex features and skipping it for simple edits",
          "score": 4,
          "created_utc": "2026-02-11 19:23:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w3lig",
              "author": "tribat",
              "text": "I have a /codex-review and /gemini-review that always delivers when I remember to use it. Codex tends to be too picky but Claude seems to be good at ‚Äúyeah, that‚Äôs technically correct but we aren‚Äôt building enterprise software‚Äù.",
              "score": 3,
              "created_utc": "2026-02-11 23:36:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4uqdvh",
              "author": "Shakalaka-bum-bum",
              "text": "Exactly right the copy-paste fatigue between windows is what killed me.\n\nYour point about cost is valid. Personally I don't run the full debate loop on everything. Quick fix? Just let Claude handle it. But for anything touching auth, payments, architecture decisions, or shipping a new feature I always want that second opinion, also the debate round uses the framework wether to continue further or not, if the fixes are obvious it would stop in just 2 rounds so there wont be much token usage. If you are using claude code for coding task and codex for review, go for the plus plan on codex its more then enough for reviewing. In the development itself I used 30% of weekly usage in 2 days and trust me those were very intense brainstorming rounds so 20$ subscription would help a lot.",
              "score": 1,
              "created_utc": "2026-02-11 19:32:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4usnot",
                  "author": "Sea-Sir-2985",
                  "text": "I tried a similar plug-in before, so whenever it sent the plan from Claude to codex every time it was a new session. Codex did not have the memory of the previous details and at the end, it did leave a few pointers which manual review ones flagged\nIs it the same here as well?",
                  "score": 1,
                  "created_utc": "2026-02-11 19:43:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ukzic",
          "author": "Extra-Record7881",
          "text": "i havw been working on the same thing but i had forked the crystal and added workflows so that every puece of code that is generated is later automatically reviewd debated and tested over and over. i totally agree that this method is very efficient. This personally is very helpful to me as i dont care about the costs and care more about the code that is written. Usages goes through the roof. But hey i am 100% in support of this.",
          "score": 3,
          "created_utc": "2026-02-11 19:06:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4umgw1",
              "author": "Shakalaka-bum-bum",
              "text": "Thanks for sharing that's really cool to hear someone else building the same loop independently. That's exactly the validation I needed. The fact that you forked and added automated review-debate-test cycles on top tells me this workflow just makes sense.\n\nbut yeah, usage goes through the roof but the code quality difference is night and day. I'm with you I'd rather burn tokens than ship bugs. The cost of a GPT review round is nothing compared to debugging in production.\n\nWould love to see what you've built with the Crystal fork if you ever open source it. Always looking for ideas on how to make the loop tighter.",
              "score": 3,
              "created_utc": "2026-02-11 19:13:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4uwjhx",
                  "author": "Extra-Record7881",
                  "text": "i am actually planning to do that. once i polish it enough to makw it presentable and from there on see how it does.",
                  "score": 1,
                  "created_utc": "2026-02-11 20:01:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4y4wbf",
          "author": "ultrathink-art",
          "text": "Nice workflow automation. The ChatGPT ‚Üí Claude ‚Üí ChatGPT loop is interesting for leveraging different model strengths.\n\nOne thing to watch: **context drift** between models. When you're bouncing analysis back and forth, each model interprets the previous output through its own lens. Small misunderstandings compound across hops.\n\nSome patterns that help:\n- **Structured handoffs** - Use JSON or YAML for inter-agent communication instead of prose. Less ambiguity.\n- **Single source of truth** - Keep the codebase state in one place. Agents read from it, write decisions back, but don't rely on conversational memory across models.\n- **Explicit contracts** - Define what each agent is responsible for (e.g., ChatGPT = planning, Claude = execution). When responsibilities overlap, you get circular reasoning.\n\nAlso curious: how do you handle cases where Claude's analysis contradicts ChatGPT's plan? Does one model have veto power, or do you resolve it manually?",
          "score": 3,
          "created_utc": "2026-02-12 08:08:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ycpnx",
              "author": "Shakalaka-bum-bum",
              "text": "Context drift is a real pain, i ran into it early on. A few things that help in practice\n\nSession persistence: each review/debate round is stored in SQLite with full message history, so when GPT picks up where it left off it's reading its own prior output, not Claude's paraphrase of it. Reduces the telephone game effect. The handoffs are already somewhat structured review findings come back as JSON with severity, file, line, message fields rather than freeform prose. So Claude isn't interpreting vibes, it's reading structured data. As for contradictions right now it's manual. If GPT's review disagrees with something Claude did, it surfaces the findings and you decide. I've been thinking about adding a tiebreaker round where both models see each other's reasoning and have to converge, but haven't shipped that yet. The debate command is the closest thing it runs actual back-and-forth rounds between them until you're satisfied.\n\nGood questions though, this is exactly the kind of stuff I'm iterating on.",
              "score": 1,
              "created_utc": "2026-02-12 09:25:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4udgq4",
          "author": "jorge-moreira",
          "text": "I‚Äôm intrigued",
          "score": 2,
          "created_utc": "2026-02-11 18:31:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uehuw",
              "author": "Shakalaka-bum-bum",
              "text": "You can explore the repo, use the tool and please provide your feedback :)",
              "score": 1,
              "created_utc": "2026-02-11 18:36:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ufjr8",
          "author": "Electronic_Froyo_947",
          "text": "We use Claude octopus\n\nIt uses all three providers for debating and consensus.\n\nAlso uses OAuth or Api\n\nMaybe see how to implement Gemini or another provider",
          "score": 2,
          "created_utc": "2026-02-11 18:41:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ujd7l",
              "author": "Shakalaka-bum-bum",
              "text": "Cool project! I am taking a different approach though. CodeMoot wraps codex cli directly. The automation happens at the CLI bridge level. All chats and debates are stored in sqlite db and there a structured way to call codex cli with session resuming so GPT actually remembers prior context across rounds. \n\nWhen doing review, both agents fire independently, Claude Code and Codex generates their own views then they critique each other‚Äôs findings. They actually talk back and forth until they reach consensus. \n\nI tried using gemini too but honestly Claude Code and Codex together are more than enough for any kind of brainstorming, review or architecture tasks. \n\nAlthough I am looking to add more CLIs to orchestration down the road but right now I am validating the core idea between two models arguing produces better code than either one alone.",
              "score": 4,
              "created_utc": "2026-02-11 18:59:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4unldl",
              "author": "chuch1234",
              "text": "Do you have any numbers or otherwise concrete metrics for the value from this approach? It sounds interesting but very expensive.",
              "score": 1,
              "created_utc": "2026-02-11 19:19:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4v5eut",
                  "author": "Shakalaka-bum-bum",
                  "text": "I have numbers for the workflow I had previously which is now automated but for now I am still validating the idea of CLI integrations. You can try chatgpt plus trial which is available in south korea region by switching your network to south korea vpn ;) its just for trial purpose. But the claude code subscription is required for which there are certain coupons available might give you 10$ off for a month for 3 months.",
                  "score": 1,
                  "created_utc": "2026-02-11 20:44:59",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uozva",
          "author": "UKCats44",
          "text": "I love the idea of this, however after installing via npm and running \"codemoot init\", I receive the errors below:\n\n    file:///Users/blahuser/.nvm/versions/node/v22.18.0/lib/node_modules/@codemoot/cli/node_modules/@codemoot/core/dist/index.js:442\n        throw new ConfigError(\n              ^\n    \n    ConfigError: Unknown preset: \"balanced\". Valid presets: cli-first\n        at loadPreset (file:///Users/blahuser/.nvm/versions/node/v22.18.0/lib/node_modules/@codemoot/cli/node_modules/@codemoot/core/dist/index.js:442:11)\n        at loadConfig (file:///Users/blahuser/.nvm/versions/node/v22.18.0/lib/node_modules/@codemoot/cli/node_modules/@codemoot/core/dist/index.js:484:26)\n        at Command.initCommand (file:///Users/blahuser/.nvm/versions/node/v22.18.0/lib/node_modules/@codemoot/cli/dist/index.js:1809:18) {\n      field: 'preset'\n    }\n    \n    Node.js v22.18.0\n    ",
          "score": 2,
          "created_utc": "2026-02-11 19:25:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uvtwd",
              "author": "Shakalaka-bum-bum",
              "text": "Hey, thanks for trying it out! This was a known bug the init prompt was offering presets from an older API-based architecture that no longer exists.\n\nIt's fixed in v0.2.4. Just run:\n\nnpm install -g u/codemoot/cli@latest\n\nThen codemoot init should work cleanly. Let me know if you hit anything else or DM me would help you setup!",
              "score": 1,
              "created_utc": "2026-02-11 19:58:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4vrxj5",
          "author": "lucianw",
          "text": "Could you say precisely what it means, in concrete terms, for the AIs to \"debate each other\"? Does one agent have a context window and the other agent's comments get added as tool calls or user prompts or holds?",
          "score": 2,
          "created_utc": "2026-02-11 22:34:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xc3sf",
              "author": "Shakalaka-bum-bum",
              "text": "The debate starts with claude hoping on and preparing their opening statements, then the codex session is launched in the same codebase where claude code is working and the claude‚Äôs opening statement is passed on, codex then analysis codebase and also the statement of claude and prepares his critique and its passed on to claude code via stdout claude reviews it add his own points and now in the same session of codex that points are passed on via stdin so codex never looses context. \n\nFor more detailed explanation you can check the public repo, I tried to explain their in simple ways.",
              "score": 2,
              "created_utc": "2026-02-12 04:06:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52sni4",
          "author": "BeginningReflection4",
          "text": "\\- Does npm install -g¬†[u/codemoot/cli](https://www.reddit.com/user/codemoot/cli/)¬†\\+ codemoot start work on your setup?\n\nYes\n\n\\- Is the review output actually useful on your project?\n\nYes, even if it is a bit verbose\n\n\\- What commands would you add?\n\ncodemoot review src/ #\n\nWhere # is the number of rounds it runs instead of doing 3 over and over.\n\n  \nGreat work - Thanks!!",
          "score": 2,
          "created_utc": "2026-02-13 00:09:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53wiw0",
              "author": "Shakalaka-bum-bum",
              "text": "Thanks a lot! Kind of feedback I was expecting. Also you can checkout git repo, fork and clone, you can try to add your own commands also. I will definitely try your suggestion.",
              "score": 2,
              "created_utc": "2026-02-13 04:16:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o556pq5",
          "author": "LukeLeeYh",
          "text": "this is exactly what I wanted thanks!! so can I get opus plan first and codex to review the plan also?",
          "score": 2,
          "created_utc": "2026-02-13 10:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5593xi",
              "author": "Shakalaka-bum-bum",
              "text": "Thanks for letting me know and please share your feedback so I can improve it too.",
              "score": 1,
              "created_utc": "2026-02-13 11:14:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o55fwv3",
          "author": "BeginningReflection4",
          "text": "The /cleanup switch only seems to find and list issues? Can I use it to fix what it finds? You probably already have this and I just don't understand how to make it work. Thanks.",
          "score": 2,
          "created_utc": "2026-02-13 12:08:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55r3np",
              "author": "Shakalaka-bum-bum",
              "text": "Yes cleanup is made be used to fix and remove slop, theres skill issue of claude, in certain workflows all those slops are detected and claude starts working on them, but sometimes it wont and wait for your input.",
              "score": 1,
              "created_utc": "2026-02-13 13:21:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55yo13",
                  "author": "BeginningReflection4",
                  "text": "Am I using it wrong? codemoot /cleanup then it finds lots of things to fix but only reports what it finds\n\nPhase 1: Scanning (parallel)...\n\n  \\[codex\\] Starting semantic scan...\n\n  \\[deterministic\\] Starting...\n\n  \\[deterministic\\] Done: 2416 findings\n\n(node:261240) \\[DEP0190\\] DeprecationWarning: Passing args to a child process with shell option true can lead to security vulnerabilities, as the arguments are not escaped, only concatenated.\n\n(Use \\`node --trace-deprecation ...\\` to show where the warning was created)\n\n  \\[cleanup-scan\\] Started (PID: 260412, cmd: codex.cmd)\n\n  \\[cleanup-scan\\] Thread: 019c574b-388...\n\n  \\[codex\\] Scan failed: CLI subprocess exited with code 1: Reading prompt from stdin...\n\n......\n\nScan complete in 109.5s\n\nBuild ID: 0tK6MJtM3CTjskER\n\n  Actionable: 835\n\n  Report-only: 1449\n\n  High: 52 | Medium: 1211 | Low: 1021",
                  "score": 1,
                  "created_utc": "2026-02-13 14:03:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uu8dw",
          "author": "El_human",
          "text": "This is great, I've had the same idea to try this. But wouldn't know how to set it up. Does it pause and ask for new prompts or new tasks at some point? Do you add those into claid or codex? I'd love to see this thing in action if you ever set up a demo.",
          "score": 1,
          "created_utc": "2026-02-11 19:50:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uwxx6",
              "author": "Shakalaka-bum-bum",
              "text": "So you don't need to set up anything between them manually that's the whole point. You install codemoot via npm, run \"codemoot init\" in your project, and then use it from inside Claude Code.\n\nThe flow depends on what you're doing:\n\n \\- codemoot review --prompt \"check for race conditions\" one-shot, GPT reviews and comes back with findings\n\n\\- /debate Claude and GPT go back and forth on an architecture decision, you just watch\n\n\\- codemoot build start fully automated loop: debate ‚Üí plan ‚Üí implement ‚Üí GPT review ‚Üí fix ‚Üí done\n\nFor the debate mode, Claude drives the conversation it sends a position, GPT responds, they go rounds until consensus or you stop it. You don't need to prompt each step.\n\nI should probably record a demo honestly I'll put one together this week. In the meantime if you install it (npm install -g u/codemoot/cli) and have Codex CLI set up, codemoot init + codemoot review is the fastest way to see it work. Let me know if you encounter any error or DM me I could probably help you setup.",
              "score": 2,
              "created_utc": "2026-02-11 20:03:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4uzhnc",
                  "author": "El_human",
                  "text": "Thanks! I'll give it a try when I get a chance.",
                  "score": 2,
                  "created_utc": "2026-02-11 20:15:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4v95pf",
          "author": "Witty-Figure186",
          "text": "Do you have anything to run claude code with copilot unlimited subscription? So that  we can use open ai and claude models.",
          "score": 1,
          "created_utc": "2026-02-11 21:03:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vab67",
              "author": "Shakalaka-bum-bum",
              "text": "Nop, this tool is designed to be work with claude code but I am working on MCP framework where you can call this tool from other IDEs such as cursor, vs code.",
              "score": 1,
              "created_utc": "2026-02-11 21:08:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w8qul",
          "author": "Upset_Way_7386",
          "text": "Would it be easy to use Gemini 3 instead of ChatGPT in this setup?",
          "score": 1,
          "created_utc": "2026-02-12 00:05:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xc8jr",
              "author": "Shakalaka-bum-bum",
              "text": "I am validating this idea about multi model collaboration and if it works will be adding gemini cli within a week.",
              "score": 1,
              "created_utc": "2026-02-12 04:07:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xh0b1",
                  "author": "Upset_Way_7386",
                  "text": "Awesome! Love the work you have done!",
                  "score": 2,
                  "created_utc": "2026-02-12 04:41:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4wynd4",
          "author": "fredastere",
          "text": "Its still really rough but I have a similar yet completely different approach with claude teams if you are curious\n\nUses native teams to spawn a group of agents that can natively communicate via the task lists and teams feature of claude code\n\nPersonally I brainstorm with opus 4.6\nFrom the brainstorm gpt5.2 and opus4.6 both generate a plan and my orchestrator (opus 4.6) synthesize and present to me the master plan, which we improve until agreed upon\n\nThen gpt5.2 takes this plan and generate a first set of tasks, a track, which is a set a prompts optimized for gpt5.3-codex to implement \nOrchestrator then sends each prompts for codex to implement, then another opus 4.6 agent reviews and if there's error codex correct them then opus 4.6 review again etc until approved\n\nRinse and repeat\n\nIts really a work in progress but send claude code on it maybe it could give you ideas on how next to optimize your flow\n\nCheers\n\nhttps://github.com/Fredasterehub/deadfish-teams",
          "score": 1,
          "created_utc": "2026-02-12 02:40:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xcwh5",
              "author": "Shakalaka-bum-bum",
              "text": "Yeah the new feature of claude code for spawning teams is amazing but at the same time it consumes a lots of tokens if you are on 20x plan you wouldn‚Äôt get much difference but I would try your approach and see where it takes. \n\nThanks :)",
              "score": 1,
              "created_utc": "2026-02-12 04:11:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xrsja",
          "author": "ultrathink-art",
          "text": "Nice work on the automation! The CLI integration approach makes a lot of sense - keeps the full power of Claude Code's tool ecosystem while adding workflow automation.\n\nOne thing I've found helpful in similar setups: spawning agents with --agent flag + --append-system-prompt for task context preserves the frontmatter config (model selection, tool restrictions) better than passing raw system prompts. Lets you have role-specific agents (coder, reviewer, etc.) with different capabilities.\n\nAlso worth considering: background task support with output files, so you can kick off long-running agents and continue working rather than blocking on completion.",
          "score": 1,
          "created_utc": "2026-02-12 06:07:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ycj3e",
              "author": "Shakalaka-bum-bum",
              "text": "Thanks! Yeah Good call on the --agent flag + --append-system-prompt approach, I'll look into that. Right now the role separation is handled through presets (security-audit, performance, etc.) but having proper frontmatter-based agent configs would be cleaner for sure.\n\nBackground task support is actually already in there you can do codemoot review --background and it queues the job, returns immediately, and you check results later with codemoot jobs status <id>. Was one of the first things I added because waiting on GPT responses while coding felt painful lol.",
              "score": 1,
              "created_utc": "2026-02-12 09:23:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yzwrr",
          "author": "RegayYager",
          "text": "Omg I love coding and the super interesting ideas that it generates. \n\nI‚Äôm still so new to this I just can‚Äôt get my product shipped. I keep running into session handoff complications‚Ä¶ \n\nI love this idea, I‚Äôll check it out",
          "score": 1,
          "created_utc": "2026-02-12 12:44:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z94rx",
              "author": "Shakalaka-bum-bum",
              "text": "Give it a try, fork the repo and you can modify it based on your need and let community know about your ideas and contributions :)",
              "score": 1,
              "created_utc": "2026-02-12 13:41:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z3h93",
          "author": "BidGrand4668",
          "text": "[Ai Counsel](https://github.com/blueman82/ai-counsel) anyone?",
          "score": 1,
          "created_utc": "2026-02-12 13:07:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z8zjo",
              "author": "Shakalaka-bum-bum",
              "text": "Its more then that, debates, building, reviews, ai slop cleaner and lot more.",
              "score": 2,
              "created_utc": "2026-02-12 13:40:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52doi6",
                  "author": "BidGrand4668",
                  "text": "Sounds excellent my friend. I‚Äôll check it out :)",
                  "score": 2,
                  "created_utc": "2026-02-12 22:45:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zqtvm",
          "author": "No-Neighborhood-5022",
          "text": "Claude can call codex exec out of the box.",
          "score": 1,
          "created_utc": "2026-02-12 15:14:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zwaug",
              "author": "Shakalaka-bum-bum",
              "text": "Yea claude can call but those are open calls and theres problem of resuming the sessions of those chats. For single session or one time call we can use that method but for maintaining context it needs to resume that session",
              "score": 1,
              "created_utc": "2026-02-12 15:40:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50ug5e",
          "author": "rotatorkuf",
          "text": "ok but wtf is a vibecoder haha",
          "score": 1,
          "created_utc": "2026-02-12 18:20:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53vrlw",
              "author": "Shakalaka-bum-bum",
              "text": "It catches more attention",
              "score": 2,
              "created_utc": "2026-02-13 04:10:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50zxmc",
          "author": "csells",
          "text": "Any of the agents can just call any of the other agents via the CLI. A skill makes it smoother (and I'm sure several exist) but they can do it without the skill. What I like to do is ask CC to run my new plan or code by all of the big three CLI agents and consolidate their feedback. Recommended.",
          "score": 1,
          "created_utc": "2026-02-12 18:45:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53w5i3",
              "author": "Shakalaka-bum-bum",
              "text": "Yes cli can be called only problem is loosing context in those cli. Codemoot calls cli, stores their session id, then on every other calls it resumes session. Not only that, context management, structured prompts, structured debates and claude opus 4.6 which is lazy in some aspects but using codemoot we reduces its laziness and make him do more hardwork",
              "score": 1,
              "created_utc": "2026-02-13 04:13:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o53k0j4",
          "author": "Deputius",
          "text": "Lol copy pasting is too much work",
          "score": 1,
          "created_utc": "2026-02-13 02:54:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53vot6",
              "author": "Shakalaka-bum-bum",
              "text": "Yes actually if the automation can be built and used then copy paste is too much work. But codemoot is designed for doing stuff more then that",
              "score": 1,
              "created_utc": "2026-02-13 04:10:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o56p2ja",
          "author": "LukeLeeYh",
          "text": "I have run /plan-review but below error pops up... and can I still use codex 5.3 with multi-level reasoning efforts in your code moot?\n\n‚è∫ Bash(codemoot plan review [BLUEPRINT.md](http://BLUEPRINT.md)\n\n\\--timeout 120000)\n\n  ‚éø ¬†Error: Exit code 1\n\nSending plan to codex for review...\n\n\\[plan-review\\] Started (PID: 29247, cmd:\n\ncodex)\n\n\\[plan-review\\] Thread: 019c57c5-33b...\n\nError: CLI subprocess exited with code 1:\n\nReading prompt from stdin..",
          "score": 1,
          "created_utc": "2026-02-13 16:14:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56zefq",
              "author": "Shakalaka-bum-bum",
              "text": "Codemoot works with whatever codex version you have installed  it shells out to the codex CLI. If your codex supports reasoning effort flags, you can pass them through your .cowork.yml config under the model's args field. We don't have a dedicated --reasoning-effort flag on codemoot commands yet, but the underlying codex calls will use whatever your codex CLI defaults to.",
              "score": 1,
              "created_utc": "2026-02-13 17:03:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5713xy",
          "author": "Equal-Meeting-519",
          "text": "Thanks for taking the time making and sharing it, wish you could make a simle video to show case how you'd use it in a normal dev session",
          "score": 1,
          "created_utc": "2026-02-13 17:11:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ai6gg",
              "author": "Shakalaka-bum-bum",
              "text": "I would be sharing video as soon as possible.",
              "score": 1,
              "created_utc": "2026-02-14 04:52:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uig2r",
          "author": "qa_anaaq",
          "text": "I know someone with a workflow just like this. I‚Äôve been meaning to jump on board. I‚Äôm a senior dev though so my question is, Do you find multiple models takes more time rather than you being able to give faster feedback for iterations?",
          "score": 1,
          "created_utc": "2026-02-11 18:54:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ukbl4",
              "author": "Shakalaka-bum-bum",
              "text": "Honestly yes, each individual iteration takes longer a debate round with GPT reviewing and critiquing adds 30-60 seconds on top of what Claude alone would do. But here's what I found intersting\n\nThe old way: Claude writes code fast -> I review -> find bugs -> fix -> review again -> find more bugs -> repeat 5-6 times. That \"fast\" iteration actually cost me hours.\n\nWith mine new approach: Claude writes code ->GPT catches bugs on first review -> they debate edge cases I wouldn't have thought of -> I get cleaner code in fewer total iterations.\n\nSo per-iteration it's slower, but total time to production-ready code is way less. Especially for security stuff  GPT catches things Claude misses and vice versa. The real win isn't speed per iteration, it's fewer iterations overall. Plus with --background flag you can queue reviews and keep working. The models grind while you move on to the next thing.",
              "score": 3,
              "created_utc": "2026-02-11 19:03:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4vesb5",
          "author": "Strong-Fruit-3309",
          "text": "You have only master branch,at least dev branch and rename master to main :)) you did vibe code it and that is visible 100% :)))",
          "score": 1,
          "created_utc": "2026-02-11 21:30:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xbamw",
              "author": "Shakalaka-bum-bum",
              "text": "I have dev branch in another repo thats private one where I do all other experiments before pushing all ik public branch and packages",
              "score": 1,
              "created_utc": "2026-02-12 04:00:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y11yl",
          "author": "openclaw-lover",
          "text": "Try OpenClaw . You can build complex multi-agent workflows.",
          "score": 0,
          "created_utc": "2026-02-12 07:31:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yc81r",
              "author": "Shakalaka-bum-bum",
              "text": "Yeah OpenClaw is cool for building custom multi-agent stuff, but honestly for day-to-day coding I wanted something more opinionated and structured. Like I don't want to wire up agents from scratch every time  I just want to run codemoot review and get GPT to review what Claude wrote. It's more of a ready-to-go workflow than a framework to build your own. Different use cases really.",
              "score": 1,
              "created_utc": "2026-02-12 09:20:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0trvp",
      "title": "these days I am like this",
      "subreddit": "ClaudeCode",
      "url": "https://v.redd.it/9qhsdz8u6mig1",
      "author": "Local-Bison-4392",
      "created_utc": "2026-02-10 06:51:09",
      "score": 176,
      "num_comments": 8,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Humor",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r0trvp/these_days_i_am_like_this/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4kwyv5",
          "author": "rm-rf-rm",
          "text": "This is unironically the kind of person who is going to stand out in the AI-assisted building/creating/coding age. Rick Rubin is an absolute GOAT and has 100% been as responsible for some of my favorite music as the artists themselves",
          "score": 36,
          "created_utc": "2026-02-10 08:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lzhd7",
          "author": "hemlockecho",
          "text": "I think this is actually more accurate than OP intended. Rick Rubin is lying. He knows a lot about music. He has played in bands. He has been a hands-on producer for tons of albums. He knows his way around a studio board, a DAW, drum machines, whatever. Possibly he can‚Äôt read sheet music or play you a Dorian scale on command, but otherwise he as fully informed about making music in a modern setting as one can be. He just likes to present this guru savant aura about himself now that he doesn‚Äôt have to get down into the weeds as much. \n\nThat is how programming with AI will be most successful. People who know code and best practices and what the AI is doing will be able to use it best without actually having to get down to the lower levels very often, while someone who doesn‚Äôt will be as useless as a producer who knew as little about music as Rubin pretends to.",
          "score": 18,
          "created_utc": "2026-02-10 13:23:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4llqlu",
          "author": "muffa",
          "text": "Pretty funny he wrote this book: https://www.thewayofcode.com/ \n\n* THE WAY\nOF CODE\nThe Timeless Art of Vibe Coding*",
          "score": 5,
          "created_utc": "2026-02-10 11:50:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4m6063",
              "author": "klumpp",
              "text": "Love Rick Ruben but wtf is this",
              "score": 3,
              "created_utc": "2026-02-10 13:59:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4n84hp",
                  "author": "muffa",
                  "text": "It's pretty out there...hahaha",
                  "score": 1,
                  "created_utc": "2026-02-10 17:06:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4llp3t",
          "author": "spinozasrobot",
          "text": "It's the pace that gets me.  I keep reading new ideas and attempts at things like orchestration, but the reviews are awesome one day, and the entire idea is trashed by something new the next day.\n\nMakes me feel like spending any time on an idea will be wasted within 24 hours.",
          "score": 5,
          "created_utc": "2026-02-10 11:50:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lgonk",
          "author": "suliatis",
          "text": "i often feel like this too. but also sometimes i use cc as my personal rick rubin to handle my imposter syndrome:)",
          "score": 3,
          "created_utc": "2026-02-10 11:09:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lp3hy",
          "author": "dviolite",
          "text": "Entirely too true. When everyone can build things, taste is the differentiator.",
          "score": 1,
          "created_utc": "2026-02-10 12:15:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r26gj1",
      "title": "GLM 5 is out now.",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/69tmde88zwig1.png",
      "author": "Cultural-Arugula-894",
      "created_utc": "2026-02-11 19:08:30",
      "score": 174,
      "num_comments": 72,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r26gj1/glm_5_is_out_now/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4w8ftz",
          "author": "A_Small_Pillowcase",
          "text": "I haven't seen one benchmark picture since the whole AI shit started that actually represented real life usage",
          "score": 43,
          "created_utc": "2026-02-12 00:04:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wq3fg",
              "author": "Codemonkeyzz",
              "text": "Yeah. There are tons of benchmarks out there but I don't feel they're useful at all. Who cares a model can one shot a tetris game in js. Who needs that in their day to day job? Safest bet is always try yourself and be a judge. But then again, models can decay too. Opus  was great in November, it shit now. And Codex , it was shit in November and it's great now.",
              "score": 4,
              "created_utc": "2026-02-12 01:49:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zxxes",
                  "author": "Quirky_Drama_3638",
                  "text": "why opus is shit now?",
                  "score": 1,
                  "created_utc": "2026-02-12 15:48:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4w1eae",
          "author": "EarEquivalent3929",
          "text": "3 shades of Grey, really?",
          "score": 38,
          "created_utc": "2026-02-11 23:24:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w34vr",
              "author": "hdmiusbc",
              "text": "Better than 50 shades tho",
              "score": 16,
              "created_utc": "2026-02-11 23:33:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4xw5fq",
                  "author": "Not-Kiddding",
                  "text": "My inner goddess agrees",
                  "score": 2,
                  "created_utc": "2026-02-12 06:46:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uq18t",
          "author": "SnooTangerines2270",
          "text": "Just 1 thing: time is money.  \nThe GLM 5 maybe lower cost, the KIMI 2.5 maybe cheaper cost than Max 5 plan.  \nBut trust me, they will bring you to a loop copy/paste/fix-it/copy-paste-fix-it. and the way they code is just slow.\n\nAnd I don't have time for it. They work fine for small task, or you give them details on your prompt, but as Feb 11th of 2026, I just tell Oppus 4.6: Do this, brainstorm with me and build that for me. Oppus 4.5 - 4.6 , their brain is on a high level already, they know what I want without put me into a loop, and their swam agent multiple in background are just too good at this moment, nothing can beat CC Oppus 4.6 for $100. If you make $5,000 a month, then $100 is nothing to help resolve all the issue quickly. ",
          "score": 28,
          "created_utc": "2026-02-11 19:30:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4us92q",
              "author": "Parking-Bet-3798",
              "text": "They are closer to sonnet 4.5 than what you might be thinking. I used Kimi for most implementation tasks and it works great. I reserve opus for complex and planning tasks. As you said yourself, we don‚Äôt have to use the same model for everything. So I for one am happy to see launch of these models and they becoming smarter with every release.",
              "score": 16,
              "created_utc": "2026-02-11 19:41:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4uuea8",
                  "author": "Sensitive_Song4219",
                  "text": "Yes. To me this is one of the likely reasons Anthropic was banning subscription use in OpenCode: they'd rather users didn't try other models and risk being impressed by the competition.\n\nWe'll see how GLM 5 performs in practice, but whilst GLM 4.7 (and Kimi 2.5 in my limited testing) felt very Sonnet-like, it didn't come close to Opus or Codex-High/XHigh. So the frontier moat is still in place - unless GLM 5 is a massive leap. Will have to test it.",
                  "score": 7,
                  "created_utc": "2026-02-11 19:51:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4vs5fg",
              "author": "AdBest4099",
              "text": "üíØ agree",
              "score": 3,
              "created_utc": "2026-02-11 22:35:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4vuwk3",
              "author": "SignificanceMurky927",
              "text": "Experienced this first hand. The models of fine and can handle complex task fairly well but the token per second output and velocity is just not there yet.",
              "score": 3,
              "created_utc": "2026-02-11 22:49:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4wgwjl",
              "author": "Intrepid_Travel_3274",
              "text": "Yep 100% with u... I used to handle a lot of small tasks with G3 Flash, but using¬†**GPT-5.2 High / Codex 5.3 High**¬†is a total time saver. I¬†**got more done**¬†with the $20 Codex in 2 days than in a month with Antigravity. I hope open-source models eventually reach this level at that price point, but for now, I don't see myself switching back to GLM, Kimi, or DeepSeek over Codex.\n\nP.S. Does 5.2 High take about an hour to finish a task? Yep... but it gets things right the first time (43 tries so far, and no misses yet).",
              "score": 2,
              "created_utc": "2026-02-12 00:53:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4x8ydj",
                  "author": "HillaryPutin",
                  "text": ">but it gets things right the first time\n\ntotally disagree that GPT 5.3 High gets it right the first time. idc what the benchmarks say, it is inferior to Opus at tactfully navigating a monolithic repo imo. Just fucks everything up beyond repair, have reverted changes probably 7 of the 10 times I've used it. And 2 of the remaining 10 were salvageable only because of opus.  ",
                  "score": 1,
                  "created_utc": "2026-02-12 03:45:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4x7vfx",
              "author": "Chalutation",
              "text": "You should use Claude code with GLM and the plug-in \"get shit done\", it's pretty awesome with only GLM.",
              "score": 2,
              "created_utc": "2026-02-12 03:38:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4w359d",
              "author": "Mochilnic",
              "text": "> Nothing can beat CC Opus 4.6\n\n> GPT 5.2 High for 20$ a month and generous quotas: hold my beer",
              "score": 2,
              "created_utc": "2026-02-11 23:33:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4woxmc",
              "author": "zeroconflicthere",
              "text": ">Oppus 4.5 - 4.6 , their brain is on a high level already, they know what I want without put me into a loop\n\nIt isn't though. I've had opus 4.6b answer me in Chinese and get stuck fixing an issue repeatedly that antigravity was able to instead. \n\nThe real issue is that you shouldn't rely onn putting your eggs all in one basket.",
              "score": 2,
              "created_utc": "2026-02-12 01:42:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4xid3p",
              "author": "maek",
              "text": "This guy fucks.",
              "score": 1,
              "created_utc": "2026-02-12 04:51:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4vockz",
          "author": "stiky21",
          "text": "I'll just stick with Opus and Codex.",
          "score": 8,
          "created_utc": "2026-02-11 22:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xl6bl",
              "author": "KiwiUnable938",
              "text": "Opus reminds me of o1 only way better.",
              "score": 3,
              "created_utc": "2026-02-12 05:13:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50axd6",
                  "author": "stiky21",
                  "text": "I miss o1. Times were simpler.",
                  "score": 3,
                  "created_utc": "2026-02-12 16:48:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4wot34",
          "author": "ianxiao",
          "text": "Still run at unsuable token/s . Not for me",
          "score": 2,
          "created_utc": "2026-02-12 01:41:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wqfqn",
          "author": "Far-Donut-1177",
          "text": "I tried GLM 4.5/4.6 and I don't see the point of subscribing when I could get similar output from local models. ",
          "score": 2,
          "created_utc": "2026-02-12 01:51:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ybbbh",
              "author": "Daniel15",
              "text": "Do you mean running GLM 4.6 locally, or a different model?¬†",
              "score": 1,
              "created_utc": "2026-02-12 09:11:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4yc5y5",
                  "author": "Far-Donut-1177",
                  "text": "I tried the coding plan from [z.ai](http://z.ai) for about 2 months. Started with 4.5 then used 4.6 when it came out. Both models required a very hands-on approach to development as opposed to Sonnet 4.5/Opus 4.1/4.5. You couldn't rely on it for tasks that required high inference.\n\nIt was good for high structured processes like if you've built a series of rules, hooks and whatnot.\n\nBut when I began trying running local models, I could also get similar output as GLM with Qwen. So I figured, why bother paying for something that I could just get with local models.",
                  "score": 2,
                  "created_utc": "2026-02-12 09:20:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yc9sr",
              "author": "AcidicAttorney",
              "text": "Unless you‚Äôve got 500GB of RAM lying about, you‚Äôre not getting anywhere near‚Ä¶ GLM 4.7 is about Claude Sonnet 4.5 level imo. Maybe GLM 5 is even better, I haven‚Äôt tried it yet.",
              "score": 1,
              "created_utc": "2026-02-12 09:21:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ycoh7",
                  "author": "Far-Donut-1177",
                  "text": "I honestly don't think GLM 4.7 is Sonnet 4.5 level. More like 3.5.",
                  "score": 2,
                  "created_utc": "2026-02-12 09:25:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o50iy3a",
              "author": "Inprobamur",
              "text": "4.6 has less than half the parameters compared to 5.0",
              "score": 1,
              "created_utc": "2026-02-12 17:26:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xkjvg",
          "author": "erizon",
          "text": "For now the Claude Code API is not yet active - it works via https://chat.z.ai/, and shows up at https://api.z.ai/api/anthropic/v1/models\nbut both variants\n    ANTHROPIC_DEFAULT_SONNET_MODEL=\"glm-5\"    \nreturns\n    API Error: 400 {\"error\":{\"code\":\"1211\",\"message\":\"Unknown Model, please check the model code.\"},\n\n{\n  \"data\": [\n    {\n      \"created_at\": \"2025-07-28T00:00:00Z\",\n      \"display_name\": \"GLM-4.5\",\n      \"id\": \"glm-4.5\",\n      \"type\": \"model\"\n    },\n    {\n      \"created_at\": \"2025-07-28T00:00:00Z\",\n      \"display_name\": \"GLM-4.5-Air\",\n      \"id\": \"glm-4.5-air\",\n      \"type\": \"model\"\n    },\n    {\n      \"created_at\": \"2025-10-01T08:00:00Z\",\n      \"display_name\": \"GLM-4.6\",\n      \"id\": \"glm-4.6\",\n      \"type\": \"model\"\n    },\n    {\n      \"created_at\": \"2025-12-22T00:00:00Z\",\n      \"display_name\": \"GLM-4.7\",\n      \"id\": \"glm-4.7\",\n      \"type\": \"model\"\n    },\n    {\n      \"created_at\": \"2026-02-11T00:00:00Z\",\n      \"display_name\": \"GLM-5\",\n      \"id\": \"glm-5\",\n      \"type\": \"model\"\n    }\n  ],\n  \"firstId\": \"glm-4.5\",\n  \"hasMore\": false,\n  \"lastId\": \"glm-5\"\n}\n\nEDIT: error changed to 429 {\"error\":{\"code\":\"1302\",\"message\":\"Rate limit reached for requests\"}\nso probably overloaded and shall be fine soonish",
          "score": 2,
          "created_utc": "2026-02-12 05:08:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zt76v",
              "author": "No-Technology6511",
              "text": "It got fixed for me on opencode later",
              "score": 1,
              "created_utc": "2026-02-12 15:26:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51g216",
              "author": "hardikbhatnagar",
              "text": "i cannot use the claude code endpoint either. weere you able to get it to work?",
              "score": 1,
              "created_utc": "2026-02-12 20:02:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51hjbt",
                  "author": "erizon",
                  "text": "Are you on Lite/Pro plan? Currently it is only at Max\n\nhttps://www.reddit.com/r/ClaudeCode/comments/1r26gj1/glm_5_is_out_now/o4xpk4s/",
                  "score": 1,
                  "created_utc": "2026-02-12 20:09:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4wfu3s",
          "author": "Level-Statement79",
          "text": "Congratulation for 3 gray colours. OMG. :D",
          "score": 2,
          "created_utc": "2026-02-12 00:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wtd2p",
          "author": "SunofaBaker",
          "text": "How does 04.6 Compare ",
          "score": 1,
          "created_utc": "2026-02-12 02:09:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xm6wz",
          "author": "KiwiUnable938",
          "text": "Just please dont pull a chatgpt and get rid of opus 4.6 or some dumb shit‚Ä¶ cause the new one ‚Äúis better‚Äù‚Ä¶ caugh o1. ü•¥",
          "score": 1,
          "created_utc": "2026-02-12 05:20:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xpk4s",
          "author": "erizon",
          "text": ">Currently, we are in the stage of replacing old model resources with new ones. **Only the Max (including both new and old subscribers) newly supports GLM-5**, and invoking GLM-5 will **consume more plan quota** than historical models. After the iteration of old and new model resources is completed, the Pro will also support GLM-5.\n\nas per https://docs.z.ai/devpack/overview",
          "score": 1,
          "created_utc": "2026-02-12 05:48:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xwy0r",
          "author": "Camaraderie",
          "text": "Is this not yet available on GLM lite plan? Just wondering before I start messing with my current claude code config files.",
          "score": 1,
          "created_utc": "2026-02-12 06:53:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ybqgt",
              "author": "Daniel15",
              "text": "They've only announced plans to add it to the Max and Pro plans. Maybe it'll come to the Lite plan eventually?\n\n\nEdit: they just announced that it's coming to lite soon.¬†",
              "score": 1,
              "created_utc": "2026-02-12 09:15:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y2jge",
          "author": "CissMN",
          "text": "Yo, their video effect template agent examples are crazy. Like what?\n\n[https://docs.z.ai/guides/agents/video-template](https://docs.z.ai/guides/agents/video-template)",
          "score": 1,
          "created_utc": "2026-02-12 07:45:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ztuwr",
              "author": "No-Technology6511",
              "text": "Haha that bodyshake was funny lmao",
              "score": 1,
              "created_utc": "2026-02-12 15:29:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y3vag",
          "author": "Dry-Storm-5784",
          "text": "Leaving aside benchmark... How does it perform for long coding sessions?",
          "score": 1,
          "created_utc": "2026-02-12 07:58:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zrz6j",
          "author": "RadioactiveBread",
          "text": "So? These chinese models are terrible compared to even Gemini.",
          "score": 1,
          "created_utc": "2026-02-12 15:20:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5098p0",
          "author": "WillingBookkeeper580",
          "text": "Gemini needs to step up",
          "score": 1,
          "created_utc": "2026-02-12 16:41:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50a84z",
          "author": "xxlordsothxx",
          "text": "Crazy that it beat gpt and Claude in humanity's last exam.",
          "score": 1,
          "created_utc": "2026-02-12 16:45:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52samd",
          "author": "MarsupialNice7695",
          "text": "I'm sorry but if you use anthropic or codex all these things still don't really seem to be true\nUse reviews and yourself\nI use codex 5.3 and it's crazy\nClaude code works magic it's pretty much coding focus and most of the industry realizes that\nI think you better off running glm and kimi2.5 for small task still like general chat and background logging of diff/status updates moving vectors and memories pushing commits\nBut you could also do that running a local qwen3 model without the cost\nYou can also make a wrapper and have codex talk to chatgpt 5.2 to use it's generalized intelligence on your CLI so you don't use API and talk to each other in json\nThis allows codex to have better multimodal generative intelligence to speak on things and looking at different tools or website data more comprehensive or have Gemini cli pro 3 look at the data while chatgpt rerank the information and verify accuracy\n\nI think Gemini, openai and Claude still holding it down",
          "score": 1,
          "created_utc": "2026-02-13 00:07:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54u7b1",
          "author": "Character-Potato9986",
          "text": "I started tested it.",
          "score": 1,
          "created_utc": "2026-02-13 08:56:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4viz6m",
          "author": "Michaeli_Starky",
          "text": "Bullshit graphs",
          "score": 1,
          "created_utc": "2026-02-11 21:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uohj2",
          "author": "Expensive-Plant-69",
          "text": "the model is 1.5 tb",
          "score": 1,
          "created_utc": "2026-02-11 19:23:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x75b7",
          "author": "According_Tea_6329",
          "text": "GLM is the greatest token value out there right now.",
          "score": 1,
          "created_utc": "2026-02-12 03:33:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vv2za",
          "author": "Bright-Celery-4058",
          "text": "They dont have enough gpus to serve everyone, also dont trust them on benchmarks.",
          "score": 0,
          "created_utc": "2026-02-11 22:50:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r03a0t",
      "title": "Claude Code + playwright CLI = superpowers",
      "subreddit": "ClaudeCode",
      "url": "https://www.youtube.com/watch?v=CVxEOfGu7Nw",
      "author": "Hopeful-Fly-5292",
      "created_utc": "2026-02-09 12:46:32",
      "score": 166,
      "num_comments": 42,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r03a0t/claude_code_playwright_cli_superpowers/",
      "domain": "youtube.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4gjcxa",
          "author": "lockyourdoor24",
          "text": "Opus 4.6 is a lot better at browser use in general. I've noticed a massive increase in speed and it's not getting stuck nearly as often when using devtools mcp. Also far fewer warnings about large 30k+ pages being read so I'm guessing it has been optimised for token usage too. It was one of the things that was noted in the improvements from 4.5 to 4.6. ",
          "score": 13,
          "created_utc": "2026-02-09 16:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4gc0nu",
          "author": "Careless_Bat_9226",
          "text": "We have playwright tests that run in CI and locally for key flows but I've been wishing I could tell Claude Code something like \"test the feature I'm working on in playwright\" and have it figure out a playwright test that would run through the necessary UI flows.\n\nI like the CLI but even then it's really slow if after each action the LLM has to think about what to do next.\n\nAnyone have ideas? I've thought about maybe creating a skill that builds up the whole testing sequence as a typescript file beforehand and then runs it and then evaluates the result.",
          "score": 5,
          "created_utc": "2026-02-09 16:13:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4gqyps",
              "author": "AI_should_do_it",
              "text": "I tell Claude to use playwright to test features",
              "score": 3,
              "created_utc": "2026-02-09 17:24:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4gxvfl",
                  "author": "Careless_Bat_9226",
                  "text": "Well, sure, but that's slow as molasses.¬†",
                  "score": 3,
                  "created_utc": "2026-02-09 17:57:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4kypzu",
              "author": "beth_maloney",
              "text": "I have a skill that writes js scripts that call playwright. Honestly I don't find it any better then using the mcp server.\n\nMaybe if I invested more time in creating a  testing framework for my app it would be better but not sure if it's worth the investment.",
              "score": 1,
              "created_utc": "2026-02-10 08:18:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fl2mk",
          "author": "sizebzebi",
          "text": "supertokens for the mcp, I tried once and instantly deleted it. what difference does this make is you don't have to transfer the context and cli will do the job for you?",
          "score": 7,
          "created_utc": "2026-02-09 13:52:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ip4tr",
              "author": "Tobi-Random",
              "text": "How about listening to what he says about the snapshot?",
              "score": 1,
              "created_utc": "2026-02-09 23:09:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fmfae",
          "author": "Arindam_200",
          "text": "i recently started using agent browser. Have you tried that?",
          "score": 6,
          "created_utc": "2026-02-09 14:00:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fx6up",
              "author": "jpcaparas",
              "text": "agent-browser is far more superior than playwright mcp. yes, it uses playwright under the hood, but it's a skill, not an MCP server.\n\nit's zippy too. reduced my context bloat by a fuckton.\n\nI did a writeup about it here with some demos:\n\n[https://extended.reading.sh/skill-agent-browser](https://extended.reading.sh/skill-agent-browser)",
              "score": 18,
              "created_utc": "2026-02-09 15:00:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4gdhsb",
                  "author": "Aggressive-Habit-698",
                  "text": "See OP - we are talking about Playwright CLI not MCP",
                  "score": 7,
                  "created_utc": "2026-02-09 16:20:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4fpver",
              "author": "Aggressive-Habit-698",
              "text": "There is also a Playwright under the hood. \n\nhttps://github.com/vercel-labs/agent-browser/blob/main/src%2Fbrowser.ts\n\nSimilar yet different ‚Äì CLI is the better solution if you want to make your own customizations.",
              "score": 4,
              "created_utc": "2026-02-09 14:20:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fmy5x",
          "author": "managing_redditor",
          "text": "agent-browser is superior for speed and token usage from my experience.",
          "score": 2,
          "created_utc": "2026-02-09 14:03:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h692x",
          "author": "jazzy8alex",
          "text": "MCP is (was?) a transient technology. Nobody should use MCP servers if there is an alternative \n\nand vercel agent-browser is great.  PW CLI has a different purpose. \n\n  \nAI summary: \n\nPlaywright‚Äôs CLI is primarily an interface to¬†**Playwright Test**¬†(run tests, debug, UI mode) and tooling like codegen. It‚Äôs excellent when you have (or want) a test project and want repeatable runs.¬†¬†\n\nagent-browser¬†is a¬†**browser-automation CLI designed for AI agents**. The core design choice is¬†**snapshot + short ‚Äúrefs‚Äù**(like¬†u/e2) so the agent doesn‚Äôt have to juggle verbose DOM selectors, and you can keep command outputs small.¬†¬†\n\nIt also runs as a¬†**client‚Äìdaemon**¬†(fast repeated commands) and uses Playwright under the hood.",
          "score": 2,
          "created_utc": "2026-02-09 18:36:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j88i9",
              "author": "inter2",
              "text": "\"MCP is a transient technology...\"\n\nI think for local tool use, maybe. But for remote to remote services, modular agents, etc, I think MCP pretty important for some time to come.",
              "score": 1,
              "created_utc": "2026-02-10 00:56:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ic16c",
          "author": "fabiononato",
          "text": "I have been using your video as an example of how MCP can be a token hog! Thanks for sharing!",
          "score": 2,
          "created_utc": "2026-02-09 22:01:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jm952",
          "author": "cfdude",
          "text": "you should try Vercel's new open-sourced 'agent-browser', its a headless browser built on Rust, super fast and powerful and loaded with features that Playwright doesn't have.  In Playwright I'd have to try and target classes or IDs for action - in agent-browser it's just 'firstname' oh and it is not fooled by iframes and botstopping hidden html either.  Not looking back...",
          "score": 2,
          "created_utc": "2026-02-10 02:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kxn09",
          "author": "ultrathink-art",
          "text": "The Playwright CLI shift is huge. I've been using it for visual QA workflows‚Äîscreenshot diffs, cross-browser checks, accessibility audits. The reliability improvement over MCP is night and day for anything involving complex JS interactions.\n\nOne pattern that's worked well: keep your Playwright scripts in version control and have Claude modify them directly rather than regenerating the flow each time. Lets you build up a library of reliable test patterns that Claude can reference and extend.",
          "score": 2,
          "created_utc": "2026-02-10 08:07:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lfvz1",
          "author": "Glad-Hall7146",
          "text": "If you are senior software engineers and have to handle multiple tasks in different projects, yes use claude or othe cli agents to automate and help you in your daily job. BUT IF YOU ARE A JUNIOR TO MID LEVEL FORGET AI , STOP VIBE CODING OR YOU WILL LEARN SHIT AND BE JOBLESS FASTER THAN YOU THINK",
          "score": 2,
          "created_utc": "2026-02-10 11:02:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h6yw6",
          "author": "cport1",
          "text": "all you have to do is type \n\n    /chrome",
          "score": 1,
          "created_utc": "2026-02-09 18:39:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iq5m4",
          "author": "shogster",
          "text": "Can the agent use it to write tests after it has explored a given page? Or maybe create POM spec files based on the refs it found, extract locators etc? Not sure if CLI is the best way for this.",
          "score": 1,
          "created_utc": "2026-02-09 23:14:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4js8gf",
          "author": "rakuu",
          "text": "Thank you!! Super useful. So much is released so fast these days it's easy to miss something useful like this.",
          "score": 1,
          "created_utc": "2026-02-10 02:52:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k1ict",
          "author": "ViperAMD",
          "text": "For most things you can write a script and not rely on an LLM and waste tokens..only really relevant for super dynamic sites¬†",
          "score": 1,
          "created_utc": "2026-02-10 03:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4muq6y",
          "author": "AdMinute3667",
          "text": "May I know how exactly this cli or MCP helps? \nI use playwright almost everyday for automation. \nI am not getting the exact use of the playwright-cli for an automation engineer. Is it used to navigate over pages / to be used by dev as a testing tool?",
          "score": 1,
          "created_utc": "2026-02-10 16:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g0787",
          "author": "No_Room636",
          "text": "I'm not sure what the point is? Is there really a use case for this that I'm missing? Isn't it faster and better to have a human do this kind of bug checking?",
          "score": -8,
          "created_utc": "2026-02-09 15:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4gqt1g",
              "author": "AI_should_do_it",
              "text": "How is a human faster then a loop?",
              "score": 2,
              "created_utc": "2026-02-09 17:23:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4gy09b",
              "author": "ragnhildensteiner",
              "text": ">  Isn't it faster and better to have a human do this\n\nü§£ü§£ü§£",
              "score": 2,
              "created_utc": "2026-02-09 17:57:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4gxvjb",
              "author": "ur-krokodile",
              "text": "Go back to Motlbook",
              "score": 2,
              "created_utc": "2026-02-09 17:57:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0a81h",
      "title": "Introducing Nelson",
      "subreddit": "ClaudeCode",
      "url": "https://v.redd.it/0lc6j48o5iig1",
      "author": "bobo-the-merciful",
      "created_utc": "2026-02-09 17:19:48",
      "score": 151,
      "num_comments": 65,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Showcase",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r0a81h/introducing_nelson/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4gvsf9",
          "author": "HypnoToad0",
          "text": "I understand you. I named mine 'Generals' and I'm the 'Supreme Commander'",
          "score": 20,
          "created_utc": "2026-02-09 17:47:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l1t5k",
              "author": "Mindspacing",
              "text": "I have both claude and codex or as I call them.. \"Jean\" Claude and \"Charles\" Xavier.   \nBonus fact; I started out with Claude code and had a Wrapper for it called Jean and then the middle is \"claude\" doing its work and then when every sesison ended i had a skill called /Vandamme (\"I'm done\") come in to do custom handoffs and stuff.",
              "score": 3,
              "created_utc": "2026-02-10 08:48:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4gwbkc",
              "author": "bobo-the-merciful",
              "text": "Love it!",
              "score": 1,
              "created_utc": "2026-02-09 17:49:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hgbep",
          "author": "Zomunieo",
          "text": "You should put Nelson in charge of a Ralph Wiggum loop.",
          "score": 9,
          "created_utc": "2026-02-09 19:23:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hkiwi",
              "author": "bobo-the-merciful",
              "text": "https://preview.redd.it/89mq1hyuviig1.png?width=1024&format=png&auto=webp&s=378f7e860945ade4dd5f3c998f4e62b270948983\n\nI'll try that now!",
              "score": 10,
              "created_utc": "2026-02-09 19:44:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hgx52",
          "author": "LocalFoe",
          "text": "--dangerously-skip-permissions gang",
          "score": 7,
          "created_utc": "2026-02-09 19:26:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hkbvb",
              "author": "bobo-the-merciful",
              "text": "Mainly because I keep forgetting how to use tmux hahaha",
              "score": 2,
              "created_utc": "2026-02-09 19:43:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4hw8tx",
                  "author": "LocalFoe",
                  "text": "who the hell cares about tmux when you have cmd+d and cmd+shift+d in warp",
                  "score": 2,
                  "created_utc": "2026-02-09 20:43:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kss61",
          "author": "jangwao",
          "text": "Give you a star on GitHub. One question, do they use worktrees? As I can't see in it in Readme. I mean there are plenty of sub-agent orchestrations (I can name at least five) but each has different agent-agents communication (ACP, files, bi-directional, governance, GitHub issues), maybe would be worth adding you to matrix once I understand your specialities :)",
          "score": 4,
          "created_utc": "2026-02-10 07:21:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4meilc",
              "author": "bobo-the-merciful",
              "text": "Nope, doesn't use worktrees (yet). It's bi-directional messaging with centralised governance. Consider it as structured methodology for Claude Code's native agent team - it provides doctrine for what is already there.",
              "score": 3,
              "created_utc": "2026-02-10 14:45:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5b3n7w",
                  "author": "jangwao",
                  "text": "Okay, makes sense, I remember one had similar governance written in Rust but forgot the name. Haven't tried it yet. \n\nBi-directional with worktrees would be sick but that's technically how Claude teams works?",
                  "score": 1,
                  "created_utc": "2026-02-14 08:00:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4grw8s",
          "author": "0xmaxhax",
          "text": "Honestly, despite the silliness of the naming, your prompt engineering and structuring of the skill is pretty good. I suggest you lose the confusing navy-related metaphors within the prompts to ensure the directives aren't convoluted or confusing and keep working on this, as it seems like it has potential for scaffolding the agent teams feature well.",
          "score": 7,
          "created_utc": "2026-02-09 17:28:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hjfu0",
              "author": "Ran4",
              "text": "Unironically, using specific terms can be a good thing - as it means a very specific thing.\n\nIf you just call something a \"planner\" or a \"temporary worker\" then the llm isn't going to verify what exactly that is, they're just going to act like a generic role, but if you tell it it's a specific thing it will look up what that means and act more like that. Same thing with Gas Town with its mayor/polecat/dog concept.",
              "score": 4,
              "created_utc": "2026-02-09 19:39:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4htnvj",
                  "author": "dashingsauce",
                  "text": "1000% semantics are more functional with LLMs than people realize",
                  "score": 5,
                  "created_utc": "2026-02-09 20:30:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4hlopt",
                  "author": "bobo-the-merciful",
                  "text": "It's also fun.",
                  "score": 4,
                  "created_utc": "2026-02-09 19:50:02",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4gtyyo",
              "author": "bobo-the-merciful",
              "text": "Thanks. I went down a funny rabbit hole with it. Started off just trying to figure out different ways of \"organising\" agent engineering teams based on the theory. Started noticing the themes of \"contracts\" and \"missions\" coming up, so pivoted to it being like creating a special forces team to complete a mission. Then thought f\\*ck it, why not make based on the Royal Navy.",
              "score": 6,
              "created_utc": "2026-02-09 17:38:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4gw3mt",
                  "author": "0xmaxhax",
                  "text": "Lol thats how most useful innovations are created. My only concern is that agents are best at task coordination and completion without metaphorical fluff, so if you kept the general concept(s) but cleaned the prompts up of the metaphorical / performative stuff I'm confident it'd be more useful. Interested to see where you go with this",
                  "score": 2,
                  "created_utc": "2026-02-09 17:48:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4gwyzf",
                  "author": "DasBlueEyedDevil",
                  "text": "I can relate to the rabbit holes... [https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)\n\nI poked at a theme for a moment and then just went all in for giggles",
                  "score": 2,
                  "created_utc": "2026-02-09 17:53:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ibnyv",
              "author": "flarpflarpflarpflarp",
              "text": "I don't want to be a Debbie Downer but I also built something like this and Opus 4.6 rendered it largely useless now.",
              "score": 2,
              "created_utc": "2026-02-09 21:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4me5s9",
                  "author": "bobo-the-merciful",
                  "text": "I think you might misunderstand - this leverages the new agent teams feature which was released at the same time as Opus 4.6",
                  "score": 1,
                  "created_utc": "2026-02-10 14:43:42",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hh5bh",
          "author": "Egg_Chen",
          "text": "cloned to experiment with. thanks u/bobo-the-merciful ",
          "score": 2,
          "created_utc": "2026-02-09 19:27:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hkem2",
              "author": "bobo-the-merciful",
              "text": "You're welcome - look forward to a PR if you fancy sharing any discoveries.",
              "score": 1,
              "created_utc": "2026-02-09 19:43:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hu2h2",
          "author": "dashingsauce",
          "text": "This is very cool. I started working on something similar last year (when Roo code had legs) and went with professional American football team organization.\n\nYours is a better fit and makes me want to play CIV though.\n\nCan you share the research/resources that went into this? Or is it pretty much all in the skill?",
          "score": 2,
          "created_utc": "2026-02-09 20:32:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4huait",
              "author": "bobo-the-merciful",
              "text": "It's all in the skill and in my vibe rifting with Claude to build the first pass of this :)",
              "score": 2,
              "created_utc": "2026-02-09 20:33:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hw42u",
          "author": "spenpal_dev",
          "text": "Does this depend on whether you have a fully drafted plan already? Or is brainstorming/planning baked into this workflow, as well?",
          "score": 2,
          "created_utc": "2026-02-09 20:42:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i082f",
              "author": "bobo-the-merciful",
              "text": "Nelson is currently more of an execution tool than a planning one, but there is some autonomous planning which is baked into the workflow via sailing orders, forming the squadron and drafting the battle plan. But you will get better results by going through more of an upfront planning process before saying \"do this now\".",
              "score": 2,
              "created_utc": "2026-02-09 21:02:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4k8vnz",
          "author": "Icy-Pay7479",
          "text": "We‚Äôre in a post ‚Äúgas town‚Äù world. Nothing can be considered silly anymore.",
          "score": 2,
          "created_utc": "2026-02-10 04:40:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kgu3z",
          "author": "GlassAd7618",
          "text": "This is very interesting and offers a lot learn about effectively dealing with agent teams. Seems like your gut feeling to go into management literature and all that was the right thing to do. I‚Äôm curious to experiment with Nelson, thanks for sharing.",
          "score": 2,
          "created_utc": "2026-02-10 05:39:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4meu2o",
              "author": "bobo-the-merciful",
              "text": "Thanks. As much as there's a comical aspect to making this a military thing - the military is amazing at creating roles that are individual agonstic. The structure in military doctrine is all about role definition and process process process. War is the ultimate test, and the doctrine has been refined over hundreds of years. So why not lean into it?",
              "score": 2,
              "created_utc": "2026-02-10 14:47:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ktf4h",
          "author": "No_Sign4878",
          "text": "How you got the sub-agents output logs displayed besides the main session?",
          "score": 2,
          "created_utc": "2026-02-10 07:27:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lhj3q",
              "author": "bobo-the-merciful",
              "text": "I used tmux for the demo.",
              "score": 1,
              "created_utc": "2026-02-10 11:16:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m31m2",
          "author": "DisplacedForest",
          "text": "I cannot get split pane to work in iterm2. Jealous",
          "score": 2,
          "created_utc": "2026-02-10 13:43:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4me1zz",
              "author": "bobo-the-merciful",
              "text": "Have you tried tmux?",
              "score": 1,
              "created_utc": "2026-02-10 14:43:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4na4vb",
                  "author": "DisplacedForest",
                  "text": "Is tmux a separate app or something I install for iTerm?",
                  "score": 1,
                  "created_utc": "2026-02-10 17:15:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4oafbf",
          "author": "Falcoace",
          "text": "Does this work with codex? Would like to use my codex sub.",
          "score": 2,
          "created_utc": "2026-02-10 20:02:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ob0h0",
              "author": "bobo-the-merciful",
              "text": "Currently it's set up to work with Claude Code to exploit the new Agent Teams feature. You could set these up as Codex skills and they might help but I'm not sure Codex would fully exploit this yet (unless it does secret stuff under the hood with agent teams which we are not aware of - possibly quite likely). Please do test and if you find that it works then happy to review a PR.",
              "score": 1,
              "created_utc": "2026-02-10 20:05:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ol865",
          "author": "Falcoace",
          "text": "Submitted a PR for a codex port.",
          "score": 2,
          "created_utc": "2026-02-10 20:53:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4olbcp",
              "author": "bobo-the-merciful",
              "text": "Thanks! Will review later today",
              "score": 1,
              "created_utc": "2026-02-10 20:53:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sk1wk",
          "author": "Clear_Management2805",
          "text": "First off, huge thanks to u/bobo-the-merciful for creating Nelson. The Royal Navy framework for coordinating CC agent teams is genuinely clever; the hierarchy, the standing orders, the risk tiers; it all maps really well to how you'd want to manage parallel AI agents.\n\nI've been experimenting with token-efficient prompt encoding (inspired by CursorRIPER‚ô¶Œ£) and decided to apply those techniques to Nelson as a test case. The result is Nelson‚ô¶Œ£, a fork that preserves full functionality while compressing the skill from ~5,050 tokens across 30 files to ~800 tokens across 6 files.\n\n  What changed:\n  - Greek letter domains (Œ© = workflow, Œ£ = risk tiers, Œ¶ = standing orders, etc.)\n  - Subscript indexing instead of verbose labels (Œ£‚ÇÄ‚ÄìŒ£‚ÇÉ, Œ¶‚ÇÅ‚ÄìŒ¶‚ÇÅ‚ÇÅ)\n  - Cumulative control notation (Œ£‚ÇÅ = Œ£‚ÇÄ + review + negative test)\n  - Standing orders compressed from 11 separate files to an inlined array\n  - Templates reduced from 6 blank-form files to field arrays\n  - All index/router files eliminated\n\n  What's preserved:\n  - All 6 workflow steps (Define, Compose, Plan, Monitor, Verify, Close)\n  - Full role hierarchy (COORD ‚Üí LEAD ‚Üí crew)\n  - All 4 risk tiers with cumulative controls\n  - All 11 anti-pattern checks\n  - All 6 damage control procedures\n  - Unit names from Royal Navy warships\n\nThe idea is that LLMs parse structured symbolic notation just as well (often better) than verbose prose, so you can convey the same instructions in a fraction of the tokens. Less context spent on the skill = more context available for the actual mission.\n\nI would love for some people to test it out.\n\nRepo: https://github.com/johnpeterman72/nelson.sigma\nOriginal: https://github.com/harrymunro/nelson",
          "score": 2,
          "created_utc": "2026-02-11 13:07:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tljqm",
              "author": "bobo-the-merciful",
              "text": "Very interesting - thank you so much for finding the approach useful and forking it across to this way of doing things. Super interesting project. New features dropping in Nelson (e.g. please check out latest PR on \"discipline\") which you may wish to port across.\n\nGood luck with the project and I'll try to find some time to test myself.",
              "score": 1,
              "created_utc": "2026-02-11 16:21:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hnm8e",
          "author": "Syllosimo",
          "text": "Looks great, hopefully I get some free time to explore my bookmarket projects. Whats the main difference of using nelson skill vs some other similar skill or agent teams if I may ask?",
          "score": 2,
          "created_utc": "2026-02-09 19:59:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hruta",
              "author": "bobo-the-merciful",
              "text": "Well I was thinking that with the new agent teams feature in Claude Code we're moving into a world where management theory might come more in handy. The Royal Navy offers a nice model for how to manage complex things. \n\nBut for a more detailed response to your question, I asked Claude:\n\n# Why Nelson?\n\nWithout Nelson, agent teams give you the mechanics (spawn agents, assign tasks, send messages) but no framework for running them well. Nelson adds three things:\n\n## 1. Risk-tiered quality gates\n\nEvery task is classified into a risk tier with escalating controls:\n\n| Station | Level | Controls |\n| --- | --- | --- |\n| 0 ‚Äî Patrol | Low blast radius | Basic validation, rollback step |\n| 1 ‚Äî Caution | User-visible changes | Independent agent review, negative test cases |\n| 2 ‚Äî Action | Security/compliance impact | Red-cell adversarial review, go/no-go checkpoint |\n| 3 ‚Äî Trafalgar | Irreversible actions | Human confirmation, two-step verification, halt if controls unavailable |\n\n## 2. Operational structure\n\nA six-step flow forces discipline that ad-hoc teams skip:\n\n- **Sailing Orders** ‚Äî scope, constraints, budget, forbidden actions, and stop criteria defined upfront\n- **Form Squadron** ‚Äî mode chosen by matching conditions (single-session / subagents / agent-team), not gut feel\n- **Battle Plan** ‚Äî tasks split with owners, dependencies, and file ownership\n- **Quarterdeck Rhythm** ‚Äî periodic checkpoints for progress, blockers, and budget burn\n- **Action Stations** ‚Äî risk-appropriate verification before marking anything complete\n- **Stand Down** ‚Äî structured teardown and captain's log\n\n## 3. Institutional memory\n\nStand-down produces a record of decisions, rationale, validation evidence, open risks, and reusable patterns ‚Äî context that most coordination approaches discard.\n\n## When not to use it\n\nNelson adds ceremony. For a quick change touching one or two files, use a single session or plain subagents. Nelson is for missions where coordination failures, unchecked risk, or lost context would actually cost you.",
              "score": 5,
              "created_utc": "2026-02-09 20:21:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kkmy9",
          "author": "ultrathink-art",
          "text": "This looks like a clean approach to session management. A few questions from production usage:\n\n1. How do you handle session metadata/tags for filtering (e.g., \"all refactoring sessions\" or \"project X work\")?\n2. Do you track which model was used per session for cost/performance analysis?\n3. Any thoughts on automatic cleanup policies for old sessions?\n\nThe SQLite backend makes sense for local-first tooling. Have you run into any concurrency issues with multiple Claude processes accessing the same DB?",
          "score": 1,
          "created_utc": "2026-02-10 06:10:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfjky",
              "author": "bobo-the-merciful",
              "text": "I think there might be some confusion - these questions don't apply to Nelson. It's not a session management tool and has no SQLite backend (or any backend at all.) Nelson is a documentation-only Claude Code skill ‚Äî it's just Markdown files that teach Claude Code how to coordinate agent teams using a Royal Navy operational framework.           ",
              "score": 1,
              "created_utc": "2026-02-10 14:50:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kqzfm",
          "author": "shaman-warrior",
          "text": "I tried this in google aistudio, no \"ai skill\" no nothing. From one shot it created a fully functional game. I play against a robot, and that robot makes 'thoughtful' moves. There are nice radar waves.",
          "score": 1,
          "created_utc": "2026-02-10 07:05:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ktayt",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-10 07:26:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mf0f6",
              "author": "bobo-the-merciful",
              "text": "Are you trying it with the new agent teams feature?",
              "score": 1,
              "created_utc": "2026-02-10 14:48:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rrsth",
          "author": "koenverc",
          "text": "Really nice work!\n\nI wonder why didn't you turn it into a plugin in order to be able to update the skill whenever you make changes to it?",
          "score": 1,
          "created_utc": "2026-02-11 09:20:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4s47jg",
              "author": "bobo-the-merciful",
              "text": "Thanks. I heard from a colleague that the plugin marketplace wasn‚Äôt particularly good.",
              "score": 1,
              "created_utc": "2026-02-11 11:13:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4sb27i",
                  "author": "koenverc",
                  "text": "Might be worthwhile to look into because plugins are the way to share functionality in the Claude Code ecosystem.",
                  "score": 1,
                  "created_utc": "2026-02-11 12:07:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4sc35v",
          "author": "krenuds",
          "text": "This is great I love it",
          "score": 1,
          "created_utc": "2026-02-11 12:14:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tn60e",
          "author": "bobo-the-merciful",
          "text": "This is what I love to see\n\nhttps://preview.redd.it/dimyccnw6wig1.png?width=2852&format=png&auto=webp&s=fb5f85e9effc234972238d9437dd0505bf8a5098\n\n",
          "score": 1,
          "created_utc": "2026-02-11 16:29:21",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o4gqx7v",
          "author": "Livid_Hat_4363",
          "text": "√ó36q50yh0",
          "score": -3,
          "created_utc": "2026-02-09 17:24:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3zbvt",
      "title": "Max 20x Plan: I audited my JSONL files against my billing dashboard ‚Äî all input tokens appear billed at the cache CREATION rate ($6.25/M), not the cache READ rate ($0.50/M)",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1r3zbvt/max_20x_plan_i_audited_my_jsonl_files_against_my/",
      "author": "jcmguy96",
      "created_utc": "2026-02-13 19:55:36",
      "score": 140,
      "num_comments": 59,
      "upvote_ratio": 0.93,
      "text": "## TL;DR\n\nI parsed Claude Code's local JSONL conversation files and cross-referenced them against the per-charge billing data from my Anthropic dashboard. Over Feb 3-12, I can see **206 individual charges totaling $2,413.25** against **388 million tokens** recorded in the JSONL files. That works out to **$6.21 per million tokens** ‚Äî almost exactly the cache *creation* rate ($6.25/M), not the cache *read* rate ($0.50/M).\n\nSince cache reads are 95% of all tokens in Claude Code, this means the advertised 90% cache discount effectively doesn't apply to Max plan extra usage billing.\n\n---\n\n## My Setup\n\n- **Plan**: Max 20x ($200/month)\n- **Usage**: Almost exclusively Claude Code (terminal). Rarely use claude.ai web.\n- **Models**: Claude Opus 4.5 and 4.6 (100% of my usage)\n- **Billing period analyzed**: Feb 3-12, 2026\n\n## The Data Sources\n\n**Source 1 ‚Äî JSONL files**: Claude Code stores every conversation as JSONL files in `~/.claude/projects/`. Each assistant response includes exact token counts:\n\n```json\n{\n  \"type\": \"assistant\",\n  \"timestamp\": \"2026-02-09T...\",\n  \"requestId\": \"req_011CX...\",\n  \"message\": {\n    \"model\": \"claude-opus-4-6\",\n    \"usage\": {\n      \"input_tokens\": 10,\n      \"output_tokens\": 4,\n      \"cache_creation_input_tokens\": 35039,\n      \"cache_read_input_tokens\": 0\n    }\n  }\n}\n```\n\nMy script scans all JSONL files, deduplicates by `requestId` (streaming chunks share the same ID), and sums token usage. No estimation ‚Äî this is the actual data Claude Code recorded locally.\n\n**Source 2 ‚Äî Billing dashboard**: My Anthropic billing page shows 206 individual charges from Feb 3-12, each between $5 and $29 (most are ~$10, suggesting a $10 billing threshold).\n\n## Token Usage (from JSONL)\n\n| Token Type | Count | % of Total |\n|---|---|---|\n| `input_tokens` | 118,426 | 0.03% |\n| `output_tokens` | 159,410 | 0.04% |\n| `cache_creation_input_tokens` | 20,009,158 | 5.17% |\n| `cache_read_input_tokens` | **367,212,919** | **94.77%** |\n| **Total** | **387,499,913** | 100% |\n\n94.77% of all tokens are cache reads. This is normal for Claude Code ‚Äî every prompt re-sends the full conversation history and system context, and most of it is served from the prompt cache.\n\n*Note: The day-by-day table below totals 388.7M tokens (1.2M more) because the scan window captures a few requests at date boundaries. This 0.3% difference doesn't affect the analysis ‚Äî I use the conservative higher total for $/M calculations.*\n\n## Day-by-Day Cross-Reference\n\n| Date | Charges | Billed | API Calls | All Tokens | $/M |\n|---|---|---|---|---|---|\n| Feb 3 | 15 | $164.41 | 214 | 21,782,702 | $7.55 |\n| Feb 4 | 24 | $255.04 | 235 | 18,441,110 | $13.83 |\n| Feb 5 | 9 | $96.90 | 531 | 54,644,290 | $1.77 |\n| Feb 6 | **0** | **$0** | 936 | 99,685,162 | - |\n| Feb 7 | **0** | **$0** | 245 | 27,847,791 | - |\n| Feb 8 | 23 | $248.25 | 374 | 41,162,324 | $6.03 |\n| Feb 9 | 38 | $422.89 | 519 | 56,893,992 | $7.43 |\n| Feb 10 | 31 | $344.41 | 194 | 21,197,855 | $16.25 |\n| Feb 11 | 53 | $703.41 | 72 | 5,627,778 | $124.99 |\n| Feb 12 | 13 | $177.94 | 135 | 14,273,217 | $12.47 |\n| **Total** | **206** | **$2,413.25** | **3,732** | **388,671,815** | **$6.21** |\n\n**Key observations:**\n- **Feb 6-7**: 1,181 API calls and 127M tokens with **zero charges**. These correspond to my weekly limit reset ‚Äî the Max plan resets weekly usage limits, and these days fell within the refreshed quota.\n- **Feb 11**: Only 72 API calls and 5.6M tokens, but **$703 in charges (53 line items)**. This is clearly billing lag ‚Äî charges from earlier heavy usage days being processed later.\n- **The per-day $/M rate varies wildly** because charges don't align 1:1 with the day they were incurred. But the **overall rate converges to $6.21/M**.\n\n## What This Should Cost (Published API Rates)\n\nOpus 4.5/4.6 published pricing:\n\n| Token Type | Rate | My Tokens | Cost |\n|---|---|---|---|\n| Input | $5.00/M | 118,426 | $0.59 |\n| Output | $25.00/M | 159,410 | $3.99 |\n| Cache Write (5min) | $6.25/M | 20,009,158 | $125.06 |\n| Cache Read | $0.50/M | 367,212,919 | $183.61 |\n| **Total** | | | **$313.24** |\n\n## The Discrepancy\n\n| | Amount |\n|---|---|\n| Published API-rate cost | $313.24 |\n| Actual billed (206 charges) | $2,413.25 |\n| **Overcharge** | **$2,100.01 (670%)** |\n\n### Reverse-Engineering the Rate\n\nIf I divide total billed ($2,413.25) by total tokens (388.7M):\n\n**$2,413.25 √∑ 388.7M = $6.21 per million tokens**\n\n| Rate | $/M | What It Is |\n|---|---|---|\n| Published cache read | $0.50 | What the docs say cache reads cost |\n| Published cache write (5min) | $6.25 | What the docs say cache *creation* costs |\n| **What I was charged (overall)** | **$6.21** | Within 1% of cache creation rate |\n\nThe blended rate across all my tokens is $6.21/M ‚Äî **within 1% of the cache creation rate**.\n\n### Scenario Testing\n\nI tested multiple billing hypotheses against my actual charges:\n\n| Hypothesis | Calculated Cost | vs Actual $2,413 |\n|---|---|---|\n| Published differentiated rates | $313 | Off by $2,100 |\n| Cache reads at CREATE rate ($6.25/M) | $2,425 | Off by $12 (0.5%) |\n| All input-type tokens at $6.25/M | $2,425 | Off by $12 (0.5%) |\n| All input at 1hr cache rate + reads at create | $2,500 | Off by $87 (3.6%) |\n\n**Best match**: Billing all input-type tokens (input + cache creation + cache reads) at the 5-minute cache creation rate ($6.25/M). This produces $2,425 ‚Äî within 0.5% of my actual $2,413.\n\n## Alternative Explanations I Ruled Out\n\nBefore concluding this is a cache-read billing issue, I checked every other pricing multiplier that could explain the gap:\n\n1. **Long context pricing (>200K tokens = 2x rates)**: I checked every request in my JSONL files. The maximum input tokens on any single request was ~174K. Zero requests exceed the 200K threshold. Long context pricing does not apply.\n\n2. **Data residency pricing (1.1x for US-only inference)**: I'm not on a data residency plan, and data residency is an enterprise feature that doesn't apply to Max consumer plans.\n\n3. **Batch vs. real-time pricing**: All Claude Code usage is real-time (interactive). Batch API pricing (50% discount) is only for async batch jobs.\n\n4. **Model misidentification**: I verified all requests in JSONL are `claude-opus-4-5-*` or `claude-opus-4-6`. Opus 4.5/4.6 pricing is $5/$25/M (not the older Opus 4.0/4.1 at $15/$75/M).\n\n5. **Service tier**: Standard tier, no premium pricing applies.\n\nNone of these explain the gap. The only hypothesis that matches my actual billing within 0.5% is: **cache reads billed at the cache creation rate**.\n\n## What Anthropic's Own Docs Say\n\nAnthropic's [Max plan page](https://www.anthropic.com/pricing) states that extra usage is billed at **\"standard API rates\"**. The [API pricing page](https://docs.anthropic.com/en/docs/about-claude/models) lists differentiated rates for cache reads ($0.50/M for Opus) vs cache writes ($6.25/M).\n\nAnthropic's own Python SDK calculates costs using these differentiated rates. The [token counting cookbook](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching#tracking-cache-performance) explicitly shows cache reads as a separate, cheaper category.\n\nThere is **no published documentation** stating that extra usage billing treats cache reads differently from API billing. If it does, that's an undisclosed pricing change.\n\n## What This Means\n\nThe 90% cache read discount ($0.50/M vs $5.00/M input) is a core part of Anthropic's published pricing. It's what makes prompt caching economically attractive. But for Max plan extra usage, my data suggests **all input-type tokens are billed at approximately the same rate** ‚Äî the cache creation rate.\n\nSince cache reads are 95% of Claude Code's token volume, this effectively **multiplies the real cost by ~8x** compared to what published pricing would suggest.\n\n### My Total February Spend\n\nMy billing dashboard shows $2,505.51 in total extra usage charges for February (the $2,413.25 above is just the charges I could itemize from Feb 3-12 ‚Äî there are likely additional charges from Feb 1-2 and Feb 13+ not shown in my extract).\n\n## Charge Pattern\n\n- 205 of 206 charges are $10 or more\n- 69 charges fall in the $10.00-$10.50 range (the most common bucket)\n- Average charge: $11.71\n\n## Caveats\n\n1. **JSONL files only capture Claude Code usage**, not claude.ai web. I rarely use web, but some billing could be from there.\n2. **Billing lag exists** ‚Äî charges don't align 1:1 with the day usage occurred. The overall total is what matters, not per-day rates.\n3. **Weekly limit resets explain zero-charge days** ‚Äî Feb 6-7 had 127M tokens with zero charges because my weekly usage limit had just reset. The $2,413 is for usage that exceeded the weekly quota.\n4. **Anthropic hasn't published** how extra usage billing maps to token types. It's possible billing all input tokens uniformly is intentional policy, not a bug.\n5. **JSONL data is what Claude Code writes locally** ‚Äî I'm assuming it matches server-side records.\n\n## Questions for Anthropic\n\n1. **Are cache read tokens billed at $0.50/M or $6.25/M for extra usage?** The published pricing page shows $0.50/M, but my data shows ~$6.21/M.\n2. **Can the billing dashboard show per-token-type breakdowns?** Right now it just shows dollar amounts with no token detail.\n3. **Is the subscription quota consuming the cheap cache reads first, leaving expensive tokens for extra usage?** If quota credits are applied to cache reads at $0.50/M, that would use very few quota credits per read, pushing most reads into extra-usage territory.\n\n## Related Issues\n\n- [GitHub #22435](https://github.com/anthropics/claude-code/issues/22435) ‚Äî Inconsistent quota burn rates, opaque billing formula\n- [GitHub #24727](https://github.com/anthropics/claude-code/issues/24727) ‚Äî Max 20x user charged extra usage while dashboard showed 73% quota used\n- [GitHub #24335](https://github.com/anthropics/claude-code/issues/24335) ‚Äî Usage tracking discrepancies\n\n## How to Audit Your Own Usage\n\nI built [attnroute](https://github.com/jeranaias/attnroute), a Claude Code hook with a BurnRate plugin that scans your local JSONL files and computes exactly this kind of audit. Install it and run the billing audit:\n\n```bash\npip install attnroute\n```\n\n```python\nfrom attnroute.plugins.burnrate import BurnRatePlugin\n\nplugin = BurnRatePlugin()\naudit = plugin.get_billing_audit(days=14)\nprint(plugin.format_billing_audit(audit))\n```\n\nThis gives you a full breakdown: all four token types with percentages, cost at published API rates, a \"what if cache reads are billed at creation rate\" scenario, and a daily breakdown with cache read percentages. Compare the published-rate total against your billing dashboard ‚Äî if your dashboard charges are closer to the flat-rate scenario than the published-rate estimate, you're likely seeing the same issue.\n\nattnroute also does real-time rate limit tracking (5h sliding window with burn rate and ETA), per-project/per-model cost attribution, and full historical usage reports. It's the billing visibility that should be built into Claude Code.\n\n---\n\n**Edit**: I'm not claiming fraud. This could be an intentional billing model where all input tokens are treated uniformly, a system bug, or something I'm misunderstanding about how cache tiers work internally. But the published pricing creates a clear expectation that cache reads cost $0.50/M (90% cheaper than input), and Max plan users appear to be paying $6.25/M. Whether intentional or not, that's a **12.5x gap on 95% of your tokens** that needs to be explained publicly.\n\n**If you're a Max plan user with extra usage charges**, I'd recommend:\n1. Install [attnroute](https://github.com/jeranaias/attnroute) and run `get_billing_audit()` to audit your own token usage against published rates\n2. Contact Anthropic support with your findings ‚Äî reference that their docs say extra usage is billed at \"standard API rates\" which should include the $0.50/M cache read rate\n3. File a billing dispute if your numbers show the same pattern\n\n\n(Tip:Just have claude run the audit for you with attnroute burnrate plugin.)\n\n\n**UPDATE 2: v0.6.1 ‚Äî Full cache tier breakdown**\n\nSeveral commenters pointed out that 5-min and 1-hr cache writes have different rates ($6.25/M vs $10/M). Fair point ‚Äî I updated the audit tool to break these out individually. Here are my numbers with tier-aware pricing:\n\n| Token Type | Tokens | % of Total | Rate | Cost |\n|---|---|---|---|---|\n| Input | 118,593 | 0.03% | $5.00/M | $0.59 |\n| Output | 179,282 | 0.04% | $25.00/M | $4.48 |\n| Cache write (5m) | 14,564,479 | 3.64% | $6.25/M | $91.03 |\n| Cache write (1h) | 5,669,448 | 1.42% | $10.00/M | $56.69 |\n| **Cache reads** | **379,926,152** | **94.87%** | **$0.50/M** | **$189.96** |\n| **TOTAL** | **400,457,954** | | | **$342.76** |\n\nMy cache writes split 72% 5-min / 28% 1-hr. Even with the more expensive 1-hr write rate factored in, the published-rate total is **$342.76**.\n\n**The issue was never about write tiers.** Cache writes are 5% of my tokens. Cache *reads* are 95%. The question is simple: are those 380M cache read tokens being billed at $0.50/M (published rate) or ~$6.25/M (creation rate)? Because **$343 and $2,506 are very different numbers**, and my dashboard is a lot closer to the second one.\n\nUpdate your audit tool and verify yourself:\n\n```bash\npip install --upgrade attnroute\n```\n\n```python\nfrom attnroute.plugins.burnrate import BurnRatePlugin\np = BurnRatePlugin()\nprint(p.format_billing_audit(p.get_billing_audit()))\n```\n\nCompare your \"published rate\" number against your actual billing dashboard. That's the whole point.\n",
      "is_original_content": false,
      "link_flair_text": "Bug Report",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r3zbvt/max_20x_plan_i_audited_my_jsonl_files_against_my/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o580bpn",
          "author": "jcmguy96",
          "text": "I tried to quadruple check all of this before posting but if I am still jacked up, please correct me.",
          "score": 45,
          "created_utc": "2026-02-13 20:02:18",
          "is_submitter": true,
          "replies": [
            {
              "id": "o589my4",
              "author": "HopeSame3153",
              "text": "I ran your audit and it's not right. It's neither 404.02 or 3642.86. You need to account for the fact that there is a difference in cache types. \n\nhttps://preview.redd.it/moqfr0vzqbjg1.png?width=1917&format=png&auto=webp&s=685fa9e169a9be791f9d0378e8a653491b8eae2f\n\n",
              "score": 15,
              "created_utc": "2026-02-13 20:49:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o58arqf",
                  "author": "jcmguy96",
                  "text": "Hmm, will adjust and run again thank you!\n\n",
                  "score": 10,
                  "created_utc": "2026-02-13 20:54:47",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o58ckmd",
          "author": "tobsn",
          "text": "you‚Äôre on 20x and you generate $2k on extra charges? how? I can barely max out my normal limit ‚Äî honestly, what exactly are you doing?",
          "score": 19,
          "created_utc": "2026-02-13 21:03:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58e5eb",
              "author": "jcmguy96",
              "text": "I am dipping nuggets you have never heard of into sauces you couldn't comprehend.",
              "score": 88,
              "created_utc": "2026-02-13 21:11:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o58rc1r",
                  "author": "addiktion",
                  "text": "No AI slop detected here",
                  "score": 19,
                  "created_utc": "2026-02-13 22:16:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58npwk",
                  "author": "TheOriginalAcidtech",
                  "text": "I'm thankful I don't know about your nuggets... :)",
                  "score": 7,
                  "created_utc": "2026-02-13 21:58:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58nh1p",
                  "author": "pilotthrow",
                  "text": "Why not get another max20 that would probably get rid of all the extra cost",
                  "score": 6,
                  "created_utc": "2026-02-13 21:57:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58whx9",
                  "author": "Denolien_",
                  "text": "Melted crayon",
                  "score": 3,
                  "created_utc": "2026-02-13 22:44:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o596wg8",
                  "author": "tobsn",
                  "text": "that is the dumbest answer I should‚Äôve expected.",
                  "score": 7,
                  "created_utc": "2026-02-13 23:44:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58fy1k",
                  "author": "Kitchen_Interview371",
                  "text": "Hahaha",
                  "score": 2,
                  "created_utc": "2026-02-13 21:20:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58l8ph",
                  "author": "Sketaverse",
                  "text": "Haha what a reply ü´°",
                  "score": 2,
                  "created_utc": "2026-02-13 21:46:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58n8ky",
                  "author": "semmy_t",
                  "text": "it took me a good 20 seconds to comprehend as a not native speaker.  \na nice one!",
                  "score": 2,
                  "created_utc": "2026-02-13 21:56:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58rt9e",
                  "author": "Better-Cause-8348",
                  "text": "Well now I gotta know.",
                  "score": 2,
                  "created_utc": "2026-02-13 22:19:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58l22w",
                  "author": "Southern-Round4731",
                  "text": "That‚Äôs gold",
                  "score": 1,
                  "created_utc": "2026-02-13 21:45:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o58o1od",
              "author": "xFloaty",
              "text": "Have you used agent teams?",
              "score": 2,
              "created_utc": "2026-02-13 22:00:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o596pgb",
                  "author": "tobsn",
                  "text": "yes, I use agents ‚Äî how many does he use lol\n\neven if the answer is plenty agents ‚Äî what are they doing?",
                  "score": -1,
                  "created_utc": "2026-02-13 23:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o584tny",
          "author": "HopeSame3153",
          "text": "There is 1 hr cache and 5 min cache. Everything has gone to 1 hr since the update to CC version last week. 1 hr cache is billed at 6.25 per M and 5 min cache is billed at .50 per M. ",
          "score": 12,
          "created_utc": "2026-02-13 20:24:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58mffp",
              "author": "Ok-Support-2385",
              "text": "Cache hits are 0.5/MTok for either 1h or 5m: https://platform.claude.com/docs/en/build-with-claude/prompt-caching\n\nAlso, 1h is billed at 10/MTok for writes and 5m is billed at 6.25/MTok for writes.",
              "score": 8,
              "created_utc": "2026-02-13 21:52:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o58u9f0",
          "author": "sintmk",
          "text": "Doing the Lord's work out here. This is solid. Even if some refinement is necessary to your model, the logic and premise is solid. Thank you",
          "score": 5,
          "created_utc": "2026-02-13 22:32:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58z7oq",
              "author": "Kitae",
              "text": "Agree happy you did the analysis and shared!",
              "score": 2,
              "created_utc": "2026-02-13 22:59:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o58wwp2",
          "author": "nicetohave99",
          "text": "Thats a lot of text, but did you get billed more than the 200$ max plan?",
          "score": 5,
          "created_utc": "2026-02-13 22:46:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o594ks1",
              "author": "TheOriginalAcidtech",
              "text": "He is talking about what he got billed AFTER using up his plan and when it went to API billing(extra usage).",
              "score": 3,
              "created_utc": "2026-02-13 23:30:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o59aoil",
                  "author": "jcmguy96",
                  "text": "![gif](giphy|TPJAvvWbSN61O)\n\n",
                  "score": 2,
                  "created_utc": "2026-02-14 00:07:12",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o59gm86",
          "author": "Specialist-Claim-537",
          "text": "Have you considered the cache is timing out, causing you to have the rewrite to cache constantly? This was happening to my Openclaw until I identified the issue.",
          "score": 1,
          "created_utc": "2026-02-14 00:42:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59hagd",
              "author": "jcmguy96",
              "text": "The JSONL data already accounts for this. Every single API response records exactly how many tokens were cache\\_creation\\_input\\_tokens vs cache\\_read\\_input\\_tokens ‚Äî so if cache were timing out and causing constant rewrites, I'd see it as a higher cache write percentage. My data shows 6% writes and 94% reads across 691M tokens. The cache is clearly hitting, not expiring. The question isn't whether cache is working ‚Äî it is ‚Äî it's whether the reads are being billed at the read rate.",
              "score": 2,
              "created_utc": "2026-02-14 00:46:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o59vxmv",
                  "author": "Specialist-Claim-537",
                  "text": "Obvious Insights\n\nFeb 6 and Feb 7 stand out immediately: massive API activity (936 and 245 calls, ~127M tokens combined) with zero charges. That‚Äôs roughly a third of your total token volume running for free, which points to batch API credits, a free tier, cached responses, or a billing anomaly worth investigating.\n\nFeb 11 is the most expensive single day at $703.41, and it‚Äôs also the day with the fewest API calls (72) and fewest tokens (5.6M). That yields an extraordinary cost of ~$125 per million tokens, which is roughly 17√ó the corrected average.\nOverall spending is volatile ‚Äî you swing from $0 to $703 across the ten days with no clear upward or downward trend.\n\nNon-Obvious Insights\n\n‚ÄúCharges‚Äù and ‚ÄúAPI Calls‚Äù measure very different things, and their disconnect tells a story. Feb 6 made 936 API calls but generated 0 charges; Feb 11 made only 72 API calls but generated 53 charges. This likely means you‚Äôre mixing different products, models, or pricing tiers ‚Äî and ‚ÄúCharges‚Äù represents discrete billable line items, not a 1:1 mapping to requests.\n\nFeb 11‚Äôs $125/M rate isn‚Äôt just expensive ‚Äî it signals a fundamentally different workload. At standard Anthropic API pricing, even the most expensive model (Opus-class output tokens) wouldn‚Äôt easily reach $125/M in a blended rate unless you had an extremely output-heavy workload, were using a premium service like fine-tuning, image generation, or were hitting some other premium pricing tier. It‚Äôs worth auditing what specifically ran that day.\n\nFeb 5 through Feb 7 form a suspicious cluster. Token volumes spike dramatically (54M ‚Üí 99M ‚Üí 27M) while cost collapses ($96 ‚Üí $0 ‚Üí $0). This pattern is consistent with a batch job or evaluation run that exhausted a credit balance partway through Feb 5, ran on free credits through Feb 6‚Äì7, and then resumed paid billing on Feb 8. Alternatively, something shifted in your pricing arrangement during that window.\n\nYour cost efficiency has a bimodal distribution, not a normal one. You essentially have ‚Äúcheap‚Äù days ($1.77‚Äì$7.55/M) and ‚Äúexpensive‚Äù days ($12‚Äì$125/M), with very little in between. This suggests two distinct usage modes ‚Äî possibly high-volume batch processing with smaller/cached models on cheap days, and low-volume interactive or premium-model usage on expensive days. Understanding which mode drives value for you could meaningfully reduce your bill.\n\nWeekend vs. weekday patterns are suggestive. Feb 8‚Äì9 (Saturday‚ÄìSunday) saw high activity and moderate cost, while the surrounding weekdays are more erratic. If automated jobs run on a schedule, the weekend consistency vs. weekday volatility might indicate that human-initiated usage (weekdays) is what‚Äôs driving cost unpredictability.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
                  "score": 1,
                  "created_utc": "2026-02-14 02:19:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5a4z1s",
          "author": "Srijaa",
          "text": "What were you building on feb 6th?!? 936 api calls and 100 million tokens in a day is crazy usage!",
          "score": 1,
          "created_utc": "2026-02-14 03:17:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a7gm2",
              "author": "jcmguy96",
              "text": "One marathon Claude Code session that ran from 1:30 AM to 11:38 PM ‚Äî 22 hours straight. Building something from scratch (\"okay, ready to start building?\" was the first message). 2,018 API calls on the main thread plus 665 subagent calls doing parallel research and code generation across Opus, Sonnet, and Haiku. Then in the evening I spun up a second project (ExpertDrivenDevelopment) and ran another 1,300 calls on that simultaneously for about 4 hours. 250M tokens on project one, 92M on project two. Just a regular Thursday.",
              "score": 2,
              "created_utc": "2026-02-14 03:35:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ae0ny",
                  "author": "Shakalaka-bum-bum",
                  "text": "Share your workflow, how did you oneshot those things and ran claude code for 22 hours, max i got is 3 hours ü´£",
                  "score": 1,
                  "created_utc": "2026-02-14 04:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5a8sws",
          "author": "AkiDenim",
          "text": "Honestly this may depend on what plugin you use. Any kind of message injection / message list manipulation invalidates cache in the Max sub.\n\nIf there is any plugin that does that, do remove it. If you‚Äôre using the sub not only in CC but in other harnesses like OC, double check for any message injection or manipulation.",
          "score": 1,
          "created_utc": "2026-02-14 03:44:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aggf0",
              "author": "jcmguy96",
              "text": "I'm not using any plugins that inject into the message list ‚Äî my only hook is attnroute's BurnRate plugin which is a PostToolUse notification hook that tracks token usage from the response. It reads the usage data after the API call, it doesn't modify the prompt or message list. No message injection, no manipulation.\n\nAnd even if something were invalidating cache, that would show up as a higher cache write percentage in the JSONL data. My data shows 6% writes and 94% reads ‚Äî the cache is clearly hitting. The issue isn't cache invalidation, it's what rate those reads are billed at.",
              "score": 1,
              "created_utc": "2026-02-14 04:39:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5arelo",
          "author": "ultrathink-art",
          "text": "The billing discrepancy you're seeing is likely the difference between token counting methods. The CLI uses tiktoken locally (same as API), but the dashboard aggregates from server-side logs which may round differently or include system prompts.\n\nFor accurate tracking: export your JSONL with `claude export`, then run `jq '.[] | .input_tokens + .output_tokens' < export.jsonl | awk '{s+=$1} END {print s}'` to get exact totals. Compare against your dashboard's raw token count (not the cost estimate).\n\nAlso check if you're hitting the context caching layer ‚Äî cached tokens show as reduced cost but full input tokens in the JSONL. That could explain a 20x perceived difference if most of your sessions are cache hits.",
          "score": 1,
          "created_utc": "2026-02-14 06:07:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ass99",
              "author": "jcmguy96",
              "text": "Hmm, where did you get this info, brother?\n\nFew corrections:\n\n\n\n  1. The JSONL token counts aren't from tiktoken or any local counting. They come directly from the API response usage object ‚Äî these are server-side counts returned by Anthropic's API. There's no client-side counting happening. What my JSONL records is what the server reported.\n\n  2. That jq command would miss 99% of the tokens. input\\_tokens + output\\_tokens ignores cache\\_creation\\_input\\_tokens and cache\\_read\\_input\\_tokens, which together are 99.6% of all tokens in Claude Code. That's the whole point of the post.\n\n  3. \"Cached tokens show as reduced cost but full input tokens in the JSONL\" is backwards. The JSONL explicitly separates them into distinct fields: input\\_tokens, cache\\_creation\\_input\\_tokens, and cache\\_read\\_input\\_tokens. They don't get lumped together. My audit reads all four token type fields separately and applies the published rate for each. Cache reads are clearly labeled as cache reads ‚Äî the question is whether they're billed at $0.50/M as published or $6.25/M as my dashboard suggests.\n\n\n\n  claude export isn't a command, either.",
              "score": 1,
              "created_utc": "2026-02-14 06:20:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b7jqr",
          "author": "privacyguy123",
          "text": "Thanks for looking into this - I am seeing the same thing and you saved me some time on researching. I believe my account also suffers from this bug but not everybodys does. Did you get an official response? How could I \"flag\" my account for this bug also?",
          "score": 1,
          "created_utc": "2026-02-14 08:38:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o596eh9",
          "author": "iam_maxinne",
          "text": "Maybe this has something to do with chat sessions? I don‚Äôt know how it works, does cache persist across sessions? ü§î",
          "score": 1,
          "created_utc": "2026-02-13 23:41:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59aaej",
              "author": "jcmguy96",
              "text": "Great question! Cache doesn't persist across sessions ‚Äî it resets each time. The reason cache reads are so high is because of how Claude Code works within a single conversation: every time you send a message, it re-sends your entire conversation history and system context to the API. On the second turn and beyond, most of that is already in cache from the previous turn, so it gets served as a cache read instead of a fresh input. By the time you're 20+ turns into a session, 95%+ of every request is cache reads. That's actually the system working as intended ‚Äî the problem is whether those reads are being billed at $0.50/M (as published) or $6.25/M (as my data suggests).",
              "score": 1,
              "created_utc": "2026-02-14 00:04:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o59enps",
                  "author": "iam_maxinne",
                  "text": "And your workload is more like single session with long conversations, or a lot of sessions with short conversation? The former would work great with the way you described, while the latter would result in heavy cache writing, I guess‚Ä¶.\n\nAnother point worth investigating may be context manipulation, variable data, compaction, etc‚Ä¶ as all those could result in cache being invalid‚Ä¶",
                  "score": 1,
                  "created_utc": "2026-02-14 00:30:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5atba4",
          "author": "Accomplished_Row4343",
          "text": "Long post.",
          "score": 0,
          "created_utc": "2026-02-14 06:24:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5atves",
              "author": "jcmguy96",
              "text": "![gif](giphy|2jOcXFwhIEypPeQvOY)\n\n",
              "score": 3,
              "created_utc": "2026-02-14 06:29:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o59y5rp",
          "author": "akumaburn",
          "text": "Not trying to pry but genuinely curious why you don't simply get multiple max plans/accounts?",
          "score": -1,
          "created_utc": "2026-02-14 02:33:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a2u2q",
              "author": "dern_throw_away",
              "text": "Thats against the rules.\n\n",
              "score": 2,
              "created_utc": "2026-02-14 03:03:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5a9a0p",
          "author": "No-Brush5909",
          "text": "Cache works only for 5 minutes",
          "score": -1,
          "created_utc": "2026-02-14 03:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ac0ms",
              "author": "jcmguy96",
              "text": "![gif](giphy|U8WkP83KzUPBxF8K0o)\n\n",
              "score": 3,
              "created_utc": "2026-02-14 04:06:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qzmofn",
      "title": "How Claude Code Auto-Memory works (official feature added in 2.1.32)",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qzmofn/how_claude_code_automemory_works_official_feature/",
      "author": "jeremynsl",
      "created_utc": "2026-02-08 22:17:34",
      "score": 138,
      "num_comments": 31,
      "upvote_ratio": 0.97,
      "text": "It seems a more complex memory system was recently added to Claude Code.  Right now there are very few docs about it.   A bit of info on this page.  \n[https://code.claude.com/docs/en/memory#manage-auto-memory](https://code.claude.com/docs/en/memory#manage-auto-memory)\n\nI asked Claude about it after I saw it writing to memory and got the response below.  My takeaways:\n* You may want to inspect these project-specific memories.  If something odd is saved in there, it could cause unexpected behaviour - and your CLAUDE.md would look normal and fine.\n* There is a 200-line limit per project for this auto-memory\n* You can turn off auto-memory as well. CLAUDE_CODE_DISABLE_AUTO_MEMORY=1\n\n\n\n> ## üõ†Ô∏è Project Documentation vs. üß† AI Auto-Memory\n>\n> ### **CLAUDE.md** *(Project Root)*\n>\n> **Your instructions to me.**\n>\n> * **Source Control:** Checked into Git and shared with your entire team.\n> * **Ownership:** **You** write and own it. I only update it when specifically asked.\n> * **Content:** Project architecture, coding conventions, test commands, and \"do/don't\" rules.\n> * **Analogy:** Think of this as the **onboarding manual** for a new developer.\n>\n> ### **MEMORY.md** *(~/.claude/projects/.../memory/)*\n>\n> **My notes to my future self.**\n>\n> * **Source Control:** **NOT** in Git; local to your machine and persists across conversations.\n> * **Ownership:** **I** write and own it. I update it proactively as I learn your project's quirks.\n> * **Content:** Debugging lessons, specific \"gotchas,\" patterns that failed, and internal logic flow.\n> * **Analogy:** Think of this as a developer's **personal scratchpad** or \"til\" (today I learned) log.\n>\n> ---\n>\n> ### **Quick Comparison: When to use which?**\n>\n> | Feature | CLAUDE.md | Auto-memory (MEMORY.md) |\n> | --- | --- | --- |\n> | **Who writes it** | You (or me when asked) | Me, proactively |\n> | **In Git?** | **Yes** | **No** |\n> | **Purpose** | Project truth & instructions | Operational knowledge & \"gotchas\" |\n> | **Example** | `\"Run tests with pytest tests/\"` | `\"Logic check A must happen before B or Test X fails.\"` |\n>\n> ---\n>\n> ### **The Bottom Line**\n>\n> The **auto-memory** is the newer, sharper pattern. It lets me remember that \"one weird trick\" needed to make your build pass without cluttering your professional project documentation with my internal \"aha!\" moments.\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qzmofn/how_claude_code_automemory_works_official_feature/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o4bxnr0",
          "author": "Ok-Experience9774",
          "text": "This just automated what some people have been doing for awhile.\n\nImplement task X, keep notes in [JOURNAL.md](http://JOURNAL.md) of problems, conclusions, questions, what the plan is, and tick off tasks as you finish them. You can and should add to your journal on things you fix. If you find something that needs fixing but isn't part of your assignment, note it in your journal and continue with your assignment.\n\n",
          "score": 38,
          "created_utc": "2026-02-08 22:28:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c0p2r",
              "author": "jeremynsl",
              "text": "Yup.  I like the way they have implemented this so far.  It's simple and everyone can benefit regardless if they are doing advanced prompting.  I can see this becoming more advanced in the future.  The obvious next step is some kind of auto-memory that lives outside the project folder - learnings between projects.",
              "score": 9,
              "created_utc": "2026-02-08 22:45:03",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4c3lg4",
              "author": "Obvious_Equivalent_1",
              "text": ">¬†This just automated what some people have been doing for awhile.\n\nIt‚Äôs relentless. Honestly Antrophic team out there deprecating community plugins with native implementations faster then you can attempt to smile and say cheese for the photo",
              "score": 14,
              "created_utc": "2026-02-08 23:01:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4d8xpp",
              "author": "taylorwilsdon",
              "text": "[Beads](https://github.com/steveyegge/beads) is worth a look if you are using multiple dev tools or want parallel orchestration. It‚Äôs memory and project tracking with a dependency-aware graph instead of markdown docs.",
              "score": 3,
              "created_utc": "2026-02-09 02:51:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4dd99j",
                  "author": "jeremynsl",
                  "text": "The new Tasks in Claude code were inspired by beads.",
                  "score": 4,
                  "created_utc": "2026-02-09 03:14:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4dzs4n",
              "author": "Illustrious-Day-4199",
              "text": "I overdid it and added a task view to my project build info, coupled them to sprints (thanks management) and then used them to log burndown progress and create better default prompts for claude when kicking off the tasks. Then I built repo commit hooks to monitor all the stats and add anything not covered by my task list into the backlog as work that's already time-windowed and done.\n\nFor the last day I've mostly been typing \"keep going\" into the chat window.",
              "score": 2,
              "created_utc": "2026-02-09 05:46:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4c552m",
          "author": "cleverhoods",
          "text": "Make sure to recheck the memory every now and then, conflicting instructions can populate there.  \nAlso, memory can go stale if you have a context collapse (running out of context window mid agent operation).",
          "score": 14,
          "created_utc": "2026-02-08 23:10:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4cyke1",
          "author": "HaagNDaazer",
          "text": "This is really interesting! I personally store all my plan files as Linear issues, and when Claude figures something out, I ask it to store it in the linear issue as a comment for future Claude to reference. Also the plans in there contain a user decision section from the planning phase . Then when working on the next task the planning phase goes and finds relevant linear issues to find historical context and important factoids",
          "score": 5,
          "created_utc": "2026-02-09 01:58:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4e2vdx",
              "author": "Murkwan",
              "text": "This is my workflow. I've setup a host of skills to allow claude to use Linear as a project manager + memory bank where all the plans, implementation logs, bugs and updates go. It's been working very well for me.",
              "score": 1,
              "created_utc": "2026-02-09 06:11:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4f5a3u",
                  "author": "HaagNDaazer",
                  "text": "The extra piece I use is a local RAG vector index of my project so Claude can trace through the whole project super accurately",
                  "score": 2,
                  "created_utc": "2026-02-09 12:08:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ccwd1",
          "author": "Bellman_",
          "text": "i've been using automemory too - it's pretty solid for capturing context you'd otherwise lose. the 200 line limit is a bit tight but forces you to be concise i guess",
          "score": 3,
          "created_utc": "2026-02-08 23:56:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4e7dkl",
          "author": "Maasu",
          "text": "I've disabled it as I wrote my own memory mcp and I like to control what goes into it with commands. \n\nVery good advice on check these project ones if Claude is automating what goes in there.",
          "score": 3,
          "created_utc": "2026-02-09 06:50:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4c9fng",
          "author": "FourthmasWish",
          "text": "I turned MEMORY.md into a live rules index at the top with Top of Mind (five most salient observations from the session) and Critical Patterns (patterns that are not yet rules) underneath, and it only touches those lower sections when updating it. Working quite well so far even across several repos. Do remember to keep it under 200 lines as I think it truncates past that.",
          "score": 2,
          "created_utc": "2026-02-08 23:35:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4drbzb",
          "author": "gh0st777",
          "text": "Finally, I was managing this myself, now i just need to migrate the kb I built up onto the official \"memory\"",
          "score": 2,
          "created_utc": "2026-02-09 04:43:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4e61ei",
          "author": "dimakp",
          "text": "so we dont need claude-mem?",
          "score": 2,
          "created_utc": "2026-02-09 06:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4epaxm",
          "author": "hollowgram",
          "text": "Hmm should I remove claude-mem then. Not sure it did much in practice.¬†",
          "score": 2,
          "created_utc": "2026-02-09 09:43:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4c8yuo",
          "author": "lundrog",
          "text": "Interesting",
          "score": 1,
          "created_utc": "2026-02-08 23:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4e3tll",
          "author": "jordi-zaragoza",
          "text": "Interesting feature. The auto-memory is good for preferences and patterns, but it doesn't solve the structural understanding problem - Claude still doesn't persistently know which files depend on which.\n\nFor example, if you refactor a function signature, Claude needs to know every file that calls that function. Auto-memory won't capture those import/dependency relationships because they change with every code edit.",
          "score": 1,
          "created_utc": "2026-02-09 06:19:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4e58ns",
              "author": "jeremynsl",
              "text": "Do you see value in maintaining a persistent memory of those relationships?  Nowadays Claude would search for the function name across your code base and stretch out from there anything else it feels it should know based on that.",
              "score": 1,
              "created_utc": "2026-02-09 06:31:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4e882d",
                  "author": "jordi-zaragoza",
                  "text": "Yeah I do.. searching works but it's reactive and costs tokens every time. If Claude already knows that auth.js is imported by 12 files, it can plan a refactor upfront instead of  discovering callers one by one mid-edit. It's the difference between having a map vs asking for directions at every corner. Both get you there, but one is way more efficient. That said, for small projects it probably doesn't matter. It's the 50+ file projects where the repeated exploration really adds up.",
                  "score": 2,
                  "created_utc": "2026-02-09 06:57:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4es0j0",
          "author": "jordi-zaragoza",
          "text": "Great breakdown. Auto-memory is solid for capturing preferences and patterns, but there's a gap: it doesn't track structural relationships between files.",
          "score": 1,
          "created_utc": "2026-02-09 10:10:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kls6u",
          "author": "JuiceBoxJonny",
          "text": "This is the most assinign attempt ive seen at memory for an llm - TRY THIS INSTEAD\n\n[https://github.com/jonhardwick-spec/specmem](https://github.com/jonhardwick-spec/specmem)",
          "score": 1,
          "created_utc": "2026-02-10 06:20:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ijdxf",
          "author": "No-Replacement-2631",
          "text": "That docs page and this post show why LLMs are so shit at writing. ",
          "score": 0,
          "created_utc": "2026-02-09 22:39:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ijrg6",
          "author": "No-Replacement-2631",
          "text": "Also, the only way to disable it is through a fucking env var?? Vibe coded slop (the model and the vibe coder likely forgot there's a config file that the program reads).",
          "score": 0,
          "created_utc": "2026-02-09 22:41:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ci0ah",
          "author": "Competitive_Act4656",
          "text": "Balancing multiple projects can get overwhelming, especially when deadlines overlap like that. I‚Äôve had similar struggles, and I found that using myNeutron really helped me keep track of everything. It‚Äôs made prioritizing tasks a lot easier for me, and I can see what needs my attention first without getting lost in the details.",
          "score": -7,
          "created_utc": "2026-02-09 00:25:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r255kz",
      "title": "Turning claude thinking time into productive microtasks",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/gallery/1r255kz",
      "author": "ItsSoFetch",
      "created_utc": "2026-02-11 18:21:49",
      "score": 138,
      "num_comments": 39,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Showcase",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1r255kz/turning_claude_thinking_time_into_productive/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4ueneo",
          "author": "Tomas1337",
          "text": "I actually love this. How do i get it?\n\nI'd add like some quick math problems or weird recipe ingredient combinations.",
          "score": 10,
          "created_utc": "2026-02-11 18:37:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ulupf",
              "author": "ItsSoFetch",
              "text": "It's the most beta something can be, but i'll wipe a bit of cruft off of it and throw it up on GH. \n\nMath problems would be fun! What are you thinking re: recipe ingredients?",
              "score": 7,
              "created_utc": "2026-02-11 19:10:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4yu79l",
                  "author": "daliovic",
                  "text": "Please let me know once published.",
                  "score": 1,
                  "created_utc": "2026-02-12 12:03:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zki3q",
                  "author": "iamthesam2",
                  "text": "this is the way",
                  "score": 1,
                  "created_utc": "2026-02-12 14:42:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o50tlob",
                  "author": "Unusual_Manager",
                  "text": "Breakfast(s) and cocktails\n\nSimple Crapes:\n- 1 egg\n- 1 cup flower\n- 300ml milk",
                  "score": 1,
                  "created_utc": "2026-02-12 18:16:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o578gmy",
              "author": "ItsSoFetch",
              "text": "I tidied things up a bit- here's the repo! [https://github.com/mdgale/microtasks](https://github.com/mdgale/microtasks)",
              "score": 1,
              "created_utc": "2026-02-13 17:47:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uokqe",
          "author": "Sea-Sir-2985",
          "text": "this is actually genius... the dead time while claude thinks is a real productivity killer because it's just long enough to pick up your phone but too short to do anything meaningful\n\nthe typing exercise one is perfect since you're already in the terminal mindset. i'd add a quick code review task where it shows you a small snippet and you spot the bug, that way you're staying in coding mode while waiting. or even flash cards for keyboard shortcuts you keep forgetting\n\nthe hooks integration is the clever part here, having it trigger automatically means you don't have to remember to start a task yourself. does it detect when claude finishes and pull you back automatically or do you have to dismiss the task manually?",
          "score": 9,
          "created_utc": "2026-02-11 19:23:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4urdpl",
              "author": "ItsSoFetch",
              "text": "re: detect when claude finishes\n\nIt doesn't right now, but it can. IMO some tasks lend themselves more to being preempted than others- but it'd be nice to be able to set that preemption per task (e.g. premepting a typing exercise might lead to unwanted characters making it into your claude input)",
              "score": 2,
              "created_utc": "2026-02-11 19:37:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w77pd",
          "author": "tribat",
          "text": "This is a good idea. I end up spawning new sessions and getting lost among them while waiting. If CC would offer up things I've marked as \"to consider later\" I could be in plan mode in another session while CC works. ",
          "score": 5,
          "created_utc": "2026-02-11 23:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wk9i6",
          "author": "nausticus",
          "text": "Maybe Anki flashcards for language learners?\nOr subway surfers video for the memes",
          "score": 4,
          "created_utc": "2026-02-12 01:13:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zr9r8",
              "author": "Hopeful-Ear-4583",
              "text": "Anki was my first thought here too",
              "score": 1,
              "created_utc": "2026-02-12 15:16:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4x3su8",
          "author": "checkwithanthony",
          "text": "this is cool. i have an idea - what if you instruct your claude (via the main project md file) to make a microtask md file and continually add small decisions that need to be made or clarified on to like solve a problem or improve on claudes understanding of the project.. then those get served up and updated via this microtask thing.\n\ni've read that telling ai why (as in just providing more context) helps, and so maybe letting it come up with all of the details it would like to know why about then serving them up to us in these little 'organize this' or 'select this' type popups would be help us with focus and the AI to better understand what it's doing.",
          "score": 5,
          "created_utc": "2026-02-12 03:11:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4x5x98",
              "author": "ItsSoFetch",
              "text": "Now that‚Äôs an idea! Super interesting",
              "score": 1,
              "created_utc": "2026-02-12 03:25:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w5z3p",
          "author": "wakawaka54",
          "text": "Most of this is also a waste of time. BUT I think you might be onto something. I could see this being useful if you as Claude or Haiku to generate a bunch of YES NO SKIP questions about your project and while you are waiting, you can answer those and then they can be processed by Claude later and integrated into your project docs, epics, etc. Basically farm you, the user lol.",
          "score": 3,
          "created_utc": "2026-02-11 23:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uf4mc",
          "author": "hheadshott",
          "text": "This is hilarious! Absolutely love the idea:)  \n\\+ idea: add quick flashcards to learn new words (learning new language or studying new theme)\n\nIs there a github repo to try it?",
          "score": 2,
          "created_utc": "2026-02-11 18:39:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ulei4",
              "author": "ItsSoFetch",
              "text": "ohh I like flashcards! I had thought of doing some language learning word-of-the-day, and this definitely fits with that!\n\n  \nIt's the most beta it could possibly be right now lol, but I'll get it up on github",
              "score": 1,
              "created_utc": "2026-02-11 19:08:42",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4uo68o",
              "author": "Tomas1337",
              "text": "Up on the learning a language theme\n\n",
              "score": 1,
              "created_utc": "2026-02-11 19:21:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uqh82",
          "author": "ItsSoFetch",
          "text": "The technical details: \n\nthe claude hook is just a curl to the server (fastapi) that decides which task should be presented to the user in the form of a url and the dimensions of the window that should be opened.\n\nThe client side is the most hairy part. The response from the server is just a url, so right now I invoke python directly to pop up a webview. I started by using chrome to show the task, but this creates a bunch of application focus problems; like if you close the task window, any other chromes you have open inherit focus, so you end up flipping between windows constantly which is really irritating. Running a python instance gives you way more flexibility with things like dismissing the task or autoclosing it on completion, but i think the final form will be a tauri or electrion app that lives in your tray- I think that'll make setup easier and provide the most reliable api for creating flexible tasks.",
          "score": 2,
          "created_utc": "2026-02-11 19:32:43",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o4ujtpo",
          "author": "Devnik",
          "text": "Share more technical background!",
          "score": 1,
          "created_utc": "2026-02-11 19:01:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ulvhz",
              "author": "ItsSoFetch",
              "text": "on it!\n\nEDIT: posted the tech details",
              "score": 1,
              "created_utc": "2026-02-11 19:10:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ul7ra",
          "author": "DesignedByPrinciple",
          "text": "neuTTS-Air + a list of words to spell\n\nMaybe it just reads a single word and you have to type it. Accuracy + speed = score (with accuracy being 70-80% of the score). I'd love to have less red squiggles.",
          "score": 1,
          "created_utc": "2026-02-11 19:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uqurt",
          "author": "gamestopfan",
          "text": "Add a Ken Ken puzzle to solve. ",
          "score": 1,
          "created_utc": "2026-02-11 19:34:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vw78y",
          "author": "SpiritedSilicon",
          "text": "hahah that's so fun!",
          "score": 1,
          "created_utc": "2026-02-11 22:56:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w9r25",
          "author": "SmallKiwi",
          "text": "I struggle to remember the names and meanings of Greek letters in research, I need to make a little study guide micro app like your typing example, actually a great idea. ",
          "score": 1,
          "created_utc": "2026-02-12 00:11:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xzio7",
          "author": "Iggy404",
          "text": "That's exactly why I run two, sometimes three CC sessions simultaneously for different projects (or sometimes same project but different parts if I'm confident they don't mess with each others files). No time to get distracted! üòÖ",
          "score": 1,
          "created_utc": "2026-02-12 07:16:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ylfdx",
          "author": "Acceptable_Area7329",
          "text": "pretty cool !  \nThe issue sorting thing hit me like a truck, that's brilliant to have simple sorting / qualifying brought to you when idling.  \nSometimes the terminal tab context switch fatigue hits and I just stare at claude crunching. I'll definitely borrow the idea",
          "score": 1,
          "created_utc": "2026-02-12 10:49:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zvc0s",
          "author": "kgoncharuk",
          "text": "running a couple of simultaneous sessions is also quite productive -- while one is thinking you reply to another.",
          "score": 1,
          "created_utc": "2026-02-12 15:36:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o504by6",
              "author": "ItsSoFetch",
              "text": "I struggle to context switch in situations like this. If I know claude is off doing something big, it feels more worth it to pay the context switch cost, but I find it hard to drive more than claude at once when the request/response is <10 seconds",
              "score": 1,
              "created_utc": "2026-02-12 16:18:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55n2x6",
                  "author": "kgoncharuk",
                  "text": "for quick responses that's true, but Opus 4.6 is a slow thinker, it can easily take minutes. Feels like a waste of time to do some random stuff meanwhile.",
                  "score": 1,
                  "created_utc": "2026-02-13 12:57:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50456n",
          "author": "gaieges",
          "text": "This has to be one of the coolest new dev innovations we've seen in recent history.  It's so relevant and useful.  Love it!",
          "score": 1,
          "created_utc": "2026-02-12 16:17:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51tgun",
          "author": "cowwoc",
          "text": "This is a great signal of everything that is wrong with AI development in its current form :)\n\nIt's a nice idea, but is only needed because the annoying stop-go nature of the current AI development model.",
          "score": 1,
          "created_utc": "2026-02-12 21:06:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4umtxq",
          "author": "Nick_Yawn",
          "text": "You ever start to feel like Claude Code is running you, and not the other way around?",
          "score": 1,
          "created_utc": "2026-02-11 19:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uur8e",
              "author": "BadAtDrinking",
              "text": "please run me claude code",
              "score": 4,
              "created_utc": "2026-02-11 19:53:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zr5u1",
          "author": "stampeding_salmon",
          "text": "Have you tried instead, using that time for thinking?",
          "score": 1,
          "created_utc": "2026-02-12 15:16:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zrb9v",
              "author": "ItsSoFetch",
              "text": "Being alone in my own thoughts?\n\new",
              "score": 2,
              "created_utc": "2026-02-12 15:16:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o504w8i",
              "author": "gaieges",
              "text": "You're no fun",
              "score": 1,
              "created_utc": "2026-02-12 16:20:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}