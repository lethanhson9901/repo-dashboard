{
  "metadata": {
    "last_updated": "2026-01-22 02:32:43",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 76,
    "file_size_bytes": 103906
  },
  "items": [
    {
      "id": "1qfkeuf",
      "title": "We tested Vector RAG on a real production codebase (~1,300 files), and it didn‚Äôt work",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfkeuf/we_tested_vector_rag_on_a_real_production/",
      "author": "Julianna_Faddy",
      "created_utc": "2026-01-17 18:12:58",
      "score": 54,
      "num_comments": 19,
      "upvote_ratio": 0.85,
      "text": "Vector RAG has become the default pattern for coding agents: embed the code, store it in a vector DB, retrieve top-k chunks that it feels obvious to do so.\n\nWe tested this on a real production codebase (\\~1,300 files) and it mostly‚Ä¶ didn‚Äôt work.\n\nThe issue isn‚Äôt embeddings or models but we realized that **similarity is a bad proxy for relevance in code**.\n\nIn practice, vector RAG kept pulling:\n\n* test files instead of implementations\n* deprecated backups alongside the current code\n* unrelated files that just happened to share keywords\n\nSo the agent‚Äôs context window filled up with noise and reasoning got worse.\n\nhttps://preview.redd.it/39j5yotaaydg1.png?width=1430&format=png&auto=webp&s=7fd32a52a167a6b6f16e565874a2c5baab4ddc93\n\nWe compared this against an **agentic search approach using context tree** (structured, intent-aware navigation instead of similarity search). We won‚Äôt dump all the numbers here, but a few highlights:\n\n* **Orders of magnitude fewer tokens per query**\n* **Much higher precision on ‚Äúwhere is X implemented?‚Äù questions**\n* **More consistent answers for refactors and feature changes**\n\nVector RAG did slightly better on recall in some cases, but that mostly came from dumping more files into context, which turned out to be actively harmful for reasoning.\n\nThe takeaway for me:\n\nCode isn‚Äôt documentation but it's a graph with structure, boundaries, and dependencies. If being treated like a bag of words, it will break down fast once the repo gets large.\n\nI wrote a [detailed breakdown](https://www.byterover.dev/blog/why-vector-rag-fails-for-code-we-tested-it-on-1-300-files) of the experiment, failure modes, and why context trees work better for code (with full setup in this [repo ](https://github.com/RyanNg1403/agentic-search-vs-rag)and metrics) here if you want the full take.\n\nLet me know if you've found better approach",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfkeuf/we_tested_vector_rag_on_a_real_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o05cnsy",
          "author": "Disneyskidney",
          "text": "Interesting! Though I feel like the like the industry standard for RAG on a codebase has now become grep and other terminal commands. Would like to see it benchmarked against that, or see how they can work in tandem.",
          "score": 12,
          "created_utc": "2026-01-17 18:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05mce6",
              "author": "Challseus",
              "text": "I think that's the key. Combinations of semantic search/hybrid RAG, along with how agents build up context with grep/cat.",
              "score": 6,
              "created_utc": "2026-01-17 19:14:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05kd0n",
          "author": "OnyxProyectoUno",
          "text": "Yeah this matches what I've seen. Vector similarity works when semantic proximity actually means relevance, which it does for docs but not for code.\n\nThe test file problem is brutal. Tests and implementations share so much vocabulary that embeddings can't distinguish them. Same with deprecated code sitting next to current versions. Structurally they're different, semantically they're nearly identical.\n\nYour context tree approach makes sense because code has explicit structure that embeddings throw away. Import graphs, call hierarchies, module boundaries. All that gets flattened into a vector.\n\nOne thing I'd add: the preprocessing step matters more than people realize. How you chunk code affects what gets retrieved. Function-level chunks vs file-level vs arbitrary token windows all produce different failure modes. I've been building [VectorFlow](https://vectorflow.dev/?utm_source=redditCP_i) to make that visible, being able to see what your chunks actually look like before embedding catches a lot of issues early.\n\nFor hybrid approaches, have you tried combining your tree navigation with vector search for specific cases? Like using structure for \"where is X implemented\" but falling back to similarity for \"find similar patterns to this function\"? Curious if there's a sweet spot.",
          "score": 6,
          "created_utc": "2026-01-17 19:04:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05pwgl",
          "author": "lundrog",
          "text": "What I am currently using and made\n\nhttps://preview.redd.it/5vdslgfjoydg1.jpeg?width=2816&format=pjpg&auto=webp&s=9180d887ade94e5a92554342f734ec0be67a200d",
          "score": 3,
          "created_utc": "2026-01-17 19:31:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0aywxz",
              "author": "ExtentHot9139",
              "text": "Mmmh bloated no ?",
              "score": 2,
              "created_utc": "2026-01-18 15:33:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b29gt",
                  "author": "Crafty_Disk_7026",
                  "text": "ExtremelyZ. I garantee just running Claude in your codebase will give you better results than this mondtrosity",
                  "score": 3,
                  "created_utc": "2026-01-18 15:49:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06gven",
          "author": "kpgalligan",
          "text": "> Vector RAG has become the default pattern for coding agents\n\nHas it? I've been building a focused agent and haven't even touched it. Everything I've seen in the past year+ was \"don't use RAG\". The agents tend to find what they need directly. At least that's been my experience. If I wanted to do something like this, I'd probably start a distinct conversation, use RAG to potentially highlight some hits, have a model review the results and pull out what the original model actually wanted. Keeps the noise out of the main context.\n\nIn our case, the agent just uses a combination of file search tools. Not that I'd be opposed to trying something else, but RAG just seemed like it wouldn't do a whole lot better.\n\nWe have a similar solution for searching and grabbing web content. Some agents do a \"web fetch\" that grabs a URL, pushes it through a markdown converter, then returns the content. That can fill up the context with useless info. Instead, we have a \"research\" tool that takes a detailed description of what the LLM wants, does a web search and content download, then extracts what the model is actually looking for in a concise \"report\".",
          "score": 3,
          "created_utc": "2026-01-17 21:47:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06d9wc",
          "author": "CriticalBandicoot27",
          "text": "Firstly very insightful! I also had similar findings. For the code part i feel like the MIT rlm research paper seems promising to tackle the codebase problem. I am yet to implement it to see the actual results, but I feel like using chunks as a variable to test the actual relevance might fix most of these issues.",
          "score": 2,
          "created_utc": "2026-01-17 21:29:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o096xer",
          "author": "ClinchySphincter",
          "text": "is this an ad?",
          "score": 2,
          "created_utc": "2026-01-18 07:31:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a0ght",
              "author": "Glad-Champion5767",
              "text": "I've seen this exact post 1:1 a week ago or so. I thought i was getting a dejavu. Its definitely a bot post atleast, with some bot replies.",
              "score": 1,
              "created_utc": "2026-01-18 12:00:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09kten",
          "author": "WarlaxZ",
          "text": "If you want to solve this problem for code, you need to think like an ide. They didn't build up knowledge base of code, they added 'find references' and auto complete method name to existing ones, and automatic import etc. Refactoring and moving methods with a single click and pointing at a file. Solve these things and it will work better and more efficiently, as we've already been here many moons ago. I made a simple refactor mcp that accepted method name and method above and below to allow methods to be moved around files easily without needing to rewrite 3/4 of the file as a diff to great results, and there's so many things we already solved with ide's that have yet to be implemented for the new ai coding tools",
          "score": 2,
          "created_utc": "2026-01-18 09:38:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09c93h",
          "author": "-Cubie-",
          "text": "Honestly, I don't really buy it. Your big \"gain\" is 130x less token use. Now tell me: how would a different retrieval approach yield so much less tokens? You could, after all, have both approaches return the same number of documents. That would help make it a fair comparison.\n\nBut you don't do that.\n\nI think you spent much more time on optimizing your (presumably paid) product that you're advertising here and purposefully created a poor baseline so your product looks better.",
          "score": 1,
          "created_utc": "2026-01-18 08:19:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0apoca",
          "author": "_thedeveloper",
          "text": "Interesting findings.\n\nFrom my experience, pure semantic similarity is almost guaranteed to fail at this scale. You really need a hybrid approach that combines metadata (paths, ownership, recency, file type, dependencies) with semantic signals to get anything reliable for code.\n\nPreprocessing also matters a lot here. Blind chunking or fixed-length chunks tend to bloat context and amplify noise, especially in large repos. Without structure-aware chunking, retrieval quality degrades quickly.\n\nAST-based approaches help, but they‚Äôre not sufficient on their own. Code understanding is repo-specific ‚Äî effective chunking and retrieval usually need to align with the project‚Äôs architecture and conventions. That means maintenance and institutional knowledge of the codebase become first-class concerns, not implementation details.\n\nCurious if you experimented with metadata-weighted retrieval or repo-aware chunking alongside the context tree approach.",
          "score": 1,
          "created_utc": "2026-01-18 14:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ayszn",
          "author": "ExtentHot9139",
          "text": "Personally, I always craft my context window manually and ended automating it. I built code2prompt check it out.\n\nThe idea is simple: select relevant file, flatten them in a big file that you can just dump in a LLM chat.\n\nIt makes coding with agents stateless, semi auto and focused.",
          "score": 1,
          "created_utc": "2026-01-18 15:32:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b2ht5",
          "author": "Crafty_Disk_7026",
          "text": "You can not do RAG with code you need specialized format like ast so you can actually reason about the code.  Finding 2 functions with similar names that do completely different things is meaningless and the kind of garbage you'll get doing rag to understand code",
          "score": 1,
          "created_utc": "2026-01-18 15:50:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g1tbi",
          "author": "Creepy-Row970",
          "text": "pretty interesting read",
          "score": 1,
          "created_utc": "2026-01-19 08:39:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r1f9n",
          "author": "Professional-Work684",
          "text": "We had similar issues with over 2k files (pdf) with medical policys and routines. We solved it by adding a postgres db as an index and contextual rag with a pgvector db. The pg index contained metadata and some context of the content of the files.¬†",
          "score": 1,
          "created_utc": "2026-01-20 22:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0so2md",
          "author": "Sufficient-Pause9765",
          "text": "I found that RAG decreased performance unless agents were restricted to using it very, very sparingly.",
          "score": 1,
          "created_utc": "2026-01-21 03:56:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06s2rm",
          "author": "BeerBatteredHemroids",
          "text": "I've built a production vector rag application on over twice that amount of documents and it works just fine. You can't just slap a chatbot on a vector store and expect it to work out of the box. \n\nYou need smart prompting, reranking, good chunking strategy and a quality embedding model. Also, you should probably use a hybrid search combining similarity and keyword search.\n\nBasically, you need to be smarter than the tools you're working with boo",
          "score": 1,
          "created_utc": "2026-01-17 22:43:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgdgq5",
      "title": "LangGraph/workflows vs agents: I made a 2-page decision sheet. What would you change?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qgdgq5",
      "author": "OnlyProggingForFun",
      "created_utc": "2026-01-18 16:45:28",
      "score": 37,
      "num_comments": 6,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qgdgq5/langgraphworkflows_vs_agents_i_made_a_2page/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0be227",
          "author": "OnlyProggingForFun",
          "text": "If anyone wants the PDF version, I can share it directly too :)",
          "score": 1,
          "created_utc": "2026-01-18 16:45:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o0iw4x6",
          "author": "ayeaiai",
          "text": "u/ayeaiai Yes, please share the PDF version as well. Thank you.",
          "score": 1,
          "created_utc": "2026-01-19 18:49:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0iwyt4",
              "author": "OnlyProggingForFun",
              "text": "Of course, here it is in full: [https://drive.google.com/file/d/1HZ1m1NIymE-9eAqFW-sfSKsIoz5FztUL/view?usp=sharing](https://drive.google.com/file/d/1HZ1m1NIymE-9eAqFW-sfSKsIoz5FztUL/view?usp=sharing)",
              "score": 2,
              "created_utc": "2026-01-19 18:52:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0njpop",
          "author": "jaisanant",
          "text": "I have used orchestrator to delegate task to special agents.\nInside special agents there is supervisor-assistant pattern.",
          "score": 1,
          "created_utc": "2026-01-20 12:10:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ul6rt",
          "author": "MansiTibude",
          "text": "Thanks for sharing, are we allowed to download it?",
          "score": 1,
          "created_utc": "2026-01-21 13:14:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ule06",
              "author": "OnlyProggingForFun",
              "text": "Sure! I have it here as well in full with the webinar I made around it or in the drive link in the comment below :) \n\n[https://academy.towardsai.net/products/digital\\_downloads/agents-cheatsheet](https://academy.towardsai.net/products/digital_downloads/agents-cheatsheet)",
              "score": 1,
              "created_utc": "2026-01-21 13:16:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfcwe0",
      "title": "Really Bad Etiquette from Langchain maintainers",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfcwe0/really_bad_etiquette_from_langchain_maintainers/",
      "author": "Total-Chef-420",
      "created_utc": "2026-01-17 13:13:33",
      "score": 36,
      "num_comments": 18,
      "upvote_ratio": 0.87,
      "text": "I have tried contributing to langchain's ecosystem multiple times and both times my commits were taken by the maintainers, added a bunch of extra things on it and immediately raised a new PR without any kind of attribution.\n\nIs this how langchain expects people to contribute to their repository ?\n\n  \nThis has happened twice (and even maintainers acknowledged it)\n\n  \n1. [https://github.com/langchain-ai/deepagents/pull/713](https://github.com/langchain-ai/deepagents/pull/713)\n\n2. [https://github.com/langchain-ai/deepagentsjs/pull/84](https://github.com/langchain-ai/deepagentsjs/pull/84)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfcwe0/really_bad_etiquette_from_langchain_maintainers/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o042d9m",
          "author": "vtrivedy-lc",
          "text": "Hey OP, one of the maintainers from LangChain‚Äôs deepagents here, really sorry to hear that and our apologies.  Closing PRs and opening new ones that could‚Äôve been built on existing community PRs is never our intention.\n\nWe do get A LOT of PRs so it‚Äôs very possible we‚Äôve made this mistake and would love to make it right with proper attribution.  If you want to DM or link it, I‚Äôll take a look at how to give attribution.\n\nWe‚Äôre incredibly grateful for the awesome LangChain community, great contributions and ideas that push our libraries to be better for users.  Will try to make this right, sorry about the bad experience!",
          "score": 18,
          "created_utc": "2026-01-17 14:48:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04e1o6",
              "author": "Total-Chef-420",
              "text": "PR for deepagentsjs: [https://github.com/langchain-ai/deepagentsjs/pull/84](https://github.com/langchain-ai/deepagentsjs/pull/84)\n\n  \nPR for deepagents : [https://github.com/langchain-ai/deepagents/pull/713](https://github.com/langchain-ai/deepagents/pull/713)",
              "score": 12,
              "created_utc": "2026-01-17 15:47:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04fq6q",
                  "author": "vtrivedy-lc",
                  "text": "Thanks for linking!  See the PR across both, the deepagents one was a duplicate of a previous open PR that the team built on and added testing.  But totally see your frustration, we‚Äôll add attribution for the work!  \n\nAnd we will definitely be better in the future.  Would love feedback on the current PR process.  We‚Äôre exploring using discussions more to make sure that external PRs are linked directly to plans for implementing.  We love the PRs but understand it takes a lot of time and is then frustrating if the work isn‚Äôt used.  This way we can confirm the direction of the work.\n\nNothing decided but wanted to get feedback if anyone here has thoughts.",
                  "score": 5,
                  "created_utc": "2026-01-17 15:55:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04eks7",
                  "author": "TalosStalioux",
                  "text": "Upvoting for you",
                  "score": 1,
                  "created_utc": "2026-01-17 15:50:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03ngca",
          "author": "pokemonplayer2001",
          "text": "Do you have links to the PRs in question?",
          "score": 2,
          "created_utc": "2026-01-17 13:25:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04e708",
              "author": "Total-Chef-420",
              "text": "Yes, I have updated in the above comment",
              "score": -1,
              "created_utc": "2026-01-17 15:48:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0o0ub6",
          "author": "sydneyrunkle",
          "text": "Hey OP, thanks for raising! We really value community contributions.\n\n  \nI forgot to add you as a co-author when I merged my PR. I've corrected this mistake and added you here: https://github.com/langchain-ai/deepagents/pull/847.\n\n  \nThanks for your contributions -- we'd be more than happy to collaborate on future PRs :).",
          "score": 1,
          "created_utc": "2026-01-20 13:57:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o060khe",
          "author": "No_Inspection4415",
          "text": "Your PRs are pretty useless, to be honest.",
          "score": 0,
          "created_utc": "2026-01-17 20:24:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o061as9",
              "author": "Total-Chef-420",
              "text": "Simple yes, but useless no.\n\nThey fixed an issue which was open since multiple days.",
              "score": 1,
              "created_utc": "2026-01-17 20:27:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o06574y",
                  "author": "No_Inspection4415",
                  "text": "Isn't it [https://github.com/langchain-ai/deepagents/pull/612/files](https://github.com/langchain-ai/deepagents/pull/612/files) a different implementation? Did you run the validation they asked you to? Honestly, unless this fix is very difficult to find, having to work with \"your\" solution is not a net positive for them...\n\nWhatever, I do not like the framework anyway and I get your point, you did the research which is not complicated to do, but you did it. You do deserve credit, of course (not that being a part of this framework is a huge honor, it is not like you closed a PR for the K8s ;P).\n\nEdit: sorry, this [https://github.com/langchain-ai/deepagents/pull/803](https://github.com/langchain-ai/deepagents/pull/803) \\- they work really weirdly.",
                  "score": 0,
                  "created_utc": "2026-01-17 20:48:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdufx4",
      "title": "Honest question: What is currently the \"Gold Standard\" framework for building General Agents?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qdufx4/honest_question_what_is_currently_the_gold/",
      "author": "Strong_Cherry6762",
      "created_utc": "2026-01-15 20:14:21",
      "score": 24,
      "num_comments": 32,
      "upvote_ratio": 0.86,
      "text": "Hi everyone,\n\nI'm a beginner developer diving into AI agents. My goal is to build a solid General Agent, but I want to make sure I start with the right tools.\n\nI keep hearing about LangGraph, but before I commit to learning it, I really want to know what the community considers the actual \"best\" framework right now.\n\nHere is what I‚Äôm hoping to learn from your experience:\n\n1. The #1 Recommendation: If you were starting a new project today, which framework would you choose and why? Is there a clear winner?\n2. LangGraph Reality Check: Is LangGraph truly the best option for a general-purpose agent, or is it overkill/too complex for a starter? What are its main pros and cons?\n3. General Best Practices: Regardless of the framework, what are the most important principles for building a stable agent?\n\nI‚Äôm looking for a solution that balances power with ease of use. Thanks for pointing me in the right direction!",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qdufx4/honest_question_what_is_currently_the_gold/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nzt57if",
          "author": "caprica71",
          "text": "Honestly the framework just disappears from thought most of the time once you get arms deep into a problem.   Most of my life is in evals and integrations.  Just pick a really popular one and get going.   If the agent frame work gets in the way swap it.",
          "score": 18,
          "created_utc": "2026-01-15 22:01:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztqakt",
              "author": "scar0x00",
              "text": "What do you use for evals?",
              "score": 2,
              "created_utc": "2026-01-15 23:49:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o017tve",
                  "author": "caprica71",
                  "text": "Langfuse for the some parts.   I have some custom python for other evals.",
                  "score": 1,
                  "created_utc": "2026-01-17 01:52:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0anbcn",
                  "author": "sunglasses-guy",
                  "text": "We use Confident AI for production monitoring + tracing",
                  "score": 0,
                  "created_utc": "2026-01-18 14:33:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00uses",
              "author": "AdditionalWeb107",
              "text": "how do you easily swap it when you have gone down the rabbit hotel of its concepts? Like CrewAI is so hard to unpack and move into LangChain. I would prefer we go stock python for most things and think through clean separation of concerns.",
              "score": 1,
              "created_utc": "2026-01-17 00:31:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o016e6d",
                  "author": "caprica71",
                  "text": "Basically you nailed it : use stock python as much as possible and good separation of concerns.   My langraph application has very light nodes. I use langchain sparingly.",
                  "score": 2,
                  "created_utc": "2026-01-17 01:42:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt0mn2",
          "author": "cordialgerm",
          "text": "Look into Langchain 1.0. you can build a basic agent harness with  a single function call. Langgraph is more for complex / low level use-cases.\n\nI think it's less about the particular framework and more about the  tools, evals, data, etc that you inject into the framework that makes or breaks your agent.",
          "score": 5,
          "created_utc": "2026-01-15 21:40:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzupspl",
              "author": "brucebay",
              "text": "I suggest langgraph. It is easier and in most cases more flexible.¬†",
              "score": 2,
              "created_utc": "2026-01-16 03:06:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt11hq",
              "author": "Strong_Cherry6762",
              "text": "Thanks~",
              "score": 1,
              "created_utc": "2026-01-15 21:42:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuplr1",
          "author": "dash_bro",
          "text": "If you're busy starting out, learn langchain/langgraph. They're okay okay to learn, but hard to deploy at scale in production : so just keep that in mind. \n\n- learn what you want to do first\n- you'll maybe realize it isn't the best fit and want to check out what other library offers these features etc.\n\nFWIW I started with autogen -> crew -> now I just do it custom myself",
          "score": 2,
          "created_utc": "2026-01-16 03:04:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw7xba",
              "author": "Born_Owl7750",
              "text": "Why is it hard to deploy in production? What issues have you faced?\nWe currently are in the Microsoft ecosystem and use semantic kernel or native sdk. I was thinking of switching to langchain and langgraph due to the sheer amount of features and updates they have.",
              "score": 1,
              "created_utc": "2026-01-16 09:58:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwf0dr",
                  "author": "dash_bro",
                  "text": "Biggest problem is bloat and noQA features. The bloat especially throws random problems when you're hosting multiple embedding models + serving to a few users live.\n\nMemory management (RAM/VRAM) harnesses are a nightmare. Bloat around using external integrations without plugging in langchain specific adapters - again, creates non DRY work. The ecosystem is good for when flexibility isn't required fully.\n\nIt's often much better to experiment with, then build for specced out features yourself.",
                  "score": 1,
                  "created_utc": "2026-01-16 11:01:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvbz8a",
          "author": "Playful_Criticism425",
          "text": "People are sleeping on PydanticAI",
          "score": 2,
          "created_utc": "2026-01-16 05:25:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw5xm8",
              "author": "FlowLab99",
              "text": "Do you mean that Pydantic team is not moving quickly or responsive? Just curious m.",
              "score": 1,
              "created_utc": "2026-01-16 09:40:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0231my",
                  "author": "Playful_Criticism425",
                  "text": "It's actually good. For agentic solutions and it is Pythonic and    more deterministic than n8n",
                  "score": 1,
                  "created_utc": "2026-01-17 05:20:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fxyzo",
          "author": "TJWrite",
          "text": "Yo, OP, sit down and pay attention to your big bro right here. Also my bad, I didn‚Äôt know I talk to damn much.\n\r\nFirst of all, there is no Gold bro, also there are no standards (With respect to a few unknown places). Most of us are using the shit that works and keeps it moving. As engineers, we tend to want to build the most complex shit in the planet, then cry about the number of bugs and issues it has, then abandon the project, and talk about it like it was a unicorn. The important lesson hete to note is: ‚ÄòReduce complexity whenever possible‚Äô (Remember this for later).\n\r\nSecond, there are other Agent Frameworks other than LangGraph, but what are the true differences and when to choose what? I will give you a few Pros & Cons about other Agent Frameworks and a few Pros & Cons for using LangGraph as a Framework. Note: This is not an exhaustive list, it‚Äôs meant to give you a better understanding of how to choose what and when.\n\r\nOther Agent Framework Pros: They focus on reducing the amount of work you would put in to build a framework. Some of them have colorful IDEs, cute buttons to do so much shit for you, and a step-by-step guide better than the guide ChatGPT could give you. If these frameworks would speak they would say, ‚ÄúI will take care of the Agent Framework, you just choose what you want, click this button and you his button and whoop, aren‚Äôt you such a developer. Now go handle your other shit, I got this‚Äù and they truly do.\n\r\nOther Agent Framework Cons: They only have a limited selection of Agent frameworks. Literally, they have a few options and ask you to choose one bro. Of you can‚Äôt find what you need, it throws a fit and tells you, we can‚Äôt work together. \r\nTherefore, you must check if your use case can be built using one of these Frameworks, it will save you time and reduce complexity. They even tell you what they are compatible with and many more. It‚Äôs really helpful when you can use them. However, if you need something they don‚Äôt offer, it‚Äôs like speaking Chinese to them, more useless than a box of rocks.\n\r\nLangGraph Pros: This Agent Framework is built to redefine the word ‚ÄòCustomization‚Äô. If we combine the amount of customization from an Android phone and a Linux OS, they won‚Äôt come close to the number of Customization that LangGraph has. Also, the number of tools that it has and can connect to. The most powerful feature its seamless integration with LangChain, and as you know LangChain by itself comes with more weapons than all of Call of Duty. \n\r\nLangGraph Cons: No fancy shit, deployment is a little sus with enterprise, requires actual coding, few files step up correctly to get this shit connected well.\nThere are some documentations, however, if you get stuck using a framework from LangGraph that doesn‚Äôt have enough documentations like me, come have a seat next to me, we can cry together. Note: The education courses on LangChain Academy is a beast in understanding LangGraph in more depth, avoid all others, trust me. Additionally, they are trying to build few templates, that anyone can use straight out of the box and works very well. However, if you are using a framework that doesn‚Äôt have a template like me, the seat next to me is still available bro.\r\n\n\r\nQuick Recap for my beginner bro, checkout the other agent frameworks that exists. Try to see all the Agent Framework features that they offer. All of them, I am serious, it will save you time and headache, trust me. Know that LangGraph is and will always be your backup option, while keeping in mind the massive overhead that you must take care of you on your own. Also, be very very careful about what has been deprecated recently when they released the new version and stick to the new version LangGraph v1. When Chatting with ChatGPT or whatever, ensure that you mention that you are using LangGraph v1, otherwise, this idiot could literally give you deprecated code and send you on a rabbit hole where there is no Wi-Fi down there. \n\r\nGood Luck bro,",
          "score": 2,
          "created_utc": "2026-01-19 08:03:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuef3v",
          "author": "attn-transformer",
          "text": "Honestly none of them. They‚Äôre all experiments. I‚Äôd start with Agno or LangGraph.",
          "score": 3,
          "created_utc": "2026-01-16 02:02:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvz87k",
              "author": "nbvehrfr",
              "text": "Agno is good.¬†",
              "score": 2,
              "created_utc": "2026-01-16 08:37:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzv23w0",
          "author": "Khade_G",
          "text": "There isn‚Äôt a single best framework right now‚Ä¶ the best choice depends on how complex your agent actually needs to be.\n\nIf I were starting today, I‚Äôd pick the simplest thing that can ship, and only upgrade when I feel pain. For most beginners, that‚Äôs a lightweight agent loop (tools + memory + logging) using whatever SDK you‚Äôre already comfortable with. LangChain can get you moving fast. LangGraph is great when you need control: multi-step workflows, branching, retries, and state you can inspect. But for a ‚Äúgeneral agent‚Äù as a first project, it can feel like overkill because you end up building a workflow engine before you‚Äôve proven the agent needs one.\n\nLangGraph pros: more reliable orchestration, easier debugging of state, safer retries, and it scales better once you have multiple steps/roles. Cons: more structure, more upfront thinking, and it‚Äôs slower to iterate if you‚Äôre still learning what your agent should even do.\n\nBest practices that matter more than framework: keep context small and explicit, log everything (inputs/tool calls/outputs), design for failure (timeouts, retries, fallbacks), and don‚Äôt let the agent ‚Äúfree roam‚Äù‚Ä¶ give it clear goals, constraints, and stopping conditions. If you do those, your agent will be stable in almost any framework.",
          "score": 3,
          "created_utc": "2026-01-16 04:19:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzubzmd",
          "author": "siddharthnibjiya",
          "text": "Claude code is now considered the best agentic structure / style to be followed.\n\nRelated but not my only reason for saying this:\n\nhttps://x.com/amasad/status/2011475533369131424?s=46",
          "score": 2,
          "created_utc": "2026-01-16 01:49:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztdbp2",
          "author": "Challseus",
          "text": "Apologies in advance, this may or may not help your cause, but... I worked on a multi-agent setup with Lang Graph close to a year ago. There was the one **Primary Agent** that would pass off the request to other agents (with their own instructions), depending on some business logic. 8-9 agents total. Image analysis, tools, RAG, everything. It worked. It had many bugs, but that was a skill issue thing, not Lang Graph's fault.\n\nWe used **gpt-4o.**\n\nSame company, CEO now wants this logic back in a new product. It's basically the same thing, except one major thing:\n\nNo Lang Graph, just Langchain. Just a single agent, one prompt, and basic conversation history. It handles everything MUCH BETTER.\n\nWe're using **gpt-4.1-mini.**\n\nLong story short, TL;DR, whatever, just go with **Langchain 1.0.** It has great support for built in RAG pipeline stuff to get you started, as well as conversation history.\n\nAlso checkout [https://langfuse.com/](https://langfuse.com/) or [https://smith.langchain.com/](https://smith.langchain.com/) for observability.",
          "score": 1,
          "created_utc": "2026-01-15 22:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzte0y5",
          "author": "Bohdanowicz",
          "text": "It depends what you are building.. lang is great when you need a stategraph, adk is great for a2a/subagents out of the box",
          "score": 1,
          "created_utc": "2026-01-15 22:44:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvplkv",
          "author": "Ambitious-Most4485",
          "text": "We are using in production google adk, but langgraph was an option we did consider.\n\nAdk has some flaws (for example we needed to log chunks and was a nightmare navigating the state).\n\n Observability is a must i recommend Phoenix arize (really easy integration)",
          "score": 1,
          "created_utc": "2026-01-16 07:12:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvwgel",
          "author": "KallistiTMP",
          "text": "It's still the wild west out there. All agentic frameworks suck in several dimensions, and often suck differently with different models and tasks. There is no consensus on what the best overall high level approach is even, it's an active area of research.\n\nDon't overthink it, any choice you make is gonna be wrong and require a major overhaul or full replacement in a couple years anyway.",
          "score": 1,
          "created_utc": "2026-01-16 08:12:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw1kub",
          "author": "Disneyskidney",
          "text": "I went to hackathon for something like this. Both first place, second place, and third place all used Claude code. It‚Äôs surprising how general coding agents are becoming. \n\nI actually just used cursor for lead generation lol.",
          "score": 1,
          "created_utc": "2026-01-16 08:59:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw1r29",
          "author": "Disneyskidney",
          "text": "Check out DSPy and RLMs",
          "score": 1,
          "created_utc": "2026-01-16 09:01:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwvtia",
          "author": "No-Fail-7644",
          "text": "Plain, old java. I found vertx with quarkus running on java 21 to be extremely versatile if reactive patterns are implemented properly. Langchain4j for agents.",
          "score": 1,
          "created_utc": "2026-01-16 13:03:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o008sg8",
          "author": "Strong_Worker4090",
          "text": "No real ‚Äúgold standard‚Äù yet. Agents are still kinda messy, and most people end up with a thin framework + their own glue.\n\nIf I‚Äôm starting today:\n\n1. LangGraph if you expect multi-step flows, branching, retries, human-in-the-loop. I moved a project from a messy ‚Äúagent loop‚Äù to LangGraph and it got way easier to debug. Downside: more setup, can feel overkill early.\n2. If you want simpler: plain LangChain (or even just your own wrapper) is fine for v1.\n3. If your agent is mostly RAG: LlamaIndex or Haystack.\n4. If you‚Äôre doing ‚Äúmultiple agents with roles‚Äù: AutoGen or CrewAI.\n\nBiggest mistake I made early was chasing frameworks instead of basics. What actually made things stable was: fewer tools, hard timeouts, good logs, and input/output checks (guardrails). Framework choice matters way less than that.",
          "score": 1,
          "created_utc": "2026-01-16 22:30:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08ety4",
          "author": "spersingerorinda",
          "text": "I‚Äôll just gently point out that neither Anthropic nor OpenAI are promoting any ‚Äúcomputational graph‚Äù type framework. What do they know that LangChain doesn‚Äôt ? Cursor may use langgraph under the covers, but do you really need it if Claude Code doesn‚Äôt need it ?",
          "score": 1,
          "created_utc": "2026-01-18 03:58:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o095b7q",
          "author": "Revolutionary-Bet-58",
          "text": "disclosure, i'm working at inkog.io. \n\nI would recommend that you also look at loops and as another commenter says how the evals are set, but also if you have proper human-in-the-loop for unrealistic agent determiniation usecases. We do that at Inkog, which you can use to scan your agent and get fast feedback.\n\nIts quite a lot things to think of if you want to build a true enterprise grade agent, but it comes down to your usecase/scale",
          "score": 1,
          "created_utc": "2026-01-18 07:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzulj4e",
          "author": "_eltigre_",
          "text": "Mastra.",
          "score": 1,
          "created_utc": "2026-01-16 02:42:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztu53d",
          "author": "naxmax2019",
          "text": "Don‚Äôt use frameworks. They suck!",
          "score": -1,
          "created_utc": "2026-01-16 00:10:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgekmg",
      "title": "fastapi-fullstack v0.1.15 released ‚Äì now with DeepAgents (LangChain's multi-agent framework) + HITL support!",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qgekmg/fastapifullstack_v0115_released_now_with/",
      "author": "VanillaOk4593",
      "created_utc": "2026-01-18 17:27:05",
      "score": 21,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hey r/LangChain,\n\nQuick recap for new folks: fastapi-fullstack is an open-source CLI generator (pip install fastapi-fullstack) that creates production-ready full-stack AI/LLM apps with FastAPI backend + optional Next.js 15 frontend. It supports PydanticAI, LangChain, LangGraph, CrewAI ‚Äì and now DeepAgents for advanced multi-agent systems.\n\n**v0.1.15 just released with full DeepAgents integration:**\n\n**Added:**\n\n* **DeepAgents as the fifth AI framework option** ‚Äì new --ai-framework deepagents CLI flag\n* Built-in tools for file ops (ls/read/write/edit/glob/grep), code execution (disabled by default for safety), and task management (todos/sub-agents)\n* StateBackend for in-memory file state\n* Skills support via DEEPAGENTS\\_SKILLS\\_PATHS env var\n\n**Human-in-the-Loop (HITL) features:**\n\n* Tool approval workflow: Users can approve/edit/reject tool calls (configurable via DEEPAGENTS\\_INTERRUPT\\_TOOLS)\n* Frontend dialog for reviewing/editing JSON args in real-time\n* WebSocket protocol for interrupts: Backend sends tool\\_approval\\_required, frontend responds with resume decisions\n\n**Fixed & improved:**\n\n* Type annotations across CrewAI handlers (from previous updates)\n* WebSocket disconnect handling during agent processing\n* Frontend timeline connectors and message grouping\n* 100% test coverage (720 statements, 0 missing) with tests for all DeepAgents events, stream edges, and disconnects\n\nThis makes building and deploying DeepAgents-powered apps (with HITL for safe, controlled execution) super straightforward ‚Äì perfect for complex, filesystem-aware agents.\n\nFull changelog: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md)  \nRepo: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template)\n\nLangChain community ‚Äì how does DeepAgents + HITL fit your multi-agent projects? Any features to add? Contributions welcome! üöÄ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qgekmg/fastapifullstack_v0115_released_now_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0d557i",
          "author": "vtrivedy-lc",
          "text": "this is awesome! basically breathe fastapi and deepagents these days so love to see this :)\n\nif there‚Äôs any way we can make deepagents easier to dev on, would love to hear it!",
          "score": 2,
          "created_utc": "2026-01-18 21:52:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ol9so",
          "author": "Difficult-Suit-6516",
          "text": "Nice üëçüèª Would Love to see LangChain + OpenRouter Integration as those are my poison of choice right now",
          "score": 1,
          "created_utc": "2026-01-20 15:41:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi5rmu",
      "title": "Deep Agents pattern: planning, delegation, file based state (wired up with CopilotKit)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qi5rmu/deep_agents_pattern_planning_delegation_file/",
      "author": "pfthurley",
      "created_utc": "2026-01-20 16:29:34",
      "score": 16,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Most agents today are just ‚ÄúLLM in a loop + tools‚Äù. They are good at reasoning and works fine for short tasks. Over long-running tasks, they usually have no plan, lose context and their execution gets messy.\n\nMore capable agents like Claude Code and Manus get around this by following a common pattern: they plan first, externalize working context (files) and break work into isolated sub-tasks.\n\nDeep Agents from LangChain are really the next level, which essentially package this pattern into a reusable runtime. you call `create_deep_agent(...)` and get a StateGraph that:\n\n* plans explicitly\n* delegates work to sub-agents\n* keeps its state in files instead of bloating the prompt\n\nEach piece is implemented as middleware (To-do list middleware, Filesystem middleware, Subagent middleware).\n\nConceptually it looks like this:\n\n    User goal\n      ‚Üì\n    Deep Agent (LangGraph StateGraph)\n      ‚îú‚îÄ Plan: write_todos ‚Üí updates \"todos\" in state\n      ‚îú‚îÄ Delegate: task(...) ‚Üí runs a subagent with its own tool loop\n      ‚îú‚îÄ Context: ls/read_file/write_file/edit_file ‚Üí persists working notes/artifacts\n      ‚Üì\n    Final answer\n\nIt push key parts into explicit state (e.g. `todos` \\+ files + messages), but the main thing I noticed was visibility over frontend.\n\nI wired it up with CopilotKit - Infrastructure for building AI copilots into any app.\n\nIt keeps the frontend in sync with what the agent is doing by streaming events and state updates in real time (using AG-UI protocol under the hood).\n\nDeep Agents is really good at multi-step workflows & CopilotKit as the orchestration + UI layer. Check out the \"Job search assistant\" demo using this pattern.\n\nGitHub Repo: [https://github.com/CopilotKit/copilotkit-deepagents](https://github.com/CopilotKit/copilotkit-deepagents)  \nTutorial: [https://www.copilotkit.ai/blog/how-to-build-a-frontend-for-langchain-deep-agents-with-copilotkit](https://www.copilotkit.ai/blog/how-to-build-a-frontend-for-langchain-deep-agents-with-copilotkit)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qi5rmu/deep_agents_pattern_planning_delegation_file/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qejo7q",
      "title": "Deploying LangGraph agents to your own AWS with one command",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qejo7q/deploying_langgraph_agents_to_your_own_aws_with/",
      "author": "DefangLabs",
      "created_utc": "2026-01-16 15:54:18",
      "score": 15,
      "num_comments": 0,
      "upvote_ratio": 0.89,
      "text": "We keep seeing deployment questions come up here, so wanted to share what we've built.\n\n**The problem:**\n\nLangGraph is great for building agents locally. But when you want to deploy:\n\n* LangSmith/LangServe are solid but your data goes through their infra\n* Self-hosting on AWS means ECS, IAM roles, VPCs, load balancers, secrets management...\n* Most tutorials stop at \"run it locally\"\n\n**What we built:**\n\nDefang lets you deploy any containerized app to your own AWS/GCP with one command. You write a compose.yaml:\n\nyaml\n\n    services:\n      agent:\n        build: .\n        ports:\n          - \"8000:8000\"\n        x-defang-llm: true\n\nRun `defang compose up`. Done. It provisions ECS, networking, SSL, everything.\n\nThe `x-defang-llm: true` part auto-configures IAM permissions for AWS Bedrock (Claude, Llama, Mistral) or GCP Vertex AI. No policy writing.\n\n**Why this matters:**\n\n* Your AWS account, your data, your infrastructure\n* Works with any LangChain/LangGraph setup (just containerize it)\n* Scales properly (ECS Fargate under the hood)\n* Free tier for open source repos (forever, not a trial)\n\n**We're launching V3 next week** with:\n\n* Named Stacks ‚Äî deploy separate instances for dev/staging/prod or per customer from the same codebase\n* Agentic CLI ‚Äî auto-debugs deployment errors, understands English commands\n* Zero-config AWS ‚Äî one click to connect, no IAM policies to write\n\nWe have a LangGraph sample ready to go: [github.com/DefangLabs/samples](http://github.com/DefangLabs/samples)\n\nLaunching on Product Hunt Jan 21. \n\nHappy to answer questions about deploying LangGraph or agents in general.",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qejo7q/deploying_langgraph_agents_to_your_own_aws_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qj9qms",
      "title": "Solved rate limiting on our agent workflow with multi-provider load balancing",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "author": "llamacoded",
      "created_utc": "2026-01-21 20:46:50",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 0.93,
      "text": "We run a codebase analysis agent that takes about 5 minutes per request. When we scaled to multiple concurrent users, we kept hitting rate limits; even the paid tiers from DeepInfra, Cerebras, and Google throttled us too hard. Queue got completely congested.\n\nTried Vercel AI Gateway thinking the endpoint pooling would help, but still broke down after \\~5 concurrent users. The issue was we were still hitting individual provider rate limits.\n\nTo tackle this we deployed an LLM gateway (Bifrost) that automatically load balances across multiple API keys and providers. When one key hits its limit, traffic routes to the others. We set it up with a few OpenAI and Anthropic keys.\n\nIntegration was just changing the base\\_url in our OpenAI SDK call. Took maybe 15-20 min total.\n\nNow we're handling 30+ concurrent users without throttling. No manual key rotation logic, no queue congestion.\n\nGithub if anyone needs:¬†[https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0xcho0",
          "author": "DanceWithEverything",
          "text": "Can I use a Claude max sub to oauth myself a token?",
          "score": 1,
          "created_utc": "2026-01-21 20:57:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xn3ti",
          "author": "Mishuri",
          "text": "Or just use open router?",
          "score": 1,
          "created_utc": "2026-01-21 21:46:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfa9vd",
      "title": "Web Search APIs Are Becoming Core Infrastructure for AI",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfa9vd/web_search_apis_are_becoming_core_infrastructure/",
      "author": "codes_astro",
      "created_utc": "2026-01-17 10:52:21",
      "score": 11,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "Web search used to be a ‚Äúnice-to-have‚Äù in software. With AI, it‚Äôs quickly becoming a requirement.\n\nLLMs are powerful, but without live data they can‚Äôt handle breaking news, current research, or fast-changing markets. At the same time, the traditional options developers relied on are disappearing, Google still doesn‚Äôt offer a truly open web search API and Bing Search API has now been retired in favor of Azure-tied solutions.\n\nI wrote a deep dive on how this gap is being filled by a new generation of AI-focused web search APIs, and why retrieval quality matters more than the model itself in RAG systems.\n\nThe article covers:\n\n* Why search is now core infrastructure for AI agents\n* Benchmarks like SimpleQA and FreshQA and what they actually tell us\n* How AI-first search APIs compare on accuracy, freshness, and latency\n* A breakdown of tools like Tavily, Exa, Valyu, Perplexity, Parallel and Linkup\n* Why general consumer search underperforms badly in AI workflows\n\nI‚Äôd love to hear from people actually building RAG or agent systems:\n\n* Which search APIs are you using today?\n* What tradeoffs have you run into around freshness vs latency vs cost?\n\nRead full writeup [here](https://mranand.substack.com/p/why-web-search-apis-are-becoming)\n\n",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfa9vd/web_search_apis_are_becoming_core_infrastructure/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0542zt",
          "author": "Born_Owl7750",
          "text": "Currently using grounding with bing. But few limitations like you can only use it with a foundry agent service. Results are fine but too high level.\n\nTavily is something we are trying out as well",
          "score": 2,
          "created_utc": "2026-01-17 17:49:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09gx0m",
              "author": "codes_astro",
              "text": "Yes bing is too limited now, I have used tavily in early 2025 but I didn‚Äôt liked the responses, linkup and exa did better. Have to implement new web APIs to test which is better",
              "score": 2,
              "created_utc": "2026-01-18 09:02:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o09pbu6",
                  "author": "Born_Owl7750",
                  "text": "Nice, will try it out",
                  "score": 1,
                  "created_utc": "2026-01-18 10:20:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o09pcoc",
                  "author": "Born_Owl7750",
                  "text": "Nice, will try it out",
                  "score": 1,
                  "created_utc": "2026-01-18 10:20:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0b4vxx",
                  "author": "TheStanfordSimpLord",
                  "text": "\\+1 for linkup - works the best for me overall",
                  "score": 1,
                  "created_utc": "2026-01-18 16:02:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhqw4u",
      "title": "AIMUG Builders Podcast - LangGraph orchestration w/ AWS agent core",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qhqw4u/aimug_builders_podcast_langgraph_orchestration_w/",
      "author": "colinmcnamara",
      "created_utc": "2026-01-20 04:11:26",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Quick share for builders: Ep.6 digs into diffusion-model roots, then gets practical‚ÄîLangChain/LangGraph orchestration, ‚Äúskills‚Äù as a framework for agent workflows, context engineering, and production gotchas (incl. AWS agent core talk).   \nVideo if useful: [https://youtu.be/iSL-K4ytQNI?utm\\_source=Reddit&utm\\_medium=social&utm\\_campaign=members](https://youtu.be/iSL-K4ytQNI?utm_source=Reddit&utm_medium=social&utm_campaign=members)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qhqw4u/aimug_builders_podcast_langgraph_orchestration_w/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qhxuzz",
      "title": "LangSmith Agent Builder + MCP: What worked, what broke, and how I finally got MCP tools to show up",
      "subreddit": "LangChain",
      "url": "https://composio.dev/blog/how-to-langsmith-agent-builder",
      "author": "cyber_harsh",
      "created_utc": "2026-01-20 10:43:41",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qhxuzz/langsmith_agent_builder_mcp_what_worked_what/",
      "domain": "composio.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o0o7p64",
          "author": "sharsha315",
          "text": "That was a great insight. Thanks for sharing.",
          "score": 2,
          "created_utc": "2026-01-20 14:33:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o95rc",
              "author": "cyber_harsh",
              "text": "Welcome , I hope it's fixed soon, For now this is the answer from the founder himself.\n\nhttps://preview.redd.it/55rej0alnieg1.png?width=1080&format=png&auto=webp&s=95b2ee95fe0ac739571566b2c097716118ace58f",
              "score": 2,
              "created_utc": "2026-01-20 14:41:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfv8hd",
      "title": "I built an LLM router that cut my API costs by 60% - Open Source, Need feedback",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfv8hd/i_built_an_llm_router_that_cut_my_api_costs_by_60/",
      "author": "Dense-Case-3615",
      "created_utc": "2026-01-18 01:37:43",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I was spending $200/month on LLM API calls and built \\*\\*Cascade\\*\\* to reduce costs through intelligent routing.\n\n\\*\\*How it works:\\*\\*\n\n\\*   Trains a DistilBERT classifier on query complexity\n\n\\*   Routes simple queries to cheap models\n\n\\*   Routes complex queries to expensive models\n\n\\*   Adds semantic caching for duplicate-ish requests\n\n\\*\\*Results:\\*\\* $100 ‚Üí $40/month (60% reduction)\n\n\\*\\*Tech stack:\\*\\*\n\n\\*   FastAPI + OpenAI-compatible API\n\n\\*   ONNX Runtime for <20ms ML inference\n\n\\*   Qdrant for vector similarity search\n\n\\*   Redis for caching\n\n\\*   Docker for deployment\n\n\\*\\*Try it live (free):\\*\\*\n\n\n\ncurl -X POST [http://136.111.230.240:8000/v1/chat/completions](http://136.111.230.240:8000/v1/chat/completions) \\\\\n\n\\-H \"Content-Type: application/json\" \\\\\n\n\\-d '{\"model\":\"auto\",\"messages\":\\[{\"role\":\"user\",\"content\":\"Hello\"}\\]}'\n\n\\*\\*Dashboard:\\*\\* [https://cascade.ayushkm.com/](https://cascade.ayushkm.com/)\n\n\\*\\*GitHub:\\*\\* [https://github.com/ayushm98/cascade](https://github.com/ayushm98/cascade)\n\n\\*\\*I'm actively looking for feedback:\\*\\* Is there something I can do to improve the architecture or routing logic? What features would make this useful for your production workloads?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qfv8hd/i_built_an_llm_router_that_cut_my_api_costs_by_60/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0927i9",
          "author": "Key-Contact-6524",
          "text": "How much latency does this add as compared to normal request?",
          "score": 2,
          "created_utc": "2026-01-18 06:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fp5bh",
          "author": "Due_Midnight9580",
          "text": "Cool I was trying to build same üôÇ",
          "score": 1,
          "created_utc": "2026-01-19 06:46:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf64ge",
      "title": "Learning multiagents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qf64ge/learning_multiagents/",
      "author": "crionuke",
      "created_utc": "2026-01-17 06:42:42",
      "score": 9,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "I am trying to understand multi-agent systems by reading materials online and by building my own prototypes and experiments.\n\nIn most discussions, the term agent is used very broadly. However, I have noticed that it actually refers to two fundamentally different concepts.\n\n1. Agent as an abstraction over an LLM call\n\nIn this model, an agent is essentially a wrapper around an LLM invocation. It is defined by a unique role and a contract for input and output data.\n\nSuch agents do not have a decision loop. They usually provide simple request‚Äìresponse behavior, similar to an API endpoint.\n\n2. Autonomous code agents\n\nExamples include Claude Code, OpenCode, and similar tools. These agents can not only generate code, but also execute tasks and coordinate complex workflows.\n\nThe key difference is that they have their own decision loop. They can plan, act, observe results, and continue working autonomously until a goal is achieved.\n\n\\---\n\nBuilding a multi-agent system composed of agents of the first type is not particularly interesting to me. It is primarily an integration problem.\n\nWhile it is possible to design non-trivial architectures, such as:\n\n\\- agent graphs with or without loops,\n\n\\- routing or pathfinding logic to select the minimal set of agents required to solve a task,\n\nthe agents themselves remain passive and reactive.\n\nWhat I truly want to understand is how to build systems composed of autonomous agents that operate inside their own decision loops and perform real work independently.\n\nThat is the part of multi-agent systems I am trying to learn. \n\nWelcome any comments on the topics.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qf64ge/learning_multiagents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o02gsnl",
          "author": "mdrxy",
          "text": "nice- you may enjoy these new docs: [https://docs.langchain.com/oss/python/langchain/multi-agent/index](https://docs.langchain.com/oss/python/langchain/multi-agent/index)",
          "score": 2,
          "created_utc": "2026-01-17 07:14:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02kixa",
              "author": "crionuke",
              "text": "I quickly went through the docs. The agent described there is a rather low-level entity that requires you to implement all the tools yourself. What makes this especially difficult is having to build your own context management.\n\nHowever, there are already mature agents such as Claude Code, OpenCode, etc. Any thought about reusing them instead of reengineering solutions that have already been solved?",
              "score": 1,
              "created_utc": "2026-01-17 07:48:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o04n8n2",
          "author": "Khade_G",
          "text": "Most multi-agent examples I‚Äôve seen online are really role-based LLM calls stitched together. They‚Äôre useful, but as you said that‚Äôs mostly an integration/orchestration problem. The agents don‚Äôt decide, they‚Äôre invoked. Autonomous agents are a different beast. The defining feature isn‚Äôt that they call tools, it‚Äôs that they own a control loop: goal ‚Üí plan ‚Üí act ‚Üí observe ‚Üí update state ‚Üí repeat. Once you do that, the hard problems stop being prompts and start being systems problems: state management, stopping conditions, failure recovery, credit assignment, and coordination between loops.\n\nA few patterns that show up in real autonomous multi-agent systems:\n- Explicit internal state: each agent has its own persistent state (goals, assumptions, progress), not just shared context.\n- Bounded autonomy: agents don‚Äôt free-run forever; they operate inside constraints (budgets, max steps, human checkpoints).\n- Communication as messages, not prompts: agents exchange structured messages/events, often asynchronously, rather than sharing giant contexts.\n- Task ownership: one agent owns a goal and decides when to ask others for help, instead of a central router deciding everything.\n- Failure as a first-class outcome: agents are allowed to say ‚ÄúI‚Äôm stuck,‚Äù escalate, or back off‚Ä¶ otherwise loops collapse into thrashing.\n\nFramework-wise, this is why things like LangGraph, AutoGPT-style planners, or workflow engines + agents exist: not to make agents smarter, but to make decision loops survivable. The intelligence comes from how you bound and coordinate those loops, not from adding more agents.\n\nA good exercise is to build one autonomous agent that can run for hours, survive restarts, and explain what it‚Äôs doing. Then add a second agent and make coordination the problem. The learning is in the doing",
          "score": 1,
          "created_utc": "2026-01-17 16:31:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05sn64",
              "author": "crionuke",
              "text": "My current idea is that I do not need autonomous agents to run for hours or longer.\n\nIn most cases, it is enough to run an agent once to accomplish a specific task, commit the changes along with all related information, and then exit.\n\nAny thoughts?",
              "score": 1,
              "created_utc": "2026-01-17 19:44:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o04ulvw",
          "author": "DaRandomStoner",
          "text": "If it's an llm that can make tool calls I call it an agent. I don't understand why people want to make the definition all complicated.",
          "score": 1,
          "created_utc": "2026-01-17 17:05:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05poa0",
              "author": "crionuke",
              "text": "As many people, as many opinions. There is no specification yet.\n\nIn some sources, an AI agent is defined simply as:\nAI agent = LLM + tools\n\nAt the same time, there are coding agents on the market that include their own decision loop.\n\nBesides that, the term sub-agents is also widely used.\n\nOn top of this, people often talk about multi-agent systems while meaning different things above by the word agent, which makes the whole topic confusing.",
              "score": 1,
              "created_utc": "2026-01-17 19:30:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05qlxx",
                  "author": "DaRandomStoner",
                  "text": "So let's simplify it... agent = llm + tools\n\nSubagent = agent that gets called by another agent\n\nMulti agent system = a system where multiple agents with their own context windows collaborate.\n\nDecision loops are just something agents can do... like how a while loop is something a python script can do.",
                  "score": 1,
                  "created_utc": "2026-01-17 19:34:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fomu9",
          "author": "hello5346",
          "text": "I prefer the term scripts because there can be more than one llm-agent in a script.",
          "score": 1,
          "created_utc": "2026-01-19 06:42:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tewyt",
              "author": "crionuke",
              "text": "Could you explain why you prefer the term ‚Äúscript‚Äù? For me, the term sounds misleading.",
              "score": 1,
              "created_utc": "2026-01-21 07:19:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0wpq0b",
                  "author": "hello5346",
                  "text": "It is like a shell script. It is a way to refer to multiple llm in a single program.  My point is that as soon as you have two or more llm it is no longer an agent. It is agentic but many agents.",
                  "score": 1,
                  "created_utc": "2026-01-21 19:14:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdd2ds",
      "title": "Are you using any SDKs for building AI agents?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qdd2ds/are_you_using_any_sdks_for_building_ai_agents/",
      "author": "finally_i_found_one",
      "created_utc": "2026-01-15 07:21:29",
      "score": 7,
      "num_comments": 13,
      "upvote_ratio": 0.89,
      "text": "We shipped an ai agent without using any of the agent building SDKs (openai, anthropic, google etc). It doesn't require much maintenance but time to time we find cases where it breaks (ex: gemini 3.x models needed the input in a certain fashion).\n\nI am wondering if any of these frameworks make it easy and maintainable.\n\nHere are some of our requirements:  \n\\- Integration with custom tools  \n\\- Integration with a variety of LLMs  \n\\- Fine grain control over context  \n\\- State checkpointing in between turns (or even multiple times a turn)  \n\\- Control over the agent loop (ex: max iterations)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qdd2ds/are_you_using_any_sdks_for_building_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nzscrqd",
          "author": "saurabhjain1592",
          "text": "One pattern we‚Äôve seen is that most SDKs are optimized for building the agent loop, not for operating it once it becomes stateful and long lived.\n\nThings like checkpointing, loop control, and provider abstraction are necessary but not sufficient once agents start retrying, branching, or touching real systems. At that point, the hard problems show up around partial execution, rollback, and explaining why a step was allowed to proceed.\n\nFrameworks help you get started faster. The production pain tends to appear later, when you need control and auditability rather than more abstractions.",
          "score": 2,
          "created_utc": "2026-01-15 19:50:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt42k3",
              "author": "caprica71",
              "text": "So is langgraph helping here or not really?",
              "score": 1,
              "created_utc": "2026-01-15 21:56:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt926s",
                  "author": "saurabhjain1592",
                  "text": "LangGraph helps with structuring the agent loop and making execution more explicit, which is a real step forward compared to ad-hoc chains.\n\nWhere teams still tend to struggle is once that graph is long-lived and interacting with real systems. Things like enforcing permissions per step, handling partial execution and rollback, or explaining *why* a transition was allowed usually sit outside the framework itself.\n\nIn practice, it reduces complexity at build time, but you still need additional control and observability once the system is running in production.",
                  "score": 1,
                  "created_utc": "2026-01-15 22:20:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzqc7do",
          "author": "mdrxy",
          "text": "LangChain does all of this ;)",
          "score": 3,
          "created_utc": "2026-01-15 14:17:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp68zo",
          "author": "Dan6erbond2",
          "text": "I find an SDK like Vercel's AI SDK a must. Being able to switch providers on the fly is one reason, handling input types uniformly is another. And in the case of Vercel's it also handles structured output and streaming really well. I don't see why I should have to reinvent the wheel.\n\nEdit: As for features the SDK supports custom tools, stopWhen conditions, context control and message shortening and all kinds of hooks to interrupt/change the flow. I haven't had any issues getting it to do what I need.",
          "score": 2,
          "created_utc": "2026-01-15 09:05:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqez3j",
          "author": "FormalAd7367",
          "text": "yea. my next project. will be using google‚Äôs.",
          "score": 1,
          "created_utc": "2026-01-15 14:31:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqgg6x",
          "author": "Reasonable-Life7326",
          "text": "Yeah, frameworks are a lifesaver for this stuff.",
          "score": 1,
          "created_utc": "2026-01-15 14:39:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrcp06",
          "author": "eavanvalkenburg",
          "text": "Agent Framework does all this for both dotnet and python",
          "score": 1,
          "created_utc": "2026-01-15 17:08:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrlfak",
          "author": "Sunchax",
          "text": "No, build my own per project, have used pydentic for some work.\n\nMainly got burned by langchain back in they day and got allergic since then, but maybe things are better now",
          "score": 1,
          "created_utc": "2026-01-15 17:47:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt46mg",
              "author": "caprica71",
              "text": "Just pydantic or pydantic ai?",
              "score": 1,
              "created_utc": "2026-01-15 21:56:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuti9v",
          "author": "abzisse",
          "text": "We tried all agent frameworks (LangChain, n8n, CrewAI and others) and did not find it easy to build agents that actually work. \"Not easy\" because there is a learning curve and they seem to add a lot of boilerplate code and then you still need to code your own tools to make the agent functional, more deterministic etc... So we decided to build [a2abase.ai](http://a2abase.ai/)¬†to make building agents (not just workflow automation) easy with access to all major LLMs, 50+ native tools and 500+ MCP servers all under 1 account.",
          "score": 1,
          "created_utc": "2026-01-16 03:26:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvr2n2",
          "author": "Worldly-Pen-8101",
          "text": "Exploring  dbos . The Lang* packages are too bloated IMO",
          "score": 1,
          "created_utc": "2026-01-16 07:24:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05ct8v",
          "author": "PangolinPossible7674",
          "text": "Most agent-building frameworks satisfy your requirements. Regarding LLMs, I have been using LiteLLM, which provides unified API. So, I only need to swap the model name when required.\n\n\nHowever, crafting a system prompt (for agents, in this case) that works with diverse LLMs can take some effort, like you have noted. I have experienced this while I have been building KodeAgent. If you are looking for a minimal agent engine or just some ideas, you can give it a try:¬†https://github.com/barun-saha/kodeagent",
          "score": 1,
          "created_utc": "2026-01-17 18:29:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj1r2z",
      "title": "Added Git-like versioning to LangChain agent contexts (open source)",
      "subreddit": "LangChain",
      "url": "https://github.com/ultracontext/ultracontext-node",
      "author": "Main_Payment_6430",
      "created_utc": "2026-01-21 15:59:44",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj1r2z/added_gitlike_versioning_to_langchain_agent/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qdztil",
      "title": "Stop building single-shot agents. If your agent can't survive a server restart, it‚Äôs not production-ready.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qdztil/stop_building_singleshot_agents_if_your_agent/",
      "author": "Interesting_Ride2443",
      "created_utc": "2026-01-15 23:41:36",
      "score": 6,
      "num_comments": 15,
      "upvote_ratio": 0.71,
      "text": "Most agents today are just long-running loops. It looks great in a terminal, but it‚Äôs an architectural dead end. If your agent is on step 7 of a 15-step flow and your backend blips or an API times out, what happens? In most cases, it just dies. You lose the state, the tokens, and the user gets ghosted.\n\nWe need to stop treating agents like simple scripts and start treating them like durable workflows. I‚Äôve shifted to a managed runtime approach where the state is persisted at the infra level. If the process crashes, it resumes from the last step instead of restarting from zero.\n\nHow are you guys handling this? Are you building custom DB logic for every single step, or just hoping the connection stays stable?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qdztil/stop_building_singleshot_agents_if_your_agent/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nzvt3wh",
          "author": "AsspressoCup",
          "text": "Finally someone is acknowledging that.\nIt killed me to see frameworks like LangGraph and ADK running workflow nodes in memory and people treat them as production ready.\n\nWe are using a queue + db that records the last thing you executed and it works quite well. Frameworks like temporal should also be good.\n\nBut there are more to production agents than that, depends on the product and customers.\n\nLLM provisioning is hard when you reach certain scale and you must use specific regions and providers.",
          "score": 2,
          "created_utc": "2026-01-16 07:42:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00gmpe",
              "author": "Interesting_Ride2443",
              "text": "exactly. the fact that industry standards still rely on in-memory state is wild.\n\nqueues and dbs work, but the boilerplate for every project is a massive headache. i‚Äôm trying to move that persistence into the runtime itself to kill the manual wiring.\n\nyou‚Äôre also spot on about scaling and provisioning. a working demo is only 10% of the job; the rest is the infra nightmare. that‚Äôs exactly the gap i‚Äôm trying to close.",
              "score": 1,
              "created_utc": "2026-01-16 23:11:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztww41",
          "author": "Illustrious-Film4018",
          "text": "If the process crashes, isn't that a bigger problem?",
          "score": 2,
          "created_utc": "2026-01-16 00:25:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztzbhm",
              "author": "Interesting_Ride2443",
              "text": "crashes, deployments, and network blips are a fact of life in production. even with 99.9% uptime, you are still eventually ghosting users.\n\nthe bigger problem isn't that a process died, it is that when it comes back, the agent has amnesia. high-availability infra doesn't just aim for zero crashes; it ensures that when a failure happens, the work isn't lost. that is the difference between a toy and enterprise-grade software.",
              "score": 2,
              "created_utc": "2026-01-16 00:38:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvmir2",
          "author": "hrishikamath",
          "text": "Temporal, DBOS?",
          "score": 1,
          "created_utc": "2026-01-16 06:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00gexa",
              "author": "Interesting_Ride2443",
              "text": "temporal is definitely solid, but it feels too heavy and complex for most ai tasks. i wanted to move away from that kind of monster setup toward something more lightweight and native for ts developers.\n\nthe goal is to have that same reliability and durable execution but without the steep learning curve of a massive framework. it should be as simple as writing regular typescript where the system just handles the state for you. basically, taking the best parts of workflow engines and tailoring them specifically for agents so you don't spend weeks on infra setup.",
              "score": 2,
              "created_utc": "2026-01-16 23:09:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o01aa8i",
                  "author": "hrishikamath",
                  "text": "Interesting, maybe you found a problem to solve :) if you are building it open source drop the url. (It should be given devs expect it)",
                  "score": 1,
                  "created_utc": "2026-01-17 02:07:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o02q7e0",
                  "author": "jedberg",
                  "text": "> the goal is to have that same reliability and durable execution but without the steep learning curve of a massive framework. it should be as simple as writing regular typescript where the system just handles the state for you.\n\n[DBOS](https://github.com/dbos-inc/dbos-transact-ts) was built with exactly these constraints in mind.  You may want to check it out before you go too far down the rabbit hole of building it yourself. :)",
                  "score": 1,
                  "created_utc": "2026-01-17 08:41:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o01i03v",
          "author": "Khade_G",
          "text": "Yeah I think it‚Äôs best not to rely on a single long-running loop. I‚Äôd make the agent replayable: persist state after each step (or after each tool call), give every step an idempotency key, and design it so you can resume from step 7 without guessing what happened. That can be as simple as writing a state blob + events to Postgres, or as structured as an event-sourced log.\n\nAlso it helps to think of the agent as more of a workflow vs. a process. The runtime can crash, but the workflow keeps going because the next step is driven by stored state + a queue/worker, not by one fragile thread. Timeouts become normal - retry with backoff, or fall back to a human/handoff state.\n\nSo I‚Äôd hope most serious teams aren‚Äôt hoping the connection stays stable. They‚Äôre either using a workflow engine pattern (queue + persisted state) or adopting frameworks that give you durable execution semantics. If you have a minimal setup: Postgres for state, a job queue for steps, and strict logging of tool calls is already enough to get you a decent amount of durability.",
          "score": 1,
          "created_utc": "2026-01-17 02:56:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o57pj",
              "author": "Interesting_Ride2443",
              "text": "you nailed it. treating it as a durable workflow rather than a thread is the only way to get out of the \"toy agent\" stage.\n\nthe challenge i see is that even with postgres and a job queue, most teams end up writing a massive amount of glue code to handle the \"replay\" logic for every new agent. you have to manually map the tool outputs, manage the message history, and ensure the llm context stays in sync with your event log.\n\ni am trying to abstract that away so the \"state blob + event log\" happens automatically at the runtime level. you write typescript, and the infra ensures it's replayable and idempotent by default. it shouldn't be a choice between a fragile loop or weeks of building custom postgres-backed orchestration.",
              "score": 1,
              "created_utc": "2026-01-20 14:20:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o06end2",
          "author": "pyhannes",
          "text": "Good point. That's why I'm betting on Prefect for workflows, caching and retries, PydanticAI for the agents. It's a good duo.",
          "score": 1,
          "created_utc": "2026-01-17 21:36:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5jur",
              "author": "Interesting_Ride2443",
              "text": "prefect and pydanticai are a strong combo if you are deep in the python ecosystem. but for teams building saas products on typescript, bringing in a heavy python stack just for agent orchestration often adds too much friction to the deployment and local development.\n\ni‚Äôm focusing on bringing that same level of durability and structured logic directly to the typescript ecosystem. the goal is to have those retries and state persistence feel like a native part of the backend code, not a separate system you have to bridge over.\n\nit is all about reducing the \"infrastructure tax\" for teams who want to stay within one language and one execution model.",
              "score": 1,
              "created_utc": "2026-01-20 14:22:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qinxsi",
      "title": "Advanced AI Program which also covers Langchain",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "author": "soundboardwithme",
      "created_utc": "2026-01-21 04:18:38",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hello Folks,\n\nI am not sure if this is the right sub, please be kind towards me if this is not the right sub.\n\nI have been really unwell and having health complications, due to which I am unable to continue my enrollment for an Advanced AI program. It's duration is 3 month and the investment is $ 700 \n\nI am in Eastern Standard Time ( EST ) and this program happens every weekend 11 AM To 2 PM IST, which is during midnight hours for me.\n\nIf I attend these LIVE sessions during midnight EST, I will increase the risk of cardio vascular disease, and I might fall dead because of my health situation. It's an intensive program, with clear learning outcomes.\n\nI tried to get a refund for this enrollment, but they would not agree to it, inspite of my risky health situation. All they could offer is swap my enrollment if I manage to find a person to join this program.\n\nThis is a sincere request and I apologize if I am posting in the wrong sub.\n\nAlso, I am not trying to promote this program in any way but I know that it's a good program for those who want to learn Agentic AI and build products.\n\nIf anyone is interested to learn and ready to take a look, I will be happy to ping you the details for consideration and help me swap the enrollment.\n\nHonestly, I am broke and my health situation is bad.\n\nAll I am trying to do is,heal and survive for the next few months.\n\nI have to prioritize my heath and my career goals have changed.\n\nAnd I only have a few months of savings left.\n\nPlease, this is a request to help me in any way possible.\n\nI was very hesistant to seek here for help.\n\nBecause of my health situation my plans have changed.\n\nHappy to DM you the details.\n\nIt's only one Spot.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qg98n5",
      "title": "Stopped choosing between LangGraph and Claude SDK - using both solved my multi-agent headaches",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qg98n5/stopped_choosing_between_langgraph_and_claude_sdk/",
      "author": "Realistic-Quarter-47",
      "created_utc": "2026-01-18 13:57:50",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Spent weeks going back and forth. LangGraph for workflow control or Claude SDK for agent execution? Each had trade-offs that frustrated me.\n\nLangGraph gave me great routing and state management but fighting its agent loop felt wrong. Claude SDK made agents easy but I lost visibility into the workflow.\n\nThe fix: stop choosing. Use both.\n\nLangGraph handles orchestration - what runs when, conditional branching, state between nodes. Claude SDK handles agent execution inside each node - reasoning, tool calling, context.\n\nThey operate at different levels. Once I saw that, everything clicked.\n\nWrote up the pattern with working code: [article](https://www.khaledelfakharany.com/articles/langgraph-claude-sdk-integration?utm_source=reddit&utm_medium=social&utm_campaign=langgraph-claude-sdk&utm_content=langchain)\n\nBonus: I can now use different models per node. Haiku for quick decisions, Sonnet for analysis. Couldn't do that easily before.\n\nAnyone else running hybrid setups like this?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qg98n5/stopped_choosing_between_langgraph_and_claude_sdk/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0go69i",
          "author": "shivmohith8",
          "text": "This actually makes sense because LangGraph is more like a directed cyclic graph framework that has some features specially made for AI applications and Claude Code sdk is made for agentic loop.",
          "score": 2,
          "created_utc": "2026-01-19 12:02:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oc7j9",
              "author": "Realistic-Quarter-47",
              "text": "the combination is just insane, I couldn't hold it",
              "score": 1,
              "created_utc": "2026-01-20 14:56:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0oamn8",
          "author": "Hey-Intent",
          "text": "I was planning to test this, thanks for sharing and for the time saved.",
          "score": 2,
          "created_utc": "2026-01-20 14:48:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ockww",
              "author": "Realistic-Quarter-47",
              "text": "You find this integration really useful, here is also a [workshop](https://www.khaledelfakharany.com/workshops/due-diligence?utm_source=reddit&utm_medium=social&utm_campaign=langgraph-claude-sdk&utm_content=langchain) that I did. it's free but I would appreciate your feedback.",
              "score": 1,
              "created_utc": "2026-01-20 14:58:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rw0w2",
          "author": "rshah4",
          "text": "I like this idea as well. I wonder if langgraph deep agents will better support this approach. It seems to make sense to take advantage of claude agents ability to work with files and code.",
          "score": 1,
          "created_utc": "2026-01-21 01:13:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfprm4",
      "title": "Open-sourced a RAG pipeline (Voyage AI + Qdrant) optimized for AI coding agents building agentic systems",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfprm4/opensourced_a_rag_pipeline_voyage_ai_qdrant/",
      "author": "PurpleCollar415",
      "created_utc": "2026-01-17 21:42:58",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "I've been working on a retrieval pipeline specifically designed to ground AI coding agents with up-to-date documentation and source code from major agentic frameworks.  \n  \n  \nA hybrid RAG setup tuned for code + documentation retrieval:  \n  \n  \n\\- Separate embedding models for docs (voyage-context-3) and code (voyage-code-3) - single models underperform on mixed content  \n\\- Hybrid retrieval: dense semantic search + sparse lexical (SPLADE++) with server-side RRF fusion  \n\\- Coverage balancing ensures results include both implementation code and conceptual docs  \n\\- Cross-encoder reranking for final precision  \n  \n  \nCurrently indexed (\\~14.7k vectors):  \n\\- Google ADK (docs + Python SDK)  \n\\- OpenAI Agents SDK (docs + source)  \n\\- LangChain / LangGraph / DeepAgents ecosystem  \n  \n  \nTwo use cases:  \n1. Direct querying - Get current references on any indexed framework  \n2. Workflow generation - 44 IDE-agnostic workflows for building ADK agents (works with Cursor, Windsurf, Antigravity, etc.)  \n  \n  \nActively maintained - I update the indexed corpora frequently as frameworks evolve.  \n  \n  \nRoadmap:  \n\\- Additional framework SDKs (CrewAI, AutoGen, etc.)  \n\\- Claude Code custom commands and hooks  \n\\- Codex skills integration  \n\\- Specialized coding sub-agents for different IDEs  \n  \n  \nEasy to add your own corpora - clone a repo, add a config block, run ingest.  \n  \n  \nGitHub: [https://github.com/MattMagg/adk-workflow-rag](https://github.com/MattMagg/adk-workflow-rag)  \n  \n  \nFeedback welcome, especially on which frameworks to prioritize next.",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfprm4/opensourced_a_rag_pipeline_voyage_ai_qdrant/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qgupfn",
      "title": "How to build Poke-like fast, multi-message AI replies",
      "subreddit": "LangChain",
      "url": "http://poke.com",
      "author": "Neat_Sun_1235",
      "created_utc": "2026-01-19 04:46:37",
      "score": 4,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qgupfn/how_to_build_pokelike_fast_multimessage_ai_replies/",
      "domain": "poke.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0fbf4p",
          "author": "ButterscotchVast2948",
          "text": "Could they perhaps queue multiple messages up at once and give the illusion of ‚Äúinstant‚Äù follow up messages?",
          "score": 1,
          "created_utc": "2026-01-19 05:00:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j3xq7",
          "author": "Oddly_Even_Pi",
          "text": " Following",
          "score": 1,
          "created_utc": "2026-01-19 19:24:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lcaac",
          "author": "qa_anaaq",
          "text": "Maybe they have small open source models trained and deployed on their own servers, which would make responses quite fast when compared to using another provider‚Äôs sdk. ChatGPT is very fast but I don‚Äôt think it‚Äôs anything other than the fact that they own their deployments.",
          "score": 1,
          "created_utc": "2026-01-20 02:12:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}