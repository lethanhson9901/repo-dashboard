{
  "metadata": {
    "last_updated": "2026-01-25 16:49:57",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 35,
    "file_size_bytes": 80742
  },
  "items": [
    {
      "id": "1qgekmg",
      "title": "fastapi-fullstack v0.1.15 released ‚Äì now with DeepAgents (LangChain's multi-agent framework) + HITL support!",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qgekmg/fastapifullstack_v0115_released_now_with/",
      "author": "VanillaOk4593",
      "created_utc": "2026-01-18 17:27:05",
      "score": 21,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hey r/LangChain,\n\nQuick recap for new folks: fastapi-fullstack is an open-source CLI generator (pip install fastapi-fullstack) that creates production-ready full-stack AI/LLM apps with FastAPI backend + optional Next.js 15 frontend. It supports PydanticAI, LangChain, LangGraph, CrewAI ‚Äì and now DeepAgents for advanced multi-agent systems.\n\n**v0.1.15 just released with full DeepAgents integration:**\n\n**Added:**\n\n* **DeepAgents as the fifth AI framework option** ‚Äì new --ai-framework deepagents CLI flag\n* Built-in tools for file ops (ls/read/write/edit/glob/grep), code execution (disabled by default for safety), and task management (todos/sub-agents)\n* StateBackend for in-memory file state\n* Skills support via DEEPAGENTS\\_SKILLS\\_PATHS env var\n\n**Human-in-the-Loop (HITL) features:**\n\n* Tool approval workflow: Users can approve/edit/reject tool calls (configurable via DEEPAGENTS\\_INTERRUPT\\_TOOLS)\n* Frontend dialog for reviewing/editing JSON args in real-time\n* WebSocket protocol for interrupts: Backend sends tool\\_approval\\_required, frontend responds with resume decisions\n\n**Fixed & improved:**\n\n* Type annotations across CrewAI handlers (from previous updates)\n* WebSocket disconnect handling during agent processing\n* Frontend timeline connectors and message grouping\n* 100% test coverage (720 statements, 0 missing) with tests for all DeepAgents events, stream edges, and disconnects\n\nThis makes building and deploying DeepAgents-powered apps (with HITL for safe, controlled execution) super straightforward ‚Äì perfect for complex, filesystem-aware agents.\n\nFull changelog: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md)  \nRepo: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template)\n\nLangChain community ‚Äì how does DeepAgents + HITL fit your multi-agent projects? Any features to add? Contributions welcome! üöÄ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qgekmg/fastapifullstack_v0115_released_now_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0d557i",
          "author": "vtrivedy-lc",
          "text": "this is awesome! basically breathe fastapi and deepagents these days so love to see this :)\n\nif there‚Äôs any way we can make deepagents easier to dev on, would love to hear it!",
          "score": 2,
          "created_utc": "2026-01-18 21:52:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ol9so",
          "author": "Difficult-Suit-6516",
          "text": "Nice üëçüèª Would Love to see LangChain + OpenRouter Integration as those are my poison of choice right now",
          "score": 1,
          "created_utc": "2026-01-20 15:41:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk2cv0",
      "title": "Could this architectural shift finally solve the \"Agent Reliability\" problem?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "author": "sophieximc",
      "created_utc": "2026-01-22 18:24:39",
      "score": 17,
      "num_comments": 7,
      "upvote_ratio": 0.84,
      "text": "As LangChain devs, we spend half our time writing OutputParsers, retry logic, and guardrails because LLMs are fundamentally probabilistic - they don't \"know\" they broke a constraint, they just guessed a token.\n\nI‚Äôve been reading up on the new wave of [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models) (backed by LeCun), and the implication for Agents is huge.\n\nUnlike Transformers that generate text left-to-right (and often paint themselves into a corner), an EBM minimizes an \"energy function\" at inference time. It basically verifies if the output meets the constraints (like \"Must be valid JSON\" or \"Must not contradict previous step\") before returning the result.\n\nIf this works at scale, we might finally get agents that can handle complex multi-step logic without needing a dozen error-handling loops.\n\nCurious if anyone sees this replacing the current RAG/Chain-of-Thought meta for strict logic tasks?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o13k2t9",
          "author": "Better_Dress_8508",
          "text": "I'm afraid you are extrapolating too far. EBM-s are not deterministic either",
          "score": 2,
          "created_utc": "2026-01-22 19:06:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13olgo",
              "author": "sophieximc",
              "text": "They are still probabilistic - you're sampling from a distribution, not running a script.  \n  \nBut the inference dynamic is different. Instead of just rolling the dice once per token (autoregressive), you're iteratively refining the output to lower the energy. It‚Äôs less about being deterministic and more about having a native mechanism to \"reject\" nonsense before finalizing the output.",
              "score": 0,
              "created_utc": "2026-01-22 19:26:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o14a1vs",
          "author": "met0xff",
          "text": "You can use constrained generation using something like xgrammar or outlines for the json problem",
          "score": 1,
          "created_utc": "2026-01-22 21:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15hrda",
          "author": "USToffee",
          "text": "It's how I'm writing my agent. It basically has a semantic binding step at the start that determines what kind of artifacts it expects and only gives an answer if the tool calls satisfy this. At this point I'm not sure if it's any better or not. It still requires the LLM to guess what artifacts are needed from the prompt.",
          "score": 1,
          "created_utc": "2026-01-23 00:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bhy3m",
          "author": "pbalIII",
          "text": "So the real question is whether the inference-time optimization loop scales without blowing up latency. Logical Intelligence just announced Kona 1.0 with LeCun on the board, and their pitch is exactly this... learning by correcting mistakes rather than guessing tokens.\n\nThe catch is EBTs need to be trained from scratch. You can't fine-tune an existing foundation model into one. That's a brutal cold start when every team already has GPT-4 wrappers in production.\n\nFor strict JSON, constrained decoding (xgrammar, outlines) already solves it deterministically without the architecture swap. The interesting unlock would be multi-step logical consistency across tool calls, where autoregressive models keep painting themselves into corners. Still waiting to see benchmarks on that before swapping out the retry loops.",
          "score": 1,
          "created_utc": "2026-01-23 22:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13hgo0",
          "author": "Educational-Bison786",
          "text": "EBMs are definitely an interesting shift for agent reliability. While they might reduce some issues, I doubt they'll fully replace the need for robust evaluation and guardrails. You'll still want tools like Pydantic for strict schema validation. For comprehensive agent quality and measuring improvements, platforms like [Maxim AI](https://www.getmaxim.ai/) are crucial. Also don't forget solid prompt engineering.",
          "score": 0,
          "created_utc": "2026-01-22 18:54:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13od1f",
              "author": "sophieximc",
              "text": "Agreed, validation (like Pydantic) isn't going anywhere. But right now, we use guardrails to catch errors after they happen (and then trigger expensive retries). The promise of EBMs is that the model wouldn't generate the error in the first place because it contradicts the \"energy\" state. I want validation to be a safety net, not the main control loop",
              "score": 1,
              "created_utc": "2026-01-22 19:25:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qi5rmu",
      "title": "Deep Agents pattern: planning, delegation, file based state (wired up with CopilotKit)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qi5rmu/deep_agents_pattern_planning_delegation_file/",
      "author": "pfthurley",
      "created_utc": "2026-01-20 16:29:34",
      "score": 16,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Most agents today are just ‚ÄúLLM in a loop + tools‚Äù. They are good at reasoning and works fine for short tasks. Over long-running tasks, they usually have no plan, lose context and their execution gets messy.\n\nMore capable agents like Claude Code and Manus get around this by following a common pattern: they plan first, externalize working context (files) and break work into isolated sub-tasks.\n\nDeep Agents from LangChain are really the next level, which essentially package this pattern into a reusable runtime. you call `create_deep_agent(...)` and get a StateGraph that:\n\n* plans explicitly\n* delegates work to sub-agents\n* keeps its state in files instead of bloating the prompt\n\nEach piece is implemented as middleware (To-do list middleware, Filesystem middleware, Subagent middleware).\n\nConceptually it looks like this:\n\n    User goal\n      ‚Üì\n    Deep Agent (LangGraph StateGraph)\n      ‚îú‚îÄ Plan: write_todos ‚Üí updates \"todos\" in state\n      ‚îú‚îÄ Delegate: task(...) ‚Üí runs a subagent with its own tool loop\n      ‚îú‚îÄ Context: ls/read_file/write_file/edit_file ‚Üí persists working notes/artifacts\n      ‚Üì\n    Final answer\n\nIt push key parts into explicit state (e.g. `todos` \\+ files + messages), but the main thing I noticed was visibility over frontend.\n\nI wired it up with CopilotKit - Infrastructure for building AI copilots into any app.\n\nIt keeps the frontend in sync with what the agent is doing by streaming events and state updates in real time (using AG-UI protocol under the hood).\n\nDeep Agents is really good at multi-step workflows & CopilotKit as the orchestration + UI layer. Check out the \"Job search assistant\" demo using this pattern.\n\nGitHub Repo: [https://github.com/CopilotKit/copilotkit-deepagents](https://github.com/CopilotKit/copilotkit-deepagents)  \nTutorial: [https://www.copilotkit.ai/blog/how-to-build-a-frontend-for-langchain-deep-agents-with-copilotkit](https://www.copilotkit.ai/blog/how-to-build-a-frontend-for-langchain-deep-agents-with-copilotkit)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qi5rmu/deep_agents_pattern_planning_delegation_file/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qji1cc",
      "title": "LangChain + OpenWork + Docling + Milvus Holy Grail Setup",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qji1cc/langchain_openwork_docling_milvus_holy_grail_setup/",
      "author": "Clay_Ferguson",
      "created_utc": "2026-01-22 02:21:45",
      "score": 16,
      "num_comments": 3,
      "upvote_ratio": 0.91,
      "text": "Hi guys. I was wondering if anyone knows of an open source project that incorporates the following technologies into a single RAG solution that people can just simply install and run. What I'm referring to here is a kind of \"Chat with your Documents\" type feature, where you scan a bunch of documents and then you can have a conversation with an AI about the documents (basic RAG).\n\n\n\n>\\* Openwork (LangChain Chat System, with Electron GUI Front end)\n\n>\\* Docling for Doc loading\n\n>\\* Milvus Vector DB  \n\n\n\n\nThis seems to be the holy grail that everyone is currently building right now (RAG systems), and I don't know if there's a popular project yet that incorporates all of the above into a single system people can just run without having to put together all the components themselves. When Openwork was recently released, that gets us 90% of the way to the finish line, but we just need a project that adds Docling and Milvus to finish it. It might be good to have a Docker Compose-base solution to this since there's several independent technologies that we're putting together.\n\n\n\nAny thoughts or ideas anyone has are greatly appreciate it. Thanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qji1cc/langchain_openwork_docling_milvus_holy_grail_setup/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0zfbhc",
          "author": "Hot_Substance_9432",
          "text": "Something like this? [https://zilliz.com/blog/build-rag-with-langchain-milvus-and-strapi](https://zilliz.com/blog/build-rag-with-langchain-milvus-and-strapi)",
          "score": 4,
          "created_utc": "2026-01-22 03:32:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zr28x",
              "author": "Clay_Ferguson",
              "text": "Not Strapi tho, but Openwork.",
              "score": 1,
              "created_utc": "2026-01-22 04:47:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0zvbcf",
          "author": "Hot_Substance_9432",
          "text": "Almost:)  [https://milvus.io/docs/build\\_RAG\\_with\\_milvus\\_and\\_docling.md](https://milvus.io/docs/build_RAG_with_milvus_and_docling.md)",
          "score": 2,
          "created_utc": "2026-01-22 05:16:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjm96c",
      "title": "Multi-agents breakthrough",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "author": "crionuke",
      "created_utc": "2026-01-22 05:41:20",
      "score": 16,
      "num_comments": 11,
      "upvote_ratio": 0.83,
      "text": "ChatGPT and similar models have become universal tools, which is why they so quickly entered the daily lives of millions of people. We use them to search for information, work with text, learn new topics, and hold discussions.  \n  \nHowever, chats themselves are not agents. They cannot operate in the real or digital world: they do not make decisions, execute chains of tasks, interact with services, or carry work through to completion.  \n  \nFor this reason, companies have begun building their own agent and multi-agent systems. These systems help users apply for loans, buy tickets, plan vacations, or complete paperwork.  \n  \nBut almost all such solutions remain narrowly specialized. Each agent is tightly bound to predefined scenarios and cannot go beyond the logic embedded by its creators.  \n  \nBecause of this, the next major technological breakthrough will likely be the emergence of universal agent systems accessible to ordinary users.  \n  \nExternally, they may look almost the same: a familiar chat interface with a bot. Internally, however, they will represent complex self-organizing systems composed of many agents, capable of understanding user goals, autonomously building plans, selecting tools, and adapting to changing conditions.  \n  \nIn essence, this marks a transition from ‚Äúanswering prompts‚Äù to digital assistants that can act ‚Äî and may even possess their own form of intent within the boundaries of achieving the user‚Äôs goals, rather than merely reacting to commands.  \n  \nGiven the current pace of development in large language models and agent frameworks, it is entirely possible that the first truly universal multi-agent systems will appear by the end of 2026.\n\n  \n**What are your thoughts on the next breakthrough in our field?**",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o103070",
          "author": "ChanceKale7861",
          "text": "Yep! I‚Äôm about to go FOSS with a 20 agent system of rust and python agents so we power users aren‚Äôt bound to API bullshit.",
          "score": 3,
          "created_utc": "2026-01-22 06:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10vgpt",
              "author": "crionuke",
              "text": "Interesting,\n\nis there anything you can share that we can already play with?",
              "score": 2,
              "created_utc": "2026-01-22 10:32:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12akg1",
                  "author": "ChanceKale7861",
                  "text": "I actually just finished that up yesterday, and myself along with 10-15 folks across business, SWE, enterprise architecture, etc. lots of folks I know have been working on projects, so, rolling to them first, and then if they are happy with where it‚Äôs at, I‚Äôm going to launch the website, and the tool. so, yes, but maybe in a week or two? need to ensure the things like file intake and generation work as designed, as well as whether the aspects like security and auditor agents orchestrate as designed and tested so far. Or like, for the folks I know in like recruiting, or sales, does it truly automate an aspects for them, like it has me. Which is where this stemmed from a couple weeks back.",
                  "score": 2,
                  "created_utc": "2026-01-22 15:42:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11a1mg",
          "author": "Number4extraDip",
          "text": "You misunderstand agents and infrastructure. There is no such thing as disembodied ai. Agents have specific architecture and defining components.\n\nYou wanna ground ai? Ground them in realtime data and telemetry\n\n[all ai is robotics](https://youtube.com/shorts/wTY2mY3XF1Y?si=QpiqBlUIK3WqNzNu)\n\nAnd multi agent systems are not complex if you think about it\n\n[heres a plug and play one copy pasta](https://github.com/vNeeL-code/ASI)",
          "score": 3,
          "created_utc": "2026-01-22 12:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10vs73",
          "author": "fabkosta",
          "text": "All of this is not new, the fantasies about such systems have been there 25 years ago. Just go pick up any book or article on muli-agent-systems from the early 2000s. What has changed today that, suddenly and miraculously, such systems can become true, although they could not 25 years ago? LLMs? GenAI? That's not enough, a lot more is required - and we did not solve the issues 25 years ago with other technology neither.\n\nIt's wild to see that nobody seems to want to learn anything from history.",
          "score": 2,
          "created_utc": "2026-01-22 10:35:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13h9cw",
          "author": "Aggressive_Bed7113",
          "text": "This post can be much shorter with only the last paragraph or last sentence.\n\nThis title made me think op will present some real breakthroughs, but it turns out the person has no idea either. Duh\n\nWhy do I want a universal agent that does mediocre stuffs in everything than a specialized agent in things I only care about?!",
          "score": 1,
          "created_utc": "2026-01-22 18:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13hrlg",
              "author": "crionuke",
              "text": "Nobody has",
              "score": 1,
              "created_utc": "2026-01-22 18:55:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o13i4l5",
                  "author": "Aggressive_Bed7113",
                  "text": "Then what‚Äôs the point of posting this?",
                  "score": 1,
                  "created_utc": "2026-01-22 18:57:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ahysn",
          "author": "LairBob",
          "text": "This is just ill-informed rambling.",
          "score": 1,
          "created_utc": "2026-01-23 19:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10u9do",
          "author": "PopPsychological4106",
          "text": "Wdym by \"truly universal\"?",
          "score": 0,
          "created_utc": "2026-01-22 10:21:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10v7xi",
              "author": "crionuke",
              "text": "I don‚Äôt have a one word term for this, but imagine systems capable of generating agent skills on the fly to handle a user request, even if those skills don‚Äôt exist beforehand, and refining them through a trial-and-error loop: develop ‚Üí test ‚Üí improve ‚Üí ‚Ä¶ ‚Üí use for the user‚Äôs task.",
              "score": 1,
              "created_utc": "2026-01-22 10:30:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qj9qms",
      "title": "Solved rate limiting on our agent workflow with multi-provider load balancing",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "author": "llamacoded",
      "created_utc": "2026-01-21 20:46:50",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "We run a codebase analysis agent that takes about 5 minutes per request. When we scaled to multiple concurrent users, we kept hitting rate limits; even the paid tiers from DeepInfra, Cerebras, and Google throttled us too hard. Queue got completely congested.\n\nTried Vercel AI Gateway thinking the endpoint pooling would help, but still broke down after \\~5 concurrent users. The issue was we were still hitting individual provider rate limits.\n\nTo tackle this we deployed an LLM gateway (Bifrost) that automatically load balances across multiple API keys and providers. When one key hits its limit, traffic routes to the others. We set it up with a few OpenAI and Anthropic keys.\n\nIntegration was just changing the base\\_url in our OpenAI SDK call. Took maybe 15-20 min total.\n\nNow we're handling 30+ concurrent users without throttling. No manual key rotation logic, no queue congestion.\n\nGithub if anyone needs:¬†[https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0xn3ti",
          "author": "Mishuri",
          "text": "Or just use open router?",
          "score": 2,
          "created_utc": "2026-01-21 21:46:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xcho0",
          "author": "DanceWithEverything",
          "text": "Can I use a Claude max sub to oauth myself a token?",
          "score": 1,
          "created_utc": "2026-01-21 20:57:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk85pb",
      "title": "I built a system for generating and operating modular AI-enabled FastAPI apps after doing this for clients over and over",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qk85pb",
      "author": "Challseus",
      "created_utc": "2026-01-22 21:59:02",
      "score": 12,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk85pb/i_built_a_system_for_generating_and_operating/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1ql3ufd",
      "title": "Langchain In production",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "author": "niklbj",
      "created_utc": "2026-01-23 21:39:55",
      "score": 12,
      "num_comments": 26,
      "upvote_ratio": 0.88,
      "text": "HI guys, i've realized a lot of us are using langchain or building agents in some of personal or official projects that are in prod. Wanted to start a discord server specific for those of us who are building AI and agent applications in prod to talk about any issues, suggestions, or advice.\n\nHere's the server: [https://discord.gg/qJVQgX2z](https://discord.gg/qJVQgX2z). Feel free to join!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1bh85l",
          "author": "HawkingsLovechild",
          "text": "Langchain is neither lightweight nor mature enough to be dependable in production in my experience. Works fine for POCs but I would reject any PR that attempts to add it to our stack.\n\nEdit: I just checked and installing langchain installed 32 packages, taking 20mb.\n\n  \nEdit2: OP has had half a dozen posts removed in the last month for spam promoting some B2B saas LLM nonsense across various subreddits . Go build a product people actually wanna use bro.",
          "score": 11,
          "created_utc": "2026-01-23 22:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1biayp",
              "author": "AdditionalWeb107",
              "text": "I am generally framework-averse. The tight coupling, lack of interoperability between other frameworks, and no clear separation of concerns makes we very weary. For example, I am not sure why I am left to my own devices to solve all the plumbing work vs. it being implemented via some standards-based infrastructure.\n\nEdit; Talking about decoupling and separating plumbing from business logic https://github.com/katanemo/plano",
              "score": 4,
              "created_utc": "2026-01-23 22:05:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bp64c",
                  "author": "HawkingsLovechild",
                  "text": "I don't think Langchain is a dead project or anything, I love the enthusiasm. But I wouldn't have used FFMPEG in 2004. Nor would I trust this open source project at this point in its lifecycle, especially when the core - the web APIs it basically wraps, could and do change on a dime.\n\n  \nNone of this applies if you're building personal projects, but if you have thousands of users paying you money, it's a different story.",
                  "score": 3,
                  "created_utc": "2026-01-23 22:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bi6hj",
              "author": "niklbj",
              "text": "Interesting, i've seen a ton of startups especially in the earlier days - series A and before building agents using langchain but that makes sense. What framework do you guys use?\n\nRegardless, just updated server to be framework agnostic! It's now just about building and scaling agents in production",
              "score": 2,
              "created_utc": "2026-01-23 22:05:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bjxcz",
                  "author": "HawkingsLovechild",
                  "text": "I am in a startup myself as the tech lead. We don't need LLM frameworks. We write code that calls the APIs. They already did the hard work. Everything Langchain does you can do yourself in a hilariously short amount of time, with more control, tailored to your business needs. \n\n  \nI don't mean to sound like a dick but I genuinely have no idea what Langchain is solving for people. What problem does your company have that you determined it was easier to use Langchain for?",
                  "score": 3,
                  "created_utc": "2026-01-23 22:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1fjbnf",
              "author": "pizzababa21",
              "text": "I dont understand why 20mb is a problem",
              "score": 2,
              "created_utc": "2026-01-24 14:36:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d7btv",
              "author": "cuba_guy",
              "text": "Pretty tight ship over there, our nodejs monorepo has 8gb of node_modules and goes to prod multiple times a day :)",
              "score": 1,
              "created_utc": "2026-01-24 03:44:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1imizm",
              "author": "BurritoBashr",
              "text": "my company uses LangChain/Graph in production with LangSmith. It's a popular artisan shopping site",
              "score": 1,
              "created_utc": "2026-01-24 23:12:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bi7ze",
              "author": "usernotfoundo",
              "text": "What's the alternative to it? Is it not dependable because further updates could lead to currently implemented features being deprecated?",
              "score": 1,
              "created_utc": "2026-01-23 22:05:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bj5bo",
                  "author": "HawkingsLovechild",
                  "text": "Using the API provided by the LLM developers and writing your own wrapping code around it. It's not particularly difficult - I maintain such a system for my company and it's a single python library with the SDKs in question and the requests library. I also get greater control and can respond to updates to say, openAI the day they're rolled out rather than waiting. \n\n  \nWhat features does langchain provide you that you can't write yourself? It's not a particularly complicated package.",
                  "score": 8,
                  "created_utc": "2026-01-23 22:09:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1dbiyl",
          "author": "code_vlogger2003",
          "text": "Hey hi guys,  i already shipped the react style multi agents in the production using the langchain and it's currently serving in the production. Ok high level the end product of the pipeline is a detailed report which contains text, images and tables etc based on unstructured raw time series data. For the control and monitoring I have debugged their call backs and written detailed functions for precise calculation that match with manual calculation. This monitoring helps us to understand the costs of the api and believe me that on average for one detailed report it takes around 0.15 $ which the report includes the multi model calls too.",
          "score": 2,
          "created_utc": "2026-01-24 04:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bdiv6",
          "author": "AdditionalWeb107",
          "text": "This is cool - shouldn't the Langchain guys host and moderate this type of discord themselves?",
          "score": 1,
          "created_utc": "2026-01-23 21:43:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bh18a",
              "author": "mdrxy",
              "text": "We have a community slack! https://www.langchain.com/join-community",
              "score": 3,
              "created_utc": "2026-01-23 21:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bi7fy",
                  "author": "niklbj",
                  "text": "that's sick!",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bdv1e",
              "author": "niklbj",
              "text": "totally open to them doing so if anybody from Langchain wants to help moderate it! didn't see something like this out there, so thought I'd create one and handle it for now",
              "score": 2,
              "created_utc": "2026-01-23 21:44:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bevvc",
                  "author": "AdditionalWeb107",
                  "text": "I use stock python - so this wouldn't be a great fit for me personally, but I see the value. Thanks for creating it OP",
                  "score": 2,
                  "created_utc": "2026-01-23 21:49:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1bj5i5",
          "author": "peejay2",
          "text": "I fw agno",
          "score": 0,
          "created_utc": "2026-01-23 22:09:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhqw4u",
      "title": "AIMUG Builders Podcast - LangGraph orchestration w/ AWS agent core",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qhqw4u/aimug_builders_podcast_langgraph_orchestration_w/",
      "author": "colinmcnamara",
      "created_utc": "2026-01-20 04:11:26",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Quick share for builders: Ep.6 digs into diffusion-model roots, then gets practical‚ÄîLangChain/LangGraph orchestration, ‚Äúskills‚Äù as a framework for agent workflows, context engineering, and production gotchas (incl. AWS agent core talk).   \nVideo if useful: [https://youtu.be/iSL-K4ytQNI?utm\\_source=Reddit&utm\\_medium=social&utm\\_campaign=members](https://youtu.be/iSL-K4ytQNI?utm_source=Reddit&utm_medium=social&utm_campaign=members)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qhqw4u/aimug_builders_podcast_langgraph_orchestration_w/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qhxuzz",
      "title": "LangSmith Agent Builder + MCP: What worked, what broke, and how I finally got MCP tools to show up",
      "subreddit": "LangChain",
      "url": "https://composio.dev/blog/how-to-langsmith-agent-builder",
      "author": "cyber_harsh",
      "created_utc": "2026-01-20 10:43:41",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qhxuzz/langsmith_agent_builder_mcp_what_worked_what/",
      "domain": "composio.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o0o7p64",
          "author": "sharsha315",
          "text": "That was a great insight. Thanks for sharing.",
          "score": 2,
          "created_utc": "2026-01-20 14:33:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o95rc",
              "author": "cyber_harsh",
              "text": "Welcome , I hope it's fixed soon, For now this is the answer from the founder himself.\n\nhttps://preview.redd.it/55rej0alnieg1.png?width=1080&format=png&auto=webp&s=95b2ee95fe0ac739571566b2c097716118ace58f",
              "score": 2,
              "created_utc": "2026-01-20 14:41:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qkknp3",
      "title": "what are some suggestions you have on minimizing silent failures with langchain?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkknp3/what_are_some_suggestions_you_have_on_minimizing/",
      "author": "niklbj",
      "created_utc": "2026-01-23 07:41:22",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.9,
      "text": "sometimes our agents in prod seem to take some, for a lack of better terms, *interesting* decisions and then other times its a couple bad responses that causes a constant back and forth with users until it eventually gets to the right response. but usually our users don't report it because they're not outright failures and sometimes they go under the radar. \n\ndo you guys do something right now, any flows to best handle these situations? My assumption is it just about continuously tuning the prompts and then adaptign the code. Thinking of setting up observability as well!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkknp3/what_are_some_suggestions_you_have_on_minimizing/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o17aqw7",
          "author": "saurabhjain1592",
          "text": "What you‚Äôre describing is a classic ‚Äúsoft failure‚Äù pattern. Nothing crashes, but behavior degrades in ways users don‚Äôt explicitly report.\n\nIn our experience, prompt tuning alone rarely fixes this once agents are in prod. The issue is usually that the system treats all deviations as recoverable retries, so you get loops, drift, and slow convergence instead of clear failures.\n\nA few things that have helped teams reduce silent failures:\n- Make retries explicit and bounded. If an agent retries automatically without knowing why the previous step failed, you‚Äôre just amplifying noise.\n- Log decisions, not just inputs and outputs. When something feels ‚Äúoff‚Äù later, you want to know why a step was allowed to proceed.\n- Introduce step-level invariants. For example, ‚Äúthis tool call should only happen if X and Y are true,‚Äù rather than letting the model decide implicitly.\n- Treat back-and-forth with users as a signal. Repeated clarification loops are often silent failures in disguise.\n\n\nObservability helps, but only if it‚Äôs tied to execution state and decisions, not just traces. Otherwise you can see what happened without understanding why.\n\nCurious where you‚Äôre seeing the most drift today: tool selection, retries, or state/context getting lost across turns?",
          "score": 2,
          "created_utc": "2026-01-23 07:56:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1az9vz",
          "author": "Disastrous_Fox_3069",
          "text": "I've found this to be helpful for evaluating context of full conversation - https://docs.langchain.com/langsmith/online-evaluations-multi-turn. My best guess though is that there may be too much context/not enough instruction for the agent. Perhaps too many tools. What model are you using?",
          "score": 1,
          "created_utc": "2026-01-23 20:36:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bjx6e",
          "author": "pbalIII",
          "text": "Soft failures are the hardest to catch because your system looks healthy while making bad decisions.\n\nTwo patterns that helped us: step-level invariants (tool X only fires if conditions Y and Z are true, enforced in code) and treating repeated clarification loops as a signal worth logging.\n\nObservability helps, but the gap is usually prompt-completion linkage. You can see what happened without understanding why. LangSmith traces get you part of the way, but you still need to instrument decision points, not just inputs and outputs.",
          "score": 1,
          "created_utc": "2026-01-23 22:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1kd7ez",
          "author": "Revolutionary-Bet-58",
          "text": "I can highly recommend using an agent scanner prior to deployment for finding silent failures such as infinite loops, bad RCE, etc..",
          "score": 1,
          "created_utc": "2026-01-25 05:02:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql1m38",
      "title": "Open Source Serverless RAG Pipeline (Lambda + Bedrock) with React Component",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "author": "HatmanStack",
      "created_utc": "2026-01-23 20:14:08",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.9,
      "text": "I built a fully serverless RAG pipeline to avoid idle server costs and container management.\n\nRepo: [https://github.com/HatmanStack/RAGStack-Lambda](https://github.com/HatmanStack/RAGStack-Lambda)\n\nDemo: [https://dhrmkxyt1t9pb.cloudfront.net](https://dhrmkxyt1t9pb.cloudfront.net)\n\n(Login: [guest@hatstack.fun](mailto:guest@hatstack.fun) / Guest@123)\n\nBlog: [https://portfolio.hatstack.fun/read/post/RAGStack-Lambda](https://portfolio.hatstack.fun/read/post/RAGStack-Lambda)\n\nKey Features:\n\n* Frontend: Drop-in <ragstack-chat> web component (React 19).\n* Multimodal: Uses Amazon Nova to embed text, images, and videos.\n* Zero Idle Costs: Pure Lambda/Step Functions/DynamoDB architecture.\n* MCP Support: Connects directly to Claude Desktop and Cursor.\n* No Control Plane: All resources deployed in your AWS Account.\n\nDeployment is one-click via CloudFormation. Feedback welcome.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qinxsi",
      "title": "Advanced AI Program which also covers Langchain",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "author": "soundboardwithme",
      "created_utc": "2026-01-21 04:18:38",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hello Folks,\n\nI am not sure if this is the right sub, please be kind towards me if this is not the right sub.\n\nI have been really unwell and having health complications, due to which I am unable to continue my enrollment for an Advanced AI program. It's duration is 3 month and the investment is $ 700 \n\nI am in Eastern Standard Time ( EST ) and this program happens every weekend 11 AM To 2 PM IST, which is during midnight hours for me.\n\nIf I attend these LIVE sessions during midnight EST, I will increase the risk of cardio vascular disease, and I might fall dead because of my health situation. It's an intensive program, with clear learning outcomes.\n\nI tried to get a refund for this enrollment, but they would not agree to it, inspite of my risky health situation. All they could offer is swap my enrollment if I manage to find a person to join this program.\n\nThis is a sincere request and I apologize if I am posting in the wrong sub.\n\nAlso, I am not trying to promote this program in any way but I know that it's a good program for those who want to learn Agentic AI and build products.\n\nIf anyone is interested to learn and ready to take a look, I will be happy to ping you the details for consideration and help me swap the enrollment.\n\nHonestly, I am broke and my health situation is bad.\n\nAll I am trying to do is,heal and survive for the next few months.\n\nI have to prioritize my heath and my career goals have changed.\n\nAnd I only have a few months of savings left.\n\nPlease, this is a request to help me in any way possible.\n\nI was very hesistant to seek here for help.\n\nBecause of my health situation my plans have changed.\n\nHappy to DM you the details.\n\nIt's only one Spot.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkswe0",
      "title": "How to deploy a LangGraph server on Heroku",
      "subreddit": "LangChain",
      "url": "https://substack.com/home/post/p-184868546",
      "author": "AlexRenz",
      "created_utc": "2026-01-23 14:53:57",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkswe0/how_to_deploy_a_langgraph_server_on_heroku/",
      "domain": "substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1cbm6u",
          "author": "shifra-dev",
          "text": "Awesome work on this!\n\nSharing a resource for deploying LangGraph on Render as well in case that's helpful for folks: [https://www.youtube.com/watch?v=Gq3CPLOGHPw](https://www.youtube.com/watch?v=Gq3CPLOGHPw)",
          "score": 2,
          "created_utc": "2026-01-24 00:39:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1f2nxi",
              "author": "AlexRenz",
              "text": "Nice, this is a great video üí™",
              "score": 1,
              "created_utc": "2026-01-24 12:56:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qj1r2z",
      "title": "Added Git-like versioning to LangChain agent contexts (open source)",
      "subreddit": "LangChain",
      "url": "https://github.com/ultracontext/ultracontext-node",
      "author": "Main_Payment_6430",
      "created_utc": "2026-01-21 15:59:44",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj1r2z/added_gitlike_versioning_to_langchain_agent/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qkyu82",
      "title": "New! ampersend added as an official LangChain integration",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "author": "kevinjonescreates",
      "created_utc": "2026-01-23 18:32:11",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "Hey everyone - ampersend just got added to the official LangChain integration docs.\n\nIf you're building agents that need to call external services or other agents, this lets them handle payments autonomously. When a remote agent requires payment, ampersend negotiates and executes the payment automatically via x402.\n\nSetup is straightforward - configure your wallet and treasurer, and your LangChain agent can discover remote agent capabilities, send messages, and pay for services without manual intervention. You set spend limits and policies upfront.\n\nUseful if you're building agents that need to:\n\n* Call paid APIs or data services\n* Use other specialized agents (research, analysis, etc)\n* Operate autonomously without constant human approval\n\nDocs:[ https://docs.langchain.com/oss/python/integrations/tools/ampersend](https://docs.langchain.com/oss/python/integrations/tools/ampersend)\n\nHappy to answer questions about the x402 integration or agent-to-agent payments.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ab13a",
          "author": "Mammoth-Nectarine513",
          "text": "Hi , I want to use agent for payment. Do you think i can integrate? What are the pros and cons? \n\nMaybe we can discuss in dm?",
          "score": 1,
          "created_utc": "2026-01-23 18:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b4k3n",
              "author": "kevinjonescreates",
              "text": "Yes it would work great for payments. Using ampersend you can build buyer agents easily, with spending limits [https://docs.ampersend.ai/](https://docs.ampersend.ai/)\n\nHappy to help you if you need dm me!",
              "score": 1,
              "created_utc": "2026-01-23 21:01:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmhxxi",
      "title": "Quantifying Hallucinations: By calculating a multi-dimensional 'Trust Score' for LLM outputs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qmhxxi",
      "author": "Charming_Group_2950",
      "created_utc": "2026-01-25 12:33:20",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmhxxi/quantifying_hallucinations_by_calculating_a/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qjwa56",
      "title": "Most agents forget their purpose after a few runs. I built a way for them to \"learn\" from attacks (99.6% defense rate).",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjwa56/most_agents_forget_their_purpose_after_a_few_runs/",
      "author": "forevergeeks",
      "created_utc": "2026-01-22 14:41:31",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.73,
      "text": "Hi LangChainers,\n\nI‚Äôve been working on a problem that most standard agent frameworks (like LangChain or AutoGen) struggle with: long-term consistency or what the industry calls \"statelessness.\"\n\nMost agents reset their \"alignment\" with every new session. If a user jailbreaks them once, the agent doesn't learn to be more defensive next time. It makes the same mistake twice.\n\nThe Solution: **Stateful Alignment Tracking** I built an open-source framework called **SAFi (Self-Alignment Framework Interface)**. The core innovation is a module that tracks the agent's coherence, detects drift, and provides live feedback to the model when it is going off-track.\n\n**The Stress Test** To test the system, I recently ran a public jailbreak challenge here on Reddit. I used a \"Socratic Tutor\" agent and challenged users to make it give direct answers or forget its purpose as a science/math tutor.\n\n* **Total Attacks:** 845\n* **Successful Jailbreaks:** 2\n* **Defense Rate:** 99.6%\n\nThe two \"successful\" jailbreaks were actually \"refusal answers\" for example, the agent said: *\"I won't tell you the answer to 2+2=4 because I want you to think!\"*\n\n**The Code** SAFi is 100% open source. You can find the repo, benchmarks, and raw logs here: **Repo:**[https://github.com/jnamaya/SAFi](https://github.com/jnamaya/SAFi)\n\nI'm looking for feedback from the builder community, especially on how you're handling stateful governance in your own agent stacks.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjwa56/most_agents_forget_their_purpose_after_a_few_runs/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkq04r",
      "title": "How do you store and load prompts from files in small LangChain projects (without a prompt DB)?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkq04r/how_do_you_store_and_load_prompts_from_files_in/",
      "author": "Gmaen",
      "created_utc": "2026-01-23 12:52:52",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\n\n\nI‚Äôm working on a smaller LangChain project and trying to find a clean, practical way to store prompts in files and load them into LangChain.\n\n\n\nI explicitly do NOT want to introduce a prompt database or a heavy prompt management tool yet.\n\nWhat I‚Äôm looking for is something that works well for:\n\n\\- small to medium projects\n\n\\- file-based prompts (Git-friendly)\n\n\\- easy loading into LangChain (PromptTemplate / ChatPromptTemplate)\n\n\\- ideally with some structure or metadata\n\n\n\nI‚Äôve experimented with things like:\n\n\\- plain .txt files\n\n\\- Jinja2 templates\n\n\\- Markdown with frontmatter\n\n\\- rendering prompts myself vs. letting LangChain render\n\n\n\nBut none of these feel like a clear ‚Äúbest practice‚Äù, and LangChain itself seems pretty open-ended here. Maybe I just oversaw the right appraoch. I also dont want to write another Loader...\n\n\n\nSo my question:\n\n\\*\\*How do you organize your prompts today in projects without a prompt DB?\\*\\*\n\n\\- What file format do you use?\n\n\\- How do you load them into LangChain?\n\n\\- Any patterns or repos you‚Äôd recommend?\n\n\n\nCurious to hear what people actually use in practice.\n\nThanks!\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkq04r/how_do_you_store_and_load_prompts_from_files_in/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1a4rbs",
          "author": "Fickle_Act_594",
          "text": "I don't use langchain any more, but I feel jinja2 is the way to go.",
          "score": 1,
          "created_utc": "2026-01-23 18:15:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bash8",
              "author": "sadism_popsicle",
              "text": "Why ? Is it because of the overhead?",
              "score": 1,
              "created_utc": "2026-01-23 21:30:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bcee7",
                  "author": "Fickle_Act_594",
                  "text": "I didn't jive with the overly abstracted style. Different strokes for different folks I guess.",
                  "score": 1,
                  "created_utc": "2026-01-23 21:38:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1a8s3n",
          "author": "Guilty_Airport_7881",
          "text": "Try Langfuse, has great prompt management.",
          "score": 1,
          "created_utc": "2026-01-23 18:33:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bka43",
          "author": "pbalIII",
          "text": "YAML with frontmatter is the cleanest pattern I've landed on. Structure like `_type: prompt`, `input_variables`, and `template` fields... LangChain's native serialization supports it out of the box.\n\nFor small projects, I keep prompts in a `/prompts` folder, one YAML file per template. Git diffs are readable, and you can load directly with `PromptTemplate.from_file()`. The langchain-hub repo structure is worth copying... they use json/yaml with relative paths for referencing shared components.\n\nThe counterargument (prompts-don't-belong-in-git camp) is that product iteration gets bottlenecked by deploys. Fair point if non-engineers need to tweak wording. But for dev-only projects, file-based wins on simplicity. You skip the Langfuse/LangSmith dependency until you actually need versioning across environments.",
          "score": 1,
          "created_utc": "2026-01-23 22:15:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qm2lrs",
      "title": "Unable to distinguish between reasoning text and final response in streaming mode with tool calls",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "author": "Dragonfruit-Eastern",
      "created_utc": "2026-01-24 23:32:33",
      "score": 5,
      "num_comments": 9,
      "upvote_ratio": 0.86,
      "text": "When streaming messages from Claude (Anthropic models) in LangGraph, the model sometimes includes explanatory text before making tool calls (e.g., \"I'll get the weather information for both New York and San Francisco for you.\").\n\nThe problem is that these text chunks arrive before the tool\\_use content blocks, making it impossible to determine whether the streaming text is:\n\n1. Preliminary reasoning/thoughts that precede a tool call, or\n2. The actual final response to the user\n\nThis creates a challenge for UI rendering, as we cannot know whether to display the text immediately or wait to see if a tool call follows.\n\n**Expected Behavior:**\n\nEither:\n\n* Provide a way to identify which text chunks are associated with tool calls versus final responses during streaming, or\n* Offer a configuration option to disable these preliminary text chunks entirely when tools are being used, so only the tool calls and final responses are streamed\n\n**Current Workaround:**\n\nCurrently, we must wait until the complete message is received to determine the message type, which defeats the purpose of streaming for real-time UI updates.\n\n**Script**\n\nfrom langgraph.graph import StateGraph, add\\_messages\n\nfrom langchain.tools import tool\n\nfrom langchain\\_anthropic import ChatAnthropic\n\nfrom typing import TypedDict, Annotated\n\n\\# Define your state schema\n\nclass State(TypedDict):\n\nmessages: Annotated\\[list, add\\_messages\\]\n\n\\# Create a simple tool\n\ndef get\\_weather(city: str) -> str:\n\n\"\"\"Get weather information for a city.\"\"\"\n\nweather\\_data = {\"New York\": \"Rainy, 65¬∞F\", \"San Francisco\": \"Sunny, 70¬∞F\", \"London\": \"Cloudy, 55¬∞F\"}\n\nreturn weather\\_data.get(city, f\"Weather data not available for {city}\")\n\n\\# Create a tool node that handles tool calls\n\nfrom langgraph.prebuilt import ToolNode\n\ntools = \\[get\\_weather\\]\n\ntool\\_node = ToolNode(tools)\n\n\\# LLM node that can call tools\n\ndef llm\\_node(state: State):\n\nllm = ChatAnthropic(\n\nmodel=\"claude-sonnet-4-5-20250929\",\n\napi\\_key=\"key\",\n\n)\n\nllm\\_with\\_tools = llm.bind\\_tools(tools)\n\nresponse = llm\\_with\\_tools.invoke(state\\[\"messages\"\\])\n\nreturn {\"messages\": \\[response\\]}\n\n\\# Build the graph\n\ngraph = StateGraph(State)\n\ngraph.add\\_node(\"llm\", llm\\_node)\n\ngraph.add\\_node(\"tools\", tool\\_node)\n\n\\# Route: if the LLM calls a tool, go to tools node, otherwise end\n\ndef should\\_use\\_tools(state: State):\n\nlast\\_message = state\\[\"messages\"\\]\\[-1\\]\n\n\\# Check if the last message has tool calls\n\nif hasattr(last\\_message, \"tool\\_calls\") and last\\_message.tool\\_calls:\n\nreturn \"tools\"\n\nreturn \"end\"\n\ngraph.set\\_entry\\_point(\"llm\")\n\ngraph.add\\_conditional\\_edges(\"llm\", should\\_use\\_tools, {\"tools\": \"tools\", \"end\": \"\\_\\_end\\_\\_\"})\n\ngraph.add\\_edge(\"tools\", \"llm\")  # After tools run, return to LLM\n\ncompiled\\_graph = graph.compile()\n\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":\n\n\\# Stream and print all messages\n\nfrom langchain.messages import HumanMessage\n\ninitial\\_state = {\"messages\": \\[HumanMessage(content=\"What's the weather in New York and San Francisco?\")\\]}\n\nOutput\n\n{'content': \\[\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_name': 'claude-sonnet-4-5-20250929', 'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': \"I'll get\", 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': ' the weather information for both New York and', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': ' San Francisco for you.', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'id': 'toolu\\_01Sz73zV5mpd4zrdThssKvnY', 'input': {}, 'name': 'get\\_weather', 'type': 'tool\\_use', 'index': 1}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[{'name': 'get\\_weather', 'args': {}, 'id': 'toolu\\_01Sz73zV5mpd4zrdThssKvnY', 'type': 'tool\\_call'}\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': 'get\\_weather', 'args': '', 'id': 'toolu\\_01Sz73zV5mpd4zrdThssKvnY', 'index': 1, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': '', 'type': 'input\\_json\\_delta', 'index': 1}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[{'name': '', 'args': {}, 'id': None, 'type': 'tool\\_call'}\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': '{\"city\"', 'type': 'input\\_json\\_delta', 'index': 1}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[{'name': '', 'args': {}, 'id': None, 'type': 'tool\\_call'}\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': '{\"city\"', 'id': None, 'index': 1, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': ': \"New Yor', 'type': 'input\\_json\\_delta', 'index': 1}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[{'name': None, 'args': ': \"New Yor', 'id': None, 'error': None, 'type': 'invalid\\_tool\\_call'}\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': ': \"New Yor', 'id': None, 'index': 1, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': 'k\"}', 'type': 'input\\_json\\_delta', 'index': 1}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[{'name': None, 'args': 'k\"}', 'id': None, 'error': None, 'type': 'invalid\\_tool\\_call'}\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': 'k\"}', 'id': None, 'index': 1, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'id': 'toolu\\_01Y8UrYNCRhYkiq9yubs1Ms7', 'input': {}, 'name': 'get\\_weather', 'type': 'tool\\_use', 'index': 2}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[{'name': 'get\\_weather', 'args': {}, 'id': 'toolu\\_01Y8UrYNCRhYkiq9yubs1Ms7', 'type': 'tool\\_call'}\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': 'get\\_weather', 'args': '', 'id': 'toolu\\_01Y8UrYNCRhYkiq9yubs1Ms7', 'index': 2, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': '', 'type': 'input\\_json\\_delta', 'index': 2}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[{'name': '', 'args': {}, 'id': None, 'type': 'tool\\_call'}\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': '', 'id': None, 'index': 2, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': '{\"', 'type': 'input\\_json\\_delta', 'index': 2}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[{'name': '', 'args': {}, 'id': None, 'type': 'tool\\_call'}\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': '{\"', 'id': None, 'index': 2, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': 'city\": ', 'type': 'input\\_json\\_delta', 'index': 2}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[{'name': None, 'args': 'city\": ', 'id': None, 'error': None, 'type': 'invalid\\_tool\\_call'}\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': 'city\": ', 'id': None, 'index': 2, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': '\"San F', 'type': 'input\\_json\\_delta', 'index': 2}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[{'name': None, 'args': '\"San F', 'id': None, 'error': None, 'type': 'invalid\\_tool\\_call'}\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': '\"San F', 'id': None, 'index': 2, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[{'partial\\_json': 'rancisco\"}', 'type': 'input\\_json\\_delta', 'index': 2}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[{'name': None, 'args': 'rancisco\"}', 'id': None, 'error': None, 'type': 'invalid\\_tool\\_call'}\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[{'name': None, 'args': 'rancisco\"}', 'id': None, 'index': 2, 'type': 'tool\\_call\\_chunk'}\\], 'chunk\\_position': None}\n\n{'content': \\[\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'stop\\_reason': 'tool\\_use', 'stop\\_sequence': None, 'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': {'input\\_tokens': 568, 'output\\_tokens': 108, 'total\\_tokens': 676, 'input\\_token\\_details': {'cache\\_creation': 0, 'cache\\_read': 0}}, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': 'last'}\n\n{'content': 'Rainy, 65¬∞F', 'additional\\_kwargs': {}, 'response\\_metadata': {}, 'type': 'tool', 'name': 'get\\_weather', 'id': '92288d1a-8262-42d3-90eb-38d68206c0f7', 'tool\\_call\\_id': 'toolu\\_01Sz73zV5mpd4zrdThssKvnY', 'artifact': None, 'status': 'success'}\n\n{'content': 'Sunny, 70¬∞F', 'additional\\_kwargs': {}, 'response\\_metadata': {}, 'type': 'tool', 'name': 'get\\_weather', 'id': 'c53f55a1-fc34-4b81-b8f3-59212983719f', 'tool\\_call\\_id': 'toolu\\_01Y8UrYNCRhYkiq9yubs1Ms7', 'artifact': None, 'status': 'success'}\n\n{'content': \\[\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_name': 'claude-sonnet-4-5-20250929', 'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': \"Here's the current\", 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': ' weather:', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': '\\\\n\\\\n-', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': ' \\*\\*New York\\*\\*: Rainy,', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': ' 65¬∞F\\\\n- \\*\\*San', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': ' Francisco\\*\\*: Sunny, 70¬∞', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[{'text': 'F', 'type': 'text', 'index': 0}\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': None, 'tool\\_call\\_chunks': \\[\\], 'chunk\\_position': None}\n\n{'content': \\[\\], 'additional\\_kwargs': {}, 'response\\_metadata': {'stop\\_reason': 'end\\_turn', 'stop\\_sequence': None, 'model\\_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc\\_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool\\_calls': \\[\\], 'invalid\\_tool\\_calls': \\[\\], 'usage\\_metadata': {'input\\_tokens': 754, 'output\\_tokens': 36, 'total\\_tokens': 790, 'input\\_token\\_details': {'cache\\_creation': 0, 'cache\\_read': 0}}, ' tool\\_call\\_chunks': \\[\\], 'chunk\\_position': 'last'}",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1jfkdw",
          "author": "iso_what_you_did",
          "text": "This isn't a bug¬†- it's how¬†autoregressive models work.\n\n**The problem:**¬†Claude generates text¬†token-by-token. When it outputs \"I'll get the weather...\", it¬†hasn't generated the tool call¬†yet. The model doesn't know what's¬†coming next - it's predicting one token at a time.\n\n**You're asking:**¬†\"Can you label¬†this text as 'preliminary' before¬†the model decides¬†to call a¬†tool?\"\n\n**That's impossible.**¬†The model hasn't made that¬†decision yet when¬†the text streams out.\n\n**Your actual solution is already in the output:**\n\n    python'stop_reason': 'tool_use'  # vs 'end_turn'\n\nWhen streaming completes, check¬†the stop\\_reason. That tells¬†you if tools were called.\n\n**Real options:**\n\n1. Buffer the stream until complete,¬†then decide how¬†to render\n2. Show the preliminary¬†text (it's actually¬†good¬†UX - users see the model \"thinking\")\n3. Accept that¬†streaming +¬†tool calls means¬†some uncertainty¬†until completion",
          "score": 2,
          "created_utc": "2026-01-25 01:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1jmywj",
              "author": "Dragonfruit-Eastern",
              "text": "Thanks for your detailed answer. I use exactly the second option. I pretend it‚Äôs the main response until I get a tool use flag for that message id. But not sure about this is the best for UI. Because for example when I use Claude Sonnet in Pycharm Github Copilot extension, It can separate thinking/tool using explanations while it‚Äôs streaming on UI. Maybe they use another abstraction or algorithm to distinguish. That‚Äôs why I thought there might be a way.",
              "score": 1,
              "created_utc": "2026-01-25 02:27:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ja45b",
          "author": "TwistCrafty7858",
          "text": "which version of langchain are you using ? your code is not displaying the stream mode but i guess the stream mode ¬´¬†messages¬†¬ª allows you to get only llm output without any AIMessage tool call etc .",
          "score": 1,
          "created_utc": "2026-01-25 01:16:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1kpbi4",
          "author": "Over_Krook",
          "text": "You pasted your hardcoded api key‚Ä¶",
          "score": 1,
          "created_utc": "2026-01-25 06:27:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iv0if",
          "author": "AdditionalWeb107",
          "text": "Please don't use LangcChain for this - just simply call the model APIs or use a passthrough proxy that gives you a unified API.   You don't want to be bound to a framework here, you want to be bound to an API. And I am not sure why you are using LangGraph for this use case of too calls?\n\nUse LangChain for modelling your business objects, not LLM calls.",
          "score": 0,
          "created_utc": "2026-01-24 23:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1j7ogg",
              "author": "Dragonfruit-Eastern",
              "text": "I get what you're saying, but my app supports multiple LLM providers (OpenAI, Gemini, Anthropic, etc.). Isn't that literally the point of LangChain - to abstract away the different APIs?\n\nI'm just using basic stuff: tool calling and streaming. Not doing anything complex with LangGraph, just the standard tool flow.\n\nIf I call each API directly, I'd have to write the same logic 3+ times for each provider. That's exactly what the framework is supposed to solve, no?",
              "score": 5,
              "created_utc": "2026-01-25 01:02:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1j873w",
                  "author": "AdditionalWeb107",
                  "text": "no you wouldn't you need to use a high-performance, high-throughput proxy that allows you write code ergonomically using any popular client (Anthropic, OpenAI) and common APIs (like v1/chat/completions or v1/messages. You could review liteLLM or [Plano](https://github.com/katanemo/plano). There are other options out there for the same use case.",
                  "score": 1,
                  "created_utc": "2026-01-25 01:05:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}