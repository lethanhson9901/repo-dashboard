{
  "metadata": {
    "last_updated": "2026-01-07 16:56:07",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 36,
    "total_comments": 131,
    "file_size_bytes": 207431
  },
  "items": [
    {
      "id": "1pzno6m",
      "title": "Semantic caching cut our LLM costs by almost 50% and I feel stupid for not doing it sooner",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pzno6m/semantic_caching_cut_our_llm_costs_by_almost_50/",
      "author": "Otherwise_Flan7339",
      "created_utc": "2025-12-30 17:12:23",
      "score": 131,
      "num_comments": 27,
      "upvote_ratio": 0.86,
      "text": "So we've been running this AI app in production for about 6 months now. Nothing crazy, maybe a few hundred daily users, but our OpenAI bill hit $4K last month and I was losing my mind. Boss asked me to figure out why we're burning through so much money.\n\nTurns out we were caching responses, but only with exact string matching. Which sounds smart until you realize users never type the exact same thing twice. \"What's the weather in SF?\" gets cached. \"What's the weather in San Francisco?\" hits the API again. Cache hit rate was like 12%. Basically useless.\n\nThen I learned about semantic caching and honestly it's one of those things that feels obvious in hindsight but I had no idea it existed. We ended up using Bifrost (it's an open source LLM gateway) because it has semantic caching built in and I didn't want to build this myself.\n\nThe way it works is pretty simple. Instead of matching exact strings, it matches the meaning of queries using embeddings. You generate an embedding for every query, store it with the response in a vector database, and when a new query comes in you check if something semantically similar already exists. If the similarity score is high enough, return the cached response instead of hitting the API.\n\nReal example from our logs - these four queries all had similarity scores above 0.90:\n\n* \"How do I reset my password?\"\n* \"Can't remember my password, help\"\n* \"Forgot password what do I do\"\n* \"Password reset instructions\"\n\nWith traditional caching that's 4 API calls. With semantic caching it's 1 API call and 3 instant cache hits.\n\nBifrost uses Weaviate for the vector store by default but you can configure it to use Qdrant or other options. The embedding cost is negligible - like $8/month for us even with decent traffic. GitHub: [https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)\n\nAfter running this for 30 days our bill dropped drastically. Cache hit rate went up. And as a bonus, cached responses are way faster - like 180ms vs 2+ seconds for actual API calls.\n\nThe tricky part was picking the similarity threshold. We tried 0.70 at first and got some weird responses where the cache would return something that wasn't quite right. Bumped it to 0.95 and the cache barely hit anything. Settled on 0.85 and it's been working great.\n\nAlso had to think about cache invalidation - we expire responses after 24 hours for time-sensitive stuff and 7 days for general queries.\n\nThe best part is we didn't have to change any of our application code. Just pointed our OpenAI client at Bifrost's gateway instead of OpenAI directly and semantic caching just works. It also handles failover to Claude if OpenAI goes down, which has saved us twice already.\n\nIf you're running LLM stuff in production and not doing semantic caching you're probably leaving money on the table. We're saving almost $2K/month now.",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1pzno6m/semantic_caching_cut_our_llm_costs_by_almost_50/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwt10pe",
          "author": "hyma",
          "text": "Advertisement?",
          "score": 22,
          "created_utc": "2025-12-30 21:48:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwuefsp",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 11,
              "created_utc": "2025-12-31 02:16:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww5ka6",
                  "author": "nihal_ar",
                  "text": "7 months lol, read before commenting duh..",
                  "score": 2,
                  "created_utc": "2025-12-31 10:20:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwvvn72",
                  "author": "Masotsheni",
                  "text": "Not sure how you got that impression, but this sounds like a legit experience. Semantic caching is a real game changer for reducing costs. Maybe check out the GitHub link if you're curious about the tech!",
                  "score": 1,
                  "created_utc": "2025-12-31 08:46:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwuj4r4",
          "author": "Whyme-__-",
          "text": "Just pipe the entire codebase of Roo code into Gemini and ask it to pull the algorithm of semantic caching and distill into simple technical spec sheet.  Then add it to your code. Concepts like these are easier to implement if you already have someone who opensourced the tech.",
          "score": 10,
          "created_utc": "2025-12-31 02:43:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1c1rj",
              "author": "UnionCounty22",
              "text": "I bet it would give you 25% of it and shoo you out the door",
              "score": 1,
              "created_utc": "2026-01-01 05:09:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx31c2r",
                  "author": "Whyme-__-",
                  "text": "Nope if you work it right it gives the whole thing. Plus you can read the readme which has all the features so ask it to double and triple check it",
                  "score": 1,
                  "created_utc": "2026-01-01 14:37:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nws6hgz",
          "author": "Conscious_Nobody9571",
          "text": "Repost",
          "score": 5,
          "created_utc": "2025-12-30 19:22:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrnnl6",
          "author": "Far_Buyer_7281",
          "text": "Seems like something I would warn my users about at least?  \nisn't a query more then its semantic meaning?",
          "score": 3,
          "created_utc": "2025-12-30 17:55:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws74sx",
              "author": "adiznats",
              "text": "I'm also wondering what is the cosine similarity between \"what's the weather in SF\" and \"whats's the weather in NY\". Also probably longer sentences like those above but with a very small detail changed will be even worse with this kind of caching.",
              "score": 8,
              "created_utc": "2025-12-30 19:26:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwzbml6",
          "author": "tomomcat",
          "text": "Lame advert. This is just pollution.",
          "score": 3,
          "created_utc": "2025-12-31 21:25:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx215r5",
          "author": "getarbiter",
          "text": "The threshold tuning problem you're describing is fundamental to similarity-based caching. You're essentially guessing where \"same meaning\" ends and \"different meaning\" begins.\n\nWe took a different approach‚Äîcoherence scoring instead of similarity scoring. Rather than asking \"how close are these vectors?\", we ask \"does this cached response actually resolve the query under its constraint field?\"\n\n\"What's the weather in SF\" and \"What's the weather in NY\" have high cosine similarity (~0.95+) but zero coherence as cache matches‚Äîdifferent constraint fields.\n\n\"How do I reset my password\" and \"Forgot my password, help\" have moderate similarity but high coherence‚Äîsame constraint resolution.\n\nThe result: no arbitrary thresholds, deterministic scoring, and the cache knows why something matches, not just how close the vectors are.\n\n26MB engine, runs locally, no API calls for the coherence check itself. Happy to share more if useful.",
          "score": 2,
          "created_utc": "2026-01-01 09:11:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx29si4",
              "author": "louis8799",
              "text": "I'm interested.",
              "score": 2,
              "created_utc": "2026-01-01 10:43:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx495se",
                  "author": "getarbiter",
                  "text": "One concrete example based on what you described:\nIn your password-reset case, similarity caching works until two queries are close in embedding space but differ in constraint (account type, region, auth method, etc.). That‚Äôs where threshold tuning starts leaking correctness.\n\nWe handle that by checking whether the cached response resolves the same constraint set, not just a similar query.\nSo:\n‚ÄúHow do I reset my password?‚Äù\n‚ÄúForgot my password, help‚Äù\n‚Üí same cache hit\n\nBut:\n‚ÄúHow do I reset my password for SSO?‚Äù\n‚ÄúReset password for API key‚Äù\n‚Üí no hit, even if embeddings are close.\n\nSeparately, on cost: we don‚Äôt store 768‚Äì3kD embeddings for cache keys. We compress meaning to a 72-D deterministic representation, which cuts vector storage and ANN overhead by ~10√ó. That‚Äôs where a lot of the hidden infra cost actually is.\n\nThis sits in front of an existing semantic cache ‚Äî not a rip-and-replace.",
                  "score": 1,
                  "created_utc": "2026-01-01 18:34:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwv15or",
          "author": "Practical-Rope-7461",
          "text": "Build that gateway requires 30 minutes vibe coding, with some very basic embedding. Do it yourself. \n\nBtw, this is not a good business idea for offering semantic caching.",
          "score": 1,
          "created_utc": "2025-12-31 04:35:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvd8p1",
          "author": "AftyOfTheUK",
          "text": "How did you measure/quantify the impact on the quality of the responses from your app?",
          "score": 1,
          "created_utc": "2025-12-31 06:02:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwve49n",
          "author": "Dramatic_Strain7370",
          "text": "Great point. I will try out bifrost. Was your application a customer service or IT service agent? where caching was paying dividends?",
          "score": 1,
          "created_utc": "2025-12-31 06:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxt3zu",
          "author": "Either_War7733",
          "text": "I keep seeing people saying this is a spam but how can you actually implement it without using the tools being promoted here?",
          "score": 1,
          "created_utc": "2025-12-31 16:44:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1xju1",
          "author": "nf_x",
          "text": "Isn‚Äôt getting embeddings another API call? üòâ",
          "score": 1,
          "created_utc": "2026-01-01 08:32:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx4jxdj",
          "author": "elrosegod",
          "text": "Great story man, I'll need to keep this in mind when we start have unstructured querying in our apps.",
          "score": 1,
          "created_utc": "2026-01-01 19:27:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxc431q",
          "author": "baadir_",
          "text": "actually i try to jina ai rerank model . ƒ± pull 10 chunks but second layer jina rerank more relavan 5 chunks. \n\nƒ± think its good idea for relavancy",
          "score": 1,
          "created_utc": "2026-01-02 22:40:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxfyla6",
          "author": "Deep_Spice",
          "text": "This worked well for us too, but we eventually ran into cases where similarity wasn‚Äôt the failure mode,  reuse itself was invalid. Things like tenant boundaries, freshness requirements, or state-dependent tools made some ‚Äúhigh similarity‚Äù hits incorrect. We ended up treating semantic cache hits as conditional, similarity is necessary but not sufficient.",
          "score": 1,
          "created_utc": "2026-01-03 14:28:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxltf9t",
          "author": "adlx",
          "text": "It might be interesting in some cases. But in my case, the exact same question might have a different answer depending on the user, even depending on the day... \n\nFor example, \"when does my password expire\", Or \"when does my team take holidays this month\", \"whats is the state of my incidents\" (real questions our chatbot can answer).\n\nSame questions, same tools, obviously different response per user...",
          "score": 1,
          "created_utc": "2026-01-04 10:46:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwt6oc5",
          "author": "qa_anaaq",
          "text": "How does the gateway work? You hit your API which hits your gateway which hits the provider‚Äôs API? Or the gateway becomes your API effectively and it‚Äôs just gateway -> provider?",
          "score": 1,
          "created_utc": "2025-12-30 22:15:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxndjy",
      "title": "Advanced RAG: Token Optimization and Cost Reduction in Production. We Cut Query Costs by 60%",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pxndjy/advanced_rag_token_optimization_and_cost/",
      "author": "Electrical-Signal858",
      "created_utc": "2025-12-28 09:33:31",
      "score": 47,
      "num_comments": 13,
      "upvote_ratio": 0.9,
      "text": "Following up on my previous RAG post: we've optimized production RAG systems further and discovered cost optimizations that nobody talks about. This is specifically about reducing token spend without sacrificing quality.\n\n# The Problem We Solved\n\nOur RAG system was working well (retrieval was solid, generation was accurate), but the token spend kept climbing:\n\n* Hybrid retrieval (BM25 + vector): \\~2,000 tokens/query\n* Retrieved documents: \\~3,000 tokens\n* LLM processing: \\~500 tokens\n* **Total: \\~5,500 tokens/query**¬†√ó 100k queries/day = expensive\n\nAt $0.03 per 1K input tokens, that's¬†**$16.50/day just for input tokens**.¬†**$495/month**.\n\nWe asked: \"Can we get similar quality with fewer tokens?\"\n\nSpoiler: Yes. We reduced it to¬†**2,200 tokens/query average**¬†(60% reduction) while maintaining 92% accuracy (same as before).\n\n# The Optimizations\n\n# 1. Smart Document Chunking Reduces Retrieved Token Count\n\n**Before:**¬†Fixed 1,000-token chunks\n\n* Simple but wasteful\n* Lots of redundant context\n* Padding with irrelevant info\n\n**After:**¬†Semantic chunks with metadata filtering\n\n    from langchain.text_splitter import RecursiveCharacterTextSplitter\n    from sentence_transformers import SentenceTransformer\n    import numpy as np\n    \n    class SemanticChunker:\n        def __init__(self, min_chunk_size=200, max_chunk_size=800):\n            self.min_chunk_size = min_chunk_size\n            self.max_chunk_size = max_chunk_size\n            self.model = SentenceTransformer('all-MiniLM-L6-v2')\n        \n        def chunk_semantically(self, text, title=\"\"):\n            \"\"\"Break text into semantic chunks\"\"\"\n            sentences = text.split('. ')\n            \n            embeddings = self.model.encode(sentences)\n            chunks = []\n            current_chunk = []\n            current_embedding = None\n            \n            for i, sentence in enumerate(sentences):\n                current_chunk.append(sentence)\n                \n                if len(' '.join(current_chunk)) >= self.min_chunk_size:\n                    # Check semantic coherence\n                    chunk_embedding = self.model.encode(' '.join(current_chunk))\n                    \n                    if current_embedding is not None:\n                        # Cosine similarity with previous chunk\n                        similarity = np.dot(chunk_embedding, current_embedding) / (\n                            np.linalg.norm(chunk_embedding) * np.linalg.norm(current_embedding)\n                        )\n                        \n                        # If semantic break detected or max size reached\n                        if similarity < 0.6 or len(' '.join(current_chunk)) >= self.max_chunk_size:\n                            chunks.append({\n                                'content': ' '.join(current_chunk),\n                                'title': title,\n                                'tokens': len(' '.join(current_chunk).split())\n                            })\n                            current_chunk = []\n                            current_embedding = None\n                            continue\n                    \n                    current_embedding = chunk_embedding\n            \n            if current_chunk:\n                chunks.append({\n                    'content': ' '.join(current_chunk),\n                    'title': title,\n                    'tokens': len(' '.join(current_chunk).split())\n                })\n            \n            return chunks\n    \n\n**Result:**¬†Average chunk size went from 1,000 tokens ‚Üí 400 tokens (but more relevant). Retrieved fewer chunks but with less padding.\n\n# 2. Retrieval Pre-filtering Reduces What Gets Retrieved\n\n**Before:**¬†\"Get top-5 by relevance, send all to LLM\"\n\n**After:**¬†Multi-stage retrieval pre-filtering\n\n    def filtered_retrieval(query: str, documents: List[str], top_k=5):\n        \"\"\"Retrieve with automatic filtering\"\"\"\n        \n        # Stage 1: Broad retrieval (get more candidates)\n        candidates = vector_store.search(query, top_k=20)\n        \n        # Stage 2: Filter by relevance threshold\n        scored = [(doc, score) for doc, score in candidates]\n        high_confidence = [\n            (doc, score) for doc, score in scored \n            if score > 0.7  # Only confident matches\n        ]\n        \n        if not high_confidence:\n            high_confidence = scored[:5]  # Fallback to top-5\n        \n        # Stage 3: Deduplicate similar content\n        unique = []\n        seen_hashes = set()\n        \n        for doc, score in high_confidence:\n            doc_hash = hash(doc[:200])  # Hash of first 200 chars\n            \n            if doc_hash not in seen_hashes:\n                unique.append((doc, score))\n                seen_hashes.add(doc_hash)\n        \n        # Stage 4: Sort by relevance and return top-k\n        final = sorted(unique, key=lambda x: x[1], reverse=True)[:top_k]\n        \n        return [doc for doc, _ in final]\n    \n\n**Result:**¬†Retrieved fewer documents, but only high-confidence ones. Reduced retrieved token count by 40%.\n\n# 3. Query Simplification Before Retrieval\n\n**Before:**¬†Send raw user query to retriever\n\n    User: \"What are the refund policies for digital products if the customer received \n           a defective item and wants to know about international shipping costs?\"\n    (Complex, confusing retriever)\n    \n\n**After:**¬†Pre-process query to find key concepts\n\n    from langchain.chains import LLMChain\n    from langchain.prompts import PromptTemplate\n    \n    def simplify_query(query: str, llm) -> str:\n        \"\"\"Simplify query for better retrieval\"\"\"\n        \n        prompt = PromptTemplate(\n            input_variables=[\"query\"],\n            template=\"\"\"Extract the main topic from this query. \n            Remove adjectives, clarifications, and side questions.\n            \n            User query: {query}\n            \n            Simplified: \"\"\"\n        )\n        \n        chain = LLMChain(llm=llm, prompt=prompt)\n        \n        # Use cheaper model for this (gpt-3.5-turbo)\n        simplified = chain.run(query=query).strip()\n        \n        return simplified\n    \n    # Usage:\n    simplified = simplify_query(\n        \"What are the refund policies for digital products if the customer received \"\n        \"a defective item and wants to know about international shipping costs?\",\n        llm\n    )\n    # Result: \"refund policy digital products\"\n    \n\n**Result:**¬†Better retrieval queries ‚Üí fewer iterations ‚Üí fewer tokens.\n\n# 4. Response Compression Before Sending to LLM\n\n**Before:**¬†Send all retrieved documents as-is\n\n    Retrieved documents (all 3,000 tokens):\n    [Document 1: 1000 tokens]\n    [Document 2: 1000 tokens]\n    [Document 3: 1000 tokens]\n    \n\n**After:**¬†Compress while preserving information\n\n    def compress_context(documents: List[str], query: str, llm) -> str:\n        \"\"\"Compress documents while preserving relevant info\"\"\"\n        \n        compression_prompt = PromptTemplate(\n            input_variables=[\"documents\", \"query\"],\n            template=\"\"\"Summarize the following documents in as few words as possible \n            while preserving information relevant to the question.\n            \n            Question: {query}\n            \n            Documents:\n            {documents}\n            \n            Compressed summary:\"\"\"\n        )\n        \n        chain = LLMChain(llm=llm, prompt=compression_prompt)\n        \n        documents_text = \"\\n---\\n\".join(documents)\n        \n        compressed = chain.run(\n            documents=documents_text,\n            query=query\n        )\n        \n        return compressed\n    \n    # Usage:\n    context = compress_context(retrieved_docs, user_query, llm)\n    # 3000 tokens ‚Üí 800 tokens (still has all relevant info)\n    \n\n**Result:**¬†60-70% context reduction with minimal quality loss.\n\n# 5. Caching at the Context Level (Not Just Response Level)\n\n**Before:**¬†Cache full responses only\n\n    cache_key = hash(f\"{query}_{user_id}\")\n    cached_response = cache.get(cache_key)  # Only hits if identical query\n    \n\n**After:**¬†Cache compressed context\n\n    def cached_context_retrieval(query: str, user_context: str) -> str:\n        \"\"\"Retrieve and cache at context level\"\"\"\n        \n        # Hash just the query (not user context)\n        context_key = f\"context:{hash(query)}\"\n        \n        # Check if we've retrieved this query before\n        cached_context = cache.get(context_key)\n        \n        if cached_context:\n            return cached_context  # Reuse compressed context\n        \n        # If not cached, retrieve and compress\n        documents = retriever.get_relevant_documents(query)\n        compressed = compress_context(documents, query, llm)\n        \n        # Cache the compressed context\n        cache.set(context_key, compressed, ttl=86400)  # 24 hours\n        \n        return compressed\n    \n    # Usage:\n    context = cached_context_retrieval(query, user_context)\n    \n    # For identical queries from different users:\n    # User A: Retrieves, compresses (3000 tokens), caches\n    # User B: Uses cached context (0 tokens)\n    \n\n**Result:**¬†Context-level caching hits on 35% of queries (many users asking similar things).\n\n# 6. Token Counting Before Sending to LLM\n\n**Before:**¬†Blindly send context to LLM, hope it fits\n\n    response = llm.generate(system_prompt + context + user_query)\n    # Sometimes exceeds context window, sometimes wastes tokens\n    \n\n**After:**¬†Count tokens, optimize if needed\n\n    import tiktoken\n    \n    def smart_context_sending(context: str, query: str, llm, max_tokens=6000):\n        \"\"\"Send context to LLM, optimizing token usage\"\"\"\n        \n        enc = tiktoken.encoding_for_model(\"gpt-4\")\n        \n        # Count tokens in different parts\n        system_tokens = len(enc.encode(SYSTEM_PROMPT))\n        query_tokens = len(enc.encode(query))\n        context_tokens = len(enc.encode(context))\n        \n        total_input = system_tokens + query_tokens + context_tokens\n        \n        # If over budget, compress context further\n        if total_input > max_tokens:\n            compression_ratio = (total_input - max_tokens) / context_tokens\n            \n            # Aggressive compression if needed\n            compressed = aggressive_compress(context, compression_ratio)\n            context_tokens = len(enc.encode(compressed))\n            context = compressed\n        \n        # Now send to LLM\n        response = llm.generate(\n            system_prompt=SYSTEM_PROMPT,\n            context=context,\n            query=query\n        )\n        \n        return response\n    \n\n**Result:**¬†Stayed under token limits, never wasted tokens on too-large contexts.\n\n# The Results\n\n|Optimization|Before|After|Savings|\n|:-|:-|:-|:-|\n|Chunk size|1,000 tokens|400 tokens|Smaller chunks|\n|Retrieved docs|5 docs|3 docs|40% fewer|\n|Context compression|None|60% reduction|2x tokens|\n|Query simplification|None|Applied|Better retrieval|\n|Context caching|0% hit rate|35% hit rate|35% queries free|\n|Token counting|None|Applied|No waste|\n|**Total per query**|**5,500 tokens**|**2,200 tokens**|**60% reduction**|\n\n**Cost Impact:**\n\n* Before: 100k queries √ó 5,500 tokens √ó $0.03/1K =¬†**$16.50/day**¬†($495/month)\n* After: 100k queries √ó 2,200 tokens √ó $0.03/1K =¬†**$6.60/day**¬†($198/month)\n* **Savings: $297/month (60% reduction)**\n\n**Accuracy Impact:**\n\n* Before: 92% accuracy\n* After: 92% accuracy (unchanged)\n\n# Important Caveat\n\nThese optimizations come with tradeoffs:\n\n1. **Query simplification**¬†adds latency (extra LLM call, even if cheap)\n2. **Context compression**¬†could lose edge-case information\n3. **Caching**¬†reduces freshness (stale context for 24 hours)\n4. **Aggressive filtering**¬†might miss relevant documents\n\nWe accepted these tradeoffs. Your situation might differ.\n\n# Implementation Difficulty\n\n* **Easy:**¬†Token counting (1 hour)\n* **Easy:**¬†Retrieval filtering (2 hours)\n* **Medium:**¬†Query simplification (3 hours)\n* **Medium:**¬†Context compression (4 hours)\n* **Medium:**¬†Semantic chunking (4 hours)\n* **Hard:**¬†Context-level caching (5 hours)\n\n**Total:**¬†\\~19 hours of engineering work to save $297/month.\n\nPayback period: \\~1 month.\n\n# Code: Complete Pipeline\n\n    class OptimizedRAGPipeline:\n        def __init__(self, llm, retriever, cache):\n            self.llm = llm\n            self.retriever = retriever\n            self.cache = cache\n            self.encoder = tiktoken.encoding_for_model(\"gpt-4\")\n        \n        def process_query(self, user_query: str) -> str:\n            \"\"\"Complete optimized pipeline\"\"\"\n            \n            # Step 1: Simplify query\n            simplified_query = self.simplify_query(user_query)\n            \n            # Step 2: Retrieve with caching\n            context = self.cached_context_retrieval(simplified_query)\n            \n            # Step 3: Smart token handling\n            response = self.smart_context_sending(\n                context=context,\n                query=user_query\n            )\n            \n            return response\n        \n        def simplify_query(self, query: str) -> str:\n            \"\"\"Extract main topic from query\"\"\"\n            # Implementation from above\n            pass\n        \n        def cached_context_retrieval(self, query: str) -> str:\n            \"\"\"Retrieve and cache at context level\"\"\"\n            # Implementation from above\n            pass\n        \n        def smart_context_sending(self, context: str, query: str) -> str:\n            \"\"\"Send context with token optimization\"\"\"\n            # Implementation from above\n            pass\n    \n\n# Questions for the Community\n\n1. **Are you doing context-level caching?**¬†We found 35% hit rate. What's your experience?\n2. **How much quality loss do you see from compression?**¬†We measured \\~1-2% accuracy drop.\n3. **Query simplification latency trade:**¬†Is it worth the extra LLM call?\n4. **Semantic chunking:**¬†Are you doing it? How much better are results?\n5. **Token optimization:**¬†What's the best bang-for-buck optimization you've found?\n\n# Edit: Responses\n\n**On query simplification latency:**¬†\\~200-300ms added. With caching, only happens once per unique query. Worth it for most systems.\n\n**On context compression quality:**¬†We tested with GPT-3.5-turbo for compression (cheaper). Slightly more loss than GPT-4, but acceptable trade. Saves another $150/month.\n\n**On whether these are general:**¬†Yes, we tested on 3 different domains (legal, technical docs, customer support). Results were similar.\n\n**On LangChain compatibility:**¬†All of this integrates cleanly with LangChain's abstractions. No fighting the framework.\n\nWould love to hear if others have found different optimizations. Token cost is becoming the bottleneck.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1pxndjy/advanced_rag_token_optimization_and_cost/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwcccn3",
          "author": "KegOfAppleJuice",
          "text": "Even though it's written up by AI, nice overview of things one can do for token optimisation",
          "score": 6,
          "created_utc": "2025-12-28 10:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg4nze",
          "author": "OnyxProyectoUno",
          "text": "The semantic chunking approach is solid but you're still doing fixed-size boundaries. The real gains come from content-aware splitting that preserves logical units.\n\nYour compression step is interesting but risky. Compressing 3000 tokens to 800 means you're losing 70% of the information and trusting an LLM to keep what matters. That works until it doesn't. The accuracy might look the same in aggregate but you're probably missing edge cases where the compressed context drops critical details.\n\nThe context-level caching is clever. Most people only cache final responses which misses the opportunity to reuse expensive retrieval work. 35% hit rate is good, though 24-hour TTL might be too aggressive depending on how often your docs change.\n\nOne thing that jumps out is you're optimizing downstream when the real waste might be upstream. If your chunks are poorly formed to begin with, you're just optimizing garbage. Bad chunks mean more retrieval attempts, more irrelevant context, more compression losses. Have you looked at what your semantic chunker is actually producing? Sometimes the chunking strategy matters more than all the downstream optimization combined.\n\nThe token counting is table stakes at this point. Surprised more people aren't doing that by default.\n\nWhat's your chunk quality like after the semantic splitting? Are you seeing clean breaks at logical boundaries or is it still cutting mid-thought sometimes?",
          "score": 4,
          "created_utc": "2025-12-28 23:10:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdi6kh",
          "author": "MathematicianSome289",
          "text": "This is great just don‚Äôt need the code",
          "score": 1,
          "created_utc": "2025-12-28 15:24:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwek7jz",
          "author": "saintskytower",
          "text": "Moderator Comment\n\nA reminder to everyone participating:\n\n‚Ä¢ Personal attacks, profanity, and calls to mass-report users or content violate Rule 2 (‚ÄúBe nice‚Äù) and will be removed.\n‚Ä¢ If you believe a post is spam or low quality, use the report function. Do not harass other users or moderators publicly.\n‚Ä¢ Moderation decisions are made by the moderation team based on the posted rules, not by hostile comments.\n\nThe post itself remains open for technical discussion. Keep replies focused on the substance of the content and within subreddit rules.",
          "score": 1,
          "created_utc": "2025-12-28 18:33:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfzxty",
          "author": "cmndr_spanky",
          "text": "Your solution isn‚Äôt good",
          "score": 1,
          "created_utc": "2025-12-28 22:44:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhlcvc",
              "author": "BothContribution7282",
              "text": "Why isn't the above solution good",
              "score": 1,
              "created_utc": "2025-12-29 04:07:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwhw75d",
                  "author": "cmndr_spanky",
                  "text": "‚ÄúSemantic chunking‚Äù in the implementation is effectively no different than picking a small min sized chunk and relying on the VDB default way of using a similarity score to bring back the right articles‚Ä¶ in fact the implementation is worse because you might bring back an 800 token sized chunk during usage when you only needed 200 tokens out of that chunk.\n\nIt‚Äôs almost 100% the above post is AI generated and the person who generated it didn‚Äôt even read it, nor are they commenting here. I wouldn‚Äôt trust any of it.",
                  "score": 1,
                  "created_utc": "2025-12-29 05:17:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q46bl7",
      "title": "Why RAG is hitting a wall‚Äîand how Apple's \"CLaRa\" architecture fixes it",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q46bl7/why_rag_is_hitting_a_walland_how_apples_clara/",
      "author": "SKD_Sumit",
      "created_utc": "2026-01-05 00:15:51",
      "score": 37,
      "num_comments": 5,
      "upvote_ratio": 0.84,
      "text": "Hey everyone,\n\nI‚Äôve been tracking the shift from \"Vanilla RAG\" to more integrated architectures, and Apple‚Äôs recent¬†**CLaRa**¬†paper is a significant milestone that I haven't seen discussed much here yet.\n\nStandard RAG treats retrieval and generation as a \"hand-off\" process, which often leads to the \"lost in the middle\" phenomenon or high latency in long-context tasks.\n\n**What makes CLaRa different?**\n\n* **Salient Compressor:**¬†It doesn't just retrieve chunks; it compresses relevant information into \"Memory Tokens\" in the latent space.\n* **Differentiable Pipeline:**¬†The retriever and generator are optimized together, meaning the system \"learns\" what is actually salient for the specific reasoning task.\n* **The 16x Speedup:**¬†By avoiding the need to process massive raw text blocks in the prompt, it handles long-context reasoning with significantly lower compute.\n\nI put together a technical breakdown of the¬†**Salient Compressor**¬†and how the¬†**two-stage pre-training**¬†works to align the memory tokens with the reasoning model.\n\n**For those interested in the architecture diagrams and math:**¬†[https://yt.openinapp.co/o942t](https://yt.openinapp.co/o942t)\n\nI'd love to discuss: Does anyone here think latent-space retrieval like this will replace standard vector database lookups in production LangChain apps, or is the complexity too high for most use cases?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q46bl7/why_rag_is_hitting_a_walland_how_apples_clara/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxqm5u5",
          "author": "qa_anaaq",
          "text": "Pretty strong rebuttal for production cases via \n\nhttps://www.reddit.com/r/Rag/s/KyDWMdlGeE\n\nbut the idea is interesting",
          "score": 5,
          "created_utc": "2026-01-05 01:45:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxqqh7o",
          "author": "BeerBatteredHemroids",
          "text": "He's \"tracking the shift\" ü´°",
          "score": 2,
          "created_utc": "2026-01-05 02:08:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxr5paz",
              "author": "johnerp",
              "text": "Game changer",
              "score": 3,
              "created_utc": "2026-01-05 03:30:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxs4fpu",
          "author": "Upset-Pop1136",
          "text": "We tried both ‚Äúbetter retrieval‚Äù and ‚Äúsmaller context‚Äù because our OpenAI bill was getting silly. The part that mattered was unit cost per successful answer, not top-1 recall on a benchmark. When we cut prompt tokens by \\~60% using aggressive filtering + short summaries, our cost per resolved ticket dropped and response time improved enough that users stopped refreshing.",
          "score": 1,
          "created_utc": "2026-01-05 07:33:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxv9sog",
          "author": "pbalIII",
          "text": "Most RAG bottlenecks come from treating retrieval and generation as separate steps... CLaRa sidesteps this by compressing documents into continuous memory tokens and optimizing both together in the same latent space. The differentiable top-k lets gradients flow from answer tokens back into the retriever, so relevance aligns with actual answer quality.\n\n16x-128x compression is nice, but the real win is the joint optimization. Traditional RAG systems hope the LLM extracts what it needs from retrieved text. Here the compression itself is trained to preserve what the generator actually uses.",
          "score": 1,
          "created_utc": "2026-01-05 19:12:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1qjkz",
      "title": "fastapi-fullstack v0.1.11 released ‚Äì now with LangGraph ReAct agent support + multi-framework AI options!",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q1qjkz/fastapifullstack_v0111_released_now_with/",
      "author": "VanillaOk4593",
      "created_utc": "2026-01-02 05:44:43",
      "score": 36,
      "num_comments": 5,
      "upvote_ratio": 0.95,
      "text": "Hey r/LangChain,\n\nFor those new or catching up: fastapi-fullstack is an open-source CLI generator (pip install fastapi-fullstack) that creates production-ready full-stack AI/LLM apps with FastAPI backend + optional Next.js 15 frontend. It's designed to skip boilerplate, with features like real-time WebSocket streaming, conversation persistence, custom tools, multi-provider support (OpenAI/Anthropic/OpenRouter), and observability via LangSmith.\n\nFull changelog: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md?referrer=grok.com)  \nRepo: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template?referrer=grok.com)\n\n**Full feature set:**\n\n* Backend: Async FastAPI with layered architecture, auth (JWT/OAuth/API keys), databases (PostgreSQL/MongoDB/SQLite with SQLModel/SQLAlchemy options), background tasks (Celery/Taskiq/ARQ), rate limiting, admin panels, webhooks\n* Frontend: React 19, Tailwind, dark mode, i18n, real-time chat UI\n* AI: Now supports **LangChain**, **PydanticAI**, and the new **LangGraph** (more below)\n* 20+ configurable integrations: Redis, Sentry, Prometheus, Docker, CI/CD, Kubernetes\n* Django-style CLI + production Docker with Traefik/Nginx reverse proxy options\n\n**Big news in v0.1.11 (just released):**  \nAdded **LangGraph as a third AI framework option** alongside LangChain and PydanticAI!\n\n* New --ai-framework langgraph CLI flag (or interactive prompt)\n* Implements **ReAct (Reasoning + Acting) agent pattern** with graph-based flow: agent node for LLM decisions, tools node for execution, conditional edges for loops\n* Full memory checkpointing for conversation continuity\n* WebSocket streaming via astream() with modes for token deltas and node updates (tool calls/results)\n* Proper tool result correlation via tool\\_call\\_id\n* Dependencies auto-added: langgraph, langgraph-checkpoint, langchain-core/openai/anthropic\n\nThis makes it even easier to build advanced, stateful agents in your full-stack apps ‚Äì LangGraph's graph architecture shines for complex workflows.\n\nLangChain community ‚Äì how does LangGraph integration fit your projects? Any features to expand (e.g., more graph nodes)? Contributions welcome! üöÄ",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LangChain/comments/1q1qjkz/fastapifullstack_v0111_released_now_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nx7ub4r",
          "author": "hopes_alive123",
          "text": "any sample projects built using this?",
          "score": 3,
          "created_utc": "2026-01-02 07:23:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7w4ea",
              "author": "VanillaOk4593",
              "text": "It's our internal tool and we use it in the projects we build for our clients so I cant share real examples but it's really easy to generate a new projects with just only 2 commands [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template?tab=readme-ov-file#installation](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template?tab=readme-ov-file#installation)",
              "score": 1,
              "created_utc": "2026-01-02 07:40:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx7jxoa",
          "author": "mamaBiskothu",
          "text": "How do you ensure exactly once processing with celery?",
          "score": 1,
          "created_utc": "2026-01-02 05:55:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx85ip6",
          "author": "Preconf",
          "text": "Can I use phoenix for observability instead?",
          "score": 1,
          "created_utc": "2026-01-02 09:09:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx85t8b",
              "author": "VanillaOk4593",
              "text": "It's not implemented, so you would need to do it yourself. However, you can do anything with it since it only generates a project template, there are no limitations",
              "score": 2,
              "created_utc": "2026-01-02 09:12:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q64nnb",
      "title": "A unified Knowledge Graph router for AI agents (Apache-2.0)",
      "subreddit": "LangChain",
      "url": "https://github.com/neuledge/graph",
      "author": "moshestv",
      "created_utc": "2026-01-07 03:37:46",
      "score": 29,
      "num_comments": 8,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1q64nnb/a_unified_knowledge_graph_router_for_ai_agents/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "ny5j8q5",
          "author": "HOLDL",
          "text": "New to this so not trying to throw shade but what‚Äôs the point? Ex if I search any of the examples in Claude I get the same answers. Is the idea that there is more latency with web search and this makes retrieval more efficient / contextual?",
          "score": 2,
          "created_utc": "2026-01-07 05:58:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5w4l3",
              "author": "Signal_Question9074",
              "text": "ok bud. so the thing is we realized in 2025 that graph db;s are the shit when it comes for memory and retrieval for LLM's. and now its one of the standards and focus points of this year, alongside neo4j, redis agent caching and symantic caching, agent fleet orchestration and skills :)",
              "score": 0,
              "created_utc": "2026-01-07 07:46:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny6scjz",
                  "author": "justanemptyvoice",
                  "text": "Why does this comment read like it‚Äôs the OP or a friend of the OP? And why does it read as condescending?\n\n‚Äúok bud. so the thing is we realized in 2025 that graph db;s are the shit when it comes for memory and retrieval for LLM's. and now its one of the standards and focus points of this year, alongside neo4j, redis agent caching and symantic caching, agent fleet orchestration and skills :)‚Äù",
                  "score": 2,
                  "created_utc": "2026-01-07 12:24:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny502fe",
          "author": "macromind",
          "text": "This is really cool, the integration tax is so real (API keys, schema plumbing, then massaging JSON so the model does not derail). Love the <100ms structured lookup angle, that is basically the missing piece for agentic flows that need reliable tools.\n\nCurious, do you have a pattern for caching and tool fallback (like if a provider is down)? I have been collecting notes on agent reliability and tool orchestration here too: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-01-07 03:49:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5vzxx",
          "author": "Signal_Question9074",
          "text": "you are getting a fat star from me and hopefully ill be able to add my contributions to you on the weekend.",
          "score": 1,
          "created_utc": "2026-01-07 07:45:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6gka9",
              "author": "moshestv",
              "text": "Thanks man, appreciate it!",
              "score": 1,
              "created_utc": "2026-01-07 10:53:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0t2qd",
      "title": "GraphQLite - Embedded graph database for building GraphRAG with SQLite",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q0t2qd/graphqlite_embedded_graph_database_for_building/",
      "author": "Fit-Presentation-591",
      "created_utc": "2026-01-01 01:59:35",
      "score": 28,
      "num_comments": 15,
      "upvote_ratio": 0.95,
      "text": "For anyone building GraphRAG systems who doesn't want to run Neo4j just to store a knowledge graph, I've been working on something that might help.\n\n\n\nGraphQLite is an SQLite extension that adds Cypher query support. The idea is that you can store your extracted entities and relationships in a graph structure, then use Cypher to traverse and expand context during retrieval. Combined with sqlite-vec for the vector search component, you get a fully embedded RAG stack in a single database file.\n\n\n\nIt includes graph algorithms like PageRank and community detection, which are useful for identifying important entities or clustering related concepts. There's an example in the repo using the HotpotQA multi-hop reasoning dataset if you want to see how the pieces fit together.\n\n\n\n\\`pip install graphqlite\\`\n\n\n\nGitHub: [https://github.com/colliery-io/graphqlite](https://github.com/colliery-io/graphqlite)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q0t2qd/graphqlite_embedded_graph_database_for_building/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nx0rjch",
          "author": "International_Quail8",
          "text": "Very cool!",
          "score": 2,
          "created_utc": "2026-01-01 02:41:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0qvkb",
          "author": "Don_Ozwald",
          "text": "Can someone explain to me, what‚Äôs useful about GraphRAG?",
          "score": 1,
          "created_utc": "2026-01-01 02:37:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0ut5y",
              "author": "Fit-Presentation-591",
              "text": "There‚Äôs an example in the project at [https://github.com/colliery-io/graphqlite/tree/main/examples/llm-graphrag](https://github.com/colliery-io/graphqlite/tree/main/examples/llm-graphrag)  \n\n\nTraditional RAG uses only vector similarity to find relevant documents. But multi-hop questions require connecting information across documents. By pre processing the documents and building up a set of relationships (COOCCURS in this case is set when two people are in the same sentence), we can use traversals to find information that may be related to the inital query and add it to the context for evaluation. \n\nThe concrete example from the demo is \n\n**Example:**¬†\"Were Scott Derrickson and Ed Wood of the same nationality?\"\n\n* Vector search finds \"Ed Wood\" but may miss \"Scott Derrickson\"\n* Graph traversal via COOCCURS edges discovers the connection\n* Community detection finds topically related articles",
              "score": 5,
              "created_utc": "2026-01-01 03:04:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx101ol",
                  "author": "Don_Ozwald",
                  "text": "I understand that. My point is more regarding, does the LLM understand that? I mean. Isn't GraphRAG just adding an unnecessary layer of abstraction for the LLM to struggle with, that are better dealt with just hybrid search. With the example in mind, it certainly seems so, as hybrid search would only fail on that one with k=1.",
                  "score": 1,
                  "created_utc": "2026-01-01 03:39:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx0uiez",
          "author": "BetaCuck80085",
          "text": "Wow, *exactly* what I‚Äôve been looking for. Use Neo4j on the job, wanted to use something more lightweight for a few personal endeavors. Really appreciate you sharing this.",
          "score": 1,
          "created_utc": "2026-01-01 03:02:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0uwh0",
              "author": "Fit-Presentation-591",
              "text": "Music to my ears !",
              "score": 1,
              "created_utc": "2026-01-01 03:05:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2p68j",
          "author": "eternviking",
          "text": "It's SQLite and you missed the chance to name it GRAPHite.",
          "score": 1,
          "created_utc": "2026-01-01 13:11:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2pqds",
              "author": "Fit-Presentation-591",
              "text": "I mean I can edit text its not like that's immutable.",
              "score": 2,
              "created_utc": "2026-01-01 13:15:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx2y1vn",
                  "author": "eternviking",
                  "text": "Do it. Will be worth it.",
                  "score": 1,
                  "created_utc": "2026-01-01 14:15:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxn5ia3",
          "author": "Bjalal",
          "text": "Wÿ§ÿ´ÿ§ÿåÿå¬§„Ää Ÿ©ÿ±",
          "score": 1,
          "created_utc": "2026-01-04 15:58:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5mjzy",
      "title": "ChatEpstein with LangChain",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q5mjzy/chatepstein_with_langchain/",
      "author": "br3nn21",
      "created_utc": "2026-01-06 16:02:51",
      "score": 24,
      "num_comments": 29,
      "upvote_ratio": 0.96,
      "text": "While there‚Äôs been a lot of information about Epstein released, much of it is very unorganized. There have been platforms like¬†jmail.world, but it still contains a wide array of information that is difficult to search through quickly.\n\nTo solve these issues, I created¬†[ChatEpstein](https://chat-epstein.vercel.app/), a chatbot with access to the Epstein files to provide a more targeted search. Right now, it only has a subset of text from the documents, but I was planning on adding more if people were more interested. This would include more advanced data types (audio, object recognition, video) while also including more of the files.\n\nHere‚Äôs the data I‚Äôm using:\n\n**Epstein Files Transparency Act (H.R.4405)**¬†\\-> I extracted all pdf text\n\n**Oversight Committee Releases Epstein Records Provided by the Department of Justice**¬†\\-> I extracted all image text\n\n**Oversight Committee Releases Additional Epstein Estate Documents**¬†\\-> I extracted all image text and text files\n\nOverall, this leads to about 300k documents total.\n\nWith all queries, results will be quoted and a link to the source provided. This will be to prevent the dangers of hallucinations, which can lead to more misinformation that can be very harmful. Additionally, proper nouns are strongly highlighted with searches. This helps to analyze specific information about people and groups. My hope with this is to increase accountability while also minimizing misinformation.\n\nFeel free to let me know if there are any issues or improvements you'd let me see. I‚Äôd love to grow this and get it into the hands of more people to spread more information about the Epstein Files.\n\n[https://chat-epstein.vercel.app/](https://chat-epstein.vercel.app/)  \n\n\n[](https://www.reddit.com/submit/?source_id=t3_1q5lgnw)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q5mjzy/chatepstein_with_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "ny0z4uq",
          "author": "br3nn21",
          "text": "Here‚Äôs the tech I used:\n\nFor initial storage, I put all the files in an AWS S3 bucket. Then, I used Pinecone as a vector database for the documents. For my chunking strategy, I initially used a character count of 1024 for each chunk, which worked well for long, multipage documents. However, since many of the documents are single-page and have a lot of continuous context, I have been experimenting with a page-based chunking strategy. Additionally, I am using spAcy to find people, places, and geopolitical entities.¬†\n\nDuring the retrieval phase, I am fetching both using traditional methods and using entity-based matching. Doing both of these gives me more accurate but diverse results. I am also having it keep track of the last 2 2 exchanges (4 messages: 2 user + 2 assistant). Overall, this gives me a token usage of 2k-5k. Because I‚Äôm semi-broke, I‚Äôm using Groq‚Äôs cheap llama-3.1-8b-instant API.\n\nOne of the most important parts of this phase is accuracy. Hallucinations from an LLM are an inherent certainty in some instances. As a result, I have ensured that I am not only providing information, but also quotes, sources, and links to every piece of information. I also prompted the LLM to try to avoid making assumptions not directly stated in the text.\n\nWith that being said, I‚Äôm certain that there will be issues, given the non-deterministic nature of AI models and the large amount of data being fed. If anyone finds any issues, please let me know! I‚Äôd love to fix them to make this a more usable tool.",
          "score": 3,
          "created_utc": "2026-01-06 16:02:59",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny42mo2",
              "author": "timmy166",
              "text": "You need to do a summary pass for first line retrieval for a dataset this massive. Going straight to vector DB embeddings will lose a lot of context unless your prompt is absolutely massive",
              "score": 2,
              "created_utc": "2026-01-07 00:46:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2ntb1",
          "author": "Radiate_Wishbone_540",
          "text": "Sent this: \"Who are the most surprising associates of Epstein?\"\n\nAnd got this: \"There was an error processing your request. Please try again.\"",
          "score": 2,
          "created_utc": "2026-01-06 20:38:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny39p8g",
              "author": "br3nn21",
              "text": "So that message actually indicates an API issue, and I saw a 500 request around the time you posted this. Currently, the rate of these errors is much less than 1%, and I'm assuming it's due to either updates or memory issues (which I should have fixed)",
              "score": 1,
              "created_utc": "2026-01-06 22:19:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny13sr8",
          "author": "mdrxy",
          "text": "Nice, can you share the source repo?",
          "score": 1,
          "created_utc": "2026-01-06 16:24:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1ipv9",
              "author": "br3nn21",
              "text": "So I accidentally posted the .env files in an early commitüòÖ I should be able to reclone it tho and make it public for people to check out",
              "score": 2,
              "created_utc": "2026-01-06 17:32:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1tz4v",
                  "author": "Still-Ad3045",
                  "text": "Nuke it first lol",
                  "score": 1,
                  "created_utc": "2026-01-06 18:22:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny22f6r",
              "author": "br3nn21",
              "text": "A little messy, but here's the cleaned repo: [https://github.com/BrennenFa/ChatEpstein](https://github.com/BrennenFa/ChatEpstein)",
              "score": 1,
              "created_utc": "2026-01-06 18:59:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1f1ud",
          "author": "OnyxProyectoUno",
          "text": "300k documents is where you start hitting real preprocessing bottlenecks. The issue isn't just volume, it's that OCR'd text from images and PDFs usually comes out messy and your chunking strategy becomes critical for retrieval quality.\n\nWith that much extracted text, you're probably seeing inconsistent formatting between the PDF extractions and image OCR results. The image text especially tends to have weird spacing, broken words, and missing context that makes chunking unpredictable. I've been building document processing tooling at vectorflow.dev specifically because this preprocessing stage is where most RAG systems break down silently.\n\nA few things to watch out for: OCR'd proper nouns (which you mentioned highlighting) often get mangled during extraction, so \"Jeffrey Epstein\" might become \"Jeffrey Ep stein\" in some chunks but not others. Your retrieval will miss these variations. Also, with 300k docs, you'll want to preserve document-level metadata (source file, date, document type) and make sure it propagates to every chunk, otherwise you lose the citation trail you're trying to maintain.\n\nFor accountability applications like this, consider adding entity extraction during preprocessing to tag people, organizations, and dates consistently across all documents. This gives you much better retrieval precision than just relying on semantic similarity.\n\nWhat does your current chunking strategy look like, and are you seeing consistency issues between the PDF and image-extracted content?",
          "score": 1,
          "created_utc": "2026-01-06 17:15:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1jqca",
              "author": "br3nn21",
              "text": "Thanks for the comment! Lots of good stuff here for me to respond to\n\nRetrieval quality is definetly one of the biggest issues, especially since I‚Äôm trying to remain token efficient. The proper noun system has not been perfect like you said, so I‚Äôve been using it with a mix of traditional retrieval. These entities are also stored as metadata which makes the querying more efficient\n\nI stored metadata, like source, file name, s3 location etc. in the vector db for sourcing like u said. At this scale, it‚Äôs definitely been something I had to mess around with. At one point I even uploaded tens of thousands of documents with the wrong sources and that made citations incorrect.\n\n\nCurrently I‚Äôm doing page based (may files are single page so not to complex). I haven‚Äôt compared the different between character and page based but was planning on doing so and using feedback from users as well",
              "score": 1,
              "created_utc": "2026-01-06 17:36:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1z6wf",
                  "author": "OnyxProyectoUno",
                  "text": "Page-based chunking makes sense for single page docs, but you'll probably hit issues where related information spans pages or where OCR artifacts create artificial boundaries mid-sentence. The metadata approach is solid though, especially storing S3 locations for the citation trail.\n\nThat upload mistake with wrong sources sounds painful but it's exactly the kind of silent failure that kills trust in these systems. With mixed retrieval combining semantic and entity matching, you're probably getting better recall on mangled proper nouns, but I'd be curious about your precision. Are users getting too many irrelevant results when entity extraction picks up common names across unrelated contexts?\n\nFor the character vs page comparison, user feedback is good but also check retrieval metrics if you can. Page chunks might miss connections between related content that got split arbitrarily, while character chunks might break up important document structure. Depends on how structured your source documents are.",
                  "score": 2,
                  "created_utc": "2026-01-06 18:45:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1k7p9",
          "author": "forevergeeks",
          "text": "Why are you guys using AI to write comments? It makes the whole interaction soulless. \n\nI used the chatbot, and yes, the two Bills are in the files, Bill Clinton, and Bill Gates! üòú",
          "score": 1,
          "created_utc": "2026-01-06 17:39:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1lr0w",
              "author": "battlepi",
              "text": "So, tell me how you feel about the traitor and serial child rapist, Donald Trump?",
              "score": 3,
              "created_utc": "2026-01-06 17:46:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1mk9z",
                  "author": "forevergeeks",
                  "text": "I feel great! he just got Nicolas Maduro out of Venezuela, and maybe he is going after the Colombian president next!!",
                  "score": -1,
                  "created_utc": "2026-01-06 17:49:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1m1oa",
          "author": "forevergeeks",
          "text": "is this thing hallucinating? I asked this question: **top 10 famous people in the files**\n\nand got:\n\nBased on the provided documents, I found the following information about the top 10 famous people mentioned:\n\n1. **Vladimir Putin**: Topped the Russian poll with a whopping 24%¬†\n2. **Lionel Messi**: Had broader support, reaching 15th in the world¬†\n3. **David Beckham**: Squeaked into 10th place in Britain¬†\n4. **Edward Snowden**: 10th most admired in the country that granted him asylum¬†\n5. **Angela Merkel**: Scored 65 times higher at 13% in Germany¬†\n6. **The Pope**: Second only to Angela Merkel in Germany¬†\n7. **Nigel Farage**: In 16th place in Britain¬†\n8. **David Cameron**: Received the \"most admired\" accolade from only two people in a thousand in Britain\n9. **Nicolas Sarkozy**: Third in France¬†\n10. **Goodluck Jonathan**: 8th in Nigeria¬†\n\n**Sources:**\n\n* **HOUSE\\_OVERSIGHT\\_022344, Page 1.0 - Oversight Committee Releases Additional Epstein Estate Documents**¬†\\-¬†View Document",
          "score": 1,
          "created_utc": "2026-01-06 17:47:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1qg1z",
              "author": "br3nn21",
              "text": "That's really strange, thanks for the comment!  I had loosened its strictness with looking at the database to allow it to make general inferences in certain instances, but it looks like it's leading to issues such as this. I just changed the prompt and the fixes should be fixed shortly. Using your same prompt, I got these results:\n\n  \nAnswer: I don't have information about that in the documents.\n\nHowever, I can tell you that the documents mention the following individuals:\n\n1. Prince Andrew (DOJ-OGR-00024825, Page 1.0)\n\n2. Bill Clinton (DOJ-OGR-00024826, Page 2.0)\n\n  \nAnswer: I don't have information about that in the documents.\n\n  \nAdditionally, I'm currently using llama 3.1. Because it's the cheapest modell I'm very certain that, especially for how large a dataset I'm giving it and how much I'm trying to limit extreme token usage (I'm broke), there are instances where it will not collect every instance of information at once",
              "score": 1,
              "created_utc": "2026-01-06 18:06:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2nvn5",
                  "author": "Radiate_Wishbone_540",
                  "text": "Add a button for people to donate to the project?",
                  "score": 2,
                  "created_utc": "2026-01-06 20:38:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3cia2",
          "author": "Radiate_Wishbone_540",
          "text": "Hallucination/nonsensical response: \"Prince Andrew was reportedly asked by lawyers, \"Have you ever been made to perform sexually on Prince Andrew?\" and Nadia replied with \"Fifth\" (Document 2, Page 1.0 and Document 4, Page 1.0)\"",
          "score": 1,
          "created_utc": "2026-01-06 22:32:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3e8md",
              "author": "br3nn21",
              "text": "So in this instance, I believe Nadia is pleading the fifth, which means she's reserving her right to not say anything in a trial. To me, that would make sense. However, it could also be that the chunk got cut off",
              "score": 1,
              "created_utc": "2026-01-06 22:41:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny4inqf",
                  "author": "Radiate_Wishbone_540",
                  "text": "No, the sentence structure is completely absurd (unless I'm going crazy). The sentence suggests that Prince Andrew was asked if he ever had to have sex with... Prince Andrew...",
                  "score": 2,
                  "created_utc": "2026-01-07 02:12:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pykyuj",
      "title": "Are agent evals the new unit tests?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pykyuj/are_agent_evals_the_new_unit_tests/",
      "author": "Hot-Guide-4464",
      "created_utc": "2025-12-29 12:23:16",
      "score": 22,
      "num_comments": 14,
      "upvote_ratio": 0.8,
      "text": "I‚Äôve been thinking about this a lot as agent workflows get more complex. Because in software, we‚Äôd never ship anything without unit tests. But right now most people just ‚Äútry a few prompts‚Äù and call it good. That clearly doesn‚Äôt scale once you have agents doing workflow automation or anything that has a real failure cost.\n\nSo I‚Äôm wondering if we‚Äôre moving to a future where CI-style evals become a standard part of building and deploying agents? Or am I overthinking it and we‚Äôre still too early for something this structured? I‚Äôd appreciate any insights on how folks in this community are running evals without drowning in infra.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1pykyuj/are_agent_evals_the_new_unit_tests/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwjsa3j",
          "author": "Kortopi-98",
          "text": "I think evals have to become the new unit tests because once an agent interacts with real data or systems, \"vibes-based QA\" becomes a liability. So we‚Äôve been moving towards lightweight CI-like evals for our internal agents. Nothing super formal, just a set of representative tasks and expected behaviors. Just so you know, setting up the infra for this sucks unless you build your own harness. We switched to Moyai because they make this a lot less painful. Their eval workflow is basically: define agent, run them across diverse tasks, get diffs or outliers, done.",
          "score": 10,
          "created_utc": "2025-12-29 14:28:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjyb12",
              "author": "Hot-Guide-4464",
              "text": "Are you testing reasoning chains, final outputs or both?",
              "score": 2,
              "created_utc": "2025-12-29 15:00:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwk4dqi",
                  "author": "Kortopi-98",
                  "text": "Both. You can check the final result (e.g. reasoning steps, metrics pulled) but also the intermediate reasoning if you want consistency across steps. We treat it almost like snapshot tests for LLMs.",
                  "score": 2,
                  "created_utc": "2025-12-29 15:31:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwjhors",
          "author": "imnotafanofit",
          "text": "We started doing mini regression suite for agents. They're fast and lightweight but the biggest challenge is infra though. Spinning up evals can get expensive if you run them often.",
          "score": 6,
          "created_utc": "2025-12-29 13:25:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjnm9b",
              "author": "Hot-Guide-4464",
              "text": "Yep, infra costs are kind of an underrated part of this conversation. How are you managing overhead?",
              "score": 3,
              "created_utc": "2025-12-29 14:01:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwj9wzh",
          "author": "charlyAtWork2",
          "text": "Most of the time is only ETL.\n\nA boring step by step transformation with LLM in the middle.",
          "score": 4,
          "created_utc": "2025-12-29 12:31:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwld9em",
          "author": "MathematicianSome289",
          "text": "See em as more integration tests than unit tests. Evals test how the pieces work together. Units test the individual pieces.",
          "score": 4,
          "created_utc": "2025-12-29 19:01:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlo4uu",
          "author": "hidai25",
          "text": "I‚Äôm mostly with you, but I don‚Äôt think it maps 1:1 to unit tests. For agents it feels more like integration/regression tests, because the ‚Äúoutput string‚Äù is the least stable thing in the system. What *is* stable is behavior: did it call the right tools, avoid the wrong ones, return valid structure, and stay within time/$ budgets.\n\nThe only way I‚Äôve seen this not turn into eval-infra hell is keeping a small ‚Äúthis can‚Äôt break‚Äù suite in CI, running the bigger flaky stuff nightly, and turning every real failure into a test case. That‚Äôs when it starts compounding like real testing.\n\nFull disclosure: I‚Äôm building an OSS harness around exactly this idea (EvalView). If it‚Äôs useful, it‚Äôs here: [https://github.com/hidai25/eval-view]()",
          "score": 2,
          "created_utc": "2025-12-29 19:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa9f75",
          "author": "No-Common1466",
          "text": "Absolutely spot on ‚Äì agent evals are becoming the new unit tests (or more accurately, the new integration/regression suite) for anything that's going to touch production.\n\nTraditional software has deterministic functions, so unit tests with exact assertions work great. Agents? They're non-deterministic, multi-turn, tool-using beasts that can go off the rails in infinite creative ways. \"Try a few prompts\" catches the obvious hallucinations, but it won't save you when a real user phrashes something weirdly, injects noise, or triggers an edge case in a 20-step workflow.\n\nFrom LangChain's own State of Agent Engineering report (late 2025 survey): observability is basically table stakes now (\\~89% adoption), but offline evals on test sets are only at \\~52%. That gap is closing fast though ‚Äì teams shipping real-stakes agents (workflow automation, customer-facing, etc.) are treating evals as non-negotiable regression gates in CI/CD, just like we do with code.\n\nLangSmith/LangGraph is pushing hard here with multi-turn evals, trajectory evaluators, open evals catalog, and even running evals directly in Studio. Other tools (Braintrust, Promptfoo, etc.) are making it easy to fail builds on dropping robustness scores.\n\nThe missing piece a lot of folks run into: most evals focus on correctness (did it get the right answer?), but in production the bigger killer is robustness (does it still work when the input is sloppy, paraphrased, noisy, or adversarial?). That's where adversarial stress-testing comes in ‚Äì mutate prompts automatically and enforce invariants to quantify how \"flaky\" your agent really is.\n\nWe're still early-ish, but the direction is clear: no serious agent ships without automated evals in the pipeline. Curious ‚Äì what tools/workflows are you all using today to avoid drowning in manual testing?\n\n(Full disclosure: I'm building an open-source tool called Flakestorm exactly for the robustness side ‚Äì local-first adversarial mutations + reports. Early days, would love feedback if anyone wants to kick the tires. LInk here: https://github.com/flakestorm/flakestorm)",
          "score": 2,
          "created_utc": "2026-01-02 17:20:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhh1zj",
              "author": "Born_Owl7750",
              "text": "Interesting idea. Do you plan to support hosted model APIs from Azure or Open AI?",
              "score": 1,
              "created_utc": "2026-01-03 18:49:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxjo8vs",
                  "author": "No-Common1466",
                  "text": "Hi, yes but that would be on the cloud version. Still on the roadmap, to see if there's demand. There's a waitlist page on the website for those who are interested. I'll build it there's enough traction",
                  "score": 1,
                  "created_utc": "2026-01-04 01:28:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm58wp",
          "author": "piyaviraj",
          "text": "We use evals as agent dev testing tool as a part of what we call agent development life cycle. Since it is part of the dev testing, every changes like prompt changes, tool changes, memory schema changes, etc are covered during the dev testing for the agents and their orchestration. This will ensure changes will not break the logic(reasoning) assumptions and as well as integration assumptions. However, we do not configure eval evaluation in a regular build CI or local build because for large project the token economics will be hard to justify at scale.",
          "score": 1,
          "created_utc": "2025-12-29 21:17:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx06uuq",
          "author": "Severe_Insurance_861",
          "text": "Within my team we call them regression eval. 400 examples covering a variety of scenarios.",
          "score": 1,
          "created_utc": "2026-01-01 00:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0znnd",
          "author": "Fit-Presentation-591",
          "text": "I‚Äôd say they‚Äôre more analogous to a mix of CI/CD and production testing TBH. They‚Äôre a bit more complex than your average unit test IME.",
          "score": 1,
          "created_utc": "2026-01-01 03:37:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q38zoo",
      "title": "Built a Lovable with Deepagents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q38zoo/built_a_lovable_with_deepagents/",
      "author": "Releow",
      "created_utc": "2026-01-03 23:01:18",
      "score": 22,
      "num_comments": 12,
      "upvote_ratio": 0.89,
      "text": "Hi guys, just wanted to share my project done used to deep dive into the deepagents architecture.\n\nIt is a little coding agent to build react app inspired by lovable.\n\n[https://github.com/emanueleielo/deepagents-open-lovable](https://github.com/emanueleielo/deepagents-open-lovable)\n\nAsking for feedback!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q38zoo/built_a_lovable_with_deepagents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxjh686",
          "author": "hwchase17",
          "text": "This is great!",
          "score": 6,
          "created_utc": "2026-01-04 00:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlhfrh",
              "author": "Releow",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-01-04 08:57:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxk046x",
          "author": "vtrivedy-lc",
          "text": "Hey this is awesome!!  Also nice agent eng design with the subagent delegation.  Would love to hear how it went using deepagents and how we can make it better to help you build more cool stuff :). Will DM you!",
          "score": 3,
          "created_utc": "2026-01-04 02:33:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxk6oi0",
          "author": "hot4botz",
          "text": "nice work!",
          "score": 2,
          "created_utc": "2026-01-04 03:10:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxkddnm",
          "author": "Feisty-Promise-78",
          "text": "Great work! Did you come up with the prompt as by yourself or ask AI to generate it or you copy pasted from some else?",
          "score": 2,
          "created_utc": "2026-01-04 03:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlhbrz",
              "author": "Releow",
              "text": "I‚Äôve been inspired from claude code frontend design skill",
              "score": 1,
              "created_utc": "2026-01-04 08:56:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxll5qg",
                  "author": "Feisty-Promise-78",
                  "text": "Can you share the link of it? I am now aware of it",
                  "score": 1,
                  "created_utc": "2026-01-04 09:31:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxkz6xb",
          "author": "monkeybrain_",
          "text": "Seems pretty interesting, will come back later to review in detail. Did you build the skills middleware yourself?",
          "score": 2,
          "created_utc": "2026-01-04 06:18:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlhxte",
              "author": "Releow",
              "text": "Yes, inspired by deepagents cli",
              "score": 2,
              "created_utc": "2026-01-04 09:02:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxl59pv",
          "author": "lundrog",
          "text": "Ill check this out",
          "score": 2,
          "created_utc": "2026-01-04 07:08:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlfd3h",
          "author": "ryan1257",
          "text": "I‚Äôm curious. Won‚Äôt your GitHub saved app simply be ingested by AI?",
          "score": 1,
          "created_utc": "2026-01-04 08:38:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q23mny",
      "title": "I mutation-tested my LangChain agent and it failed in ways evals didn‚Äôt catch",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q23mny/i_mutationtested_my_langchain_agent_and_it_failed/",
      "author": "No-Common1466",
      "created_utc": "2026-01-02 16:48:05",
      "score": 17,
      "num_comments": 4,
      "upvote_ratio": 0.91,
      "text": "I‚Äôve been working on an agent that passed all its evals and manual tests.\n\nOut of curiosity, I ran it through mutation testing  small changes like:\n\n\\- typos\n\n\\- formatting changes\n\n\\- tone shifts\n\n\\- mild prompt injection attempts\n\n\n\nIt broke. Repeatedly.\n\n\n\nSome examples:\n\n\\- Agent ignored tool constraints under minor wording changes\n\n\\- Safety logic failed when context order changed\n\n\\- Agent hallucinated actions it never took before\n\n\n\nI built a small open-source tool to automate this kind of testing (Flakestorm).\n\nIt generates adversarial mutations and runs them against your agent.\n\n\n\nI put together a minimal reproducible example here:\n\n GitHub repo:  [https://github.com/flakestorm/flakestorm](https://github.com/flakestorm/flakestorm)\n\nExample: [https://github.com/flakestorm/flakestorm/tree/main/examples/langchain\\_agent](https://github.com/flakestorm/flakestorm/tree/main/examples/langchain_agent)\n\n\n\nYou can reproduce the failure locally in \\~10 minutes:\n\n\\- pip install\n\n\\- run one command\n\n\\- see the report\n\n\n\nThis is very early and rough - I‚Äôm mostly looking for:\n\n\\- feedback on whether this is useful\n\n\\- what kinds of failures you‚Äôve seen but couldn‚Äôt test for\n\n\\- whether mutation testing belongs in agent workflows at all\n\n\n\nNot selling anything. Genuinely curious if others hit the same issues.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q23mny/i_mutationtested_my_langchain_agent_and_it_failed/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxat6a4",
          "author": "Reasonable-Life7326",
          "text": "Of, that's rough. Glad you found it though!",
          "score": 1,
          "created_utc": "2026-01-02 18:51:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxcs9hd",
              "author": "No-Common1466",
              "text": "Yeah",
              "score": 1,
              "created_utc": "2026-01-03 00:51:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxd5g1d",
          "author": "erikg1337",
          "text": "Flakestorm looks very interesting..",
          "score": 1,
          "created_utc": "2026-01-03 02:07:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd5tbp",
              "author": "No-Common1466",
              "text": "Thanks. it started as a way to catch failures in my own agents that evals missed.\nStill early, but I‚Äôm curious what others are using (or missing) today",
              "score": 1,
              "created_utc": "2026-01-03 02:09:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q4rm66",
      "title": "I Finished a Fully Local Agentic RAG Tutorial",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q4rm66/i_finished_a_fully_local_agentic_rag_tutorial/",
      "author": "CapitalShake3085",
      "created_utc": "2026-01-05 17:15:28",
      "score": 17,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hi,\nI‚Äôve just finished a **complete Agentic RAG tutorial + repository** that shows how to build a fully local, end-to-end system.\n\nNo APIs, no cloud, no hidden costs.\n\n---\n\n### üí° What‚Äôs inside\n\nThe tutorial covers the full pipeline, including the parts most examples skip:\n\n- PDF ‚Üí Markdown ingestion  \n- Hierarchical chunking (parent / child)  \n- Hybrid retrieval (dense + sparse)  \n- Vector store with **Qdrant**  \n- Query rewriting + **human-in-the-loop**  \n- Context summarization  \n- **Multi-agent map-reduce** with **LangGraph**  \n- Local inference with **Ollama**  \n- Simple **Gradio** UI\n\n---\n\n### üéØ Who it‚Äôs for\n\nIf you want to **understand Agentic RAG by building it**, not just reading theory, this might help.\n\n---\n\n### üîó Repo\n\n https://github.com/GiovanniPasq/agentic-rag-for-dummies",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1q4rm66/i_finished_a_fully_local_agentic_rag_tutorial/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q5gfsx",
      "title": "So I've been losing my mind over document extraction in insurance for the past few years and I finally figured out what the right approach is.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q5gfsx/so_ive_been_losing_my_mind_over_document/",
      "author": "GloomyEquipment2120",
      "created_utc": "2026-01-06 11:46:32",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "I've been doing document extraction for insurance for a while now and honestly I almost gave up on it completely last year. Spent months fighting with accuracy issues that made no sense until I figured out what I was doing wrong.\n\neveryone's using llms or tools like LlamaParse for extraction and they work fine but then you put them in an actual production env and accuracy just falls off a cliff after a few weeks. I kept thinking I picked the wrong tools or tried to brute force my way through (Like any distinguished engineer would do XD) but it turned out to be way simpler and way more annoying.\n\nSo if you ever worked in an information extraction project you already know that most documents have literally zero consistency. I don't mean like \"oh the formatting is slightly different\" , I mean every single document is structured completely differently than all the others.\n\nFor example in my case : a workers comp FROI from California puts the injury date in a specific box at the top. Texas puts it in a table halfway down. New York embeds it in a paragraph. Then you get medical bills where one provider uses line items, another uses narrative format, another has this weird hybrid table thing. And that's before you even get to the faxed-sideways handwritten nightmares that somehow still exist in 2026???\n\nSadly llms  have no concept of document structure. So when you ask about details in a doc  it might pull from the right field, or from some random sentence, or just make something up. \n\nAfter a lot of headaches and honestly almost giving up completely, I came across a process that might save you some pain, so I thought I'd share it:\n\n1. Stop throwing documents at your extraction model blind. Build a classifier that figures out document type first (FROI vs medical bill vs correspondence vs whatever). Then route to type specific extraction. This alone fixed like 60% of my accuracy problems. (Really This is the golden tip ... a lot of people under estimate classification)\n\n2.  Don't just extract and hope. Get confidence scores for each field. \"I'm 96% sure this is the injury date, 58% sure on this wage calc\" Auto-process anything above 90%, flag the rest. This is how you actually scale without hiring people to validate everything AI does.\n\n3. Layout matters more than you think. Vision-language models that actually see the document structure perform way better than text only approaches. I switched to Qwen2.5-VL and it was night and day.\n\n4. Fine-tune on your actual documents. Generic models choke on industry-specific stuff. Fine-tuning with LoRA takes like 3 hours now and accuracy jumps 15-20%. Worth it every time.\n\n5. When a human corrects an extraction, feed that back into training. Your model should get better over time. (This will save you the struggle of having to recreate your process from scratch each time)\n\nWrote a little blog with more details about this implementation if anyone wants it \"I know... Shameless self promotion). ( link in comments)  \n  \nAnyway this is all the stuff I wish someone had told me when I was starting. Happy to share or just answer questions if you're stuck on this problem. Took me way too long to figure this out.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q5gfsx/so_ive_been_losing_my_mind_over_document/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxzq4wy",
          "author": "GloomyEquipment2120",
          "text": "Link to write up : [https://kudra.ai/how-agentic-document-intelligence-transformed-workers-compensation-claims-processing-for-insurance-companies/](https://kudra.ai/how-agentic-document-intelligence-transformed-workers-compensation-claims-processing-for-insurance-companies/)",
          "score": 3,
          "created_utc": "2026-01-06 11:49:20",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "ny01ng0",
          "author": "Mammoth-Nectarine513",
          "text": "Thanks for sharing! \n\nDo you mind sharing details about fine tuning like how did you do? Where did you learn from?",
          "score": 1,
          "created_utc": "2026-01-06 13:09:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny02ixe",
              "author": "GloomyEquipment2120",
              "text": "i studied ai engineering but honestly finetuning is getting way easier with existing tools now. [kudra.ai](http://kudra.ai) and [ubiai.tools](http://ubiai.tools) are what i use in my personal tech stack.\n\nthey both have tutorials on youtube and integration is pretty straightforward.\n\nif you want more details on finetuning i'd recommend getting the theory down first. start with this guide [https://ubiai.gitbook.io/llm-guide](https://ubiai.gitbook.io/llm-guide) then maybe grab some coursera courses if you want to go deeper.\n\nbut honestly for most practical stuff the tools handle a lot of the complexity now. you just need to understand the basics",
              "score": 0,
              "created_utc": "2026-01-06 13:14:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny04m9m",
                  "author": "Mammoth-Nectarine513",
                  "text": "I will go through this for sure. Moreover, Do I need to learn deep learning as well?",
                  "score": 1,
                  "created_utc": "2026-01-06 13:27:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q4qamq",
      "title": "Anyone monitoring their LangChain/LangGraph workflows in production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q4qamq/anyone_monitoring_their_langchainlanggraph/",
      "author": "gkarthi280",
      "created_utc": "2026-01-05 16:28:37",
      "score": 13,
      "num_comments": 15,
      "upvote_ratio": 0.94,
      "text": "I‚Äôve been building a few apps using LangChain, and once things moved beyond simple chains, I ran into a familiar issue: very little visibility into what‚Äôs actually happening during execution.\n\nAs workflows get more complex (multi-step chains, agents, tool calls, retries), it gets hard to answer questions like:\n\n* Where is latency coming from?\n* How many tokens are we using per chain or user?\n* Which tools, chains, or agents are invoked most?\n* Where do errors, retries, or partial failures happen?\n\nTo get better insight, I instrumented a LangChain-based app with OpenTelemetry, exporting traces, logs, and metrics to an OTEL-compatible backend (SigNoz in my case).\n\nhttps://preview.redd.it/c6iwa9vu4kbg1.png?width=2886&format=png&auto=webp&s=c8d260a9b50eac20b714d7e68d7028a4ce228dfc\n\nYou can use the traces, logs, and metrics to create useful dashboards as well which tracks things like:\n\n* Tool call distribution\n* Errors over time\n* Token usage & cost\n\nCurious how others here think about observability for LangChain apps:\n\n* What metrics or signals are you tracking?\n* How do you evaluate chain or agent output quality over time?\n* Are you monitoring failures or degraded runs?\n\nIf anyone‚Äôs interested, I followed the LangChain + OpenTelemetry setup here:  \n[https://signoz.io/docs/langchain-observability/](https://signoz.io/docs/langchain-observability/)\n\nWould love to hear how others are monitoring and debugging LangChain workflows in production.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q4qamq/anyone_monitoring_their_langchainlanggraph/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxvagb7",
          "author": "pbalIII",
          "text": "LangSmith is the obvious choice if you're already in the LangChain ecosystem... one env var and you get full trace visibility with zero latency overhead. The async collector runs out of band so it doesn't slow your agent down.\n\nLangfuse is solid if you want something OSS or need to self-host. Works with LangGraph out of the box and gives you the same trace-level debugging.\n\nThe tricky part is figuring out what to actually monitor. Token costs and latency are easy. Catching when your agent loops or picks the wrong tool is harder. I've found step-level tracing plus a few custom evals on production traffic catches most of the weird stuff.",
          "score": 7,
          "created_utc": "2026-01-05 19:15:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxxr43",
              "author": "sweetlemon69",
              "text": "This!",
              "score": 2,
              "created_utc": "2026-01-06 03:13:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1buxx",
              "author": "gkarthi280",
              "text": "I agree. Agent loops/incorrect tool calls are super important to avoid unknown extra token usage and bills, yet super hard to monitor since these agents are so blackboxed. Interestingly, SigNoz has alerts, which you can use to actually detect these agent loops.   \n  \nJust as a simple example, you can set an alert to trigger every time an agent makes an identical tool call three times in a row or more. In this case you could be notified on any channel whenever an agent is doing these unnecessary repeated tool calls, giving you insight into when these agents are looping and how and where to optimize them and effectively lower spend.",
              "score": 1,
              "created_utc": "2026-01-06 17:00:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxv7oah",
          "author": "mdrxy",
          "text": "[https://www.langchain.com/langsmith/observability](https://www.langchain.com/langsmith/observability)",
          "score": 1,
          "created_utc": "2026-01-05 19:02:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwszqy",
          "author": "OnyxProyectoUno",
          "text": "Solid setup with OTEL, that's the right foundation. The token and latency tracking will save you a lot of headaches.\n\nOne thing I'd add: most of the \"where did this go wrong\" debugging I've done traces back upstream of the chain execution itself. Like, the retrieval returned garbage because the chunks were bad, or the tool got invoked with wrong context because metadata didn't propagate correctly. By the time you're looking at traces, you're seeing symptoms not causes.\n\nFor output quality over time, I've found it useful to log the actual retrieved chunks alongside the final response. When quality degrades, you can usually spot it in what got retrieved vs what should have. Evals on final output alone miss a lot.\n\nWhat's your retrieval setup look like? That's usually where the interesting failure modes hide.",
          "score": 1,
          "created_utc": "2026-01-05 23:35:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxjgod",
          "author": "saurabhjain1592",
          "text": "OTEL + LangSmith or Langfuse work well once you are inside LangChain execution.\n\nOne thing we kept running into in production is that many of the worst failures do not show up as errors in traces. They show up as valid executions that should not have happened, like retries with side effects, tools invoked with stale permissions, or chains continuing after the business outcome was already decided.\n\nTracing tells you what happened. You still need some notion of runtime control to decide whether it should have happened and to stop or intervene mid-run.\n\nCurious if others have hit this once workflows became long-running or stateful.",
          "score": 1,
          "created_utc": "2026-01-06 01:55:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxy8mnj",
          "author": "dinkinflika0",
          "text": "Your OTel setup handles infra metrics well but how do you track output quality?\n\nWe had the same stack and it showed us when things broke, but not why outputs degraded. Like retrieval working fine (low latency, no errors) but the agent ignoring context.\n\nAdded Maxim on top for LLM-specific metrics - hallucination rates, context usage, tool accuracy. Works with OTel but adds quality evaluation. [https://www.getmaxim.ai/products/agent-observability](https://www.getmaxim.ai/products/agent-observability)",
          "score": 1,
          "created_utc": "2026-01-06 04:18:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyjji8",
          "author": "Tough-Permission-804",
          "text": "just do replit or something similar.  the days of buulding your own workflow nightmare are over",
          "score": 1,
          "created_utc": "2026-01-06 05:33:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyph7m",
          "author": "mrpeakyblinder2",
          "text": "Try sentry",
          "score": 1,
          "created_utc": "2026-01-06 06:19:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyt7yz",
          "author": "HoldZealousideal1966",
          "text": "Mlflow",
          "score": 1,
          "created_utc": "2026-01-06 06:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz4506",
          "author": "Ok_Constant_9886",
          "text": "confident ai",
          "score": 1,
          "created_utc": "2026-01-06 08:30:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzn75e",
          "author": "jj_taylor_05",
          "text": "Have a look to phoenix, nevertheless all of this tools are so reactive, yo should look to a dashboard or set up alerts .:. We need something else",
          "score": 1,
          "created_utc": "2026-01-06 11:26:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1d9kc",
              "author": "gkarthi280",
              "text": "agreed! Just exporting traces is one step, but the real power of observability is enhanced when you are able to make relevant dashboards combined with alerts. SigNoz does include dashboard and alert features on their platform which ive found super helpful. I think the main challenge as a dev is to use these tools in a creative and efficient way to be able to detect these problems in prod and solve them effectively.",
              "score": 2,
              "created_utc": "2026-01-06 17:07:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny44vof",
          "author": "BeerBatteredHemroids",
          "text": "MLFlow",
          "score": 1,
          "created_utc": "2026-01-07 00:57:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0dpty",
      "title": "mem0, Zep, Letta, Supermemory etc: why do memory layers keep remembering the wrong things?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q0dpty/mem0_zep_letta_supermemory_etc_why_do_memory/",
      "author": "nicolo_memorymodel",
      "created_utc": "2025-12-31 14:02:45",
      "score": 11,
      "num_comments": 7,
      "upvote_ratio": 0.87,
      "text": "Hi everyone,\nthis question is for people building AI agents that go a bit beyond basic demos.\nI keep running into the same limitation: many memory layers (mem0, Zep, Letta, Supermemory, etc.) decide for you what should be remembered.\n\nConcrete example: contracts that evolve over time\n‚Äì initial agreement\n‚Äì addenda / amendments\n‚Äì clauses that get modified or replaced\n\nWhat I see in practice:\nRAG: good at retrieving text, but it doesn‚Äôt understand versions, temporal priority, or clause replacement.\nVector DBs: they flatten everything, mixing old and new clauses together.\n\nMemory layers: they store generic or conversational ‚Äúmemories‚Äù, but not the information that actually matters, such as:\n\n-clause IDs or fingerprints\n-effective dates\n-active vs superseded clauses\n-relationships between different versions of the same contract\n\nThe problem isn‚Äôt how much is remembered, but what gets chosen as memory.\n\nSo my questions are:\nhow do you handle cases where you need structured, deterministic, temporal memory?\n\ndo you build custom schemas, graphs, or event logs on top of the LLM?\n\nor do these use cases inevitably require a fully custom memory layer?",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1q0dpty/mem0_zep_letta_supermemory_etc_why_do_memory/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwxs397",
          "author": "southern_gio",
          "text": "Have you tried EverMemOS?",
          "score": 1,
          "created_utc": "2025-12-31 16:39:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2gvr1",
              "author": "nicolo_memorymodel",
              "text": "Honestly no, do you think it could be right for me? \nI am very interested in deciding what kind of memories to save mainly",
              "score": 1,
              "created_utc": "2026-01-01 11:57:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwz0z2s",
          "author": "rkpandey20",
          "text": "All of these memory layers just solve the problem of compaction of context. Compaction can be done on context from many different ways and depending on the use case, some may work better than others.¬†\nI am not sure if general purpose memory layer can solve all use cases. You may have to plug-in your code to extract important bits from the context and preserve it.¬†",
          "score": 1,
          "created_utc": "2025-12-31 20:27:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0qbi4",
          "author": "BeerBatteredHemroids",
          "text": "Idk wtf you're talking about. You can store anything you want in your database as memory. Why are you pretending like you have no choice in the matter? Im not even sure you know what you're talking about.",
          "score": 0,
          "created_utc": "2026-01-01 02:33:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2h7db",
              "author": "nicolo_memorymodel",
              "text": "Wow, quiet haha\n\nSaving them in my personal db means managing vdb, building ingestion and retrieval middleware, avoiding duplicates, and structuring the vdb so that it scales over time without creating hallucinations in memory retrieval. \n\nThere are great (cloud-managed) systems that do this, but I struggle to find one that fits very vertical use cases, they are mainly made for personal assistants",
              "score": 1,
              "created_utc": "2026-01-01 12:00:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q5rtr8",
      "title": "I applied \"Systemic Design\" principles from Game Dev (BioShock/Star Wars) to AI Agents. Here is why it works better than hard-coding.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q5rtr8/i_applied_systemic_design_principles_from_game/",
      "author": "reidkimball",
      "created_utc": "2026-01-06 19:11:00",
      "score": 10,
      "num_comments": 3,
      "upvote_ratio": 0.86,
      "text": "I spent 10+ years as a game designer (LucasArts) before moving into AI and App development. In games, we rely heavily on \"Systemic Design\" where we create systems (physics, AI rules, environmental hazards) that interact to create emergent gameplay instead of scripting every single moment.\n\nI‚Äôve been applying this same philosophy to building AI Agents, and I think it solves the \"brittleness\" problem a lot of us are facing with LLMs.\n\n**The Problem: Deterministic vs. Systemic**  \nWhen I started building my current health app (Meadow Mentor), my instinct was to hard-code logic for safety.\n\n* The Old Way: Write endless if/else statements. If user.isDairyFree AND item == 'milk', then suggest\\_alternative().\n* The Issue: This doesn't scale. You spend weeks mapping out edge cases.\n\n**The Solution: Systemic Agent Design**  \nInstead of scripting the path, I set up a system consisting of three parts:\n\n1. **Dynamic Data:** The user's live state (e.g., \"Dairy-Free,\" \"High Stress\").\n2. **Systemic Tools:** Functions like addToShoppingList or updateStressLevel.\n3. **Reasoning:** An LLM with a system prompt to strictly adhere to health safety.\n\n**The Result (Emergent Behavior)**  \nI tested this by asking my agent to \"add milk, eggs, and bananas\" to my list while my profile was set to Dairy-Free.\n\nI hadn't written a specific script to handle this conflict. However, the agent paused, analyzed the input against the **Dynamic Data**, and refused the request. It autonomously suggested swapping for Oat or Almond milk. Once I confirmed, it called the tool with the safe ingredients.\n\nWhat would have been a 2-week sprint of mapping out diet vs. ingredient conflicts took about an hour to set up as a system.\n\n**The Takeaway**  \nIf you are building agents, stop trying to predict every user path. Focus on defining the \"physics\" of your app (the tools) and the \"environment\" (the data) and let the model handle the navigation.\n\nI wrote a longer breakdown of the logic and the \"Recipe Search\" implementation on my site if anyone wants to see the specific setup:\n\n[https://reidkimball.com/journal/systemic-agent-design/](https://reidkimball.com/journal/systemic-agent-design/)\n\nAre you building Systemic Agents? Feel free to reach out, would love to share notes and help each other grow in this new discipline.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q5rtr8/i_applied_systemic_design_principles_from_game/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "ny2ezdm",
          "author": "Objective-Fig-4250",
          "text": "You can go even more meta than this. By your analogy, choose \"physics\" (tools) as - application types you want - assistant / researcher / consultant - \"environment\" (data) as - sectors like HealthCare / education / environment & let LLM think of ways to jot down & connect all these low-level components, to form something cohesive & workable at a high level - like your \"Meadows Mentor\" application.\n\nThe excerpt above is just to state that this paradigm of agentic AI development was designed with EXACTLY this methodology or workflow in mind, that you have eventually have come across in your own explorations - of defining the tools + data & letting the LLM come up with reasoning of what control flow the program should opt for. Without needing to chart your own decision tree of all possible scenarios & edge cases! \n\nIf I am wrong, please correct me, but I think you've just rehashed what agentic development expects of us, based on your own deep understanding of game development. I can't seem to find that great of a distinction here. Sorry, if I misread what you're trying to convey. Like, for example, how will \"your way\" reduce confabulations of a diet plan that adheres to constraints by suggesting something that's not edible ?",
          "score": 5,
          "created_utc": "2026-01-06 19:57:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny32v1b",
              "author": "reidkimball",
              "text": "Hey thank you for the thoughtful reply. You may be right that I'm already describing what is expected of AI Agent Engineers. I think that's great! I'd like to connect with other AI Agent Engineers. \n\nGood question about preventing confabulations. As I'm sure you know, that often happens when an AI relies on its training data or lack of data. My systemic approach grounds everything in a user's current reality, like the physics engine in a game world.   \n  \nThe AI doesn't rely on its training data, but the data of the user, the rules of the therapeutic diet, and data about food in my custom food database. It's like if an AI enemy tries to run through a wall in a video game, it can't because the physics system won't allow it to.   \n  \nIn my health app, the AI can't produce wrong answers because my system won't allow it to. If the AI produces a recipe JSON with ingredients not allowed, the system prompts it to retry again until the recipe is approved. Because I first ground the AI in rules of the diet, and user data, it usually nails it 9/10 times. When it doesn't, it takes one revision to fix it.",
              "score": 2,
              "created_utc": "2026-01-06 21:47:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny52cvr",
                  "author": "Objective-Fig-4250",
                  "text": "So kind of like RLHF hyperscaled by self-supervision - where you design the template (\"physics\") as a system that holds the last authority to approve the diet plan before the user sees it. See, exactly this is how crude, pre-trained models like GPT are polished into a serviceable products like ChatGPT, inferences of which are increasingly more \"aligned\" to human-like responses with time. I personally haven't encountered the hot paths that trigger its confabulations until something that I ask about requires multi-step, complex planning or/and is esoteric.\n\nI think these extrinsic, cosmetic checks are still duct-tape fixes to the more innate architectural choices of transformer network & the current way of how computation is being utilised towards simulating intelligent human behavior. These are well & good, until the day they are not. RAG, vector stores, etc. all are meant for grounding the responses, AFTER they had been 'conjured' up by the network.\n\nHave you stress-tested your application under various use-cases ? Given your LLM sees the diet plan, health history, how do you ensure that LLM puts  the optimal set of food items in the cart, of all the allowed permutations & combinations ?",
                  "score": 2,
                  "created_utc": "2026-01-07 04:03:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pzierz",
      "title": "I built a lightweight, durable full stack AI orchestration framework",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pzierz/i_built_a_lightweight_durable_full_stack_ai/",
      "author": "Worried_Market4466",
      "created_utc": "2025-12-30 13:41:19",
      "score": 9,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "Hello everyone,\n\nI've been building agentic webapps for around a year and a half now. Started with loops, then moved onto langgraph + Assistant UI. I've been using the lang ecosystem since their launch and have seen their evolution.\n\nIt's great and easy to build agents, but things got really frustrating once I needed more fine grained control, especially has a hard time building interesting user experiences. I loved the idea of building agents as DAGs, but I really wanted to model UIs in my flow as nodes too. \n\nDeployment was another nightmare. I am kinda cheap and the per node executed tax seemed ... Well, not great. But hey, the devs gotta eat.\n\n\nAround six months back, I snapped and started working on an idea i had been throwing around for a while. It's called Cascaide.\n\nCascaide is a lightweight low level AI orchestration framework written in typescript designed to run anywhere JS/TS can. It is primarily built for web applications. However, you can create headless AI agents and workflows with it in Node.js.\n\nHere are the reasons why you should try it out. We are in the process of opensourcing it(probably Jan first week).\n\nDeveloper Experience and UX\n\nüç± Learn Fast ‚Äì Simple, powerful abstractions you can learn over lunch\n\nüé® Build UI First ‚Äì UI and human-in-the-loop support is natural, not an add-on\n\nüèéÔ∏è Build Fast ‚Äì Single codebase (if you choose), no context switching\n\n‚è≥ Debug Easily ‚Äì Debugging and time-travel out of the box\n\nüåç Deploy Anywhere ‚Äì Deploy like any other application, no caveats\n\nü™∂ Stay Light ‚Äì Tiny bundle size, small enough to actually understand\n\nüîÆ UX Possibilities ‚Äì Enables novel UX patterns beyond chatbots: smart components, AI workflow visualization, and dynamic portalling\n\nüîå Extensibility ‚Äì Easily extend for custom capabilities via middleware patterns\n\nüßë‚ÄçüíªStack Agnostic ‚Äì Use with your favorite stack\n\nCosts\n\nZero orchestration costs in production \n\nLow TCO - far less moving parts to maintain\n\nTalent pool: enable any web dev to easily transition to AI engineering.\n\nObservability and reliability \n\n\nDurability: enterprise grade durability with no new overhead. Resume workflows post server/client crashes easily, or pick up weeks or months later.\n\nObservability and control: full observability out of the box with easy timetravel rollback and forking\n\n\nI have two production apps running on it and it's working great for us. It's very easy to use with serverless as well.\n\nI would love to talk to devs and get some feedback. We can do an early sneek peek!\n\nCheers!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1pzierz/i_built_a_lightweight_durable_full_stack_ai/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwqjlwz",
          "author": "hyma",
          "text": "is this a competitor to langgraph?",
          "score": 2,
          "created_utc": "2025-12-30 14:43:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqla0m",
              "author": "Worried_Market4466",
              "text": "Yes, it's an alternative. Especially if you've been struggling with UI integrations, deployment/pricing and prefer to work with TS. A great use case would be AI SaaS.",
              "score": 1,
              "created_utc": "2025-12-30 14:52:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwt1dzz",
                  "author": "Plaszz",
                  "text": "Interesting!",
                  "score": 1,
                  "created_utc": "2025-12-30 21:50:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwu75h4",
          "author": "Live-Guitar-8661",
          "text": "Sounds interesting, we are building something similar. Would love to chat if you are up for it.",
          "score": 1,
          "created_utc": "2025-12-31 01:34:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww9ud3",
          "author": "Worried_Market4466",
          "text": "Opensourcing on 3rd January!",
          "score": 1,
          "created_utc": "2025-12-31 11:00:18",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1y63d",
      "title": "I wrote a beginner-friendly explanation of how Large Language Models work",
      "subreddit": "LangChain",
      "url": "https://blog.lokes.dev/how-large-language-models-work",
      "author": "Feisty-Promise-78",
      "created_utc": "2026-01-02 13:07:59",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1q1y63d/i_wrote_a_beginnerfriendly_explanation_of_how/",
      "domain": "blog.lokes.dev",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1pzpltc",
      "title": "Building AI agents that actually learn from you, instead of just reacting",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pzpltc/building_ai_agents_that_actually_learn_from_you/",
      "author": "Nir777",
      "created_utc": "2025-12-30 18:25:02",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Just added a brand new tutorial about Mem0 to my \"Agents Towards Production\" repo. It addresses the \"amnesia\" problem in AI, which is the limitation where agents lose valuable context the moment a session ends.\n\nWhile many developers use standard chat history or basic RAG, Mem0 offers a specific approach by creating a self-improving memory layer. It extracts insights, resolves conflicting information, and evolves as you interact with it.\n\nThe tutorial walks through building a Personal AI Research Assistant with a two-phase architecture:\n\n* Vector Memory Foundation: Focusing on storing semantic facts. It covers how the system handles knowledge extraction and conflict resolution, such as updating your preferences when they change.\n* Graph Enhancement: Mapping explicit relationships. This allows the agent to understand lineage, like how one research paper influenced another, rather than just finding similar text.\n\nA significant benefit of this approach is efficiency. Instead of stuffing the entire chat history into a context window, the system retrieves only the specific memories relevant to the current query. This helps maintain accuracy and manages token usage effectively.\n\nThis foundation helps transform a generic chatbot into a personalized assistant that remembers your interests, research notes, and specific domain connections over time.\n\nPart of the collection of practical guides for building production-ready AI systems.\n\nCheck out the full repo with 30+ tutorials and give it a ‚≠ê if you find it useful:[https://github.com/NirDiamant/agents-towards-production](https://github.com/NirDiamant/agents-towards-production)\n\nDirect link to the tutorial:[https://github.com/NirDiamant/agents-towards-production/blob/main/tutorials/agent-memory-with-mem0/mem0\\_tutorial.ipynb](https://github.com/NirDiamant/agents-towards-production/blob/main/tutorials/agent-memory-with-mem0/mem0_tutorial.ipynb)\n\nHow are you handling long-term context? Are you relying on raw history, or are you implementing structured memory layers?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1pzpltc/building_ai_agents_that_actually_learn_from_you/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pys6wv",
      "title": "Implementing Production-Grade Human-in-the-Loop (HITL) with LangGraph for Sensitive Workflows",
      "subreddit": "LangChain",
      "url": "https://rampakanayev.com/blog/langgraph-human-in-the-loop",
      "author": "No-Conversation-8984",
      "created_utc": "2025-12-29 17:23:45",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1pys6wv/implementing_productiongrade_humanintheloop_hitl/",
      "domain": "rampakanayev.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q4qgr7",
      "title": "What are you using instead of LangSmith?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q4qgr7/what_are_you_using_instead_of_langsmith/",
      "author": "clickittech",
      "created_utc": "2026-01-05 16:34:44",
      "score": 8,
      "num_comments": 29,
      "upvote_ratio": 0.69,
      "text": "I‚Äôve been reading some negative opinions about LangSmith lately, not that it‚Äôs bad, just that it doesn‚Äôt always fit once things get real.\n\nStuff like, gets expensive fast or hard to fit into existing observability stacks\n\nI‚Äôve some alternatives for langsimth like\n\n* Arize Phoenix\n* OpenTelemetry setups\n* Datadog/ELK\n* ZenML\n* Mirascope\n* HoneyHive\n* Helicone\n\nwhat are you guys using instead?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1q4qgr7/what_are_you_using_instead_of_langsmith/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxutkom",
          "author": "caprica71",
          "text": " Langfuse",
          "score": 16,
          "created_utc": "2026-01-05 17:59:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxujyqi",
          "author": "Ecto-1A",
          "text": "We‚Äôre in the process of getting Confident AI set up. We tested most of these and it seemed to be the best fit without much code rewriting. Langsmith has been fine for the past year and a half but as our infrastructure grows, it becomes more obvious where langsmith is lacking.",
          "score": 5,
          "created_utc": "2026-01-05 17:15:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxusmik",
              "author": "Business-Hyena-6173",
              "text": "I work on LangSmith and would love to understand where we‚Äôre falling short. Feel free to DM me!",
              "score": 2,
              "created_utc": "2026-01-05 17:55:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxumv5n",
          "author": "necati-ozmen",
          "text": "We have users migration from langsmith to Voltagent which has built-in observability & automation layer.  \n[https://github.com/VoltAgent/voltagent](https://github.com/VoltAgent/voltagent)",
          "score": 2,
          "created_utc": "2026-01-05 17:29:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxvh232",
              "author": "nineelevglen",
              "text": "\\+1 on Volt. I've found it really good. We use langfuse for logging / benchmarking still, but Volt has plugins for that",
              "score": 2,
              "created_utc": "2026-01-05 19:45:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxv57x7",
          "author": "Ancient-Direction231",
          "text": "https://www.nfrax.com/ai-infra\n\nCombines langsmith/langchain, pydantic-ai, llmlite and more capabilities into one",
          "score": 2,
          "created_utc": "2026-01-05 18:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxue701",
          "author": "ninadpathak",
          "text": "The fact that this question even exists shows observability tooling for AI wasn't built with developers in mind. In 5 years these tools will be baked into the LLM frameworks themselves. Right now people cobble together open-source solutions. Keep an eye on who's building observability-first AI agents because that market category is about to explode.",
          "score": 2,
          "created_utc": "2026-01-05 16:48:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxv0kb9",
              "author": "OneTurnover3432",
              "text": "100% agree - check what I'm building : [thinkhive.ai](http://thinkhive.ai) \n\nWe're platform agnostic and focused on making the management of AI agents as easy as possible",
              "score": -7,
              "created_utc": "2026-01-05 18:30:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxuevfq",
          "author": "thelolzmaster",
          "text": "Throw https://tryspyglass.com into the mix",
          "score": 1,
          "created_utc": "2026-01-05 16:51:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxuwgnd",
          "author": "ChipsAhoy21",
          "text": "MLFlow 3.0, it‚Äôs open source and great at what it does. My org is databricks forward so that helps",
          "score": 1,
          "created_utc": "2026-01-05 18:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvlnlw",
          "author": "pbalIII",
          "text": "Depends on whether you're locked into LangChain or not.\n\nIf you are, LangSmith is still the path of least resistance. If you want out, Langfuse is the open-source default now... 19k+ GitHub stars, MIT license, self-host for free. Native SDKs for Python/JS, plus it plugs into LangChain, LlamaIndex, and 50+ other frameworks.\n\nFor vanilla API calls, gateway tools like Helicone or Portkey work well. Just a URL change to start logging. Portkey also handles fallbacks and load balancing across providers.\n\nIf you're already in Datadog's ecosystem, their LLM Observability module auto-instruments OpenAI, Anthropic, and Bedrock without code changes. Pricey at scale though.",
          "score": 1,
          "created_utc": "2026-01-05 20:06:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyph6n",
          "author": "FluffyFill64",
          "text": "Confident AI",
          "score": 1,
          "created_utc": "2026-01-06 06:19:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyqjlp",
          "author": "xelnet",
          "text": "AI is so custom that the value needed for troubleshooting forced me to build my own. Happy to consult if need any help.",
          "score": 1,
          "created_utc": "2026-01-06 06:28:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz2ftf",
          "author": "Ok_Constant_9886",
          "text": "Helicone was a solid choice but eventually we needed really solid evals on top of observability, and ended up choosing Confident AI",
          "score": 1,
          "created_utc": "2026-01-06 08:14:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzs73k",
          "author": "jaisanant",
          "text": "Mlflow",
          "score": 1,
          "created_utc": "2026-01-06 12:04:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny61g1d",
              "author": "Masotsheni",
              "text": "Mlflow's a solid choice! It really shines for tracking experiments and managing models. How have you found its integration with your existing tools?",
              "score": 1,
              "created_utc": "2026-01-07 08:34:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny648ur",
                  "author": "jaisanant",
                  "text": "I am using langgraph for multi agent architecture and using mlflow autolog for langgraph/langchain.\nUsed set experiment for multiple sessions and tracking each run in that session \nYou can set custom tag too for each agent run under different sessions\nIt is very easy. Look in their doc.",
                  "score": 1,
                  "created_utc": "2026-01-07 09:00:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0c45s",
          "author": "bzImage",
          "text": "I ask the llm to provide a reasoning and explanation for their actions.. i catch that output and save it on opensearch.. that is my observability. What can i gain with langsmith/langfuse/x ?",
          "score": 1,
          "created_utc": "2026-01-06 14:08:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny552n3",
          "author": "HoldZealousideal1966",
          "text": "Mlflow - Open Source, self managed, and can also be used for experiment tracking",
          "score": 1,
          "created_utc": "2026-01-07 04:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5lwxm",
          "author": "MisterIndemni",
          "text": "langsmith is good, not perfect, but you can do most anything on it - and if your using langchain its easy and makes sense. I use a few in that list, but I always use confident ai with it because of their red teaming functionality you can't really get with any of the alternatives. Considering to exclusively use their platform going forward if they keep up with great updates this year.",
          "score": 1,
          "created_utc": "2026-01-07 06:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6kzg3",
          "author": "Preconf",
          "text": "Phoenix is what I'm using while putting together the project I'm working on. It plays well with langchain and langgraph",
          "score": 1,
          "created_utc": "2026-01-07 11:30:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvkrvi",
          "author": "gkarthi280",
          "text": "I‚Äôve been using SigNoz and it‚Äôs been a really solid alternative for me.\n\nIt‚Äôs open source and natively compatible with OpenTelemetry, which is a big plus. You get traces, metrics, and logs all in one place, with strong correlation between them, so debugging feels much more straightforward than jumping across tools.\n\nAnother big advantage is that since it‚Äôs Otel based, you‚Äôre not limited to just LLM calls. You can instrument and monitor your entire application like API latency, background jobs, infra metrics, etc. alongside your LLM traces. That broader context has been super useful as things get more ‚Äúreal‚Äù in production.\n\nCheck out the SigNoz LangChain Observability docs it's pretty helpful to get you started: [https://signoz.io/docs/langchain-observability/](https://signoz.io/docs/langchain-observability/)",
          "score": 0,
          "created_utc": "2026-01-05 20:02:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxy889a",
          "author": "Otherwise_Flan7339",
          "text": "We moved from LangSmith to Maxim a few months ago for exactly the cost reason you mentioned - per-trace pricing gets wild at scale.\n\nThe bigger issue for us was that LangSmith treats everything as pass/fail on the whole system. When something breaks, you know *that* it broke but not *why*. With agents, you need component-level testing - is retrieval broken? Is the LLM ignoring context? Is tool selection wrong?\n\nMaxim does workspace-based pricing instead of per-trace and has way better component isolation for debugging. You can test each part of your agent separately which makes it actually possible to fix issues instead of just knowing they exist.\n\n[https://www.getmaxim.ai](https://www.getmaxim.ai)\n\nNot saying LangSmith is bad, just didn't scale well for our use case. If you're deep in LangChain it probably still makes sense though.",
          "score": 0,
          "created_utc": "2026-01-06 04:15:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxubdk1",
          "author": "clickittech",
          "text": "if you guys want to know more about these alternative here is breakdown of LangSmith alternatives and differences  \n[https://www.clickittech.com/ai/langsmith-alternatives/](https://www.clickittech.com/ai/langsmith-alternatives/)",
          "score": -3,
          "created_utc": "2026-01-05 16:35:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nxuzkgz",
          "author": "OneTurnover3432",
          "text": "I‚Äôve seen the same pattern, and I agree with most of what‚Äôs being said here.\n\nIn my experience, **LangSmith** works well early on, but once agents are in real production, teams start hitting the same walls: cost scaling with traces, lots of raw data, and still no clear answer to *what‚Äôs actually hurting or improving outcomes*.\n\nMost teams I‚Äôve worked with end up stitching together:\n\n* LangSmith or something similar for dev/debug\n* And then a manual analysis when it comes to explaining behavior ‚Üí impact ‚Üí ROI\n\nThat gap is exactly why I‚Äôm building **ThinkHive**.\n\nThinkHive sits on top of traces and logs (including OTel-based setups) and focuses on:\n\n* Summarizing logs and traces into clear issue patterns instead of raw data\n* Highlighting which agent behaviors actually move business metrics (cost, deflection, resolution, quality)\n\n It‚Äôs meant to answer the question those tools don‚Äôt: *what should I fix first to improve ROI?*\n\nI‚Äôm opening a small, free beta right now for teams:\n\n* Building AI agents internally for enterprises, or\n* Deploying agents for clients as consultants or agencies\n\nIf anyone here wants early access or to sanity-check whether this fits their setup, feel free to DM me. Happy to share and get feedback from people actually in the trenches.",
          "score": -3,
          "created_utc": "2026-01-05 18:26:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx0qq6",
              "author": "ctwillie77",
              "text": "This looks really good and promising! Seems the year is static at the bottom of your site: ¬© 2025 ThinkHive. All rights reserved.",
              "score": 0,
              "created_utc": "2026-01-06 00:16:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q3t915",
      "title": "How can I develop an agent skill system on top of LangChain 1.0",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q3t915/how_can_i_develop_an_agent_skill_system_on_top_of/",
      "author": "GardenOwn1917",
      "created_utc": "2026-01-04 15:50:20",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 0.77,
      "text": "How can I develop an agent skill system on top of LangChain 1.0 toolset to replace tools, and enable the agent to automatically unload and load these tools? How should I design the prompts for this? Can anyone share their approach?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q3t915/how_can_i_develop_an_agent_skill_system_on_top_of/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxnepq3",
          "author": "vtrivedy-lc",
          "text": "Hey op, our deepagents repo is built on the 1.0 create_agent() and we have an integrated SkillsMiddleware in the deepagents-cli that supports adding skills [here](https://github.com/langchain-ai/deepagents/blob/master/libs/deepagents-cli/deepagents_cli/skills/middleware.py)\n\nHope that‚Äôs a good example to get started with and understand how skill building/loading works.  It uses the latest AgentSkills spec.\n\nWe also have this [blog](https://blog.langchain.com/using-skills-with-deep-agents/) on Using Skills with DeepAgents that walks through it.  Hope this helps, lmk if there‚Äôs any way we can help as you build!",
          "score": 6,
          "created_utc": "2026-01-04 16:41:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxnta4l",
              "author": "cmndr_spanky",
              "text": "Is this basically the same thing as ‚Äútool selector‚Äù tool for the agent and a ‚Äútool executor‚Äù ? The first can return a short list / descriptions of available tools / skills, the second is how it executes one.  Other than semantics, if implemented this way, is there really any difference between a tool and a skill? A tool‚Äôs docstring is effectively merged into the prompt, and the function itself can contain whatever code you want the LLM to be able to execute.",
              "score": 1,
              "created_utc": "2026-01-04 17:48:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnwriz",
                  "author": "vtrivedy-lc",
                  "text": "it's a bit different.  Skills are bundles of capabilities (md files, scripts to run, anything really).  The Middleware adds the frontmatter to the prompt (kind of like a tool\\_description), but the agent access all of the additional instructions and scripts in the skill folder, these are primarily executed via the agent using bash.  Less bloat than bundling all tools into the context.  So if you design your the function of your tools as scripts in the Skill, the agent can still discover and run them when needed.\n\nWhat's your use case?  Trying to understand the exact flow so can make a good suggestion.",
                  "score": 1,
                  "created_utc": "2026-01-04 18:04:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxp6qo1",
          "author": "pbalIII",
          "text": "The key distinction u/cmndr_spanky raised is worth clarifying... skills are higher-order than tools. A tool is a single function with a docstring. A skill bundles prompts, scripts, and context that the agent can discover and execute on demand.\n\nFor the mode-switching you're describing, LLMToolSelectorMiddleware is probably what you want. It runs before the main model call and filters down to relevant tools based on query context. Combine that with domain-specific prompt templates in a custom before_model hook and you get something close to skill switching without the multi-agent overhead.\n\nOne gotcha: dynamic tool addition after agent creation isn't supported yet. All tools need to be registered upfront, middleware just filters the active set per turn.",
          "score": 2,
          "created_utc": "2026-01-04 21:31:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpkb1s",
              "author": "cmndr_spanky",
              "text": "Makes sense, and I‚Äôm not trying to be argumentative here, but if a skill is a ‚Äúbundle of prompts, scripts, and context‚Äù how is that different from an agent conditionally accessing a sub-agent? This would seem (to me) like a preferred architecture if prompts and non-deterministic decisioning is a necessary part of that ‚Äúbundle‚Äù.. also you can use a cheaper (or conversely more powerful) LLM with that sub-agent depending on the complexity of what it should do and how much context it‚Äôs going to manage.",
              "score": 1,
              "created_utc": "2026-01-04 22:34:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxq73h8",
                  "author": "pbalIII",
                  "text": "You're right that the line gets blurry. The main difference is overhead and state management. With sub-agents, each invocation spins up a new context window, manages its own conversation state, and has full autonomy to make tool calls. That's powerful but expensive... you pay for the orchestration layer, the handoff logic, and the latency of multiple LLM roundtrips. Skills sit lower in the stack. They're more like parameterized recipes the parent agent executes directly. No separate context window, no independent decision-making. The parent stays in control and just runs the bundled instructions. The tradeoff: sub-agents give you isolation and flexibility (different models, independent error handling). Skills give you speed and predictability. If your bundle needs to make multiple LLM calls with its own reasoning, sub-agent makes sense.",
                  "score": 1,
                  "created_utc": "2026-01-05 00:26:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxn57ld",
          "author": "adlx",
          "text": "Do you mean a first step does select some most  relevant tools from a listbof (possibly many) available tools and then offers them to the next llm call as tools?\n\nI'd say first is a chain with structured output to return list of selected tools. \n\nThen just bind those selected tools for the llm to use in next calls/graph",
          "score": 1,
          "created_utc": "2026-01-04 15:57:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxn6d7c",
              "author": "GardenOwn1917",
              "text": "Because the tools on my side can be divided into collections from different domains, the current architecture is a multi-agent architecture. I would prefer a single-agent implementation that can load prompt templates from different domains without needing retrieval‚Äîinstead, something similar to mode switching.",
              "score": 1,
              "created_utc": "2026-01-04 16:02:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxn8eq9",
                  "author": "nate_f",
                  "text": "You might consider langchain.agents.middleware.dynamic_prompt and the tool selector middleware. https://docs.langchain.com/oss/python/langchain/middleware/built-in#llm-tool-selector",
                  "score": 1,
                  "created_utc": "2026-01-04 16:12:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q3mpy1",
      "title": "How can I use use-stream-react / CopilotKit without LangSmith Cloud / AgentServer (self-hosted LangGraph)?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q3mpy1/how_can_i_use_usestreamreact_copilotkit_without/",
      "author": "Other_Past_2880",
      "created_utc": "2026-01-04 10:30:10",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hey all,  \nI‚Äôm building a web app with **LangGraph** and I‚Äôm running my own backend/server.\n\nI‚Äôd like to use **LangSmith** `use-stream-react` (and possibly **CopilotKit**) to stream agent/graph updates to the React client, but the docs seem to assume **LangSmith Cloud + AgentServer**.\n\n**Question:**  \nCan [use-stream-react](https://docs.langchain.com/langsmith/use-stream-react) / CopilotKit work with a self-hosted server (no AgentServer / no LangSmith Cloud)?  \nIf yes, what does my server need to expose (SSE? specific event schema?) so the client hooks/components work?\n\nIf not, what‚Äôs the recommended way to stream LangGraph events to React in a similar experience?\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1q3mpy1/how_can_i_use_usestreamreact_copilotkit_without/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q32p4h",
      "title": "Do you prefer to make Human-in-the-loop approvals on your phone or PC",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q32p4h/do_you_prefer_to_make_humanintheloop_approvals_on/",
      "author": "Antique_Try7765",
      "created_utc": "2026-01-03 18:52:36",
      "score": 7,
      "num_comments": 16,
      "upvote_ratio": 0.82,
      "text": "I am currently building an HITL system that initiates with systems but I want to understand how people prefer to make human input into their workflows or agents. >> [hitl.sh](http://hitl.sh)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q32p4h/do_you_prefer_to_make_humanintheloop_approvals_on/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxiq316",
          "author": "Signal_Question9074",
          "text": "ok, let me save you from some hair pulling.\n\nGreat question furst if all becuase I've been building HITL into my own agent system, so I have some thoughts on this.\n\n**Short answer: PC for complex decisions, phone for quick approvals.**\n\nBut the real insight I learned: **the UX design matters more than the device.**\n\n**What I built:**\n\nMy system uses a request/response pattern (similar to how Claude Code handles it). When the agent needs human input, it doesn't truly \"pause\" mid-execution it completes its turn, returns a question marker, and the backend emits a socket event to the frontend:\n\n    // Agent returns this when it needs input\n    {\n      __askUser: true,\n      question: \"Which database should we use?\",\n      options: [\n        { label: \"PostgreSQL\", description: \"Relational, ACID compliant\" },\n        { label: \"MongoDB\", description: \"Document store, flexible schema\" }\n      ],\n      multiSelect: false\n    }",
          "score": 5,
          "created_utc": "2026-01-03 22:28:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxiq3ye",
              "author": "Signal_Question9074",
              "text": "Frontend catches this and renders clickable options. User picks one, answer goes back as a new message, agent continues with full context preserved.\n\n**Why this matters for phone vs PC:**\n\n1. **Single-select options** ‚Äî Work great on phone. Tap and done.\n2. **Multi-select or free-text** ‚Äî Better on PC. Typing on phone sucks.\n3. **Context-heavy decisions** ‚Äî PC. You need to see the conversation history.\n4. **Quick \"approve/reject\"** ‚Äî Phone. Perfect for notifications.\n\n**The two main patterns:**\n\n| Pattern | How it works | Best for |\n\n|---------|--------------|----------|\n\n| **Request/Response** | Agent completes turn, returns question, waits for answer as new message | Simpler to build, works well with existing chat UIs |\n\n| **True Interrupt** (LangGraph style) | Agent pauses mid-execution via `interrupt()`, state checkpointed, resumes with `Command(resume=...)` | More complex, but cleaner for multi-step approvals |\n\nLangGraph's `interrupt()` is cleaner architecturally execution actually pauses and resumes from the exact point. My approach re-executes with full context, which works but burns more tokens on long conversations.\n\n**What I'd recommend for your build:**\n\n1. **Start with simple options UI:** 2-4 clickable buttons covers 80% of cases\n2. **Add \"Other\" free-text fallback:** Users hate being boxed in\n3. **Persist pending questions:** If user refreshes page or switches devices, the question should still be there (I use Redis for this)\n4. **Handle timeouts gracefully:** What happens if user takes 10 minutes? Don't let the agent hang.\n\n**Honest take on phone:**\n\nI rarely approve from phone unless it's truly urgent. Context switching kills focus. But for async workflows where you're not actively watching the agent and phone notifications for \"needs approval\" ‚Üí tap to approve ‚Üí done. that flow is solid.\n\nWhat kind of decisions are you handling? Simple approve/reject, or complex multi-option stuff?",
              "score": 5,
              "created_utc": "2026-01-03 22:28:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxjkpg3",
                  "author": "Antique_Try7765",
                  "text": "Is there any out of the box solution I can use for this ?",
                  "score": 2,
                  "created_utc": "2026-01-04 01:08:32",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nxoyxs6",
                  "author": "vansterdam_city",
                  "text": "Add voice to text support for mobile and your text box issues are mitigated quite a bit.",
                  "score": 1,
                  "created_utc": "2026-01-04 20:54:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxj37vi",
          "author": "amilo111",
          "text": "Who are you building this for?  The answer to your question depends heavily on the target persona and use case.\n\nAlso what hitl interactions are you solving for?  I‚Äôve worked on applications that had hitl and we had to solve for multiple different interaction models depending on what the customer was trying to do and how we fit into their processes.",
          "score": 3,
          "created_utc": "2026-01-03 23:35:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjkgsh",
              "author": "Antique_Try7765",
              "text": "The client is into content management and want to approve before content is automatically posted to their social media platform.",
              "score": 1,
              "created_utc": "2026-01-04 01:07:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxjrx5k",
                  "author": "pebblebypebble",
                  "text": "I‚Äôd definitely want to show them any related news stories that could shift meaning before pushing live if you want 1 click from mobile",
                  "score": 2,
                  "created_utc": "2026-01-04 01:48:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxk8ium",
          "author": "Reasonable-Life7326",
          "text": "PC all the way",
          "score": 2,
          "created_utc": "2026-01-04 03:21:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxjrn6k",
          "author": "pebblebypebble",
          "text": "Phone if it is quick but mostly on my laptop‚Ä¶ either way I prefer to do any of it with audio playback at the same time. Some of it can be complicated and the audio playback as I read really helps.",
          "score": 1,
          "created_utc": "2026-01-04 01:46:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjs8i8",
              "author": "Antique_Try7765",
              "text": "Are you available to try it and give me an honest opinion ?? >> [hitl.sh](http://hitl.sh)",
              "score": 1,
              "created_utc": "2026-01-04 01:49:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxjulg3",
                  "author": "pebblebypebble",
                  "text": "In the morning if you help me with answering some user research questions I have about professional teams working and communicating via AI. You can even send me a user onboarding test and I‚Äôll do a 30m greenfield voice of customer for that kind of a trade. My 30m for your 30m.",
                  "score": 1,
                  "created_utc": "2026-01-04 02:03:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1py0skm",
      "title": "Relay: a proposal for framework-agnostic agent orchestration",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1py0skm/relay_a_proposal_for_frameworkagnostic_agent/",
      "author": "bumswagger",
      "created_utc": "2025-12-28 19:57:35",
      "score": 6,
      "num_comments": 7,
      "upvote_ratio": 0.88,
      "text": "You have LangGraph agents, teammate has CrewAI, another team uses custom agents. Getting them to work together sucks.\n\nProposal: agents coordinate through \"relay repos\"\n\n* Shared versioned state store\n* Agents commit outputs, read inputs from previous commits\n* Branch for parallel experimentation\n* Policies define triggers (when agent A commits, run agent B)\n* MCP for agent interface - framework agnostic\n\nIt's like git for agent collaboration instead of code collaboration.\n\nWould this actually help? What's wrong with this model?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1py0skm/relay_a_proposal_for_frameworkagnostic_agent/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwftvl5",
          "author": "rkpandey20",
          "text": "Just wondering if you can use A2A protocol to communicate.¬†",
          "score": 3,
          "created_utc": "2025-12-28 22:13:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh9936",
              "author": "AdditionalWeb107",
              "text": "You have to implement all the low-level logic yourself in that case.",
              "score": 1,
              "created_utc": "2025-12-29 02:54:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwhlexy",
                  "author": "rkpandey20",
                  "text": "You are right. But it is not that much. It is just Agent card besides the agent endpoint. ¬†",
                  "score": 1,
                  "created_utc": "2025-12-29 04:07:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwg7ztz",
          "author": "Khade_G",
          "text": "Interesting idea. I think the ‚Äúgit for agents‚Äù framing is directionally right, but the pain usually isn‚Äôt state storage‚Ä¶ it‚Äôs semantics + contracts.\n\nWhat would help:\n- Framework-agnostic interfaces (MCP-style)\n- Versioned artifacts so runs are reproducible\n- Branching for experimentation\n\nPotential pitfalls id see:\n- ‚ÄúShared state‚Äù becomes a junk drawer unless outputs are strongly typed\n- Triggers quickly turn into a hidden workflow engine (Airflow/Temporal vibes)\n- Merge conflicts aren‚Äôt like code‚Ä¶ agents need domain-specific conflict rules\n- Latency + debugging get ugly if everything is commit/poll/trigger\n\nSo this works only if it‚Äôs really a typed artifact registry + eventing + policies, with git-like versioning as UX‚Ä¶ not literally ‚Äúgit as the runtime.‚Äù\n\nOtherwise it risks being a clever abstraction that mostly re-implements orchestration, but harder to debug.",
          "score": 2,
          "created_utc": "2025-12-28 23:28:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwh96o3",
          "author": "AdditionalWeb107",
          "text": "Checkout: [https://github.com/katanemo/plano](https://github.com/katanemo/plano) \\- Plano is delivery infrastructure for agents, and promises to be framework-agnostic and offers support for \"agents as tools\" via MCP. It doesn't have policy-defined orchestration, but has user-trigger orchestration worfklows built in.",
          "score": 1,
          "created_utc": "2025-12-29 02:54:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwikr0w",
          "author": "Ok-Priority35",
          "text": " were actively working on this at [slashmcp.com](http://slashmcp.com)",
          "score": 1,
          "created_utc": "2025-12-29 08:48:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4j1vc",
      "title": "How to use postgres for checkpointer, when using langchain dev",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q4j1vc/how_to_use_postgres_for_checkpointer_when_using/",
      "author": "SearchTricky7875",
      "created_utc": "2026-01-05 11:14:38",
      "score": 6,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I m using free version of langsmith n hosting my deep agent with agent server [https://docs.langchain.com/langsmith/agent-server#parts-of-a-deployment](https://docs.langchain.com/langsmith/agent-server#parts-of-a-deployment) everything works but my agent using inmemory for storing checkpoint store, if I configure postgres, created checkpoint tables calling with PostgresSaver.from\\_conn\\_string(DATABASE\\_URL) as checkpointer:\n\ncheckpointer.setup()\n\nbut when I pass the checkpointer to agent it says, on dev mode langchain doesnt support custom checkpointer. Do I need to buy license for it, which version of license should I buy if I need to.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q4j1vc/how_to_use_postgres_for_checkpointer_when_using/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxyxxur",
          "author": "Heavymetal_17",
          "text": "I have been attempting it too,\nBut found out we just have to set environment variables \nhttps://github.com/langchain-ai/langgraph/issues/5360 https://github.com/langchain-ai/langgraph/issues/6559 https://docs.langchain.com/langsmith/env-var#postgres-uri-custom https://forum.langchain.com/t/postgres-uri-custom-is-ignored-by-langgraph-runtime-runtime-always-fa‚Ä¶\n\nBut as you can see in the issues even that is not working. So I am not at all sure how to proceed.",
          "score": 1,
          "created_utc": "2026-01-06 07:33:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzm43k",
              "author": "SearchTricky7875",
              "text": "only way seems to be to use 'langgraph serve' which requires license, does langgraph also need license, if I use langgraph and dont use agent server? I am thinking to redevelop my agent using langgraph.",
              "score": 1,
              "created_utc": "2026-01-06 11:16:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxznkdk",
                  "author": "Heavymetal_17",
                  "text": "You can attempt that, but it seems that would be much of an effort, I am attempting to deploy deepagents directly through fastapi on same api signatures endpoints.",
                  "score": 1,
                  "created_utc": "2026-01-06 11:29:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyy3pl",
          "author": "Heavymetal_17",
          "text": "One might bypass langgraph dev completely and create fastapis directly and then attempt  from there.",
          "score": 1,
          "created_utc": "2026-01-06 07:34:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0uf3q",
      "title": "Is it one big agent, or sub-agents?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q0uf3q/is_it_one_big_agent_or_subagents/",
      "author": "AdditionalWeb107",
      "created_utc": "2026-01-01 03:16:38",
      "score": 6,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "If you are building agents, are you resorting to send traffic to one agent that is responsible for all sub-tasks (via its instructions) and packaging tools intelligently - or are you using a lightweight router to define/test/update sub-agents that can handle user specific tasks.\n\nThe former is a simple architecture, but I feel its a large bloated piece of software that's harder to debug. The latter is cleaner and simpler to build (especially packaging tools) but requires a great/robust orchestration/router.\n\nHow are you all thinking about this? Would love framework-agnostic approaches because these frameworks add very little value and become an operational nightmare as you push agents to production.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1q0uf3q/is_it_one_big_agent_or_subagents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nx1xzxr",
          "author": "Seeking_Adrenaline",
          "text": "Start with s single prompt and tools. Grow and split as needed. Use evals to measure this and detect when to change and if you are making progress. Every additional prompt layer is a slower end result, take this into consideration.",
          "score": 3,
          "created_utc": "2026-01-01 08:37:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx44q1p",
              "author": "AdditionalWeb107",
              "text": "Managing the split feels very painful - as I am now in the business of routing and middleware.",
              "score": 0,
              "created_utc": "2026-01-01 18:12:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx58xdh",
          "author": "attn-transformer",
          "text": "Once you include more than ~8 tools then the llm may not select the right tool. This is the limitation of the llm that should drive the decision between single or multi agent.",
          "score": 2,
          "created_utc": "2026-01-01 21:36:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx593uq",
              "author": "AdditionalWeb107",
              "text": "interesting way to think about - is this practical/empirical testing or a fact that more than 8 tools and the models hallucinate?",
              "score": 0,
              "created_utc": "2026-01-01 21:37:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx5dsu0",
                  "author": "attn-transformer",
                  "text": "It‚Äôs just fact. A tool call is a decision that the llm needs to make. The more options the more confusion. Humans have this exact limitation.\n\nEmpirically after 8-10 tool choices the llm starts to make mistakes.",
                  "score": 1,
                  "created_utc": "2026-01-01 22:00:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx663tu",
          "author": "Zealousideal_Emu7912",
          "text": "Depends on how long a single agent's context gets. I find that agents handle upto 100k context length quite well these days, so I tend to keep to simple and have everything in one prompt. I only use sub-agents when there's an isolated context-intensive task with little to no follow ups for the sub-agent.",
          "score": 1,
          "created_utc": "2026-01-02 00:36:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q427ua",
      "title": "Added a validation layer between my SQL agent and the database - sharing in case useful",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q427ua/added_a_validation_layer_between_my_sql_agent_and/",
      "author": "Educational_Poet_862",
      "created_utc": "2026-01-04 21:29:18",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.86,
      "text": "Been building a LangChain agent that queries a Postgres database. Model is smart enough not to do anything malicious, but I wanted:\n\n1. **Explicit scope control** - define exactly which tables the agent can touch\n2. **Observability** - log when the agent tries something outside its lane\n3. **Another layer** - defense in depth alongside read-only DB creds\n\nBuilt a small validation layer:\n\n    from langchain_community.utilities import SQLDatabase\n    from proxql import Validator\n\n    db = SQLDatabase.from_uri(\"postgresql://readonly@localhost/mydb\")\n\n    validator = Validator(\n        mode=\"read_only\",\n        allowed_tables=[\"products\", \"orders\", \"categories\"]\n    )\n\n    def run_query(query: str) -> str:\n        check = validator.validate(query)\n        if not check.is_safe:\n            logger.warning(f\"Out of scope: {query} - {check.reason}\")\n            return f\"Query not allowed: {check.reason}\"\n        return db.run(query)\n\n**What it does:**\n\n- Table allowlist - hard boundary on which tables are accessible (catches subqueries, CTEs, JOINs)\n- Statement filtering - read_only mode only allows SELECT\n- Dialect-aware - uses sqlglot for Postgres/MySQL/Snowflake support\n\n**What it doesn't do:**\n\n- Replace proper DB permissions (still use a read-only user)\n- Prevent expensive queries\n- Protect against a determined attacker - it's a guardrail for mistakes, not security\n\nMostly useful for observability. When a query gets blocked, I review what the agent was trying to do - usually means my prompts need tuning.\n\n---\n\npip install proxql\n\nGitHub: https://github.com/zeredbaron/proxql\n\n---\n\nCurious what others are doing for agent scope control. Are you just trusting the model + DB permissions, or adding validation layers?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q427ua/added_a_validation_layer_between_my_sql_agent_and/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxsby05",
          "author": "rkpandey20",
          "text": "I see a lot of people building protection layer to process action described by the agent. Like in this case, sql generated by agent.¬†\nJust wondering if age old way of creating indirection where you create a grammar equivalent to sql that you want to support, is out of fashion these days.¬†",
          "score": 1,
          "created_utc": "2026-01-05 08:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxy8b5b",
          "author": "pbalIII",
          "text": "Most SQL agents ship the query straight to the DB and pray. The validation layer is where you catch the expensive mistakes... malformed joins, accidental mutations, queries that'd time out in prod.\n\nLangChain has a built-in sql_db_query_checker tool but layering your own checks (schema validation, read-only enforcement, cost estimation) gives you way more control. Curious what checks you're running in yours.",
          "score": 1,
          "created_utc": "2026-01-06 04:16:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3a09f",
      "title": "Autonomous Manim Coder with Deepagents",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/1krmmk8t08bg1",
      "author": "Eastwindy123",
      "created_utc": "2026-01-03 23:43:28",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 0.73,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1q3a09f/autonomous_manim_coder_with_deepagents/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxjz7go",
          "author": "vtrivedy-lc",
          "text": "Hey this is awesome thanks for sharing!!  Would love to feature it and hear about how using DeepAgents went (and how we can make it better).  Will DM you!\n\nWas a math major in undergrad, Manim was always magic :)",
          "score": 1,
          "created_utc": "2026-01-04 02:28:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyp3x5",
      "title": "Everyone and their mother building AI agents while document extraction is still broken for most companies",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pyp3x5/everyone_and_their_mother_building_ai_agents/",
      "author": "GloomyEquipment2120",
      "created_utc": "2025-12-29 15:27:31",
      "score": 4,
      "num_comments": 3,
      "upvote_ratio": 0.64,
      "text": "While everyone's hyped about AI agents, I've been looking at a problem that's way more mundane but costs companies actual money: document processing still sucks.\n\nMost OCR systems plateau around 60% automation despite claiming high accuracy. The gap between test benchmarks and production reality is brutal - invoices with weird table layouts, multi-column forms, handwritten notes on printed docs, or just shitty scans break these pipelines constantly.\n\nSo I tried combining the two: built an agentic chatbot that uses a fine-tuned VLM (Qwen2.5-VL) for document extraction with a reflection-based verification process.\n\n**The basic idea:**\n\nInstead of rigid OCR ‚Üí parse ‚Üí extract, the agent plans extraction strategy based on document type, uses the VLM to pull information, then reflects on its own output before answering. If something looks wrong (numbers don't add up, dates are illogical, missing required fields), it re-runs extraction with refined prompts.\n\nThat self-correction loop is what pushes automation rates from 60% to 90%+. The system catches its own mistakes instead of sending garbage to humans.\n\n**What makes this different from traditional pipelines:**\n\n* VLM processes images directly, no separate OCR/layout analysis steps that create error cascades\n* Agent can adapt extraction strategy per document (financial tables ‚â† contracts)\n* Reflection pattern validates outputs before returning answers\n* Handles the real failure cases: nested tables, multi-column layouts, mixed print/handwriting\n\nBuilt the whole thing as a chatbot interface where you can ask questions about documents and it extracts + verifies answers. Uses langchain for the agent framework, fine-tuned the VLM on DocVQA dataset (real invoices/receipts/forms with all the complexity issues).\n\nWrote up the full implementation with code - dataset prep, fine-tuning workflow, agent setup with reflection patterns, deployment approach: link in comments.\n\nThe accuracy/automation tradeoff part was interesting to figure out. Traditional systems can't escape it (high confidence = low automation, low confidence = high errors), but reflection changes the game since you can be less certain initially because validation catches mistakes.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1pyp3x5/everyone_and_their_mother_building_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nwk3r6m",
          "author": "GloomyEquipment2120",
          "text": "You can read the details of the project here:  [https://ubiai.tools/agentic-document-intelligence-building-a-self-correcting-document-qna-pipeline/](https://ubiai.tools/agentic-document-intelligence-building-a-self-correcting-document-qna-pipeline/)",
          "score": 1,
          "created_utc": "2025-12-29 15:28:18",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwl07dx",
          "author": "Terrible_Attention83",
          "text": "What was the impact on throughout numbers? How much more time your implementation took compared to just the ocr one? How scalable would this approach be?",
          "score": 1,
          "created_utc": "2025-12-29 18:02:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpz4qh",
              "author": "GloomyEquipment2120",
              "text": "Good questions. The reflection approach is definitely slower per document since it makes multiple VLM passes for validation. Roughly 3-4x the processing time compared to standard OCR.\n\nScalability: This works best for moderate volumes where accuracy matters more than raw speed. For high-volume scenarios, you'd need aggressive batching or use it selectively on complex documents where basic OCR fails.\n\nThe key tradeoff: slower per-doc processing but way less human review overall, so total end-to-end time can actually improve despite the slower extraction.",
              "score": 1,
              "created_utc": "2025-12-30 12:40:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pywsxg",
      "title": "[Open Source] LangGraph Threads Export Tool - Backup, migrate, and own your conversation data",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1pywsxg/open_source_langgraph_threads_export_tool_backup/",
      "author": "SignatureHuman8057",
      "created_utc": "2025-12-29 20:13:30",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "Hey everyone! üëã\n\nI built a tool to solve a problem I had with LangGraph Cloud and wanted to share it with the community.\n\n### The Problem\n\nI had two LangGraph Cloud deployments - a production one (expensive) and a dev one (cheaper). I wanted to:\n- Migrate all user conversations from prod to dev\n- Keep the same thread IDs so users don't lose their chat history\n- Preserve multi-tenancy (each user only sees their own threads)\n\nThere's no built-in way to do this in LangGraph Cloud, so I built one.\n\n### What This Tool Does\n\n**Export your LangGraph threads to:**\n- üìÑ **JSON file** - Simple backup you can store anywhere\n- üêò **PostgreSQL database** - Own your data with proper schema and indexes\n- üîÑ **Another deployment** - Migrate between environments\n\n**What gets exported:**\n- Thread IDs (preserved exactly)\n- Metadata (including `owner` for multi-tenancy)\n- Full checkpoint history\n- Conversation values/messages\n\n### Quick Example\n\n```bash\n# Export all threads to JSON\npython migrate_threads.py \\\n  --source-url https://my-deployment.langgraph.app \\\n  --export-json backup.json\n\n# Export to PostgreSQL\npython migrate_threads.py \\\n  --source-url https://my-deployment.langgraph.app \\\n  --export-postgres\n\n# Migrate between deployments\npython migrate_threads.py \\\n  --source-url https://prod.langgraph.app \\\n  --target-url https://dev.langgraph.app \\\n  --full\n```\n\n### Why You Might Need This\n\n- **Cost optimization** - Move from expensive prod to cheaper deployment\n- **Backup before deletion** - Export everything before removing a deployment\n- **Compliance** - Store conversation data in your own database\n- **Analytics** - Query your threads with SQL\n- **Disaster recovery** - Restore from JSON backup\n\n### GitHub\n\nüîó **[github.com/farouk09/langgraph-threads-migration](https://github.com/farouk09/langgraph-threads-migration)**\n\nMIT licensed, PRs welcome!\n\n---\n\n### Note for deployments with custom auth\n\nIf you use Auth0 or custom authentication, you'll need to temporarily disable it during export (the tool uses the LangSmith API key, not user tokens). Just set `\"auth\": null` in your `langgraph.json`, export, then re-enable.\n\n---\n\nHope this helps someone! Let me know if you have questions or feature requests. üôÇ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1pywsxg/open_source_langgraph_threads_export_tool_backup/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q15sf0",
      "title": "What is the best embedding and retrieval model both OSS/proprietary for technical texts (e.g manuals, datasheets, and so on)?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q15sf0/what_is_the_best_embedding_and_retrieval_model/",
      "author": "Imaginary-Bee-8770",
      "created_utc": "2026-01-01 14:45:57",
      "score": 4,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1q15sf0/what_is_the_best_embedding_and_retrieval_model/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nx39059",
          "author": "Khade_G",
          "text": "I‚Äôd think in embedding + reranker pairs (since rerankers usually move quality more than swapping embeddings).\n\nIf you just want a solid default:\n- Proprietary (pretty easy): OpenAI text-embedding-3-large + a good reranker.  Ôøº\n- OSS (best all-around starting point): BAAI bge-m3 (it‚Äôs popular for RAG and supports multiple retrieval styles).  Ôøº\n- Another strong proprietary option: Cohere Embed v3/v4 (used a lot in retrieval stacks).  Ôøº\n\nFor tech docs, I think you‚Äôll usually get the biggest impact from clean chunking (sections/headers) + hybrid retrieval (BM25 + embeddings) + reranking, vs trying to find the one perfect embedding model.Ôøº",
          "score": 1,
          "created_utc": "2026-01-01 15:25:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3f1pv",
              "author": "Imaginary-Bee-8770",
              "text": "Thanks a lot! \n\nWe were exploring better parsing options as well. We are currently using LlamaParse with the cost-effective tier option.   \n  \nWe were exploring OSS options such as Paddle, MinerU, Docling, Marker and so on, there are strong proprietary options as well such as Unstructured, Landing AI, Mathpix and many more.\n\nDo you have any insights that you could share with us please? Thanks in advance",
              "score": 1,
              "created_utc": "2026-01-01 15:58:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxb8dk0",
                  "author": "Ok-Introduction354",
                  "text": "How are you evaluating your parsing quality currently? Is it mainly through eyeballing or do you have some kind of an eval set with <documents, ground truth parse> pairs?\n\nIf you don't have an eval set, I'd recommend creating one even if it's small. That way you'll be able to cleanly compare the different parsing alternatives.\n\nApart from the ones you mentioned, I've heard Gemini-3-Flash, DeepSeek-OCR and Mistral are quite good as well. Among the proprietary options, I've heard good things about Reducto and Nanonets.\n\n[https://github.com/opendatalab/OmniDocBench](https://github.com/opendatalab/OmniDocBench) looked quite relevant as well.",
                  "score": 2,
                  "created_utc": "2026-01-02 20:03:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxc207l",
                  "author": "Khade_G",
                  "text": "Totally agree with the @ok-introduction‚Ä¶ if you don‚Äôt have even a small eval set, you‚Äôre mostly guessing.\n\nWhat‚Äôs worked for me is creating a small, realistic benchmark (dozens of docs is enough) that matches your actual inputs: clean PDFs, messy scans, tables, multi-column manuals. Instead of judging parses by how ‚Äúnice‚Äù they look, evaluate them by downstream RAG behavior: does the right chunk get retrieved, and can the model answer questions that depend on a specific section or table?\n\nIn practice, a hybrid approach usually wins. Use a fast, cheap parser for most pages, detect the hard ones (tables, scans, math), and only route those to heavier tools. Also, reliable structure matters more than people expect‚Ä¶ if headings and reading order are right, retrieval quality improves even with the same embeddings.",
                  "score": 1,
                  "created_utc": "2026-01-02 22:29:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q30qw1",
      "title": "How are fintech companies auditing what their AI actually does?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q30qw1/how_are_fintech_companies_auditing_what_their_ai/",
      "author": "Such-Persimmon1622",
      "created_utc": "2026-01-03 17:39:19",
      "score": 4,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "I keep reading about companies adding AI to handle refunds,\n\n  chargebacks, account changes, etc. But I never see anyone\n\n  talk about how they track what the AI decided or why.\n\n\n\n  Is everyone just logging stuff to a database and hoping\n\n  for the best? Genuinely curious what the reality looks like.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q30qw1/how_are_fintech_companies_auditing_what_their_ai/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxh8gdx",
          "author": "indutrajeev",
          "text": "Same KPI‚Äôs as when you had humans do this. Don‚Äôt see why that would change?",
          "score": 2,
          "created_utc": "2026-01-03 18:10:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxp9hbt",
              "author": "ChanceKale7861",
              "text": "LOTS. But what you mention aren‚Äôt audits. run an end to end audit of your code, access controls, privileges and access controls for agents, etc‚Ä¶ but because these are agents and no people, your threat model is different. So no, these aren‚Äôt the same as for humans.",
              "score": 1,
              "created_utc": "2026-01-04 21:43:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhq8bl",
          "author": "Khade_G",
          "text": "A lot of companies are basically ‚Äúlogging and praying‚Äù early on. In practice, the mature setups look more like ‚Äî> every AI action becomes an auditable record. That usually means you log the user request, the final decision, the key facts the model relied on (inputs/retrieved docs), the tool calls it made, and a reason code (policy section / rule) that a human can understand. Then you add guardrails like confidence thresholds, human review for edge cases, and dashboards for reversal rates and chargeback outcomes.\n\nI think the real shift is treating it like payments/fraud systems‚Ä¶ I.e. you don‚Äôt just want an answer, you want traceability and the ability to replay ‚Äúwhy did this happen?‚Äù months later. If a company can‚Äôt do that, they‚Äôre taking on a lot of risk and usually don‚Äôt realize it until something blows up.",
          "score": 2,
          "created_utc": "2026-01-03 19:31:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpadpf",
              "author": "ChanceKale7861",
              "text": "BOOM! THANK YOU! Someone gets it! :)\n\nThere is a paradigm shift in observability, because agents don‚Äôt stay siloed. The value is when agents don‚Äôt have to regard silos or the arbitrary boundaries of an org, or the dumbass entrenched folks, who always want everyone to stay in their lane. I‚Äôm ready for the many roles that aren‚Äôt necessary and the folks who are joy status quo and stability to be forced out of the workforce in favor of the largest orgs failing and shutting down, and people using tech to become direct competitors with their employers overnight. \n\nIt‚Äôs basically the dicks sporting goods case study at scale. Either put your employer out of business, or let a competitor do it for you.",
              "score": 2,
              "created_utc": "2026-01-04 21:48:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxihq2w",
          "author": "adiberk",
          "text": "Build our own audit on top of existing framework (Agno).\n\nBasically audit and track every run providing fast debugging and easy ways of viewing conversations. We auto run evals to catch things early.\n\nYou can a lot of this from tracing providers as well, but this integration allows us to really customize it to our needs",
          "score": 2,
          "created_utc": "2026-01-03 21:46:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpagpo",
              "author": "ChanceKale7861",
              "text": "whoopp! Let‚Äôs go agno agentOS!!!!!\n\nHell yeah!",
              "score": 1,
              "created_utc": "2026-01-04 21:48:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxpcmcu",
                  "author": "adiberk",
                  "text": "Yeah they are awesome very active. Give it a run. The only downside is now dynamic configuration, though that is in the roadmap.\n\nI have personally had my own entire framework on top of Agno to enable high db based customization lol",
                  "score": 2,
                  "created_utc": "2026-01-04 21:58:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxhf0ju",
          "author": "Born_Owl7750",
          "text": "There are many ways to do it.\nThere are logging and tracing stack for almost any framework.\nSemantic kernel - Application insights \nLangchain/langgraph - Langsmith\n\nSome might have custom dashboards done on top of the data. This dashboard itself has the scope to be a whole new project.\n\nWe have even done power bi dashboards with analytics on top of chat history. It will need some form of data processing pipelines that run behind the scene",
          "score": 1,
          "created_utc": "2026-01-03 18:40:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxp9lij",
              "author": "ChanceKale7861",
              "text": "But this doesn‚Äôt touch anything related to security, GRC, business process controls, etc.",
              "score": 1,
              "created_utc": "2026-01-04 21:44:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxp93x6",
          "author": "ChanceKale7861",
          "text": "Career auditor here‚Ä¶ companies don‚Äôt have the capability to do this in a real way,  it they sure can ‚Äúbe compliant‚Äù which doesn‚Äôt mean the audits are effective for fixing anything.",
          "score": 1,
          "created_utc": "2026-01-04 21:42:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxuj7lj",
          "author": "ninadpathak",
          "text": "The answer is logging + policy rules. Every AI action gets logged (inputs, reasoning, outputs, decision rationale). Then compliance/audit reviews a sample + exception cases. Most companies ARE just logging and praying though. That's a regulation waiting to happen.",
          "score": 1,
          "created_utc": "2026-01-05 17:12:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q26o5g",
      "title": "How are you handling governance and guardrails in your LangChain agents?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q26o5g/how_are_you_handling_governance_and_guardrails_in/",
      "author": "forevergeeks",
      "created_utc": "2026-01-02 18:37:35",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "Hi Everyone,\n\nHow are you handling governance/guardrails in your agents today? Are you building in regulated fields like healthcare, legal, or finance and how are you dealing with compliance requirements?\n\nFor the last year, I've been working on¬†SAFi, an open-source governance engine that wraps your LLM agents in ethical guardrails. It can block responses before they  are delivered to the user, audit every decision, and detect behavioral drift over time.\n\nIt's based on four principles:\n\n* **Value Sovereignty -** You decide the values your AI enforces, not the model provider\n* **Full Traceability -** Every response is logged and auditable\n* **Model Independence -** Switch LLMs without losing your governance layer\n* **Long-Term Consistency -** Detect and correct ethical drift over time\n\nI'd love feedback on how SAFi could¬†complement¬†the work you're doing with LangChain:\n\n* **Live demo:**¬†[safi.selfalignmentframework.com](https://safi.selfalignmentframework.com/)\n* **GitHub:**¬†[github.com/jnamaya/SAFi](https://github.com/jnamaya/SAFi)\n\nTry the pre-built agents:¬†*SAFi Guide*¬†(RAG),¬†*Fiduciary*, or¬†*Health Navigator*.\n\nHappy to answer any questions!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q26o5g/how_are_you_handling_governance_and_guardrails_in/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxazax3",
          "author": "AdditionalWeb107",
          "text": "Great work OP. But look at Plano: [https://github.com/katanemo/plano](https://github.com/katanemo/plano) agent filter chains: https://docs.planoai.dev/concepts/filter\\_chain.html. Framework-agnostic and easily extensible.",
          "score": 1,
          "created_utc": "2026-01-02 19:19:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2lyx4",
      "title": "Langgraph history summarisation",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q2lyx4/langgraph_history_summarisation/",
      "author": "ankitsi9gh",
      "created_utc": "2026-01-03 05:16:11",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "How do you guys summarise old chats in langgraph with trim_message, without deleting or removing old chats from state. ??\n\nLike for summarizing should I use langmem our build custom node and also for trim_message what would be best token base trimming or message count base trimming ??",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1q2lyx4/langgraph_history_summarisation/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q48k0b",
      "title": "AI Pre-code",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q48k0b/ai_precode/",
      "author": "umutkrts",
      "created_utc": "2026-01-05 01:51:25",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "Hey everyone, is there a tool where we can design an AI-native feature/functionality before writing code‚Äîeither visually or code-based‚Äîrun it, see outputs and costs, and compare different systems?\n\nI can build flows in FlowiseAI or LangFlow, but I can‚Äôt see costs or easily compare different design approaches.\n\nFor example, say you‚Äôre building a mobile app and need a specific AI feature. You design and run one setup like LangChain splitter ‚Üí OpenAI embeddings ‚Üí Pinecone vector store ‚Üí retriever, and then compare it against another setup like LlamaIndex splitter ‚Üí Cohere embeddings ‚Üí ChromaDB ‚Üí retriever for the same use case.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1q48k0b/ai_precode/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "nxtb3kb",
          "author": "SearchTricky7875",
          "text": "not really, for ai based feature you need to either use apis provided by different companies , lets say for image generation, video generation, but there is no such option to built gpu based function and make it api accessible. building the function isn't enough , you have to make it api accessible as well",
          "score": 1,
          "created_utc": "2026-01-05 13:29:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2r39u",
      "title": "ai-rulez: universal agent context manager",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1q2r39u/airulez_universal_agent_context_manager/",
      "author": "Goldziher",
      "created_utc": "2026-01-03 10:10:45",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "I'd like to share [ai-rulez](https://github.com/Goldziher/ai-rulez). It's a tool for managing and generating rules, skills, subagents, context and similar constructs for AI agents. It supports basically any agent out there because it allows users to control the generated outputs, and it has out-of-the-box presets for all the popular tools (Claude, Codex, Gemini, Cursor, Windsurf, Opencode and several others).\n\n## Why?\n\nThis is a valid question. As someone wrote to me on a previous post -- \"this is such a temporary problem\". Well, that's true, I don't expect this problem to last for very long. Heck, I don't even expect such hugely successful tools as Claude Code itself to last very long - technology is moving so fast, this will probably become redundant in a year, or two - or three. Who knows. Still, it's a real problem now - and one I am facing myself. So what's the problem?\n\nYou can create your own .cursor, .claude or .gemini folder, and some of these tools - primarily Claude - even have support for sharing (Claude plugins and marketplaces for example) and composition. The problem really is vendor lock-in. Unlike MCP - which was offered as a standard - AI rules, and now skills, hooks, context management etc. are ad hoc additions by the various manufacturers (yes there is the AGENTS.md initiative but it's far from sufficient), and there isn't any real attempt to make this a standard.\n\nFurthermore, there are actual moves by Anthropic to vendor lock-in. What do I mean? One of my clients is an enterprise. And to work with Claude Code across dozens of teams and domains, they had to create a massive internal infra built around Claude marketplaces. This works -- okish. But it absolutely adds vendor lock-in at present.\n\nI also work with smaller startups, I even lead one myself, where devs use their own preferable tools. I use IntelliJ, Claude Code, Codex and Gemini CLI, others use VSCode, Anti-gravity, Cursor, Windsurf clients. On top of that, I manage a polyrepo setup with many nested repositories. Without a centralized solution, keeping AI configurations synchronized was a nightmare - copy-pasting rules across repos, things drifting out of sync, no single source of truth. I therefore need a single tool that can serve as a source of truth and then .gitignore the artifacts for all the different tools.\n\n## How AI-Rulez works\n\nThe basic flow is: you run `ai-rulez init` to create the folder structure with a `config.yaml` and directories for rules, context, skills, and agents. Then you add your content as markdown files - rules are prescriptive guidelines your AI must follow, context is background information about your project (architecture, stack, conventions), and skills define specialized agent personas for specific tasks (code reviewer, documentation writer, etc.). In `config.yaml` you specify which presets you want - claude, cursor, gemini, copilot, windsurf, codex, etc. - and when you run `ai-rulez generate`, it outputs native config files for each tool.\n\nA few features that make this practical for real teams:\n\nYou can compose configurations from multiple sources via includes - pull in shared rules from a Git repo, a local path, or combine several sources. This is how you share standards across an organization or polyrepo setup without copy-pasting.\n\nFor larger codebases with multiple teams, you can organize rules by domain (backend, frontend, qa) and create profiles that bundle specific domains together. Backend team generates with `--profile backend`, frontend with `--profile frontend`.\n\nThere's a priority system where you can mark rules as critical, high, medium, or low to control ordering and emphasis in the generated output.\n\nThe tool can also run as a server (supports the Model Context Protocol), so you can manage your configuration directly from within Claude or other MCP-aware tools.\n\nIt's written in Go but you can use it via npx, uvx, go run, or brew - installation is straightforward regardless of your stack. It also comes with an MCP server, so agents can interact with it (add, update rules, skill etc.) using MCP. \n\n## Examples\n\nWe use [ai-rulez](https://github.com/Goldziher/ai-rulez) in the [Kreuzberg.dev Github Organization](https://github.com/kreuzberg-dev) and the open source repositories underneath it - [Kreuzberg](https://github.com/kreuzberg-dev/kreuzberg) and [html-to-markdown](https://github.com/kreuzberg-dev/html-to-markdown) - both of which are polyglot libraries with a lot of moving parts. The rules are shared via git, for example you can see the [config.yaml](https://github.com/kreuzberg-dev/html-to-markdown/blob/main/.ai-rulez/config.yaml) file in the html-to-markdown .ai-rulez folder, showing how the rules module is read from GitHub. The `includes` key is an array, you can install from git and local sources, and multiple of them - it scales well, and it supports SSH and bearer tokens as well.\n\nAt any rate, this is the [shared rules](https://github.com/kreuzberg-dev/ai-rulez) repository itself - you can see how the [data is organized under a .ai-rulez folder](https://github.com/kreuzberg-dev/ai-rulez/tree/main/.ai-rulez), and you can see how some of the data is split among [domains](https://github.com/kreuzberg-dev/ai-rulez/tree/main/.ai-rulez/domains).\n\nWhat do the generated files look like? Well, they're native config files for each tool - CLAUDE.md for Claude, .cursorrules for Cursor, .continuerules for Continue, etc. Each preset generates exactly what that tool expects, with all your rules, context, and skills properly formatted.\n",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1q2r39u/airulez_universal_agent_context_manager/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    }
  ]
}