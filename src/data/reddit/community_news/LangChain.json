{
  "metadata": {
    "last_updated": "2026-02-13 09:09:58",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 40,
    "file_size_bytes": 82146
  },
  "items": [
    {
      "id": "1r1o9hf",
      "title": "EpsteinFiles-RAG: Building a RAG Pipeline on 2M+ Pages",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r1o9hf/epsteinfilesrag_building_a_rag_pipeline_on_2m/",
      "author": "Cod3Conjurer",
      "created_utc": "2026-02-11 05:01:03",
      "score": 90,
      "num_comments": 18,
      "upvote_ratio": 0.95,
      "text": "I love playing around with RAG and AI, optimizing every layer to squeeze out better performance. Last night I thought: why not tackle something massive?\n\nTook the Epstein Files dataset from Hugging Face (teyler/epstein-files-20k) â€“ 2 million+ pages of trending news and documents. The cleaning, chunking, and optimization challenges are exactly what excites me.\n\nWhat I built:\n\n\\- Full RAG pipeline with optimized data processing\n\n\\- Processed 2M+ pages (cleaning, chunking, vectorization)\n\n\\- Semantic search & Q&A over massive dataset\n\n\\- Constantly tweaking for better retrieval & performance\n\n\\- Python, MIT Licensed, open source\n\nWhy I built this:\n\nItâ€™s trending, real-world data at scale, the perfect playground.\n\nWhen you operate at scale, every optimization matters. This project lets me experiment with RAG architectures, data pipelines, and AI performance tuning on real-world workloads.\n\nRepo: [https://github.com/AnkitNayak-eth/EpsteinFiles-RAG](https://github.com/AnkitNayak-eth/EpsteinFiles-RAG)\n\nOpen to ideas, optimizations, and technical discussions!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r1o9hf/epsteinfilesrag_building_a_rag_pipeline_on_2m/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4w6ivw",
          "author": "BeerBatteredHemroids",
          "text": "This is the best post I've seen on this thread in a long time ğŸ˜‚",
          "score": 4,
          "created_utc": "2026-02-11 23:53:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xjyvo",
              "author": "Cod3Conjurer",
              "text": "Haha appreciate that ğŸ˜„ just experimenting and sharing what Iâ€™m building.",
              "score": 2,
              "created_utc": "2026-02-12 05:03:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sitcm",
          "author": "Tengoles",
          "text": "How much space is needed to store the huggingface dataset + JSONS + vector DB?",
          "score": 3,
          "created_utc": "2026-02-11 13:00:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ti4vu",
              "author": "Cod3Conjurer",
              "text": "huggingface dataset- 250mb  \nvector DB - 1.5gb  \n",
              "score": 3,
              "created_utc": "2026-02-11 16:05:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xx64k",
                  "author": "Cobra_venom12",
                  "text": "From where did you learn hugging face and other stuff.",
                  "score": 2,
                  "created_utc": "2026-02-12 06:55:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u31mi",
          "author": "generate-addict",
          "text": "Is this the same post from /r/epstein?\n\nYouâ€™re missing the Jan 30 dataset so the content in your DB likely isnâ€™t as interesting .",
          "score": 2,
          "created_utc": "2026-02-11 17:43:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xl5b4",
              "author": "Cod3Conjurer",
              "text": "Yeah, Iâ€™m aware the Jan 30 dataset isnâ€™t included. I tried finding updated versions, but most of the newer mirrors seem to have been taken down.",
              "score": 1,
              "created_utc": "2026-02-12 05:12:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xzgdq",
                  "author": "generate-addict",
                  "text": "Really? All the torrent links are failing? They should be working. I think dataset 11 is still slow and seeding out there. \n\nhttps://github.com/yung-megafone/Epstein-Files",
                  "score": 1,
                  "created_utc": "2026-02-12 07:16:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4xwpua",
          "author": "SharpRule4025",
          "text": "2M+ pages is where the ingestion pipeline design really matters. At that scale, the bottleneck shifts from retrieval quality to processing throughput and storage costs.\n\nCurious about your chunking approach for scanned documents. OCR quality on these types of files is usually inconsistent, lots of headers, page numbers, redaction markers mixed in with actual content. Are you doing any pre-filtering to strip out low-information chunks before they hit the vector store?\n\nThe storage question above is worth answering too. At 2M pages, your vector DB size can get significant depending on your embedding dimensions and whether you're storing the raw text alongside the vectors.",
          "score": 2,
          "created_utc": "2026-02-12 06:51:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zjo9v",
              "author": "Cod3Conjurer",
              "text": "shifted from pure semantic search to **MMR**, which reduced redundant chunks and improved retrieval quality.",
              "score": 1,
              "created_utc": "2026-02-12 14:38:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rnfwn",
          "author": "Kooky-Breadfruit-837",
          "text": "Extract out everything about the terrornation israel",
          "score": 6,
          "created_utc": "2026-02-11 08:38:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4s4c1t",
              "author": "Cod3Conjurer",
              "text": "Ha haa ğŸ¤£",
              "score": 1,
              "created_utc": "2026-02-11 11:14:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4x4maw",
              "author": "Sungog1",
              "text": "Thatâ€™s a pretty intense focus! If youâ€™re looking for specific data about Israel, maybe try filtering by keywords or key events in your processing steps. What kind of insights are you hoping to extract?",
              "score": 1,
              "created_utc": "2026-02-12 03:17:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uifs8",
          "author": "Cobra_venom12",
          "text": "I'm looking to start from the absolute basics of RAG. Beyond just 'using' a tool, what are the fundamental concepts (like embeddings or vector math) I should grasp first so I actually understand what's happening under the hood? I'd love a recommendation on a 'Step 1' resource for someone starting at zero.",
          "score": 1,
          "created_utc": "2026-02-11 18:54:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xvagu",
              "author": "fishishuntingsharks",
              "text": "For embeddings in particular, I really like https://jalammar.github.io/illustrated-word2vec/\n\nFor how LLMs work in general, there is also a great video by 3blue1brown https://youtu.be/LPZh9BOjkQs?si=9QJWSXTTZJM5G7oe",
              "score": 1,
              "created_utc": "2026-02-12 06:38:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4t2pb2",
          "author": "Exciting_Passage5443",
          "text": "Indian product is just a messÂ ",
          "score": 1,
          "created_utc": "2026-02-11 14:51:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r08s87",
      "title": "What's everyone using to deploy LangChain agents to production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r08s87/whats_everyone_using_to_deploy_langchain_agents/",
      "author": "MathematicianTop1654",
      "created_utc": "2026-02-09 16:28:35",
      "score": 21,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "Curious what production setups people are running for their LangChain agents/workflows.\n\nI've been cobbling together FastAPI + Docker + some kind of queue system (currently trying Celery), but honestly it feels like I'm reinventing the wheel. Dealing with timeouts, scaling, versioning, keeping secrets organized - it works but it's a lot of moving parts.\n\nWhat are you all using? Are most people just building custom infra, or are there patterns/tools that make this smoother?\n\nSpecifically interested in:\n\n* How you handle long-running agent workflows (async patterns, webhooks, polling?)\n* Deployment/orchestration setup (k8s, serverless, something else?)\n* Managing different versions when you're iterating quickly\n* Observability - how do you actually debug when an agent does something weird in prod?\n\nWould love to hear what's working well for people, or if there are resources/repos I should check out to level up my setup.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r08s87/whats_everyone_using_to_deploy_langchain_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4gy661",
          "author": "penguinzb1",
          "text": "the observability piece is harder than most people expect. by the time you're debugging in prod, you've already lostâ€”users saw the weird behavior.\n\nwe ended up leaning heavily on pre-deployment simulation. run the agent through scenarios that mimic prod traffic patterns before it goes live. catches a lot of the \"why did it do that?\" moments early when they're cheap to fix, not after users report them.\n\nfor the stack itselfâ€”fastapi works, but if you're hitting timeout issues frequently, might be worth looking at whether those are actually agent behavior problems (going down unproductive paths, getting stuck in loops) vs infrastructure problems. simulating those workflows offline first helps separate the two.",
          "score": 6,
          "created_utc": "2026-02-09 17:58:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4q9txw",
              "author": "arbiter_rise",
              "text": "Totally agree â€” observability always ends up being harder than expected. Pre-deployment simulation sounds like a really effective way to catch those â€œwhy did it do that?â€ cases early.\n\nCurious if you have any other tips for diagnosing agent behavior problems, especially around unproductive paths or loops?",
              "score": 1,
              "created_utc": "2026-02-11 02:19:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sr2v8",
          "author": "Informal_Tangerine51",
          "text": "Long-running workflows need async execution but the real problem is debugging when they fail.\n\nWe run FastAPI + SQS + Lambda for async. Works for execution but observability is the gap. When agent makes wrong decision at step 4 of 12-step workflow, logs show it executed, not what data it saw or why it chose that path. LangSmith traces help with structure but don't capture retrieval results or decision context.\n\nFor production debugging: you need more than execution logs. What did vector search return? What was in context window when model decided? Can you replay this exact decision without re-running side effects? Most deployment setups optimize for execution, ignore evidence capture. That's fine until incidents require root cause analysis instead of just \"retry and hope.\"",
          "score": 2,
          "created_utc": "2026-02-11 13:48:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i87yr",
          "author": "DullTicket5286",
          "text": "Aegra+langfuse",
          "score": 1,
          "created_utc": "2026-02-09 21:42:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j1tbb",
              "author": "jlebensold",
              "text": "We wrote an agent that reads your langfuse traces and helps save you money in prod: https://www.jetty.io",
              "score": 1,
              "created_utc": "2026-02-10 00:19:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ntwtm",
          "author": "Few-Programmer4405",
          "text": "Youâ€™re not alone, FastAPI + Docker + queues seems to be the default and it gets messy fast. Iâ€™ve been testing Crewship and itâ€™s been pretty nice so far. It handles long-running agent workflows, retries, versioning, and observability out of the box, so it feels more like deploying agents than building infra. ",
          "score": 1,
          "created_utc": "2026-02-10 18:46:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxg9dd",
      "title": "3D-Agent multi agent system with LangChain for Blender AI",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/kprnhlhgavhg1",
      "author": "Large-Explorer-8532",
      "created_utc": "2026-02-06 12:27:15",
      "score": 19,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qxg9dd/3dagent_multi_agent_system_with_langchain_for/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3ym0vy",
          "author": "Jorsoi13",
          "text": "Cool! Thanks for so much detail! When you mean â€verify the frameâ€œ you are talking about sending a screenshot to the agent or how does verification prevent drift? \n\nIâ€˜m also currently building an agent, however I just started out literally a week ago. Iâ€˜m really trying to grasp how to orchestrate everything together. Iâ€˜m still lacking best practices and Langchain Docs are also a b*tch when it comes to documentation and integrating it with the frontend like yours (nextjs, etc.) \n\nDid you deploy using LangSmith or did you set up a self hosted version yourself? Weâ€˜re currently debating what the best approach is since we donâ€™t want to pay 40â‚¬ just for their deployment. I was more hoping for an â€n8n self-host approachâ€œ on Digitalocean for like 5$ a month :)",
          "score": 3,
          "created_utc": "2026-02-06 20:07:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ynskn",
              "author": "Large-Explorer-8532",
              "text": "We do not use langsmith, we have a mix of custom frameworks and langchain.\n\nI would recomend self-hosted allÂ the way. NoÂ reasonÂ to payÂ $40/monthÂ for LangSmith when you're startingÂ out. YourÂ n8n onÂ DigitalOcean instinctÂ is solid. KeepÂ it simple, it is easy to get lost buying endless things.",
              "score": 1,
              "created_utc": "2026-02-06 20:16:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3zbhks",
                  "author": "mdrxy",
                  "text": "starting out, LangSmith has a free plan for developers ;)",
                  "score": 2,
                  "created_utc": "2026-02-06 22:15:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3zbc8k",
          "author": "mdrxy",
          "text": "cool can you talk more about the langchain architecture you used?",
          "score": 2,
          "created_utc": "2026-02-06 22:14:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o422hvp",
              "author": "Large-Explorer-8532",
              "text": "[](https://docs.langchain.com/oss/python/deepagents/skills)it givesÂ us ready-to-use primitives for subagentÂ orchestration, isolation, memory, andÂ context management outÂ of the box. Each agentÂ (Gemini, GPT, Claude) runsÂ inÂ its own isolated nodeÂ withÂ its own contextÂ window, andÂ LangGraph handles the routing, state persistence, and handoffsÂ between them. It's whatÂ letsÂ us keepÂ eachÂ agent focusedÂ on whatÂ it'sÂ bestÂ at withoutÂ themÂ steppingÂ on each other. HappyÂ to goÂ deeper on any specificÂ partÂ if you'reÂ curious![](https://docs.langchain.com/oss/python/deepagents/skills)",
              "score": 1,
              "created_utc": "2026-02-07 09:58:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zd2up",
          "author": "Upstairs-Spell7521",
          "text": "why do you use langchain tho? what advantages it gives to you?",
          "score": 2,
          "created_utc": "2026-02-06 22:23:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o421v7z",
              "author": "Large-Explorer-8532",
              "text": "LangChain/LangGraph hasÂ some reallyÂ usefulÂ built-in features for subagentÂ orchestration, memory management, human-in-the-loop workflows, and otherÂ waysÂ to coordinate aÂ multi-agent system. We've alsoÂ experimented with skills from DeepAgent... mixed feelings onÂ that soÂ far  \nTheÂ mainÂ benefit is notÂ having to build theseÂ primitives from scratch, havingÂ them ready to use saves us hours ofÂ work",
              "score": 1,
              "created_utc": "2026-02-07 09:52:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xiado",
          "author": "Jorsoi13",
          "text": "Wow! Thats amazing. I mean the visuals of that Eiffel Tower are debateable but the fact that it works is great. Now the next step is probably reducing friction. It seems like there are a lot of steps to actually start using the product at least thats what your dashboard suggests. \n\nOther than that: \n\n\\- The agent runs really long. I thought \"Oh shit that thing must swallow some serious credits\". Am I right? How much money did you spend on creating the eiffel tower? Or how many tokens does an operation like that generate? \n\n\\- What is your agent orchestration like? I would really love to see your graph structure for the sake of learning. Would you mind sharing it ?",
          "score": 1,
          "created_utc": "2026-02-06 16:57:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yiph7",
              "author": "Large-Explorer-8532",
              "text": "ThanksÂ man, reallyÂ appreciate the thoughtful feedback!\n\nyeahÂ theÂ Eiffel Tower is definitelyÂ roughÂ blocking, notÂ a portfolioÂ piece. But the pointÂ isÂ theÂ agentÂ builtÂ it autonomously fromÂ aÂ singleÂ prompt, whichÂ is theÂ hardÂ part. QualityÂ willÂ keepÂ improving asÂ the modelsÂ get better.\n\nyou'reÂ 100% right andÂ we're activelyÂ workingÂ on this. TheÂ onboarding hasÂ tooÂ many steps rightÂ now. GoalÂ is: installÂ theÂ pluginÂ â†’ connectÂ â†’ start chatting. We're cuttingÂ itÂ down.\n\nhonestlyÂ it's lessÂ thanÂ you'd think. TheÂ agent isÂ smartÂ about batching operationsÂ andÂ onlyÂ callsÂ theÂ reasoningÂ model when itÂ actuallyÂ needs to makeÂ a decision. MostÂ of theÂ \"thinking\" stepsÂ are lightweight. TheÂ longÂ runtimeÂ is mostlyÂ Blender executingÂ theÂ code, not the AIÂ burningÂ tokens. The output are short mostly short.\n\nThe highÂ levelÂ is: we useÂ a planningÂ agent that breaksÂ theÂ taskÂ into stages, another ones comes to reason and think in \"3D/Spatial Math\" then anÂ execution agent handlesÂ eachÂ stageÂ inÂ aÂ loopÂ (perceive sceneÂ â†’ decideÂ nextÂ actionÂ â†’ executeÂ code â†’ verify viaÂ viewport). The keyÂ insightÂ wasÂ addingÂ theÂ verificationÂ step... withoutÂ it theÂ agent drifts andÂ you getÂ garbage. There's a routerÂ inÂ betweenÂ that decidesÂ whenÂ to escalate toÂ the reasoningÂ model vsÂ handleÂ it withÂ a faster/cheaper one. WouldÂ love to doÂ a deeperÂ write-up atÂ some point onceÂ we'veÂ solidified the architecture more.\n\nWhat's your background? YouÂ soundÂ like you'reÂ buildingÂ agentsÂ yourselfÂ ",
              "score": 2,
              "created_utc": "2026-02-06 19:51:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0dvgp",
      "title": "How do you handle agent-to-agent discovery as you scale past 20+ agents?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r0dvgp/how_do_you_handle_agenttoagent_discovery_as_you/",
      "author": "Sea-Perception1619",
      "created_utc": "2026-02-09 19:28:42",
      "score": 14,
      "num_comments": 7,
      "upvote_ratio": 0.95,
      "text": "We're running about 30 specialized agents (mix of LangGraph and custom) and the coordination is getting painful. Right now everything goes through a central orchestrator that maintains a registry of who can do what. It works but it's fragile â€” orchestrator went down last week and everything stopped.\n\nCurious how other teams are handling this:\n\n* How do your agents find each other's capabilities?\n* What breaks first as you add more agents?\n* Anyone running agents across multiple teams/orgs? How do you handle discovery across boundaries?\n* Is anyone using MCP or A2A for this, and how's that going?\n\nNot looking for a specific tool recommendation â€” more interested in architectural patterns that work at scale.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r0dvgp/how_do_you_handle_agenttoagent_discovery_as_you/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4iurm5",
          "author": "ArmOk3290",
          "text": "This feels a lot like service discovery plus workflow orchestration, with LLMs making the edges fuzzier.\n\nWhat has worked for me is separating three things:\n- Capability registry as data, not a single process. Put it in a durable store and replicate it. Treat updates as events.\n- Routing as stateless. The orchestrator can die and come back because it only reads registry plus current task state.\n- Execution as durable jobs. If an agent dies mid task, you can retry or reassign based on idempotent steps.\n\nFor agent to agent calls, I would keep a small, versioned contract for each tool or capability and require each agent to self report health and supported versions. At 30 plus agents, the first thing that breaks is observability, so I would invest early in traces and per agent quotas so one bad loop cannot take the whole system down.",
          "score": 6,
          "created_utc": "2026-02-09 23:40:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iwmzg",
              "author": "Sea-Perception1619",
              "text": "This is a clean separation. The registry-as-data pattern with event-driven updates is something I keep seeing in mature setups â€” it avoids the SPOF of a registry process while keeping things consistent.\n\nCurious about the routing layer â€” when multiple agents can handle the same capability and you need to pick one, what's the selection logic? Round-robin, random, or something quality-aware? And does the routing improve over time based on past outcomes, or is it static once the registry is populated?\n\nThe observability point resonates. Per-agent traces and quotas before anything else at scale.",
              "score": 2,
              "created_utc": "2026-02-09 23:50:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4klqca",
                  "author": "TheExodu5",
                  "text": "I'm speaking out of my depth here as I don't yet have any experience at this scale, but what about using a reranking model to choose the best agent if multiple fit the criteria? You'd need to store agent metadata as embeddings, but that would be cheap.",
                  "score": 2,
                  "created_utc": "2026-02-10 06:19:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4mc12s",
                  "author": "fasti-au",
                  "text": "Shrug first in locks item.  Timing based allocation to groups",
                  "score": 1,
                  "created_utc": "2026-02-10 14:32:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mbryl",
          "author": "fasti-au",
          "text": "Hold control of the strings and use real-time state control and then task based then is queues based.   Itâ€™s just state checking various sources and needing a green or red light for a Iâ€™d in a queue.",
          "score": 1,
          "created_utc": "2026-02-10 14:31:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xx9lv",
          "author": "YUYbox",
          "text": "Hi , if you want better results from your agents you should try InsAIts:\nhttps://github.com/Nomadu27/InsAIts\n\n    InsAIts V2.5 features: Edge/Hybrid Swarm Routing (routes embeddings across local/cloud/edge with privacy modes: STRICT/BALANCED/PERFORMANCE, get_embedding() failover); AI Lineage Oracle (provenance tracking: record_message(), verify_chain_integrity(), export_audit_trail() for GDPR/HIPAA compliance); Decipher enhancements., anchor-aware detection and forensic visualization. \nIf you find this helpfull please star the repo and install free: https://github.com/Nomadu27/InsAIts â€“ 100 free keys for early adopters.'",
          "score": 1,
          "created_utc": "2026-02-12 06:56:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0sd5p",
      "title": "Looked into OpenClaw security after the MCP discussion here and the numbers are worse than I expected",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r0sd5p/looked_into_openclaw_security_after_the_mcp/",
      "author": "Drysetcat",
      "created_utc": "2026-02-10 05:32:54",
      "score": 13,
      "num_comments": 2,
      "upvote_ratio": 0.81,
      "text": "Been setting up OpenClaw for a side project (local automation stuff, nothing crazy) and the recent thread about MCPs being outdated got me thinking about the actual security posture of what I'm running. Did some digging and found research from Gen Threat Labs that honestly made me reconsider my setup.\n\nThe big one: over 18,000 OpenClaw instances are currently exposed to the public internet. That's not instances running locally as intended, that's port 18789 sitting open for anyone to poke at. Given that these agents often have filesystem access, shell execution, and credentials to various services, that's a lot of attack surface just sitting there. Made me immediately go check my own firewall rules.\n\nThe other number that stood out: their analysis claims nearly 15% of community skills contain malicious instructions. Now I'm genuinely not sure how they verified that or what threshold they used for \"malicious\" so take it with some salt. But even if the real number is half that it's pretty concerning. Apparently when bad skills get flagged and removed from ClawHub they frequently reappear under different names which tracks with what I've seen in other package ecosystems.\n\nHonestly the OpenClaw FAQ itself is refreshingly blunt about this being a \"Faustian bargain\" with no \"perfectly safe\" setup. The power comes from deep system access which is exactly what creates the exposure. I respect the transparency but it does make me reconsider how casually I've been treating this stuff. I had my instance connected to my actual email for testing which in retrospect was pretty dumb.\n\nThe concept that stuck with me is what the research called \"delegated compromise\" where attackers don't need to target you directly, they just compromise the agent and inherit whatever permissions you gave it. Obvious in hindsight but I hadn't really thought about my agents as high value targets in their own right. That realization is what finally got me to actually change my setup instead of just thinking \"I should probably fix this eventually.\"\n\nI've since moved everything into a Docker container with network set to none except when I explicitly need external access, and stripped permissions down to just filesystem read on a single project directory mounted as a volume. No email, no shell execution, no browser. Basically treating it like I would any random npm package from an unknown author.\n\nWhat security practices are others here using? Curious whether people are actually running these in isolated environments or just going full send on their dev machines. For those who do vet skills before installing, what does your workflow look like? I've seen a few scanner tools floating around (something called Agent Trust Hub and a couple others) but haven't tried any yet and manually reviewing every skill is getting tedious.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r0sd5p/looked_into_openclaw_security_after_the_mcp/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4lwm15",
          "author": "tabdon",
          "text": "I did a google search just for fun to see what security practices are. Found the following link (no affiliation). Just skimming through it a lot of interesting things pop out.  \n[https://aimaker.substack.com/p/openclaw-security-hardening-guide](https://aimaker.substack.com/p/openclaw-security-hardening-guide)\n\nSo there's clear need for OpenClaw. If someone can crack the \"secure and easy to use\" nut, there be gold.",
          "score": 2,
          "created_utc": "2026-02-10 13:06:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nkgqt",
          "author": "felixthekraut",
          "text": "The only secure way to run OpenClaw is to not run it at all.",
          "score": 1,
          "created_utc": "2026-02-10 18:03:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r30gjb",
      "title": "The MCP thread got me paranoid about community skills and supply chain risks",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r30gjb/the_mcp_thread_got_me_paranoid_about_community/",
      "author": "Independent_Plum_489",
      "created_utc": "2026-02-12 17:59:43",
      "score": 13,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "That discussion about MCPs being outdated and agents moving toward raw CLI access sent me down a rabbit hole I wasn't expecting. Been experimenting with OpenClaw recently (hard to ignore 160K stars) and saw someone in the GitHub issues flag a calendar integration skill that was requesting file system write access and network permissions for something that should just be reading a schedule. They dug into the code and found base64 encoded strings that decoded to external URLs and some sketchy eval statements. Maintainer removed it pretty quick but it had already been up for a few days.\n\nStarted googling after reading that thread and honestly got a bit worried. Apparently a decent chunk of community built skills have been flagged for doing sketchy things like data collection or downloading external payloads. Can't verify the exact numbers myself but it tracks with what I've been seeing in issue trackers. OpenClaw's own docs call the whole setup a \"Faustian bargain\" which... yeah.\n\nFeels like we're repeating the npm left-pad era except now the stakes are higher because these agents have real permissions. Read your emails, browse authenticated pages, execute shell commands. One bad skill and you've basically handed over the keys.\n\nSo now I'm being paranoid about everything. Manual code review when I have patience for it, though I'm slow at spotting obfuscated stuff. Checking GitHub issues and recent commits before installing anything. Running everything in Docker with network monitoring just in case. I've tried throwing Semgrep at some skills with mixed results, poked around with Snyk and Agent Trust Hub too. Even grep for obvious patterns like base64 or eval. The automated scanners all feel like security theater though when you're dealing with prompt injection vectors they weren't really designed for.\n\nStarting to think the only real answer is extreme permission isolation but that defeats half the usefulness of these agents. There's probably no good solution here.\n\nWhat does your vetting process look like before installing community stuff? Or is the general approach to just run everything sandboxed and hope for the best?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r30gjb/the_mcp_thread_got_me_paranoid_about_community/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r38uf7",
      "title": "I built a Recursive Language Model (RLM) with LangGraph that spawns child agents to beat context rot",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r38uf7/i_built_a_recursive_language_model_rlm_with/",
      "author": "DolphinSyndrome",
      "created_utc": "2026-02-12 23:18:56",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hey r/LangChain ğŸ‘‹\n\nI builtÂ **Fractal Context**Â â€” a LangGraph implementation of Recursive Language Models that solves the \"context rot\" problem by letting an LLMÂ **recursively spawn child agents**Â to process large text.\n\n**The problem:**Â When you stuff a massive document into an LLM, attention degrades â€” details in the middle get \"forgotten\" and the model starts hallucinating. This is context rot.\n\n**The solution:**Â Instead of cramming everything into one prompt, the parent agent:\n\n1. Evaluates if the context is too large\n2. Uses a Python REPL to slice the text into chunks\n3. CallsÂ `delegate_subtask` Â to spawn aÂ **child agent**Â atÂ `depth + 1`\n4. Each child processes its chunk and reports back\n5. The parent synthesizes all answers\n\nThe recursion is depth-limited to prevent runaway chains.\n\n**The \"Glass Box\" UI:**Â Built with Chainlit, the UI shows nested steps in real-time so you can actuallyÂ *see*Â the recursion happening:\n\n* ğŸ§ Â **Thinkingâ€¦**Â â€” LLM reasoning (token by token)\n* ğŸ’»Â **Codingâ€¦**Â â€” when the agent writes Python to slice text\n* ğŸ”€Â **Sub-Agent (Depth N)**Â â€” child agents spawning and reporting\n\n**Tech stack:**\n\n* LangGraph (StateGraph with conditional edges)\n* LangChain + Groq API (Llama 3.3 70B)\n* Chainlit for the UI\n* Python 3.11+\n\n**Repo:**Â [github.com/Dolphin-Syndrom/fractal-context](https://github.com/Dolphin-Syndrom/fractal-context)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r38uf7/i_built_a_recursive_language_model_rlm_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o54lfa3",
          "author": "Don_Ozwald",
          "text": "I just wish people would use the word recursion appropriately. \n\nBut I like what you describe with the UI, well done there!\n\nEdit: I see now your implementation is much closer to actual recursion than what it usually is when the term â€œRecursive language modelâ€ is thrown around. Bravo!",
          "score": 1,
          "created_utc": "2026-02-13 07:35:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2n74g",
      "title": "Open Source Kreuzberg v4.3.0 and benchmarks",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r2n74g/open_source_kreuzberg_v430_and_benchmarks/",
      "author": "Eastern-Surround7763",
      "created_utc": "2026-02-12 07:32:00",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "Hi all,\n\nI have two announcements related toÂ [Kreuzberg](https://github.com/kreuzberg-dev/kreuzberg):\n\n1. We released our newÂ [comparative benchmarks](https://kreuzberg.dev/benchmarks). These have a slick UI and we have been working hard on them for a while now (more on this below), and we'd love to hear your impressions and get some feedback from the community!\n2. We released v4.3.0, which brings in a bunch of improvements including PaddleOCR as an optional backend, document structure extraction, and native Word97 format support. More details below.\n\n# What is Kreuzberg?\n\n[Kreuzberg](https://github.com/kreuzberg-dev/kreuzberg)Â is an open-source (MIT license) polyglot document intelligence framework written in Rust, with bindings for Python, TypeScript/JavaScript (Node/Bun/WASM), PHP, Ruby, Java, C#, Golang and Elixir. It's also available as a docker image and standalone CLI tool you can install via homebrew.\n\nIf the above is unintelligible to you (understandably so), here is the TL;DR: Kreuzberg allows users to extract text from 75+ formats (and growing), perform OCR, create embeddings and quite a few other things as well. This is necessary for many AI applications, data pipelines, machine learning, and basically any use case where you need to process documents and images as sources for textual outputs.\n\n# Comparative Benchmarks\n\nOur new comparative benchmarks UI is live here:Â [https://kreuzberg.dev/benchmarks](https://kreuzberg.dev/benchmarks)\n\nThe comparative benchmarks compare Kreuzberg with several of the top open source alternatives - Apache Tika, Docling, Markitdown, [Unstructured.io](http://Unstructured.io), PDFPlumber, Mineru, MuPDF4LLM. In a nutshell - Kreuzberg is 9x faster on average, uses substantially less memory, has much better cold start, and a smaller installation footprint. It also requires less system dependencies to function (onlyÂ **optional**Â system dependency for it is onnxruntime, for embeddings/PaddleOCR).\n\nThe benchmarks measure throughput, duration, p99/95/50, memory, installation size and cold start with more than 50 different file formats. They are run in GitHub CI on ubuntu latest machines and the results are published into GitHub releases (here is anÂ [example](https://github.com/kreuzberg-dev/kreuzberg/releases/tag/benchmark-run-21923145045)). TheÂ [source code](https://github.com/kreuzberg-dev/kreuzberg/tree/main/tools/benchmark-harness)Â for the benchmarks and the full data is available in GitHub, and you are invited to check it out.\n\n# V4.3.0 Changes\n\nThe v4.3.0 full release notes can be found here:Â [https://github.com/kreuzberg-dev/kreuzberg/releases/tag/v4.3.0](https://github.com/kreuzberg-dev/kreuzberg/releases/tag/v4.3.0)\n\nKey highlights:\n\n1. PaddleOCR optional backend - in Rust. Yes, you read this right, Kreuzberg now supports PaddleOCR in Rust and by extension - across all languages and bindings except WASM. This is a big one, especially for Chinese speakers and other east Asian languages, at which these models excel.\n2. Document structure extraction - while we already had page hierarchy extraction, we had requests to give document structure extraction similar to Docling, which has very good extraction. We now have a different but up to par implementation that extracts document structure from a huge variety of text documents - yes, including PDFs.\n3. Native Word97 format extraction - wait, what? Yes, we now support the legacyÂ `.doc`Â andÂ `.ppt`Â formats directly in Rust. This means we no longer need LibreOffice as an optional system dependency, which saves a lot of space. Who cares you may ask? Well, usually enterprises and governmental orgs to be honest, but we still live in a world where legacy is a thing.\n\n# How to get involved with Kreuzberg\n\n* Kreuzberg is an open-source project, and as such contributions are welcome. You can check us out on GitHub, open issues or discussions, and of course submit fixes and pull requests. Here is the GitHub:Â [https://github.com/kreuzberg-dev/kreuzberg](https://github.com/kreuzberg-dev/kreuzberg)\n* We have aÂ [Discord Server](https://discord.gg/rzGzur3kj4)Â and you are all invited to join (and lurk)!\n\nThat's it for now. As always, if you like it -- star it on GitHub, it helps us get visibility!",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1r2n74g/open_source_kreuzberg_v430_and_benchmarks/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4yvj92",
          "author": "___cjg___",
          "text": "Nice, thanx!",
          "score": 1,
          "created_utc": "2026-02-12 12:13:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o523b13",
          "author": "GiveMeAegis",
          "text": "Are you located in xberg?",
          "score": 1,
          "created_utc": "2026-02-12 21:53:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r05q9n",
      "title": "Building a chat-with-data agent in LangGraph without LLM SQL generation",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/ofdbrxr85hig1.png",
      "author": "deputystaggz",
      "created_utc": "2026-02-09 14:32:31",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r05q9n/building_a_chatwithdata_agent_in_langgraph/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qz6i99",
      "title": "For anyone building agents that need email context: here's what the pipeline actually looks like",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qz6i99/for_anyone_building_agents_that_need_email/",
      "author": "EnoughNinja",
      "created_utc": "2026-02-08 11:22:31",
      "score": 11,
      "num_comments": 4,
      "upvote_ratio": 0.87,
      "text": "Building an agent that needs to reason over email data and wanted to share what the actual infrastructure requirement looks like, because it was way more than I expected.\n\nThe model/reasoning part is straightforward. The hard part is everything before the prompt:\n\n1. OAuth flows per email provider, per user, with token refresh\n2. Thread reconstruction (nested replies, forwarded messages, quoted text stripping, CC/BCC parsing)\n3. Incremental sync so you're not reprocessing full inboxes\n4. Per-user data isolation if you have multiple users\n5. Cross-thread retrieval, because the answer to most work questions spans multiple conversations\n6. Structured extraction into typed JSON, not prose summaries\n\nOne thing I noticed when running dozens of tests with different models (I used threads with 20+ emails, with 4 or 5 different threads per prompt), is that the thread reconstruction is a completely different problem per provider. \n\nGmail gives you threadId but the message ordering and quoted text handling is inconsistent. Outlook threads differently, and forwarded messages break both. If you're building this yourself, don't assume a universal parser will work.\n\nWe built an API that handles all of this (igpt.ai) because we couldn't find anything that did it well. \n\nOne endpoint, you pass a user ID and a query and get back structured JSON with the context already assembled. \n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qz6i99/for_anyone_building_agents_that_need_email/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o49598a",
          "author": "Jorsoi13",
          "text": "How did you handle incremental syncs?",
          "score": 2,
          "created_utc": "2026-02-08 14:07:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4efqxc",
              "author": "EnoughNinja",
              "text": "Per-provider cursors + webhook deltas. We only fetch changes since last sync, then re-index affected \n\nNo full inbox reprocessing",
              "score": 1,
              "created_utc": "2026-02-09 08:08:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ap3yn",
          "author": "bugtank",
          "text": "Honestly this is amazing. Did you use instructor for the structured data?",
          "score": 2,
          "created_utc": "2026-02-08 18:47:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4efpz4",
              "author": "EnoughNinja",
              "text": "No. We enforce schemas at the pipeline level, before the model sees anything ",
              "score": 1,
              "created_utc": "2026-02-09 08:08:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r1zpai",
      "title": "memv â€” open-source memory for AI agents that only stores what it failed to predict",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r1zpai/memv_opensource_memory_for_ai_agents_that_only/",
      "author": "brgsk",
      "created_utc": "2026-02-11 15:02:55",
      "score": 11,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I built an open-source memory system for AI agents with a different approach to knowledge extraction.\n\nThe problem: Most memory systems extract every fact from conversations and rely on retrieval to sort out what matters. This leads to noisy knowledge bases full of redundant information.\n\nThe approach: memv uses predict-calibrate extraction (based on the [https://arxiv.org/abs/2508.03341](https://arxiv.org/abs/2508.03341)). Before extracting knowledge from a new conversation, it predicts what the episode should contain given existing knowledge. Only facts that were unpredicted â€” the prediction errors â€” get stored. Importance emerges from surprise, not upfront LLM scoring.\n\nOther things worth mentioning:\n\n* Bi-temporal model â€” every fact tracks both when it was true in the world (event time) and when you learned it (transaction time). You can query \"what did we know about this user in January?\"\n* Hybrid retrieval â€” vector similarity (sqlite-vec) + BM25 text search (FTS5), fused via Reciprocal Rank Fusion\n* Contradiction handling â€” new facts automatically invalidate conflicting old ones, but full history is preserved\n* SQLite default â€” zero external dependencies, no Postgres/Redis/Pinecone needed\n* Framework agnostic â€” works with LangGraph, CrewAI, AutoGen, LlamaIndex, or plain Python\n\n\n```python\n    from memv import Memory\n    from memv.embeddings import OpenAIEmbedAdapter\n    from memv.llm import PydanticAIAdapter\n    \n    memory = Memory(\n        db_path=\"memory.db\",\n        embedding_client=OpenAIEmbedAdapter(),\n        llm_client=PydanticAIAdapter(\"openai:gpt-4o-mini\"),\n    )\n    \n    async with memory:\n        await memory.add_exchange(\n            user_id=\"user-123\",\n            user_message=\"I just started at Anthropic as a researcher.\",\n            assistant_message=\"Congrats! What's your focus area?\",\n        )\n        await memory.process(\"user-123\")\n        result = await memory.retrieve(\"What does the user do?\", user_id=\"user-123\")\n```\n\nMIT licensed. Python 3.13+. Async everywhere.  \n\\- GitHub: [https://github.com/vstorm-co/memv](https://github.com/vstorm-co/memv)  \n\\- Docs: [https://vstorm-co.github.io/memv/](https://vstorm-co.github.io/memv/)  \n\\- PyPI: [https://pypi.org/project/memvee/](https://pypi.org/project/memvee/)\n\nEarly stage (v0.1.0). Feedback welcome â€” especially on the extraction approach and what integrations would be useful.",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1r1zpai/memv_opensource_memory_for_ai_agents_that_only/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4xwov2",
          "author": "arul-ql",
          "text": "Super interesting approach! Any benchmarks yet on noise reduction vs mem0-style â€œstore everythingâ€ approaches?\n\nWould love to see precision/recall + db growth curves.",
          "score": 1,
          "created_utc": "2026-02-12 06:51:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzsux5",
      "title": "What are the typical steps to turn an idea into a production service using LangChain?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qzsux5/what_are_the_typical_steps_to_turn_an_idea_into_a/",
      "author": "arbiter_rise",
      "created_utc": "2026-02-09 03:06:11",
      "score": 10,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "*(English may sound a bit awkward â€” not a native speaker, sorry in advance!)*  \n  \nIf I want to serve my own idea using LangChain, what are the typical steps people go through to get from a prototype to a production-ready service?\n\nMost tutorials and examples cover things like:  \nprompt design â†’ chain composition â†’ a simple RAG setup.  \nThat part makes sense to me.\n\nBut when it comes to **building something real that users actually use**,  \nIâ€™m not very clear on what comes *after* that.\n\nIn particular, Iâ€™m curious about:\n\n* Whether people usually keep the LangChain architecture as-is when traffic grows\n* How monitoring, logging, and error handling are typically handled in production\n* Whether LangChain remains a core part of the system in the long run, or if it tends to get stripped out over time\n\nFor those who have taken a project from  \n**idea â†’ real production service** using LangChain,  \nIâ€™d really appreciate hearing about the common stages you went through, or any practical advice like  \nâ€œthis is worth doing earlyâ€ vs. â€œthis can wait until later.â€\n\nThanks in advance for sharing your real-world experience",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qzsux5/what_are_the_typical_steps_to_turn_an_idea_into_a/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4eobll",
          "author": "Sam_YARINK",
          "text": "The gap between tutorial examples and production systems is real. Hereâ€™s what typically happens when taking LangChain from prototype to production:\nThe Core Architecture Question\nMost teams actually do keep LangChain in production, but the architecture often evolves significantly. It usually stays as the orchestration layer, but gets wrapped in more infrastructure. Some teams eventually migrate to lighter alternatives if they find theyâ€™re only using basic chain logic, but this tends to happen gradually rather than as a planned replacement.\nTypical Production Steps\nInfrastructure additions:\n- Moving from simple chains to LangGraph for more complex, stateful workflows with better control flow\n- Adding proper API layers (FastAPI/Flask) around your chains\n- Implementing request queuing and rate limiting\n- Setting up proper database connections for conversation history and state management\nObservability stack:\n- LangSmith for tracing and debugging (LangChainâ€™s native tool)\n- Structured logging with correlation IDs across chain steps\n- Custom metrics for latency, token usage, and success rates per chain component\n- Error tracking (Sentry or similar) with LangChain-specific context\nProduction hardening:\n- Implementing retries with exponential backoff for LLM calls\n- Adding circuit breakers for external services\n- Prompt versioning and A/B testing infrastructure\n- Input validation and output sanitization\n- Cost tracking per user/request\nCommon â€œDo This Earlyâ€ Advice\n- Set up tracing from day one - Youâ€™ll need it to debug chain behavior, and retrofitting is painful\n- Design for prompt iteration - Store prompts in config/database, not hardcoded\n- Plan your state management - Conversation memory gets complex quickly with multiple users\n- Implement proper error boundaries - LangChain errors can be cryptic; wrap components with clear error handling\nCommon â€œCan Waitâ€ Items\n- Highly optimized caching strategies\n- Custom chain implementations (start with LangChainâ€™s built-ins)\n- Complex multi-agent systems (unless core to your use case)\nThe biggest shift is often moving from LangChain Expression Language (LCEL) chains to LangGraph when you need more complex control flow, error recovery, or human-in-the-loop patterns.",
          "score": 6,
          "created_utc": "2026-02-09 09:33:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ju6ig",
              "author": "arbiter_rise",
              "text": "Thank you for your answer. What was the most difficult part of your development process?",
              "score": 1,
              "created_utc": "2026-02-10 03:04:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4wl2vr",
              "author": "TJWrite",
              "text": "Damn bro! that last bullet point tho. Much respect ğŸ«¡\n\nYO, OP, I donâ€™t know if you know this or not, but itâ€™s so underrated. Google â€œLangChain Academyâ€, login with whatever. You will find more structured tutorials, videos, codes and so many instructions, regarding so many topics about LangChain/LangGraph in TS/Python. This is 10x better than their YouTube channel, trust me on this. Hope this helps ğŸ‘",
              "score": 1,
              "created_utc": "2026-02-12 01:18:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4feysl",
          "author": "llamacoded",
          "text": "Add observability early. Distributed tracing, evaluation on production traffic, cost tracking. We use [Maxim](https://getmax.im/Max1m) for this. Don't wait until production to add monitoring.",
          "score": 2,
          "created_utc": "2026-02-09 13:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dg38b",
          "author": "Rude_Extension_3788",
          "text": "Im working on applications that use langgraph rn. while none have hit production yet, ive never thought of a reason as to why id ever have to strip it out so im just curious as to why you think that would happen? Am i missing out on something myself? I'm fairly new to lang, only 3-4 months in but it seems pretty scalable out of the box.",
          "score": 1,
          "created_utc": "2026-02-09 03:30:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dgsrv",
              "author": "arbiter_rise",
              "text": "I should clarify that this isnâ€™t based on my own direct experience of stripping out LangGraph in production. Itâ€™s more something Iâ€™ve heard repeatedly from others who started with a framework and later chose to move away from it for various reasons (complexity, constraints, team familiarity, etc.), so I wanted to bring that perspective into the discussion.\n\nThanks for sharing your experience.",
              "score": 1,
              "created_utc": "2026-02-09 03:34:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4dhiaf",
                  "author": "Rude_Extension_3788",
                  "text": "Ahh well its a good thing I came across this post then, would love to hear about the experiences people have under heavy prod applications to see the shortcomings of the library.",
                  "score": 2,
                  "created_utc": "2026-02-09 03:38:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z7qky",
          "author": "ampancha",
          "text": "The framework question (keep LangChain or strip it) is secondary. What actually breaks in production is cost and safety: no per-user attribution, no token or tool-call caps, no allowlists on what tools can be invoked, and prompt injection treated like a prompt-tuning problem instead of an architectural risk. Worth doing early: hard spend limits with attribution, structured logs that tie every LLM call to a user and request ID, and circuit breakers so one bad chain doesn't cascade. Those survive regardless of whether LangChain stays or goes. Sent you a DM.",
          "score": 1,
          "created_utc": "2026-02-12 13:33:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1u6qk",
      "title": "activefence quietly rebranded to alice, anyone notice?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r1u6qk/activefence_quietly_rebranded_to_alice_anyone/",
      "author": "Aggravating_Log9704",
      "created_utc": "2026-02-11 10:47:58",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "just saw in some t&s newsletter that activefence the moderation company behind content filtering for a bunch of big platforms is now going by alice. happened back on Jan 14, 2026, new site is [alice.io](http://alice.io) and old one redirects.\n\nfrom what i can tell, its mostly a branding update as they shift more toward ai/genai safety stuff like guardrails for models, handling prompt attacks, that kind of thing while keeping the core ugc moderation side. apis and tools seem unchanged so far.\n\nanyone using them run into issues with the name change in tickets orsupport or is it just a logo refresh?\n\n(Their blog post:[ https://alice.io/blog/why-we-became-alice](https://alice.io/blog/why-we-became-alice))\n\nThoughts?",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LangChain/comments/1r1u6qk/activefence_quietly_rebranded_to_alice_anyone/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4s2ya1",
          "author": "Kitchen_West_3482",
          "text": "This seems like a strategic pivot rather than just a logo change. They are signaling a broader focus on AI and GenAI safety and prompt attack mitigation which aligns with the growing LangChain ecosystem. For anyone using their moderation APIs the main thing to watch is support continuity and naming in tickets. Operationally it is probably fine but the rebrand indicates they want to be perceived as a full spectrum AI safety company not just UGC moderators.",
          "score": 2,
          "created_utc": "2026-02-11 11:02:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r122yn",
      "title": "Dlovable  is an open-source, AI-powered web UI/UX",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/lwt5s1cjfoig1.png",
      "author": "LeadingFun1849",
      "created_utc": "2026-02-10 14:23:34",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r122yn/dlovable_is_an_opensource_aipowered_web_uiux/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qzxia4",
      "title": "Added Ollama support to MCPlexor â€“ now you can run it 100% locally (and free)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qzxia4/added_ollama_support_to_mcplexor_now_you_can_run/",
      "author": "Basic_Tea9680",
      "created_utc": "2026-02-09 07:04:55",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nLast week, I posted here aboutÂ [how preloading MCP tools was costing me \\~50k tokens per run](https://www.reddit.com/r/LangChain/comments/1qukgay/preloading_mcp_tools_cost_me_50k_tokens_per_run/). The TL;DR was that heavy MCP servers like Linear, GitHub, Figma etc. were eating 25% of my context window before I even asked a question.\n\nI built MCPlexor to solve this â€“ it dynamically routes to the right MCP server instead of dumping 100+ tool definitions into your agent's context.\n\n**What's new: Full Ollama Support**\n\nI kept getting asked: \"Can I run this locally without calling your API?\"\n\nShort answer: yes, now you can.\n\nIf you have Ollama running, MCPlexor can use it for the routing logic instead of our cloud. Zero cost, works offline, your data stays on localhost.\n\non localhost.\n\n    # Install\n    curl -fsSL https://mcplexor.com/install.sh | bash\n\nIn MCPlexor cli you can use your local Ollama instance (llama3, mistral, qwen, whatever you've got) to figure out which MCP server to route to.\n\n**How MCPlexor will eventually make money**\n\nFigured I'd be transparent since I'm indie-hacking this:\n\nFor local/low-volume users â†’ Ollama is free. Use it if you have many mcps on for you agent. Seriously.\n\nFor high-volume / cloud users â†’ We run the routing on cheaper, efficient models (not Opus or Gemini Pro). We take a small cut from the savings we're passing on. Think of it as: you were gonna spend $X on context tokens anyway, we help you spend $X/10, and we take a slice of the difference.\n\nHaven't launched the paid tier yet (still in waitlist mode), but that's the game plan.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qzxia4/added_ollama_support_to_mcplexor_now_you_can_run/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4ehxsc",
          "author": "EcstaticAd9869",
          "text": "Oh that's interesting",
          "score": 1,
          "created_utc": "2026-02-09 08:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4emcyt",
              "author": "Basic_Tea9680",
              "text": "![gif](giphy|LXsmHIeoWM16d3w2Ju)",
              "score": 2,
              "created_utc": "2026-02-09 09:14:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4epkri",
                  "author": "EcstaticAd9869",
                  "text": "![gif](giphy|CbSGut2wzWKZy)",
                  "score": 1,
                  "created_utc": "2026-02-09 09:46:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0bvuj",
      "title": "anyone can explain what are these divisions in langsmith logs?",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/2bgvt3i8giig1.png",
      "author": "Any_Animator4546",
      "created_utc": "2026-02-09 18:18:21",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1r0bvuj/anyone_can_explain_what_are_these_divisions_in/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4lkru6",
          "author": "Shl0ng88",
          "text": "I use Langfuse tho I see (almost) the same output. I admit it does look redundant lol and the nesting order is confusing.\n\nThe first node is the ReAct `agent` node, It gets created whenever the agent is called.  \nIt triggers `call_model`, which initiates the model invocation pipeline with the provided input, inside we have:\n\n* `Prompt` node is responsible for formatting the input to be ready for the..\n* `ChatGoogleGeneration` node where the actual model invocation happens.\n\nOnce the model finishes, if the response includes tool calls, a `tools` node is created. It appears outside the parent agent node in the graph view, but if you switch to timeline view you can see itâ€™s created immediately after the Gemini call completes.\n\nFinally, the `should_continue` node decides what to do next; If a tool call was present in the previous model output, it returns the tool name and arguments; otherwise, it returns `_end_` to signal the end of the graph\n\nEdit: I wrote my initial comment based on my langfuse output, but after further inspection I realised it's not fully the same",
          "score": 1,
          "created_utc": "2026-02-10 11:43:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2mdz1",
      "title": "Detecting infinite loops in LangGraph multi-agent systems (before tokens explode)",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/5orp23uxe0jg1.png",
      "author": "Responsible-Peach503",
      "created_utc": "2026-02-12 06:42:47",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r2mdz1/detecting_infinite_loops_in_langgraph_multiagent/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4yt71l",
          "author": "SharpRule4025",
          "text": "The loop pattern you're describing usually starts with bad data coming back from the web_search tool. The research agent gets partial or garbage HTML, passes it to analysis, analysis says insufficient data, and research goes back to search again with slightly different params. Rinse repeat.\n\nFixing it at the detection layer works but the cleaner solution is making the data step reliable. If web_search consistently returns clean structured content instead of raw HTML soup, the analysis agent has enough signal to move forward on the first pass. Most of the loops I've debugged trace back to the agent retrying because the input data was technically there but unusable.",
          "score": 3,
          "created_utc": "2026-02-12 11:55:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yttcz",
              "author": "Responsible-Peach503",
              "text": "Youâ€™re absolutely right , a lot of coordination loops do originate from poor tool output.\n\nIf web\\_search returns messy or partially structured data, analysis often says thereâ€™s not enough signal, and research just tries again with slightly tweaked params. That definitely creates retry loops. In those cases improving the data layer can solve the root issue.\n\nWhat Iâ€™m trying to look at here is a slightly different class of loops. Iâ€™ve seen systems loop even when the data is clean, just because thereâ€™s no clear â€œdoneâ€ condition, or agents keep optimizing instead of converging, or the planner state doesnâ€™t reflect real progress. Sometimes two agents just implicitly disagree on whether the task is complete.\n\nSo I see Watchtower more as a runtime guardrail than a fix for bad tools. It doesnâ€™t replace improving data quality, but it can surface pathological behavior early, regardless of the cause.\n\nOut of curiosity, in your experience were most loops purely data-quality issues, or did you also see coordination-level ones?",
              "score": 1,
              "created_utc": "2026-02-12 12:00:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xw3cb",
          "author": "Responsible-Peach503",
          "text": "Repo: [github.com/yairsabag/watchtower](http://github.com/yairsabag/watchtower) â€” clone, run python -m demo.loop\\_demo, takes 30 seconds. Happy to hear feedback.",
          "score": 1,
          "created_utc": "2026-02-12 06:45:48",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5254ic",
          "author": "SystemFlowStudio",
          "text": "In LangGraph specifically, loops usually show up as repeated node traversals with no net state change.\n\nTwo practical techniques:  \nâ€¢ hash the serialized graph state at each step and abort on repeats  \nâ€¢ enforce monotonic progress (a value that must strictly decrease or converge)\n\nAlso worth separating â€œretryâ€ edges from normal edges â€” when retries are implicit, loops are invisible until the bill shows up.",
          "score": 1,
          "created_utc": "2026-02-12 22:02:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1apvk",
      "title": "memv â€” open-source memory for AI agents that only stores what it failed to predict",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r1apvk/memv_opensource_memory_for_ai_agents_that_only/",
      "author": "brgsk",
      "created_utc": "2026-02-10 19:36:47",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "I built an open-source memory system for AI agents with a different approach to knowledge extraction.\n\nThe problem: Most memory systems extract every fact from conversations and rely on retrieval to sort out what matters. This leads to noisy knowledge bases full of redundant information.\n\nThe approach: memv uses predict-calibrate extraction (based on the [https://arxiv.org/abs/2508.03341](https://arxiv.org/abs/2508.03341)). Before extracting knowledge from a new conversation, it predicts what the episode should contain given existing knowledge. Only facts that were unpredicted â€” the prediction errors â€” get stored. Importance emerges from surprise, not upfront LLM scoring.\n\nOther things worth mentioning:\n\n* Bi-temporal model â€” every fact tracks both when it was true in the world (event time) and when you learned it (transaction time). You can query \"what did we know about this user in January?\"\n* Hybrid retrieval â€” vector similarity (sqlite-vec) + BM25 text search (FTS5), fused via Reciprocal Rank Fusion\n* Contradiction handling â€” new facts automatically invalidate conflicting old ones, but full history is preserved\n* SQLite default â€” zero external dependencies, no Postgres/Redis/Pinecone needed\n* Framework agnostic â€” works with LangGraph, CrewAI, AutoGen, LlamaIndex, or plain Python\n\n\n```python\n    from memv import Memory\n    from memv.embeddings import OpenAIEmbedAdapter\n    from memv.llm import PydanticAIAdapter\n    \n    memory = Memory(\n        db_path=\"memory.db\",\n        embedding_client=OpenAIEmbedAdapter(),\n        llm_client=PydanticAIAdapter(\"openai:gpt-4o-mini\"),\n    )\n    \n    async with memory:\n        await memory.add_exchange(\n            user_id=\"user-123\",\n            user_message=\"I just started at Anthropic as a researcher.\",\n            assistant_message=\"Congrats! What's your focus area?\",\n        )\n        await memory.process(\"user-123\")\n        result = await memory.retrieve(\"What does the user do?\", user_id=\"user-123\")\n```\n\nMIT licensed. Python 3.13+. Async everywhere.  \n\\- GitHub: [https://github.com/vstorm-co/memv](https://github.com/vstorm-co/memv)  \n\\- Docs: [https://vstorm-co.github.io/memv/](https://vstorm-co.github.io/memv/)  \n\\- PyPI: [https://pypi.org/project/memvee/](https://pypi.org/project/memvee/)\n\nEarly stage (v0.1.0). Feedback welcome â€” especially on the extraction approach and what integrations would be useful.",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1r1apvk/memv_opensource_memory_for_ai_agents_that_only/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qyw82q",
      "title": "Plano reaches 5K+ GH Stars!",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/1fhvvcamg6ig1.png",
      "author": "AdditionalWeb107",
      "created_utc": "2026-02-08 01:58:44",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.69,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1qyw82q/plano_reaches_5k_gh_stars/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r0yxzo",
      "title": "How do you persist agent state & resume conversations in a multi-agent system when moving from CLI to UI/API?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r0yxzo/how_do_you_persist_agent_state_resume/",
      "author": "Familiar-Gur9501",
      "created_utc": "2026-02-10 12:04:37",
      "score": 5,
      "num_comments": 11,
      "upvote_ratio": 0.86,
      "text": "Sorry if this is basic â€” Iâ€™m relatively new toÂ *agents*. Until now Iâ€™ve mostly builtÂ **RAG systems**, so please feel free to correct me if Iâ€™m thinking about this the wrong way.\n\nIâ€™m building aÂ **multi-agent system**Â with \\~3â€“4 agents:\n\n* OneÂ **RAG agent**\n* OneÂ **vision agent**\n* OneÂ **action agent**Â (e.g., updating a DB)\n* One or more agents thatÂ **require human confirmation**Â before proceeding (e.g., â€œAre you sure you want to update this record?â€)\n\n# What works today\n\nWhen I run everything in aÂ **Python terminal**, this feels straightforward:\n\n* I can maintain state in memory\n* Pause execution for human input\n* Resume from the same agent/node once the user responds\n\n# The problem\n\nThings get tricky once I move this to aÂ **UI + API setup**.\n\nIn the UI:\n\n* Every user message hits theÂ **API**\n* The API always invokes theÂ **delegator/orchestrator agent**\n* From the APIâ€™s point of view, each request looks â€œnewâ€\n\nSo my question is:\n\n>\n\n# Specific questions Iâ€™m struggling with\n\n1. **Where should agent context/state live?**\n   * In-memory store (not scalable)?\n   * Database (Redis / Postgres / vector DB)?\n   * Framework-managed checkpointing?\n2. **What exactly should I persist?**\n   * Full conversation history?\n   * AgentState (current agent, step, tool calls)?\n   * Partial graph execution state?\n3. **How do people usually handle human-in-the-loop steps?**\n   * Do you block the workflow?\n   * Store a â€œpending confirmationâ€ state and resume later?\n   * Use some kind of event-driven approach?\n4. **Is this typically solved at the framework level or application level?**\n   * Should the orchestrator be stateless and rely entirely on stored state?\n   * Or should agents manage their own resumable state?\n\nIf youâ€™ve built multi-agent systems behind an API/UI, Iâ€™d love to hear:\n\n* How you modeled state\n* What you persisted\n* Any architectural gotchas you ran into\n\nThanks in advance â€” and sorry again if this is something obvious  \nHappy to learn.\n\nps : using python, langgraph , langgraph and fastapi for now",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1r0yxzo/how_do_you_persist_agent_state_resume/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o4lqyzy",
          "author": "Atsoc1993",
          "text": "Set the `use_responses_api` flag to *True* on the model to toggle conversation IDâ€™s â€” as for persistent state, you define your own object with whatever states you want (eg; iterations, last message, approved), and when you instantiate an AgentGraph, pass that into it (eg; `AgentGraph(MyState)`). Lastly, of course, utilize these states in your node/edge functions, and always return the new state.\n\nEdit: Also, the last 4 digits in your username are the last 4 digits in my phone number\n\nEdit edit: I kind of glazed over your post, seems some of this information you may already know since you have some working implementation already active; but you would basically use the conversation IDâ€™s as checkpoints if you want to resume a previous agentic workflow from some point in the flow, I havenâ€™t actually ever tried that yet but I assume that you would store them in a method of your preference â€” sqlite, json, whatever.",
          "score": 2,
          "created_utc": "2026-02-10 12:29:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r6d7u",
              "author": "Familiar-Gur9501",
              "text": "sure i will try this, thankyou ",
              "score": 2,
              "created_utc": "2026-02-11 06:03:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o50u5qg",
                  "author": "meridian_dan123",
                  "text": "Blocking the workflow for human confirmation can be cumbersome; consider storing a \"pending confirmation\" state instead. This way, you can keep the flow going and just resume once the user responds. It makes the system feel more responsive!",
                  "score": 1,
                  "created_utc": "2026-02-12 18:18:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4lvpv0",
          "author": "ArmOk3290",
          "text": "I ran into this building something similar. Ended up using SQLite for dev and Postgres for prod, serializing the full graph state plus convo history. For human-in-loop, I block on a 'pending' status in state and poll for approval via websocket. Works pretty reliably now.",
          "score": 2,
          "created_utc": "2026-02-10 13:00:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r6k1h",
              "author": "Familiar-Gur9501",
              "text": "ok, i have to explore a little bit more on this topic - will try to implement",
              "score": 1,
              "created_utc": "2026-02-11 06:04:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4me6bn",
          "author": "code_vlogger2003",
          "text": "Hey instead of using the original orchestrator why can't you treat the agents as a tool and wrap them in a react pattern. So let's say if there is a tool called 'sql_tool' in Ai message then the next message is obviously a tool message. Using the post processing for introducing the human in the loop for getting the actions as accept or reject or modify etc then based on the tool needs to be executed in the sandbox. So let's say if we use the websocket then from the frontend we can get that hitl string etc. so in the db we store complete one state message entire dictionary which has human message, collection of ai messages and tool messages final structured response if we enforce any structure output",
          "score": 2,
          "created_utc": "2026-02-10 14:43:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r6ynr",
              "author": "Familiar-Gur9501",
              "text": "sure will try",
              "score": 1,
              "created_utc": "2026-02-11 06:08:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m1n6h",
          "author": "fasti-au",
          "text": "Iâ€™m at 30 agents active mate. Thi g waves and where as sources not the object.",
          "score": 0,
          "created_utc": "2026-02-10 13:36:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}