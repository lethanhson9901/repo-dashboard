{
  "metadata": {
    "last_updated": "2026-01-29 02:49:02",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 55,
    "file_size_bytes": 99782
  },
  "items": [
    {
      "id": "1qmpjef",
      "title": "Do actual AI practitioners find the Clawdbot hype realistic?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qmpjef/do_actual_ai_practitioners_find_the_clawdbot_hype/",
      "author": "julsezerus",
      "created_utc": "2026-01-25 17:34:28",
      "score": 88,
      "num_comments": 38,
      "upvote_ratio": 0.95,
      "text": "I’m curious what people who actually work with AI think about the Clawdbot hype. \n\nHere’s my take:\n\nThe capabilities Clawdbot demonstrates aren’t particularly difficult to achieve technically - we can already make LLMs do most of what it’s doing. The real challenge has always been implementing proper security procedures and guardrails, not the core functionality itself.\n\nFrom what I can tell, Clawdbot is essentially burning through massive amounts of LLM tokens to accomplish certain tasks without much concern for security protocols. \n\nThat’s… not exactly groundbreaking? It’s more like “look what happens when you remove the safety rails and throw credits at it.”\n\nMaybe I’m missing something, but this doesn’t feel like the revolution people are making it out to be. It feels more like a demo of “what if we just didn’t worry about the hard parts?”\n\nWhat do people actually working in this space think? Am I being too cynical here, or is this hype as overblown as it seems?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmpjef/do_actual_ai_practitioners_find_the_clawdbot_hype/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1nm307",
          "author": "ImaginaryRea1ity",
          "text": "Saw the YT video of the guy hyping it up but I think all the marketing is paid.",
          "score": 15,
          "created_utc": "2026-01-25 17:43:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o94n7",
              "author": "gastro_psychic",
              "text": "Who is making money?",
              "score": 2,
              "created_utc": "2026-01-25 19:19:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p175w",
                  "author": "LiveBeyondNow",
                  "text": "The creator and the suppliers, Anthropic, YT etc",
                  "score": 2,
                  "created_utc": "2026-01-25 21:22:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1pl3v6",
          "author": "Hackerjurassicpark",
          "text": "More hype. Most likely paid marketing.",
          "score": 5,
          "created_utc": "2026-01-25 22:50:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qv0do",
              "author": "mediaempire45",
              "text": "Mranwhile the creator of the clawdbot is saying on X that nobody is checking out his \"sponsor\" link",
              "score": 2,
              "created_utc": "2026-01-26 02:35:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1rci5q",
                  "author": "Hackerjurassicpark",
                  "text": "They’re playing the long game… hyping up and creating massive visibility to add more users, the use those impressive user growth to justify a 1B valuation in their next seed round",
                  "score": 1,
                  "created_utc": "2026-01-26 04:13:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1r9f36",
          "author": "Proof-Sand-7157",
          "text": "What Clawdbot does is essentially the same as **Copilot/Cowork-style agents connected to channels like WhatsApp or Slack**.\n\nThere’s no particularly complex capability involved.  \nIt mainly feels impressive because **it’s open source**, so everything is visible and reproducible.",
          "score": 4,
          "created_utc": "2026-01-26 03:54:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wfsgw",
              "author": "laslog",
              "text": "And, unlike Copilot, it works.",
              "score": 3,
              "created_utc": "2026-01-26 21:48:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1r9wka",
          "author": "Zatkoma",
          "text": "Hype, let them some time to prove that is make sense... :)",
          "score": 2,
          "created_utc": "2026-01-26 03:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1tacxy",
          "author": "Educational_Bag_4003",
          "text": "Don't think the founder is out to make money. Look at all of his recent dev work and look at his background [https://github.com/steipete](https://github.com/steipete) Really don't think it is paid marketing pushing this...",
          "score": 2,
          "created_utc": "2026-01-26 13:19:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1vleje",
              "author": "auskadi",
              "text": "It's a great little tool. Lots of people here seem to be taking through their ...",
              "score": 2,
              "created_utc": "2026-01-26 19:34:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2bosay",
              "author": "Street_Profile_8998",
              "text": "It is literally paid marketing. It says as much on the sponsored posts that endlessly run on my linked in feed",
              "score": 1,
              "created_utc": "2026-01-29 00:48:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vxvzq",
          "author": "Significant-Sweet-53",
          "text": "https://preview.redd.it/tl5mnc7u6rfg1.jpeg?width=945&format=pjpg&auto=webp&s=eda45bcd2bf6a97b9844cee99223ccd2d2c9ce4b\n\nI just made a trimmed down version of this bot that uses Deepseek or Ollama, less noise and you can add your own skills easily, Ive added gog cli to test, controlling Google workspace from WhatsApp",
          "score": 2,
          "created_utc": "2026-01-26 20:29:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1w8mu9",
              "author": "Kubuli",
              "text": "Can you share your methods, results, limitations and suggestions?",
              "score": 1,
              "created_utc": "2026-01-26 21:17:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1w1j1w",
          "author": "Lonely-Elephant2130",
          "text": "Honestly spent an afternoon trying to set up ClawdBot and gave up - I'm not technical and the Mac Mini + local setup was way over my head. But I do love the idea of bringing AI into messaging apps. Been using something similar called Super Intern （https://www.superintern.ai/） lately - same concept of AI in your chat, but way simpler to get started. Just works in browser/Slack, no setup needed. Maybe I'm just not the target user for ClawdBot, but feels like there's a gap between \"impressive tech\" and \"actually usable for non-tech people.",
          "score": 1,
          "created_utc": "2026-01-26 20:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z6ksy",
          "author": "damanamathos",
          "text": "I created an AI Personal Assistant over Christmas and it's amazing — one of the best things I've created. I haven't used Clawdbot but have seen a bit, and did download the repo and get my AI PA to assess it vs what I already do, and it seemed pretty similar but probably a downgrade for me. So if you're not using any kind of AI assistant, it's probably worth checking out.",
          "score": 1,
          "created_utc": "2026-01-27 07:22:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1z6vji",
              "author": "damanamathos",
              "text": "I should add that my \"assistant\" isn't even that complicated. It's just Claude Code or OpenCode will a decent AGENTS file and specialised skills combined with custom-made CLI commands that let it access all my services so it can search and read email, create drafts, create images, etc from command line tools.",
              "score": 1,
              "created_utc": "2026-01-27 07:24:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o20t0q9",
          "author": "AccountEffective369",
          "text": "I haven't checked it out but that's why people are not looking to hire AI driven employees they still looking for individuals who knows processes comprehensively. Good Knowledge before trying the application itself.",
          "score": 1,
          "created_utc": "2026-01-27 14:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21p92q",
          "author": "Classic-Log-162",
          "text": "Completely useless and unsafe.",
          "score": 1,
          "created_utc": "2026-01-27 17:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o4z7a",
          "author": "Not_a_doxxtor",
          "text": "We've had these Jarvis things for a while now\n\nSomeone paid for advertising",
          "score": 1,
          "created_utc": "2026-01-25 19:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1pb1md",
          "author": "cqzero",
          "text": "Does it even work on Windows? I saw just MacOS/iOS/Android. Not interested unless it's Windows (or even Linux)",
          "score": 1,
          "created_utc": "2026-01-25 22:05:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1sfm4t",
              "author": "4rtdud3",
              "text": "Just got it up and running under WSL (Ubuntu) on Win 11.",
              "score": 1,
              "created_utc": "2026-01-26 09:16:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o25mk7x",
              "author": "dmees",
              "text": "Yes but you should join the hype and buy a Mac Mini!",
              "score": 1,
              "created_utc": "2026-01-28 04:21:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1qezr6",
              "author": "almeidamarcell",
              "text": "are you 12?!",
              "score": -1,
              "created_utc": "2026-01-26 01:13:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1sfkan",
                  "author": "Sore6",
                  "text": "are you?",
                  "score": 0,
                  "created_utc": "2026-01-26 09:16:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1qnodi",
              "author": "PositiveShallot7191",
              "text": "lol its self hosted its not running on phones",
              "score": 0,
              "created_utc": "2026-01-26 01:58:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1uhk9w",
          "author": "Significant-Sweet-53",
          "text": "Paid-first assumptions",
          "score": 1,
          "created_utc": "2026-01-26 16:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nn0th",
          "author": "AykutSek",
          "text": "You’re not being cynical; you’re being realistic. Clawdbot feels like a high-speed car with no brakes. It’s exciting to watch until it hits a wall of security protocols or a massive API bill. The real breakthrough won't be 'doing things,' it will be doing things safely and efficiently within the chaos of real-world data.",
          "score": 1,
          "created_utc": "2026-01-25 17:47:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nndhy",
          "author": "Resident_Green8814",
          "text": "Spot on. From a GTM and product perspective, the 'revolution' here isn't technical brilliance, but the removal of friction by ignoring guardrails. Scaling an AI agent in an enterprise environment requires solving the 'hard parts' you mentioned: security, token efficiency, and reliability. Clawdbot is a great demo of potential, but a nightmare for risk management. We need sustainable innovation, not just credit-burning experiments.",
          "score": 0,
          "created_utc": "2026-01-25 17:49:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpci1h",
      "title": "You can now train embedding models ~2x faster!",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/kbenz74xl3gg1.png",
      "author": "yoracale",
      "created_utc": "2026-01-28 14:15:31",
      "score": 31,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qpci1h/you_can_now_train_embedding_models_2x_faster/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qpi07h",
      "title": "I built a job search assistant to understand LangChain Deep Agents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qpi07h",
      "author": "Acrobatic-Pay-279",
      "created_utc": "2026-01-28 17:34:30",
      "score": 21,
      "num_comments": 1,
      "upvote_ratio": 0.77,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qpi07h/i_built_a_job_search_assistant_to_understand/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2bvl13",
          "author": "qa_anaaq",
          "text": "Cool and thanks for sharing. 2 Qs. Do you feel the deep agents harness is any good, and how’s the cost of running it?",
          "score": 1,
          "created_utc": "2026-01-29 01:26:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qmhxxi",
      "title": "Quantifying Hallucinations: By calculating a multi-dimensional 'Trust Score' for LLM outputs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qmhxxi",
      "author": "Charming_Group_2950",
      "created_utc": "2026-01-25 12:33:20",
      "score": 20,
      "num_comments": 0,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmhxxi/quantifying_hallucinations_by_calculating_a/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qk2cv0",
      "title": "Could this architectural shift finally solve the \"Agent Reliability\" problem?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "author": "sophieximc",
      "created_utc": "2026-01-22 18:24:39",
      "score": 17,
      "num_comments": 7,
      "upvote_ratio": 0.84,
      "text": "As LangChain devs, we spend half our time writing OutputParsers, retry logic, and guardrails because LLMs are fundamentally probabilistic - they don't \"know\" they broke a constraint, they just guessed a token.\n\nI’ve been reading up on the new wave of [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models) (backed by LeCun), and the implication for Agents is huge.\n\nUnlike Transformers that generate text left-to-right (and often paint themselves into a corner), an EBM minimizes an \"energy function\" at inference time. It basically verifies if the output meets the constraints (like \"Must be valid JSON\" or \"Must not contradict previous step\") before returning the result.\n\nIf this works at scale, we might finally get agents that can handle complex multi-step logic without needing a dozen error-handling loops.\n\nCurious if anyone sees this replacing the current RAG/Chain-of-Thought meta for strict logic tasks?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o13k2t9",
          "author": "Better_Dress_8508",
          "text": "I'm afraid you are extrapolating too far. EBM-s are not deterministic either",
          "score": 2,
          "created_utc": "2026-01-22 19:06:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13olgo",
              "author": "sophieximc",
              "text": "They are still probabilistic - you're sampling from a distribution, not running a script.  \n  \nBut the inference dynamic is different. Instead of just rolling the dice once per token (autoregressive), you're iteratively refining the output to lower the energy. It’s less about being deterministic and more about having a native mechanism to \"reject\" nonsense before finalizing the output.",
              "score": 0,
              "created_utc": "2026-01-22 19:26:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o14a1vs",
          "author": "met0xff",
          "text": "You can use constrained generation using something like xgrammar or outlines for the json problem",
          "score": 1,
          "created_utc": "2026-01-22 21:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15hrda",
          "author": "USToffee",
          "text": "It's how I'm writing my agent. It basically has a semantic binding step at the start that determines what kind of artifacts it expects and only gives an answer if the tool calls satisfy this. At this point I'm not sure if it's any better or not. It still requires the LLM to guess what artifacts are needed from the prompt.",
          "score": 1,
          "created_utc": "2026-01-23 00:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bhy3m",
          "author": "pbalIII",
          "text": "So the real question is whether the inference-time optimization loop scales without blowing up latency. Logical Intelligence just announced Kona 1.0 with LeCun on the board, and their pitch is exactly this... learning by correcting mistakes rather than guessing tokens.\n\nThe catch is EBTs need to be trained from scratch. You can't fine-tune an existing foundation model into one. That's a brutal cold start when every team already has GPT-4 wrappers in production.\n\nFor strict JSON, constrained decoding (xgrammar, outlines) already solves it deterministically without the architecture swap. The interesting unlock would be multi-step logical consistency across tool calls, where autoregressive models keep painting themselves into corners. Still waiting to see benchmarks on that before swapping out the retry loops.",
          "score": 1,
          "created_utc": "2026-01-23 22:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13hgo0",
          "author": "Educational-Bison786",
          "text": "EBMs are definitely an interesting shift for agent reliability. While they might reduce some issues, I doubt they'll fully replace the need for robust evaluation and guardrails. You'll still want tools like Pydantic for strict schema validation. For comprehensive agent quality and measuring improvements, platforms like [Maxim AI](https://www.getmaxim.ai/) are crucial. Also don't forget solid prompt engineering.",
          "score": 0,
          "created_utc": "2026-01-22 18:54:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13od1f",
              "author": "sophieximc",
              "text": "Agreed, validation (like Pydantic) isn't going anywhere. But right now, we use guardrails to catch errors after they happen (and then trigger expensive retries). The promise of EBMs is that the model wouldn't generate the error in the first place because it contradicts the \"energy\" state. I want validation to be a safety net, not the main control loop",
              "score": 1,
              "created_utc": "2026-01-22 19:25:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjm96c",
      "title": "Multi-agents breakthrough",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "author": "crionuke",
      "created_utc": "2026-01-22 05:41:20",
      "score": 16,
      "num_comments": 11,
      "upvote_ratio": 0.83,
      "text": "ChatGPT and similar models have become universal tools, which is why they so quickly entered the daily lives of millions of people. We use them to search for information, work with text, learn new topics, and hold discussions.  \n  \nHowever, chats themselves are not agents. They cannot operate in the real or digital world: they do not make decisions, execute chains of tasks, interact with services, or carry work through to completion.  \n  \nFor this reason, companies have begun building their own agent and multi-agent systems. These systems help users apply for loans, buy tickets, plan vacations, or complete paperwork.  \n  \nBut almost all such solutions remain narrowly specialized. Each agent is tightly bound to predefined scenarios and cannot go beyond the logic embedded by its creators.  \n  \nBecause of this, the next major technological breakthrough will likely be the emergence of universal agent systems accessible to ordinary users.  \n  \nExternally, they may look almost the same: a familiar chat interface with a bot. Internally, however, they will represent complex self-organizing systems composed of many agents, capable of understanding user goals, autonomously building plans, selecting tools, and adapting to changing conditions.  \n  \nIn essence, this marks a transition from “answering prompts” to digital assistants that can act — and may even possess their own form of intent within the boundaries of achieving the user’s goals, rather than merely reacting to commands.  \n  \nGiven the current pace of development in large language models and agent frameworks, it is entirely possible that the first truly universal multi-agent systems will appear by the end of 2026.\n\n  \n**What are your thoughts on the next breakthrough in our field?**",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o103070",
          "author": "ChanceKale7861",
          "text": "Yep! I’m about to go FOSS with a 20 agent system of rust and python agents so we power users aren’t bound to API bullshit.",
          "score": 3,
          "created_utc": "2026-01-22 06:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10vgpt",
              "author": "crionuke",
              "text": "Interesting,\n\nis there anything you can share that we can already play with?",
              "score": 2,
              "created_utc": "2026-01-22 10:32:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12akg1",
                  "author": "ChanceKale7861",
                  "text": "I actually just finished that up yesterday, and myself along with 10-15 folks across business, SWE, enterprise architecture, etc. lots of folks I know have been working on projects, so, rolling to them first, and then if they are happy with where it’s at, I’m going to launch the website, and the tool. so, yes, but maybe in a week or two? need to ensure the things like file intake and generation work as designed, as well as whether the aspects like security and auditor agents orchestrate as designed and tested so far. Or like, for the folks I know in like recruiting, or sales, does it truly automate an aspects for them, like it has me. Which is where this stemmed from a couple weeks back.",
                  "score": 2,
                  "created_utc": "2026-01-22 15:42:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11a1mg",
          "author": "Number4extraDip",
          "text": "You misunderstand agents and infrastructure. There is no such thing as disembodied ai. Agents have specific architecture and defining components.\n\nYou wanna ground ai? Ground them in realtime data and telemetry\n\n[all ai is robotics](https://youtube.com/shorts/wTY2mY3XF1Y?si=QpiqBlUIK3WqNzNu)\n\nAnd multi agent systems are not complex if you think about it\n\n[heres a plug and play one copy pasta](https://github.com/vNeeL-code/ASI)",
          "score": 3,
          "created_utc": "2026-01-22 12:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10vs73",
          "author": "fabkosta",
          "text": "All of this is not new, the fantasies about such systems have been there 25 years ago. Just go pick up any book or article on muli-agent-systems from the early 2000s. What has changed today that, suddenly and miraculously, such systems can become true, although they could not 25 years ago? LLMs? GenAI? That's not enough, a lot more is required - and we did not solve the issues 25 years ago with other technology neither.\n\nIt's wild to see that nobody seems to want to learn anything from history.",
          "score": 2,
          "created_utc": "2026-01-22 10:35:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13h9cw",
          "author": "Aggressive_Bed7113",
          "text": "This post can be much shorter with only the last paragraph or last sentence.\n\nThis title made me think op will present some real breakthroughs, but it turns out the person has no idea either. Duh\n\nWhy do I want a universal agent that does mediocre stuffs in everything than a specialized agent in things I only care about?!",
          "score": 1,
          "created_utc": "2026-01-22 18:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13hrlg",
              "author": "crionuke",
              "text": "Nobody has",
              "score": 1,
              "created_utc": "2026-01-22 18:55:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o13i4l5",
                  "author": "Aggressive_Bed7113",
                  "text": "Then what’s the point of posting this?",
                  "score": 1,
                  "created_utc": "2026-01-22 18:57:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ahysn",
          "author": "LairBob",
          "text": "This is just ill-informed rambling.",
          "score": 1,
          "created_utc": "2026-01-23 19:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10u9do",
          "author": "PopPsychological4106",
          "text": "Wdym by \"truly universal\"?",
          "score": 0,
          "created_utc": "2026-01-22 10:21:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10v7xi",
              "author": "crionuke",
              "text": "I don’t have a one word term for this, but imagine systems capable of generating agent skills on the fly to handle a user request, even if those skills don’t exist beforehand, and refining them through a trial-and-error loop: develop → test → improve → … → use for the user’s task.",
              "score": 1,
              "created_utc": "2026-01-22 10:30:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qnqln9",
      "title": "A practical open-source repo for learning AI agents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qnqln9/a_practical_opensource_repo_for_learning_ai_agents/",
      "author": "Creepy-Row970",
      "created_utc": "2026-01-26 19:43:49",
      "score": 16,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "A practical open-source repo for learning AI agents. I’ve contributed 10+ examples\n\nI’ve contributed 10+ agent examples to an open-source repo that’s grown into a solid reference for building AI agents.\n\nRepo:[ https://github.com/Arindam200/awesome-ai-apps](https://github.com/Arindam200/awesome-ai-apps)\n\nWhat makes it useful:\n\n* 70+ runnable agent projects, not toy demos\n* Same ideas built across different frameworks\n* Covers starter agents, MCP, memory, RAG, and multi-stage workflows\n\nFrameworks include LangChain, LangGraph, LlamaIndex, CrewAI, Agno, Google ADK, OpenAI Agents SDK, AWS Strands, and PydanticAI.\n\nSharing in case others here prefer learning agents by reading real code instead of theory.\n\n",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qnqln9/a_practical_opensource_repo_for_learning_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1vok23",
          "author": "Pristine_Shelter_28",
          "text": "are these live apps?",
          "score": 1,
          "created_utc": "2026-01-26 19:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o246fka",
          "author": "YUYbox",
          "text": "Hi, \n  I built a tool for anyone running multi-agent AI systems.\n When LLMs talk to each other, they develop patterns that are hard to audit - invented acronyms, lost context, meaning drift.\r\n\r\n   The solution: InsAIts monitors these communications and flags anomalies.\r\n\r\n```python\r\nfrom insa_its import insAItsMonitor\r\n\r\nmonitor = insAItsMonitor()  # Free tier, no key needed\r\nmonitor.register_agent(\"agent_1\", \"gpt-4\")\r\n\r\nresult = monitor.send_message(\r\n    text=\"The QFC needs recalibration on sector 7G\",\r\n    sender_id=\"agent_1\"\r\n)\r\n\r\nif result[\"anomalies\"]:\r\n    print(\"Warning:\", result[\"anomalies\"])\r\n```\r\n\r\n  Features:\r\n- Local processing (sentence-transformers)\r\n- LangChain & CrewAI integrations\r\n- Adaptive jargon dictionary\r\n- Zero cloud dependency for detection\r\n\r\nGitHub: https://github.com/Nomadu27/InsAIts\r\nPyPI: pip install insa-its",
          "score": 1,
          "created_utc": "2026-01-27 23:42:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk85pb",
      "title": "I built a system for generating and operating modular AI-enabled FastAPI apps after doing this for clients over and over",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qk85pb",
      "author": "Challseus",
      "created_utc": "2026-01-22 21:59:02",
      "score": 14,
      "num_comments": 0,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk85pb/i_built_a_system_for_generating_and_operating/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qo6uax",
      "title": "What It Actually Takes to Build a Context-Aware Multi-Agent AI System",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qo6uax/what_it_actually_takes_to_build_a_contextaware/",
      "author": "pretty_prit",
      "created_utc": "2026-01-27 07:05:33",
      "score": 13,
      "num_comments": 7,
      "upvote_ratio": 0.93,
      "text": "Designing a multi-agent system with memory raises a different set of problems than most demos show.  \n  \nThe diagram below shows a simple multi-agent architecture I built to explore that gap.  \n  \nInstead of agents talking to each other directly, everything goes through an orchestration layer that handles:  \n\\-intent routing  \n\\-shared user context  \n\\-memory retrieval and compaction  \n  \nWhile designing this, a set of product questions surfaced that you don’t see in most demos  \n\\-What belongs in long-term memory vs. short-term history?  \n\\-When do you summarize context, and what do you risk losing?  \n\\-How do you keep multiple agents consistent as context evolves?  \n  \nI wrote a detailed breakdown of this architecture, including routing strategy, memory design, and the trade-offs this approach introduces.  \n  \n[https://medium.com/towards-artificial-intelligence/how-i-built-a-context-aware-multi-agent-wellness-system-a3eacbc33fe4?sk=c37c88e2f74aa9e5c2b2d681292d26c2](https://medium.com/towards-artificial-intelligence/how-i-built-a-context-aware-multi-agent-wellness-system-a3eacbc33fe4?sk=c37c88e2f74aa9e5c2b2d681292d26c2)  \n  \nIf you’re a PM, founder, or student trying to move beyond one-off agent demos, this might be useful.\n\nhttps://preview.redd.it/mr1w53kmcufg1.png?width=1838&format=png&auto=webp&s=e36245c419d44c006fdd8e3ff006c060eb320489\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qo6uax/what_it_actually_takes_to_build_a_contextaware/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1zgezp",
          "author": "DaRandomStoner",
          "text": "This looks pretty well put together... Is there a github repo we could check out?",
          "score": 1,
          "created_utc": "2026-01-27 08:51:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1zusom",
              "author": "pretty_prit",
              "text": "Thank you. the github link is there at the end of the article but posting here again - [https://github.com/pritha21/llm\\_projects/tree/main/wellness\\_langchain\\_app](https://github.com/pritha21/llm_projects/tree/main/wellness_langchain_app)",
              "score": 1,
              "created_utc": "2026-01-27 11:01:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1zmbdv",
          "author": "sleepnow",
          "text": "Good effort, but there is nothing at all new or particularly unique about this approach. ",
          "score": 1,
          "created_utc": "2026-01-27 09:46:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20aayx",
              "author": "pretty_prit",
              "text": "Maybe. But I was just exploring this topic, so its new for me.",
              "score": 2,
              "created_utc": "2026-01-27 12:55:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o244gr7",
          "author": "YUYbox",
          "text": "Hi there, I think InsAIts could be very helpful in this matter. \nhttps://github.com/Nomadu27/InsAIts",
          "score": 1,
          "created_utc": "2026-01-27 23:32:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o260i4c",
              "author": "pretty_prit",
              "text": "Will check it out",
              "score": 2,
              "created_utc": "2026-01-28 05:55:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24l5lq",
          "author": "pbalIII",
          "text": "Context compaction is where most of these designs break down quietly. You summarize to save tokens, but summaries drop the specifics that matter six turns later... and you only find out when an agent makes a decision based on stale assumptions.\n\nOne pattern that's helped: treating memory writes as versioned facts rather than mutable state. Agents can reference which version they're working from, and conflicts surface explicitly instead of silently diverging.\n\nThe orchestration-layer-as-bottleneck tradeoff you're hitting is real. Centralizing routing keeps agents consistent, but it also means every context update round-trips through one chokepoint. Some teams split into private vs shared memory tiers to let agents work locally until they need to sync. Adds complexity, but scales better when you're past 3-4 agents.",
          "score": 0,
          "created_utc": "2026-01-28 00:57:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql3ufd",
      "title": "Langchain In production",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "author": "niklbj",
      "created_utc": "2026-01-23 21:39:55",
      "score": 12,
      "num_comments": 28,
      "upvote_ratio": 0.84,
      "text": "HI guys, i've realized a lot of us are using langchain or building agents in some of personal or official projects that are in prod. Wanted to start a discord server specific for those of us who are building AI and agent applications in prod to talk about any issues, suggestions, or advice.\n\nHere's the server: [https://discord.gg/qJVQgX2z](https://discord.gg/qJVQgX2z). Feel free to join!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1bh85l",
          "author": "HawkingsLovechild",
          "text": "Langchain is neither lightweight nor mature enough to be dependable in production in my experience. Works fine for POCs but I would reject any PR that attempts to add it to our stack.\n\nEdit: I just checked and installing langchain installed 32 packages, taking 20mb.\n\n  \nEdit2: OP has had half a dozen posts removed in the last month for spam promoting some B2B saas LLM nonsense across various subreddits . Go build a product people actually wanna use bro.",
          "score": 10,
          "created_utc": "2026-01-23 22:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1biayp",
              "author": "AdditionalWeb107",
              "text": "I am generally framework-averse. The tight coupling, lack of interoperability between other frameworks, and no clear separation of concerns makes we very weary. For example, I am not sure why I am left to my own devices to solve all the plumbing work vs. it being implemented via some standards-based infrastructure.\n\nEdit; Talking about decoupling and separating plumbing from business logic https://github.com/katanemo/plano",
              "score": 5,
              "created_utc": "2026-01-23 22:05:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bp64c",
                  "author": "HawkingsLovechild",
                  "text": "I don't think Langchain is a dead project or anything, I love the enthusiasm. But I wouldn't have used FFMPEG in 2004. Nor would I trust this open source project at this point in its lifecycle, especially when the core - the web APIs it basically wraps, could and do change on a dime.\n\n  \nNone of this applies if you're building personal projects, but if you have thousands of users paying you money, it's a different story.",
                  "score": 3,
                  "created_utc": "2026-01-23 22:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bi6hj",
              "author": "niklbj",
              "text": "Interesting, i've seen a ton of startups especially in the earlier days - series A and before building agents using langchain but that makes sense. What framework do you guys use?\n\nRegardless, just updated server to be framework agnostic! It's now just about building and scaling agents in production",
              "score": 2,
              "created_utc": "2026-01-23 22:05:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bjxcz",
                  "author": "HawkingsLovechild",
                  "text": "I am in a startup myself as the tech lead. We don't need LLM frameworks. We write code that calls the APIs. They already did the hard work. Everything Langchain does you can do yourself in a hilariously short amount of time, with more control, tailored to your business needs. \n\n  \nI don't mean to sound like a dick but I genuinely have no idea what Langchain is solving for people. What problem does your company have that you determined it was easier to use Langchain for?",
                  "score": 4,
                  "created_utc": "2026-01-23 22:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1fjbnf",
              "author": "pizzababa21",
              "text": "I dont understand why 20mb is a problem",
              "score": 2,
              "created_utc": "2026-01-24 14:36:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d7btv",
              "author": "cuba_guy",
              "text": "Pretty tight ship over there, our nodejs monorepo has 8gb of node_modules and goes to prod multiple times a day :)",
              "score": 1,
              "created_utc": "2026-01-24 03:44:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1imizm",
              "author": "BurritoBashr",
              "text": "my company uses LangChain/Graph in production with LangSmith. It's a popular artisan shopping site",
              "score": 1,
              "created_utc": "2026-01-24 23:12:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1opbut",
              "author": "cmndr_spanky",
              "text": "Report him then",
              "score": 1,
              "created_utc": "2026-01-25 20:31:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bi7ze",
              "author": "usernotfoundo",
              "text": "What's the alternative to it? Is it not dependable because further updates could lead to currently implemented features being deprecated?",
              "score": 1,
              "created_utc": "2026-01-23 22:05:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bj5bo",
                  "author": "HawkingsLovechild",
                  "text": "Using the API provided by the LLM developers and writing your own wrapping code around it. It's not particularly difficult - I maintain such a system for my company and it's a single python library with the SDKs in question and the requests library. I also get greater control and can respond to updates to say, openAI the day they're rolled out rather than waiting. \n\n  \nWhat features does langchain provide you that you can't write yourself? It's not a particularly complicated package.",
                  "score": 7,
                  "created_utc": "2026-01-23 22:09:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1dbiyl",
          "author": "code_vlogger2003",
          "text": "Hey hi guys,  i already shipped the react style multi agents in the production using the langchain and it's currently serving in the production. Ok high level the end product of the pipeline is a detailed report which contains text, images and tables etc based on unstructured raw time series data. For the control and monitoring I have debugged their call backs and written detailed functions for precise calculation that match with manual calculation. This monitoring helps us to understand the costs of the api and believe me that on average for one detailed report it takes around 0.15 $ which the report includes the multi model calls too.",
          "score": 2,
          "created_utc": "2026-01-24 04:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bdiv6",
          "author": "AdditionalWeb107",
          "text": "This is cool - shouldn't the Langchain guys host and moderate this type of discord themselves?",
          "score": 1,
          "created_utc": "2026-01-23 21:43:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bh18a",
              "author": "mdrxy",
              "text": "We have a community slack! https://www.langchain.com/join-community",
              "score": 3,
              "created_utc": "2026-01-23 21:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bi7fy",
                  "author": "niklbj",
                  "text": "that's sick!",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bdv1e",
              "author": "niklbj",
              "text": "totally open to them doing so if anybody from Langchain wants to help moderate it! didn't see something like this out there, so thought I'd create one and handle it for now",
              "score": 2,
              "created_utc": "2026-01-23 21:44:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bevvc",
                  "author": "AdditionalWeb107",
                  "text": "I use stock python - so this wouldn't be a great fit for me personally, but I see the value. Thanks for creating it OP",
                  "score": 2,
                  "created_utc": "2026-01-23 21:49:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1uiews",
          "author": "pbalIII",
          "text": "Timing matters more than framework choice here. The 45% never-make-it-to-production stat floating around matches what I've seen... teams build POCs with LangChain, then strip it out when the 32-package dependency graph starts slowing deploys and the abstractions get in the way of a custom memory or retry pattern.\n\nThe counter-argument is observability. LangSmith alone is worth more than person-months of custom tracing work, and switching LLM providers with a one-line change saves real time during vendor negotiations.\n\nMy heuristic: if you're calling one model with a straightforward RAG pipeline, raw SDK wins. If you're juggling 3+ providers, need async multi-agent coordination, or want prod tracing out of the box, LangChain still earns its keep. The middle ground is messy.",
          "score": 1,
          "created_utc": "2026-01-26 16:48:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bj5i5",
          "author": "peejay2",
          "text": "I fw agno",
          "score": 0,
          "created_utc": "2026-01-23 22:09:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qna46j",
      "title": "Best practice for managing LangGraph Postgres checkpoints for short-term memory in production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/",
      "author": "Major_Ad7865",
      "created_utc": "2026-01-26 08:05:35",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "’m building a memory system for a chatbot using **LangGraph**.  \nRight now I’m focusing on **short-term memory**, backed by **PostgresSaver**.\n\nEvery state transition is stored in the `checkpoints` table. As expected, each user interaction (graph invocation / LLM call) creates multiple checkpoints, so the checkpoint data in checkpoints table grows **linearly with usage**.\n\nIn a production setup, what’s the recommended strategy for managing this growth?\n\nSpecifically:\n\n* Is it best practice to **keep only the last N checkpoints per** thread\\_id  and delete older ones?\n* How do people balance **resume/recovery safety** vs **database growth** at scale?\n\nFor context:\n\n* I already use conversation summarization, so older messages aren’t required for context\n* Checkpoints are mainly needed for short-term recovery and state continuity, not long-term memory\n* LangGraph can **resume from the last checkpoint**\n\nCurious how others handle this in real production systems.\n\nAdditionally in postgres langgraph creates 4 tables regarding checkpoints : checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1v6nu7",
          "author": "TextHour2838",
          "text": "You’re already thinking about this the right way: treat checkpoints as operational logs, not permanent memory, and prune aggressively.\n\n\n\nMain point: keep only a small, rolling window per thread (last N or last T minutes/hours) and purge the rest with a background job.\n\n\n\nWhat’s worked for us:\n\n\\- Per-thread policy: e.g., keep last 10–20 checkpoints or last 24h, whichever is smaller.\n\n\\- Time-based GC: daily job that deletes old checkpoints/checkpoint\\_writes/checkpoint\\_blobs by thread\\_id + created\\_at, in batches to avoid locks.\n\n\\- Promotion: anything you might need long-term (audit, analytics, durable memory) gets promoted into a separate, slimmer schema / vector store before you delete.\n\n\\- Safety: pair this with idempotent tools and a compensating-action log so you can replay from business events if a resume fails, not from ancient checkpoints.\n\n\n\nOn the tooling side, I’ve mixed Supabase and RDS for this, and for chatbots in ecom I’ve tried Gorgias and Intercom; Zipchat sits in that space too but handles the short-term vs long-term memory split for you so you don’t babysit raw checkpoint tables.\n\n\n\nSo: rolling window + periodic GC + promote anything important out of the checkpoint tables before pruning.",
          "score": 1,
          "created_utc": "2026-01-26 18:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1uya4l",
          "author": "AdditionalWeb107",
          "text": "This should be native to some substrate via durable APIs. Doing this by hand feels like a great way to mess it  up and also distract you from building your agent.",
          "score": 0,
          "created_utc": "2026-01-26 17:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql1m38",
      "title": "Open Source Serverless RAG Pipeline (Lambda + Bedrock) with React Component",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "author": "HatmanStack",
      "created_utc": "2026-01-23 20:14:08",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I built a fully serverless RAG pipeline to avoid idle server costs and container management.\n\nRepo: [https://github.com/HatmanStack/RAGStack-Lambda](https://github.com/HatmanStack/RAGStack-Lambda)\n\nDemo: [https://dhrmkxyt1t9pb.cloudfront.net](https://dhrmkxyt1t9pb.cloudfront.net)\n\n(Login: [guest@hatstack.fun](mailto:guest@hatstack.fun) / Guest@123)\n\nBlog: [https://portfolio.hatstack.fun/read/post/RAGStack-Lambda](https://portfolio.hatstack.fun/read/post/RAGStack-Lambda)\n\nKey Features:\n\n* Frontend: Drop-in <ragstack-chat> web component (React 19).\n* Multimodal: Uses Amazon Nova to embed text, images, and videos.\n* Zero Idle Costs: Pure Lambda/Step Functions/DynamoDB architecture.\n* MCP Support: Connects directly to Claude Desktop and Cursor.\n* No Control Plane: All resources deployed in your AWS Account.\n\nDeployment is one-click via CloudFormation. Feedback welcome.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkknp3",
      "title": "what are some suggestions you have on minimizing silent failures with langchain?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkknp3/what_are_some_suggestions_you_have_on_minimizing/",
      "author": "niklbj",
      "created_utc": "2026-01-23 07:41:22",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "sometimes our agents in prod seem to take some, for a lack of better terms, *interesting* decisions and then other times its a couple bad responses that causes a constant back and forth with users until it eventually gets to the right response. but usually our users don't report it because they're not outright failures and sometimes they go under the radar. \n\ndo you guys do something right now, any flows to best handle these situations? My assumption is it just about continuously tuning the prompts and then adaptign the code. Thinking of setting up observability as well!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkknp3/what_are_some_suggestions_you_have_on_minimizing/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o17aqw7",
          "author": "saurabhjain1592",
          "text": "What you’re describing is a classic “soft failure” pattern. Nothing crashes, but behavior degrades in ways users don’t explicitly report.\n\nIn our experience, prompt tuning alone rarely fixes this once agents are in prod. The issue is usually that the system treats all deviations as recoverable retries, so you get loops, drift, and slow convergence instead of clear failures.\n\nA few things that have helped teams reduce silent failures:\n- Make retries explicit and bounded. If an agent retries automatically without knowing why the previous step failed, you’re just amplifying noise.\n- Log decisions, not just inputs and outputs. When something feels “off” later, you want to know why a step was allowed to proceed.\n- Introduce step-level invariants. For example, “this tool call should only happen if X and Y are true,” rather than letting the model decide implicitly.\n- Treat back-and-forth with users as a signal. Repeated clarification loops are often silent failures in disguise.\n\n\nObservability helps, but only if it’s tied to execution state and decisions, not just traces. Otherwise you can see what happened without understanding why.\n\nCurious where you’re seeing the most drift today: tool selection, retries, or state/context getting lost across turns?",
          "score": 2,
          "created_utc": "2026-01-23 07:56:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1az9vz",
          "author": "Disastrous_Fox_3069",
          "text": "I've found this to be helpful for evaluating context of full conversation - https://docs.langchain.com/langsmith/online-evaluations-multi-turn. My best guess though is that there may be too much context/not enough instruction for the agent. Perhaps too many tools. What model are you using?",
          "score": 1,
          "created_utc": "2026-01-23 20:36:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bjx6e",
          "author": "pbalIII",
          "text": "Soft failures are the hardest to catch because your system looks healthy while making bad decisions.\n\nTwo patterns that helped us: step-level invariants (tool X only fires if conditions Y and Z are true, enforced in code) and treating repeated clarification loops as a signal worth logging.\n\nObservability helps, but the gap is usually prompt-completion linkage. You can see what happened without understanding why. LangSmith traces get you part of the way, but you still need to instrument decision points, not just inputs and outputs.",
          "score": 1,
          "created_utc": "2026-01-23 22:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1kd7ez",
          "author": "Revolutionary-Bet-58",
          "text": "I can highly recommend using an agent scanner prior to deployment for finding silent failures such as infinite loops, bad RCE, etc..",
          "score": 1,
          "created_utc": "2026-01-25 05:02:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkyu82",
      "title": "New! ampersend added as an official LangChain integration",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "author": "kevinjonescreates",
      "created_utc": "2026-01-23 18:32:11",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "Hey everyone - ampersend just got added to the official LangChain integration docs.\n\nIf you're building agents that need to call external services or other agents, this lets them handle payments autonomously. When a remote agent requires payment, ampersend negotiates and executes the payment automatically via x402.\n\nSetup is straightforward - configure your wallet and treasurer, and your LangChain agent can discover remote agent capabilities, send messages, and pay for services without manual intervention. You set spend limits and policies upfront.\n\nUseful if you're building agents that need to:\n\n* Call paid APIs or data services\n* Use other specialized agents (research, analysis, etc)\n* Operate autonomously without constant human approval\n\nDocs:[ https://docs.langchain.com/oss/python/integrations/tools/ampersend](https://docs.langchain.com/oss/python/integrations/tools/ampersend)\n\nHappy to answer questions about the x402 integration or agent-to-agent payments.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ab13a",
          "author": "Mammoth-Nectarine513",
          "text": "Hi , I want to use agent for payment. Do you think i can integrate? What are the pros and cons? \n\nMaybe we can discuss in dm?",
          "score": 1,
          "created_utc": "2026-01-23 18:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b4k3n",
              "author": "kevinjonescreates",
              "text": "Yes it would work great for payments. Using ampersend you can build buyer agents easily, with spending limits [https://docs.ampersend.ai/](https://docs.ampersend.ai/)\n\nHappy to help you if you need dm me!",
              "score": 1,
              "created_utc": "2026-01-23 21:01:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpfnym",
      "title": "I stopped manually iterating on my agent prompts: I built an open-source system that extracts prompt improvements from my agent traces",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qpfnym/i_stopped_manually_iterating_on_my_agent_prompts/",
      "author": "cheetguy",
      "created_utc": "2026-01-28 16:13:28",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 0.77,
      "text": "Some of you might remember my [post about ACE](https://reddit.com/r/LangChain/comments/1p35tko/your_local_llm_agents_can_be_just_as_good_as/) about my open-source implementation of ACE (Agentic Context Engineering). ACE is a framework that makes agents learn from their own execution feedback without fine-tuning.\n\nI've now built a specific application: **agentic system prompting** that does offline prompt optimization from agent traces (e.g. from LangSmith)\n\n**Why did I build this?**\n\nI kept noticing my agents making the same mistakes across runs. I fixed it by digging through traces, figure out what went wrong, patch the system prompt, repeat. It works, but it's tedious and didn't really scale.\n\nSo I built a way to automate this. You feed ACE your agent's execution traces, and it extracts actionable prompt improvements automatically.\n\n**How it works:**\n\n1. **ReplayAgent** \\- Simulates agent behavior from recorded conversations (no live runs)\n2. **Reflector** \\- Analyzes what succeeded/failed, identifies patterns\n3. **SkillManager** \\- Transforms reflections into atomic, actionable strategies\n4. **Deduplicator** \\- Consolidates similar insights using embeddings\n5. **Skillbook** \\- Outputs human-readable recommendations with evidence\n\n**Each insight includes:**\n\n* Prompt suggestion - the actual text to add to your system prompt\n* Justification - why this change would help based on the analysis\n* Evidence - what actually happened in the trace that led to this insights\n\n**Try it yourself**   \n[https://github.com/kayba-ai/agentic-context-engine/tree/main/examples/agentic-system-prompting](https://github.com/kayba-ai/agentic-context-engine/tree/main/examples/agentic-system-prompting)\n\nWould love to hear if anyone tries this with their agents!",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qpfnym/i_stopped_manually_iterating_on_my_agent_prompts/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2a3fbe",
          "author": "caprica71",
          "text": "How is this different from dspy?",
          "score": 1,
          "created_utc": "2026-01-28 20:17:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2afqgi",
              "author": "cheetguy",
              "text": "DSPy works best with structured input/output pairs, ACE works on raw traces (conversation logs, markdown) so no restructuring needed. DSPy auto-optimizes while ACE generates suggestions with evidence for you to review first. Think of DSPy for pipelines with clear metrics, ACE for learning from messy agent failures.",
              "score": 2,
              "created_utc": "2026-01-28 21:11:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28mh9b",
          "author": "KitchenSomew",
          "text": "\\*\\*Production Agent Experience:\\*\\*\n\n\n\nBuilt chatbots for 50+ B2B clients - prompt drift is one of the hardest problems to catch early. Your ACE approach solves a massive pain point.\n\n\n\n\\*\\*What Resonates:\\*\\*\n\n\n\n✓ Trace-based learning vs manual iteration (saves weeks of debugging)\n\n✓ Offline optimization (no live experiments on customers)\n\n✓ Embedding-based deduplication (critical at scale)\n\n\n\n\\*\\*Questions from Production:\\*\\*\n\n\n\n1. \\*\\*Token Cost:\\*\\* How expensive is running ReplayAgent + Reflector on 100+ conversations? Is it viable for startups?\n\n\n\n2. \\*\\*Prompt Versioning:\\*\\* Do you version the Skillbook outputs? We've had cases where a \"good\" prompt change broke edge cases 2 weeks later.\n\n\n\n3. \\*\\*Confidence Scoring:\\*\\* Does ACE rate how confident it is in each recommendation? Some patterns need 50+ traces to be statistically significant.\n\n\n\n\\*\\*Our Workflow (manual):\\*\\*\n\n\\`\\`\\`python\n\n\\# What we do now (tedious):\n\n1. Export LangSmith traces weekly\n\n2. Filter failures (user retry, escalation)\n\n3. Manual pattern analysis\n\n4. Prompt A/B test (3-7 days)\n\n5. Repeat\n\n\\`\\`\\`\n\n\n\nACE automating steps 2-3 would save \\~8 hours/week per agent.\n\n\n\n\\*\\*Pro Tip:\\*\\* For anyone trying this - start with failure-only traces. Analyzing successful runs adds noise early on.\n\n\n\nDoes ACE handle multi-agent systems? Curious if it can trace decisions across agent handoffs.",
          "score": -1,
          "created_utc": "2026-01-28 16:26:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp3lp3",
      "title": "We cache decisions, not responses - does this solve your cost problem?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qp3lp3/we_cache_decisions_not_responses_does_this_solve/",
      "author": "llm-60",
      "created_utc": "2026-01-28 06:21:30",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.82,
      "text": "Quick question for anyone running AI at scale:\n\nTraditional caching stores the response text. So \"How do I reset my password?\" gets cached, but \"I forgot my password\" is a cache miss - even though they need the same answer.\n\nWe flip this: cache the **decision** (what docs to retrieve, what action to take), then generate fresh responses each time.\n\nResult: 85-95% cache hit rate vs 10-30% with response caching.\n\n**Example:**\n\n* \"Reset my password\" → decision: fetch docs \\[45, 67\\]\n* \"I forgot my password\" → same decision, cache hit\n* \"Can't log in\" → same decision, cache hit\n* All get personalized responses, not copied text\n\n**Question: If you're spending $2K+/month on LLM APIs for repetitive tasks (support, docs, workflows), would this matter to you?**",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qp3lp3/we_cache_decisions_not_responses_does_this_solve/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o26v8xf",
          "author": "ruben_rrf",
          "text": "I get that you generate different outputs and cut the costs of having to make the tool calls and also the time. But how do you achieve a better cache rate? If I get it right...\n\nQuestion -> Actions -> Response\n\nIf you cache the Response, then you get a cache with Question -> Response, but if you cache the actions, you get a Question -> Actions cache, and then you use the model as \\[Question, Actions\\] -> Response.\n\nBut the key on the cache wouldn't be the same?",
          "score": 4,
          "created_utc": "2026-01-28 10:22:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26vsqv",
              "author": "llm-60",
              "text": "We don't cache the question, we cache the **normalized intent**.\n\nWe extracts the \"meaning\" first:  \n  \n\"What's your return policy?\" - intent: return\\_policy  \n\"Can I return stuff?\" - intent: return\\_policy  \n\"How do returns work?\" - intent: return\\_policy\n\nand it also learn the context to fit the answer later...\n\nThree different questions, same cache key = cache hit.\n\nThat's how we get 80%",
              "score": 2,
              "created_utc": "2026-01-28 10:27:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o27t0lu",
          "author": "SpecialBeatForce",
          "text": "Couldn‘t you just use semantic caching question->answer if questions like reset password and forgot password are close enough semantically?",
          "score": 1,
          "created_utc": "2026-01-28 14:10:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27un18",
              "author": "llm-60",
              "text": "Traditional semantic caching caches the entire answer, so everyone gets the same response.\n\n**Example:**  \n  \n\"Forgot password\" - cached: \"Click the reset link in your email\"  \n\"Reset my password\" - cached: \"Click the reset link in your email\"\n\nWe cache the decision (what to do), then personalize the response.\n\n**Example:**  \n\"I'm John, forgot password\" - Decision cached: \"send reset email\"  Response: \"Hi John, we sent you a reset link\"  \n\"Sarah needs reset\" -Same cached decision - Response: \"Hi Sarah, we sent you a reset link\"\n\nOne LLM call for the logic, cheap model personalizes each response. You can't do that if you cache the full answer.",
              "score": 3,
              "created_utc": "2026-01-28 14:18:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o28fjzm",
                  "author": "SpecialBeatForce",
                  "text": "Okay i like the idea😊 but i guess it comes down to a decision between personalized answers and saving compute?",
                  "score": 1,
                  "created_utc": "2026-01-28 15:56:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2bgmt3",
                  "author": "CourtsDigital",
                  "text": "i’m not sure i understand this use case. maybe provide some examples that require personalization. i’ve never expected to receive a password reset email that’s tailored to me, or to hear about a store return policy that mentions me by name\n\ni agree with BeatForce that this seems almost exactly like semantic caching, with an additional, unnecessary LLM cost\n\ni’m not saying this couldn’t be useful, but if you intend to sell it for $1k+ per month then the use case(s) should be solid",
                  "score": 1,
                  "created_utc": "2026-01-29 00:06:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qkswe0",
      "title": "How to deploy a LangGraph server on Heroku",
      "subreddit": "LangChain",
      "url": "https://substack.com/home/post/p-184868546",
      "author": "AlexRenz",
      "created_utc": "2026-01-23 14:53:57",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkswe0/how_to_deploy_a_langgraph_server_on_heroku/",
      "domain": "substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1cbm6u",
          "author": "shifra-dev",
          "text": "Awesome work on this!\n\nSharing a resource for deploying LangGraph on Render as well in case that's helpful for folks: [https://www.youtube.com/watch?v=Gq3CPLOGHPw](https://www.youtube.com/watch?v=Gq3CPLOGHPw)",
          "score": 2,
          "created_utc": "2026-01-24 00:39:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1f2nxi",
              "author": "AlexRenz",
              "text": "Nice, this is a great video 💪",
              "score": 1,
              "created_utc": "2026-01-24 12:56:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qm2lrs",
      "title": "Unable to distinguish between reasoning text and final response in streaming mode with tool calls",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "author": "Dragonfruit-Eastern",
      "created_utc": "2026-01-24 23:32:33",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "When streaming messages from Claude (Anthropic models) in LangGraph, the model sometimes includes explanatory text before making tool calls (e.g., \"I'll get the weather information for both New York and San Francisco for you.\").\n\nThe problem is that these text chunks arrive before the tool\\_use content blocks, making it impossible to determine whether the streaming text is:\n\n1. Preliminary reasoning/thoughts that precede a tool call, or\n2. The actual final response to the user\n\nThis creates a challenge for UI rendering, as we cannot know whether to display the text immediately or wait to see if a tool call follows.\n\n**Expected Behavior:**\n\nEither:\n\n* Provide a way to identify which text chunks are associated with tool calls versus final responses during streaming, or\n* Offer a configuration option to disable these preliminary text chunks entirely when tools are being used, so only the tool calls and final responses are streamed\n\n**Current Workaround:**\n\nCurrently, we must wait until the complete message is received to determine the message type, which defeats the purpose of streaming for real-time UI updates.\n\n**Script**\n\n    from langchain_openai import ChatOpenAI\n    from langgraph.graph import StateGraph, add_messages\n    from langchain.tools import tool\n    from langchain_anthropic import ChatAnthropic\n    from typing import TypedDict, Annotated\n    \n    \n    class State(TypedDict):\n        messages: Annotated[list, add_messages]\n    \n    \n    # Create a simple tool\n    @tool\n    def get_weather(city: str) -> str:\n        \n    \"\"\"Get weather information for a city.\"\"\"\n        \n    weather_data = {\"New York\": \"Rainy, 65°F\", \"San Francisco\": \"Sunny, 70°F\", \"London\": \"Cloudy, 55°F\"}\n        return weather_data.get(city, f\"Weather data not available for {city}\")\n    \n    \n    from langgraph.prebuilt import ToolNode\n    \n    tools = [get_weather]\n    tool_node = ToolNode(tools)\n    \n    \n    # LLM node that can call tools\n    def llm_node(state: State):\n        llm = ChatAnthropic(\n            model=\"claude-sonnet-4-5-20250929\",\n            api_key=\"key\",\n        llm_with_tools = llm.bind_tools(tools)\n    \n        response = llm_with_tools.invoke(state[\"messages\"])\n        return {\"messages\": [response]}\n    \n    \n    # Build the graph\n    graph = StateGraph(State)\n    graph.add_node(\"llm\", llm_node)\n    graph.add_node(\"tools\", tool_node)\n    \n    \n    # Route: if the LLM calls a tool, go to tools node, otherwise end\n    def should_use_tools(state: State):\n        last_message = state[\"messages\"][-1]\n        # Check if the last message has tool calls\n        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n            return \"tools\"\n        return \"end\"\n    \n    \n    graph.set_entry_point(\"llm\")\n    graph.add_conditional_edges(\"llm\", should_use_tools, {\"tools\": \"tools\", \"end\": \"__end__\"})\n    graph.add_edge(\"tools\", \"llm\")  # After tools run, return to LLM\n    \n    compiled_graph = graph.compile()\n    \n    \n    if __name__ == \"__main__\":\n        # Stream and print all messages\n        from langchain.messages import HumanMessage\n    \n        initial_state = {\"messages\": [HumanMessage(content=\"What's the weather in New York and San Francisco?\")]}\n    \n        print(\"Streaming updates:\")\n        for event, type in compiled_graph.stream(initial_state, stream_mode=\"messages\"):\n            print(f\"{dict(event)}\")\n\nOutput\n\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': \"I'll get\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' the weather information for both New York and', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' San Francisco for you.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'input': {}, 'name': 'get_weather', 'type': 'tool_use', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': 'get_weather', 'args': {}, 'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': 'get_weather', 'args': '', 'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '{\"city\"', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '{\"city\"', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': ': \"New Yor', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': ': \"New Yor', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': ': \"New Yor', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'k\"}', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'k\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'k\"}', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'input': {}, 'name': 'get_weather', 'type': 'tool_use', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': 'get_weather', 'args': {}, 'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': 'get_weather', 'args': '', 'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '{\"', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '{\"', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'city\": ', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'city\": ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'city\": ', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '\"San F', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': '\"San F', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '\"San F', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'rancisco\"}', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'rancisco\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'rancisco\"}', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'tool_use', 'stop_sequence': None, 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 568, 'output_tokens': 108, 'total_tokens': 676, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, 'tool_call_chunks': [], 'chunk_position': 'last'}\n    {'content': 'Rainy, 65°F', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'get_weather', 'id': '92288d1a-8262-42d3-90eb-38d68206c0f7', 'tool_call_id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'artifact': None, 'status': 'success'}\n    {'content': 'Sunny, 70°F', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'get_weather', 'id': 'c53f55a1-fc34-4b81-b8f3-59212983719f', 'tool_call_id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'artifact': None, 'status': 'success'}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': \"Here's the current\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' weather:', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': '\\n\\n-', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' **New York**: Rainy,', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' 65°F\\n- **San', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' Francisco**: Sunny, 70°', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': 'F', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None, 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 754, 'output_tokens': 36, 'total_tokens': 790, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, ' tool_call_chunks': [], 'chunk_position': 'last'}",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ja45b",
          "author": "TwistCrafty7858",
          "text": "which version of langchain are you using ? your code is not displaying the stream mode but i guess the stream mode « messages » allows you to get only llm output without any AIMessage tool call etc .",
          "score": 2,
          "created_utc": "2026-01-25 01:16:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jfkdw",
          "author": "iso_what_you_did",
          "text": "This isn't a bug - it's how autoregressive models work.\n\n**The problem:** Claude generates text token-by-token. When it outputs \"I'll get the weather...\", it hasn't generated the tool call yet. The model doesn't know what's coming next - it's predicting one token at a time.\n\n**You're asking:** \"Can you label this text as 'preliminary' before the model decides to call a tool?\"\n\n**That's impossible.** The model hasn't made that decision yet when the text streams out.\n\n**Your actual solution is already in the output:**\n\n    python'stop_reason': 'tool_use'  # vs 'end_turn'\n\nWhen streaming completes, check the stop\\_reason. That tells you if tools were called.\n\n**Real options:**\n\n1. Buffer the stream until complete, then decide how to render\n2. Show the preliminary text (it's actually good UX - users see the model \"thinking\")\n3. Accept that streaming + tool calls means some uncertainty until completion",
          "score": 2,
          "created_utc": "2026-01-25 01:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1jmywj",
              "author": "Dragonfruit-Eastern",
              "text": "Thanks for your detailed answer. I use exactly the second option. I pretend it’s the main response until I get a tool use flag for that message id. But not sure about this is the best for UI. Because for example when I use Claude Sonnet in Pycharm Github Copilot extension, It can separate thinking/tool using explanations while it’s streaming on UI. Maybe they use another abstraction or algorithm to distinguish. That’s why I thought there might be a way.",
              "score": 1,
              "created_utc": "2026-01-25 02:27:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1kpbi4",
          "author": "Over_Krook",
          "text": "You pasted your hardcoded api key…",
          "score": 2,
          "created_utc": "2026-01-25 06:27:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iv0if",
          "author": "AdditionalWeb107",
          "text": "Please don't use LangcChain for this - just simply call the model APIs or use a passthrough proxy that gives you a unified API.   You don't want to be bound to a framework here, you want to be bound to an API. And I am not sure why you are using LangGraph for this use case of too calls?\n\nUse LangChain for modelling your business objects, not LLM calls.",
          "score": -2,
          "created_utc": "2026-01-24 23:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1j7ogg",
              "author": "Dragonfruit-Eastern",
              "text": "I get what you're saying, but my app supports multiple LLM providers (OpenAI, Gemini, Anthropic, etc.). Isn't that literally the point of LangChain - to abstract away the different APIs?\n\nI'm just using basic stuff: tool calling and streaming. Not doing anything complex with LangGraph, just the standard tool flow.\n\nIf I call each API directly, I'd have to write the same logic 3+ times for each provider. That's exactly what the framework is supposed to solve, no?",
              "score": 5,
              "created_utc": "2026-01-25 01:02:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1j873w",
                  "author": "AdditionalWeb107",
                  "text": "no you wouldn't you need to use a high-performance, high-throughput proxy that allows you write code ergonomically using any popular client (Anthropic, OpenAI) and common APIs (like v1/chat/completions or v1/messages. You could review liteLLM or [Plano](https://github.com/katanemo/plano). There are other options out there for the same use case.",
                  "score": 1,
                  "created_utc": "2026-01-25 01:05:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qn6ydn",
      "title": "I built langgraph2slack - connect any LangGraph agent to Slack in 3 lines of code",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qn6ydn/i_built_langgraph2slack_connect_any_langgraph/",
      "author": "syasini",
      "created_utc": "2026-01-26 05:12:19",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "Hey everyone! I've been working on an open-source package called `langgraph2slack` that makes it super easy to deploy your **LangGraph** agents to **Slack**.\n\nHere's how you can set it up:\n\n    from langgraph2slack import SlackBot\n    bot = SlackBot()\n    app = bot.app\n\nThen add it to your langgraph.json:\n\n    {\n      \"dependencies\": [\"langgraph2slack\", \".\"],\n      \"graphs\": {\n        \"my-assistant\": \"./agent.py:app\"\n      },\n      \"http\": {\n        \"/events/slack\": \"slack/server:app\"\n      }\n    }\n\nThat's it!\n\nThen run `langgraph dev`, point your Slack app's event URL to it (ngrok works great for local testing), and you're done.\n\nhttps://reddit.com/link/1qn6ydn/video/pn3bxqh5mmfg1/player\n\n**The library currently handles**:\n\n* Real-time streaming responses (uses Slack's streaming API so users see tokens as they come in)\n* Thread management (conversation history is preserved)\n* Works with DMs and mentions in channels/threads\n* Optional feedback buttons that integrate directly with LangSmith\n* Input/output transformers if you need to customize messages before/after they hit your agent\n* Markdown to Slack formatting conversion\n* Image extraction from markdown responses\n\n**Why I built this:**\n\nNow that we're all building chatbots and agentic applications, one of the biggest challenges is getting them in front of users in a way that actually gets adopted. Most enterprise teams already live in Slack. So instead of asking people to context-switch to a separate web app, it makes sense to bring your agent to where they already are.\n\nThis was inspired by the `langgraph-messaging-integrations` repo which was a great reference, but I wanted something I could just pip install and have running in minutes without a ton of setup.\n\nLinks:\n\n* GitHub: [https://github.com/syasini/langgraph2slack](https://github.com/syasini/langgraph2slack)\n* PyPI: `pip install langgraph2slack`\n\nIt's MIT licensed, and I'd love for folks to try it out. If you end up using it or have ideas for improvements, let me know!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qn6ydn/i_built_langgraph2slack_connect_any_langgraph/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qol9sp",
      "title": "GraphRAG vs LangGraph agents for codebase visualization — which one should I use?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qol9sp/graphrag_vs_langgraph_agents_for_codebase/",
      "author": "Dizzy-Item-7123",
      "created_utc": "2026-01-27 17:59:58",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.73,
      "text": "I’m building an app that visualizes and queries an entire codebase.\n\nStack:\nDjango backend\nLangChain for LLM integration\n\nI want to avoid hallucinations and improve accuracy. I’m exploring:\n\nGraphRAG (to model file/function/module relationships)\nLangGraph + ReAct agents (for multi-step reasoning and tool use)\n\nNow I’m confused about the right architecture.\nQuestions:\n\nIf I’m using LangGraph agents, does GraphRAG still make sense?\n\nIs GraphRAG a replacement for agents, or a retrieval layer under agents?\n\nCan agents with tools parse and traverse a large codebase without GraphRAG?\n\nFor a codebase Q&A + visualization app, what’s the cleaner approach?\n\nLooking for advice from anyone who’s built code intelligence or repo analysis tools.",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qol9sp/graphrag_vs_langgraph_agents_for_codebase/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o28zxqv",
          "author": "Striking-Bluejay6155",
          "text": "Sharing a tool I think does what you’re describing with graphrag in the background and the ability to to chat: https://code-graph.falkordb.com/",
          "score": 1,
          "created_utc": "2026-01-28 17:25:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}