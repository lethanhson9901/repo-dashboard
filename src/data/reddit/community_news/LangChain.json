{
  "metadata": {
    "last_updated": "2026-02-23 03:09:58",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 111,
    "file_size_bytes": 126710
  },
  "items": [
    {
      "id": "1r8k1qu",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/wo2lnacmfckg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 00:12:36",
      "score": 156,
      "num_comments": 23,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r8k1qu/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o666sm6",
          "author": "Reasonable-Froyo3181",
          "text": "Ok",
          "score": 3,
          "created_utc": "2026-02-19 02:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66anvg",
              "author": "DeathShot7777",
              "text": "Thanks",
              "score": 2,
              "created_utc": "2026-02-19 02:44:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67jxom",
          "author": "Msense_",
          "text": "Impressive!",
          "score": 3,
          "created_utc": "2026-02-19 08:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67k739",
              "author": "DeathShot7777",
              "text": "‚ù§Ô∏è",
              "score": 1,
              "created_utc": "2026-02-19 08:25:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66irxh",
          "author": "SithLordRising",
          "text": "Very cool. Working on a thinking engine myself",
          "score": 2,
          "created_utc": "2026-02-19 03:33:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o677mug",
              "author": "DeathShot7777",
              "text": "Thanks. What's your approach?",
              "score": 1,
              "created_utc": "2026-02-19 06:32:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o696gin",
                  "author": "ble1901",
                  "text": "I'm focusing on integrating neural networks with a more interactive user interface. The goal is to make it easier for users to experiment and see real-time results. What about your thinking engine?",
                  "score": 2,
                  "created_utc": "2026-02-19 15:25:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6bzo69",
                  "author": "SithLordRising",
                  "text": "Just spent time going through the GitNexus codebase in detail. Really impressive work. A few things stood out:\n\n\\- The phased ingestion pipeline is cleanly separated - structure ‚Üí parse ‚Üí resolve ‚Üí relate ‚Üí cluster ‚Üí trace ‚Üí embed. That's a strong pattern.\n\n\\- Leiden community detection on the relationship graph is a smart choice. The heuristic labelling from folder/naming patterns is pragmatic.\n\n\\- Process tracing via BFS from scored entry points is elegant. The confidence tiers on CALLS edges (import-resolved ‚Üí same-file ‚Üí fuzzy-global) show good engineering judgment.\n\n\\- RRF for combining BM25 + semantic search is the right call over trying to normalize different score scales.\n\n\\- KuzuDB as the embedded graph store is an interesting choice - embedded like SQLite but with native Cypher traversal.\n\nI'm working on a knowledge infrastructure project where we compile documents - academic papers, technical standards, legal texts - into structured knowledge graphs with explicit relationships (prerequisites, dependencies, contradictions between sources). Think of it as applying the same intuition you've had about code to text: raw documents are to knowledge what source files are to architecture. Both need to be parsed into structured units and their relationships made explicit before you can reason about them properly. One of the differences we have is contradictions, something code typically fixes at compile.\n\nYour work has been genuinely useful for validating some architectural directions we've been considering, particularly around graph storage and hybrid search. The parallel between tracing execution flows through code and tracing reasoning chains through knowledge is  closer than I expected.\n\nGreat project. Following with interest.",
                  "score": 1,
                  "created_utc": "2026-02-19 23:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o67ka5m",
          "author": "DeathShot7777",
          "text": "Thanks for all the github stars idk where they r coming from. But holly shit 496 stars üò≠",
          "score": 2,
          "created_utc": "2026-02-19 08:26:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o65ozs6",
          "author": "VanillaOk4593",
          "text": "Obsidian on steroids!",
          "score": 1,
          "created_utc": "2026-02-19 00:39:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65zx0p",
              "author": "DeathShot7777",
              "text": "üòÅ",
              "score": 1,
              "created_utc": "2026-02-19 01:42:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kg1jn",
          "author": "cleverhoods",
          "text": "wow",
          "score": 1,
          "created_utc": "2026-02-21 07:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ua7ib",
          "author": "Brave-Photograph9845",
          "text": "oh cool , i actually built something similar ... you can check it on [https://nomik.co/](https://nomik.co/)",
          "score": 1,
          "created_utc": "2026-02-22 21:10:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6udf6v",
              "author": "DeathShot7777",
              "text": "Cool, the website looks great. What DB r u using?",
              "score": 1,
              "created_utc": "2026-02-22 21:26:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vbuaq",
          "author": "adspendagency",
          "text": "you have my attention",
          "score": 1,
          "created_utc": "2026-02-23 00:33:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vjkng",
          "author": "rafapozzi",
          "text": "I think this is the future of AI. I'll come back a few years later and see.",
          "score": 1,
          "created_utc": "2026-02-23 01:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vxb0x",
          "author": "SuperIce07",
          "text": "I'm interested to know how does it work",
          "score": 1,
          "created_utc": "2026-02-23 02:42:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9u4uj",
      "title": "Noob question... is LangChain still relevant?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9u4uj/noob_question_is_langchain_still_relevant/",
      "author": "Odd-Aside456",
      "created_utc": "2026-02-20 12:31:58",
      "score": 99,
      "num_comments": 71,
      "upvote_ratio": 0.91,
      "text": "I'm planning to build an AI personal assistant. First capabilities it will need include the standard assistant stuff: calendar, contracts, email, tasks, etc. But EVENTUALLY I'd like to build it up to be able to do autonomous work to along the lines of research, building tools, etc, and acting more like an employee than an agent (similarish to the whole OpenClaw hype, but much more on rails and personalized). Doing some research on tech stacks with LLMs, I keep getting pointed to LangChain and / or LangGraph. However, doing some Googling of my own, I keep finding people who say they've moved away from LangChain or that it's generally disliked (which I find hard to fully believe). Given the rapid pace at which new AI technologies are being developed, is LangChain / LangGraph still hyper-relevant today, and applicable for my end goal?",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1r9u4uj/noob_question_is_langchain_still_relevant/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6f8r13",
          "author": "Friendly-Ask6895",
          "text": "LangChain gets a lot of hate but IMO most of it is from people who used it like a year ago when the API was changing every 2 weeks and the abstractions were pretty leaky. It's matured a lot since then. LangGraph specifically is actually really solid for the kind of agent workflows you're describing, especially when you need things like conditional branching, human-in-the-loop steps, and persistent state across conversations.\n\nThat said, for the basic personal assistant stuff (calendar, email, etc) you could honestly start with just raw API calls + function calling and get pretty far. The place where LangChain/LangGraph really starts paying off is when you want the agent to plan multi-step tasks, recover from errors, and maintain context across tool calls. Which sounds like exactly where you want to end up.\n\nI'd say start simple with direct API calls so you actually understand whats happening under the hood, then bring in LangGraph when you need the orchestration layer. Going straight to a framework before you understand the basics is how people end up confused when something breaks.",
          "score": 61,
          "created_utc": "2026-02-20 14:00:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsrgi",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 5,
              "created_utc": "2026-02-20 15:40:51",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6h69er",
              "author": "mzinz",
              "text": "In each of these scenarios (direct API calls with LLM; LangGraph agents) - what are the common ways for invoking? Dependent on how you want the trigger to occur I assume, but what are the most common setups?\n\nThinking about things like:\n\n* checking email occasionally and sending a notification when an urgent email is identified (probably Cron?)\n* work scenario: a ticket is cut when a document is ready for review/approval. Need a way to monitor for tickets of that type to come in, then invoke the agent/call in some way\n\n",
              "score": 2,
              "created_utc": "2026-02-20 19:27:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6gwqop",
              "author": "Singularity-42",
              "text": "Does LangChain support image models now?\n\nI've tried it for a real production project in early 2023 (and it was the TS version) and I was so disgusted by the experience that I swore I'd never go back to Langchain again. The only value I ever got out of it was vendor consolidation. But just cumbersome as fuck.",
              "score": 4,
              "created_utc": "2026-02-20 18:43:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6idatx",
              "author": "FMWizard",
              "text": "Code base is still spaghetti. Pedantic AI is super clean and reliable and their API is stable ie they are real software engineers.",
              "score": 1,
              "created_utc": "2026-02-20 23:04:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6iza49",
                  "author": "Budget_Bar2294",
                  "text": "the worst part of my amazing job is dealing with this crap ass framework. LangGraph is so much better but no one uses that. and the core abstractions in the Lang\\* ecosystem are awful anyway. the best part of my job is sneakily avoiding using LangChain whenever possible",
                  "score": 1,
                  "created_utc": "2026-02-21 01:12:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6obr05",
              "author": "municorn_ai",
              "text": "Langgraph is great and we made a hybrid version with HATEOAS to generate portal, voice and chat agents from a shared configuration for a consistent deterministic behavior. This is too much complexity unless you are looking to build a SaaS AI application. For most one off customer specific applications, the graph is pretty static usually and hard coded implementations are more efficient than incorporating complexity. LLMs thrive on static instructions and RAG is not always a value addition.",
              "score": 1,
              "created_utc": "2026-02-21 22:20:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6evmc3",
          "author": "Freed4ever",
          "text": "Langchain IMO has a lot of fluff that is not needed. Langgraph OTOH is solid. But you can just build your own if I were you.",
          "score": 25,
          "created_utc": "2026-02-20 12:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsdck",
              "author": "Odd-Aside456",
              "text": "Good to know, thank you!",
              "score": 3,
              "created_utc": "2026-02-20 15:38:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ev3l9",
          "author": "Bubba_deets",
          "text": "if you care about long-term maintainability, keep the core logic modular so you‚Äôre not locked into any one framework",
          "score": 15,
          "created_utc": "2026-02-20 12:41:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsboi",
              "author": "Odd-Aside456",
              "text": "Good advice, thank you.",
              "score": 1,
              "created_utc": "2026-02-20 15:38:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffc2a",
          "author": "cleverhoods",
          "text": "I think LangGraph might still be relevant for those who want to work with graph based approach. However the more I dig into claude the more I question this thing. One thing LangGraph does absolutely fantastic - imo - is the visualisation of what is happening. ",
          "score": 4,
          "created_utc": "2026-02-20 14:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h7m9c",
              "author": "mzinz",
              "text": "Using LangStudio for visualization?",
              "score": 3,
              "created_utc": "2026-02-20 19:34:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hoqo5",
                  "author": "cleverhoods",
                  "text": "now reading back, yeah, that could be misunderstood. What I meant is that for agentic work I found LangSmith a great tool to \\*see what is going where, how token expensive it is, what goes to system prompt, to agent prompt, etc. Not \\*LangGraph for \\*visualization.",
                  "score": 3,
                  "created_utc": "2026-02-20 20:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6fszzg",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 0,
              "created_utc": "2026-02-20 15:41:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fvq4y",
          "author": "PretendPop4647",
          "text": "As someone mentioned earlier,keep core things modular. \nCome the point, yes langchain especially deepagent is good.  They provide built in agent harness like file system,sub agent etc\n\nUsing it i built a job search agent.  you can check this out how i implement deepagent for get some idea.\n\nhttps://github.com/Rahat-Kabir/job-search-agent\n\nbtw when you finish your project, give us Update.",
          "score": 4,
          "created_utc": "2026-02-20 15:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fycs0",
              "author": "Odd-Aside456",
              "text": "Will do! And thank you!",
              "score": 2,
              "created_utc": "2026-02-20 16:07:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f3ypj",
          "author": "adlx",
          "text": "Have a look at deepagents, by LangChain. Your Ai assistant is already built üòÇ",
          "score": 7,
          "created_utc": "2026-02-20 13:34:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsees",
              "author": "Odd-Aside456",
              "text": "I'll check it out, thanks!",
              "score": 2,
              "created_utc": "2026-02-20 15:39:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fylnc",
          "author": "DavidtheLawyer",
          "text": "I find that Claude Code can accomplish much of this work, but I‚Äôm big fan of LangGraph.",
          "score": 3,
          "created_utc": "2026-02-20 16:08:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fzw0s",
              "author": "Odd-Aside456",
              "text": "I do love Claude Code. But I can't afford anything beyond the Pro plan right now, and I can't spend those precious tokens on an assistant at the moment.",
              "score": 4,
              "created_utc": "2026-02-20 16:14:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6g9jda",
                  "author": "DavidtheLawyer",
                  "text": "True, it does go hog sometimes",
                  "score": 2,
                  "created_utc": "2026-02-20 16:57:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ibab2",
          "author": "MathematicianSome289",
          "text": "Absolutely. It is the de-facto OSS choice. It‚Äôs why OSS-friendly companies like cloudflare have native support and why closed source companies like AWS built their own agent framework. They know langgraph is too portable given it‚Äôs ubiquity.",
          "score": 3,
          "created_utc": "2026-02-20 22:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fcqtx",
          "author": "Delicious-One-5129",
          "text": "Yes. LangChain is still a practical go to for prototyping and integrations.",
          "score": 6,
          "created_utc": "2026-02-20 14:21:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsvp2",
              "author": "Odd-Aside456",
              "text": "\"For Prototyping,\" So what would you recommend for production, assuming a product got to that point?",
              "score": 3,
              "created_utc": "2026-02-20 15:41:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hmb6z",
                  "author": "zhuki",
                  "text": "Its always prototyping, everything is just for prototyping, never production ü•≤",
                  "score": 11,
                  "created_utc": "2026-02-20 20:46:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6fe61z",
          "author": "Odd-Literature-5302",
          "text": "If you need more structured state and graph style workflows try LangGraph as a complement",
          "score": 2,
          "created_utc": "2026-02-20 14:28:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsxc3",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-02-20 15:41:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gu88x",
          "author": "micupa",
          "text": "Unpopular opinion: Langchain was very early.. we didn‚Äôt even need a framework to build on top of ai APIs.. now we are seeing the need but with a totally different approach: the problem isn‚Äôt the api or the code integration but the context and tools. Frameworks like openclaw are the new way of angetic frameworks, to build good ai assistant think in terms of a new layer of abstraction.",
          "score": 2,
          "created_utc": "2026-02-20 18:32:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6p74lf",
              "author": "vvitali26",
              "text": "Could you elaborate more on the problem with the langchain/langgraph approach in the modern environment comparing to openclaw, please?",
              "score": 1,
              "created_utc": "2026-02-22 01:30:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6r4wbp",
                  "author": "micupa",
                  "text": "I mean, Langchain is a framework for human developers, a layer of abstraction for managing APIs from different providers.. but openclaw is a framework for the agent. The user is the agent not the human.",
                  "score": 1,
                  "created_utc": "2026-02-22 10:57:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6hqmxv",
          "author": "HotMud9713",
          "text": "with agent skill, not anymore",
          "score": 2,
          "created_utc": "2026-02-20 21:07:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g4gn1",
          "author": "AlexRenz",
          "text": "Who are you building this for - your own personal use? Then I'd rather see how far you can get with Claude or n8n first and see if this gets you there. \n\nIf you want to ship something that's an app to use for others, scalable or that you can sell, deploy it somewhere, scale it, trace it etc. that's a whole different thing. \n\nI find LangGraph to be a great option (and I'm not really differentiating between Chain & Graph tbh). Others have mentioned already that a lot of the online reviews are pre-version 1.0 which just came out end of last year and improved a ton of stuff. \n\nYou'll want to use their pre-built agent and customize that one with integrations and middleware. Nobody can really tell you where all the frameworks are going, so keep your stuff modular as much as you can. But honestly, you can optimize for that later - get started and don't overthink this before you must. And often, a lot of value will lie in your context and prompts which are portable. ",
          "score": 3,
          "created_utc": "2026-02-20 16:34:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6g5chv",
              "author": "Odd-Aside456",
              "text": "It's gonna start for personal use, but then I'm gonna ship it for some friends and family. If they receive it well, I'll probably make it public. Mainly for that reason I'm trying to stay provider/model agnostic.\n\nThanks so much for all the info!",
              "score": 2,
              "created_utc": "2026-02-20 16:38:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6gwahn",
                  "author": "EveYogaTech",
                  "text": "You could use Nyno (see my profile), unlike n8n it's open-source and it's based on multiple languages, so you can stay as agnostic as possible even though using a framework + GUI builder.\n\nLanguages currently supported: Python, Node, Typescript, PHP and Ruby.",
                  "score": 3,
                  "created_utc": "2026-02-20 18:41:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6kuef5",
                  "author": "AlexRenz",
                  "text": "Another question btw is how comfortable you're coding. \n\nIn what I've seen on many many products, it's best to lean towards least resistance early on - in your case put something together with Claude/ChatGPT or n8n and see what features you actually  need. Once you know that AND you hit a limit, write code. ",
                  "score": 1,
                  "created_utc": "2026-02-21 10:01:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6h739u",
              "author": "mzinz",
              "text": "What do you mean by pre-built agents? Re-usable code they offer, or a diff package or product?",
              "score": 2,
              "created_utc": "2026-02-20 19:31:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ktwv2",
                  "author": "AlexRenz",
                  "text": "They have a ReAct agent package that already gets you a core agent, to which one can add integrations and middleware: [https://docs.langchain.com/oss/python/langchain/agents](https://docs.langchain.com/oss/python/langchain/agents)\n\nThey also offer a \"Deep Agent\" which I feel is the same but with more built-in features: [https://docs.langchain.com/oss/python/deepagents/overview](https://docs.langchain.com/oss/python/deepagents/overview)  \n",
                  "score": 2,
                  "created_utc": "2026-02-21 09:56:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ffxdy",
          "author": "Hackerjurassicpark",
          "text": "Just feed your requirements to Claude code and let it build it from scratch. Langchain is unnecessary bloatware built for an age when the ability reuse code and design patterns were important. That is no longer the case now. Claude code can pretty much be your scaffolding using native components instead of an additional layer like Langchain.",
          "score": 3,
          "created_utc": "2026-02-20 14:38:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft34s",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-20 15:42:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6imf9r",
                  "author": "No_Indication_1238",
                  "text": "Do not listen to people in this sub. They are clueless. ",
                  "score": 5,
                  "created_utc": "2026-02-20 23:56:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6h6h5j",
              "author": "mzinz",
              "text": "If asking Claude to do it - would it make sense to ask it to use LangChain/LangGraph, though? If not, why?",
              "score": 1,
              "created_utc": "2026-02-20 19:28:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hxh3o",
                  "author": "Leo2000Immortal",
                  "text": "It's an extra layer of abstraction which does not really help much. It's easier to debug with less abstractions when things don't work as expected",
                  "score": 1,
                  "created_utc": "2026-02-20 21:41:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gkdyx",
          "author": "damanamathos",
          "text": "If you want to build an effective personal assistant, my recommendation is start with something like OpenCode or Claude Code (depending on which underlying model you want to use), then write custom command line tools that let it access calendar, email, tasks, image generation, whatever you want. Then give it skills so it can learn how to use all those commands when needed.\n\nI think this is the fastest way to get up to speed with building agents, which will help you think about how to build something more customised in code. The nice thing about using OpenCode is that it's open source so you can always see how they implement agents.\n\nI don't have a strong view on LangGraph as haven't seen their latest updates. I do use it in parts of my codebase for handling general LLM calls, and do have an older agent that runs on LangChain, though my more recent agents have all been custom code with direct calls to the provider APIs.",
          "score": 1,
          "created_utc": "2026-02-20 17:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hq2hx",
          "author": "sundevil21CS",
          "text": "I have found myself recently ditching langchain and graph and using models SDK structured outputs and manually chaining calls based off structured outputs.",
          "score": 1,
          "created_utc": "2026-02-20 21:04:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ignqe",
          "author": "coreofapples-",
          "text": "Use Temporal and suddenly your life becomes infinitely easier",
          "score": 1,
          "created_utc": "2026-02-20 23:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6irwyk",
          "author": "AdWorried6080",
          "text": "tbh if you want to learn with project start with scratch then you started going to know how this chains,agent, memory and tools are working. If you build small stuff and can check langchain repo than you‚Äôll say why langchain need to use or not. Langchain is good starter for early knowledge and quick build stuff. But when it comes to more customisation, integration, scalability and cost you‚Äôll not go for any framework. As per experience big organisation often build their POC with this frameworks but when it comes to make a product then they‚Äôll create from scratch. It‚Äôs more reliable, scalable, cost optimised(highly needed, lacks in this frameworks), customisable and maintainable.",
          "score": 1,
          "created_utc": "2026-02-21 00:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jrbxi",
          "author": "autoshag",
          "text": "LangGraph for sure. \nAnd then within the nodes I usually use Claude Agents SDK, or OpenCode SDK or langchain depending on the complexity of the task",
          "score": 1,
          "created_utc": "2026-02-21 04:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jvpfd",
          "author": "sergeant113",
          "text": "Use baml-ai for all the core LLM abstraction. Don‚Äôt bother with langChain at all.",
          "score": 1,
          "created_utc": "2026-02-21 04:45:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k2uj4",
          "author": "bornwithmistake",
          "text": "you can vibe code a LangChain equivalent for internal use, focused on your exact workflows, with cleaner abstractions and fewer moving parts than the open source stack",
          "score": 1,
          "created_utc": "2026-02-21 05:41:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ka0ej",
          "author": "themessymiddle",
          "text": "Personal experience - I‚Äôve tested our same agentic workflow with langchain, strands, and Claude agents sdk and the langchain one has the best results. I think it‚Äôs because you have so much more control. It‚Äôs more complex to manage than something like Claude agents sdk, but you have much more granular control",
          "score": 1,
          "created_utc": "2026-02-21 06:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kfn8w",
          "author": "AloneSYD",
          "text": "I would honestly try Agno as it's much simpler compared to lang*  frameworks",
          "score": 1,
          "created_utc": "2026-02-21 07:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kgyhx",
          "author": "SaltedFesh",
          "text": "Only use LangGraph to build graph based workflow and some LangChain necessary components like chunking text, and directly use OpenAI sdk to work with AI",
          "score": 1,
          "created_utc": "2026-02-21 07:48:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kpqm6",
          "author": "ParticularBasket6187",
          "text": "I used this and in future I‚Äôll definitely continue this. Have there some issue but it‚Äôs not big as such.",
          "score": 1,
          "created_utc": "2026-02-21 09:15:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kvxn7",
          "author": "ws6kid",
          "text": "TBH seems it‚Äôs only relevant in abstracted low code tools like n8n‚Ä¶ openclaw is eating its lunch in terms of autonomous agent capabilities even Claude code..",
          "score": 1,
          "created_utc": "2026-02-21 10:16:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lna0e",
          "author": "Gold_Emphasis1325",
          "text": "My understanding and people with more direct experience please correct/supplement: LanchChain is great abstraction, orchestration for linear flows. More branching and complex flows warrant LangGraph, another orchestrator. All of the other DevSecOps and software engineering are still 95% of the work and these are nifty and for people with the complexity to push them into the extra work -- game changing.",
          "score": 1,
          "created_utc": "2026-02-21 13:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lnzz8",
          "author": "Acrobatic_Task_6573",
          "text": "Interesting point. I ran into something similar when building multi-step chains. The config layer is way more important than it looks on the surface.",
          "score": 1,
          "created_utc": "2026-02-21 14:02:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lwsdh",
          "author": "RandomForest42",
          "text": "Just vibe code the whole thing without any dependencies, just like half the Internet is doing already",
          "score": 1,
          "created_utc": "2026-02-21 14:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mcbas",
          "author": "Cats4BreakfastPlz",
          "text": "I've been here before. Try to build with langchain/langgraph, end up wondering why its not working, can't get proper obsevability on whats going wrong, try and figure out what's wrong, just end up building my own that claude understands perfectly and doesn't have to guess around\n\nafter trying pretty hard for a while I'm pretty sure langgraph is moronic and pointless and only good for people who want to sound fancy on their resume. you'll notice most devs who are forced to use it will tell you they hate it and prefer to do it themselves but their bosses want them to use it.\n\nits like stringing templates together. none ofthem work exactly the way you want to and you end up having to implement your own custom solution the majority of the time.\n\nthese tools try to simplify things by giving it to you easy but they just end up making everything more difficult than it needs to be. especially these days where opus/sonnet can do almost anything.",
          "score": 1,
          "created_utc": "2026-02-21 16:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r13ny",
          "author": "Eugeniusz87",
          "text": "I still see langchain used in a bunch of projects, especially for prototyping and chaining LLMs with tools. It may not be perfect, but i've found it useful when i needed a quick integration and didn't want to build everything from scratch",
          "score": 1,
          "created_utc": "2026-02-22 10:21:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s3et3",
          "author": "coccoinomane",
          "text": "Give a chance to Pydantic AI, too: it feels it has the must-have features (including observability with Logfire) without as many of the technicalities as Langchain/Langgraph.",
          "score": 1,
          "created_utc": "2026-02-22 14:57:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t29rp",
          "author": "Accomplished-Score28",
          "text": "I have a project that I am building out with langchain. Has 6 different agents. User can dictate the model being used. The project is a POC and being submitted to try and win a grant to build it out more",
          "score": 1,
          "created_utc": "2026-02-22 17:38:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fqaxw",
          "author": "Interesting_Ride2443",
          "text": "LangChain is great for prototyping and short workflows, but once you need durable state, retries, or long-running multi-step execution, you run into limits. Tools like Calljmp provide built-in execution management, pause/resume, and observability, which makes scaling autonomous agents more practical without reinventing all that infrastructure.",
          "score": 1,
          "created_utc": "2026-02-20 15:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft59f",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-02-20 15:42:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fth36",
                  "author": "sandman_br",
                  "text": "It‚Äôs a ad dude. Don‚Äôt fall for it",
                  "score": 7,
                  "created_utc": "2026-02-20 15:44:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gn80d",
          "author": "BeerBatteredHemroids",
          "text": "If you have to ask this, maybe you should just focus on learning the framework first",
          "score": -2,
          "created_utc": "2026-02-20 18:00:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbd4x5",
      "title": "LangGraph-based production-style RAG (Parent-Child retrieval, idempotent ingestion) ‚Äî feedback on recursive loops?",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/91vqmkq1czkg1",
      "author": "Lazy-Kangaroo-573",
      "created_utc": "2026-02-22 05:11:47",
      "score": 76,
      "num_comments": 33,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1rbd4x5/langgraphbased_productionstyle_rag_parentchild/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6r89j6",
          "author": "RubenC35",
          "text": "Great. Out of scope, how did you make that diagram?",
          "score": 15,
          "created_utc": "2026-02-22 11:29:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sc1ir",
              "author": "Oddly_Even_Pi",
              "text": "Also would love to know",
              "score": 3,
              "created_utc": "2026-02-22 15:40:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ses7z",
                  "author": "ar_tyom2000",
                  "text": "u/RubenC35, u/Oddly_Even_Pi, the graph in the picture seems like a Gemini-generated graph based on a description. But if you're interested in real-time graph animation, here is one I know of [https://github.com/proactive-agent/langgraphics](https://github.com/proactive-agent/langgraphics)",
                  "score": 7,
                  "created_utc": "2026-02-22 15:53:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qreaw",
          "author": "SithLordRising",
          "text": "Looks really nice. I just use cytoscape.min.js for most of my flows",
          "score": 2,
          "created_utc": "2026-02-22 08:48:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ra9h4",
              "author": "Lazy-Kangaroo-573",
              "text": "Glad you liked it.",
              "score": 2,
              "created_utc": "2026-02-22 11:48:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rckd6",
          "author": "International-Mood83",
          "text": "Also curious as to how you made this animation. its pretty cool!",
          "score": 2,
          "created_utc": "2026-02-22 12:07:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6re9zg",
              "author": "Lazy-Kangaroo-573",
              "text": "Built it as an SVG with CSS animations + animateMotion paths. Happy to share the approach if useful for anyone documenting RAG architectures.",
              "score": 8,
              "created_utc": "2026-02-22 12:21:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rgmge",
                  "author": "jay-phi",
                  "text": "Would definitely be interested in your approach!",
                  "score": 3,
                  "created_utc": "2026-02-22 12:40:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6rv3oy",
                  "author": "croninsiglos",
                  "text": "Definitely interested. It‚Äôs both visually appealing and could probably be easily integrated into documentation pages.",
                  "score": 2,
                  "created_utc": "2026-02-22 14:13:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6tsrg5",
                  "author": "Nzkx",
                  "text": "The fun fact is people are more interested to the graphics itself than the AI lmao.\n\nGood job anyway. Really like the graphs presentation.",
                  "score": 2,
                  "created_utc": "2026-02-22 19:42:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rm8eu",
          "author": "peregrinefalco9",
          "text": "The parent-child split with Qdrant for children and Postgres for parents is solid. For context growth in recursive retrieval, have you tried summarizing intermediate results before feeding them back into the loop? Keeps the window manageable without losing signal.",
          "score": 2,
          "created_utc": "2026-02-22 13:19:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6scazv",
          "author": "Oddly_Even_Pi",
          "text": "Would you be open to sharing the project? Would love to take a look at it",
          "score": 2,
          "created_utc": "2026-02-22 15:41:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sg5zt",
              "author": "ar_tyom2000",
              "text": "As I can understand from [OP's reply](https://www.reddit.com/r/LangChain/comments/1rbd4x5/comment/o6re9zg/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) above, it is a custom-made SVG. If you're interested in autogenerating animated flows of your existing graphs, take a look at the [LangGraphics](https://github.com/proactive-agent/langgraphics) project.\n\nhttps://i.redd.it/8smvzdjfj2lg1.gif",
              "score": 0,
              "created_utc": "2026-02-22 15:58:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6th2dp",
                  "author": "meridian_dan123",
                  "text": "That LangGraphics project looks interesting! Autogenerating animated flows could really enhance the visual aspect of complex graph structures. Have you had any experience using it with similar setups?",
                  "score": 2,
                  "created_utc": "2026-02-22 18:46:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6sv3g7",
          "author": "Key-Place-273",
          "text": "Hmm‚Ä¶.dont hate me but like‚Ä¶why? What‚Äôs the use case? Genuinely asking. I have a prod agentic app with 400+ enterprise users now and we‚Äôve basically written off vector RAG unless for very specific niche use cases.\n\nThis rag pipeline looks like the ultimate like technical bleeding edge, but, in practice and testing that usually means little production outcome. So defs really interested in seeing how this would go against realistic use cases",
          "score": 2,
          "created_utc": "2026-02-22 17:05:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sypap",
              "author": "Lazy-Kangaroo-573",
              "text": "https://preview.redd.it/c5fquai9y2lg1.jpeg?width=3196&format=pjpg&auto=webp&s=474149d965b0f46f22ef74e67c71f6984c440b22\n\nValid point! I understand the skepticism around RAG at scale. However, the reason I'm sticking with this architecture instead of just a Long-Context Window is the Precision-Risk in Legal Data. ‚Äã\\*Attached are some shots from my Supabase backend. I'm processing heavy compliance docs. One of the files alone has over 3,500 child chunks mapped to hundreds of parents. ‚ÄãFeeding this entire context into a single prompt creates too much noise and 'Lost in the Middle' issues. For 400+ general enterprise users, RAG might be overkill, but for a Legal AI where a single 'mis-retrieved' clause can invalidate an entire reasoning chain, I need this level of granular control that LangGraph provides. ‚ÄãI'd love to hear more about why you wrote off RAG‚Äîwas it the latency, the cost, or just the retrieval hallucinations?",
              "score": 3,
              "created_utc": "2026-02-22 17:21:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6tb5iz",
                  "author": "Key-Place-273",
                  "text": "So like ‚Äòvector embedding‚Äô is the issue for us within RAG realm. Legal docs might be different so for sure good to know your work! For us we use procedural guidance data for enterprise apps like NetSuite. So right now the best we managed with semantic search, BM25, reranking, hierarchy indexing etc, is around 85% match..at best‚Ä¶ and we‚Äôre still at like 90% reliability for the chunks being in the correct order.  \n\nI read this paper from Chroma that they showed the order of chunk retrieval does NOT actually have to be accurate. If anything they showed the LM had better contextual understanding when it wasn‚Äôt in logical order BUT, for us it‚Äôs very much like ‚Äúyou must do Step A and step A then branches into 5 different scenarios each with 10 steps each with 10 sub scenarios. \n\nSo we haven‚Äôt found a semantic space where we can reliably embed out knowledge into, and match it with the same semantic space that queries go to. One is a ‚Äúto do a take you must do x and then y‚Äù the other is ‚Äúdo me x‚Äù, it‚Äôs the Agent‚Äôs job to asses given the context, X really mean scenario 6A, schema C (for example) out of 100 scenarios and 1000s of schemas. \n\nI will say though. We‚Äôre a tiny ass team. The fact that I‚Äôve not managed to do it, doesn‚Äôt mean it‚Äôs 100% not meant to be for us. However, now, 2 years into doing this at Enterprise level and two agentic firms in‚Ä¶I tend to give my own experience and insight a little more weight than industry and research now (even though kinda cocky‚Ä¶ it legit I come up with ideas daily that the industry comes up with names for in like 6 months lol) \n\nSo idk, like I have experiment after experiment where my own creation is stilll tops (I made a specialized knowledge graph that isn‚Äôt vector basically), but could be that I‚Äôm way too engrossed in my own niche now!\n\nBest of luck to you I‚Äôm gonna follow your profile :)",
                  "score": 2,
                  "created_utc": "2026-02-22 18:19:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6tc2p0",
              "author": "ichig0_kurosaki",
              "text": "How would you do it without RAG?",
              "score": 1,
              "created_utc": "2026-02-22 18:23:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6teitv",
                  "author": "Key-Place-273",
                  "text": "Really meticulous context engineering. We‚Äôre patenting so I can‚Äôt share much, but it‚Äôs a none - vector knowledge graph at its core",
                  "score": 1,
                  "created_utc": "2026-02-22 18:34:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vnteo",
          "author": "Lazy-Kangaroo-573",
          "text": "Seeing a lot of comments hyper-focusing on the diagram aesthetics and debating whether it's generated by Gemini or Claude. üòÇ \nTaking that as a massive compliment!\nHowever, the real AI magic is under the hood. The core focus of this post isn't the pixels, but the actual LangGraph orchestration, the PII sanitization layer, and the Agentic RAG logic. üß†\nIf we can move past the graphic design debate, I‚Äôd genuinely love to hear your technical critiques on the backend architecture, the chunking strategy, or the retrieval logic. The live demo is up (link in bio) ‚Äî feel free to try and break the actual system instead of pixel-peeping the diagram! üöÄ\"",
          "score": 2,
          "created_utc": "2026-02-23 01:45:14",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6sga6d",
          "author": "NigaTroubles",
          "text": "SVG animated ??",
          "score": 1,
          "created_utc": "2026-02-22 15:59:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sis4u",
              "author": "Lazy-Kangaroo-573",
              "text": "Exactly! It‚Äôs just pure XML. I used <rect> for the systemnodes and <path> for the connections.. The   traveling data packets is just <circle> tags paired with <animateMotion> along those paths, plus some CSS @keyframesfor the glowing effecls.",
              "score": 5,
              "created_utc": "2026-02-22 16:09:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6q4gzr",
          "author": "Lazy-Kangaroo-573",
          "text": "For context ‚Äî LangGraph is mainly handling the cyclic retrieval loop and retry control.\n\nEach node:\n- Classifies intent\n- Applies PII masking\n- Executes parent-child retrieval\n- Applies circuit breaker logic before LLM call\n\nOne thing I'm still evaluating:\nShould recursive retrieval stop based on confidence threshold, token growth, or graph depth?\n\nCurious how others are handling termination criteria in LangGraph loops.",
          "score": 0,
          "created_utc": "2026-02-22 05:20:39",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1rau962",
      "title": "How are you actually evaluating your LangChain agents in production, not just in the notebook?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1rau962/how_are_you_actually_evaluating_your_langchain/",
      "author": "Afzaalch00",
      "created_utc": "2026-02-21 15:42:16",
      "score": 19,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "I have been building a LangChain-based customer support agent for the past few months and kept running into the same issue. Everything looked fine locally, but once it hit production I had no real way to know if quality was holding up or slowly degrading. I was basically eyeballing outputs and hoping for the best.\n\nI started with DeepEval for offline evals since it integrates cleanly with LangChain and the pytest-style setup felt familiar. It was genuinely useful for pre-deployment checks: testing faithfulness, answer relevancy, and hallucination on a fixed dataset before each release. Highly recommend it as a starting point if you haven't tried it.\n\nThe gap I kept hitting though was that my offline dataset didn't reflect what real users were actually sending. I'd pass all my tests and still get weird failures in prod that I never anticipated. That's when I moved to Confident AI, which is built by the same team behind DeepEval. The big difference is it runs those same evals continuously on production traces instead of just a static dataset. When a metric like faithfulness or relevance drops, you get alerted before users complain. The other thing I didn't expect to find useful was the automatic dataset curation from real traces. Bad production outputs get turned into test cases, so over time your eval dataset actually reflects your real traffic instead of synthetic examples you wrote on day one.\n\nThe combo that works for us now is DeepEval for pre-deployment regression testing in CI and Confident AI for live quality monitoring in prod. Took a while to get here but the iteration loop is way tighter now.\n\nAnyone else using a similar setup or found a different approach for keeping LangChain agent quality stable over time?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1rau962/how_are_you_actually_evaluating_your_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6m728y",
          "author": "cool_girrl",
          "text": "Solid setup. We do something similar but use LangSmith for tracing and run DeepEval checks separately. The annoying part is keeping the two in sync.",
          "score": 3,
          "created_utc": "2026-02-21 15:48:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m7pfm",
          "author": "Otherwise_Wave9374",
          "text": "This is exactly the pain point, notebook success means nothing once real traffic hits. The DeepEval + continuous monitoring split makes a lot of sense, offline for regression and then production traces to catch drift.\n\nOne thing thats helped us is defining a small set of \"agent contract\" checks: tool call validity, JSON schema compliance, refusal behavior, and grounding/citation rules. Even if answer quality is subjective, those checks catch a surprising amount of breakage.\n\nIf youre collecting patterns around agent evals, a few notes and links here: https://www.agentixlabs.com/blog/",
          "score": 2,
          "created_utc": "2026-02-21 15:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mq1dy",
          "author": "Happy-Fruit-8628",
          "text": "The automatic dataset curation part is underrated. We were manually curating failure cases into test sets which took forever. Anything that makes that automatic is a big deal when you are trying to ship fast.",
          "score": 1,
          "created_utc": "2026-02-21 17:23:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6muivj",
          "author": "Abdullah_3254",
          "text": "+1 on this. DeepEval offline plus Confident AI on live traffic is honestly the combo I wish I had set up from day one.",
          "score": 1,
          "created_utc": "2026-02-21 17:46:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n5aqc",
          "author": "SpareIntroduction721",
          "text": "I used langfuse since it‚Äôs very similar to langsmith and private",
          "score": 1,
          "created_utc": "2026-02-21 18:39:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pd8wa",
          "author": "Clear-Dimension-6890",
          "text": "Pet peeve about deepeval : it overtakes your system , makes .deepeval directories everyhere",
          "score": 1,
          "created_utc": "2026-02-22 02:09:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pdj9c",
          "author": "Clear-Dimension-6890",
          "text": "If you‚Äôre already in the LangChain ecosystem, LangSmith covers a lot of this ‚Äî tracing, annotation, dataset curation from prod ‚Äî and it‚Äôs a more natural fit. Alternatively, a lightweight custom loop (sample prod traces, run LLM-as-judge scoring, funnel failures back into tests) gets you most of the way without adding a vendor dependency.",
          "score": 1,
          "created_utc": "2026-02-22 02:11:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pvyg4",
          "author": "Disastrous-Royal-829",
          "text": "This matches what we've been seeing researching the agent observability space. The gap between \"passes offline evals\" and \"works in prod\" is where quality silently degrades.\n\nOne pattern that keeps coming up: tracing alone isn't enough. If you can't tie a quality drop back to the exact step in your chain ‚Äî retrieval, prompt, model ‚Äî you're just collecting expensive logs.\n\nCurious ‚Äî are you tracking quality per-chain-step or just at the final output level? Step-level observability seems to catch issues way earlier from what we've seen.",
          "score": 1,
          "created_utc": "2026-02-22 04:16:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q2m9g",
          "author": "Used-Middle1640",
          "text": "I am actually running almost the exact same stack with LangChain and it is honestly a lifesaver. We were struggling with those random production failures too until we plugged in Confident AI to monitor the live traces. The best part for me was definitely the regression testing because now we actually know if a prompt change is going to mess up the retrieval quality before it even hits the main branch. It is way better than just crossing your fingers and hoping the agent behaves after a deployment.",
          "score": 1,
          "created_utc": "2026-02-22 05:05:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qka7c",
          "author": "Far-Run-3778",
          "text": "Following! Hoping to learn something useful",
          "score": 1,
          "created_utc": "2026-02-22 07:40:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mr65s",
          "author": "darkluna_94",
          "text": "The CI + prod monitoring split is key. We started with just offline evals and kept getting blindsided. Now we use a similar setup evals in CI for regressions prod traces feeding back into the test set.",
          "score": 0,
          "created_utc": "2026-02-21 17:29:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8x2mi",
      "title": "Alternative to LangChain memory for agents ‚Äî zero deps, file-based, 1ms search, no API key needed",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r8x2mi/alternative_to_langchain_memory_for_agents_zero/",
      "author": "fourbeersthepirates",
      "created_utc": "2026-02-19 11:43:44",
      "score": 18,
      "num_comments": 2,
      "upvote_ratio": 0.82,
      "text": "I like LangChain for orchestration but always found the memory options limiting ‚Äî ConversationBufferMemory doesn't do real retrieval (just returns recent items), and VectorStoreRetrieverMemory needs an embedding API key and a vector store.\n\nI built antaris-memory as an alternative that sits in the middle: real relevance-ranked retrieval (BM25, not just recency), but with zero external dependencies. No OpenAI key, no Pinecone, no Chroma. Pure Python, file-based, portable.\n\n**Quick comparison:**\n\n||antaris-memory|LangChain Buffer|LangChain VectorStore|\n|:-|:-|:-|:-|\n|Search latency|1.01ms|0.005ms|Depends on provider|\n|Finds relevant (not just recent)|‚úì|‚úó|‚úì|\n|Scales past 1K memories|‚úì (sharding)|‚úó (dumps all to LLM)|‚úì|\n|API key required|None|None|Yes (embeddings)|\n|Persistent storage|‚úì (file-based)|‚úó (in-memory)|Depends on store|\n|WAL + crash recovery|‚úì|‚úó|Depends on store|\n\nIt's part of a larger suite (guard, router, context, pipeline) but antaris-memory works standalone:\n\npython\n\n    pip install antaris-memory\n    \n    from antaris_memory import MemorySystem\n    memory = MemorySystem(workspace=\"./my_agent_memory\")\n    memory.ingest(\"User prefers dark mode and uses Python 3.12\")\n    results = memory.search(\"what does the user prefer?\")\n\n293 tests on antaris-memory,  1,183 tests on the whole suite (0 failures), Apache 2.0. Also ships as an MCP server and an OpenClaw plugin.\n\nAll the modules work together and compliment each other though, and pipeline ties them all together. Take a look at the Git if you want to see the insides.  \n\n\nGitHub: [https://github.com/Antaris-Analytics/antaris-suite](https://github.com/Antaris-Analytics/antaris-suite)\n\nDocs: [https://docs.antarisanalytics.ai](https://docs.antarisanalytics.ai)\n\nSite: [https://antarisanalytics.ai](https://antarisanalytics.ai)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8x2mi/alternative_to_langchain_memory_for_agents_zero/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6a73rr",
          "author": "Delicious-One-5129",
          "text": "actually pretty cool. Zero deps and no API key is a big win, especially for local agents.\n\nBM25 for memory feels underrated too. Nice middle ground between dumb buffer and full vector stack. Gonna check the repo",
          "score": 3,
          "created_utc": "2026-02-19 18:21:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6auiky",
              "author": "fourbeersthepirates",
              "text": "Cool let me know what you think! Have a ton of features to add this week on the way to 3.0. Shared agent memory, sub-agent context and semantic search is next in line.",
              "score": 1,
              "created_utc": "2026-02-19 20:12:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9ur3x",
      "title": "Structure-first RAG with metadata enrichment (stop chunking PDFs into text blocks)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9ur3x/structurefirst_rag_with_metadata_enrichment_stop/",
      "author": "Independent-Cost-971",
      "created_utc": "2026-02-20 13:01:41",
      "score": 13,
      "num_comments": 11,
      "upvote_ratio": 0.84,
      "text": "I think most people are still chunking PDFs into flat text and hoping semantic search works. This breaks completely on structured documents like research papers.\n\nTraditional approach extracts PDFs into text strings (tables become garbled, figures disappear), then chunks into 512-token blocks with arbitrary boundaries. Ask \"What methodology did the authors use?\" and you get three disconnected paragraphs from different sections or papers.\n\nThe problem is research papers aren't random text. They're hierarchically organized (Abstract, Introduction, Methodology, Results, Discussion). Each section answers different question types. Destroying this structure makes precise retrieval impossible.\n\nI've been using structure-first extraction where documents get converted to JSON objects (sections, tables, figures) enriched with metadata like section names, content types, and semantic tags. The JSON gets flattened to natural language only for embedding while metadata stays available for filtering.\n\nThe workflow uses Kudra for extraction (OCR ‚Üí vision-based table extraction ‚Üí VLM generates summaries and semantic tags). Then LangChain agents with tools that leverage the metadata. When someone asks about datasets, the agent filters by content\\_type=\"table\" and semantic\\_tags=\"datasets\" before running vector search.\n\nThis enables multi-hop reasoning, precise citations (\"Table 2 from Methods section\" instead of \"Chunk 47\"), and intelligent routing based on query intent. For structured documents where hierarchy matters, metadata enrichment during extraction seems like the right primitive.\n\nAnyway thought I should share since most people are still doing naive chunking by default.",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1r9ur3x/structurefirst_rag_with_metadata_enrichment_stop/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6eycn4",
          "author": "Independent-Cost-971",
          "text": "I wrote a whole blog about this that goes into the steps with code if anyone's interested:¬†[https://kudra.ai/metadata-enriched-rag-agent-why-document-structure-beats-text-chunking/](https://kudra.ai/metadata-enriched-rag-agent-why-document-structure-beats-text-chunking/)",
          "score": 2,
          "created_utc": "2026-02-20 13:02:09",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6oep6n",
              "author": "patrick9331",
              "text": "I would avoid OCR at all cost, usually it‚Äôs expensive and I would only use it if you have to parse Images. Well that‚Äôs what it‚Äôs therefore I guess. Otherwise just parse it in to markdown and then split it based on the sections.\n\nMicrosoft has an awesome library for that:¬†https://github.com/microsoft/markitdown Have you tried this library? I think that covers most of the use cases and also supports OCR actually. One approach I also like. Often the PDF have stable of content at the beginning. Parse that and use it to split your PDF. And as a very last resort use OCR.",
              "score": 1,
              "created_utc": "2026-02-21 22:37:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6rrjsi",
                  "author": "pillieee",
                  "text": "The link doesn‚Äôt work",
                  "score": 1,
                  "created_utc": "2026-02-22 13:52:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ezxh1",
          "author": "PopPsychological4106",
          "text": "Correct idea. Don't like throwing vlm on it to make it work though. Also table structure understanding is a science for itself.\nWhat labels do you use? How well does toc reconstruction work with vlm?",
          "score": 1,
          "created_utc": "2026-02-20 13:11:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f7lf3",
          "author": "AdRepresentative6947",
          "text": "Yeah had this realisation the other day. Really love your blog gonna implement it into a project I‚Äôve been working on.\n\nDoes the Kundra AI bit run separate as you‚Äôd only have to run the documents in that pipeline once to get the data or when new data arrives ?",
          "score": 1,
          "created_utc": "2026-02-20 13:54:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7xda",
              "author": "AdRepresentative6947",
              "text": "Dw I just saw in the blog, looks slick",
              "score": 1,
              "created_utc": "2026-02-20 13:56:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffj3p",
          "author": "Happy-Fruit-8628",
          "text": "Totally agree. Structure first extraction with metadata filtering makes RAG far more precise and lets you cite exact tables and sections.",
          "score": 1,
          "created_utc": "2026-02-20 14:36:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jelfe",
          "author": "BigDry3037",
          "text": "Docling solves this problem",
          "score": 1,
          "created_utc": "2026-02-21 02:48:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t1iag",
              "author": "ResidentTicket1273",
              "text": "What's the output format that docling generates? Is there a meta-model I can look at to see what the post-docling process generates?",
              "score": 1,
              "created_utc": "2026-02-22 17:34:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6tldeq",
                  "author": "BigDry3037",
                  "text": "It returns a docling document, and maintains relational tabular data representations in different output formats",
                  "score": 1,
                  "created_utc": "2026-02-22 19:06:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rbyd8x",
      "title": "Why flat Vector DBs aren't enough for true LLM memory (and why I'm building a database around \"Gaussian Splats\" instead)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1rbyd8x/why_flat_vector_dbs_arent_enough_for_true_llm/",
      "author": "TallAdeptness6550",
      "created_utc": "2026-02-22 21:33:26",
      "score": 13,
      "num_comments": 12,
      "upvote_ratio": 0.84,
      "text": "Hey everyone,\n\nLately, I've been thinking about the limitations of standard RAG setups. Right now, we treat LLM memory as a flat bag of vectors (whether via Pinecone, Milvus, or FAISS). You embed a chunk of text, throw it in a database, and do a cosine similarity search.\n\nBut human memory doesn‚Äôt work like a flat list of coordinates, and I don't think AGI memory should either. Flat vectors lack¬†*shape, density, and hierarchical context*.\n\nI‚Äôve been experimenting with storing memory chunks as¬†**Gaussian Splats**¬†(nodes with a mean¬†`¬µ`, precision¬†`Œ±`, and concentration¬†`Œ∫`) mapped to a high-dimensional S\\^639 hypersphere.\n\nBy giving embeddings a \"shape\" rather than just a point, the implications for LLM databases are massive:\n\nüß†¬†**1. Dynamic Forgetting & Consolidation (Self-Organized Criticality)**¬†Instead of deleting old embeddings or keeping everything forever, Splats can naturally decay or merge. If an LLM encounters the same concept multiple times, the \"splat\" increases in concentration (`Œ∫`). If a concept is trivial and never accessed, it degrades. The database curates itself like biological memory.\n\nüîç¬†**2. Hierarchical \"Zoom\" for Context (HRM2)**¬†When querying a flat vector DB, you just get the Top-K closest chunks. With splats, you can query at different resolutions. Need a broad summary of a topic? Retrieve the massive, low-density \"parent\" splat. Need a specific quote? Zoom into the high-density \"child\" splat. It turns O(N) search into O(log N).\n\nüíæ¬†**3. 3-Tier Biological Memory Routing**¬†Because splats have metadata about their importance/density, the DB can automatically route them:\n\n* **VRAM (Hot):**¬†Highly active, dense splats ready for instant LLM attention.\n* **RAM (Warm):**¬†Broad conceptual splats.\n* **SSD (Cold):**¬†Low-density, rarely accessed memory.\n\n**Current Status:**¬†I‚Äôve actually managed to get a functional implementation of this working on CPU. By using a Hierarchical Retrieval Engine (HRM2) and Mini-Batch K-Means, I‚Äôm currently benchmarking a¬†**96x speedup**¬†against linear search on 100K splats (`0.99ms`¬†vs¬†`94.7ms`), proving the O(log N) math works.\n\nI‚Äôm currently heavily refactoring the codebase and building Vulkan GPU acceleration before I officially push the full V1.0 to GitHub.\n\nHas anyone else experimented with non-flat, hierarchical, or density-based memory structures for their local LLMs? I‚Äôd love to hear your thoughts on where this architecture might face bottlenecks before I finalize the release.\n\n[https:\\/\\/github.com\\/schwabauerbriantomas-gif\\/m2m-vector-search](https://preview.redd.it/0yzr6ttu64lg1.jpg?width=640&format=pjpg&auto=webp&s=c9602b890ad39acb2101b6c6b10ee07df9aca39a)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1rbyd8x/why_flat_vector_dbs_arent_enough_for_true_llm/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6v1oe4",
          "author": "-DonQuixote-",
          "text": "You said faster, but nothing about the quality of the retrievals. How has that been?",
          "score": 6,
          "created_utc": "2026-02-22 23:36:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v04sw",
          "author": "Don_Ozwald",
          "text": "Conceptually interesting, but have you actually measured it? Beating linear time is not really a meaningful benchmark here.",
          "score": 3,
          "created_utc": "2026-02-22 23:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6umnq9",
          "author": "georgeApuiu",
          "text": "![gif](giphy|5xfcseoKgpAcg)",
          "score": 2,
          "created_utc": "2026-02-22 22:13:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ung12",
              "author": "TallAdeptness6550",
              "text": "Same",
              "score": 1,
              "created_utc": "2026-02-22 22:17:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ujh8o",
          "author": "4b3c",
          "text": "im mind blown, that sounds sick",
          "score": 1,
          "created_utc": "2026-02-22 21:57:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6uktu8",
              "author": "TallAdeptness6550",
              "text": "Thanks man! Really appreciate it. It‚Äôs been a wild ride trying to wrap my head around projecting semantic data onto a hyper-sphere instead of a flat plane, but seeing the O(log N) speedup actually working on CPU made it worth it.\n\nLet me know if you want to poke around the repo when you have time, always looking for feedback on where the math might break at larger scales!",
              "score": 2,
              "created_utc": "2026-02-22 22:04:12",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6ul4pj",
              "author": "TallAdeptness6550",
              "text": "feel free to take a look at the repo \"https://github.com/schwabauerbriantomas-gif/m2m-vector-search\"",
              "score": 2,
              "created_utc": "2026-02-22 22:05:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uutvc",
          "author": "yoyo4581",
          "text": "This is amazing OP.\nI'm really interested if you've dabled with the idea of creating structured databases from this hierarchical splats as you referred to them. \n\nAs you said you can refer to parent splats for summaries of child splats, but what about categorizing data in the parents, and forming something akin to an ontology from derived data.",
          "score": 1,
          "created_utc": "2026-02-22 22:57:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v284n",
          "author": "Affectionate-Leg8133",
          "text": "Would assist with experimenting, do you have a repo?",
          "score": 1,
          "created_utc": "2026-02-22 23:39:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v2uum",
              "author": "TallAdeptness6550",
              "text": "this is the repo [https://github.com/schwabauerbriantomas-gif/m2m-vector-search](https://github.com/schwabauerbriantomas-gif/m2m-vector-search) I'm sorry, but I rely heavily on artificial intelligence for coding. Feel free to give my feed back ",
              "score": 1,
              "created_utc": "2026-02-22 23:42:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7fsnr",
      "title": "Debugging LangChain agents is painful until you can visualize the full trace",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7fsnr/debugging_langchain_agents_is_painful_until_you/",
      "author": "ruhila12",
      "created_utc": "2026-02-17 19:19:32",
      "score": 10,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "I really like working with LangChain, but debugging multi step agents can feel like a black box.\nWhen something breaks, it‚Äôs never obvious where it actually failed.\n\n\nDid retrieval return garbage?\n\n\nDid the reranker strip out the only useful chunk?\n\n\nDid the LLM just hallucinate?\n\n\nOr did the agent get stuck in some weird tool loop?\n\n\nFor the longest time, I was just staring at terminal logs and scrolling through JSON traces trying to piece things together. It technically works‚Ä¶ but once your chain gets even slightly complex, it becomes painful.\n\nRecently, I plugged my chains into a tracing tool (Confident AI) mostly out of frustration. I wasn‚Äôt looking for metrics or anything fancy. I just wanted to see what was happening step by step.\nThe biggest difference for me wasn‚Äôt scoring or dashboards. It was the visual breakdown of each hop in the chain. I could literally see:\n\n\nRetrieval step\n\n\nReranking\n\n\nTool calls\n\n\nLLM responses\n\n\nLatency per step\n\n\nAt one point, I realized my agent wasn‚Äôt ‚Äúfailing‚Äù randomly, it was looping on a specific tool call because my system prompt wasn‚Äôt strict enough about exit conditions. That would‚Äôve taken me way longer to diagnose just from logs.\n\nBeing able to replay a failed interaction and inspect the full flow changed how I debug. It feels less like guessing and more like actual engineering.\n\nCurious how others are handling debugging for multi-step agents. Are you just logging everything, or using something more structured?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7fsnr/debugging_langchain_agents_is_painful_until_you/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5x9ab5",
          "author": "Overall_Insurance956",
          "text": "Use langsmith",
          "score": 5,
          "created_utc": "2026-02-17 19:59:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o623tdf",
              "author": "LuckySwimming8564",
              "text": "This.  It is super easy to setup (just a couple vars in your .env) and it is very detailed.  https://docs.langchain.com/langsmith/trace-with-langchain. ",
              "score": 1,
              "created_utc": "2026-02-18 14:28:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6a3bbh",
                  "author": "sunglasses-guy",
                  "text": "to be fair though literally every tool out there now offers 1-2 line integration with langchain and langgraph, langsmith is expensive as hell",
                  "score": 1,
                  "created_utc": "2026-02-19 18:03:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5x2c9v",
          "author": "pvatokahu",
          "text": "Check out open source monocle2ai from Linux foundation - it does the full tracing with agentic attribute capture built on OpenTelemetry and part of pytest.",
          "score": 2,
          "created_utc": "2026-02-17 19:27:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o658ixy",
          "author": "TheExodu5",
          "text": "Please don‚Äôt interact with the fake-engagement advertising bot.",
          "score": 2,
          "created_utc": "2026-02-18 23:08:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o678rvy",
              "author": "NotAHost",
              "text": "Yup just search author:username to see all their spam.",
              "score": 1,
              "created_utc": "2026-02-19 06:42:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o61sh9d",
          "author": "Informal_Tangerine51",
          "text": "Yeah, once a chain has retrieval + reranking + tools, ‚Äúprint the logs‚Äù stops being a debugging strategy and starts being archaeology. A good trace view pays for itself fast, especially when you can replay a run and see exactly where the agent diverged or started looping.\n\nOne thing I‚Äôd add (even if you keep the fancy UI) is a small ‚Äústructured trace contract‚Äù: every hop logs inputs/outputs, tool args, and a reason code for why the agent continued or stopped. Then you can write regression tests off real failures: ‚Äúthis tool loop should terminate‚Äù or ‚Äúthis retrieval query should return at least one relevant chunk,‚Äù instead of hoping prompts stay stable.\n\nWe‚Äôre working on this at Clyra (open source here): [https://github.com/Clyra-AI](https://github.com/Clyra-AI)",
          "score": 1,
          "created_utc": "2026-02-18 13:28:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o624842",
          "author": "93simoon",
          "text": "Use langfuse, it's lang Smith but foss",
          "score": 1,
          "created_utc": "2026-02-18 14:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o625evm",
          "author": "Revolutionary-Bet-58",
          "text": "I'm biased but I can recommend you to check out [inkog.io](http://inkog.io) , you can insert your LangChain agent in there and get feedback directly to solve some issues that you will face before debugging like infinite loops, tool calls etc . It will also recommend you how to fix the problems with examples, or you can just use the Inkog MCP and let Claude fix it for you :D\n\nHappy to sit down with you if you have any questions ",
          "score": 1,
          "created_utc": "2026-02-18 14:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o628qhb",
          "author": "penguinzb1",
          "text": "trace replay is great for diagnosing what happened, but the tool loop you described, where the agent ignored exit conditions, is also the kind of thing that shows up before users see it if you run it against adversarial or edge case scenarios first. what we've found is that simulating these before deployment catches them earlier than any trace tool can, because you're finding the failure before the first incident.",
          "score": 1,
          "created_utc": "2026-02-18 14:52:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9kx8o",
      "title": "I built an open-source library on top of LangChain for batch-transforming structured data through LLMs",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9kx8o/i_built_an_opensource_library_on_top_of_langchain/",
      "author": "papipapi419",
      "created_utc": "2026-02-20 03:50:54",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "The problem: every project I worked on needed the same thing ‚Äî take rows of data, run them through an LLM, get back validated Pydantic models. I kept rewriting batching, retries, concurrency, and row-ordering logic.\n\nSo I packaged it up: **smelt-ai**.\n\nWhat it handles under the hood:\n\n* **Batching** ‚Äî splits rows into configurable batch sizes\n* **Concurrency** ‚Äî async semaphore-based, no threads\n* **Retries** ‚Äî exponential backoff for 429s, 5xx, validation errors\n* **Row ordering** ‚Äî injects row\\_id, validates it, reorders results to match input\n* **Structured output** ‚Äî uses `with_structured_output` so you get typed Pydantic models back\n* **Metrics** ‚Äî token counts, timing, retry stats per run\n\nWorks with any LangChain provider (OpenAI, Anthropic, Gemini, etc.) since it uses `init_chat_model` under the hood.\n\n`pip install smelt-ai`\n\nGitHub: [https://github.com/Cydra-Tech/smelt-ai](https://github.com/Cydra-Tech/smelt-ai)  \nDocs: [https://cydra-tech.github.io/smelt-ai/](https://cydra-tech.github.io/smelt-ai/)\n\nWould love feedback from the LangChain community. What would you add?\n\nEdit: Grammer",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r9kx8o/i_built_an_opensource_library_on_top_of_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r78a13",
      "title": "Run untrusted code locally in LangChain using WASM sandboxes",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r78a13/run_untrusted_code_locally_in_langchain_using/",
      "author": "Tall_Insect7119",
      "created_utc": "2026-02-17 15:00:43",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "Lately I've seen a lot of cloud-based solutions for running untrusted code. But in reality, you can do it safely on your local machine without sending anything to the cloud.\n\n**Quick context**: When an AI generates code to perform a task, executing it directly could be dangerous for your host system. Sandboxing helps protect your host from any issues that untrusted code might cause.\n\nI built an open-source runtime that isolates code using WebAssembly sandboxes. You can plug it into an existing project in just a few lines:\n\n    from capsule import run\n    \n    result = await run(\n        file=\"./capsule.py\",\n        args=[\"code to execute\"]\n    ]\n\nThen you define your sandboxed logic like this:\n\n    from capsule import task\n    \n    @task(name=\"main\", compute=\"MEDIUM\", ram=\"512mb\")\n    def main(code: str) -> str:\n        \"\"\"Execute untrusted code in an isolated sandbox\"\"\"\n        return exec(code)\n\nThe code (task) runs in its own isolated WASM sandbox. You can define multiple tasks with different limits and even run it standalone.\n\nI put together an example integrated with LangChain here: [https://github.com/mavdol/capsule/tree/main/examples/python/langchain-agent](https://github.com/mavdol/capsule/tree/main/examples/python/langchain-agent)\n\nAnd here‚Äôs the main repo: [https://github.com/mavdol/capsule](https://github.com/mavdol/capsule)\n\nWould love to hear your feedback or thoughts !",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r78a13/run_untrusted_code_locally_in_langchain_using/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5vtc83",
          "author": "vansterdam_city",
          "text": "I‚Äôm absolutely in favor of local sandboxes for agentic coding. There is no way I‚Äôm turning on the super unsafe mode on my local userspace with all my personal creds, but without doing so it‚Äôs super annoying. I like codex web for that reason, but it has limitations.\n\nI‚Äôm curious, why not dev containers? Containers are already a mature platform for creating isolation.",
          "score": 2,
          "created_utc": "2026-02-17 15:51:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w3paq",
              "author": "Tall_Insect7119",
              "text": "That's a valid question. Currently, containers are great for safe application isolation, but they share the host kernel, which could be a risk for untrusted code, even if it's hard to exploit in practice. The real difference is overhead. WASM is lighter than a container, and after the cold start, it's about 100x faster than Docker, for example.\n\nThe only limitation for now is that C extensions (like numpy) aren't supported yet, so it really depends on the use case.",
              "score": 0,
              "created_utc": "2026-02-17 16:43:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5z08jl",
          "author": "ChanceKale7861",
          "text": "This. Those who have done security work, would do the same I think.",
          "score": 2,
          "created_utc": "2026-02-18 01:20:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61vywp",
          "author": "peregrinefalco9",
          "text": "un arbitrary code with the agent's full permissions\" which is terrifying in production.\n\n  \nThe key things to validate with any sandbox approach: can the sandboxed code make network requests? Can it read the filesystem outside its sandbox? What happens when the LLM generates code that tries to escape the sandbox (because it will ‚Äî not maliciously, just because the model doesn't understand sandbox boundaries)?\n\n  \nWASM's capability-based security model is actually well-suited for this. You can explicitly grant only the capabilities the code needs ‚Äî file access to specific paths, network access to specific hosts, memory limits. The attack surface is much smaller than a container and the startup overhead is negligible.\n\n  \nCurious how this handles cases where the agent needs to install dependencies at runtime. That's usually where sandboxed execution falls apart in practice.",
          "score": 2,
          "created_utc": "2026-02-18 13:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61y5ge",
          "author": "Informal_Tangerine51",
          "text": "This is a great direction. ‚ÄúLocal, sandboxed execution‚Äù is exactly what you want for agent-generated code, and WASM gives you a cleaner isolation boundary than ‚Äújust run it in a venv and hope.‚Äù The ergonomic API matters too, because if it‚Äôs annoying people will bypass it.\n\nThe big questions I‚Äôd want answered are around escape hatches: what‚Äôs the default filesystem/network surface, how do you handle timeouts and memory limits deterministically, and can you produce an audit trail of what ran (hash of code, args, resource limits, stdout/stderr) for later debugging. In practice, a sandbox without good observability becomes a new kind of black box.\n\nWe‚Äôre working on this at Clyra (open source here): [https://github.com/Clyra-AI](https://github.com/Clyra-AI)",
          "score": 2,
          "created_utc": "2026-02-18 13:58:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7vn7p",
      "title": "I can‚Äôt figure out how to ask LLM to write an up-to-date LangChain script with the latest docs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7vn7p/i_cant_figure_out_how_to_ask_llm_to_write_an/",
      "author": "gowtham150",
      "created_utc": "2026-02-18 06:34:18",
      "score": 8,
      "num_comments": 16,
      "upvote_ratio": 0.75,
      "text": "Whenever I ask claude or chatgpt to write me a simple langchain agent - even the very simple ones - it always gives me a script with outdated libraries. I tried using claude with context7mcp and langchain docs mcp - still i get out of date obsolete script with deprecated libraries. Even for a simple use case i have to go to langchain docs and get it. Its frustrating to ask LLM to write a sample code and later on to find that its deprecated. How you are you guys solving this problem.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7vn7p/i_cant_figure_out_how_to_ask_llm_to_write_an/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o60jchc",
          "author": "mdrxy",
          "text": "Would encourage cloning the repos locally and letting your agent know that it can traverse the source code in your filesystem!",
          "score": 7,
          "created_utc": "2026-02-18 07:22:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63mjh1",
              "author": "orthogonal-ghost",
              "text": "This is a fantastic idea",
              "score": 1,
              "created_utc": "2026-02-18 18:38:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60tj3n",
          "author": "gowtham150",
          "text": "The general observation is that if i use claude code with context 7 MCP and ask it to write a a simple agent with Langchain it gives me a script most of the time with outdated versions and libraries. Same with chatgpt. So it's becoming extremely difficult to just test out a feature.",
          "score": 3,
          "created_utc": "2026-02-18 08:57:01",
          "is_submitter": true,
          "replies": [
            {
              "id": "o61bc9k",
              "author": "Individual_Day_9508",
              "text": "Use a CLAUDE.md or AGENTS.md file in your workspace to set a strict rule enforcing Langchain 1.x syntax. If you pair that explicit instruction with context 7, it completely fixes the outdated library issue.",
              "score": 1,
              "created_utc": "2026-02-18 11:34:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o61ci16",
                  "author": "gowtham150",
                  "text": "Ok let me check that. Thanks for sharing",
                  "score": 1,
                  "created_utc": "2026-02-18 11:44:01",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60eznz",
          "author": "gaureshai",
          "text": "Very hard.  Because langchain docs are also outdated.",
          "score": 2,
          "created_utc": "2026-02-18 06:44:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60zbec",
              "author": "NoleMercy05",
              "text": "Not true anymore",
              "score": 2,
              "created_utc": "2026-02-18 09:51:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6179bd",
                  "author": "gaureshai",
                  "text": "Well then it's good. I had really hard time in js docs. Will try it again then.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:01:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60jaqu",
              "author": "mdrxy",
              "text": "Not sure what you mean -- can you point to specific pages? Will flag with the team",
              "score": 1,
              "created_utc": "2026-02-18 07:22:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60l0t8",
          "author": "Character_Leg1134",
          "text": "Use chat.langchain.com \nIts their own bot \nWhich can give you the code with updated libraries",
          "score": 2,
          "created_utc": "2026-02-18 07:38:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tdxv",
              "author": "gowtham150",
              "text": "Will try this",
              "score": 1,
              "created_utc": "2026-02-18 08:55:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o61cjj2",
              "author": "gowtham150",
              "text": "This has been working well so far. Thanks for sharing.",
              "score": 1,
              "created_utc": "2026-02-18 11:44:20",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o63c2w2",
              "author": "rk_11",
              "text": "Second this",
              "score": 1,
              "created_utc": "2026-02-18 17:52:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62l7az",
          "author": "notAllBits",
          "text": "That is the cost of unstable conventions (API/classes) in coding. If LLMs cannot be confident about their memory, they spoil it for everyone",
          "score": 1,
          "created_utc": "2026-02-18 15:51:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60qx1v",
          "author": "kolmar41k",
          "text": "If you using and IDE, try using an MCP called 'context7', it provides up to date docs including langgraph/langchain to your llm",
          "score": 1,
          "created_utc": "2026-02-18 08:32:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tczj",
              "author": "gowtham150",
              "text": "I already did, like i mentioned in my post. I used context 7 and Langchain has its own mc as well",
              "score": 1,
              "created_utc": "2026-02-18 08:55:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ra2b0r",
      "title": "expectllm: A lightweight alternative when you just need pattern matching",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ra2b0r/expectllm_a_lightweight_alternative_when_you_just/",
      "author": "Final_Signature9950",
      "created_utc": "2026-02-20 17:51:55",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I built a small library called **expectllm**.\n\n\n\nIf you've ever thought \"I just need to extract a number from an LLM response, why am I importing 50 modules?\" - this might be for you.\n\n\n\nIt treats LLM conversations like classic expect scripts:\n\n\n\nsend ‚Üí pattern match ‚Üí branch\n\n\n\nYou explicitly define what response format you expect from the model.\n\nIf it matches, you capture it.\n\nIf it doesn't, it fails fast with an explicit ExpectError.\n\n\n\nExample:\n\n    from expectllm import Conversation\n    \n    c = Conversation()\n    \n    c.send(\"Review this code for security issues. Reply exactly: 'found N issues'\")\n    c.expect(r\"found (\\d+) issues\")\n    \n    issues = int(c.match.group(1))\n    \n    if issues > 0:\n       c.send(\"Fix the top 3 issues\")\n\n\n\nCore features:\n\n\\- expect\\_json(), expect\\_number(), expect\\_yesno()\n\n\\- Regex pattern matching with capture groups\n\n\\- Auto-generates format instructions from patterns\n\n\\- Raises explicit errors on mismatch (no silent failures)\n\n\\- Works with OpenAI and Anthropic (more providers planned)\n\n\\- \\~365 lines of code, fully readable\n\n\\- Full type hints\n\n\n\nRepo: [https://github.com/entropyvector/expectllm](https://github.com/entropyvector/expectllm)\n\nPyPI: [https://pypi.org/project/expectllm/](https://pypi.org/project/expectllm/)\n\n\n\nIt's not designed to replace LangChain or similar frameworks - those are great when you need the full toolbox. This is for when you don't. Minimalism, control, transparent flow.\n\n\n\nWould appreciate feedback:\n\n\\- Is this approach useful in real-world projects?\n\n\\- What edge cases should I handle?\n\n\\- Where would this break down?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ra2b0r/expectllm_a_lightweight_alternative_when_you_just/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r79j1x",
      "title": "Don't Prompt Your Agent for Reliability ‚Äî Engineer It",
      "subreddit": "LangChain",
      "url": "https://www.aiyan.io/blog/engineer-agent-reliability/",
      "author": "NetworkFlux",
      "created_utc": "2026-02-17 15:47:11",
      "score": 6,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r79j1x/dont_prompt_your_agent_for_reliability_engineer_it/",
      "domain": "aiyan.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5vspec",
          "author": "NetworkFlux",
          "text": "I've spent the past year at my company building a data engineering agent for non-technical users. I rearchitected it three times, from a rigid state machine, to a multi-agent orchestrator, to a single general-purpose agent with lightweight tools. Each time, the system actually got simpler and more reliable. Wrote up the full evolution and the two biggest lessons I took away!",
          "score": 2,
          "created_utc": "2026-02-17 15:48:21",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o629lt8",
          "author": "penguinzb1",
          "text": "how do you quantitatively verify that the agent improves when the complexity is changed? when I'm building agents sometimes the more simple agents seem more reliable but it turns out they just have a reduced action space / problem-solving area, and refuse to solve many things. we use simulations to gauge the agent behaviour and then grade it, which is a bit of a newer thing ",
          "score": 1,
          "created_utc": "2026-02-18 14:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62mjs3",
              "author": "NetworkFlux",
              "text": "That's a good point and is probably worth for me to write about. But in short, we're actually doing something very similar.\n\nWe have \"simulated user\" LLMs with different personas defined in config files. They talk to our agent until the simulated user decides to end the conversation (goal reached), or if certain deterministic criteria are met, like max # of turns or state reached.\n\nFor judging, we have a suite of heuristic judges (checking for tool calls, checking text for data leakage, etc.) and an LLM judge which is given a precise pass/fail criteria.\n\nFinally we compute a weighted average based on the passes and fails and assign a score to the simulation after running enough for a statistically significant result.\n\nAre you doing something similar?",
              "score": 1,
              "created_utc": "2026-02-18 15:57:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64awwg",
          "author": "ScArL3T",
          "text": "Do your tools do any heavy lifting in regards to semantic understanding and if yes how do you achieve it?  \nLater in the article you mention about having a simple general agent which in turn calls some well defined tools. In that diagram you showcased the possibility of having a sub-agent -- so they are not completely gone?\n\nI'm kind of interested in the technicalities a bit and diving a bit more in-depth into your architecture.  \nI'm also interested how your initial user query (2 edit requests and 1 question in the same message) gets handled by the generic agent now that it is specifically NOT instructed to deconstruct the user query. Do you just rely on the model's intelligence? And if yes, what model are you using.\n\nThank you!",
          "score": 1,
          "created_utc": "2026-02-18 20:30:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69h8kd",
              "author": "NetworkFlux",
              "text": "Right, in the last architecture version we still kept the dataflow (code) generation sub-agent because its system prompt contains a lot of niche guidance on data pipeline patterns that wouldn't make a ton of sense polluting the main agent's context.\n\nThat being said, with code and MCP execution in sandbox being refined (https://www.anthropic.com/engineering/code-execution-with-mcp), I think this may not hold true for long. I can envision a future where agents perform most of its tasks (including tool-calling) within a code sandbox, backed by a filesystem (its \"environment\").\n\n\\-\n\nRe general agent - we're achieving good performance with just the open-source tool-calling models. And I think the insight I can provide is most helpful broadly:\n\nMy key learning is that deconstructing the user query, like you mention, isn't the goal, but rather invoking the necessary side-effects (tools).\n\nIt was also very enlightening thinking about the final objects/artifacts we actually *want* out of the agent. LLMs act greedily, so making sure our tools don't elongate the path to the goal was very helpful.\n\nI.e., instead of tools that \"set\" certain objects, just make those objects inputs to the next tool in the dependency chain",
              "score": 2,
              "created_utc": "2026-02-19 16:17:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8ngzq",
      "title": "üöÄ Launch Idea: A Curated Marketplace for AI Agents, Workflows & Automations",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r8ngzq/launch_idea_a_curated_marketplace_for_ai_agents/",
      "author": "NoSwimming4210",
      "created_utc": "2026-02-19 02:46:10",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Right now, discovering reliable AI agents and automation systems is messy ‚Äî too many scattered tools, too little trust, and almost no true curation.\n\nThe vision:\nA single marketplace where businesses and creators can find tested, ready-to-deploy AI agents, structured workflows, and powerful automations ‚Äî all organized by real-world use cases.\n\nWhat makes it different:\n‚úîÔ∏è Curated listings ‚Äî quality over quantity\n‚úîÔ∏è No-code + full-code solutions in one place\n‚úîÔ∏è Verified workflows that actually work\n‚úîÔ∏è Builders can monetize their systems\n‚úîÔ∏è Companies adopt AI faster without technical chaos\n\nThis isn‚Äôt another tool directory ‚Äî it‚Äôs an execution layer for applied AI.\n\nLooking for:\n‚Ä¢ Early adopters who want to try curated AI workflows\n‚Ä¢ Builders interested in listing their agents\n‚Ä¢ Feedback on must-have features before MVP\n\nComment or connect if you want to be part of shaping it.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8ngzq/launch_idea_a_curated_marketplace_for_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6a7lfx",
          "author": "Delicious-One-5129",
          "text": "A curated marketplace could save so much time - finding reliable AI workflows is such a headache right now. Would definitely be interested in testing or giving feedback.",
          "score": 1,
          "created_utc": "2026-02-19 18:23:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lbxby",
          "author": "Traditional-Carry409",
          "text": "AI slop post",
          "score": 1,
          "created_utc": "2026-02-21 12:41:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6lceab",
              "author": "NoSwimming4210",
              "text": "Hey its not a Ai Slop post we are actually being constantly improving the idea, behind a team of people with professors are working on it. This is a part to know the peoples response on it.",
              "score": 1,
              "created_utc": "2026-02-21 12:44:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8q0jm",
      "title": "LangChain's Deep Agents scores 5th on Terminal Bench 2",
      "subreddit": "LangChain",
      "url": "https://x.com/Vtrivedy10/status/2023805578561060992",
      "author": "mdrxy",
      "created_utc": "2026-02-19 04:49:30",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8q0jm/langchains_deep_agents_scores_5th_on_terminal/",
      "domain": "x.com",
      "is_self": false,
      "comments": [
        {
          "id": "o66xh90",
          "author": "Material_Policy6327",
          "text": "Any non x link",
          "score": 1,
          "created_utc": "2026-02-19 05:11:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6735v5",
              "author": "mdrxy",
              "text": "[https://blog.langchain.com/improving-deep-agents-with-harness-engineering/](https://blog.langchain.com/improving-deep-agents-with-harness-engineering/)",
              "score": 2,
              "created_utc": "2026-02-19 05:55:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6b1wa",
      "title": "What Are DeepAgents in LangChain?",
      "subreddit": "LangChain",
      "url": "https://www.blog.qualitypointtech.com/2026/02/what-are-deepagents-in-langchain.html",
      "author": "qptbook",
      "created_utc": "2026-02-16 14:28:22",
      "score": 6,
      "num_comments": 12,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r6b1wa/what_are_deepagents_in_langchain/",
      "domain": "blog.qualitypointtech.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5pfckh",
          "author": "justanemptyvoice",
          "text": "A buzzword\n\nSaved you a click",
          "score": 2,
          "created_utc": "2026-02-16 16:24:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r0wqa",
              "author": "93simoon",
              "text": "Opened the post to comment the same thing üòÇ",
              "score": 1,
              "created_utc": "2026-02-16 20:55:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5pmlf6",
              "author": "Niightstalker",
              "text": "No a specific concepts of agents that is worth reading but ok",
              "score": 0,
              "created_utc": "2026-02-16 16:57:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rzw0k",
                  "author": "mamaBiskothu",
                  "text": "A concept introduced a year too late into the most popular framework in the field. My team Interview questuon is to ask what their thought is on langchain and to reject anyone saying positive things.",
                  "score": 1,
                  "created_utc": "2026-02-16 23:57:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61sng4",
          "author": "Puzzled_Celery_6190",
          "text": "TLDR: compare to normal ReAct agent, deep agent contains a detailed system prompt, plan tool, sub agent plus an external file system (so that you don‚Äôt put everything in context/prompt). Take writing paper for example, it could write paper page by page or sentence by sentence, write as long as you want.",
          "score": 1,
          "created_utc": "2026-02-18 13:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68p8lh",
          "author": "kalyugira",
          "text": "It does not even follow its own internal langchain standards - ex. StateSchema concept is entirely missing that is part of react agent. You are better off taking the middlewares and use them if you are using langchain.",
          "score": 1,
          "created_utc": "2026-02-19 13:53:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rarwc6",
      "title": "My LangChain agent kept ignoring its own rules. Took me three days to figure out why.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1rarwc6/my_langchain_agent_kept_ignoring_its_own_rules/",
      "author": "Acrobatic_Task_6573",
      "created_utc": "2026-02-21 14:03:43",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.69,
      "text": "Built a personal assistant agent on top of LangChain about two months ago. It worked fine at first. Then it started skipping steps I had explicitly told it to skip, making API calls it was never supposed to make. Once it tried to respond to a message as a completely different persona.\n\nI spent two days tweaking the system prompt. Different model temperatures. Re-read the LangChain docs twice. Nothing worked consistently.\n\nTurned out the problem wasn't the code or the model at all. It was the config files. I had a rough SOUL.md and a few notes in AGENTS.md but they were inconsistent, half-finished, and contradicting each other in spots I hadn't noticed.\n\nSomeone pointed me to Lattice OpenClaw. You answer questions about what your agent is supposed to do, what it should never do, how it handles memory and communication, and it generates SOUL.md, AGENTS.md, SECURITY.md, MEMORY.md, and HEARTBEAT.md in one shot. Five minutes.\n\nNight and day difference. Same model, same code, stable for three weeks now just from having coherent config files.\n\nAnyone else hit this? Wondering if it's a common blind spot or just me not paying enough attention early on.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1rarwc6/my_langchain_agent_kept_ignoring_its_own_rules/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6lyb8m",
          "author": "mzinz",
          "text": "Wait, was this OpenClaw running a langchain agent?",
          "score": 3,
          "created_utc": "2026-02-21 15:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pp7br",
          "author": "doncheeto12",
          "text": "Honestly there are too many .md files now. Some repos at my company are drowning in Claude.md, agents.md, readme.md, soul.md, a million different docs Md files. It‚Äôs out of hand and like your experience, proves very hard to debug. Crazy how unscientific applying AI is.",
          "score": 1,
          "created_utc": "2026-02-22 03:29:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7uhed",
      "title": "stopped using flaky youtube loaders and finally fixed my rag accuracy",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7uhed/stopped_using_flaky_youtube_loaders_and_finally/",
      "author": "straightedge23",
      "created_utc": "2026-02-18 05:29:02",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "i‚Äôve been building a RAG pipeline for a technical documentation project, and the biggest bottleneck was the \"garbage in, garbage out\" problem with youtube transcripts. i started with the standard community loaders, but the formatting was so messy that the embeddings were coming out low-quality, and the retrieval was hitting all the wrong chunks.\n\ni finally swapped out my custom scraping logic for [transcript api](https://transcriptapi.com/) as a direct source.\n\n**the difference it made for the chain:**\n\n* **cleaner chunks:** the api gives me a clean, stripped string. without the html junk and weird timestamps, my recursive character text splitter actually creates coherent chunks instead of breaking in the middle of a sentence.\n* **metadata integrity:** since i can pull structured segments with start times, i can actually map my vector metadata back to the exact second in the video. when the user asks a question, the agent can cite the exact timestamp in the source.\n* **reliability at scale:** i‚Äôm not getting blocked or hitting 403 errors during batch processing anymore. it treats the transcript like a stable production data source rather than a side-project hack.\n\nif you‚Äôre building agents that need to \"reason\" over technical tutorials or long-form lectures, don't waste your context window on garbage formatting. once the input pipe is clean, the \"hallucinations\" drop significantly because the model actually has the full, un-mangled context.\n\ncurious if anyone else has moved away from the standard loaders to a dedicated api for their ingestion layer?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7uhed/stopped_using_flaky_youtube_loaders_and_finally/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o61t5yc",
          "author": "Informal_Tangerine51",
          "text": "Yep, this is the unsexy part of RAG that matters most: loader quality and normalization beats clever prompting. Once the text is clean, chunk boundaries make sense, and your embeddings stop ‚Äúsmearing‚Äù unrelated concepts together.\n\nIf you haven‚Äôt already, a couple small additions tend to pay off: normalize casing/whitespace consistently, strip repeated boilerplate (‚Äúsubscribe‚Äù, intros), and store both the raw segment + the cleaned segment so you can always re-render citations. I also like adding a lightweight ‚Äúchunk health‚Äù check (avg chars, sentence breaks, % non-alpha) so bad transcripts get quarantined before they pollute the index.\n\nTimestamp metadata is a killer feature too, because it makes answers verifiable. Are you also storing a stable video ID + language track, and handling ‚Äúupdated transcripts‚Äù (so your vector store can reindex without breaking existing citations)?",
          "score": 1,
          "created_utc": "2026-02-18 13:31:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64hsw1",
          "author": "One_Presentation7722",
          "text": "clean transcripts improve rag pipelines ScraperCity offers structured data with unlimited downloads.",
          "score": 1,
          "created_utc": "2026-02-18 21:02:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8532g",
      "title": "Open-source agent templates with built-in x402 micropayments, no API keys needed",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/3komg1v7o9kg1.jpeg",
      "author": "Artificial-Lab",
      "created_utc": "2026-02-18 14:54:07",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1r8532g/opensource_agent_templates_with_builtin_x402/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1racwma",
      "title": "How are you guys tracking costs per agentic workflow run in production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1racwma/how_are_you_guys_tracking_costs_per_agentic/",
      "author": "Top-Seaweed970",
      "created_utc": "2026-02-21 00:43:09",
      "score": 3,
      "num_comments": 6,
      "upvote_ratio": 0.81,
      "text": "",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1racwma/how_are_you_guys_tracking_costs_per_agentic/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6jzkmu",
          "author": "StarThinker2025",
          "text": "Per-call token logging + run_id tagging\nWe compute cost from model pricing table and aggregate per workflow execution\n\nWithout step-level attribution, agent costs become impossible to debug in prod",
          "score": 4,
          "created_utc": "2026-02-21 05:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lnfjf",
          "author": "Gold_Emphasis1325",
          "text": "Strategic usage checks server-side and locally throughout pipeline/orchestration.",
          "score": 2,
          "created_utc": "2026-02-21 13:59:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p8r8x",
          "author": "Top-Seaweed970",
          "text": "Are there any tools that can do this automatically and show me everything on a dashboard?",
          "score": 1,
          "created_utc": "2026-02-22 01:41:03",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6sc00f",
          "author": "Lazy-Kangaroo-573",
          "text": "Try Langfuse it will show you the tracings, api cost and tokens , P95 Latencies and many more features like Evaluation scores.",
          "score": 1,
          "created_utc": "2026-02-22 15:40:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}