{
  "metadata": {
    "last_updated": "2026-02-22 02:59:49",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 88,
    "file_size_bytes": 107977
  },
  "items": [
    {
      "id": "1r8k1qu",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/wo2lnacmfckg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 00:12:36",
      "score": 135,
      "num_comments": 18,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r8k1qu/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o666sm6",
          "author": "Reasonable-Froyo3181",
          "text": "Ok",
          "score": 3,
          "created_utc": "2026-02-19 02:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66anvg",
              "author": "DeathShot7777",
              "text": "Thanks",
              "score": 2,
              "created_utc": "2026-02-19 02:44:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67jxom",
          "author": "Msense_",
          "text": "Impressive!",
          "score": 3,
          "created_utc": "2026-02-19 08:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67k739",
              "author": "DeathShot7777",
              "text": "‚ù§Ô∏è",
              "score": 1,
              "created_utc": "2026-02-19 08:25:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67ka5m",
          "author": "DeathShot7777",
          "text": "Thanks for all the github stars idk where they r coming from. But holly shit 496 stars üò≠",
          "score": 2,
          "created_utc": "2026-02-19 08:26:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o65ozs6",
          "author": "VanillaOk4593",
          "text": "Obsidian on steroids!",
          "score": 1,
          "created_utc": "2026-02-19 00:39:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65zx0p",
              "author": "DeathShot7777",
              "text": "üòÅ",
              "score": 1,
              "created_utc": "2026-02-19 01:42:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66irxh",
          "author": "SithLordRising",
          "text": "Very cool. Working on a thinking engine myself",
          "score": 1,
          "created_utc": "2026-02-19 03:33:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o677mug",
              "author": "DeathShot7777",
              "text": "Thanks. What's your approach?",
              "score": 1,
              "created_utc": "2026-02-19 06:32:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o696gin",
                  "author": "ble1901",
                  "text": "I'm focusing on integrating neural networks with a more interactive user interface. The goal is to make it easier for users to experiment and see real-time results. What about your thinking engine?",
                  "score": 2,
                  "created_utc": "2026-02-19 15:25:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6bzo69",
                  "author": "SithLordRising",
                  "text": "Just spent time going through the GitNexus codebase in detail. Really impressive work. A few things stood out:\n\n\\- The phased ingestion pipeline is cleanly separated - structure ‚Üí parse ‚Üí resolve ‚Üí relate ‚Üí cluster ‚Üí trace ‚Üí embed. That's a strong pattern.\n\n\\- Leiden community detection on the relationship graph is a smart choice. The heuristic labelling from folder/naming patterns is pragmatic.\n\n\\- Process tracing via BFS from scored entry points is elegant. The confidence tiers on CALLS edges (import-resolved ‚Üí same-file ‚Üí fuzzy-global) show good engineering judgment.\n\n\\- RRF for combining BM25 + semantic search is the right call over trying to normalize different score scales.\n\n\\- KuzuDB as the embedded graph store is an interesting choice - embedded like SQLite but with native Cypher traversal.\n\nI'm working on a knowledge infrastructure project where we compile documents - academic papers, technical standards, legal texts - into structured knowledge graphs with explicit relationships (prerequisites, dependencies, contradictions between sources). Think of it as applying the same intuition you've had about code to text: raw documents are to knowledge what source files are to architecture. Both need to be parsed into structured units and their relationships made explicit before you can reason about them properly. One of the differences we have is contradictions, something code typically fixes at compile.\n\nYour work has been genuinely useful for validating some architectural directions we've been considering, particularly around graph storage and hybrid search. The parallel between tracing execution flows through code and tracing reasoning chains through knowledge is  closer than I expected.\n\nGreat project. Following with interest.",
                  "score": 1,
                  "created_utc": "2026-02-19 23:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6kg1jn",
          "author": "cleverhoods",
          "text": "wow",
          "score": 1,
          "created_utc": "2026-02-21 07:40:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9u4uj",
      "title": "Noob question... is LangChain still relevant?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9u4uj/noob_question_is_langchain_still_relevant/",
      "author": "Odd-Aside456",
      "created_utc": "2026-02-20 12:31:58",
      "score": 90,
      "num_comments": 67,
      "upvote_ratio": 0.92,
      "text": "I'm planning to build an AI personal assistant. First capabilities it will need include the standard assistant stuff: calendar, contracts, email, tasks, etc. But EVENTUALLY I'd like to build it up to be able to do autonomous work to along the lines of research, building tools, etc, and acting more like an employee than an agent (similarish to the whole OpenClaw hype, but much more on rails and personalized). Doing some research on tech stacks with LLMs, I keep getting pointed to LangChain and / or LangGraph. However, doing some Googling of my own, I keep finding people who say they've moved away from LangChain or that it's generally disliked (which I find hard to fully believe). Given the rapid pace at which new AI technologies are being developed, is LangChain / LangGraph still hyper-relevant today, and applicable for my end goal?",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1r9u4uj/noob_question_is_langchain_still_relevant/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6f8r13",
          "author": "Friendly-Ask6895",
          "text": "LangChain gets a lot of hate but IMO most of it is from people who used it like a year ago when the API was changing every 2 weeks and the abstractions were pretty leaky. It's matured a lot since then. LangGraph specifically is actually really solid for the kind of agent workflows you're describing, especially when you need things like conditional branching, human-in-the-loop steps, and persistent state across conversations.\n\nThat said, for the basic personal assistant stuff (calendar, email, etc) you could honestly start with just raw API calls + function calling and get pretty far. The place where LangChain/LangGraph really starts paying off is when you want the agent to plan multi-step tasks, recover from errors, and maintain context across tool calls. Which sounds like exactly where you want to end up.\n\nI'd say start simple with direct API calls so you actually understand whats happening under the hood, then bring in LangGraph when you need the orchestration layer. Going straight to a framework before you understand the basics is how people end up confused when something breaks.",
          "score": 59,
          "created_utc": "2026-02-20 14:00:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsrgi",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 3,
              "created_utc": "2026-02-20 15:40:51",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6h69er",
              "author": "mzinz",
              "text": "In each of these scenarios (direct API calls with LLM; LangGraph agents) - what are the common ways for invoking? Dependent on how you want the trigger to occur I assume, but what are the most common setups?\n\nThinking about things like:\n\n* checking email occasionally and sending a notification when an urgent email is identified (probably Cron?)\n* work scenario: a ticket is cut when a document is ready for review/approval. Need a way to monitor for tickets of that type to come in, then invoke the agent/call in some way\n\n",
              "score": 2,
              "created_utc": "2026-02-20 19:27:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6gwqop",
              "author": "Singularity-42",
              "text": "Does LangChain support image models now?\n\nI've tried it for a real production project in early 2023 (and it was the TS version) and I was so disgusted by the experience that I swore I'd never go back to Langchain again. The only value I ever got out of it was vendor consolidation. But just cumbersome as fuck.",
              "score": 3,
              "created_utc": "2026-02-20 18:43:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6idatx",
              "author": "FMWizard",
              "text": "Code base is still spaghetti. Pedantic AI is super clean and reliable and their API is stable ie they are real software engineers.",
              "score": 1,
              "created_utc": "2026-02-20 23:04:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6iza49",
                  "author": "Budget_Bar2294",
                  "text": "the worst part of my amazing job is dealing with this crap ass framework. LangGraph is so much better but no one uses that. and the core abstractions in the Lang\\* ecosystem are awful anyway. the best part of my job is sneakily avoiding using LangChain whenever possible",
                  "score": 1,
                  "created_utc": "2026-02-21 01:12:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6obr05",
              "author": "municorn_ai",
              "text": "Langgraph is great and we made a hybrid version with HATEOAS to generate portal, voice and chat agents from a shared configuration for a consistent deterministic behavior. This is too much complexity unless you are looking to build a SaaS AI application. For most one off customer specific applications, the graph is pretty static usually and hard coded implementations are more efficient than incorporating complexity. LLMs thrive on static instructions and RAG is not always a value addition.",
              "score": 1,
              "created_utc": "2026-02-21 22:20:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6evmc3",
          "author": "Freed4ever",
          "text": "Langchain IMO has a lot of fluff that is not needed. Langgraph OTOH is solid. But you can just build your own if I were you.",
          "score": 25,
          "created_utc": "2026-02-20 12:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsdck",
              "author": "Odd-Aside456",
              "text": "Good to know, thank you!",
              "score": 3,
              "created_utc": "2026-02-20 15:38:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ev3l9",
          "author": "Bubba_deets",
          "text": "if you care about long-term maintainability, keep the core logic modular so you‚Äôre not locked into any one framework",
          "score": 15,
          "created_utc": "2026-02-20 12:41:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsboi",
              "author": "Odd-Aside456",
              "text": "Good advice, thank you.",
              "score": 1,
              "created_utc": "2026-02-20 15:38:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffc2a",
          "author": "cleverhoods",
          "text": "I think LangGraph might still be relevant for those who want to work with graph based approach. However the more I dig into claude the more I question this thing. One thing LangGraph does absolutely fantastic - imo - is the visualisation of what is happening. ",
          "score": 5,
          "created_utc": "2026-02-20 14:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h7m9c",
              "author": "mzinz",
              "text": "Using LangStudio for visualization?",
              "score": 3,
              "created_utc": "2026-02-20 19:34:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hoqo5",
                  "author": "cleverhoods",
                  "text": "now reading back, yeah, that could be misunderstood. What I meant is that for agentic work I found LangSmith a great tool to \\*see what is going where, how token expensive it is, what goes to system prompt, to agent prompt, etc. Not \\*LangGraph for \\*visualization.",
                  "score": 3,
                  "created_utc": "2026-02-20 20:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6fszzg",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 0,
              "created_utc": "2026-02-20 15:41:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fvq4y",
          "author": "PretendPop4647",
          "text": "As someone mentioned earlier,keep core things modular. \nCome the point, yes langchain especially deepagent is good.  They provide built in agent harness like file system,sub agent etc\n\nUsing it i built a job search agent.  you can check this out how i implement deepagent for get some idea.\n\nhttps://github.com/Rahat-Kabir/job-search-agent\n\nbtw when you finish your project, give us Update.",
          "score": 3,
          "created_utc": "2026-02-20 15:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fycs0",
              "author": "Odd-Aside456",
              "text": "Will do! And thank you!",
              "score": 2,
              "created_utc": "2026-02-20 16:07:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f3ypj",
          "author": "adlx",
          "text": "Have a look at deepagents, by LangChain. Your Ai assistant is already built üòÇ",
          "score": 8,
          "created_utc": "2026-02-20 13:34:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsees",
              "author": "Odd-Aside456",
              "text": "I'll check it out, thanks!",
              "score": 2,
              "created_utc": "2026-02-20 15:39:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fylnc",
          "author": "DavidtheLawyer",
          "text": "I find that Claude Code can accomplish much of this work, but I‚Äôm big fan of LangGraph.",
          "score": 3,
          "created_utc": "2026-02-20 16:08:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fzw0s",
              "author": "Odd-Aside456",
              "text": "I do love Claude Code. But I can't afford anything beyond the Pro plan right now, and I can't spend those precious tokens on an assistant at the moment.",
              "score": 4,
              "created_utc": "2026-02-20 16:14:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6g9jda",
                  "author": "DavidtheLawyer",
                  "text": "True, it does go hog sometimes",
                  "score": 2,
                  "created_utc": "2026-02-20 16:57:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ibab2",
          "author": "MathematicianSome289",
          "text": "Absolutely. It is the de-facto OSS choice. It‚Äôs why OSS-friendly companies like cloudflare have native support and why closed source companies like AWS built their own agent framework. They know langgraph is too portable given it‚Äôs ubiquity.",
          "score": 3,
          "created_utc": "2026-02-20 22:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fcqtx",
          "author": "Delicious-One-5129",
          "text": "Yes. LangChain is still a practical go to for prototyping and integrations.",
          "score": 4,
          "created_utc": "2026-02-20 14:21:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsvp2",
              "author": "Odd-Aside456",
              "text": "\"For Prototyping,\" So what would you recommend for production, assuming a product got to that point?",
              "score": 3,
              "created_utc": "2026-02-20 15:41:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hmb6z",
                  "author": "zhuki",
                  "text": "Its always prototyping, everything is just for prototyping, never production ü•≤",
                  "score": 10,
                  "created_utc": "2026-02-20 20:46:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6fe61z",
          "author": "Odd-Literature-5302",
          "text": "If you need more structured state and graph style workflows try LangGraph as a complement",
          "score": 2,
          "created_utc": "2026-02-20 14:28:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsxc3",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-02-20 15:41:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gu88x",
          "author": "micupa",
          "text": "Unpopular opinion: Langchain was very early.. we didn‚Äôt even need a framework to build on top of ai APIs.. now we are seeing the need but with a totally different approach: the problem isn‚Äôt the api or the code integration but the context and tools. Frameworks like openclaw are the new way of angetic frameworks, to build good ai assistant think in terms of a new layer of abstraction.",
          "score": 2,
          "created_utc": "2026-02-20 18:32:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6p74lf",
              "author": "vvitali26",
              "text": "Could you elaborate more on the problem with the langchain/langgraph approach in the modern environment comparing to openclaw, please?",
              "score": 1,
              "created_utc": "2026-02-22 01:30:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hqmxv",
          "author": "HotMud9713",
          "text": "with agent skill, not anymore",
          "score": 2,
          "created_utc": "2026-02-20 21:07:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g4gn1",
          "author": "AlexRenz",
          "text": "Who are you building this for - your own personal use? Then I'd rather see how far you can get with Claude or n8n first and see if this gets you there. \n\nIf you want to ship something that's an app to use for others, scalable or that you can sell, deploy it somewhere, scale it, trace it etc. that's a whole different thing. \n\nI find LangGraph to be a great option (and I'm not really differentiating between Chain & Graph tbh). Others have mentioned already that a lot of the online reviews are pre-version 1.0 which just came out end of last year and improved a ton of stuff. \n\nYou'll want to use their pre-built agent and customize that one with integrations and middleware. Nobody can really tell you where all the frameworks are going, so keep your stuff modular as much as you can. But honestly, you can optimize for that later - get started and don't overthink this before you must. And often, a lot of value will lie in your context and prompts which are portable. ",
          "score": 3,
          "created_utc": "2026-02-20 16:34:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6g5chv",
              "author": "Odd-Aside456",
              "text": "It's gonna start for personal use, but then I'm gonna ship it for some friends and family. If they receive it well, I'll probably make it public. Mainly for that reason I'm trying to stay provider/model agnostic.\n\nThanks so much for all the info!",
              "score": 2,
              "created_utc": "2026-02-20 16:38:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6gwahn",
                  "author": "EveYogaTech",
                  "text": "You could use Nyno (see my profile), unlike n8n it's open-source and it's based on multiple languages, so you can stay as agnostic as possible even though using a framework + GUI builder.\n\nLanguages currently supported: Python, Node, Typescript, PHP and Ruby.",
                  "score": 3,
                  "created_utc": "2026-02-20 18:41:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6kuef5",
                  "author": "AlexRenz",
                  "text": "Another question btw is how comfortable you're coding. \n\nIn what I've seen on many many products, it's best to lean towards least resistance early on - in your case put something together with Claude/ChatGPT or n8n and see what features you actually  need. Once you know that AND you hit a limit, write code. ",
                  "score": 1,
                  "created_utc": "2026-02-21 10:01:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6h739u",
              "author": "mzinz",
              "text": "What do you mean by pre-built agents? Re-usable code they offer, or a diff package or product?",
              "score": 2,
              "created_utc": "2026-02-20 19:31:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ktwv2",
                  "author": "AlexRenz",
                  "text": "They have a ReAct agent package that already gets you a core agent, to which one can add integrations and middleware: [https://docs.langchain.com/oss/python/langchain/agents](https://docs.langchain.com/oss/python/langchain/agents)\n\nThey also offer a \"Deep Agent\" which I feel is the same but with more built-in features: [https://docs.langchain.com/oss/python/deepagents/overview](https://docs.langchain.com/oss/python/deepagents/overview)  \n",
                  "score": 2,
                  "created_utc": "2026-02-21 09:56:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ffxdy",
          "author": "Hackerjurassicpark",
          "text": "Just feed your requirements to Claude code and let it build it from scratch. Langchain is unnecessary bloatware built for an age when the ability reuse code and design patterns were important. That is no longer the case now. Claude code can pretty much be your scaffolding using native components instead of an additional layer like Langchain.",
          "score": 2,
          "created_utc": "2026-02-20 14:38:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft34s",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-20 15:42:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6imf9r",
                  "author": "No_Indication_1238",
                  "text": "Do not listen to people in this sub. They are clueless. ",
                  "score": 3,
                  "created_utc": "2026-02-20 23:56:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6h6h5j",
              "author": "mzinz",
              "text": "If asking Claude to do it - would it make sense to ask it to use LangChain/LangGraph, though? If not, why?",
              "score": 1,
              "created_utc": "2026-02-20 19:28:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hxh3o",
                  "author": "Leo2000Immortal",
                  "text": "It's an extra layer of abstraction which does not really help much. It's easier to debug with less abstractions when things don't work as expected",
                  "score": 1,
                  "created_utc": "2026-02-20 21:41:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gkdyx",
          "author": "damanamathos",
          "text": "If you want to build an effective personal assistant, my recommendation is start with something like OpenCode or Claude Code (depending on which underlying model you want to use), then write custom command line tools that let it access calendar, email, tasks, image generation, whatever you want. Then give it skills so it can learn how to use all those commands when needed.\n\nI think this is the fastest way to get up to speed with building agents, which will help you think about how to build something more customised in code. The nice thing about using OpenCode is that it's open source so you can always see how they implement agents.\n\nI don't have a strong view on LangGraph as haven't seen their latest updates. I do use it in parts of my codebase for handling general LLM calls, and do have an older agent that runs on LangChain, though my more recent agents have all been custom code with direct calls to the provider APIs.",
          "score": 1,
          "created_utc": "2026-02-20 17:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hq2hx",
          "author": "sundevil21CS",
          "text": "I have found myself recently ditching langchain and graph and using models SDK structured outputs and manually chaining calls based off structured outputs.",
          "score": 1,
          "created_utc": "2026-02-20 21:04:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ignqe",
          "author": "coreofapples-",
          "text": "Use Temporal and suddenly your life becomes infinitely easier",
          "score": 1,
          "created_utc": "2026-02-20 23:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6irwyk",
          "author": "AdWorried6080",
          "text": "tbh if you want to learn with project start with scratch then you started going to know how this chains,agent, memory and tools are working. If you build small stuff and can check langchain repo than you‚Äôll say why langchain need to use or not. Langchain is good starter for early knowledge and quick build stuff. But when it comes to more customisation, integration, scalability and cost you‚Äôll not go for any framework. As per experience big organisation often build their POC with this frameworks but when it comes to make a product then they‚Äôll create from scratch. It‚Äôs more reliable, scalable, cost optimised(highly needed, lacks in this frameworks), customisable and maintainable.",
          "score": 1,
          "created_utc": "2026-02-21 00:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jrbxi",
          "author": "autoshag",
          "text": "LangGraph for sure. \nAnd then within the nodes I usually use Claude Agents SDK, or OpenCode SDK or langchain depending on the complexity of the task",
          "score": 1,
          "created_utc": "2026-02-21 04:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jvpfd",
          "author": "sergeant113",
          "text": "Use baml-ai for all the core LLM abstraction. Don‚Äôt bother with langChain at all.",
          "score": 1,
          "created_utc": "2026-02-21 04:45:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k2uj4",
          "author": "bornwithmistake",
          "text": "you can vibe code a LangChain equivalent for internal use, focused on your exact workflows, with cleaner abstractions and fewer moving parts than the open source stack",
          "score": 1,
          "created_utc": "2026-02-21 05:41:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ka0ej",
          "author": "themessymiddle",
          "text": "Personal experience - I‚Äôve tested our same agentic workflow with langchain, strands, and Claude agents sdk and the langchain one has the best results. I think it‚Äôs because you have so much more control. It‚Äôs more complex to manage than something like Claude agents sdk, but you have much more granular control",
          "score": 1,
          "created_utc": "2026-02-21 06:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kfn8w",
          "author": "AloneSYD",
          "text": "I would honestly try Agno as it's much simpler compared to lang*  frameworks",
          "score": 1,
          "created_utc": "2026-02-21 07:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kgyhx",
          "author": "SaltedFesh",
          "text": "Only use LangGraph to build graph based workflow and some LangChain necessary components like chunking text, and directly use OpenAI sdk to work with AI",
          "score": 1,
          "created_utc": "2026-02-21 07:48:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kpqm6",
          "author": "ParticularBasket6187",
          "text": "I used this and in future I‚Äôll definitely continue this. Have there some issue but it‚Äôs not big as such.",
          "score": 1,
          "created_utc": "2026-02-21 09:15:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kvxn7",
          "author": "ws6kid",
          "text": "TBH seems it‚Äôs only relevant in abstracted low code tools like n8n‚Ä¶ openclaw is eating its lunch in terms of autonomous agent capabilities even Claude code..",
          "score": 1,
          "created_utc": "2026-02-21 10:16:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lna0e",
          "author": "Gold_Emphasis1325",
          "text": "My understanding and people with more direct experience please correct/supplement: LanchChain is great abstraction, orchestration for linear flows. More branching and complex flows warrant LangGraph, another orchestrator. All of the other DevSecOps and software engineering are still 95% of the work and these are nifty and for people with the complexity to push them into the extra work -- game changing.",
          "score": 1,
          "created_utc": "2026-02-21 13:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lnzz8",
          "author": "Acrobatic_Task_6573",
          "text": "Interesting point. I ran into something similar when building multi-step chains. The config layer is way more important than it looks on the surface.",
          "score": 1,
          "created_utc": "2026-02-21 14:02:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lwsdh",
          "author": "RandomForest42",
          "text": "Just vibe code the whole thing without any dependencies, just like half the Internet is doing already",
          "score": 1,
          "created_utc": "2026-02-21 14:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mcbas",
          "author": "Cats4BreakfastPlz",
          "text": "I've been here before. Try to build with langchain/langgraph, end up wondering why its not working, can't get proper obsevability on whats going wrong, try and figure out what's wrong, just end up building my own that claude understands perfectly and doesn't have to guess around\n\nafter trying pretty hard for a while I'm pretty sure langgraph is moronic and pointless and only good for people who want to sound fancy on their resume. you'll notice most devs who are forced to use it will tell you they hate it and prefer to do it themselves but their bosses want them to use it.\n\nits like stringing templates together. none ofthem work exactly the way you want to and you end up having to implement your own custom solution the majority of the time.\n\nthese tools try to simplify things by giving it to you easy but they just end up making everything more difficult than it needs to be. especially these days where opus/sonnet can do almost anything.",
          "score": 1,
          "created_utc": "2026-02-21 16:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fqaxw",
          "author": "Interesting_Ride2443",
          "text": "LangChain is great for prototyping and short workflows, but once you need durable state, retries, or long-running multi-step execution, you run into limits. Tools like Calljmp provide built-in execution management, pause/resume, and observability, which makes scaling autonomous agents more practical without reinventing all that infrastructure.",
          "score": 1,
          "created_utc": "2026-02-20 15:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft59f",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-02-20 15:42:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fth36",
                  "author": "sandman_br",
                  "text": "It‚Äôs a ad dude. Don‚Äôt fall for it",
                  "score": 7,
                  "created_utc": "2026-02-20 15:44:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gn80d",
          "author": "BeerBatteredHemroids",
          "text": "If you have to ask this, maybe you should just focus on learning the framework first",
          "score": -1,
          "created_utc": "2026-02-20 18:00:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8x2mi",
      "title": "Alternative to LangChain memory for agents ‚Äî zero deps, file-based, 1ms search, no API key needed",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r8x2mi/alternative_to_langchain_memory_for_agents_zero/",
      "author": "fourbeersthepirates",
      "created_utc": "2026-02-19 11:43:44",
      "score": 15,
      "num_comments": 2,
      "upvote_ratio": 0.78,
      "text": "I like LangChain for orchestration but always found the memory options limiting ‚Äî ConversationBufferMemory doesn't do real retrieval (just returns recent items), and VectorStoreRetrieverMemory needs an embedding API key and a vector store.\n\nI built antaris-memory as an alternative that sits in the middle: real relevance-ranked retrieval (BM25, not just recency), but with zero external dependencies. No OpenAI key, no Pinecone, no Chroma. Pure Python, file-based, portable.\n\n**Quick comparison:**\n\n||antaris-memory|LangChain Buffer|LangChain VectorStore|\n|:-|:-|:-|:-|\n|Search latency|1.01ms|0.005ms|Depends on provider|\n|Finds relevant (not just recent)|‚úì|‚úó|‚úì|\n|Scales past 1K memories|‚úì (sharding)|‚úó (dumps all to LLM)|‚úì|\n|API key required|None|None|Yes (embeddings)|\n|Persistent storage|‚úì (file-based)|‚úó (in-memory)|Depends on store|\n|WAL + crash recovery|‚úì|‚úó|Depends on store|\n\nIt's part of a larger suite (guard, router, context, pipeline) but antaris-memory works standalone:\n\npython\n\n    pip install antaris-memory\n    \n    from antaris_memory import MemorySystem\n    memory = MemorySystem(workspace=\"./my_agent_memory\")\n    memory.ingest(\"User prefers dark mode and uses Python 3.12\")\n    results = memory.search(\"what does the user prefer?\")\n\n293 tests on antaris-memory,  1,183 tests on the whole suite (0 failures), Apache 2.0. Also ships as an MCP server and an OpenClaw plugin.\n\nAll the modules work together and compliment each other though, and pipeline ties them all together. Take a look at the Git if you want to see the insides.  \n\n\nGitHub: [https://github.com/Antaris-Analytics/antaris-suite](https://github.com/Antaris-Analytics/antaris-suite)\n\nDocs: [https://docs.antarisanalytics.ai](https://docs.antarisanalytics.ai)\n\nSite: [https://antarisanalytics.ai](https://antarisanalytics.ai)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8x2mi/alternative_to_langchain_memory_for_agents_zero/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6a73rr",
          "author": "Delicious-One-5129",
          "text": "actually pretty cool. Zero deps and no API key is a big win, especially for local agents.\n\nBM25 for memory feels underrated too. Nice middle ground between dumb buffer and full vector stack. Gonna check the repo",
          "score": 3,
          "created_utc": "2026-02-19 18:21:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6auiky",
              "author": "fourbeersthepirates",
              "text": "Cool let me know what you think! Have a ton of features to add this week on the way to 3.0. Shared agent memory, sub-agent context and semantic search is next in line.",
              "score": 1,
              "created_utc": "2026-02-19 20:12:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rau962",
      "title": "How are you actually evaluating your LangChain agents in production, not just in the notebook?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1rau962/how_are_you_actually_evaluating_your_langchain/",
      "author": "Afzaalch00",
      "created_utc": "2026-02-21 15:42:16",
      "score": 14,
      "num_comments": 8,
      "upvote_ratio": 0.95,
      "text": "I have been building a LangChain-based customer support agent for the past few months and kept running into the same issue. Everything looked fine locally, but once it hit production I had no real way to know if quality was holding up or slowly degrading. I was basically eyeballing outputs and hoping for the best.\n\nI started with DeepEval for offline evals since it integrates cleanly with LangChain and the pytest-style setup felt familiar. It was genuinely useful for pre-deployment checks: testing faithfulness, answer relevancy, and hallucination on a fixed dataset before each release. Highly recommend it as a starting point if you haven't tried it.\n\nThe gap I kept hitting though was that my offline dataset didn't reflect what real users were actually sending. I'd pass all my tests and still get weird failures in prod that I never anticipated. That's when I moved to Confident AI, which is built by the same team behind DeepEval. The big difference is it runs those same evals continuously on production traces instead of just a static dataset. When a metric like faithfulness or relevance drops, you get alerted before users complain. The other thing I didn't expect to find useful was the automatic dataset curation from real traces. Bad production outputs get turned into test cases, so over time your eval dataset actually reflects your real traffic instead of synthetic examples you wrote on day one.\n\nThe combo that works for us now is DeepEval for pre-deployment regression testing in CI and Confident AI for live quality monitoring in prod. Took a while to get here but the iteration loop is way tighter now.\n\nAnyone else using a similar setup or found a different approach for keeping LangChain agent quality stable over time?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1rau962/how_are_you_actually_evaluating_your_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6m728y",
          "author": "cool_girrl",
          "text": "Solid setup. We do something similar but use LangSmith for tracing and run DeepEval checks separately. The annoying part is keeping the two in sync.",
          "score": 3,
          "created_utc": "2026-02-21 15:48:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m7pfm",
          "author": "Otherwise_Wave9374",
          "text": "This is exactly the pain point, notebook success means nothing once real traffic hits. The DeepEval + continuous monitoring split makes a lot of sense, offline for regression and then production traces to catch drift.\n\nOne thing thats helped us is defining a small set of \"agent contract\" checks: tool call validity, JSON schema compliance, refusal behavior, and grounding/citation rules. Even if answer quality is subjective, those checks catch a surprising amount of breakage.\n\nIf youre collecting patterns around agent evals, a few notes and links here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-02-21 15:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mq1dy",
          "author": "Happy-Fruit-8628",
          "text": "The automatic dataset curation part is underrated. We were manually curating failure cases into test sets which took forever. Anything that makes that automatic is a big deal when you are trying to ship fast.",
          "score": 1,
          "created_utc": "2026-02-21 17:23:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mr65s",
          "author": "darkluna_94",
          "text": "The CI + prod monitoring split is key. We started with just offline evals and kept getting blindsided. Now we use a similar setup evals in CI for regressions prod traces feeding back into the test set.",
          "score": 1,
          "created_utc": "2026-02-21 17:29:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6muivj",
          "author": "Abdullah_3254",
          "text": "+1 on this. DeepEval offline plus Confident AI on live traffic is honestly the combo I wish I had set up from day one.",
          "score": 1,
          "created_utc": "2026-02-21 17:46:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n5aqc",
          "author": "SpareIntroduction721",
          "text": "I used langfuse since it‚Äôs very similar to langsmith and private",
          "score": 1,
          "created_utc": "2026-02-21 18:39:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pd8wa",
          "author": "Clear-Dimension-6890",
          "text": "Pet peeve about deepeval : it overtakes your system , makes .deepeval directories everyhere",
          "score": 1,
          "created_utc": "2026-02-22 02:09:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pdj9c",
          "author": "Clear-Dimension-6890",
          "text": "If you‚Äôre already in the LangChain ecosystem, LangSmith covers a lot of this ‚Äî tracing, annotation, dataset curation from prod ‚Äî and it‚Äôs a more natural fit. Alternatively, a lightweight custom loop (sample prod traces, run LLM-as-judge scoring, funnel failures back into tests) gets you most of the way without adding a vendor dependency.",
          "score": 1,
          "created_utc": "2026-02-22 02:11:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5lb28",
      "title": "I built an autonomous agent with DeepAgents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r5lb28/i_built_an_autonomous_agent_with_deepagents/",
      "author": "Releow",
      "created_utc": "2026-02-15 18:01:47",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "[CianaParrot](https://preview.redd.it/rq9dgmdy6pjg1.png?width=1024&format=png&auto=webp&s=57714055a2897397227f67ff326251af488456eb)\n\nHi\n\nI built this project for myself because I wanted full control over what my personal assistant does and the ability to modify it quickly whenever I need to. I decided to share it on GitHub here's the link: [https://github.com/emanueleielo/ciana-parrot](https://github.com/emanueleielo/ciana-parrot)\n\nIf you find it useful, leave a star or some feedback\n\n  \n\n\n  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r5lb28/i_built_an_autonomous_agent_with_deepagents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5jrehc",
          "author": "hwchase17",
          "text": "very very cool!",
          "score": 2,
          "created_utc": "2026-02-15 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtixt",
              "author": "Releow",
              "text": "thank u!",
              "score": 1,
              "created_utc": "2026-02-15 18:37:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5txwrs",
                  "author": "nm-ranga",
                  "text": "Well.. a silly question from a novice (in AI). How to test this? Any instructions?",
                  "score": 1,
                  "created_utc": "2026-02-17 07:58:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5txrkv",
              "author": "nm-ranga",
              "text": "I‚Äôm amazed to see that you find time to reply even at this stage where you busy doing so many things. Keep it up!! \n\nI came to know about LangChain through coursera. Just now started with the course. I‚Äôll come up with some (possibly) weird questions. \n\nBtw, I‚Äôm a mechanical engineer by profession with CAD programming skills.",
              "score": 1,
              "created_utc": "2026-02-17 07:57:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9ur3x",
      "title": "Structure-first RAG with metadata enrichment (stop chunking PDFs into text blocks)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9ur3x/structurefirst_rag_with_metadata_enrichment_stop/",
      "author": "Independent-Cost-971",
      "created_utc": "2026-02-20 13:01:41",
      "score": 10,
      "num_comments": 7,
      "upvote_ratio": 0.78,
      "text": "I think most people are still chunking PDFs into flat text and hoping semantic search works. This breaks completely on structured documents like research papers.\n\nTraditional approach extracts PDFs into text strings (tables become garbled, figures disappear), then chunks into 512-token blocks with arbitrary boundaries. Ask \"What methodology did the authors use?\" and you get three disconnected paragraphs from different sections or papers.\n\nThe problem is research papers aren't random text. They're hierarchically organized (Abstract, Introduction, Methodology, Results, Discussion). Each section answers different question types. Destroying this structure makes precise retrieval impossible.\n\nI've been using structure-first extraction where documents get converted to JSON objects (sections, tables, figures) enriched with metadata like section names, content types, and semantic tags. The JSON gets flattened to natural language only for embedding while metadata stays available for filtering.\n\nThe workflow uses Kudra for extraction (OCR ‚Üí vision-based table extraction ‚Üí VLM generates summaries and semantic tags). Then LangChain agents with tools that leverage the metadata. When someone asks about datasets, the agent filters by content\\_type=\"table\" and semantic\\_tags=\"datasets\" before running vector search.\n\nThis enables multi-hop reasoning, precise citations (\"Table 2 from Methods section\" instead of \"Chunk 47\"), and intelligent routing based on query intent. For structured documents where hierarchy matters, metadata enrichment during extraction seems like the right primitive.\n\nAnyway thought I should share since most people are still doing naive chunking by default.",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1r9ur3x/structurefirst_rag_with_metadata_enrichment_stop/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6eycn4",
          "author": "Independent-Cost-971",
          "text": "I wrote a whole blog about this that goes into the steps with code if anyone's interested:¬†[https://kudra.ai/metadata-enriched-rag-agent-why-document-structure-beats-text-chunking/](https://kudra.ai/metadata-enriched-rag-agent-why-document-structure-beats-text-chunking/)",
          "score": 2,
          "created_utc": "2026-02-20 13:02:09",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6oep6n",
              "author": "patrick9331",
              "text": "I would avoid OCR at all cost, usually it‚Äôs expensive and I would only use it if you have to parse Images. Well that‚Äôs what it‚Äôs therefore I guess. Otherwise just parse it in to markdown and then split it based on the sections.\n\nMicrosoft has an awesome library for that:¬†https://github.com/microsoft/markitdownHave you tried this library? I think that covers most of the use cases and also supports OCR actually. One approach I also like. Often the PDF have stable of content at the beginning. Parse that and use it to split your PDF. And as a very last resort use OCR.\n",
              "score": 1,
              "created_utc": "2026-02-21 22:37:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ezxh1",
          "author": "PopPsychological4106",
          "text": "Correct idea. Don't like throwing vlm on it to make it work though. Also table structure understanding is a science for itself.\nWhat labels do you use? How well does toc reconstruction work with vlm?",
          "score": 1,
          "created_utc": "2026-02-20 13:11:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f7lf3",
          "author": "AdRepresentative6947",
          "text": "Yeah had this realisation the other day. Really love your blog gonna implement it into a project I‚Äôve been working on.\n\nDoes the Kundra AI bit run separate as you‚Äôd only have to run the documents in that pipeline once to get the data or when new data arrives ?",
          "score": 1,
          "created_utc": "2026-02-20 13:54:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7xda",
              "author": "AdRepresentative6947",
              "text": "Dw I just saw in the blog, looks slick",
              "score": 1,
              "created_utc": "2026-02-20 13:56:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffj3p",
          "author": "Happy-Fruit-8628",
          "text": "Totally agree. Structure first extraction with metadata filtering makes RAG far more precise and lets you cite exact tables and sections.",
          "score": 1,
          "created_utc": "2026-02-20 14:36:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jelfe",
          "author": "BigDry3037",
          "text": "Docling solves this problem",
          "score": 1,
          "created_utc": "2026-02-21 02:48:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7fsnr",
      "title": "Debugging LangChain agents is painful until you can visualize the full trace",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7fsnr/debugging_langchain_agents_is_painful_until_you/",
      "author": "ruhila12",
      "created_utc": "2026-02-17 19:19:32",
      "score": 9,
      "num_comments": 12,
      "upvote_ratio": 0.92,
      "text": "I really like working with LangChain, but debugging multi step agents can feel like a black box.\nWhen something breaks, it‚Äôs never obvious where it actually failed.\n\n\nDid retrieval return garbage?\n\n\nDid the reranker strip out the only useful chunk?\n\n\nDid the LLM just hallucinate?\n\n\nOr did the agent get stuck in some weird tool loop?\n\n\nFor the longest time, I was just staring at terminal logs and scrolling through JSON traces trying to piece things together. It technically works‚Ä¶ but once your chain gets even slightly complex, it becomes painful.\n\nRecently, I plugged my chains into a tracing tool (Confident AI) mostly out of frustration. I wasn‚Äôt looking for metrics or anything fancy. I just wanted to see what was happening step by step.\nThe biggest difference for me wasn‚Äôt scoring or dashboards. It was the visual breakdown of each hop in the chain. I could literally see:\n\n\nRetrieval step\n\n\nReranking\n\n\nTool calls\n\n\nLLM responses\n\n\nLatency per step\n\n\nAt one point, I realized my agent wasn‚Äôt ‚Äúfailing‚Äù randomly, it was looping on a specific tool call because my system prompt wasn‚Äôt strict enough about exit conditions. That would‚Äôve taken me way longer to diagnose just from logs.\n\nBeing able to replay a failed interaction and inspect the full flow changed how I debug. It feels less like guessing and more like actual engineering.\n\nCurious how others are handling debugging for multi-step agents. Are you just logging everything, or using something more structured?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7fsnr/debugging_langchain_agents_is_painful_until_you/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5x9ab5",
          "author": "Overall_Insurance956",
          "text": "Use langsmith",
          "score": 5,
          "created_utc": "2026-02-17 19:59:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o623tdf",
              "author": "LuckySwimming8564",
              "text": "This.  It is super easy to setup (just a couple vars in your .env) and it is very detailed.  https://docs.langchain.com/langsmith/trace-with-langchain. ",
              "score": 1,
              "created_utc": "2026-02-18 14:28:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6a3bbh",
                  "author": "sunglasses-guy",
                  "text": "to be fair though literally every tool out there now offers 1-2 line integration with langchain and langgraph, langsmith is expensive as hell",
                  "score": 1,
                  "created_utc": "2026-02-19 18:03:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5x2c9v",
          "author": "pvatokahu",
          "text": "Check out open source monocle2ai from Linux foundation - it does the full tracing with agentic attribute capture built on OpenTelemetry and part of pytest.",
          "score": 2,
          "created_utc": "2026-02-17 19:27:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o658ixy",
          "author": "TheExodu5",
          "text": "Please don‚Äôt interact with the fake-engagement advertising bot.",
          "score": 2,
          "created_utc": "2026-02-18 23:08:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o678rvy",
              "author": "NotAHost",
              "text": "Yup just search author:username to see all their spam.",
              "score": 1,
              "created_utc": "2026-02-19 06:42:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o61sh9d",
          "author": "Informal_Tangerine51",
          "text": "Yeah, once a chain has retrieval + reranking + tools, ‚Äúprint the logs‚Äù stops being a debugging strategy and starts being archaeology. A good trace view pays for itself fast, especially when you can replay a run and see exactly where the agent diverged or started looping.\n\nOne thing I‚Äôd add (even if you keep the fancy UI) is a small ‚Äústructured trace contract‚Äù: every hop logs inputs/outputs, tool args, and a reason code for why the agent continued or stopped. Then you can write regression tests off real failures: ‚Äúthis tool loop should terminate‚Äù or ‚Äúthis retrieval query should return at least one relevant chunk,‚Äù instead of hoping prompts stay stable.\n\nWe‚Äôre working on this at Clyra (open source here): [https://github.com/Clyra-AI](https://github.com/Clyra-AI)",
          "score": 1,
          "created_utc": "2026-02-18 13:28:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o624842",
          "author": "93simoon",
          "text": "Use langfuse, it's lang Smith but foss",
          "score": 1,
          "created_utc": "2026-02-18 14:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o625evm",
          "author": "Revolutionary-Bet-58",
          "text": "I'm biased but I can recommend you to check out [inkog.io](http://inkog.io) , you can insert your LangChain agent in there and get feedback directly to solve some issues that you will face before debugging like infinite loops, tool calls etc . It will also recommend you how to fix the problems with examples, or you can just use the Inkog MCP and let Claude fix it for you :D\n\nHappy to sit down with you if you have any questions ",
          "score": 1,
          "created_utc": "2026-02-18 14:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o628qhb",
          "author": "penguinzb1",
          "text": "trace replay is great for diagnosing what happened, but the tool loop you described, where the agent ignored exit conditions, is also the kind of thing that shows up before users see it if you run it against adversarial or edge case scenarios first. what we've found is that simulating these before deployment catches them earlier than any trace tool can, because you're finding the failure before the first incident.",
          "score": 1,
          "created_utc": "2026-02-18 14:52:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r78a13",
      "title": "Run untrusted code locally in LangChain using WASM sandboxes",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r78a13/run_untrusted_code_locally_in_langchain_using/",
      "author": "Tall_Insect7119",
      "created_utc": "2026-02-17 15:00:43",
      "score": 9,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Lately I've seen a lot of cloud-based solutions for running untrusted code. But in reality, you can do it safely on your local machine without sending anything to the cloud.\n\n**Quick context**: When an AI generates code to perform a task, executing it directly could be dangerous for your host system. Sandboxing helps protect your host from any issues that untrusted code might cause.\n\nI built an open-source runtime that isolates code using WebAssembly sandboxes. You can plug it into an existing project in just a few lines:\n\n    from capsule import run\n    \n    result = await run(\n        file=\"./capsule.py\",\n        args=[\"code to execute\"]\n    ]\n\nThen you define your sandboxed logic like this:\n\n    from capsule import task\n    \n    @task(name=\"main\", compute=\"MEDIUM\", ram=\"512mb\")\n    def main(code: str) -> str:\n        \"\"\"Execute untrusted code in an isolated sandbox\"\"\"\n        return exec(code)\n\nThe code (task) runs in its own isolated WASM sandbox. You can define multiple tasks with different limits and even run it standalone.\n\nI put together an example integrated with LangChain here: [https://github.com/mavdol/capsule/tree/main/examples/python/langchain-agent](https://github.com/mavdol/capsule/tree/main/examples/python/langchain-agent)\n\nAnd here‚Äôs the main repo: [https://github.com/mavdol/capsule](https://github.com/mavdol/capsule)\n\nWould love to hear your feedback or thoughts !",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r78a13/run_untrusted_code_locally_in_langchain_using/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5vtc83",
          "author": "vansterdam_city",
          "text": "I‚Äôm absolutely in favor of local sandboxes for agentic coding. There is no way I‚Äôm turning on the super unsafe mode on my local userspace with all my personal creds, but without doing so it‚Äôs super annoying. I like codex web for that reason, but it has limitations.\n\nI‚Äôm curious, why not dev containers? Containers are already a mature platform for creating isolation.",
          "score": 2,
          "created_utc": "2026-02-17 15:51:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w3paq",
              "author": "Tall_Insect7119",
              "text": "That's a valid question. Currently, containers are great for safe application isolation, but they share the host kernel, which could be a risk for untrusted code, even if it's hard to exploit in practice. The real difference is overhead. WASM is lighter than a container, and after the cold start, it's about 100x faster than Docker, for example.\n\nThe only limitation for now is that C extensions (like numpy) aren't supported yet, so it really depends on the use case.",
              "score": 0,
              "created_utc": "2026-02-17 16:43:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5z08jl",
          "author": "ChanceKale7861",
          "text": "This. Those who have done security work, would do the same I think.",
          "score": 2,
          "created_utc": "2026-02-18 01:20:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61vywp",
          "author": "peregrinefalco9",
          "text": "un arbitrary code with the agent's full permissions\" which is terrifying in production.\n\n  \nThe key things to validate with any sandbox approach: can the sandboxed code make network requests? Can it read the filesystem outside its sandbox? What happens when the LLM generates code that tries to escape the sandbox (because it will ‚Äî not maliciously, just because the model doesn't understand sandbox boundaries)?\n\n  \nWASM's capability-based security model is actually well-suited for this. You can explicitly grant only the capabilities the code needs ‚Äî file access to specific paths, network access to specific hosts, memory limits. The attack surface is much smaller than a container and the startup overhead is negligible.\n\n  \nCurious how this handles cases where the agent needs to install dependencies at runtime. That's usually where sandboxed execution falls apart in practice.",
          "score": 2,
          "created_utc": "2026-02-18 13:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61y5ge",
          "author": "Informal_Tangerine51",
          "text": "This is a great direction. ‚ÄúLocal, sandboxed execution‚Äù is exactly what you want for agent-generated code, and WASM gives you a cleaner isolation boundary than ‚Äújust run it in a venv and hope.‚Äù The ergonomic API matters too, because if it‚Äôs annoying people will bypass it.\n\nThe big questions I‚Äôd want answered are around escape hatches: what‚Äôs the default filesystem/network surface, how do you handle timeouts and memory limits deterministically, and can you produce an audit trail of what ran (hash of code, args, resource limits, stdout/stderr) for later debugging. In practice, a sandbox without good observability becomes a new kind of black box.\n\nWe‚Äôre working on this at Clyra (open source here): [https://github.com/Clyra-AI](https://github.com/Clyra-AI)",
          "score": 2,
          "created_utc": "2026-02-18 13:58:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7vn7p",
      "title": "I can‚Äôt figure out how to ask LLM to write an up-to-date LangChain script with the latest docs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7vn7p/i_cant_figure_out_how_to_ask_llm_to_write_an/",
      "author": "gowtham150",
      "created_utc": "2026-02-18 06:34:18",
      "score": 9,
      "num_comments": 16,
      "upvote_ratio": 0.76,
      "text": "Whenever I ask claude or chatgpt to write me a simple langchain agent - even the very simple ones - it always gives me a script with outdated libraries. I tried using claude with context7mcp and langchain docs mcp - still i get out of date obsolete script with deprecated libraries. Even for a simple use case i have to go to langchain docs and get it. Its frustrating to ask LLM to write a sample code and later on to find that its deprecated. How you are you guys solving this problem.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7vn7p/i_cant_figure_out_how_to_ask_llm_to_write_an/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o60jchc",
          "author": "mdrxy",
          "text": "Would encourage cloning the repos locally and letting your agent know that it can traverse the source code in your filesystem!",
          "score": 6,
          "created_utc": "2026-02-18 07:22:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63mjh1",
              "author": "orthogonal-ghost",
              "text": "This is a fantastic idea",
              "score": 1,
              "created_utc": "2026-02-18 18:38:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60tj3n",
          "author": "gowtham150",
          "text": "The general observation is that if i use claude code with context 7 MCP and ask it to write a a simple agent with Langchain it gives me a script most of the time with outdated versions and libraries. Same with chatgpt. So it's becoming extremely difficult to just test out a feature.",
          "score": 3,
          "created_utc": "2026-02-18 08:57:01",
          "is_submitter": true,
          "replies": [
            {
              "id": "o61bc9k",
              "author": "Individual_Day_9508",
              "text": "Use a CLAUDE.md or AGENTS.md file in your workspace to set a strict rule enforcing Langchain 1.x syntax. If you pair that explicit instruction with context 7, it completely fixes the outdated library issue.",
              "score": 1,
              "created_utc": "2026-02-18 11:34:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o61ci16",
                  "author": "gowtham150",
                  "text": "Ok let me check that. Thanks for sharing",
                  "score": 1,
                  "created_utc": "2026-02-18 11:44:01",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60eznz",
          "author": "gaureshai",
          "text": "Very hard.  Because langchain docs are also outdated.",
          "score": 3,
          "created_utc": "2026-02-18 06:44:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60zbec",
              "author": "NoleMercy05",
              "text": "Not true anymore",
              "score": 2,
              "created_utc": "2026-02-18 09:51:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6179bd",
                  "author": "gaureshai",
                  "text": "Well then it's good. I had really hard time in js docs. Will try it again then.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:01:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60jaqu",
              "author": "mdrxy",
              "text": "Not sure what you mean -- can you point to specific pages? Will flag with the team",
              "score": 1,
              "created_utc": "2026-02-18 07:22:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60l0t8",
          "author": "Character_Leg1134",
          "text": "Use chat.langchain.com \nIts their own bot \nWhich can give you the code with updated libraries",
          "score": 2,
          "created_utc": "2026-02-18 07:38:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tdxv",
              "author": "gowtham150",
              "text": "Will try this",
              "score": 1,
              "created_utc": "2026-02-18 08:55:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o61cjj2",
              "author": "gowtham150",
              "text": "This has been working well so far. Thanks for sharing.",
              "score": 1,
              "created_utc": "2026-02-18 11:44:20",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o63c2w2",
              "author": "rk_11",
              "text": "Second this",
              "score": 1,
              "created_utc": "2026-02-18 17:52:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62l7az",
          "author": "notAllBits",
          "text": "That is the cost of unstable conventions (API/classes) in coding. If LLMs cannot be confident about their memory, they spoil it for everyone",
          "score": 1,
          "created_utc": "2026-02-18 15:51:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60qx1v",
          "author": "kolmar41k",
          "text": "If you using and IDE, try using an MCP called 'context7', it provides up to date docs including langgraph/langchain to your llm",
          "score": 1,
          "created_utc": "2026-02-18 08:32:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tczj",
              "author": "gowtham150",
              "text": "I already did, like i mentioned in my post. I used context 7 and Langchain has its own mc as well",
              "score": 1,
              "created_utc": "2026-02-18 08:55:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9kx8o",
      "title": "I built an open-source library on top of LangChain for batch-transforming structured data through LLMs",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9kx8o/i_built_an_opensource_library_on_top_of_langchain/",
      "author": "papipapi419",
      "created_utc": "2026-02-20 03:50:54",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "The problem: every project I worked on needed the same thing ‚Äî take rows of data, run them through an LLM, get back validated Pydantic models. I kept rewriting batching, retries, concurrency, and row-ordering logic.\n\nSo I packaged it up: **smelt-ai**.\n\nWhat it handles under the hood:\n\n* **Batching** ‚Äî splits rows into configurable batch sizes\n* **Concurrency** ‚Äî async semaphore-based, no threads\n* **Retries** ‚Äî exponential backoff for 429s, 5xx, validation errors\n* **Row ordering** ‚Äî injects row\\_id, validates it, reorders results to match input\n* **Structured output** ‚Äî uses `with_structured_output` so you get typed Pydantic models back\n* **Metrics** ‚Äî token counts, timing, retry stats per run\n\nWorks with any LangChain provider (OpenAI, Anthropic, Gemini, etc.) since it uses `init_chat_model` under the hood.\n\n`pip install smelt-ai`\n\nGitHub: [https://github.com/Cydra-Tech/smelt-ai](https://github.com/Cydra-Tech/smelt-ai)  \nDocs: [https://cydra-tech.github.io/smelt-ai/](https://cydra-tech.github.io/smelt-ai/)\n\nWould love feedback from the LangChain community. What would you add?\n\nEdit: Grammer",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r9kx8o/i_built_an_opensource_library_on_top_of_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r58t34",
      "title": "Using LangGraph for long-term memory (RAG + Obsidian) ‚Äî does this design make sense?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r58t34/using_langgraph_for_longterm_memory_rag_obsidian/",
      "author": "Glittering_Aerie54",
      "created_utc": "2026-02-15 07:47:17",
      "score": 8,
      "num_comments": 14,
      "upvote_ratio": 0.79,
      "text": "Hi everyone,\n\nI'm fairly new to building autonomous agents and recently started experimenting with LangGraph.\n\nI'm trying to solve a simple question:\n\n**How would you design long-term memory for a trading agent?**\n\nInstead of keeping memory only inside a vector DB, I experimented with connecting the agent to my Obsidian notes ‚Äî almost like giving it a \"second brain\".\n\n# Current approach\n\nThe workflow is roughly:\n\n* When analyzing a stock, the agent retrieves related notes from an Obsidian vault (RAG)\n* Bull / Bear analyst agents debate using both live data and retrieved context\n* The final analysis is summarized and saved back into the vault\n\nSo the memory grows over time.\n\n# Tech I'm experimenting with\n\n* LangGraph / LangChain\n* Streamlit\n* ChromaDB\n* Obsidian as long-term memory\n\nSince this is my first serious attempt with LangGraph, I'm not sure if my graph structure or memory recall logic is the right approach.\n\n# What I‚Äôd really like feedback on\n\n* How do you usually structure long-term memory in LangGraph?\n* Should memory retrieval happen once at the start, or at multiple nodes?\n* Any patterns to avoid when using RAG as persistent memory?\n\nIf anyone is curious I can share the repo in comments ‚Äî mainly looking for design feedback first.\n\nThanks üôè",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r58t34/using_langgraph_for_longterm_memory_rag_obsidian/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5iejo1",
          "author": "WowSoWholesome",
          "text": "LangGraph supports a bunch of stores, and you can use this to implement check pointing and long term memory in langgraph.¬†https://docs.langchain.com/oss/python/langgraph/add-memory",
          "score": 3,
          "created_utc": "2026-02-15 14:23:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6j36j6",
              "author": "Glittering_Aerie54",
              "text": "Combining them¬†as¬†a hybrid¬†makes¬†a lot of sense¬†they solve different problems¬†cleanly¬†(checkpointing¬†for¬†session/state¬†continuity, and¬†your Chroma-based¬†memory for¬†semantic retrieval).   \nThanks¬†for¬†pointing¬†it out this¬†is¬†really¬†helpful.",
              "score": 1,
              "created_utc": "2026-02-21 01:36:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o5fw8",
          "author": "No-Fail-7644",
          "text": "Why not postgress? Lg4j already has in built checkpointing support for postgres.\nYour biggest challenge would be designing tiers of memory. You wouldn‚Äôt want to mix up semantic memory with low level financial information. You‚Äôll need atleast two tiers. You can wire these with AgentState in graph.. something similar to Plan, Tasks pattern. Lg4j also has supervisor agent pattern.\n\nClone the lg4j repo, there is a directory named ‚Äòhow-tos‚Äô, feed it to your coding agent and ask it more detailed questions!",
          "score": 2,
          "created_utc": "2026-02-16 12:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o6evg",
              "author": "No-Fail-7644",
              "text": "If you are new to dev, better start with DBMS a bit. You can code out the app in couple of days but if you intent to use it long term reliably. You would need proper DB procedures so that your DB doesnt get poisoned over time, given your AI would be making up its content.",
              "score": 1,
              "created_utc": "2026-02-16 12:18:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5o6oxz",
                  "author": "No-Fail-7644",
                  "text": "You don‚Äôt need to query DB full shot once on startup, you can query per node by simply writing a wrapper over it.",
                  "score": 1,
                  "created_utc": "2026-02-16 12:21:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hortm",
          "author": "adlx",
          "text": "Take your post and ask ChatGPT, Claude or Gemini...\nIf you're really into what you say, building autonomous agent, you should already be into vibe coding and definitely using AIs first. Being here asking that sounds a contradiction to me. Sorry",
          "score": 3,
          "created_utc": "2026-02-15 11:15:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hwpnh",
              "author": "Glittering_Aerie54",
              "text": "Fair point.\n\nI did use AI Tool for brainstorming, but I wanted feedback from people actually building with LangGraph in real projects.\n\nThis is the project for context:\n\n[https://github.com/jiwoomap/TradingAgents-Dashboard](https://github.com/jiwoomap/TradingAgents-Dashboard)",
              "score": 3,
              "created_utc": "2026-02-15 12:24:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5idncv",
                  "author": "WowSoWholesome",
                  "text": "I think what you‚Äôre doing drives conversation and improves the community. Thank you for not just blindly vibe coding without an understanding of the solution you want first.¬†",
                  "score": 3,
                  "created_utc": "2026-02-15 14:18:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61xs8j",
          "author": "Informal_Tangerine51",
          "text": "Your design makes sense, and Obsidian can be a great ‚Äúhuman-readable memory‚Äù layer, but I‚Äôd be careful about treating RAG memory as truth in a trading context. Markets change, so a super relevant note from 6 months ago can be actively harmful unless you carry strong timestamps, regime tags, and ‚Äúwhat data did this rely on‚Äù alongside it.\n\nIn LangGraph I‚Äôd usually split memory into two lanes: (1) structured state you can trust (positions, constraints, risk limits, last decision, feature values), and (2) narrative notes (theses, learnings, postmortems) that are advisory. Retrieval shouldn‚Äôt be only at the start; pull it at key nodes (hypothesis generation, counter-argument, decision), but keep the retrieved set small and require each claim to cite a note or a current datapoint.\n\nBig pattern to avoid: writing back everything the model says. Only persist summaries that pass a simple checklist (dated, sources linked, what changed since last time, explicit confidence), otherwise you end up with a compounding ‚Äúmemory hallucination‚Äù loop. What are you using as the ground-truth price/fundamentals feed, and do you want memory to influence actual trades or just generate research notes?",
          "score": 1,
          "created_utc": "2026-02-18 13:56:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6j24yg",
              "author": "Glittering_Aerie54",
              "text": "I was concerned about that point as well, so I designed the system to let me choose whether to use the existing Markdown (md) files or not. Only the summarized content is stored, and only those summaries are used.\n\nEach agent keeps a record of the articles it has verified. This way, if a page has no verified articles or the content has been removed, it won‚Äôt be used.\n\nI‚Äôm now thinking that I should implement a feature to periodically re-validate those articles to ensure they‚Äôre still accessible and reliable.\n\nThank you for the helpful advice.",
              "score": 1,
              "created_utc": "2026-02-21 01:29:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r79j1x",
      "title": "Don't Prompt Your Agent for Reliability ‚Äî Engineer It",
      "subreddit": "LangChain",
      "url": "https://www.aiyan.io/blog/engineer-agent-reliability/",
      "author": "NetworkFlux",
      "created_utc": "2026-02-17 15:47:11",
      "score": 6,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r79j1x/dont_prompt_your_agent_for_reliability_engineer_it/",
      "domain": "aiyan.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5vspec",
          "author": "NetworkFlux",
          "text": "I've spent the past year at my company building a data engineering agent for non-technical users. I rearchitected it three times, from a rigid state machine, to a multi-agent orchestrator, to a single general-purpose agent with lightweight tools. Each time, the system actually got simpler and more reliable. Wrote up the full evolution and the two biggest lessons I took away!",
          "score": 1,
          "created_utc": "2026-02-17 15:48:21",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o629lt8",
          "author": "penguinzb1",
          "text": "how do you quantitatively verify that the agent improves when the complexity is changed? when I'm building agents sometimes the more simple agents seem more reliable but it turns out they just have a reduced action space / problem-solving area, and refuse to solve many things. we use simulations to gauge the agent behaviour and then grade it, which is a bit of a newer thing ",
          "score": 1,
          "created_utc": "2026-02-18 14:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62mjs3",
              "author": "NetworkFlux",
              "text": "That's a good point and is probably worth for me to write about. But in short, we're actually doing something very similar.\n\nWe have \"simulated user\" LLMs with different personas defined in config files. They talk to our agent until the simulated user decides to end the conversation (goal reached), or if certain deterministic criteria are met, like max # of turns or state reached.\n\nFor judging, we have a suite of heuristic judges (checking for tool calls, checking text for data leakage, etc.) and an LLM judge which is given a precise pass/fail criteria.\n\nFinally we compute a weighted average based on the passes and fails and assign a score to the simulation after running enough for a statistically significant result.\n\nAre you doing something similar?",
              "score": 1,
              "created_utc": "2026-02-18 15:57:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64awwg",
          "author": "ScArL3T",
          "text": "Do your tools do any heavy lifting in regards to semantic understanding and if yes how do you achieve it?  \nLater in the article you mention about having a simple general agent which in turn calls some well defined tools. In that diagram you showcased the possibility of having a sub-agent -- so they are not completely gone?\n\nI'm kind of interested in the technicalities a bit and diving a bit more in-depth into your architecture.  \nI'm also interested how your initial user query (2 edit requests and 1 question in the same message) gets handled by the generic agent now that it is specifically NOT instructed to deconstruct the user query. Do you just rely on the model's intelligence? And if yes, what model are you using.\n\nThank you!",
          "score": 1,
          "created_utc": "2026-02-18 20:30:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69h8kd",
              "author": "NetworkFlux",
              "text": "Right, in the last architecture version we still kept the dataflow (code) generation sub-agent because its system prompt contains a lot of niche guidance on data pipeline patterns that wouldn't make a ton of sense polluting the main agent's context.\n\nThat being said, with code and MCP execution in sandbox being refined (https://www.anthropic.com/engineering/code-execution-with-mcp), I think this may not hold true for long. I can envision a future where agents perform most of its tasks (including tool-calling) within a code sandbox, backed by a filesystem (its \"environment\").\n\n\\-\n\nRe general agent - we're achieving good performance with just the open-source tool-calling models. And I think the insight I can provide is most helpful broadly:\n\nMy key learning is that deconstructing the user query, like you mention, isn't the goal, but rather invoking the necessary side-effects (tools).\n\nIt was also very enlightening thinking about the final objects/artifacts we actually *want* out of the agent. LLMs act greedily, so making sure our tools don't elongate the path to the goal was very helpful.\n\nI.e., instead of tools that \"set\" certain objects, just make those objects inputs to the next tool in the dependency chain",
              "score": 2,
              "created_utc": "2026-02-19 16:17:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ra2b0r",
      "title": "expectllm: A lightweight alternative when you just need pattern matching",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ra2b0r/expectllm_a_lightweight_alternative_when_you_just/",
      "author": "Final_Signature9950",
      "created_utc": "2026-02-20 17:51:55",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I built a small library called **expectllm**.\n\n\n\nIf you've ever thought \"I just need to extract a number from an LLM response, why am I importing 50 modules?\" - this might be for you.\n\n\n\nIt treats LLM conversations like classic expect scripts:\n\n\n\nsend ‚Üí pattern match ‚Üí branch\n\n\n\nYou explicitly define what response format you expect from the model.\n\nIf it matches, you capture it.\n\nIf it doesn't, it fails fast with an explicit ExpectError.\n\n\n\nExample:\n\n    from expectllm import Conversation\n    \n    c = Conversation()\n    \n    c.send(\"Review this code for security issues. Reply exactly: 'found N issues'\")\n    c.expect(r\"found (\\d+) issues\")\n    \n    issues = int(c.match.group(1))\n    \n    if issues > 0:\n       c.send(\"Fix the top 3 issues\")\n\n\n\nCore features:\n\n\\- expect\\_json(), expect\\_number(), expect\\_yesno()\n\n\\- Regex pattern matching with capture groups\n\n\\- Auto-generates format instructions from patterns\n\n\\- Raises explicit errors on mismatch (no silent failures)\n\n\\- Works with OpenAI and Anthropic (more providers planned)\n\n\\- \\~365 lines of code, fully readable\n\n\\- Full type hints\n\n\n\nRepo: [https://github.com/entropyvector/expectllm](https://github.com/entropyvector/expectllm)\n\nPyPI: [https://pypi.org/project/expectllm/](https://pypi.org/project/expectllm/)\n\n\n\nIt's not designed to replace LangChain or similar frameworks - those are great when you need the full toolbox. This is for when you don't. Minimalism, control, transparent flow.\n\n\n\nWould appreciate feedback:\n\n\\- Is this approach useful in real-world projects?\n\n\\- What edge cases should I handle?\n\n\\- Where would this break down?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ra2b0r/expectllm_a_lightweight_alternative_when_you_just/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r8q0jm",
      "title": "LangChain's Deep Agents scores 5th on Terminal Bench 2",
      "subreddit": "LangChain",
      "url": "https://x.com/Vtrivedy10/status/2023805578561060992",
      "author": "mdrxy",
      "created_utc": "2026-02-19 04:49:30",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8q0jm/langchains_deep_agents_scores_5th_on_terminal/",
      "domain": "x.com",
      "is_self": false,
      "comments": [
        {
          "id": "o66xh90",
          "author": "Material_Policy6327",
          "text": "Any non x link",
          "score": 1,
          "created_utc": "2026-02-19 05:11:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6735v5",
              "author": "mdrxy",
              "text": "[https://blog.langchain.com/improving-deep-agents-with-harness-engineering/](https://blog.langchain.com/improving-deep-agents-with-harness-engineering/)",
              "score": 2,
              "created_utc": "2026-02-19 05:55:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6b1wa",
      "title": "What Are DeepAgents in LangChain?",
      "subreddit": "LangChain",
      "url": "https://www.blog.qualitypointtech.com/2026/02/what-are-deepagents-in-langchain.html",
      "author": "qptbook",
      "created_utc": "2026-02-16 14:28:22",
      "score": 5,
      "num_comments": 12,
      "upvote_ratio": 0.69,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r6b1wa/what_are_deepagents_in_langchain/",
      "domain": "blog.qualitypointtech.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5pfckh",
          "author": "justanemptyvoice",
          "text": "A buzzword\n\nSaved you a click",
          "score": 3,
          "created_utc": "2026-02-16 16:24:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r0wqa",
              "author": "93simoon",
              "text": "Opened the post to comment the same thing üòÇ",
              "score": 1,
              "created_utc": "2026-02-16 20:55:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5pmlf6",
              "author": "Niightstalker",
              "text": "No a specific concepts of agents that is worth reading but ok",
              "score": 0,
              "created_utc": "2026-02-16 16:57:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rzw0k",
                  "author": "mamaBiskothu",
                  "text": "A concept introduced a year too late into the most popular framework in the field. My team Interview questuon is to ask what their thought is on langchain and to reject anyone saying positive things.",
                  "score": 1,
                  "created_utc": "2026-02-16 23:57:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61sng4",
          "author": "Puzzled_Celery_6190",
          "text": "TLDR: compare to normal ReAct agent, deep agent contains a detailed system prompt, plan tool, sub agent plus an external file system (so that you don‚Äôt put everything in context/prompt). Take writing paper for example, it could write paper page by page or sentence by sentence, write as long as you want.",
          "score": 1,
          "created_utc": "2026-02-18 13:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68p8lh",
          "author": "kalyugira",
          "text": "It does not even follow its own internal langchain standards - ex. StateSchema concept is entirely missing that is part of react agent. You are better off taking the middlewares and use them if you are using langchain.",
          "score": 1,
          "created_utc": "2026-02-19 13:53:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7uhed",
      "title": "stopped using flaky youtube loaders and finally fixed my rag accuracy",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7uhed/stopped_using_flaky_youtube_loaders_and_finally/",
      "author": "straightedge23",
      "created_utc": "2026-02-18 05:29:02",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "i‚Äôve been building a RAG pipeline for a technical documentation project, and the biggest bottleneck was the \"garbage in, garbage out\" problem with youtube transcripts. i started with the standard community loaders, but the formatting was so messy that the embeddings were coming out low-quality, and the retrieval was hitting all the wrong chunks.\n\ni finally swapped out my custom scraping logic for [transcript api](https://transcriptapi.com/) as a direct source.\n\n**the difference it made for the chain:**\n\n* **cleaner chunks:** the api gives me a clean, stripped string. without the html junk and weird timestamps, my recursive character text splitter actually creates coherent chunks instead of breaking in the middle of a sentence.\n* **metadata integrity:** since i can pull structured segments with start times, i can actually map my vector metadata back to the exact second in the video. when the user asks a question, the agent can cite the exact timestamp in the source.\n* **reliability at scale:** i‚Äôm not getting blocked or hitting 403 errors during batch processing anymore. it treats the transcript like a stable production data source rather than a side-project hack.\n\nif you‚Äôre building agents that need to \"reason\" over technical tutorials or long-form lectures, don't waste your context window on garbage formatting. once the input pipe is clean, the \"hallucinations\" drop significantly because the model actually has the full, un-mangled context.\n\ncurious if anyone else has moved away from the standard loaders to a dedicated api for their ingestion layer?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7uhed/stopped_using_flaky_youtube_loaders_and_finally/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o61t5yc",
          "author": "Informal_Tangerine51",
          "text": "Yep, this is the unsexy part of RAG that matters most: loader quality and normalization beats clever prompting. Once the text is clean, chunk boundaries make sense, and your embeddings stop ‚Äúsmearing‚Äù unrelated concepts together.\n\nIf you haven‚Äôt already, a couple small additions tend to pay off: normalize casing/whitespace consistently, strip repeated boilerplate (‚Äúsubscribe‚Äù, intros), and store both the raw segment + the cleaned segment so you can always re-render citations. I also like adding a lightweight ‚Äúchunk health‚Äù check (avg chars, sentence breaks, % non-alpha) so bad transcripts get quarantined before they pollute the index.\n\nTimestamp metadata is a killer feature too, because it makes answers verifiable. Are you also storing a stable video ID + language track, and handling ‚Äúupdated transcripts‚Äù (so your vector store can reindex without breaking existing citations)?",
          "score": 1,
          "created_utc": "2026-02-18 13:31:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64hsw1",
          "author": "One_Presentation7722",
          "text": "clean transcripts improve rag pipelines ScraperCity offers structured data with unlimited downloads.",
          "score": 1,
          "created_utc": "2026-02-18 21:02:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5eq9f",
      "title": "Open-source research agent with LangGraph that maps its findings in 3D",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/81xrw2pqunjg1",
      "author": "FickleSwordfish8689",
      "created_utc": "2026-02-15 13:32:43",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r5eq9f/opensource_research_agent_with_langgraph_that/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r8ngzq",
      "title": "üöÄ Launch Idea: A Curated Marketplace for AI Agents, Workflows & Automations",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r8ngzq/launch_idea_a_curated_marketplace_for_ai_agents/",
      "author": "NoSwimming4210",
      "created_utc": "2026-02-19 02:46:10",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Right now, discovering reliable AI agents and automation systems is messy ‚Äî too many scattered tools, too little trust, and almost no true curation.\n\nThe vision:\nA single marketplace where businesses and creators can find tested, ready-to-deploy AI agents, structured workflows, and powerful automations ‚Äî all organized by real-world use cases.\n\nWhat makes it different:\n‚úîÔ∏è Curated listings ‚Äî quality over quantity\n‚úîÔ∏è No-code + full-code solutions in one place\n‚úîÔ∏è Verified workflows that actually work\n‚úîÔ∏è Builders can monetize their systems\n‚úîÔ∏è Companies adopt AI faster without technical chaos\n\nThis isn‚Äôt another tool directory ‚Äî it‚Äôs an execution layer for applied AI.\n\nLooking for:\n‚Ä¢ Early adopters who want to try curated AI workflows\n‚Ä¢ Builders interested in listing their agents\n‚Ä¢ Feedback on must-have features before MVP\n\nComment or connect if you want to be part of shaping it.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8ngzq/launch_idea_a_curated_marketplace_for_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6a7lfx",
          "author": "Delicious-One-5129",
          "text": "A curated marketplace could save so much time - finding reliable AI workflows is such a headache right now. Would definitely be interested in testing or giving feedback.",
          "score": 1,
          "created_utc": "2026-02-19 18:23:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lbxby",
          "author": "Traditional-Carry409",
          "text": "AI slop post",
          "score": 1,
          "created_utc": "2026-02-21 12:41:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6lceab",
              "author": "NoSwimming4210",
              "text": "Hey its not a Ai Slop post we are actually being constantly improving the idea, behind a team of people with professors are working on it. This is a part to know the peoples response on it.",
              "score": 1,
              "created_utc": "2026-02-21 12:44:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1racwma",
      "title": "How are you guys tracking costs per agentic workflow run in production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1racwma/how_are_you_guys_tracking_costs_per_agentic/",
      "author": "Top-Seaweed970",
      "created_utc": "2026-02-21 00:43:09",
      "score": 4,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1racwma/how_are_you_guys_tracking_costs_per_agentic/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6jzkmu",
          "author": "StarThinker2025",
          "text": "Per-call token logging + run_id tagging\nWe compute cost from model pricing table and aggregate per workflow execution\n\nWithout step-level attribution, agent costs become impossible to debug in prod",
          "score": 3,
          "created_utc": "2026-02-21 05:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lnfjf",
          "author": "Gold_Emphasis1325",
          "text": "Strategic usage checks server-side and locally throughout pipeline/orchestration.",
          "score": 2,
          "created_utc": "2026-02-21 13:59:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p8r8x",
          "author": "Top-Seaweed970",
          "text": "Are there any tools that can do this automatically and show me everything on a dashboard?",
          "score": 1,
          "created_utc": "2026-02-22 01:41:03",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r788ux",
      "title": "webMCP is insane....",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/vbrxxu5ui2kg1",
      "author": "GeobotPY",
      "created_utc": "2026-02-17 14:59:32",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r788ux/webmcp_is_insane/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}