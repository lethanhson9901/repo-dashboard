{
  "metadata": {
    "last_updated": "2026-01-30 16:57:45",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 58,
    "file_size_bytes": 110956
  },
  "items": [
    {
      "id": "1qmpjef",
      "title": "Do actual AI practitioners find the Clawdbot hype realistic?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qmpjef/do_actual_ai_practitioners_find_the_clawdbot_hype/",
      "author": "julsezerus",
      "created_utc": "2026-01-25 17:34:28",
      "score": 90,
      "num_comments": 38,
      "upvote_ratio": 0.95,
      "text": "I‚Äôm curious what people who actually work with AI think about the Clawdbot hype. \n\nHere‚Äôs my take:\n\nThe capabilities Clawdbot demonstrates aren‚Äôt particularly difficult to achieve technically - we can already make LLMs do most of what it‚Äôs doing. The real challenge has always been implementing proper security procedures and guardrails, not the core functionality itself.\n\nFrom what I can tell, Clawdbot is essentially burning through massive amounts of LLM tokens to accomplish certain tasks without much concern for security protocols. \n\nThat‚Äôs‚Ä¶ not exactly groundbreaking? It‚Äôs more like ‚Äúlook what happens when you remove the safety rails and throw credits at it.‚Äù\n\nMaybe I‚Äôm missing something, but this doesn‚Äôt feel like the revolution people are making it out to be. It feels more like a demo of ‚Äúwhat if we just didn‚Äôt worry about the hard parts?‚Äù\n\nWhat do people actually working in this space think? Am I being too cynical here, or is this hype as overblown as it seems?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmpjef/do_actual_ai_practitioners_find_the_clawdbot_hype/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1nm307",
          "author": "ImaginaryRea1ity",
          "text": "Saw the YT video of the guy hyping it up but I think all the marketing is paid.",
          "score": 14,
          "created_utc": "2026-01-25 17:43:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o94n7",
              "author": "gastro_psychic",
              "text": "Who is making money?",
              "score": 2,
              "created_utc": "2026-01-25 19:19:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p175w",
                  "author": "LiveBeyondNow",
                  "text": "The creator and the suppliers, Anthropic, YT etc",
                  "score": 2,
                  "created_utc": "2026-01-25 21:22:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1pl3v6",
          "author": "Hackerjurassicpark",
          "text": "More hype. Most likely paid marketing.",
          "score": 5,
          "created_utc": "2026-01-25 22:50:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qv0do",
              "author": "mediaempire45",
              "text": "Mranwhile the creator of the clawdbot is saying on X that nobody is checking out his \"sponsor\" link",
              "score": 2,
              "created_utc": "2026-01-26 02:35:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1rci5q",
                  "author": "Hackerjurassicpark",
                  "text": "They‚Äôre playing the long game‚Ä¶ hyping up and creating massive visibility to add more users, the use those impressive user growth to justify a 1B valuation in their next seed round",
                  "score": 1,
                  "created_utc": "2026-01-26 04:13:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1r9f36",
          "author": "Proof-Sand-7157",
          "text": "What Clawdbot does is essentially the same as **Copilot/Cowork-style agents connected to channels like WhatsApp or Slack**.\n\nThere‚Äôs no particularly complex capability involved.  \nIt mainly feels impressive because **it‚Äôs open source**, so everything is visible and reproducible.",
          "score": 3,
          "created_utc": "2026-01-26 03:54:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wfsgw",
              "author": "laslog",
              "text": "And, unlike Copilot, it works.",
              "score": 3,
              "created_utc": "2026-01-26 21:48:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1r9wka",
          "author": "Zatkoma",
          "text": "Hype, let them some time to prove that is make sense... :)",
          "score": 2,
          "created_utc": "2026-01-26 03:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1tacxy",
          "author": "Educational_Bag_4003",
          "text": "Don't think the founder is out to make money. Look at all of his recent dev work and look at his background [https://github.com/steipete](https://github.com/steipete) Really don't think it is paid marketing pushing this...",
          "score": 2,
          "created_utc": "2026-01-26 13:19:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1vleje",
              "author": "auskadi",
              "text": "It's a great little tool. Lots of people here seem to be taking through their ...",
              "score": 2,
              "created_utc": "2026-01-26 19:34:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2bosay",
              "author": "Street_Profile_8998",
              "text": "It is literally paid marketing. It says as much on the sponsored posts that endlessly run on my linked in feed",
              "score": 1,
              "created_utc": "2026-01-29 00:48:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vxvzq",
          "author": "Significant-Sweet-53",
          "text": "https://preview.redd.it/tl5mnc7u6rfg1.jpeg?width=945&format=pjpg&auto=webp&s=eda45bcd2bf6a97b9844cee99223ccd2d2c9ce4b\n\nI just made a trimmed down version of this bot that uses Deepseek or Ollama, less noise and you can add your own skills easily, Ive added gog cli to test, controlling Google workspace from WhatsApp",
          "score": 2,
          "created_utc": "2026-01-26 20:29:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1w8mu9",
              "author": "Kubuli",
              "text": "Can you share your methods, results, limitations and suggestions?",
              "score": 1,
              "created_utc": "2026-01-26 21:17:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1w1j1w",
          "author": "Lonely-Elephant2130",
          "text": "Honestly spent an afternoon trying to set up ClawdBot and gave up - I'm not technical and the Mac Mini + local setup was way over my head. But I do love the idea of bringing AI into messaging apps. Been using something similar called Super Intern Ôºàhttps://www.superintern.ai/Ôºâ lately - same concept of AI in your chat, but way simpler to get started. Just works in browser/Slack, no setup needed. Maybe I'm just not the target user for ClawdBot, but feels like there's a gap between \"impressive tech\" and \"actually usable for non-tech people.",
          "score": 1,
          "created_utc": "2026-01-26 20:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z6ksy",
          "author": "damanamathos",
          "text": "I created an AI Personal Assistant over Christmas and it's amazing ‚Äî one of the best things I've created. I haven't used Clawdbot but have seen a bit, and did download the repo and get my AI PA to assess it vs what I already do, and it seemed pretty similar but probably a downgrade for me. So if you're not using any kind of AI assistant, it's probably worth checking out.",
          "score": 1,
          "created_utc": "2026-01-27 07:22:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1z6vji",
              "author": "damanamathos",
              "text": "I should add that my \"assistant\" isn't even that complicated. It's just Claude Code or OpenCode will a decent AGENTS file and specialised skills combined with custom-made CLI commands that let it access all my services so it can search and read email, create drafts, create images, etc from command line tools.",
              "score": 1,
              "created_utc": "2026-01-27 07:24:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o20t0q9",
          "author": "AccountEffective369",
          "text": "I haven't checked it out but that's why people are not looking to hire AI driven employees they still looking for individuals who knows processes comprehensively. Good Knowledge before trying the application itself.",
          "score": 1,
          "created_utc": "2026-01-27 14:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21p92q",
          "author": "Classic-Log-162",
          "text": "Completely useless and unsafe.",
          "score": 1,
          "created_utc": "2026-01-27 17:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o4z7a",
          "author": "Not_a_doxxtor",
          "text": "We've had these Jarvis things for a while now\n\nSomeone paid for advertising",
          "score": 1,
          "created_utc": "2026-01-25 19:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1pb1md",
          "author": "cqzero",
          "text": "Does it even work on Windows? I saw just MacOS/iOS/Android. Not interested unless it's Windows (or even Linux)",
          "score": 1,
          "created_utc": "2026-01-25 22:05:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1sfm4t",
              "author": "4rtdud3",
              "text": "Just got it up and running under WSL (Ubuntu) on Win 11.",
              "score": 1,
              "created_utc": "2026-01-26 09:16:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o25mk7x",
              "author": "dmees",
              "text": "Yes but you should join the hype and buy a Mac Mini!",
              "score": 1,
              "created_utc": "2026-01-28 04:21:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1qezr6",
              "author": "almeidamarcell",
              "text": "are you 12?!",
              "score": -1,
              "created_utc": "2026-01-26 01:13:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1sfkan",
                  "author": "Sore6",
                  "text": "are you?",
                  "score": 0,
                  "created_utc": "2026-01-26 09:16:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1qnodi",
              "author": "PositiveShallot7191",
              "text": "lol its self hosted its not running on phones",
              "score": 0,
              "created_utc": "2026-01-26 01:58:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1uhk9w",
          "author": "Significant-Sweet-53",
          "text": "Paid-first assumptions",
          "score": 1,
          "created_utc": "2026-01-26 16:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nn0th",
          "author": "AykutSek",
          "text": "You‚Äôre not being cynical; you‚Äôre being realistic. Clawdbot feels like a high-speed car with no brakes. It‚Äôs exciting to watch until it hits a wall of security protocols or a massive API bill. The real breakthrough won't be 'doing things,' it will be doing things safely and efficiently within the chaos of real-world data.",
          "score": 1,
          "created_utc": "2026-01-25 17:47:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nndhy",
          "author": "Resident_Green8814",
          "text": "Spot on. From a GTM and product perspective, the 'revolution' here isn't technical brilliance, but the removal of friction by ignoring guardrails. Scaling an AI agent in an enterprise environment requires solving the 'hard parts' you mentioned: security, token efficiency, and reliability. Clawdbot is a great demo of potential, but a nightmare for risk management. We need sustainable innovation, not just credit-burning experiments.",
          "score": 0,
          "created_utc": "2026-01-25 17:49:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpci1h",
      "title": "You can now train embedding models ~2x faster!",
      "subreddit": "LangChain",
      "url": "https://i.redd.it/kbenz74xl3gg1.png",
      "author": "yoracale",
      "created_utc": "2026-01-28 14:15:31",
      "score": 38,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qpci1h/you_can_now_train_embedding_models_2x_faster/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qpi07h",
      "title": "I built a job search assistant to understand LangChain Deep Agents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qpi07h",
      "author": "Acrobatic-Pay-279",
      "created_utc": "2026-01-28 17:34:30",
      "score": 30,
      "num_comments": 3,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qpi07h/i_built_a_job_search_assistant_to_understand/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2bvl13",
          "author": "qa_anaaq",
          "text": "Cool and thanks for sharing. 2 Qs. Do you feel the deep agents harness is any good, and how‚Äôs the cost of running it?",
          "score": 2,
          "created_utc": "2026-01-29 01:26:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dj8hk",
              "author": "Acrobatic-Pay-279",
              "text": "yeah it's good, especially for long running tasks. in the earlier version, I actually tracked write\\_todos with the statuses and it was breaking things down step by step. I also tried HITL flows. the docs mention prompt caching (Anthropic) and pluggable storage backends but I wasn't able to verify/use those.\n\nthe cost is just the underlying model (I used OpenAI in this case).",
              "score": 2,
              "created_utc": "2026-01-29 08:06:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ek6gp",
                  "author": "qa_anaaq",
                  "text": "Cool thanks a lot",
                  "score": 1,
                  "created_utc": "2026-01-29 13:08:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qmhxxi",
      "title": "Quantifying Hallucinations: By calculating a multi-dimensional 'Trust Score' for LLM outputs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qmhxxi",
      "author": "Charming_Group_2950",
      "created_utc": "2026-01-25 12:33:20",
      "score": 21,
      "num_comments": 0,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmhxxi/quantifying_hallucinations_by_calculating_a/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qnqln9",
      "title": "A practical open-source repo for learning AI agents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qnqln9/a_practical_opensource_repo_for_learning_ai_agents/",
      "author": "Creepy-Row970",
      "created_utc": "2026-01-26 19:43:49",
      "score": 16,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "A practical open-source repo for learning AI agents. I‚Äôve contributed 10+ examples\n\nI‚Äôve contributed 10+ agent examples to an open-source repo that‚Äôs grown into a solid reference for building AI agents.\n\nRepo:[ https://github.com/Arindam200/awesome-ai-apps](https://github.com/Arindam200/awesome-ai-apps)\n\nWhat makes it useful:\n\n* 70+ runnable agent projects, not toy demos\n* Same ideas built across different frameworks\n* Covers starter agents, MCP, memory, RAG, and multi-stage workflows\n\nFrameworks include LangChain, LangGraph, LlamaIndex, CrewAI, Agno, Google ADK, OpenAI Agents SDK, AWS Strands, and PydanticAI.\n\nSharing in case others here prefer learning agents by reading real code instead of theory.\n\n",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qnqln9/a_practical_opensource_repo_for_learning_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1vok23",
          "author": "Pristine_Shelter_28",
          "text": "are these live apps?",
          "score": 1,
          "created_utc": "2026-01-26 19:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o246fka",
          "author": "YUYbox",
          "text": "Hi, \n  I built a tool for anyone running multi-agent AI systems.\n When LLMs talk to each other, they develop patterns that are hard to audit - invented acronyms, lost context, meaning drift.\r\n\r\n   The solution: InsAIts monitors these communications and flags anomalies.\r\n\r\n```python\r\nfrom insa_its import insAItsMonitor\r\n\r\nmonitor = insAItsMonitor()  # Free tier, no key needed\r\nmonitor.register_agent(\"agent_1\", \"gpt-4\")\r\n\r\nresult = monitor.send_message(\r\n    text=\"The QFC needs recalibration on sector 7G\",\r\n    sender_id=\"agent_1\"\r\n)\r\n\r\nif result[\"anomalies\"]:\r\n    print(\"Warning:\", result[\"anomalies\"])\r\n```\r\n\r\n  Features:\r\n- Local processing (sentence-transformers)\r\n- LangChain & CrewAI integrations\r\n- Adaptive jargon dictionary\r\n- Zero cloud dependency for detection\r\n\r\nGitHub: https://github.com/Nomadu27/InsAIts\r\nPyPI: pip install insa-its",
          "score": 1,
          "created_utc": "2026-01-27 23:42:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qo6uax",
      "title": "What It Actually Takes to Build a Context-Aware Multi-Agent AI System",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qo6uax/what_it_actually_takes_to_build_a_contextaware/",
      "author": "pretty_prit",
      "created_utc": "2026-01-27 07:05:33",
      "score": 13,
      "num_comments": 7,
      "upvote_ratio": 0.89,
      "text": "Designing a multi-agent system with memory raises a different set of problems than most demos show.  \n  \nThe diagram below shows a simple multi-agent architecture I built to explore that gap.  \n  \nInstead of agents talking to each other directly, everything goes through an orchestration layer that handles:  \n\\-intent routing  \n\\-shared user context  \n\\-memory retrieval and compaction  \n  \nWhile designing this, a set of product questions surfaced that you don‚Äôt see in most demos  \n\\-What belongs in long-term memory vs. short-term history?  \n\\-When do you summarize context, and what do you risk losing?  \n\\-How do you keep multiple agents consistent as context evolves?  \n  \nI wrote a detailed breakdown of this architecture, including routing strategy, memory design, and the trade-offs this approach introduces.  \n  \n[https://medium.com/towards-artificial-intelligence/how-i-built-a-context-aware-multi-agent-wellness-system-a3eacbc33fe4?sk=c37c88e2f74aa9e5c2b2d681292d26c2](https://medium.com/towards-artificial-intelligence/how-i-built-a-context-aware-multi-agent-wellness-system-a3eacbc33fe4?sk=c37c88e2f74aa9e5c2b2d681292d26c2)  \n  \nIf you‚Äôre a PM, founder, or student trying to move beyond one-off agent demos, this might be useful.\n\nhttps://preview.redd.it/mr1w53kmcufg1.png?width=1838&format=png&auto=webp&s=e36245c419d44c006fdd8e3ff006c060eb320489\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qo6uax/what_it_actually_takes_to_build_a_contextaware/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1zgezp",
          "author": "DaRandomStoner",
          "text": "This looks pretty well put together... Is there a github repo we could check out?",
          "score": 1,
          "created_utc": "2026-01-27 08:51:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1zusom",
              "author": "pretty_prit",
              "text": "Thank you. the github link is there at the end of the article but posting here again - [https://github.com/pritha21/llm\\_projects/tree/main/wellness\\_langchain\\_app](https://github.com/pritha21/llm_projects/tree/main/wellness_langchain_app)",
              "score": 1,
              "created_utc": "2026-01-27 11:01:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1zmbdv",
          "author": "sleepnow",
          "text": "Good effort, but there is nothing at all new or particularly unique about this approach. ",
          "score": 1,
          "created_utc": "2026-01-27 09:46:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20aayx",
              "author": "pretty_prit",
              "text": "Maybe. But I was just exploring this topic, so its new for me.",
              "score": 2,
              "created_utc": "2026-01-27 12:55:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o244gr7",
          "author": "YUYbox",
          "text": "Hi there, I think InsAIts could be very helpful in this matter. \nhttps://github.com/Nomadu27/InsAIts",
          "score": 1,
          "created_utc": "2026-01-27 23:32:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o260i4c",
              "author": "pretty_prit",
              "text": "Will check it out",
              "score": 2,
              "created_utc": "2026-01-28 05:55:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24l5lq",
          "author": "pbalIII",
          "text": "Context compaction is where most of these designs break down quietly. You summarize to save tokens, but summaries drop the specifics that matter six turns later... and you only find out when an agent makes a decision based on stale assumptions.\n\nOne pattern that's helped: treating memory writes as versioned facts rather than mutable state. Agents can reference which version they're working from, and conflicts surface explicitly instead of silently diverging.\n\nThe orchestration-layer-as-bottleneck tradeoff you're hitting is real. Centralizing routing keeps agents consistent, but it also means every context update round-trips through one chokepoint. Some teams split into private vs shared memory tiers to let agents work locally until they need to sync. Adds complexity, but scales better when you're past 3-4 agents.",
          "score": 0,
          "created_utc": "2026-01-28 00:57:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql3ufd",
      "title": "Langchain In production",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "author": "niklbj",
      "created_utc": "2026-01-23 21:39:55",
      "score": 11,
      "num_comments": 28,
      "upvote_ratio": 0.83,
      "text": "HI guys, i've realized a lot of us are using langchain or building agents in some of personal or official projects that are in prod. Wanted to start a discord server specific for those of us who are building AI and agent applications in prod to talk about any issues, suggestions, or advice.\n\nHere's the server: [https://discord.gg/qJVQgX2z](https://discord.gg/qJVQgX2z). Feel free to join!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1bh85l",
          "author": "HawkingsLovechild",
          "text": "Langchain is neither lightweight nor mature enough to be dependable in production in my experience. Works fine for POCs but I would reject any PR that attempts to add it to our stack.\n\nEdit: I just checked and installing langchain installed 32 packages, taking 20mb.\n\n  \nEdit2: OP has had half a dozen posts removed in the last month for spam promoting some B2B saas LLM nonsense across various subreddits . Go build a product people actually wanna use bro.",
          "score": 10,
          "created_utc": "2026-01-23 22:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1biayp",
              "author": "AdditionalWeb107",
              "text": "I am generally framework-averse. The tight coupling, lack of interoperability between other frameworks, and no clear separation of concerns makes we very weary. For example, I am not sure why I am left to my own devices to solve all the plumbing work vs. it being implemented via some standards-based infrastructure.\n\nEdit; Talking about decoupling and separating plumbing from business logic https://github.com/katanemo/plano",
              "score": 5,
              "created_utc": "2026-01-23 22:05:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bp64c",
                  "author": "HawkingsLovechild",
                  "text": "I don't think Langchain is a dead project or anything, I love the enthusiasm. But I wouldn't have used FFMPEG in 2004. Nor would I trust this open source project at this point in its lifecycle, especially when the core - the web APIs it basically wraps, could and do change on a dime.\n\n  \nNone of this applies if you're building personal projects, but if you have thousands of users paying you money, it's a different story.",
                  "score": 3,
                  "created_utc": "2026-01-23 22:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bi6hj",
              "author": "niklbj",
              "text": "Interesting, i've seen a ton of startups especially in the earlier days - series A and before building agents using langchain but that makes sense. What framework do you guys use?\n\nRegardless, just updated server to be framework agnostic! It's now just about building and scaling agents in production",
              "score": 2,
              "created_utc": "2026-01-23 22:05:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bjxcz",
                  "author": "HawkingsLovechild",
                  "text": "I am in a startup myself as the tech lead. We don't need LLM frameworks. We write code that calls the APIs. They already did the hard work. Everything Langchain does you can do yourself in a hilariously short amount of time, with more control, tailored to your business needs. \n\n  \nI don't mean to sound like a dick but I genuinely have no idea what Langchain is solving for people. What problem does your company have that you determined it was easier to use Langchain for?",
                  "score": 4,
                  "created_utc": "2026-01-23 22:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1fjbnf",
              "author": "pizzababa21",
              "text": "I dont understand why 20mb is a problem",
              "score": 2,
              "created_utc": "2026-01-24 14:36:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d7btv",
              "author": "cuba_guy",
              "text": "Pretty tight ship over there, our nodejs monorepo has 8gb of node_modules and goes to prod multiple times a day :)",
              "score": 1,
              "created_utc": "2026-01-24 03:44:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1imizm",
              "author": "BurritoBashr",
              "text": "my company uses LangChain/Graph in production with LangSmith. It's a popular artisan shopping site",
              "score": 1,
              "created_utc": "2026-01-24 23:12:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1opbut",
              "author": "cmndr_spanky",
              "text": "Report him then",
              "score": 1,
              "created_utc": "2026-01-25 20:31:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bi7ze",
              "author": "usernotfoundo",
              "text": "What's the alternative to it? Is it not dependable because further updates could lead to currently implemented features being deprecated?",
              "score": 1,
              "created_utc": "2026-01-23 22:05:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bj5bo",
                  "author": "HawkingsLovechild",
                  "text": "Using the API provided by the LLM developers and writing your own wrapping code around it. It's not particularly difficult - I maintain such a system for my company and it's a single python library with the SDKs in question and the requests library. I also get greater control and can respond to updates to say, openAI the day they're rolled out rather than waiting. \n\n  \nWhat features does langchain provide you that you can't write yourself? It's not a particularly complicated package.",
                  "score": 8,
                  "created_utc": "2026-01-23 22:09:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1dbiyl",
          "author": "code_vlogger2003",
          "text": "Hey hi guys,  i already shipped the react style multi agents in the production using the langchain and it's currently serving in the production. Ok high level the end product of the pipeline is a detailed report which contains text, images and tables etc based on unstructured raw time series data. For the control and monitoring I have debugged their call backs and written detailed functions for precise calculation that match with manual calculation. This monitoring helps us to understand the costs of the api and believe me that on average for one detailed report it takes around 0.15 $ which the report includes the multi model calls too.",
          "score": 2,
          "created_utc": "2026-01-24 04:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bdiv6",
          "author": "AdditionalWeb107",
          "text": "This is cool - shouldn't the Langchain guys host and moderate this type of discord themselves?",
          "score": 1,
          "created_utc": "2026-01-23 21:43:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bh18a",
              "author": "mdrxy",
              "text": "We have a community slack! https://www.langchain.com/join-community",
              "score": 3,
              "created_utc": "2026-01-23 21:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bi7fy",
                  "author": "niklbj",
                  "text": "that's sick!",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bdv1e",
              "author": "niklbj",
              "text": "totally open to them doing so if anybody from Langchain wants to help moderate it! didn't see something like this out there, so thought I'd create one and handle it for now",
              "score": 2,
              "created_utc": "2026-01-23 21:44:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bevvc",
                  "author": "AdditionalWeb107",
                  "text": "I use stock python - so this wouldn't be a great fit for me personally, but I see the value. Thanks for creating it OP",
                  "score": 2,
                  "created_utc": "2026-01-23 21:49:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1uiews",
          "author": "pbalIII",
          "text": "Timing matters more than framework choice here. The 45% never-make-it-to-production stat floating around matches what I've seen... teams build POCs with LangChain, then strip it out when the 32-package dependency graph starts slowing deploys and the abstractions get in the way of a custom memory or retry pattern.\n\nThe counter-argument is observability. LangSmith alone is worth more than person-months of custom tracing work, and switching LLM providers with a one-line change saves real time during vendor negotiations.\n\nMy heuristic: if you're calling one model with a straightforward RAG pipeline, raw SDK wins. If you're juggling 3+ providers, need async multi-agent coordination, or want prod tracing out of the box, LangChain still earns its keep. The middle ground is messy.",
          "score": 1,
          "created_utc": "2026-01-26 16:48:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bj5i5",
          "author": "peejay2",
          "text": "I fw agno",
          "score": 0,
          "created_utc": "2026-01-23 22:09:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qna46j",
      "title": "Best practice for managing LangGraph Postgres checkpoints for short-term memory in production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/",
      "author": "Major_Ad7865",
      "created_utc": "2026-01-26 08:05:35",
      "score": 11,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "‚Äôm building a memory system for a chatbot using **LangGraph**.  \nRight now I‚Äôm focusing on **short-term memory**, backed by **PostgresSaver**.\n\nEvery state transition is stored in the `checkpoints` table. As expected, each user interaction (graph invocation / LLM call) creates multiple checkpoints, so the checkpoint data in checkpoints table grows **linearly with usage**.\n\nIn a production setup, what‚Äôs the recommended strategy for managing this growth?\n\nSpecifically:\n\n* Is it best practice to **keep only the last N checkpoints per** thread\\_id  and delete older ones?\n* How do people balance **resume/recovery safety** vs **database growth** at scale?\n\nFor context:\n\n* I already use conversation summarization, so older messages aren‚Äôt required for context\n* Checkpoints are mainly needed for short-term recovery and state continuity, not long-term memory\n* LangGraph can **resume from the last checkpoint**\n\nCurious how others handle this in real production systems.\n\nAdditionally in postgres langgraph creates 4 tables regarding checkpoints : checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1v6nu7",
          "author": "TextHour2838",
          "text": "You‚Äôre already thinking about this the right way: treat checkpoints as operational logs, not permanent memory, and prune aggressively.\n\n\n\nMain point: keep only a small, rolling window per thread (last N or last T minutes/hours) and purge the rest with a background job.\n\n\n\nWhat‚Äôs worked for us:\n\n\\- Per-thread policy: e.g., keep last 10‚Äì20 checkpoints or last 24h, whichever is smaller.\n\n\\- Time-based GC: daily job that deletes old checkpoints/checkpoint\\_writes/checkpoint\\_blobs by thread\\_id + created\\_at, in batches to avoid locks.\n\n\\- Promotion: anything you might need long-term (audit, analytics, durable memory) gets promoted into a separate, slimmer schema / vector store before you delete.\n\n\\- Safety: pair this with idempotent tools and a compensating-action log so you can replay from business events if a resume fails, not from ancient checkpoints.\n\n\n\nOn the tooling side, I‚Äôve mixed Supabase and RDS for this, and for chatbots in ecom I‚Äôve tried Gorgias and Intercom; Zipchat sits in that space too but handles the short-term vs long-term memory split for you so you don‚Äôt babysit raw checkpoint tables.\n\n\n\nSo: rolling window + periodic GC + promote anything important out of the checkpoint tables before pruning.",
          "score": 1,
          "created_utc": "2026-01-26 18:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1uya4l",
          "author": "AdditionalWeb107",
          "text": "This should be native to some substrate via durable APIs. Doing this by hand feels like a great way to mess it  up and also distract you from building your agent.",
          "score": 0,
          "created_utc": "2026-01-26 17:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp3lp3",
      "title": "We cache decisions, not responses - does this solve your cost problem?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qp3lp3/we_cache_decisions_not_responses_does_this_solve/",
      "author": "llm-60",
      "created_utc": "2026-01-28 06:21:30",
      "score": 10,
      "num_comments": 14,
      "upvote_ratio": 0.86,
      "text": "Quick question for anyone running AI at scale:\n\nTraditional caching stores the response text. So \"How do I reset my password?\" gets cached, but \"I forgot my password\" is a cache miss - even though they need the same answer.\n\nWe flip this: cache the **decision** (what docs to retrieve, what action to take), then generate fresh responses each time.\n\nResult: 85-95% cache hit rate vs 10-30% with response caching.\n\n**Example:**\n\n* \"Reset my password\" ‚Üí decision: fetch docs \\[45, 67\\]\n* \"I forgot my password\" ‚Üí same decision, cache hit\n* \"Can't log in\" ‚Üí same decision, cache hit\n* All get personalized responses, not copied text\n\n**Question: If you're spending $2K+/month on LLM APIs for repetitive tasks (support, docs, workflows), would this matter to you?**",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qp3lp3/we_cache_decisions_not_responses_does_this_solve/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o26v8xf",
          "author": "ruben_rrf",
          "text": "I get that you generate different outputs and cut the costs of having to make the tool calls and also the time. But how do you achieve a better cache rate? If I get it right...\n\nQuestion -> Actions -> Response\n\nIf you cache the Response, then you get a cache with Question -> Response, but if you cache the actions, you get a Question -> Actions cache, and then you use the model as \\[Question, Actions\\] -> Response.\n\nBut the key on the cache wouldn't be the same?",
          "score": 5,
          "created_utc": "2026-01-28 10:22:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26vsqv",
              "author": "llm-60",
              "text": "We don't cache the question, we cache the¬†**normalized intent**.\n\nWe extracts the \"meaning\" first:  \n  \n\"What's your return policy?\" - intent: return\\_policy  \n\"Can I return stuff?\" - intent: return\\_policy  \n\"How do returns work?\" - intent: return\\_policy\n\nand it also learn the context to fit the answer later...\n\nThree different questions, same cache key = cache hit.\n\nThat's how we get 80%",
              "score": 2,
              "created_utc": "2026-01-28 10:27:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2cgwn4",
          "author": "pbalIII",
          "text": "Intent normalization is doing the heavy lifting here. Most semantic cache implementations use embedding similarity directly on the query, which means you're still sensitive to phrasing variance even with cosine thresholds.\n\nCaching the decision output (retrieval path, action type) instead of the response is cleaner in theory... but you've moved the problem upstream. Now your intent extractor becomes the cache key generator, and any drift in how it normalizes inputs breaks your hit rate.\n\nMulti-intent queries are where this gets tricky. Something like a user forgetting their password and wanting to change their email maps to two decisions. The decomposition step either needs its own cache layer or you end up recomputing the split every time.",
          "score": 2,
          "created_utc": "2026-01-29 03:23:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2d3ttn",
              "author": "llm-60",
              "text": "Great observations. You're right - intent extraction is doing the heavy lifting, and that's intentional.\n\n**On drift:**¬†Valid concern. We handle this with versioned extraction models + policy rules as fallbacks. If the extractor changes, old cache keys naturally expire (TTL). You can also monitor extraction confidence and invalidate cache when you update the model. Not perfect, but manageable.\n\n**On multi-intent queries:**¬†You're absolutely right - this is a known limitation. \"Reset password AND change email\" currently goes to low confidence ‚Üí bypasses cache ‚Üí escalates.\n\nFor v1, we're targeting single-intent policy decisions (returns, approvals, routing). Multi-intent decomposition is on the roadmap (Phase 2), likely with its own caching layer as you suggest.\n\nThe trade-off: Embedding similarity gives you \\~30-40% hit rates with fuzzy matching. Intent extraction gives 80%+ when queries fit the pattern, but breaks on edge cases. We're betting that most high-volume use cases (support, returns, routing) are single-intent dominant.",
              "score": 1,
              "created_utc": "2026-01-29 05:56:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gbjd7",
                  "author": "pbalIII",
                  "text": "Versioned extractors with TTL is a clean solve for drift. The confidence threshold routing you described maps well to what I've seen in production semantic caches... the 0.8% false-positive rate most systems report happens exactly at those threshold boundaries where similarity is just above cutoff but intent diverges slightly.\n\nCurious about the 80%+ hit rate claim. Recent benchmarks on ensemble embedding approaches show 92% for semantically equivalent queries, but that's with careful threshold tuning per query type. Are you seeing 80%+ out of the box, or does that assume some domain-specific calibration?\n\nThe single-intent constraint is probably the right call for v1. Multi-intent decomposition adds a lot of surface area for edge cases, and most high-volume support flows are indeed single-intent dominant.",
                  "score": 1,
                  "created_utc": "2026-01-29 18:08:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27t0lu",
          "author": "SpecialBeatForce",
          "text": "Couldn‚Äòt you just use semantic caching question->answer if questions like reset password and forgot password are close enough semantically?",
          "score": 1,
          "created_utc": "2026-01-28 14:10:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27un18",
              "author": "llm-60",
              "text": "Traditional semantic caching caches the entire answer, so everyone gets the same response.\n\n**Example:**  \n  \n\"Forgot password\" - cached: \"Click the reset link in your email\"  \n\"Reset my password\" - cached: \"Click the reset link in your email\"\n\nWe cache the decision (what to do), then personalize the response.\n\n**Example:**  \n\"I'm John, forgot password\" - Decision cached: \"send reset email\"  Response: \"Hi John, we sent you a reset link\"  \n\"Sarah needs reset\" -Same cached decision - Response: \"Hi Sarah, we sent you a reset link\"\n\nOne LLM call for the logic, cheap model personalizes each response. You can't do that if you cache the full answer.",
              "score": 3,
              "created_utc": "2026-01-28 14:18:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o28fjzm",
                  "author": "SpecialBeatForce",
                  "text": "Okay i like the ideaüòä but i guess it comes down to a decision between personalized answers and saving compute?",
                  "score": 1,
                  "created_utc": "2026-01-28 15:56:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2bgmt3",
                  "author": "CourtsDigital",
                  "text": "i‚Äôm not sure i understand this use case. maybe provide some examples that require personalization. i‚Äôve never expected to receive a password reset email that‚Äôs tailored to me, or to hear about a store return policy that mentions me by name\n\ni agree with BeatForce that this seems almost exactly like semantic caching, with an additional, unnecessary LLM cost\n\ni‚Äôm not saying this couldn‚Äôt be useful, but if you intend to sell it for $1k+ per month then the use case(s) should be solid",
                  "score": 1,
                  "created_utc": "2026-01-29 00:06:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2d7yto",
          "author": "Khade_G",
          "text": "Yeah this would matter to anyone actually paying the bill. What you‚Äôre describing sounds like semantic / policy caching, and it‚Äôs way more aligned with how real systems behave than response caching. Most production queries don‚Äôt differ in intent, they differ in phrasing, tone, or user context. Caching text throws all that signal away; caching the decision preserves it.\n\nThe big wins I‚Äôve seen with this approach are much higher cache hit rates, fresh/personalized responses without re-doing expensive reasoning, and cleaner separation between ‚Äúunderstand the problem‚Äù and ‚Äúsay the answer‚Äù\n\nThe main things to watch out for are:\n- Decision drift: if your retrieval or routing logic changes, you need a clean way to invalidate or version the decision cache.\n- Over-generalization: making sure different intents don‚Äôt collapse into the same decision accidentally.\n- Debuggability: being able to explain why two queries mapped to the same decision.\n\nBut for support, docs, and workflow-heavy systems this is definitely the direction things are going. Once you cross ~$1‚Äì2k/month, optimizing reasoning reuse matters way more than token shaving. If you can make the cache safe and observable then this is a no-brainer.",
          "score": 1,
          "created_utc": "2026-01-29 06:29:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2d8jhq",
              "author": "llm-60",
              "text": "Appreciate this - you nailed the trade offs. We're addressing those exact concerns:\n\n* Decision drift: TTL-based expiry + policy versioning\n* Over-generalization: Confidence gating (low confidence - bypass cache)\n* Debuggability: Dashboard shows canonical state extraction + cache hit/miss audit trail\n\nAlready seeing 75% hit rates with policy based workloads on simulations and some test users.",
              "score": 2,
              "created_utc": "2026-01-29 06:33:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2d8t3j",
                  "author": "Khade_G",
                  "text": "Good stuff!",
                  "score": 1,
                  "created_utc": "2026-01-29 06:36:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qn6ydn",
      "title": "I built langgraph2slack - connect any LangGraph agent to Slack in 3 lines of code",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qn6ydn/i_built_langgraph2slack_connect_any_langgraph/",
      "author": "syasini",
      "created_utc": "2026-01-26 05:12:19",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "Hey everyone! I've been working on an open-source package called¬†`langgraph2slack`¬†that makes it super¬†easy to deploy your **LangGraph** agents¬†to **Slack**.\n\nHere's how you can set it up:\n\n    from¬†langgraph2slack¬†import¬†SlackBot\n    bot¬†=¬†SlackBot()\n    app¬†=¬†bot.app\n\nThen add it to your¬†langgraph.json:\n\n    {\n    ¬†¬†\"dependencies\":¬†[\"langgraph2slack\",¬†\".\"],\n    ¬†¬†\"graphs\":¬†{\n    ¬†¬†¬†¬†\"my-assistant\":¬†\"./agent.py:app\"\n    ¬†¬†},\n    ¬†¬†\"http\":¬†{\n    ¬†¬†¬†¬†\"/events/slack\":¬†\"slack/server:app\"\n    ¬†¬†}\n    }\n\nThat's it!\n\nThen run¬†`langgraph¬†dev`, point your Slack app's¬†event URL to it (ngrok works¬†great for local testing), and you're¬†done.\n\nhttps://reddit.com/link/1qn6ydn/video/pn3bxqh5mmfg1/player\n\n**The library currently handles**:\n\n* Real-time streaming responses (uses Slack's streaming API so users see tokens as they come in)\n* Thread management (conversation¬†history is preserved)\n* Works with DMs and mentions in channels/threads\n* Optional feedback buttons that integrate directly with LangSmith\n* Input/output¬†transformers if you need to customize messages¬†before/after they hit your agent\n* Markdown to Slack formatting conversion\n* Image extraction from markdown responses\n\n**Why I built this:**\n\nNow¬†that we're all building chatbots and agentic applications, one of the biggest challenges is getting them in front of users in a way that¬†actually gets adopted. Most enterprise teams already¬†live in Slack. So instead of asking people to¬†context-switch to a separate web app, it makes sense to bring your agent¬†to where they already are.\n\nThis was inspired by the¬†`langgraph-messaging-integrations`¬†repo¬†which was a great reference, but I wanted something I could just¬†pip install¬†and have running in minutes without a ton of setup.\n\nLinks:\n\n* GitHub: [https://github.com/syasini/langgraph2slack](https://github.com/syasini/langgraph2slack)\n* PyPI:¬†`pip install langgraph2slack`\n\nIt's MIT licensed, and I'd love for folks to try it out. If you end up using it or have¬†ideas for improvements, let me know!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qn6ydn/i_built_langgraph2slack_connect_any_langgraph/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qq0pdf",
      "title": "I built a RAG backend for non-developers who just want a simple chatbot",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qq0pdf/i_built_a_rag_backend_for_nondevelopers_who_just/",
      "author": "Unlikely_Outcome4432",
      "created_utc": "2026-01-29 06:12:04",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.8,
      "text": "Hey r/LangChain,\n\nI'm a PM who became a \"vibe coder\" ‚Äì I can read code and tweak things, but I'm not a traditional developer.\n\nWhile working as a freelancer on RAG chat services, I noticed something: a lot of people wanted to build simple RAG chatbots for non-commercial use, but the existing tools felt overwhelming for them.\n\nInstead of building custom chatbots for each person, I thought: \"What if I made a tool where you just change a config file and get a working RAG backend?\"\n\n\n\n**So I built OneRAG.**\n\n**The idea is simple:**\n\n\\- Want to switch from Chroma to Pinecone? Change one line in config.\n\n\\- Want to try Claude instead of GPT? Change one line.\n\n\\- Want to add a reranker? One line.\n\n\n\nIt uses dependency injection, so you don't need to rewrite code ‚Äì just swap components.\n\n\n\n**Currently supports:**\n\n\\- 6 Vector DBs (Chroma, Pinecone, Weaviate, Qdrant, pgvector, MongoDB)\n\n\\- 4 LLMs (OpenAI, Claude, Gemini, OpenRouter)\n\n\\- Rerankers, caching, Korean NLP optimization\n\nIt's not meant to replace LangChain for complex pipelines. It's for people who just want a working RAG backend without the learning curve.\n\nGitHub: [https://github.com/notaDev-iamAura/OneRAG](https://github.com/notaDev-iamAura/OneRAG)\n\nWould love feedback from this community ‚Äì what features would make this more useful for beginners?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qq0pdf/i_built_a_rag_backend_for_nondevelopers_who_just/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2l5j23",
          "author": "ich3ckmat3",
          "text": "Sweet!",
          "score": 1,
          "created_utc": "2026-01-30 11:49:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpfnym",
      "title": "I stopped manually iterating on my agent prompts: I built an open-source system that extracts prompt improvements from my agent traces",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qpfnym/i_stopped_manually_iterating_on_my_agent_prompts/",
      "author": "cheetguy",
      "created_utc": "2026-01-28 16:13:28",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 0.75,
      "text": "Some of you might remember my [post about ACE](https://reddit.com/r/LangChain/comments/1p35tko/your_local_llm_agents_can_be_just_as_good_as/) about my open-source implementation of ACE (Agentic Context Engineering). ACE is a framework that makes agents learn from their own execution feedback without fine-tuning.\n\nI've now built a specific application: **agentic system prompting** that does offline prompt optimization from agent traces (e.g. from LangSmith)\n\n**Why did I build this?**\n\nI kept noticing my agents making the same mistakes across runs. I fixed it by digging through traces, figure out what went wrong, patch the system prompt, repeat. It works, but it's tedious and didn't really scale.\n\nSo I built a way to automate this. You feed ACE your agent's execution traces, and it extracts actionable prompt improvements automatically.\n\n**How it works:**\n\n1. **ReplayAgent** \\- Simulates agent behavior from recorded conversations (no live runs)\n2. **Reflector** \\- Analyzes what succeeded/failed, identifies patterns\n3. **SkillManager** \\- Transforms reflections into atomic, actionable strategies\n4. **Deduplicator** \\- Consolidates similar insights using embeddings\n5. **Skillbook** \\- Outputs human-readable recommendations with evidence\n\n**Each insight includes:**\n\n* Prompt suggestion - the actual text to add to your system prompt\n* Justification - why this change would help based on the analysis\n* Evidence - what actually happened in the trace that led to this insights\n\n**Try it yourself**   \n[https://github.com/kayba-ai/agentic-context-engine/tree/main/examples/agentic-system-prompting](https://github.com/kayba-ai/agentic-context-engine/tree/main/examples/agentic-system-prompting)\n\nWould love to hear if anyone tries this with their agents!",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qpfnym/i_stopped_manually_iterating_on_my_agent_prompts/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2a3fbe",
          "author": "caprica71",
          "text": "How is this different from dspy?",
          "score": 1,
          "created_utc": "2026-01-28 20:17:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2afqgi",
              "author": "cheetguy",
              "text": "DSPy works best with structured input/output pairs, ACE works on raw traces (conversation logs, markdown) so no restructuring needed. DSPy auto-optimizes while ACE generates suggestions with evidence for you to review first. Think of DSPy for pipelines with clear metrics, ACE for learning from messy agent failures.",
              "score": 2,
              "created_utc": "2026-01-28 21:11:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2g798y",
          "author": "pbalIII",
          "text": "Trace-to-prompt pipelines are getting crowded fast. DSPy's MIPROv2 does bootstrap optimization, GEPA does evolutionary reflection, and ACE (the Stanford/SambaNova paper) does incremental playbook edits. All three extract patterns from execution traces... the difference is what happens next.\n\nDSPy needs structured I/O pairs. GEPA mutates prompt text directly and uses Pareto frontiers to keep diverse variants. ACE maintains a living context doc with delta edits so you don't get the brevity bias problem where insights get summarized away.\n\nThe 8 hours/week manual pattern analysis that u/KitchenSomew mentions is real. Curious whether your deduplicator handles semantic drift over time... embeddings cluster well initially but the similarity threshold that works at 100 traces often breaks at 1000.",
          "score": 1,
          "created_utc": "2026-01-29 17:49:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28mh9b",
          "author": "KitchenSomew",
          "text": "\\*\\*Production Agent Experience:\\*\\*\n\n\n\nBuilt chatbots for 50+ B2B clients - prompt drift is one of the hardest problems to catch early. Your ACE approach solves a massive pain point.\n\n\n\n\\*\\*What Resonates:\\*\\*\n\n\n\n‚úì Trace-based learning vs manual iteration (saves weeks of debugging)\n\n‚úì Offline optimization (no live experiments on customers)\n\n‚úì Embedding-based deduplication (critical at scale)\n\n\n\n\\*\\*Questions from Production:\\*\\*\n\n\n\n1. \\*\\*Token Cost:\\*\\* How expensive is running ReplayAgent + Reflector on 100+ conversations? Is it viable for startups?\n\n\n\n2. \\*\\*Prompt Versioning:\\*\\* Do you version the Skillbook outputs? We've had cases where a \"good\" prompt change broke edge cases 2 weeks later.\n\n\n\n3. \\*\\*Confidence Scoring:\\*\\* Does ACE rate how confident it is in each recommendation? Some patterns need 50+ traces to be statistically significant.\n\n\n\n\\*\\*Our Workflow (manual):\\*\\*\n\n\\`\\`\\`python\n\n\\# What we do now (tedious):\n\n1. Export LangSmith traces weekly\n\n2. Filter failures (user retry, escalation)\n\n3. Manual pattern analysis\n\n4. Prompt A/B test (3-7 days)\n\n5. Repeat\n\n\\`\\`\\`\n\n\n\nACE automating steps 2-3 would save \\~8 hours/week per agent.\n\n\n\n\\*\\*Pro Tip:\\*\\* For anyone trying this - start with failure-only traces. Analyzing successful runs adds noise early on.\n\n\n\nDoes ACE handle multi-agent systems? Curious if it can trace decisions across agent handoffs.",
          "score": -2,
          "created_utc": "2026-01-28 16:26:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql1m38",
      "title": "Open Source Serverless RAG Pipeline (Lambda + Bedrock) with React Component",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "author": "HatmanStack",
      "created_utc": "2026-01-23 20:14:08",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.9,
      "text": "I built a fully serverless RAG pipeline to avoid idle server costs and container management.\n\nRepo: [https://github.com/HatmanStack/RAGStack-Lambda](https://github.com/HatmanStack/RAGStack-Lambda)\n\nDemo: [https://dhrmkxyt1t9pb.cloudfront.net](https://dhrmkxyt1t9pb.cloudfront.net)\n\n(Login: [guest@hatstack.fun](mailto:guest@hatstack.fun) / Guest@123)\n\nBlog: [https://portfolio.hatstack.fun/read/post/RAGStack-Lambda](https://portfolio.hatstack.fun/read/post/RAGStack-Lambda)\n\nKey Features:\n\n* Frontend: Drop-in <ragstack-chat> web component (React 19).\n* Multimodal: Uses Amazon Nova to embed text, images, and videos.\n* Zero Idle Costs: Pure Lambda/Step Functions/DynamoDB architecture.\n* MCP Support: Connects directly to Claude Desktop and Cursor.\n* No Control Plane: All resources deployed in your AWS Account.\n\nDeployment is one-click via CloudFormation. Feedback welcome.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qol9sp",
      "title": "GraphRAG vs LangGraph agents for codebase visualization ‚Äî which one should I use?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qol9sp/graphrag_vs_langgraph_agents_for_codebase/",
      "author": "Dizzy-Item-7123",
      "created_utc": "2026-01-27 17:59:58",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.82,
      "text": "I‚Äôm building an app that visualizes and queries an entire codebase.\n\nStack:\nDjango backend\nLangChain for LLM integration\n\nI want to avoid hallucinations and improve accuracy. I‚Äôm exploring:\n\nGraphRAG (to model file/function/module relationships)\nLangGraph + ReAct agents (for multi-step reasoning and tool use)\n\nNow I‚Äôm confused about the right architecture.\nQuestions:\n\nIf I‚Äôm using LangGraph agents, does GraphRAG still make sense?\n\nIs GraphRAG a replacement for agents, or a retrieval layer under agents?\n\nCan agents with tools parse and traverse a large codebase without GraphRAG?\n\nFor a codebase Q&A + visualization app, what‚Äôs the cleaner approach?\n\nLooking for advice from anyone who‚Äôs built code intelligence or repo analysis tools.",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qol9sp/graphrag_vs_langgraph_agents_for_codebase/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o28zxqv",
          "author": "Striking-Bluejay6155",
          "text": "Sharing a tool I think does what you‚Äôre describing with graphrag in the background and the ability to to chat: https://code-graph.falkordb.com/",
          "score": 1,
          "created_utc": "2026-01-28 17:25:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g88my",
          "author": "pbalIII",
          "text": "They're different layers, not alternatives. GraphRAG handles your retrieval... file/function/module relationships as a knowledge graph that your agent queries. LangGraph handles orchestration... how your agent reasons through multi-step tasks.\n\nThe pattern that's working in production: build your code graph (Neo4j, FalkorDB, Memgraph all have SDKs for this), then let your LangGraph agent query it as a tool. The agent decides what to look up, GraphRAG returns the relevant subgraph.\n\nWithout the graph structure, agents can still traverse codebases but they waste tokens re-discovering relationships. With it, you get pre-indexed connections so the agent jumps straight to relevant files.\n\nFor visualization specifically, the graph is doing double duty... feeding both your UI and your agent's retrieval.",
          "score": 1,
          "created_utc": "2026-01-29 17:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l1l0o",
          "author": "Luneriazz",
          "text": "langraph is for rigid workflow... lets say every time you ask the agent must look at previous chat before searching into graphRAG. you use langgraph for something like that\n\nfor graphRAG, is for hierarchical knowledge query instead of nearest or similarity search",
          "score": 1,
          "created_utc": "2026-01-30 11:18:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkyu82",
      "title": "New! ampersend added as an official LangChain integration",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "author": "kevinjonescreates",
      "created_utc": "2026-01-23 18:32:11",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "Hey everyone - ampersend just got added to the official LangChain integration docs.\n\nIf you're building agents that need to call external services or other agents, this lets them handle payments autonomously. When a remote agent requires payment, ampersend negotiates and executes the payment automatically via x402.\n\nSetup is straightforward - configure your wallet and treasurer, and your LangChain agent can discover remote agent capabilities, send messages, and pay for services without manual intervention. You set spend limits and policies upfront.\n\nUseful if you're building agents that need to:\n\n* Call paid APIs or data services\n* Use other specialized agents (research, analysis, etc)\n* Operate autonomously without constant human approval\n\nDocs:[ https://docs.langchain.com/oss/python/integrations/tools/ampersend](https://docs.langchain.com/oss/python/integrations/tools/ampersend)\n\nHappy to answer questions about the x402 integration or agent-to-agent payments.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ab13a",
          "author": "Mammoth-Nectarine513",
          "text": "Hi , I want to use agent for payment. Do you think i can integrate? What are the pros and cons? \n\nMaybe we can discuss in dm?",
          "score": 1,
          "created_utc": "2026-01-23 18:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b4k3n",
              "author": "kevinjonescreates",
              "text": "Yes it would work great for payments. Using ampersend you can build buyer agents easily, with spending limits [https://docs.ampersend.ai/](https://docs.ampersend.ai/)\n\nHappy to help you if you need dm me!",
              "score": 1,
              "created_utc": "2026-01-23 21:01:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qm2lrs",
      "title": "Unable to distinguish between reasoning text and final response in streaming mode with tool calls",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "author": "Dragonfruit-Eastern",
      "created_utc": "2026-01-24 23:32:33",
      "score": 5,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "When streaming messages from Claude (Anthropic models) in LangGraph, the model sometimes includes explanatory text before making tool calls (e.g., \"I'll get the weather information for both New York and San Francisco for you.\").\n\nThe problem is that these text chunks arrive before the tool\\_use content blocks, making it impossible to determine whether the streaming text is:\n\n1. Preliminary reasoning/thoughts that precede a tool call, or\n2. The actual final response to the user\n\nThis creates a challenge for UI rendering, as we cannot know whether to display the text immediately or wait to see if a tool call follows.\n\n**Expected Behavior:**\n\nEither:\n\n* Provide a way to identify which text chunks are associated with tool calls versus final responses during streaming, or\n* Offer a configuration option to disable these preliminary text chunks entirely when tools are being used, so only the tool calls and final responses are streamed\n\n**Current Workaround:**\n\nCurrently, we must wait until the complete message is received to determine the message type, which defeats the purpose of streaming for real-time UI updates.\n\n**Script**\n\n    from langchain_openai import ChatOpenAI\n    from langgraph.graph import StateGraph, add_messages\n    from langchain.tools import tool\n    from langchain_anthropic import ChatAnthropic\n    from typing import TypedDict, Annotated\n    \n    \n    class State(TypedDict):\n        messages: Annotated[list, add_messages]\n    \n    \n    # Create a simple tool\n    @tool\n    def get_weather(city: str) -> str:\n        \n    \"\"\"Get weather information for a city.\"\"\"\n        \n    weather_data = {\"New York\": \"Rainy, 65¬∞F\", \"San Francisco\": \"Sunny, 70¬∞F\", \"London\": \"Cloudy, 55¬∞F\"}\n        return weather_data.get(city, f\"Weather data not available for {city}\")\n    \n    \n    from langgraph.prebuilt import ToolNode\n    \n    tools = [get_weather]\n    tool_node = ToolNode(tools)\n    \n    \n    # LLM node that can call tools\n    def llm_node(state: State):\n        llm = ChatAnthropic(\n            model=\"claude-sonnet-4-5-20250929\",\n            api_key=\"key\",\n        llm_with_tools = llm.bind_tools(tools)\n    \n        response = llm_with_tools.invoke(state[\"messages\"])\n        return {\"messages\": [response]}\n    \n    \n    # Build the graph\n    graph = StateGraph(State)\n    graph.add_node(\"llm\", llm_node)\n    graph.add_node(\"tools\", tool_node)\n    \n    \n    # Route: if the LLM calls a tool, go to tools node, otherwise end\n    def should_use_tools(state: State):\n        last_message = state[\"messages\"][-1]\n        # Check if the last message has tool calls\n        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n            return \"tools\"\n        return \"end\"\n    \n    \n    graph.set_entry_point(\"llm\")\n    graph.add_conditional_edges(\"llm\", should_use_tools, {\"tools\": \"tools\", \"end\": \"__end__\"})\n    graph.add_edge(\"tools\", \"llm\")  # After tools run, return to LLM\n    \n    compiled_graph = graph.compile()\n    \n    \n    if __name__ == \"__main__\":\n        # Stream and print all messages\n        from langchain.messages import HumanMessage\n    \n        initial_state = {\"messages\": [HumanMessage(content=\"What's the weather in New York and San Francisco?\")]}\n    \n        print(\"Streaming updates:\")\n        for event, type in compiled_graph.stream(initial_state, stream_mode=\"messages\"):\n            print(f\"{dict(event)}\")\n\nOutput\n\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': \"I'll get\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' the weather information for both New York and', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' San Francisco for you.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'input': {}, 'name': 'get_weather', 'type': 'tool_use', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': 'get_weather', 'args': {}, 'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': 'get_weather', 'args': '', 'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '{\"city\"', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '{\"city\"', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': ': \"New Yor', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': ': \"New Yor', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': ': \"New Yor', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'k\"}', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'k\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'k\"}', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'input': {}, 'name': 'get_weather', 'type': 'tool_use', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': 'get_weather', 'args': {}, 'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': 'get_weather', 'args': '', 'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '{\"', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '{\"', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'city\": ', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'city\": ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'city\": ', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '\"San F', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': '\"San F', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '\"San F', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'rancisco\"}', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'rancisco\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'rancisco\"}', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'tool_use', 'stop_sequence': None, 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 568, 'output_tokens': 108, 'total_tokens': 676, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, 'tool_call_chunks': [], 'chunk_position': 'last'}\n    {'content': 'Rainy, 65¬∞F', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'get_weather', 'id': '92288d1a-8262-42d3-90eb-38d68206c0f7', 'tool_call_id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'artifact': None, 'status': 'success'}\n    {'content': 'Sunny, 70¬∞F', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'get_weather', 'id': 'c53f55a1-fc34-4b81-b8f3-59212983719f', 'tool_call_id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'artifact': None, 'status': 'success'}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': \"Here's the current\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' weather:', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': '\\n\\n-', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' **New York**: Rainy,', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' 65¬∞F\\n- **San', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' Francisco**: Sunny, 70¬∞', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': 'F', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None, 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 754, 'output_tokens': 36, 'total_tokens': 790, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, ' tool_call_chunks': [], 'chunk_position': 'last'}",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ja45b",
          "author": "TwistCrafty7858",
          "text": "which version of langchain are you using ? your code is not displaying the stream mode but i guess the stream mode ¬´¬†messages¬†¬ª allows you to get only llm output without any AIMessage tool call etc .",
          "score": 2,
          "created_utc": "2026-01-25 01:16:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jfkdw",
          "author": "iso_what_you_did",
          "text": "This isn't a bug¬†- it's how¬†autoregressive models work.\n\n**The problem:**¬†Claude generates text¬†token-by-token. When it outputs \"I'll get the weather...\", it¬†hasn't generated the tool call¬†yet. The model doesn't know what's¬†coming next - it's predicting one token at a time.\n\n**You're asking:**¬†\"Can you label¬†this text as 'preliminary' before¬†the model decides¬†to call a¬†tool?\"\n\n**That's impossible.**¬†The model hasn't made that¬†decision yet when¬†the text streams out.\n\n**Your actual solution is already in the output:**\n\n    python'stop_reason': 'tool_use'  # vs 'end_turn'\n\nWhen streaming completes, check¬†the stop\\_reason. That tells¬†you if tools were called.\n\n**Real options:**\n\n1. Buffer the stream until complete,¬†then decide how¬†to render\n2. Show the preliminary¬†text (it's actually¬†good¬†UX - users see the model \"thinking\")\n3. Accept that¬†streaming +¬†tool calls means¬†some uncertainty¬†until completion",
          "score": 2,
          "created_utc": "2026-01-25 01:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1jmywj",
              "author": "Dragonfruit-Eastern",
              "text": "Thanks for your detailed answer. I use exactly the second option. I pretend it‚Äôs the main response until I get a tool use flag for that message id. But not sure about this is the best for UI. Because for example when I use Claude Sonnet in Pycharm Github Copilot extension, It can separate thinking/tool using explanations while it‚Äôs streaming on UI. Maybe they use another abstraction or algorithm to distinguish. That‚Äôs why I thought there might be a way.",
              "score": 1,
              "created_utc": "2026-01-25 02:27:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1kpbi4",
          "author": "Over_Krook",
          "text": "You pasted your hardcoded api key‚Ä¶",
          "score": 2,
          "created_utc": "2026-01-25 06:27:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iv0if",
          "author": "AdditionalWeb107",
          "text": "Please don't use LangcChain for this - just simply call the model APIs or use a passthrough proxy that gives you a unified API.   You don't want to be bound to a framework here, you want to be bound to an API. And I am not sure why you are using LangGraph for this use case of too calls?\n\nUse LangChain for modelling your business objects, not LLM calls.",
          "score": -2,
          "created_utc": "2026-01-24 23:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1j7ogg",
              "author": "Dragonfruit-Eastern",
              "text": "I get what you're saying, but my app supports multiple LLM providers (OpenAI, Gemini, Anthropic, etc.). Isn't that literally the point of LangChain - to abstract away the different APIs?\n\nI'm just using basic stuff: tool calling and streaming. Not doing anything complex with LangGraph, just the standard tool flow.\n\nIf I call each API directly, I'd have to write the same logic 3+ times for each provider. That's exactly what the framework is supposed to solve, no?",
              "score": 4,
              "created_utc": "2026-01-25 01:02:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1j873w",
                  "author": "AdditionalWeb107",
                  "text": "no you wouldn't you need to use a high-performance, high-throughput proxy that allows you write code ergonomically using any popular client (Anthropic, OpenAI) and common APIs (like v1/chat/completions or v1/messages. You could review liteLLM or [Plano](https://github.com/katanemo/plano). There are other options out there for the same use case.",
                  "score": 1,
                  "created_utc": "2026-01-25 01:05:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qp2yk2",
      "title": "Advice on Consistent Prompt Outputs Across Multiple LLMs in LangChain",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qp2yk2/advice_on_consistent_prompt_outputs_across/",
      "author": "NoEntertainment8292",
      "created_utc": "2026-01-28 05:47:02",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hi all, I‚Äôm experimenting with building multi-LLM pipelines using LangChain and trying to keep outputs consistent in **tone, style, and intent** across different models.\n\nHere‚Äôs a simplified example prompt I‚Äôm testing:\n\n    You are an AI assistant. Convert this prompt for {TARGET_MODEL} while keeping the original tone, intent, and style intact.\n    \n    Original Prompt: \"Summarize this article in a concise, professional tone suitable for LinkedIn.\"\n\n**Questions for the community:**\n\n* How would you structure this in a LangChain `LLMChain` or `SequentialChain` to reduce interpretation drift?\n* Are there techniques for preserving tone and formatting across multiple models?\n* Any tips for chaining multi-turn prompts while maintaining consistency?\n\nI‚Äôd love to see how others handle **cross-model consistency in LangChain pipelines**, or any patterns you‚Äôve used.",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qp2yk2/advice_on_consistent_prompt_outputs_across/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o27e66m",
          "author": "Upset-Pop1136",
          "text": "we solved this by forcing a canonical JSON schema + a final ‚Äústyle normalizer‚Äù pass on one model. don‚Äôt fight every model, collapse outputs late. ",
          "score": 1,
          "created_utc": "2026-01-28 12:47:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2cin4c",
              "author": "NoEntertainment8292",
              "text": "That makes sense! Collapsing late feels cleaner than over-constraining each step. Do you keep the schema purely semantic (content + intent) and let the style normalizer handle tone entirely, or do you still encode style hints in the JSON? Also wondering how brittle this gets as you add more models to the pipeline?",
              "score": 1,
              "created_utc": "2026-01-29 03:34:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmkkkp",
      "title": "MAIRA",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qmkkkp/maira/",
      "author": "SiteCharacter428",
      "created_utc": "2026-01-25 14:30:26",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "üöÄ **MAIRA: Multi-Agent Intelligent Research Assistant for Automated Report Generation**\n\nI‚Äôm currently building **MAIRA**, a **research-oriented multi-agent AI system** designed to automate and streamline academic research workflows.\n\nFrameworks : Langchain , Deep Agents\n\nMAIRA focuses on problems students and researchers commonly face, such as:\n\n* conducting structured literature surveys\n* synthesizing information from academic papers and web sources\n* generating well-organized research drafts and reports\n\nThe system follows a **multi-agent architecture**, where specialized agents collaborate for:\n\n* academic and web-based information retrieval\n* deep reasoning across multiple sources\n* draft creation and validation\n* final report generation in reusable formats\n\nThe goal is not just answering questions, but producing **research-ready artifacts** that can be directly used for assignments, documentation, and academic submissions.\n\nI‚Äôm currently at the MVP stage and would love to get insights from the community:\n\n* What are the biggest pain points you‚Äôve faced while doing literature surveys or research documentation?\n* Are there workflows you feel could be better automated?\n* Any thoughts on multi-agent systems in academic research?\n\nI also attached planned architecture\n\nOpen to feedback, ideas, and discussions.  \nAlways excited to learn from fellow researchers and engineers üôå\n\nhttps://preview.redd.it/3i2e0ccp9ifg1.png?width=8192&format=png&auto=webp&s=97b09bbe0889a430aeab99023319f8872a9c1a0d\n\n\\#ResearchAI #MultiAgentSystems #AcademicResearch #AIEngineering #EdTech #LLM #Automation #StudentResearch",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmkkkp/maira/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1nnh0f",
          "author": "radicalSymmetry",
          "text": "My two cents: use duckdb and files if this is just for you. Don‚Äôt bring a db online unless you intend to build a product. And then that ocean is pretty red. \n\nFocus on getting the research right and for that the eng side stuff is likely overkill. \n\nGl;hf",
          "score": 3,
          "created_utc": "2026-01-25 17:49:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qz57z",
              "author": "SiteCharacter428",
              "text": "Appreciate the feedback that‚Äôs a fair point.\n\nFor pure local experimentation, I agree that DuckDB + files would be sufficient and much lighter. In my case though, the goal isn‚Äôt just to get outputs, but to study and document system level design choices in a research-oriented multi-agent architecture (persistence vs cache, traceability, extensibility, etc.).\n\nThe storage layer is mainly there to support reproducibility, agent trace analysis, and future evaluation, rather than productization. That said, I do see value in lightweight setups and may even mention DuckDB/file-based storage as an alternative configuration in the write-up.",
              "score": 1,
              "created_utc": "2026-01-26 02:56:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l90jo",
          "author": "dephraiiim",
          "text": "For streamlining your report generation workflow, you might want to check out [writer.so](http://writer.so); it handles research and drafting in one place instead of juggling multiple tools.\n\nCould save you serious time on the writing side of MAIRA!",
          "score": 2,
          "created_utc": "2026-01-30 12:15:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lspo5",
              "author": "SiteCharacter428",
              "text": "Thanks for the heads up, will check it out.",
              "score": 1,
              "created_utc": "2026-01-30 14:09:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qnckty",
      "title": "Multi Agent system losing state + breaking routing. Stuck after days of debugging.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qnckty/multi_agent_system_losing_state_breaking_routing/",
      "author": "goodevibes",
      "created_utc": "2026-01-26 10:34:03",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Hey team üëãüèº, I‚Äôm building a multi-agent system that switches between different personas and connects to a legacy API using custom tools. I‚Äôve spent a few days deep in code and Ive run into some architectural issues and I‚Äôm hoping to get advice from anyone who‚Äôs dealt with similar problems.\n\nCouple of the main issues I‚Äôm trying to solve;\n\nThe system forgets what it‚Äôs doing when asking for confirmation\n\n\\- I‚Äôm trying to set up a flow where the agent proposes an action, asks for confirmation, then executes it. But the graph loses track of what action was pending between turns, so when I say ‚Äúyes,‚Äù it just treats it like normal conversation instead of confirming the action I was asked about.\n\nPersonas keep switching unexpectedly\n\n\\- I have different roles (like admin vs. field user) that the system switches between. But the router and state initialization seem to clash sometimes, causing the persona to flip back to the wrong one unexpectedly. It feels like there‚Äôs some circular state issue or the defaults are fighting each other, but I can‚Äôt for the life of me find them.\n\nTrouble passing context into tools\n\n\\- I need to inject things like auth tokens and user context when tools actually run. But this causes type errors because the tools aren‚Äôt expecting those extra arguments. I‚Äôm not sure what the clean pattern is for handling stateful context when the tools themselves are supposed to be stateless. This is relatively new for the projects I have been working on.\n\nThe legacy API is misleading\n\n\\- The API returns a 200 success code even when things actually fail (bad parameters, malformed XML, etc). Agents think everything worked when it didn‚Äôt, which makes debugging inside the graph really frustrating.\n\nWhat I‚Äôm hoping to find some solid advice on is;\n\n\\- Best way to debug why state gets wiped between nodes/turns\n\n\\- The standard pattern for propose ‚Üí confirm ‚Üí execute flows\n\n\\- How to make personas ‚Äústick‚Äù without conflicting with graph initialization\n\n\\- How others cleanly pass execution context into tools\n\nIf you‚Äôve built something similar, I‚Äôd really appreciate any pointers or heads-up about gotchas. I feel like I‚Äôm missing a few fundamental patterns and just going in circles at this point.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã I‚Äôve watched a heap of YouTube guides etc, studied Dev docs but I feel like I‚Äôve hit a point where I‚Äôm going in circles üòÆ‚Äçüí®\n\nCheers :)",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qnckty/multi_agent_system_losing_state_breaking_routing/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1tc1td",
          "author": "bzImage",
          "text": "Langgraph",
          "score": 1,
          "created_utc": "2026-01-26 13:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1tnxd1",
          "author": "Tough-Permission-804",
          "text": "just use github agent via vs code.  it will help you get sorted",
          "score": 1,
          "created_utc": "2026-01-26 14:31:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21t3qv",
          "author": "kacxdak",
          "text": "I think it‚Äôs just a fundamental approach of how to think about agents. \n\nhttps://youtu.be/wD3zieaV0Yc?si=SVu-nJhiUmZ8nJ-S (Starting at 4:37)\n\nOnce you model agents and tool calling into traditional software (as opposed to new paradigms), controlling an agent becomes a lot easier.",
          "score": 1,
          "created_utc": "2026-01-27 17:17:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o22nv9e",
          "author": "YUYbox",
          "text": "\nSharing a tool I built for anyone running multi-agent AI systems.\n\nThe problem: When LLMs talk to each other, they develop patterns that are hard to audit - invented acronyms, lost context, meaning drift.\n\nThe solution: InsAIts monitors these communications and flags anomalies.\n\nfrom insa_its import insAItsMonitor\n\nmonitor = insAItsMonitor()  # Free tier, no key needed\nmonitor.register_agent(\"agent_1\", \"gpt-4\")\n\nresult = monitor.send_message(\n    text=\"The QFC needs recalibration on sector 7G\",\n    sender_id=\"agent_1\"\n)\n\nif result[\"anomalies\"]:\n    print(\"Warning:\", result[\"anomalies\"])\n\nFeatures:\n- Local processing (sentence-transformers)\n- LangChain & CrewAI integrations\n- Adaptive jargon dictionary\n- Zero cloud dependency for detection\n\nGitHub: https://github.com/Nomadu27/InsAIts\nPyPI: pip install insa-its",
          "score": 1,
          "created_utc": "2026-01-27 19:29:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1tz4l0",
          "author": "saurabhjain1592",
          "text": "You‚Äôre not missing a random trick, you‚Äôve hit a real architectural boundary that most agent frameworks don‚Äôt make explicit.\n\nAll four issues you describe stem from the same root problem: execution-critical state is implicit and conversational, not explicit and owned.\n\nIn propose ‚Üí confirm ‚Üí execute flows, the ‚Äúpending action‚Äù cannot live only in the LLM context. It needs to be a first-class execution object that survives turns, otherwise a simple ‚Äúyes‚Äù has no stable referent.\n\nPersona flipping is usually the same issue in disguise. Routing logic and initialization are both mutating shared state, so whichever runs last wins.\n\nTool context injection breaks because tools are treated as stateless functions, while the system actually needs scoped execution context (auth, role, intent) that is managed outside the tool signature.\n\nAnd legacy APIs returning 200 on failure is the worst case for agents, because success needs to be derived from semantic validation, not HTTP status.\n\nThe common pattern that helps is to separate:\n\n* conversational reasoning (LLM context)\n* execution state (what is pending, allowed, approved, failed)\n\nOnce those are decoupled, confirmation flows, personas, retries, and debugging become tractable again.\n\nYou‚Äôre not going in circles because you‚Äôre bad at this. You‚Äôre there because the abstractions stop short right where things become stateful and irreversible.",
          "score": 0,
          "created_utc": "2026-01-26 15:25:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq8v85",
      "title": "Why email context is way harder than document RAG",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qq8v85/why_email_context_is_way_harder_than_document_rag/",
      "author": "EnoughNinja",
      "created_utc": "2026-01-29 13:41:51",
      "score": 4,
      "num_comments": 6,
      "upvote_ratio": 0.7,
      "text": "I've been seeing a lot of posts on Reddit and other forums about connecting agents to Gmail or making \"email-aware\" assistants.\n\nI don't think it's obvious why this is much harder than document RAG until you're deep into it, so here's my breakdown.\n\n**1. Threading isn‚Äôt linear**  \nEmail threads aren‚Äôt clean sequences. You‚Äôve got nested quotes, forwards inside forwards, and inline replies that break sentences in half. Standard chunking strategies fall apart because boundaries aren‚Äôt real. You end up retrieving fragments that are meaningless on their own.\n\n**2. ‚ÄúWho said what‚Äù actually matters**  \nWhen someone asks ‚Äúwhat did they commit to?‚Äù, you have to separate their words from text they quoted from someone else. Embeddings optimize for semantic similarity, rather than for authorship or intent. \n\n**3. Attachments are their own problem**  \nPDFs need OCR. and images need processing, and also Calendar invites are structured objects. Often the real decision lives in the attachment, not the email body, but each type wants a different pipeline.\n\n**4. Permissions break naive retrieval**  \nIn multi-user systems, relevance isn‚Äôt enough. User A must never see User B‚Äôs emails, even if they‚Äôre semantically perfect matches. Vector search doesn‚Äôt care about access control unless you‚Äôre very deliberate.\n\n**5. Recency and role interact badly**  \nThe latest message might just be ‚ÄúThanks!‚Äù while the actual answer is found eight messages back. But you also can‚Äôt ignore recency, because the context does shift over time.\n\nRAG works well for documents because documents are self-contained, but email threads are relational and so the meaning lives in the connections between messages.\n\nThis is the problem we ended up building [iGPT](https://www.igpt.ai/) around.\n\nHappy to talk through edge cases or trade notes if anyone else is wrestling with this.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qq8v85/why_email_context_is_way_harder_than_document_rag/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2euxsg",
          "author": "PAChilds",
          "text": "You certainly nailed the issues with email. \n\nEmail also has a time element critical to investigations. The headers include a raft of metadata also of use to investigations. Finally any differences in the display names associated with a specific email address can indicate an intent to deceive or sidebar conversation between a subset of copied parties.",
          "score": 2,
          "created_utc": "2026-01-29 14:06:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f1x93",
          "author": "Lumpy-Comedian-1027",
          "text": "Definitively a complex challenge. But i really don't want to use a SaaS for this. But a library that solves the threading issue would be great, even if it is a bit simplistic - people usually just put their answer on the top of the last mail.",
          "score": 1,
          "created_utc": "2026-01-29 14:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i3yzg",
              "author": "jsjoana",
              "text": "For sure! A library that helps with threading could save a lot of headaches. Even a simple solution that just consolidates replies would be a game changer. It‚Äôs wild how much context gets lost in those nested conversations.",
              "score": 1,
              "created_utc": "2026-01-29 23:16:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2fc42w",
          "author": "Trawling_",
          "text": "Why wouldn‚Äôt someone just use copilot for outlook on m365?\n\nHave you compared the two against a defined baseline of tests? What problem are you solving and for who?",
          "score": 1,
          "created_utc": "2026-01-29 15:30:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gb7n9",
          "author": "pbalIII",
          "text": "Inbox RAG goes sideways if you treat each message as standalone. Meaning lives in reply structure and who was in the room, drop that and you'll keep pulling the wrong slice. Parse the tree from headers, keep quote depth and inline edits as annotations, and store decisions, commitments, owners as fields. Filter by participant before vector search so perms and relevance stay tied.",
          "score": 1,
          "created_utc": "2026-01-29 18:07:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kaz13",
          "author": "R-4553",
          "text": "Input compression could be interesting to try with this use case although I'd might want to protect some parts of the input from compression",
          "score": 1,
          "created_utc": "2026-01-30 07:22:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}