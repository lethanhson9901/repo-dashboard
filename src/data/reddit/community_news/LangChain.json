{
  "metadata": {
    "last_updated": "2026-02-21 08:57:51",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 84,
    "file_size_bytes": 116464
  },
  "items": [
    {
      "id": "1r8k1qu",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/wo2lnacmfckg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 00:12:36",
      "score": 123,
      "num_comments": 16,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r8k1qu/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o666sm6",
          "author": "Reasonable-Froyo3181",
          "text": "Ok",
          "score": 3,
          "created_utc": "2026-02-19 02:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66anvg",
              "author": "DeathShot7777",
              "text": "Thanks",
              "score": 2,
              "created_utc": "2026-02-19 02:44:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67jxom",
          "author": "Msense_",
          "text": "Impressive!",
          "score": 3,
          "created_utc": "2026-02-19 08:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67k739",
              "author": "DeathShot7777",
              "text": "‚ù§Ô∏è",
              "score": 1,
              "created_utc": "2026-02-19 08:25:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67ka5m",
          "author": "DeathShot7777",
          "text": "Thanks for all the github stars idk where they r coming from. But holly shit 496 stars üò≠",
          "score": 2,
          "created_utc": "2026-02-19 08:26:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o65ozs6",
          "author": "VanillaOk4593",
          "text": "Obsidian on steroids!",
          "score": 1,
          "created_utc": "2026-02-19 00:39:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65zx0p",
              "author": "DeathShot7777",
              "text": "üòÅ",
              "score": 1,
              "created_utc": "2026-02-19 01:42:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66irxh",
          "author": "SithLordRising",
          "text": "Very cool. Working on a thinking engine myself",
          "score": 1,
          "created_utc": "2026-02-19 03:33:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o677mug",
              "author": "DeathShot7777",
              "text": "Thanks. What's your approach?",
              "score": 1,
              "created_utc": "2026-02-19 06:32:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o696gin",
                  "author": "ble1901",
                  "text": "I'm focusing on integrating neural networks with a more interactive user interface. The goal is to make it easier for users to experiment and see real-time results. What about your thinking engine?",
                  "score": 2,
                  "created_utc": "2026-02-19 15:25:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6bzo69",
                  "author": "SithLordRising",
                  "text": "Just spent time going through the GitNexus codebase in detail. Really impressive work. A few things stood out:\n\n\\- The phased ingestion pipeline is cleanly separated - structure ‚Üí parse ‚Üí resolve ‚Üí relate ‚Üí cluster ‚Üí trace ‚Üí embed. That's a strong pattern.\n\n\\- Leiden community detection on the relationship graph is a smart choice. The heuristic labelling from folder/naming patterns is pragmatic.\n\n\\- Process tracing via BFS from scored entry points is elegant. The confidence tiers on CALLS edges (import-resolved ‚Üí same-file ‚Üí fuzzy-global) show good engineering judgment.\n\n\\- RRF for combining BM25 + semantic search is the right call over trying to normalize different score scales.\n\n\\- KuzuDB as the embedded graph store is an interesting choice - embedded like SQLite but with native Cypher traversal.\n\nI'm working on a knowledge infrastructure project where we compile documents - academic papers, technical standards, legal texts - into structured knowledge graphs with explicit relationships (prerequisites, dependencies, contradictions between sources). Think of it as applying the same intuition you've had about code to text: raw documents are to knowledge what source files are to architecture. Both need to be parsed into structured units and their relationships made explicit before you can reason about them properly. One of the differences we have is contradictions, something code typically fixes at compile.\n\nYour work has been genuinely useful for validating some architectural directions we've been considering, particularly around graph storage and hybrid search. The parallel between tracing execution flows through code and tracing reasoning chains through knowledge is  closer than I expected.\n\nGreat project. Following with interest.",
                  "score": 1,
                  "created_utc": "2026-02-19 23:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6kg1jn",
          "author": "cleverhoods",
          "text": "wow",
          "score": 1,
          "created_utc": "2026-02-21 07:40:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9u4uj",
      "title": "Noob question... is LangChain still relevant?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9u4uj/noob_question_is_langchain_still_relevant/",
      "author": "Odd-Aside456",
      "created_utc": "2026-02-20 12:31:58",
      "score": 65,
      "num_comments": 56,
      "upvote_ratio": 0.92,
      "text": "I'm planning to build an AI personal assistant. First capabilities it will need include the standard assistant stuff: calendar, contracts, email, tasks, etc. But EVENTUALLY I'd like to build it up to be able to do autonomous work to along the lines of research, building tools, etc, and acting more like an employee than an agent (similarish to the whole OpenClaw hype, but much more on rails and personalized). Doing some research on tech stacks with LLMs, I keep getting pointed to LangChain and / or LangGraph. However, doing some Googling of my own, I keep finding people who say they've moved away from LangChain or that it's generally disliked (which I find hard to fully believe). Given the rapid pace at which new AI technologies are being developed, is LangChain / LangGraph still hyper-relevant today, and applicable for my end goal?",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1r9u4uj/noob_question_is_langchain_still_relevant/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6f8r13",
          "author": "Friendly-Ask6895",
          "text": "LangChain gets a lot of hate but IMO most of it is from people who used it like a year ago when the API was changing every 2 weeks and the abstractions were pretty leaky. It's matured a lot since then. LangGraph specifically is actually really solid for the kind of agent workflows you're describing, especially when you need things like conditional branching, human-in-the-loop steps, and persistent state across conversations.\n\nThat said, for the basic personal assistant stuff (calendar, email, etc) you could honestly start with just raw API calls + function calling and get pretty far. The place where LangChain/LangGraph really starts paying off is when you want the agent to plan multi-step tasks, recover from errors, and maintain context across tool calls. Which sounds like exactly where you want to end up.\n\nI'd say start simple with direct API calls so you actually understand whats happening under the hood, then bring in LangGraph when you need the orchestration layer. Going straight to a framework before you understand the basics is how people end up confused when something breaks.",
          "score": 44,
          "created_utc": "2026-02-20 14:00:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsrgi",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 3,
              "created_utc": "2026-02-20 15:40:51",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6gwqop",
              "author": "Singularity-42",
              "text": "Does LangChain support image models now?\n\nI've tried it for a real production project in early 2023 (and it was the TS version) and I was so disgusted by the experience that I swore I'd never go back to Langchain again. The only value I ever got out of it was vendor consolidation. But just cumbersome as fuck.",
              "score": 2,
              "created_utc": "2026-02-20 18:43:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6h69er",
              "author": "mzinz",
              "text": "In each of these scenarios (direct API calls with LLM; LangGraph agents) - what are the common ways for invoking? Dependent on how you want the trigger to occur I assume, but what are the most common setups?\n\nThinking about things like:\n\n* checking email occasionally and sending a notification when an urgent email is identified (probably Cron?)\n* work scenario: a ticket is cut when a document is ready for review/approval. Need a way to monitor for tickets of that type to come in, then invoke the agent/call in some way\n\n",
              "score": 1,
              "created_utc": "2026-02-20 19:27:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6idatx",
              "author": "FMWizard",
              "text": "Code base is still spaghetti. Pedantic AI is super clean and reliable and their API is stable ie they are real software engineers.",
              "score": 1,
              "created_utc": "2026-02-20 23:04:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6iza49",
                  "author": "Budget_Bar2294",
                  "text": "the worst part of my amazing job is dealing with this crap ass framework. LangGraph is so much better but no one uses that. and the core abstractions in the Lang\\* ecosystem are awful anyway. the best part of my job is sneakily avoiding using LangChain whenever possible",
                  "score": 1,
                  "created_utc": "2026-02-21 01:12:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6evmc3",
          "author": "Freed4ever",
          "text": "Langchain IMO has a lot of fluff that is not needed. Langgraph OTOH is solid. But you can just build your own if I were you.",
          "score": 19,
          "created_utc": "2026-02-20 12:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsdck",
              "author": "Odd-Aside456",
              "text": "Good to know, thank you!",
              "score": 3,
              "created_utc": "2026-02-20 15:38:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ev3l9",
          "author": "Bubba_deets",
          "text": "if you care about long-term maintainability, keep the core logic modular so you‚Äôre not locked into any one framework",
          "score": 15,
          "created_utc": "2026-02-20 12:41:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsboi",
              "author": "Odd-Aside456",
              "text": "Good advice, thank you.",
              "score": 1,
              "created_utc": "2026-02-20 15:38:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffc2a",
          "author": "cleverhoods",
          "text": "I think LangGraph might still be relevant for those who want to work with graph based approach. However the more I dig into claude the more I question this thing. One thing LangGraph does absolutely fantastic - imo - is the visualisation of what is happening. ",
          "score": 4,
          "created_utc": "2026-02-20 14:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h7m9c",
              "author": "mzinz",
              "text": "Using LangStudio for visualization?",
              "score": 3,
              "created_utc": "2026-02-20 19:34:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hoqo5",
                  "author": "cleverhoods",
                  "text": "now reading back, yeah, that could be misunderstood. What I meant is that for agentic work I found LangSmith a great tool to \\*see what is going where, how token expensive it is, what goes to system prompt, to agent prompt, etc. Not \\*LangGraph for \\*visualization.",
                  "score": 3,
                  "created_utc": "2026-02-20 20:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6fszzg",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 0,
              "created_utc": "2026-02-20 15:41:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f3ypj",
          "author": "adlx",
          "text": "Have a look at deepagents, by LangChain. Your Ai assistant is already built üòÇ",
          "score": 6,
          "created_utc": "2026-02-20 13:34:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsees",
              "author": "Odd-Aside456",
              "text": "I'll check it out, thanks!",
              "score": 2,
              "created_utc": "2026-02-20 15:39:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fylnc",
          "author": "DavidtheLawyer",
          "text": "I find that Claude Code can accomplish much of this work, but I‚Äôm big fan of LangGraph.",
          "score": 3,
          "created_utc": "2026-02-20 16:08:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fzw0s",
              "author": "Odd-Aside456",
              "text": "I do love Claude Code. But I can't afford anything beyond the Pro plan right now, and I can't spend those precious tokens on an assistant at the moment.",
              "score": 4,
              "created_utc": "2026-02-20 16:14:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6g9jda",
                  "author": "DavidtheLawyer",
                  "text": "True, it does go hog sometimes",
                  "score": 2,
                  "created_utc": "2026-02-20 16:57:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ibab2",
          "author": "MathematicianSome289",
          "text": "Absolutely. It is the de-facto OSS choice. It‚Äôs why OSS-friendly companies like cloudflare have native support and why closed source companies like AWS built their own agent framework. They know langgraph is too portable given it‚Äôs ubiquity.",
          "score": 3,
          "created_utc": "2026-02-20 22:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fcqtx",
          "author": "Delicious-One-5129",
          "text": "Yes. LangChain is still a practical go to for prototyping and integrations.",
          "score": 5,
          "created_utc": "2026-02-20 14:21:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsvp2",
              "author": "Odd-Aside456",
              "text": "\"For Prototyping,\" So what would you recommend for production, assuming a product got to that point?",
              "score": 3,
              "created_utc": "2026-02-20 15:41:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hmb6z",
                  "author": "zhuki",
                  "text": "Its always prototyping, everything is just for prototyping, never production ü•≤",
                  "score": 9,
                  "created_utc": "2026-02-20 20:46:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6fe61z",
          "author": "Odd-Literature-5302",
          "text": "If you need more structured state and graph style workflows try LangGraph as a complement",
          "score": 2,
          "created_utc": "2026-02-20 14:28:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fsxc3",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-02-20 15:41:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fvq4y",
          "author": "PretendPop4647",
          "text": "As someone mentioned earlier,keep core things modular. \nCome the point, yes langchain especially deepagent is good.  They provide built in agent harness like file system,sub agent etc\n\nUsing it i built a job search agent.  you can check this out how i implement deepagent for get some idea.\n\nhttps://github.com/Rahat-Kabir/job-search-agent\n\nbtw when you finish your project, give us Update.",
          "score": 2,
          "created_utc": "2026-02-20 15:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fycs0",
              "author": "Odd-Aside456",
              "text": "Will do! And thank you!",
              "score": 2,
              "created_utc": "2026-02-20 16:07:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gu88x",
          "author": "micupa",
          "text": "Unpopular opinion: Langchain was very early.. we didn‚Äôt even need a framework to build on top of ai APIs.. now we are seeing the need but with a totally different approach: the problem isn‚Äôt the api or the code integration but the context and tools. Frameworks like openclaw are the new way of angetic frameworks, to build good ai assistant think in terms of a new layer of abstraction.",
          "score": 2,
          "created_utc": "2026-02-20 18:32:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g4gn1",
          "author": "AlexRenz",
          "text": "Who are you building this for - your own personal use? Then I'd rather see how far you can get with Claude or n8n first and see if this gets you there. \n\nIf you want to ship something that's an app to use for others, scalable or that you can sell, deploy it somewhere, scale it, trace it etc. that's a whole different thing. \n\nI find LangGraph to be a great option (and I'm not really differentiating between Chain & Graph tbh). Others have mentioned already that a lot of the online reviews are pre-version 1.0 which just came out end of last year and improved a ton of stuff. \n\nYou'll want to use their pre-built agent and customize that one with integrations and middleware. Nobody can really tell you where all the frameworks are going, so keep your stuff modular as much as you can. But honestly, you can optimize for that later - get started and don't overthink this before you must. And often, a lot of value will lie in your context and prompts which are portable. ",
          "score": 2,
          "created_utc": "2026-02-20 16:34:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6g5chv",
              "author": "Odd-Aside456",
              "text": "It's gonna start for personal use, but then I'm gonna ship it for some friends and family. If they receive it well, I'll probably make it public. Mainly for that reason I'm trying to stay provider/model agnostic.\n\nThanks so much for all the info!",
              "score": 2,
              "created_utc": "2026-02-20 16:38:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6gwahn",
                  "author": "EveYogaTech",
                  "text": "You could use Nyno (see my profile), unlike n8n it's open-source and it's based on multiple languages, so you can stay as agnostic as possible even though using a framework + GUI builder.\n\nLanguages currently supported: Python, Node, Typescript, PHP and Ruby.",
                  "score": 2,
                  "created_utc": "2026-02-20 18:41:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6h739u",
              "author": "mzinz",
              "text": "What do you mean by pre-built agents? Re-usable code they offer, or a diff package or product?",
              "score": 2,
              "created_utc": "2026-02-20 19:31:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffxdy",
          "author": "Hackerjurassicpark",
          "text": "Just feed your requirements to Claude code and let it build it from scratch. Langchain is unnecessary bloatware built for an age when the ability reuse code and design patterns were important. That is no longer the case now. Claude code can pretty much be your scaffolding using native components instead of an additional layer like Langchain.",
          "score": 2,
          "created_utc": "2026-02-20 14:38:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft34s",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-20 15:42:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6imf9r",
                  "author": "No_Indication_1238",
                  "text": "Do not listen to people in this sub. They are clueless. ",
                  "score": 4,
                  "created_utc": "2026-02-20 23:56:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6h6h5j",
              "author": "mzinz",
              "text": "If asking Claude to do it - would it make sense to ask it to use LangChain/LangGraph, though? If not, why?",
              "score": 1,
              "created_utc": "2026-02-20 19:28:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hxh3o",
                  "author": "Leo2000Immortal",
                  "text": "It's an extra layer of abstraction which does not really help much. It's easier to debug with less abstractions when things don't work as expected",
                  "score": 1,
                  "created_utc": "2026-02-20 21:41:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gkdyx",
          "author": "damanamathos",
          "text": "If you want to build an effective personal assistant, my recommendation is start with something like OpenCode or Claude Code (depending on which underlying model you want to use), then write custom command line tools that let it access calendar, email, tasks, image generation, whatever you want. Then give it skills so it can learn how to use all those commands when needed.\n\nI think this is the fastest way to get up to speed with building agents, which will help you think about how to build something more customised in code. The nice thing about using OpenCode is that it's open source so you can always see how they implement agents.\n\nI don't have a strong view on LangGraph as haven't seen their latest updates. I do use it in parts of my codebase for handling general LLM calls, and do have an older agent that runs on LangChain, though my more recent agents have all been custom code with direct calls to the provider APIs.",
          "score": 1,
          "created_utc": "2026-02-20 17:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hq2hx",
          "author": "sundevil21CS",
          "text": "I have found myself recently ditching langchain and graph and using models SDK structured outputs and manually chaining calls based off structured outputs.",
          "score": 1,
          "created_utc": "2026-02-20 21:04:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hqmxv",
          "author": "HotMud9713",
          "text": "with agent skill, not anymore",
          "score": 1,
          "created_utc": "2026-02-20 21:07:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ignqe",
          "author": "coreofapples-",
          "text": "Use Temporal and suddenly your life becomes infinitely easier",
          "score": 1,
          "created_utc": "2026-02-20 23:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6irwyk",
          "author": "AdWorried6080",
          "text": "tbh if you want to learn with project start with scratch then you started going to know how this chains,agent, memory and tools are working. If you build small stuff and can check langchain repo than you‚Äôll say why langchain need to use or not. Langchain is good starter for early knowledge and quick build stuff. But when it comes to more customisation, integration, scalability and cost you‚Äôll not go for any framework. As per experience big organisation often build their POC with this frameworks but when it comes to make a product then they‚Äôll create from scratch. It‚Äôs more reliable, scalable, cost optimised(highly needed, lacks in this frameworks), customisable and maintainable.",
          "score": 1,
          "created_utc": "2026-02-21 00:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jrbxi",
          "author": "autoshag",
          "text": "LangGraph for sure. \nAnd then within the nodes I usually use Claude Agents SDK, or OpenCode SDK or langchain depending on the complexity of the task",
          "score": 1,
          "created_utc": "2026-02-21 04:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jvpfd",
          "author": "sergeant113",
          "text": "Use baml-ai for all the core LLM abstraction. Don‚Äôt bother with langChain at all.",
          "score": 1,
          "created_utc": "2026-02-21 04:45:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k2uj4",
          "author": "bornwithmistake",
          "text": "you can vibe code a LangChain equivalent for internal use, focused on your exact workflows, with cleaner abstractions and fewer moving parts than the open source stack",
          "score": 1,
          "created_utc": "2026-02-21 05:41:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ka0ej",
          "author": "themessymiddle",
          "text": "Personal experience - I‚Äôve tested our same agentic workflow with langchain, strands, and Claude agents sdk and the langchain one has the best results. I think it‚Äôs because you have so much more control. It‚Äôs more complex to manage than something like Claude agents sdk, but you have much more granular control",
          "score": 1,
          "created_utc": "2026-02-21 06:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kfn8w",
          "author": "AloneSYD",
          "text": "I would honestly try Agno as it's much simpler compared to lang*  frameworks",
          "score": 1,
          "created_utc": "2026-02-21 07:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kgyhx",
          "author": "SaltedFesh",
          "text": "Only use LangGraph to build graph based workflow and some LangChain necessary components like chunking text, and directly use OpenAI sdk to work with AI",
          "score": 1,
          "created_utc": "2026-02-21 07:48:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fqaxw",
          "author": "Interesting_Ride2443",
          "text": "LangChain is great for prototyping and short workflows, but once you need durable state, retries, or long-running multi-step execution, you run into limits. Tools like Calljmp provide built-in execution management, pause/resume, and observability, which makes scaling autonomous agents more practical without reinventing all that infrastructure.",
          "score": 1,
          "created_utc": "2026-02-20 15:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ft59f",
              "author": "Odd-Aside456",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-02-20 15:42:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fth36",
                  "author": "sandman_br",
                  "text": "It‚Äôs a ad dude. Don‚Äôt fall for it",
                  "score": 6,
                  "created_utc": "2026-02-20 15:44:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gn80d",
          "author": "BeerBatteredHemroids",
          "text": "If you have to ask this, maybe you should just focus on learning the framework first",
          "score": -1,
          "created_utc": "2026-02-20 18:00:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4hhvp",
      "title": "Good UI / UX solution for langchain deployments",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r4hhvp/good_ui_ux_solution_for_langchain_deployments/",
      "author": "ddewaele",
      "created_utc": "2026-02-14 10:37:26",
      "score": 19,
      "num_comments": 14,
      "upvote_ratio": 1.0,
      "text": "We really like LangChain as an AI orchestration engine but we're seeing a shift that a lot of our customers come to expect more autonomy in defining agents / configuring models / managing data and knowledge bases themselves.\n\n  \nFor that a good UI / UX experience is required and that is something that Langchain is currently not able to provide. It lacks an off the shelf UI / UX solutions.\n\n  \nWe've tried using [https://github.com/langchain-ai/agent-chat-ui](https://github.com/langchain-ai/agent-chat-ui), customizing it a little bit (adding OIDC connectors and stuff), but it is not something we necessarily want to spend time on. You would have to build a lot of features on top of it to make it useful (sharing chats / multi-user chats / agent config / prompt mgmt / memory system). Langchain offers that on the backend via langsmith, but this is not really user-friendly.\n\nSolutions like LibreChat already offer a really nice UI/UX experience.\n\nWhat do you think the strategic vision of LangChain is with regards to this. \n\nDo they keep focussing on the engine and believe people should build their UI / UX solutions themselves ? \n\nShould all customizations be done on the LangGraph platform side of things (Langsmith)\n\nIs LangChain ChatUI the way to go ? (extending it yourself).\n\nHooking up LangChain to Librehcat (via Agent-as-a-tool) seems very limiting and also forces you to use 2 systems, 2 types of message threading , configuration , ....)\n\n  \nWonder what the communities thoughts are on this.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r4hhvp/good_ui_ux_solution_for_langchain_deployments/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5bmbc7",
          "author": "Otherwise_Wave9374",
          "text": "I have hit the same gap: LangChain/LangGraph is great as an orchestration layer, but most teams eventually need a real \"agent console\" for non-devs (prompt/version mgmt, tool permissions, KB/data connectors, chat sharing, audit logs, evals).\n\nOne path I have seen work is pairing the backend with a generic chat UI, then incrementally adding an admin surface just for agent config and observability. This overview might help frame the pieces: https://www.agentixlabs.com/blog/",
          "score": 6,
          "created_utc": "2026-02-14 11:03:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bmap5",
          "author": "Diao_nasing",
          "text": "Both assistant ui and copilotkit provide more complete ui, but assistant ui is not friendly to local deployment, and copilotkit has more bugs.",
          "score": 2,
          "created_utc": "2026-02-14 11:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cvlbz",
              "author": "ddewaele",
              "text": "Haven't tried either of them but will take a look.   \n  \nWas hoping the langchain team was going to give [https://github.com/langchain-ai/agent-chat-ui](https://github.com/langchain-ai/agent-chat-ui) some love but i have the impression they have a habit of launching stuff and then quickly abandoning it, leaving it in a pre-alpha state.",
              "score": 1,
              "created_utc": "2026-02-14 16:03:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5c0nxv",
          "author": "AccountantGlad9947",
          "text": "I‚Äôm building on top of chainlit for the UI. Was great and feature rich. Unsure what the future holds for the project but I like it.",
          "score": 1,
          "created_utc": "2026-02-14 13:03:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cvxu2",
              "author": "ddewaele",
              "text": "Do you use LangGraph platform and deploy your graphs to langgraph ? Or just embedding langchain in your own systems / backends",
              "score": 1,
              "created_utc": "2026-02-14 16:05:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5cx6m6",
                  "author": "AccountantGlad9947",
                  "text": "I use langgraph on my own servers",
                  "score": 1,
                  "created_utc": "2026-02-14 16:11:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5c7y2l",
          "author": "JasperTesla",
          "text": "What about a few boilerplate applications? The user may start off with one idea, and then find out they really prefer something else.",
          "score": 1,
          "created_utc": "2026-02-14 13:51:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cwr3h",
              "author": "ddewaele",
              "text": "Customers these day expect the following out of the box (without custom development) : \n\n\\- the ability to create their own agents (with prompts / tools / knowledge)  \n\\- want to link agents together (multi-agency via handoffs or tools)  \n\\- want to be able to share their agents  \n\\- have easy integration with their identity provider (azure / google / ...)  \n\\- have easy integration with their knowledge base (sharepoint / drive / ....)\n\nNot something you'll easily vibe-code into existence\n\nAt the end of the day I think 90% of the people are happy with a generic chat interface type application (like chatgpt). these things are multi-modal and very flexible.\n\nIn some cases you might want some agentic flows embedded in custom UI / UX, but I would say today that this is a minority of the cases\n\n\n\n",
              "score": 2,
              "created_utc": "2026-02-14 16:09:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5cz60v",
                  "author": "JasperTesla",
                  "text": "Hmm, I see. So basically they want an AI that makes AIs. Very amusing, but a fun challenge!\n\nWho are your customers, by the way? Are they other developers or people who use AI without knowing? Would they be okay with a low-code platform where they can drag-and-drop pre-built components?\n\nThe workflow you're describing sounds a bit like an n8n or LangDock workflow. n8n specifically would solve all of your issues, and I do know LangDock has a mechanism where you can explain to an AI what you want, and it builds the workflow itself. That might be worth trying out, or at least using as an inspiration.\n\nI think the best would be a system akin to Oracle VBCS, but with AI stuff, and focus on microservices with customisability.",
                  "score": 1,
                  "created_utc": "2026-02-14 16:21:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cr03b",
          "author": "International_Quail8",
          "text": "I built a custom UI using the AG-UI protocol. I stopped using CoPilotKit and went to the protocol layer instead. It‚Äôs easy to work with and customize and bonus: you‚Äôll actually understand the protocol!",
          "score": 1,
          "created_utc": "2026-02-14 15:39:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5csuzc",
              "author": "ddewaele",
              "text": "Does the custom UI also allow customers to create their own agents / prompts / knowledge ? \n\nThat's the main drawback we see as it requires a lot of custom dev to get all of that in place. Our clients aren't always willing to fund this type of development.\n\nNot to mention security, chat sharing , multi-user chats, ....  This would almost need to be a like a strategic thing within a company to put the time and effort in. (some context : we're a software development company delivering AI solutions to many different clients).  We don't think our added value should be in delivering a UI/UX experience for that. People nowadays see lots of platforms where you can create an agent , add some prompts and some documents and you have an agentic system. They also want this level of autonomy.\n\nWith an app like Librechat you get a lot of that stuff for free. But there is no clean way to integrate langchain into it, and Librechat's approach to multi agent systems (using handoffs) is more limited to what langchain has to offer.",
              "score": 1,
              "created_utc": "2026-02-14 15:49:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ct68v",
          "author": "ar_tyom2000",
          "text": "I've been working a lot with LangGraph and ran into this once graphs get large - understanding execution paths, branching, and why an agent behaved a certain way quickly becomes hard. I ended up building [https://github.com/proactive-agent/langgraphics](https://github.com/proactive-agent/langgraphics) to make complex graphs easier to follow and reason about during runs. My takeaway so far is that the ecosystem is still very engine-centric, and the operability/UX layer around real deployments is only starting to take shape.",
          "score": 1,
          "created_utc": "2026-02-14 15:50:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d4ztn",
          "author": "jannemansonh",
          "text": "lol this is literally the problem we kept running into too. ended up just using needle (needle.app) instead of trying to duct-tape a UI together. might be worth a look if you don't want to spend months building agent config screens and knowledge base integrations from scratch",
          "score": 1,
          "created_utc": "2026-02-14 16:50:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8x2mi",
      "title": "Alternative to LangChain memory for agents ‚Äî zero deps, file-based, 1ms search, no API key needed",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r8x2mi/alternative_to_langchain_memory_for_agents_zero/",
      "author": "fourbeersthepirates",
      "created_utc": "2026-02-19 11:43:44",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.79,
      "text": "I like LangChain for orchestration but always found the memory options limiting ‚Äî ConversationBufferMemory doesn't do real retrieval (just returns recent items), and VectorStoreRetrieverMemory needs an embedding API key and a vector store.\n\nI built antaris-memory as an alternative that sits in the middle: real relevance-ranked retrieval (BM25, not just recency), but with zero external dependencies. No OpenAI key, no Pinecone, no Chroma. Pure Python, file-based, portable.\n\n**Quick comparison:**\n\n||antaris-memory|LangChain Buffer|LangChain VectorStore|\n|:-|:-|:-|:-|\n|Search latency|1.01ms|0.005ms|Depends on provider|\n|Finds relevant (not just recent)|‚úì|‚úó|‚úì|\n|Scales past 1K memories|‚úì (sharding)|‚úó (dumps all to LLM)|‚úì|\n|API key required|None|None|Yes (embeddings)|\n|Persistent storage|‚úì (file-based)|‚úó (in-memory)|Depends on store|\n|WAL + crash recovery|‚úì|‚úó|Depends on store|\n\nIt's part of a larger suite (guard, router, context, pipeline) but antaris-memory works standalone:\n\npython\n\n    pip install antaris-memory\n    \n    from antaris_memory import MemorySystem\n    memory = MemorySystem(workspace=\"./my_agent_memory\")\n    memory.ingest(\"User prefers dark mode and uses Python 3.12\")\n    results = memory.search(\"what does the user prefer?\")\n\n293 tests on antaris-memory,  1,183 tests on the whole suite (0 failures), Apache 2.0. Also ships as an MCP server and an OpenClaw plugin.\n\nAll the modules work together and compliment each other though, and pipeline ties them all together. Take a look at the Git if you want to see the insides.  \n\n\nGitHub: [https://github.com/Antaris-Analytics/antaris-suite](https://github.com/Antaris-Analytics/antaris-suite)\n\nDocs: [https://docs.antarisanalytics.ai](https://docs.antarisanalytics.ai)\n\nSite: [https://antarisanalytics.ai](https://antarisanalytics.ai)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8x2mi/alternative_to_langchain_memory_for_agents_zero/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6a73rr",
          "author": "Delicious-One-5129",
          "text": "actually pretty cool. Zero deps and no API key is a big win, especially for local agents.\n\nBM25 for memory feels underrated too. Nice middle ground between dumb buffer and full vector stack. Gonna check the repo",
          "score": 3,
          "created_utc": "2026-02-19 18:21:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6auiky",
              "author": "fourbeersthepirates",
              "text": "Cool let me know what you think! Have a ton of features to add this week on the way to 3.0. Shared agent memory, sub-agent context and semantic search is next in line.",
              "score": 1,
              "created_utc": "2026-02-19 20:12:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7fsnr",
      "title": "Debugging LangChain agents is painful until you can visualize the full trace",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7fsnr/debugging_langchain_agents_is_painful_until_you/",
      "author": "ruhila12",
      "created_utc": "2026-02-17 19:19:32",
      "score": 11,
      "num_comments": 12,
      "upvote_ratio": 1.0,
      "text": "I really like working with LangChain, but debugging multi step agents can feel like a black box.\nWhen something breaks, it‚Äôs never obvious where it actually failed.\n\n\nDid retrieval return garbage?\n\n\nDid the reranker strip out the only useful chunk?\n\n\nDid the LLM just hallucinate?\n\n\nOr did the agent get stuck in some weird tool loop?\n\n\nFor the longest time, I was just staring at terminal logs and scrolling through JSON traces trying to piece things together. It technically works‚Ä¶ but once your chain gets even slightly complex, it becomes painful.\n\nRecently, I plugged my chains into a tracing tool (Confident AI) mostly out of frustration. I wasn‚Äôt looking for metrics or anything fancy. I just wanted to see what was happening step by step.\nThe biggest difference for me wasn‚Äôt scoring or dashboards. It was the visual breakdown of each hop in the chain. I could literally see:\n\n\nRetrieval step\n\n\nReranking\n\n\nTool calls\n\n\nLLM responses\n\n\nLatency per step\n\n\nAt one point, I realized my agent wasn‚Äôt ‚Äúfailing‚Äù randomly, it was looping on a specific tool call because my system prompt wasn‚Äôt strict enough about exit conditions. That would‚Äôve taken me way longer to diagnose just from logs.\n\nBeing able to replay a failed interaction and inspect the full flow changed how I debug. It feels less like guessing and more like actual engineering.\n\nCurious how others are handling debugging for multi-step agents. Are you just logging everything, or using something more structured?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7fsnr/debugging_langchain_agents_is_painful_until_you/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5x9ab5",
          "author": "Overall_Insurance956",
          "text": "Use langsmith",
          "score": 5,
          "created_utc": "2026-02-17 19:59:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o623tdf",
              "author": "LuckySwimming8564",
              "text": "This.  It is super easy to setup (just a couple vars in your .env) and it is very detailed.  https://docs.langchain.com/langsmith/trace-with-langchain. ",
              "score": 1,
              "created_utc": "2026-02-18 14:28:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6a3bbh",
                  "author": "sunglasses-guy",
                  "text": "to be fair though literally every tool out there now offers 1-2 line integration with langchain and langgraph, langsmith is expensive as hell",
                  "score": 1,
                  "created_utc": "2026-02-19 18:03:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5x2c9v",
          "author": "pvatokahu",
          "text": "Check out open source monocle2ai from Linux foundation - it does the full tracing with agentic attribute capture built on OpenTelemetry and part of pytest.",
          "score": 2,
          "created_utc": "2026-02-17 19:27:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o658ixy",
          "author": "TheExodu5",
          "text": "Please don‚Äôt interact with the fake-engagement advertising bot.",
          "score": 2,
          "created_utc": "2026-02-18 23:08:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o678rvy",
              "author": "NotAHost",
              "text": "Yup just search author:username to see all their spam.",
              "score": 1,
              "created_utc": "2026-02-19 06:42:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o61sh9d",
          "author": "Informal_Tangerine51",
          "text": "Yeah, once a chain has retrieval + reranking + tools, ‚Äúprint the logs‚Äù stops being a debugging strategy and starts being archaeology. A good trace view pays for itself fast, especially when you can replay a run and see exactly where the agent diverged or started looping.\n\nOne thing I‚Äôd add (even if you keep the fancy UI) is a small ‚Äústructured trace contract‚Äù: every hop logs inputs/outputs, tool args, and a reason code for why the agent continued or stopped. Then you can write regression tests off real failures: ‚Äúthis tool loop should terminate‚Äù or ‚Äúthis retrieval query should return at least one relevant chunk,‚Äù instead of hoping prompts stay stable.\n\nWe‚Äôre working on this at Clyra (open source here): [https://github.com/Clyra-AI](https://github.com/Clyra-AI)",
          "score": 1,
          "created_utc": "2026-02-18 13:28:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o624842",
          "author": "93simoon",
          "text": "Use langfuse, it's lang Smith but foss",
          "score": 1,
          "created_utc": "2026-02-18 14:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o625evm",
          "author": "Revolutionary-Bet-58",
          "text": "I'm biased but I can recommend you to check out [inkog.io](http://inkog.io) , you can insert your LangChain agent in there and get feedback directly to solve some issues that you will face before debugging like infinite loops, tool calls etc . It will also recommend you how to fix the problems with examples, or you can just use the Inkog MCP and let Claude fix it for you :D\n\nHappy to sit down with you if you have any questions ",
          "score": 1,
          "created_utc": "2026-02-18 14:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o628qhb",
          "author": "penguinzb1",
          "text": "trace replay is great for diagnosing what happened, but the tool loop you described, where the agent ignored exit conditions, is also the kind of thing that shows up before users see it if you run it against adversarial or edge case scenarios first. what we've found is that simulating these before deployment catches them earlier than any trace tool can, because you're finding the failure before the first incident.",
          "score": 1,
          "created_utc": "2026-02-18 14:52:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5lb28",
      "title": "I built an autonomous agent with DeepAgents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r5lb28/i_built_an_autonomous_agent_with_deepagents/",
      "author": "Releow",
      "created_utc": "2026-02-15 18:01:47",
      "score": 11,
      "num_comments": 5,
      "upvote_ratio": 0.93,
      "text": "[CianaParrot](https://preview.redd.it/rq9dgmdy6pjg1.png?width=1024&format=png&auto=webp&s=57714055a2897397227f67ff326251af488456eb)\n\nHi\n\nI built this project for myself because I wanted full control over what my personal assistant does and the ability to modify it quickly whenever I need to. I decided to share it on GitHub here's the link: [https://github.com/emanueleielo/ciana-parrot](https://github.com/emanueleielo/ciana-parrot)\n\nIf you find it useful, leave a star or some feedback\n\n  \n\n\n  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r5lb28/i_built_an_autonomous_agent_with_deepagents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5jrehc",
          "author": "hwchase17",
          "text": "very very cool!",
          "score": 2,
          "created_utc": "2026-02-15 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtixt",
              "author": "Releow",
              "text": "thank u!",
              "score": 1,
              "created_utc": "2026-02-15 18:37:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5txwrs",
                  "author": "nm-ranga",
                  "text": "Well.. a silly question from a novice (in AI). How to test this? Any instructions?",
                  "score": 1,
                  "created_utc": "2026-02-17 07:58:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5txrkv",
              "author": "nm-ranga",
              "text": "I‚Äôm amazed to see that you find time to reply even at this stage where you busy doing so many things. Keep it up!! \n\nI came to know about LangChain through coursera. Just now started with the course. I‚Äôll come up with some (possibly) weird questions. \n\nBtw, I‚Äôm a mechanical engineer by profession with CAD programming skills.",
              "score": 1,
              "created_utc": "2026-02-17 07:57:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4k671",
      "title": "I built an python AI agent framework that doesn't make me want to mass-delete my venv",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r4k671/i_built_an_python_ai_agent_framework_that_doesnt/",
      "author": "anandesh-sharma",
      "created_utc": "2026-02-14 13:06:32",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "Hey all. I've been building [https://github.com/definableai/definable.ai](https://github.com/definableai/definable.ai) \\- a Python framework for AI agents. I got frustrated with existing options being either too bloated or too toy-like, so I built what I actually wanted to use in production.\n\n\n\nHere's what it looks like:\n\n    ```from definable.agents import Agent\n    from definable.models.openai import OpenAIChat\n    from definable.tools.decorator import tool\n    from definable.interfaces.telegram import TelegramInterface, TelegramConfig\n    \n    @tool\n    def search_docs(query: str) -> str:\n        \"\"\"Search internal documentation.\"\"\"\n        return db.search(query)\n    \n    agent = Agent(\n        model=OpenAIChat(id=\"gpt-5.2\"),\n        tools=[search_docs],\n        instructions=\"You are a docs assistant.\",\n    )\n    \n    # Use it directly\n    response = agent.run(\"Steps for configuring auth?\")\n    \n    # Or deploy it ‚Äî HTTP API + Telegram bot in one line\n    agent.add_interface(TelegramInterface(\n        config=TelegramConfig(bot_token=os.environ[\"TELEGRAM_BOT_TOKEN\"]),\n    ))\n    agent.serve(port=8000)\n    \n\n\n\n**What My Project Does**\n\nPython framework for AI agents with built-in cognitive memory, run replay, file parsing (14+ formats), streaming, HITL workflows, and one-line deployment to HTTP + Telegram/Discord/Signal. Async-first, fully typed, non-fatal error handling by design.\n\n\n\n**Target Audience**\n\nDevelopers building production AI agents who've outgrown raw API calls but don't want LangChain-level complexity. v0.2.6, running in production.\n\n\n\n**Comparison**\n\n\\- \\*\\*vs LangChain\\*\\* - No chain/runnable abstraction. Normal Python. Memory is multi-tier with distillation, not just a chat buffer. Deployment is built-in, not a separate project.\n\n\\- \\*\\*vs CrewAI/AutoGen\\*\\* - Those focus on multi-agent orchestration. Definable focuses on making a single agent production-ready: memory, replay, file parsing, streaming, HITL.\n\n\\- \\*\\*vs raw OpenAI SDK\\*\\* - Adds tool management, RAG, cognitive memory, tracing, middleware, deployment, and file parsing out of the box.\n\n\n\n\\`*pip install definable*\\`\n\n\n\nWould love feedback. Still early but it's been running in production for a few weeks now.\n\n\n\n[https://github.com/definableai/definable.ai](https://github.com/definableai/definable.ai)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r4k671/i_built_an_python_ai_agent_framework_that_doesnt/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5cob3h",
          "author": "bsampera",
          "text": "It looks painfully similar to langchain. Can you repeat what are the advantages without using buzzwords?",
          "score": 1,
          "created_utc": "2026-02-14 15:25:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ks7hm",
              "author": "anandesh-sharma",
              "text": "The structure overall is simple, now i have covered most of the hard parts here like interfaces, cognitive memory,etc. And you want customisation you can simply extend functionality and change the behaviour.\n\nAnd thats nearly impossible to manage with langchain. Its more performant wrt langchain.",
              "score": 1,
              "created_utc": "2026-02-15 21:33:01",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5ksdas",
              "author": "anandesh-sharma",
              "text": "rest u can also take a look at, https://docs.definable.ai",
              "score": 1,
              "created_utc": "2026-02-15 21:33:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5oi5an",
          "author": "Feisty-Promise-78",
          "text": "Hi, this is really cool. Recently I have been trying to learn to build an AI framework by myself. Is there any resource that helped you build this framework? Can you share it with me?",
          "score": 1,
          "created_utc": "2026-02-16 13:36:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a4tu2",
          "author": "gardenia856",
          "text": "The main win here is you‚Äôve treated ‚Äúsingle agent in production‚Äù as the actual problem, not ‚Äúinfinite orchestration graphs.‚Äù Cognitive memory + replay + one-line deployment is exactly where most teams I‚Äôve seen get stuck once the demo is over.\nHard lessons from my side: where this usually hurts in prod is (1) observability across tools and memory tiers, (2) migrations when you change schema/instructions, and (3) safely iterating on prompts/models without breaking existing users. A simple timeline view of runs + memory writes/reads + tool I/O, and a way to pin ‚Äúagent versions‚Äù tied to configs, will save you and your users a ton of pain.\nI‚Äôd also think about how it fits into people‚Äôs existing stacks: e.g., folks wiring agents via LangChain, n8n, or even something like Pulse for Reddit usually want a clean HTTP/gRPC boundary and solid auth so they can treat the agent as infra, not magic.\nSo I‚Äôd double down on versioning + traces + clean interfaces if you want this to stay pleasant at scale.",
          "score": 1,
          "created_utc": "2026-02-19 18:10:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9ur3x",
      "title": "Structure-first RAG with metadata enrichment (stop chunking PDFs into text blocks)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9ur3x/structurefirst_rag_with_metadata_enrichment_stop/",
      "author": "Independent-Cost-971",
      "created_utc": "2026-02-20 13:01:41",
      "score": 10,
      "num_comments": 6,
      "upvote_ratio": 0.81,
      "text": "I think most people are still chunking PDFs into flat text and hoping semantic search works. This breaks completely on structured documents like research papers.\n\nTraditional approach extracts PDFs into text strings (tables become garbled, figures disappear), then chunks into 512-token blocks with arbitrary boundaries. Ask \"What methodology did the authors use?\" and you get three disconnected paragraphs from different sections or papers.\n\nThe problem is research papers aren't random text. They're hierarchically organized (Abstract, Introduction, Methodology, Results, Discussion). Each section answers different question types. Destroying this structure makes precise retrieval impossible.\n\nI've been using structure-first extraction where documents get converted to JSON objects (sections, tables, figures) enriched with metadata like section names, content types, and semantic tags. The JSON gets flattened to natural language only for embedding while metadata stays available for filtering.\n\nThe workflow uses Kudra for extraction (OCR ‚Üí vision-based table extraction ‚Üí VLM generates summaries and semantic tags). Then LangChain agents with tools that leverage the metadata. When someone asks about datasets, the agent filters by content\\_type=\"table\" and semantic\\_tags=\"datasets\" before running vector search.\n\nThis enables multi-hop reasoning, precise citations (\"Table 2 from Methods section\" instead of \"Chunk 47\"), and intelligent routing based on query intent. For structured documents where hierarchy matters, metadata enrichment during extraction seems like the right primitive.\n\nAnyway thought I should share since most people are still doing naive chunking by default.",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1r9ur3x/structurefirst_rag_with_metadata_enrichment_stop/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o6eycn4",
          "author": "Independent-Cost-971",
          "text": "I wrote a whole blog about this that goes into the steps with code if anyone's interested:¬†[https://kudra.ai/metadata-enriched-rag-agent-why-document-structure-beats-text-chunking/](https://kudra.ai/metadata-enriched-rag-agent-why-document-structure-beats-text-chunking/)",
          "score": 2,
          "created_utc": "2026-02-20 13:02:09",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6ezxh1",
          "author": "PopPsychological4106",
          "text": "Correct idea. Don't like throwing vlm on it to make it work though. Also table structure understanding is a science for itself.\nWhat labels do you use? How well does toc reconstruction work with vlm?",
          "score": 1,
          "created_utc": "2026-02-20 13:11:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f7lf3",
          "author": "AdRepresentative6947",
          "text": "Yeah had this realisation the other day. Really love your blog gonna implement it into a project I‚Äôve been working on.\n\nDoes the Kundra AI bit run separate as you‚Äôd only have to run the documents in that pipeline once to get the data or when new data arrives ?",
          "score": 1,
          "created_utc": "2026-02-20 13:54:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7xda",
              "author": "AdRepresentative6947",
              "text": "Dw I just saw in the blog, looks slick",
              "score": 1,
              "created_utc": "2026-02-20 13:56:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ffj3p",
          "author": "Happy-Fruit-8628",
          "text": "Totally agree. Structure first extraction with metadata filtering makes RAG far more precise and lets you cite exact tables and sections.",
          "score": 1,
          "created_utc": "2026-02-20 14:36:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jelfe",
          "author": "BigDry3037",
          "text": "Docling solves this problem",
          "score": 1,
          "created_utc": "2026-02-21 02:48:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r78a13",
      "title": "Run untrusted code locally in LangChain using WASM sandboxes",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r78a13/run_untrusted_code_locally_in_langchain_using/",
      "author": "Tall_Insect7119",
      "created_utc": "2026-02-17 15:00:43",
      "score": 9,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Lately I've seen a lot of cloud-based solutions for running untrusted code. But in reality, you can do it safely on your local machine without sending anything to the cloud.\n\n**Quick context**: When an AI generates code to perform a task, executing it directly could be dangerous for your host system. Sandboxing helps protect your host from any issues that untrusted code might cause.\n\nI built an open-source runtime that isolates code using WebAssembly sandboxes. You can plug it into an existing project in just a few lines:\n\n    from capsule import run\n    \n    result = await run(\n        file=\"./capsule.py\",\n        args=[\"code to execute\"]\n    ]\n\nThen you define your sandboxed logic like this:\n\n    from capsule import task\n    \n    @task(name=\"main\", compute=\"MEDIUM\", ram=\"512mb\")\n    def main(code: str) -> str:\n        \"\"\"Execute untrusted code in an isolated sandbox\"\"\"\n        return exec(code)\n\nThe code (task) runs in its own isolated WASM sandbox. You can define multiple tasks with different limits and even run it standalone.\n\nI put together an example integrated with LangChain here: [https://github.com/mavdol/capsule/tree/main/examples/python/langchain-agent](https://github.com/mavdol/capsule/tree/main/examples/python/langchain-agent)\n\nAnd here‚Äôs the main repo: [https://github.com/mavdol/capsule](https://github.com/mavdol/capsule)\n\nWould love to hear your feedback or thoughts !",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r78a13/run_untrusted_code_locally_in_langchain_using/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5vtc83",
          "author": "vansterdam_city",
          "text": "I‚Äôm absolutely in favor of local sandboxes for agentic coding. There is no way I‚Äôm turning on the super unsafe mode on my local userspace with all my personal creds, but without doing so it‚Äôs super annoying. I like codex web for that reason, but it has limitations.\n\nI‚Äôm curious, why not dev containers? Containers are already a mature platform for creating isolation.",
          "score": 2,
          "created_utc": "2026-02-17 15:51:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w3paq",
              "author": "Tall_Insect7119",
              "text": "That's a valid question. Currently, containers are great for safe application isolation, but they share the host kernel, which could be a risk for untrusted code, even if it's hard to exploit in practice. The real difference is overhead. WASM is lighter than a container, and after the cold start, it's about 100x faster than Docker, for example.\n\nThe only limitation for now is that C extensions (like numpy) aren't supported yet, so it really depends on the use case.",
              "score": 0,
              "created_utc": "2026-02-17 16:43:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5z08jl",
          "author": "ChanceKale7861",
          "text": "This. Those who have done security work, would do the same I think.",
          "score": 2,
          "created_utc": "2026-02-18 01:20:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61vywp",
          "author": "peregrinefalco9",
          "text": "un arbitrary code with the agent's full permissions\" which is terrifying in production.\n\n  \nThe key things to validate with any sandbox approach: can the sandboxed code make network requests? Can it read the filesystem outside its sandbox? What happens when the LLM generates code that tries to escape the sandbox (because it will ‚Äî not maliciously, just because the model doesn't understand sandbox boundaries)?\n\n  \nWASM's capability-based security model is actually well-suited for this. You can explicitly grant only the capabilities the code needs ‚Äî file access to specific paths, network access to specific hosts, memory limits. The attack surface is much smaller than a container and the startup overhead is negligible.\n\n  \nCurious how this handles cases where the agent needs to install dependencies at runtime. That's usually where sandboxed execution falls apart in practice.",
          "score": 2,
          "created_utc": "2026-02-18 13:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61y5ge",
          "author": "Informal_Tangerine51",
          "text": "This is a great direction. ‚ÄúLocal, sandboxed execution‚Äù is exactly what you want for agent-generated code, and WASM gives you a cleaner isolation boundary than ‚Äújust run it in a venv and hope.‚Äù The ergonomic API matters too, because if it‚Äôs annoying people will bypass it.\n\nThe big questions I‚Äôd want answered are around escape hatches: what‚Äôs the default filesystem/network surface, how do you handle timeouts and memory limits deterministically, and can you produce an audit trail of what ran (hash of code, args, resource limits, stdout/stderr) for later debugging. In practice, a sandbox without good observability becomes a new kind of black box.\n\nWe‚Äôre working on this at Clyra (open source here): [https://github.com/Clyra-AI](https://github.com/Clyra-AI)",
          "score": 2,
          "created_utc": "2026-02-18 13:58:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9kx8o",
      "title": "I built an open-source library on top of LangChain for batch-transforming structured data through LLMs",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r9kx8o/i_built_an_opensource_library_on_top_of_langchain/",
      "author": "papipapi419",
      "created_utc": "2026-02-20 03:50:54",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.85,
      "text": "The problem: every project I worked on needed the same thing ‚Äî take rows of data, run them through an LLM, get back validated Pydantic models. I kept rewriting batching, retries, concurrency, and row-ordering logic.\n\nSo I packaged it up: **smelt-ai**.\n\nWhat it handles under the hood:\n\n* **Batching** ‚Äî splits rows into configurable batch sizes\n* **Concurrency** ‚Äî async semaphore-based, no threads\n* **Retries** ‚Äî exponential backoff for 429s, 5xx, validation errors\n* **Row ordering** ‚Äî injects row\\_id, validates it, reorders results to match input\n* **Structured output** ‚Äî uses `with_structured_output` so you get typed Pydantic models back\n* **Metrics** ‚Äî token counts, timing, retry stats per run\n\nWorks with any LangChain provider (OpenAI, Anthropic, Gemini, etc.) since it uses `init_chat_model` under the hood.\n\n`pip install smelt-ai`\n\nGitHub: [https://github.com/Cydra-Tech/smelt-ai](https://github.com/Cydra-Tech/smelt-ai)  \nDocs: [https://cydra-tech.github.io/smelt-ai/](https://cydra-tech.github.io/smelt-ai/)\n\nWould love feedback from the LangChain community. What would you add?\n\nEdit: Grammer",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r9kx8o/i_built_an_opensource_library_on_top_of_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r7vn7p",
      "title": "I can‚Äôt figure out how to ask LLM to write an up-to-date LangChain script with the latest docs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7vn7p/i_cant_figure_out_how_to_ask_llm_to_write_an/",
      "author": "gowtham150",
      "created_utc": "2026-02-18 06:34:18",
      "score": 8,
      "num_comments": 16,
      "upvote_ratio": 0.72,
      "text": "Whenever I ask claude or chatgpt to write me a simple langchain agent - even the very simple ones - it always gives me a script with outdated libraries. I tried using claude with context7mcp and langchain docs mcp - still i get out of date obsolete script with deprecated libraries. Even for a simple use case i have to go to langchain docs and get it. Its frustrating to ask LLM to write a sample code and later on to find that its deprecated. How you are you guys solving this problem.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7vn7p/i_cant_figure_out_how_to_ask_llm_to_write_an/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o60jchc",
          "author": "mdrxy",
          "text": "Would encourage cloning the repos locally and letting your agent know that it can traverse the source code in your filesystem!",
          "score": 5,
          "created_utc": "2026-02-18 07:22:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63mjh1",
              "author": "orthogonal-ghost",
              "text": "This is a fantastic idea",
              "score": 1,
              "created_utc": "2026-02-18 18:38:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60tj3n",
          "author": "gowtham150",
          "text": "The general observation is that if i use claude code with context 7 MCP and ask it to write a a simple agent with Langchain it gives me a script most of the time with outdated versions and libraries. Same with chatgpt. So it's becoming extremely difficult to just test out a feature.",
          "score": 3,
          "created_utc": "2026-02-18 08:57:01",
          "is_submitter": true,
          "replies": [
            {
              "id": "o61bc9k",
              "author": "Individual_Day_9508",
              "text": "Use a CLAUDE.md or AGENTS.md file in your workspace to set a strict rule enforcing Langchain 1.x syntax. If you pair that explicit instruction with context 7, it completely fixes the outdated library issue.",
              "score": 1,
              "created_utc": "2026-02-18 11:34:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o61ci16",
                  "author": "gowtham150",
                  "text": "Ok let me check that. Thanks for sharing",
                  "score": 1,
                  "created_utc": "2026-02-18 11:44:01",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60eznz",
          "author": "gaureshai",
          "text": "Very hard.  Because langchain docs are also outdated.",
          "score": 4,
          "created_utc": "2026-02-18 06:44:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60zbec",
              "author": "NoleMercy05",
              "text": "Not true anymore",
              "score": 2,
              "created_utc": "2026-02-18 09:51:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6179bd",
                  "author": "gaureshai",
                  "text": "Well then it's good. I had really hard time in js docs. Will try it again then.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:01:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60jaqu",
              "author": "mdrxy",
              "text": "Not sure what you mean -- can you point to specific pages? Will flag with the team",
              "score": 1,
              "created_utc": "2026-02-18 07:22:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60l0t8",
          "author": "Character_Leg1134",
          "text": "Use chat.langchain.com \nIts their own bot \nWhich can give you the code with updated libraries",
          "score": 2,
          "created_utc": "2026-02-18 07:38:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tdxv",
              "author": "gowtham150",
              "text": "Will try this",
              "score": 1,
              "created_utc": "2026-02-18 08:55:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o61cjj2",
              "author": "gowtham150",
              "text": "This has been working well so far. Thanks for sharing.",
              "score": 1,
              "created_utc": "2026-02-18 11:44:20",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o63c2w2",
              "author": "rk_11",
              "text": "Second this",
              "score": 1,
              "created_utc": "2026-02-18 17:52:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62l7az",
          "author": "notAllBits",
          "text": "That is the cost of unstable conventions (API/classes) in coding. If LLMs cannot be confident about their memory, they spoil it for everyone",
          "score": 1,
          "created_utc": "2026-02-18 15:51:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60qx1v",
          "author": "kolmar41k",
          "text": "If you using and IDE, try using an MCP called 'context7', it provides up to date docs including langgraph/langchain to your llm",
          "score": 1,
          "created_utc": "2026-02-18 08:32:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tczj",
              "author": "gowtham150",
              "text": "I already did, like i mentioned in my post. I used context 7 and Langchain has its own mc as well",
              "score": 1,
              "created_utc": "2026-02-18 08:55:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r58t34",
      "title": "Using LangGraph for long-term memory (RAG + Obsidian) ‚Äî does this design make sense?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r58t34/using_langgraph_for_longterm_memory_rag_obsidian/",
      "author": "Glittering_Aerie54",
      "created_utc": "2026-02-15 07:47:17",
      "score": 8,
      "num_comments": 14,
      "upvote_ratio": 0.83,
      "text": "Hi everyone,\n\nI'm fairly new to building autonomous agents and recently started experimenting with LangGraph.\n\nI'm trying to solve a simple question:\n\n**How would you design long-term memory for a trading agent?**\n\nInstead of keeping memory only inside a vector DB, I experimented with connecting the agent to my Obsidian notes ‚Äî almost like giving it a \"second brain\".\n\n# Current approach\n\nThe workflow is roughly:\n\n* When analyzing a stock, the agent retrieves related notes from an Obsidian vault (RAG)\n* Bull / Bear analyst agents debate using both live data and retrieved context\n* The final analysis is summarized and saved back into the vault\n\nSo the memory grows over time.\n\n# Tech I'm experimenting with\n\n* LangGraph / LangChain\n* Streamlit\n* ChromaDB\n* Obsidian as long-term memory\n\nSince this is my first serious attempt with LangGraph, I'm not sure if my graph structure or memory recall logic is the right approach.\n\n# What I‚Äôd really like feedback on\n\n* How do you usually structure long-term memory in LangGraph?\n* Should memory retrieval happen once at the start, or at multiple nodes?\n* Any patterns to avoid when using RAG as persistent memory?\n\nIf anyone is curious I can share the repo in comments ‚Äî mainly looking for design feedback first.\n\nThanks üôè",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r58t34/using_langgraph_for_longterm_memory_rag_obsidian/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o5iejo1",
          "author": "WowSoWholesome",
          "text": "LangGraph supports a bunch of stores, and you can use this to implement check pointing and long term memory in langgraph.¬†https://docs.langchain.com/oss/python/langgraph/add-memory",
          "score": 3,
          "created_utc": "2026-02-15 14:23:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6j36j6",
              "author": "Glittering_Aerie54",
              "text": "Combining them¬†as¬†a hybrid¬†makes¬†a lot of sense¬†they solve different problems¬†cleanly¬†(checkpointing¬†for¬†session/state¬†continuity, and¬†your Chroma-based¬†memory for¬†semantic retrieval).   \nThanks¬†for¬†pointing¬†it out this¬†is¬†really¬†helpful.",
              "score": 1,
              "created_utc": "2026-02-21 01:36:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o5fw8",
          "author": "No-Fail-7644",
          "text": "Why not postgress? Lg4j already has in built checkpointing support for postgres.\nYour biggest challenge would be designing tiers of memory. You wouldn‚Äôt want to mix up semantic memory with low level financial information. You‚Äôll need atleast two tiers. You can wire these with AgentState in graph.. something similar to Plan, Tasks pattern. Lg4j also has supervisor agent pattern.\n\nClone the lg4j repo, there is a directory named ‚Äòhow-tos‚Äô, feed it to your coding agent and ask it more detailed questions!",
          "score": 2,
          "created_utc": "2026-02-16 12:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o6evg",
              "author": "No-Fail-7644",
              "text": "If you are new to dev, better start with DBMS a bit. You can code out the app in couple of days but if you intent to use it long term reliably. You would need proper DB procedures so that your DB doesnt get poisoned over time, given your AI would be making up its content.",
              "score": 1,
              "created_utc": "2026-02-16 12:18:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5o6oxz",
                  "author": "No-Fail-7644",
                  "text": "You don‚Äôt need to query DB full shot once on startup, you can query per node by simply writing a wrapper over it.",
                  "score": 1,
                  "created_utc": "2026-02-16 12:21:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hortm",
          "author": "adlx",
          "text": "Take your post and ask ChatGPT, Claude or Gemini...\nIf you're really into what you say, building autonomous agent, you should already be into vibe coding and definitely using AIs first. Being here asking that sounds a contradiction to me. Sorry",
          "score": 1,
          "created_utc": "2026-02-15 11:15:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hwpnh",
              "author": "Glittering_Aerie54",
              "text": "Fair point.\n\nI did use AI Tool for brainstorming, but I wanted feedback from people actually building with LangGraph in real projects.\n\nThis is the project for context:\n\n[https://github.com/jiwoomap/TradingAgents-Dashboard](https://github.com/jiwoomap/TradingAgents-Dashboard)",
              "score": 3,
              "created_utc": "2026-02-15 12:24:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5idncv",
                  "author": "WowSoWholesome",
                  "text": "I think what you‚Äôre doing drives conversation and improves the community. Thank you for not just blindly vibe coding without an understanding of the solution you want first.¬†",
                  "score": 3,
                  "created_utc": "2026-02-15 14:18:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61xs8j",
          "author": "Informal_Tangerine51",
          "text": "Your design makes sense, and Obsidian can be a great ‚Äúhuman-readable memory‚Äù layer, but I‚Äôd be careful about treating RAG memory as truth in a trading context. Markets change, so a super relevant note from 6 months ago can be actively harmful unless you carry strong timestamps, regime tags, and ‚Äúwhat data did this rely on‚Äù alongside it.\n\nIn LangGraph I‚Äôd usually split memory into two lanes: (1) structured state you can trust (positions, constraints, risk limits, last decision, feature values), and (2) narrative notes (theses, learnings, postmortems) that are advisory. Retrieval shouldn‚Äôt be only at the start; pull it at key nodes (hypothesis generation, counter-argument, decision), but keep the retrieved set small and require each claim to cite a note or a current datapoint.\n\nBig pattern to avoid: writing back everything the model says. Only persist summaries that pass a simple checklist (dated, sources linked, what changed since last time, explicit confidence), otherwise you end up with a compounding ‚Äúmemory hallucination‚Äù loop. What are you using as the ground-truth price/fundamentals feed, and do you want memory to influence actual trades or just generate research notes?",
          "score": 1,
          "created_utc": "2026-02-18 13:56:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6j24yg",
              "author": "Glittering_Aerie54",
              "text": "I was concerned about that point as well, so I designed the system to let me choose whether to use the existing Markdown (md) files or not. Only the summarized content is stored, and only those summaries are used.\n\nEach agent keeps a record of the articles it has verified. This way, if a page has no verified articles or the content has been removed, it won‚Äôt be used.\n\nI‚Äôm now thinking that I should implement a feature to periodically re-validate those articles to ensure they‚Äôre still accessible and reliable.\n\nThank you for the helpful advice.",
              "score": 1,
              "created_utc": "2026-02-21 01:29:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4olni",
      "title": "I built a visual execution tracking for LangGraph workflows",
      "subreddit": "LangChain",
      "url": "https://github.com/proactive-agent/langgraphics",
      "author": "ar_tyom2000",
      "created_utc": "2026-02-14 16:15:02",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r4olni/i_built_a_visual_execution_tracking_for_langgraph/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5iy8yp",
          "author": "ar_tyom2000",
          "text": "https://i.redd.it/bkymbofulojg1.gif\n\nJust one line of code is all it takes to visualize your LangGraph agent's workflow in real-time as it executes. Any feedback?",
          "score": 1,
          "created_utc": "2026-02-15 16:06:00",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5u45nw",
          "author": "bsampera",
          "text": "So the same that langgraph studio?",
          "score": 1,
          "created_utc": "2026-02-17 08:58:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5u4pok",
              "author": "ar_tyom2000",
              "text": "Not quite. Currently adding more tracing features and it will be a light, single line usage (no setup needed), and free (for studio you should have langsmith API key).",
              "score": 1,
              "created_utc": "2026-02-17 09:03:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4nv7j",
      "title": "I built an open-source ‚Äúflight recorder‚Äù for AI agents (records every step, works offline, cryptographically verifiable)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r4nv7j/i_built_an_opensource_flight_recorder_for_ai/",
      "author": "ALWAYSHONEST69",
      "created_utc": "2026-02-14 15:45:26",
      "score": 7,
      "num_comments": 9,
      "upvote_ratio": 0.73,
      "text": "I‚Äôve been working on an open-source project called epi-recorder.\nThe problem I kept running into while building agents was simple:\nwhen something breaks, logs are not enough. You often can‚Äôt reconstruct what actually happened step by step, and in many cases you can‚Äôt prove what the system did.\nSo I built a recorder that captures: ‚Ä¢ prompts, responses, tool calls, and state transitions\n‚Ä¢ timestamps, token usage, and environment snapshot\n‚Ä¢ replayable execution history\n‚Ä¢ optional cryptographic signatures for tamper-evident records\n‚Ä¢ offline viewer ‚Äî no cloud required\nAn .epi file is basically a flight recorder for AI agents.\nIt works with: ‚Ä¢ OpenAI / Anthropic / local LLMs\n‚Ä¢ LangGraph and async workflows\n‚Ä¢ any Python agent via wrappers or explicit logging\nInstall: pip install epi-recorder\nI‚Äôm a solo founder building this and would really value:\nFeedback from people running agents\nIdeas on real-world use cases\nStars on the repo if you find the project useful or interesting ‚Äî it helps visibility a lot\nGitHub: https://github.com/mohdibrahimaiml/epi-recorder\nIf you‚Äôve ever had an agent fail and wished you could replay exactly what happened, I‚Äôd especially like to hear how you‚Äôre debugging today.",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1r4nv7j/i_built_an_opensource_flight_recorder_for_ai/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o61f97u",
          "author": "Outrageous_Hat_9852",
          "text": "This is really cool - having cryptographically verifiable execution traces is huge for debugging agent behavior and building trust in production systems. One thing we've seen teams struggle with is connecting these detailed execution logs back to whether the agent actually met its requirements or behaved correctly. The flight recorder captures *what* happened, but you still need structured ways to evaluate *whether* it was the right thing, especially for catching subtle issues like context drift or goal deviation that aren't obvious from logs alone.",
          "score": 2,
          "created_utc": "2026-02-18 12:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61p8hm",
              "author": "ALWAYSHONEST69",
              "text": "You're exactly right, EPI Recorder captures ground truth, not correctness.\nThe goal is to make debugging and trust possible by preserving the exact execution path and full context in a tamper-evident way. Once you have a canonical trace, structured evaluation becomes much more reliable.\nWithout a verifiable execution record, evaluation systems are often judging reconstructed or partial state. With a cryptographically signed trace, you can attach evaluators directly to specific turns and systematically detect things like context drift, goal deviation, or tool misuse.\n\nI see it as two complementary layers:\n1. Execution capture ‚Üí What actually happened (verifiable, replayable).\n2. Evaluation layer ‚Üí Was it correct relative to requirements?\n\nRight now EPI focuses on making the first layer solid. That foundation makes the second layer far more trustworthy.\n\nIf you're experimenting with agent evaluation pipelines, I‚Äôd love for you to try it and see if the trace structure fits your workflow. And if you find it useful, a star on the repo genuinely helps signal that this problem space matters. ‚≠êüôèüèª",
              "score": 1,
              "created_utc": "2026-02-18 13:09:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ct5py",
          "author": "baneeishaquek",
          "text": "Any guidance on \"How to use this on Antigravity Chat Window?\".",
          "score": 1,
          "created_utc": "2026-02-14 15:50:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cudwa",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-02-14 15:57:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cuhht",
                  "author": "ALWAYSHONEST69",
                  "text": "PLEASE STAR IF YOU LIKED THE EPI",
                  "score": 1,
                  "created_utc": "2026-02-14 15:57:32",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5u5288",
          "author": "Icy-Cartographer23",
          "text": "\"Logs are not enough\" is exactly the right framing. I've been running into this constantly.\n\nOne specific question: when epi-recorder captures 'prompts and responses' in a multi-turn conversation, does it store the full context window at each step ‚Äî meaning the entire accumulated prompt (system prompt + conversation history + all prior tool results that were included at that point)? Or does it capture the delta (what was new in that turn)?\n\nThe reason I ask: in a 40+ turn agent run, the bugs I struggle to debug are usually not in the last step. They're in a decision made at turn 23 where the model had accumulated a bunch of context from prior web searches and tool calls. To figure out why it made a weird choice at turn 23, I need to see what the FULL context window looked like at that exact moment ‚Äî not just what new input was added.\n\nIf epi-recorder stores the full context snapshot at each step, it would actually solve this for me. The GitHub link is going in my queue either way ‚Äî the cryptographic tamper-evidence angle is clever for any compliance use case.",
          "score": 1,
          "created_utc": "2026-02-17 09:07:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5u6k8l",
              "author": "ALWAYSHONEST69",
              "text": "Great question - this is exactly the class of problem EPI Recorder is designed for.\n\nIt captures the full context window at every step, not just the delta.\n\nBecause LLM APIs are stateless, the agent has to send the entire accumulated context (system prompt, conversation history, and any prior tool outputs) with each request. EPI Recorder intercepts the raw request payload just before it is sent, so each step shows exactly what the model saw at that moment.\n\nSo in your example: if something odd happens at turn 23, you can open step 23 and see the full prompt as it was sent, system prompt + turns 1‚Äì22 + turn 23 input - without reconstructing anything manually.\n\nA couple of implementation notes:\n\n- For OpenAI and Anthropic calls, the full message history is captured without truncation.\n- Gemini currently has a safety truncation in very large payloads (mainly to prevent massive image/video contexts from exploding log size), but that‚Äôs being refined.\n- For generic raw HTTP traffic, only metadata is stored, but LLM calls are recorded in full specifically to support debugging cases like the one you described.\n\nIf you end up trying it, I‚Äôd appreciate a star on the repo, it helps visibility and signals that this kind of tooling is actually needed.\n\nüôèüèª",
              "score": 1,
              "created_utc": "2026-02-17 09:21:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r79j1x",
      "title": "Don't Prompt Your Agent for Reliability ‚Äî Engineer It",
      "subreddit": "LangChain",
      "url": "https://www.aiyan.io/blog/engineer-agent-reliability/",
      "author": "NetworkFlux",
      "created_utc": "2026-02-17 15:47:11",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1r79j1x/dont_prompt_your_agent_for_reliability_engineer_it/",
      "domain": "aiyan.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5vspec",
          "author": "NetworkFlux",
          "text": "I've spent the past year at my company building a data engineering agent for non-technical users. I rearchitected it three times, from a rigid state machine, to a multi-agent orchestrator, to a single general-purpose agent with lightweight tools. Each time, the system actually got simpler and more reliable. Wrote up the full evolution and the two biggest lessons I took away!",
          "score": 1,
          "created_utc": "2026-02-17 15:48:21",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o629lt8",
          "author": "penguinzb1",
          "text": "how do you quantitatively verify that the agent improves when the complexity is changed? when I'm building agents sometimes the more simple agents seem more reliable but it turns out they just have a reduced action space / problem-solving area, and refuse to solve many things. we use simulations to gauge the agent behaviour and then grade it, which is a bit of a newer thing ",
          "score": 1,
          "created_utc": "2026-02-18 14:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62mjs3",
              "author": "NetworkFlux",
              "text": "That's a good point and is probably worth for me to write about. But in short, we're actually doing something very similar.\n\nWe have \"simulated user\" LLMs with different personas defined in config files. They talk to our agent until the simulated user decides to end the conversation (goal reached), or if certain deterministic criteria are met, like max # of turns or state reached.\n\nFor judging, we have a suite of heuristic judges (checking for tool calls, checking text for data leakage, etc.) and an LLM judge which is given a precise pass/fail criteria.\n\nFinally we compute a weighted average based on the passes and fails and assign a score to the simulation after running enough for a statistically significant result.\n\nAre you doing something similar?",
              "score": 1,
              "created_utc": "2026-02-18 15:57:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64awwg",
          "author": "ScArL3T",
          "text": "Do your tools do any heavy lifting in regards to semantic understanding and if yes how do you achieve it?  \nLater in the article you mention about having a simple general agent which in turn calls some well defined tools. In that diagram you showcased the possibility of having a sub-agent -- so they are not completely gone?\n\nI'm kind of interested in the technicalities a bit and diving a bit more in-depth into your architecture.  \nI'm also interested how your initial user query (2 edit requests and 1 question in the same message) gets handled by the generic agent now that it is specifically NOT instructed to deconstruct the user query. Do you just rely on the model's intelligence? And if yes, what model are you using.\n\nThank you!",
          "score": 1,
          "created_utc": "2026-02-18 20:30:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69h8kd",
              "author": "NetworkFlux",
              "text": "Right, in the last architecture version we still kept the dataflow (code) generation sub-agent because its system prompt contains a lot of niche guidance on data pipeline patterns that wouldn't make a ton of sense polluting the main agent's context.\n\nThat being said, with code and MCP execution in sandbox being refined (https://www.anthropic.com/engineering/code-execution-with-mcp), I think this may not hold true for long. I can envision a future where agents perform most of its tasks (including tool-calling) within a code sandbox, backed by a filesystem (its \"environment\").\n\n\\-\n\nRe general agent - we're achieving good performance with just the open-source tool-calling models. And I think the insight I can provide is most helpful broadly:\n\nMy key learning is that deconstructing the user query, like you mention, isn't the goal, but rather invoking the necessary side-effects (tools).\n\nIt was also very enlightening thinking about the final objects/artifacts we actually *want* out of the agent. LLMs act greedily, so making sure our tools don't elongate the path to the goal was very helpful.\n\nI.e., instead of tools that \"set\" certain objects, just make those objects inputs to the next tool in the dependency chain",
              "score": 2,
              "created_utc": "2026-02-19 16:17:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6b1wa",
      "title": "What Are DeepAgents in LangChain?",
      "subreddit": "LangChain",
      "url": "https://www.blog.qualitypointtech.com/2026/02/what-are-deepagents-in-langchain.html",
      "author": "qptbook",
      "created_utc": "2026-02-16 14:28:22",
      "score": 6,
      "num_comments": 12,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r6b1wa/what_are_deepagents_in_langchain/",
      "domain": "blog.qualitypointtech.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5pfckh",
          "author": "justanemptyvoice",
          "text": "A buzzword\n\nSaved you a click",
          "score": 3,
          "created_utc": "2026-02-16 16:24:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r0wqa",
              "author": "93simoon",
              "text": "Opened the post to comment the same thing üòÇ",
              "score": 1,
              "created_utc": "2026-02-16 20:55:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5pmlf6",
              "author": "Niightstalker",
              "text": "No a specific concepts of agents that is worth reading but ok",
              "score": 0,
              "created_utc": "2026-02-16 16:57:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rzw0k",
                  "author": "mamaBiskothu",
                  "text": "A concept introduced a year too late into the most popular framework in the field. My team Interview questuon is to ask what their thought is on langchain and to reject anyone saying positive things.",
                  "score": 1,
                  "created_utc": "2026-02-16 23:57:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61sng4",
          "author": "Puzzled_Celery_6190",
          "text": "TLDR: compare to normal ReAct agent, deep agent contains a detailed system prompt, plan tool, sub agent plus an external file system (so that you don‚Äôt put everything in context/prompt). Take writing paper for example, it could write paper page by page or sentence by sentence, write as long as you want.",
          "score": 1,
          "created_utc": "2026-02-18 13:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68p8lh",
          "author": "kalyugira",
          "text": "It does not even follow its own internal langchain standards - ex. StateSchema concept is entirely missing that is part of react agent. You are better off taking the middlewares and use them if you are using langchain.",
          "score": 1,
          "created_utc": "2026-02-19 13:53:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7uhed",
      "title": "stopped using flaky youtube loaders and finally fixed my rag accuracy",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1r7uhed/stopped_using_flaky_youtube_loaders_and_finally/",
      "author": "straightedge23",
      "created_utc": "2026-02-18 05:29:02",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "i‚Äôve been building a RAG pipeline for a technical documentation project, and the biggest bottleneck was the \"garbage in, garbage out\" problem with youtube transcripts. i started with the standard community loaders, but the formatting was so messy that the embeddings were coming out low-quality, and the retrieval was hitting all the wrong chunks.\n\ni finally swapped out my custom scraping logic for [transcript api](https://transcriptapi.com/) as a direct source.\n\n**the difference it made for the chain:**\n\n* **cleaner chunks:** the api gives me a clean, stripped string. without the html junk and weird timestamps, my recursive character text splitter actually creates coherent chunks instead of breaking in the middle of a sentence.\n* **metadata integrity:** since i can pull structured segments with start times, i can actually map my vector metadata back to the exact second in the video. when the user asks a question, the agent can cite the exact timestamp in the source.\n* **reliability at scale:** i‚Äôm not getting blocked or hitting 403 errors during batch processing anymore. it treats the transcript like a stable production data source rather than a side-project hack.\n\nif you‚Äôre building agents that need to \"reason\" over technical tutorials or long-form lectures, don't waste your context window on garbage formatting. once the input pipe is clean, the \"hallucinations\" drop significantly because the model actually has the full, un-mangled context.\n\ncurious if anyone else has moved away from the standard loaders to a dedicated api for their ingestion layer?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r7uhed/stopped_using_flaky_youtube_loaders_and_finally/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o61t5yc",
          "author": "Informal_Tangerine51",
          "text": "Yep, this is the unsexy part of RAG that matters most: loader quality and normalization beats clever prompting. Once the text is clean, chunk boundaries make sense, and your embeddings stop ‚Äúsmearing‚Äù unrelated concepts together.\n\nIf you haven‚Äôt already, a couple small additions tend to pay off: normalize casing/whitespace consistently, strip repeated boilerplate (‚Äúsubscribe‚Äù, intros), and store both the raw segment + the cleaned segment so you can always re-render citations. I also like adding a lightweight ‚Äúchunk health‚Äù check (avg chars, sentence breaks, % non-alpha) so bad transcripts get quarantined before they pollute the index.\n\nTimestamp metadata is a killer feature too, because it makes answers verifiable. Are you also storing a stable video ID + language track, and handling ‚Äúupdated transcripts‚Äù (so your vector store can reindex without breaking existing citations)?",
          "score": 1,
          "created_utc": "2026-02-18 13:31:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64hsw1",
          "author": "One_Presentation7722",
          "text": "clean transcripts improve rag pipelines ScraperCity offers structured data with unlimited downloads.",
          "score": 1,
          "created_utc": "2026-02-18 21:02:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5eq9f",
      "title": "Open-source research agent with LangGraph that maps its findings in 3D",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/81xrw2pqunjg1",
      "author": "FickleSwordfish8689",
      "created_utc": "2026-02-15 13:32:43",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r5eq9f/opensource_research_agent_with_langgraph_that/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1ra2b0r",
      "title": "expectllm: A lightweight alternative when you just need pattern matching",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ra2b0r/expectllm_a_lightweight_alternative_when_you_just/",
      "author": "Final_Signature9950",
      "created_utc": "2026-02-20 17:51:55",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "I built a small library called **expectllm**.\n\n\n\nIf you've ever thought \"I just need to extract a number from an LLM response, why am I importing 50 modules?\" - this might be for you.\n\n\n\nIt treats LLM conversations like classic expect scripts:\n\n\n\nsend ‚Üí pattern match ‚Üí branch\n\n\n\nYou explicitly define what response format you expect from the model.\n\nIf it matches, you capture it.\n\nIf it doesn't, it fails fast with an explicit ExpectError.\n\n\n\nExample:\n\n    from expectllm import Conversation\n    \n    c = Conversation()\n    \n    c.send(\"Review this code for security issues. Reply exactly: 'found N issues'\")\n    c.expect(r\"found (\\d+) issues\")\n    \n    issues = int(c.match.group(1))\n    \n    if issues > 0:\n       c.send(\"Fix the top 3 issues\")\n\n\n\nCore features:\n\n\\- expect\\_json(), expect\\_number(), expect\\_yesno()\n\n\\- Regex pattern matching with capture groups\n\n\\- Auto-generates format instructions from patterns\n\n\\- Raises explicit errors on mismatch (no silent failures)\n\n\\- Works with OpenAI and Anthropic (more providers planned)\n\n\\- \\~365 lines of code, fully readable\n\n\\- Full type hints\n\n\n\nRepo: [https://github.com/entropyvector/expectllm](https://github.com/entropyvector/expectllm)\n\nPyPI: [https://pypi.org/project/expectllm/](https://pypi.org/project/expectllm/)\n\n\n\nIt's not designed to replace LangChain or similar frameworks - those are great when you need the full toolbox. This is for when you don't. Minimalism, control, transparent flow.\n\n\n\nWould appreciate feedback:\n\n\\- Is this approach useful in real-world projects?\n\n\\- What edge cases should I handle?\n\n\\- Where would this break down?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ra2b0r/expectllm_a_lightweight_alternative_when_you_just/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r8q0jm",
      "title": "LangChain's Deep Agents scores 5th on Terminal Bench 2",
      "subreddit": "LangChain",
      "url": "https://x.com/Vtrivedy10/status/2023805578561060992",
      "author": "mdrxy",
      "created_utc": "2026-02-19 04:49:30",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1r8q0jm/langchains_deep_agents_scores_5th_on_terminal/",
      "domain": "x.com",
      "is_self": false,
      "comments": [
        {
          "id": "o66xh90",
          "author": "Material_Policy6327",
          "text": "Any non x link",
          "score": 1,
          "created_utc": "2026-02-19 05:11:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6735v5",
              "author": "mdrxy",
              "text": "[https://blog.langchain.com/improving-deep-agents-with-harness-engineering/](https://blog.langchain.com/improving-deep-agents-with-harness-engineering/)",
              "score": 2,
              "created_utc": "2026-02-19 05:55:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}