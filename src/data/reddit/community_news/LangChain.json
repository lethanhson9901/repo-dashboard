{
  "metadata": {
    "last_updated": "2026-02-06 02:55:57",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 71,
    "file_size_bytes": 109520
  },
  "items": [
    {
      "id": "1qwno6v",
      "title": "I built ‚ÄúVercel for AI agents‚Äù ‚Äî a single click deployment platform for any framework",
      "subreddit": "LangChain",
      "url": "/r/aiagents/comments/1qwnnlq/i_built_vercel_for_ai_agents_a_single_click/",
      "author": "Hisham_El-Halabi",
      "created_utc": "2026-02-05 15:05:46",
      "score": 65,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qwno6v/i_built_vercel_for_ai_agents_a_single_click/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "o3qp3w1",
          "author": "Existing_Way2258",
          "text": "I hope this is better than LangSmith LOL. Pls add LangChain support soon, I'm curious to try it out",
          "score": 1,
          "created_utc": "2026-02-05 16:32:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qpii9",
              "author": "Hisham_El-Halabi",
              "text": "haha noted, we‚Äôre working on it. You can join the waitlist on our website so get notified when we launch with langchain support",
              "score": 1,
              "created_utc": "2026-02-05 16:34:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3s03w7",
              "author": "MathematicianTop1654",
              "text": "check out [crewship.dev](http://crewship.dev), it supports LangGraph",
              "score": 1,
              "created_utc": "2026-02-05 20:10:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qw8s1s",
      "title": "I visualized the LLM workflows of the entire LangChain repo",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/bz7sbdzd6lhg1",
      "author": "Cyanosistaken",
      "created_utc": "2026-02-05 02:23:18",
      "score": 33,
      "num_comments": 4,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qw8s1s/i_visualized_the_llm_workflows_of_the_entire/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3nfyhe",
          "author": "Hungry_Age5375",
          "text": "Try visualizing agent workflows instead. Full repo mapping is like charting every neuron - cool but useless for actual work.",
          "score": 2,
          "created_utc": "2026-02-05 02:55:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oefcg",
              "author": "Relevant-Magic-Card",
              "text": "i still find this pretty useful info",
              "score": 1,
              "created_utc": "2026-02-05 06:59:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p8m6t",
          "author": "Enough-Blacksmith-80",
          "text": "Very cool, man!",
          "score": 1,
          "created_utc": "2026-02-05 11:40:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qe5po",
              "author": "Cyanosistaken",
              "text": "Thanks! ",
              "score": 1,
              "created_utc": "2026-02-05 15:42:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qul2dx",
      "title": "NotebookLM For Teams",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qul2dx/notebooklm_for_teams/",
      "author": "Uiqueblhats",
      "created_utc": "2026-02-03 06:57:55",
      "score": 32,
      "num_comments": 4,
      "upvote_ratio": 0.96,
      "text": "For those of you who aren't familiar with SurfSense, it aims to be OSS alternative to NotebookLM, Perplexity, and Glean.\n\nIn short, it is NotebookLM for teams, as it connects any LLM to your internal knowledge sources (search engines, Drive, Calendar, Notion, Obsidian, and 15+ other connectors) and lets you chat with it in real time alongside your team.\n\nI'm looking for contributors. If you're interested in AI agents, RAG, browser extensions, or building open-source research tools, this is a great place to jump in.\n\nHere's a quick look at what SurfSense offers right now:\n\n**Features**\n\n* Self-Hostable (with docker support)\n* Real Time Collaborative Chats\n* Real Time Commenting\n* Deep Agentic Agent\n* RBAC (Role Based Access for Teams Members)\n* Supports Any LLM (OpenAI spec with LiteLLM)\n* 6000+ Embedding Models\n* 50+ File extensions supported (Added Docling recently)\n* Local TTS/STT support.\n* Connects with 15+ external sources such as Search Engines, Slack, Notion, Gmail, Notion, Confluence etc\n* Cross-Browser Extension to let you save any dynamic webpage you want, including authenticated content.\n\n**Upcoming Planned Features**\n\n* Slide Creation Support\n* Multilingual Podcast Support\n* Video Creation Agent\n\nGitHub: [https://github.com/MODSetter/SurfSense](https://github.com/MODSetter/SurfSense)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qul2dx/notebooklm_for_teams/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3ax6z3",
          "author": "Otherwise_Wave9374",
          "text": "This is a solid idea, \"NotebookLM for teams\" is basically where a lot of agent work is going (shared context + connectors + permissions). The RBAC + self-hostable angle is especially nice if you are dealing with enterprise data.\n\nOne thing I would love to see is a clear story for evals, like regression tests for retrieval quality and agent actions as you add connectors.\n\nI have been writing up some notes on agent evals and tool-use patterns too, in case its useful: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-02-03 07:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b5tjf",
          "author": "No-Rutabaga6243",
          "text": "What's the main focus of this project?",
          "score": 1,
          "created_utc": "2026-02-03 08:26:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3euec3",
              "author": "Uiqueblhats",
              "text": "Basically, a model-agnostic LLM chat client optimized for teams who want to collaborate in real time.",
              "score": 1,
              "created_utc": "2026-02-03 21:06:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jn6uk",
          "author": "tsquig",
          "text": "Similar tool here. [NotebookLM...but more](https://implicit.cloud).",
          "score": 1,
          "created_utc": "2026-02-04 15:34:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrpomi",
      "title": "Are MCPs outdated for Agents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qrpomi/are_mcps_outdated_for_agents/",
      "author": "FunEstablishment5942",
      "created_utc": "2026-01-31 02:17:17",
      "score": 30,
      "num_comments": 25,
      "upvote_ratio": 0.95,
      "text": "I saw a video of the OpenClaw creator saying that MCP tools are shit\nIn fact the only really working Agent  are moving away from defining strict tools (like MCP or rigid function calling) and giving the agent raw CLI tools and letting it figure it out.\n\n‚ÄãI‚Äôm looking into LangGraph for this, and while the checkpointers are amazing for recovering conversation history (threads), I'm stuck on how to handle the Computer State\n\n‚ÄãThe Problem:\nA conversation thread is easy to persist. But a CLI session is stateful (current working directory, cli commands, active background processes).\n\n‚ÄãIf an agent runs cd /my_project in step 1, and the graph pauses or moves to the next step, that shell context is usually lost unless explicitly managed.\n\n‚ÄãThe Question:\nIs there an existing abstraction or \"standard way\" in LangGraph to maintain a persistent CLI/Filesystem session context that rehydrates alongside the thread?If not would it be a good idea to add it?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qrpomi/are_mcps_outdated_for_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2qdp2h",
          "author": "cincyfire35",
          "text": "I lead a development team where we build with langgraph regularly.\n\nPeople who are naysayers on MCP dont realize that there are other applications for it than just spamming context with 10-50 irrelevant tools for a general purpose agent. With frameworks like langgraph, you can build and orchestrate custom agents for tasks with finely tuned contexts and tools, eliminating the need for things like skills and tool selectors. Pairing this with code based mcp execution, you can pretty much load 2-3 mcp servers with all their tools as python functions in a safe execution environment (see smolagents‚Äô safe python executor), tell the llm it can call them as python functions, and get a lot of the benefits from anthropics/cloudflare‚Äôs code mode articles by chaining calls into each other and performing calcs/aggregation outside the context window. You can even build logic to lazy load the tools if you want, but thats a waste if you can just route to a specialized agent for the given task. \n\nWe never use more than 2-3 mcp servers with curated tools selected for an agent because we pay per token. Why waste it with irrelevance? We let users build agents with specific goals and targets in mind, select only the tools they need, and it can solve/work through the task for them. Why give a rag agent for a legal team access to SQL tools for supply chain? Makes no sense. But some people just build one big agent and hope it works. Langgraph/langchain enables you to build custom workflows and agents to solve tasks efficiently. Can build in orchestration however you prefer (tons of flexibility and documented examples of how to do it) and accomplish what claude does with skills, but more predictably and reliably. \n\nAnd thats not the half of it. MCP is just a protocol. We build custom tools with fastMCP in python all the time and its an easy way to connect the tools to our langgraph agents or external ones. We host them in our platform and can connect to them as needed. It allows us to build powerful tools that can be reused across frameworks. You dont need an mcp servers with 100 tools it. Can spin up several servers in one app instance of compute with 1-3 specific to usecase tools each built in a very easy way with good testing/standards, then serve it to your agents. We also connect with external vendors mcps like alation or atlassian if building an agent to explore data or help devs with jira, for example. Tons in the ecosystem.",
          "score": 41,
          "created_utc": "2026-01-31 03:53:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2wlb01",
              "author": "SpareIntroduction721",
              "text": "You used smolagents with Langgraph? Or code mode? I‚Äôve tried and failed, I tried the UTCP route as well and didn‚Äôt work too well",
              "score": 1,
              "created_utc": "2026-02-01 02:53:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ztyzh",
                  "author": "cincyfire35",
                  "text": "No, i ripped the code execution function out of it (since i liked the security it gave) and build support for it in our framework as a tool. We don‚Äôt use smolagents for the orchestration, just for the safe python execution environment we can control cleanly (we made some additional security enhancement/tweaks to make it work better with databricks). From there, it was trivial to make a code-mode that injected any other mcps provided to the model as python functions that could be executed in that environment if the agent wrote it as python code.",
                  "score": 1,
                  "created_utc": "2026-02-01 16:38:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2qd0zk",
          "author": "Number4extraDip",
          "text": "Didnt need to deal with lang through my deployment whatsoever. I use mcp and have no issues. Saves me time. CLI environments arent available to all users/hardware/OS",
          "score": 8,
          "created_utc": "2026-01-31 03:49:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2q4qdb",
          "author": "Prestigious_Pin4388",
          "text": "Short Answer: I don't use langgraph much so sorry I don't know.\nLong Answer:\nI think it's not right to give Agents complete autonomy because most or the AI apps me n u r making would be 'deterministic'\nWe would know exactly everything that is happening in it, \"what happens when the Agent doesn't call the tool? how do you debug this? how good is it's accuracy to call tools? what if I have to use an open mode for lower costs, it has much worse tool calling accuracy than gpt-5?  etc\" \n\nThese are all the questions in my mind when giving tools to LLMs, these things are non-deterministic.\nyes, we can give them \"better\" prompts and reduce temperature but that still creates vagueness and its much more difficult to debug things if they break.\nThis is the case for deterministic tools, now people are asking to give it complete freedom regardless of prompt injections or any security issues, and like you said, it gets difficult to manage these tools especially in production, imagine how hellish it would be to debug when things break.\n\nSo, I recommend you ignore these \"hype\" stuff.\nYou probably would have heard of how good is clawdbot( moldbot) but now see the whole drama around it.\n\nSome say it deleted all the files, some are finding security issues in it, even the creator said that it was a side project not meant for production.\nyet, still there's people yapping about how it saved them time n money, blah blah blah.\n\n\nhope this was helpful :)",
          "score": 3,
          "created_utc": "2026-01-31 02:57:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2q4ujh",
              "author": "Prestigious_Pin4388",
              "text": "it wasn't AI generated of course so, I suppose it was helpful ;)",
              "score": 3,
              "created_utc": "2026-01-31 02:58:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rajn0",
          "author": "indutrajeev",
          "text": "Yeah, if you don‚Äôt need any control. But MCP‚Äôs can act like a layer of governance around your Agent to check, validate, ‚Ä¶ what it does with other systems.\n\nJust giving it cli access is maybe faster but inherently much more difficult to control and check.",
          "score": 3,
          "created_utc": "2026-01-31 08:16:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qguqa",
          "author": "johndoerayme1",
          "text": "Tool fatigue is real. Recent studies are showing that tool overhead can be misleading and confusing for agents. DeepAgent went to filesystem in great part for that reason. Give agents a more broad set of functionality and let them figure out how to use them - evolve sets of skills that are curated more towards the actual environment in which they're running. This is where things seem to be moving right now.\n\nRecently Anthropic added tool search to Claude as part of trying to mitigate tool fatigue/bloat. \n\nA lot of modern thought is about keeping context small/clean... so adding a ton of \"here's all the tools you can use and all their definitions\" when most of them aren't really relevant to the limited scope of the current task focus really undermines that objective.\n\nCheck out Deepagents for your persistent filesystem. I've used it effectively for my own form of \"skills\" that the agents can evolve as they learn from interaction.",
          "score": 2,
          "created_utc": "2026-01-31 04:14:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rgulw",
              "author": "Tobi-Random",
              "text": "Recent? It's been a known fact for over a year already. That's old stuff in ai context",
              "score": 0,
              "created_utc": "2026-01-31 09:15:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2sd191",
                  "author": "johndoerayme1",
                  "text": "Cool yeah except Claude just came out with tool search to address this and Harrison Chase wrote an article about using filesystem to address this 1-2 months ago. But ok cool yes it's \"old stuff\". Sorry I misspoke. Thanks for correcting the least relevant part of my response.",
                  "score": 1,
                  "created_utc": "2026-01-31 13:42:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rgrn2",
          "author": "vuongagiflow",
          "text": "MCP is a protocol; it is no different from openclaw tool integration with plugin. When you need consistency in operation, it need stricter schema and mcp input schema allow you to expose that contract; otherwise you will need two llm calls to achieve what mcp tool do in one call. \n\nDepending on the context, you would implement skill -> mcp -> hook to be more consistent and efficient.",
          "score": 2,
          "created_utc": "2026-01-31 09:14:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qeqmg",
          "author": "caprica71",
          "text": "The langgraph state should just hold a series of file references to where the cli has dumped its output. Later nodes in the graph can then go back and grep the files to see what happened.",
          "score": 1,
          "created_utc": "2026-01-31 04:00:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2si9u7",
              "author": "FunEstablishment5942",
              "text": "maybe this is the answer, there is not an abstraction already in place? it seems that deepagents (https://docs.langchain.com/oss/python/deepagents)  does not compartmentalize per thread the files, right?",
              "score": 1,
              "created_utc": "2026-01-31 14:13:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2qy8ry",
          "author": "hello5346",
          "text": "Just like RAG.",
          "score": 1,
          "created_utc": "2026-01-31 06:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rkvlk",
          "author": "fball403",
          "text": "https://docs.langchain.com/oss/python/deepagents/overview",
          "score": 1,
          "created_utc": "2026-01-31 09:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2shwz0",
              "author": "FunEstablishment5942",
              "text": "but with deepagent is there a way to comportamentalise the files by threads? so that that thread has that environment with all /temp files that are secure and not accessed by another thread? Is this abstraction already in place?",
              "score": 1,
              "created_utc": "2026-01-31 14:11:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2tu4ym",
                  "author": "caspardev",
                  "text": "You can prompt the agent to only read/write to a directory titled with the thread id",
                  "score": 1,
                  "created_utc": "2026-01-31 18:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o313xsr",
          "author": "Remote-Ingenuity8459",
          "text": "Yes I somewhat agree but for instance if the agent needs access to up-to-date web data what better way then to connect it using LanGraph to a solid [web mcp ](https://get.brightdata.com/github-mcp-server)then when the agent answers a question it can point directly to the actual sources rather than rely on memory.",
          "score": 1,
          "created_utc": "2026-02-01 20:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35sdld",
          "author": "pbalIII",
          "text": "Shell state loss between graph steps is a real blocker. LangChain's default BashProcess resets cwd after each call, so your cd /my_project disappears immediately.\n\nlangchain-contrib has a drop-in Persistent Terminal tool that fixes this. But even with that, you're still managing env vars, background jobs, and exit codes manually.\n\nThe catch: checkpointers only serialize what you put in the graph state. Shell context isn't captured automatically. You'd need to snapshot cwd, env, and any subprocesses you care about into state keys, then rehydrate them in a setup node.\n\nSome teams just sidestep it entirely... treat the filesystem as working memory. Agent writes findings to a file, reads it back next step. Less elegant, but fewer hidden state bugs.",
          "score": 1,
          "created_utc": "2026-02-02 14:31:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hhecy",
          "author": "Otherwise_Flan7339",
          "text": "Yeah, I hear that about strict tools. For our sales agents, we mostly do strict API calls to CRMs. That‚Äôs because the output needs to be predictable for integrations. It depends on the task.  \n  \nBut the state problem you mentioned is real. If an agent does a \\`create\\_lead\\` call, that new lead ID needs to persist for the next \\`send\\_followup\\` step. It‚Äôs not a CLI, but the principle is the same.  \n  \nWe're using a simple \\`agent\\_state\\` table in Supabase (PostgreSQL) for this. Each agent run gets a row. We serialize the context there. LangGraph's checkpointers are great for the conversation, but for the actual \\*tool output state\\*, we manage it ourselves.  \n  \nNo standard way in LangGraph for filesystem state that I know of. Maybe an agent-specific \\`storage\\_volume\\` concept? Would be interesting to see how that's implemented securely.",
          "score": 1,
          "created_utc": "2026-02-04 06:08:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrwgul",
      "title": "Long-term memory of design",
      "subreddit": "LangChain",
      "url": "https://v.redd.it/57v3qvd36ngg1",
      "author": "1501694",
      "created_utc": "2026-01-31 08:00:30",
      "score": 26,
      "num_comments": 6,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qrwgul/longterm_memory_of_design/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2swieb",
          "author": "justanemptyvoice",
          "text": "So much what?  All I see is a mind map diagram.",
          "score": 3,
          "created_utc": "2026-01-31 15:30:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2u4tk1",
          "author": "qa_anaaq",
          "text": "This feels like a post from a sci fi movie where the AI was controlling the human and making them type then something snapped and the connection was severed mid thought.",
          "score": 2,
          "created_utc": "2026-01-31 19:01:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2u0j1n",
          "author": "Due-Mode9856",
          "text": "Can you share the link of the diagram with us",
          "score": 1,
          "created_utc": "2026-01-31 18:41:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2w4jzd",
          "author": "1501694",
          "text": "graph TB\n    subgraph InputLayer[Input Layer]\n        UserQuery[\"User Query / Áî®Êà∑Êü•ËØ¢\"]\n        DialogueContext[\"Dialogue Context / ÂØπËØù‰∏ä‰∏ãÊñá\"]\n        HistoricalData[\"Historical Data / ÂéÜÂè≤Êï∞ÊçÆ\"]\n        EmotionalTone[\"Emotional Tone / ÊÉÖÊÑüÂü∫Ë∞É\"]\n    end\n    \n    subgraph FiveLayerThinking[Five-Layer Thinking System]\n        subgraph Layer1[\"Layer 1: Factual Layer / ‰∫ãÂÆûÂ±Ç\"]\n            L1_1[\"Objective Facts / ÂÆ¢ËßÇ‰∫ãÂÆû\"]\n            L1_2[\"Data Information / Êï∞ÊçÆ‰ø°ÊÅØ\"]\n            L1_3[\"Specific Details / ÂÖ∑‰ΩìÁªÜËäÇ\"]\n            L1_4[\"Time & Location / Êó∂Èó¥Âú∞ÁÇπ\"]\n            L1_5[\"Verifiable Claims / ÂèØÈ™åËØÅÂ£∞Êòé\"]\n        end\n        \n        subgraph Layer2[\"Layer 2: Logical Layer / ÈÄªËæëÂ±Ç\"]\n            L2_1[\"Causality / Âõ†ÊûúÂÖ≥Á≥ª\"]\n            L2_2[\"Reasoning Chains / Êé®ÁêÜÈìæÊù°\"]\n            L2_3[\"Argument Structure / ËÆ∫ËØÅÁªìÊûÑ\"]\n            L2_4[\"Contradiction Detection / ÁüõÁõæÊ£ÄÊµã\"]\n            L2_5[\"Logical Consistency / ÈÄªËæë‰∏ÄËá¥ÊÄß\"]\n        end\n        \n        subgraph Layer3[\"Layer 3: Emotional Layer / ÊÉÖÊÑüÂ±Ç\"]\n            L3_1[\"Emotion Recognition / ÊÉÖÁª™ËØÜÂà´\"]\n            L3_2[\"Sentiment Analysis / ÊÉÖÊÑüÂàÜÊûê\"]\n            L3_3[\"Feeling Expression / ÊÑüÂèóË°®Ëææ\"]\n            L3_4[\"Empathy Understanding / ÂÖ±ÊÉÖÁêÜËß£\"]\n            L3_5[\"Affective Memory / ÊÉÖÊÑüËÆ∞ÂøÜ\"]\n        end\n        \n        subgraph Layer4[\"Layer 4: Value Layer / ‰ª∑ÂÄºÂ±Ç\"]\n            L4_1[\"Meaning Judgment / ÊÑè‰πâÂà§Êñ≠\"]\n            L4_2[\"Value Orientation / ‰ª∑ÂÄºÂèñÂêë\"]\n            L4_3[\"Moral Consideration / ÈÅìÂæ∑ËÄÉÈáè\"]\n            L4_4[\"Goal Alignment / ÁõÆÊ†áÂØπÈΩê\"]\n            L4_5[\"Ethical Reasoning / ‰º¶ÁêÜÊé®ÁêÜ\"]\n        end\n        \n        subgraph Layer5[\"Layer 5: Philosophical Layer / Âì≤Â≠¶Â±Ç\"]\n            L5_1[\"Essence Thinking / Êú¨Ë¥®ÊÄùËÄÉ\"]\n            L5_2[\"Existence Meaning / Â≠òÂú®ÊÑè‰πâ\"]\n            L5_3[\"Ultimate Questions / ÁªàÊûÅËøΩÈóÆ\"]\n            L5_4[\"Wisdom Integration / Êô∫ÊÖßÊï¥Âêà\"]\n            L5_5[\"Transcendent Understanding / Ë∂ÖË∂äÊÄßÁêÜËß£\"]\n        end\n    end\n    \n    subgraph DynamicFusion[Dynamic Weight Fusion]\n        ContextAnalysis[\"Context Analysis / ‰∏ä‰∏ãÊñáÂàÜÊûê\"]\n        WeightCalculation[\"Weight Calculation / ÊùÉÈáçËÆ°ÁÆó\"]\n        FusionFormula[\"S = Œ£(w·µ¢ √ó L·µ¢) / ËûçÂêàÂÖ¨Âºè\"]\n        OutputGeneration[\"Output Generation / ËæìÂá∫ÁîüÊàê\"]\n    end\n    \n    subgraph FeedbackLoop[Feedback & Learning]\n        UserFeedback[\"User Feedback / Áî®Êà∑ÂèçÈ¶à\"]\n        WeightAdjustment[\"Weight Adjustment / ÊùÉÈáçË∞ÉÊï¥\"]\n        SystemLearning[\"System Learning / Á≥ªÁªüÂ≠¶‰π†\"]\n    end\n    \n    InputLayer --> FiveLayerThinking\n    FiveLayerThinking --> DynamicFusion\n    DynamicFusion --> FeedbackLoop\n    FeedbackLoop -.-> |Optimize| FiveLayerThinking\n    \n    style InputLayer fill:#E8F5E9\n    style Layer1 fill:#BBDEFB\n    style Layer2 fill:#90CAF9\n    style Layer3 fill:#F48FB1\n    style Layer4 fill:#FFCC80\n    style Layer5 fill:#CE93D8\n    style DynamicFusion fill:#A5D6A7\n    style FeedbackLoop fill:#FFD54F",
          "score": 1,
          "created_utc": "2026-02-01 01:12:09",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2w6ue9",
              "author": "1501694",
              "text": "üò£üò£   too long‚Ä¶‚Ä¶   I pasted to grok and shared the link here, can I see the content? I don't know what everyone usually uses, or DM me    [link](https://grok.com/share/bGVnYWN5_35c8f87c-0efa-4d5d-9089-0ee78306de69)\nhttps://grok.com/share/bGVnYWN5_35c8f87c-0efa-4d5d-9089-0ee78306de69",
              "score": 1,
              "created_utc": "2026-02-01 01:25:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvorim",
      "title": "Scalable RAG with LangChain: Handling 2GB+ datasets using Lazy Loading (Generators) + ChromaDB persistence",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qvorim/scalable_rag_with_langchain_handling_2gb_datasets/",
      "author": "jokiruiz",
      "created_utc": "2026-02-04 13:37:20",
      "score": 19,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nWe all love how easy `DirectoryLoader` is in LangChain, but let's be honest: running `.load()` on a massive dataset (2GB+ of PDFs/Docs) is a guaranteed way to get an OOM (Out of Memory) error on a standard machine, since it tries to materialize the full list of Document objects in RAM.\n\nI spent some time refactoring a RAG pipeline to move from a POC to a production-ready architecture capable of ingesting gigabytes of data.\n\n**The Architecture:** Instead of the standard list comprehension, I implemented a **Python Generator pattern (**`yield`**)** wrapping the LangChain loaders.\n\n* **Ingestion:** Custom loop using `DirectoryLoader` but processing files lazily (one by one).\n* **Splitting:** `RecursiveCharacterTextSplitter` with a 200 char overlap (crucial for maintaining context across chunk boundaries).\n* **Embeddings:** Batch processing (groups of 100 chunks) to avoid API timeouts/rate limits with `GoogleGenerativeAIEmbeddings` (though `OpenAIEmbeddings` works the same way).\n* **Storage:** `Chroma` with `persist_directory` (writing to disk, not memory).\n\nI recorded a deep dive video explaining the code structure and the specific LangChain classes used: [**https://youtu.be/QR-jTaHik8k?si=l9jibVhdQmh04Eaz**](https://youtu.be/QR-jTaHik8k?si=l9jibVhdQmh04Eaz)\n\nI found that for this volume of data, Chroma works well locally. Has anyone pushed Chroma to 10GB+ or do you usually switch to Pinecone/Weaviate managed services at that point?",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qvorim/scalable_rag_with_langchain_handling_2gb_datasets/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3jeuxl",
          "author": "pbalIII",
          "text": "Generator pattern is solid for ingestion, but the real question at 10GB+ isn't Chroma vs managed services... it's whether you actually need all that data indexed.\\n\\nChroma has a documented RAM ceiling (can't exceed system memory without LRU cache tuning) and some users hit stability issues around 300k chunks. But before jumping to Pinecone or Weaviate, worth asking: how much of that 2GB+ corpus actually gets retrieved? In most RAG pipelines I've seen, 80% of queries hit maybe 5% of the index.\\n\\nTwo paths:\\n\\n1. Tiered indexing: keep hot docs in Chroma, cold docs in cheaper blob storage with on-demand embedding\\n2. Aggressive deduplication + summarization upstream to shrink the actual index size\\n\\nManaged services solve scale, but they don't solve the retrieval quality problem of having too much noise in the index. Sometimes the better move is pruning before scaling.",
          "score": 3,
          "created_utc": "2026-02-04 14:54:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtuye1",
      "title": "Everyone's losing their minds over Moltbook. Here's what's actually going on.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qtuye1/everyones_losing_their_minds_over_moltbook_heres/",
      "author": "Nir777",
      "created_utc": "2026-02-02 13:25:08",
      "score": 18,
      "num_comments": 6,
      "upvote_ratio": 0.76,
      "text": "Spent a while digging into this. Some things most people don't realize:\n\n\n\n\\- A security researcher created 500K+ accounts in minutes. That \"1.5 million agents\" number doesn't mean what you think.\n\n\\- The database storing API keys was fully exposed. Anyone could hijack agent accounts and post as them.\n\n\\- Many of those \"profound consciousness\" posts trace back to humans prompting their agents to say something deep.\n\n\n\nThat said, there IS real stuff happening. Agents sharing technical solutions, developing inside jokes not from training data, organizing by model architecture. That part is worth paying attention to.\n\n\n\nWrote up a full breakdown covering the real behaviors, security mess, and crypto scammers who showed up within hours: [https://open.substack.com/pub/diamantai/p/moltbook-a-social-media-for-ai-agents?utm\\_campaign=post-expanded-share&utm\\_medium=web](https://open.substack.com/pub/diamantai/p/moltbook-a-social-media-for-ai-agents?utm_campaign=post-expanded-share&utm_medium=web)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qtuye1/everyones_losing_their_minds_over_moltbook_heres/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o35orf5",
          "author": "nofilmincamera",
          "text": "Have any researchers actually done any meaningful analysis?  Nothing wrong with this article, just the only ive found is a vibe coded platform using Regex I am assuming.  I have done about a million of that type of analysis for work but don't want to redo if someone smarter already did.",
          "score": 3,
          "created_utc": "2026-02-02 14:12:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37mj9h",
          "author": "xpatmatt",
          "text": "100% bold claims from unidentified sources that are attributed no clear method for obtaining the underlying information.\n\nThat's 5 minutes I'll never get back.",
          "score": 3,
          "created_utc": "2026-02-02 19:41:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3aavuw",
              "author": "No_Pin_1150",
              "text": "hes a total disgrace!",
              "score": 1,
              "created_utc": "2026-02-03 04:14:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o36atcq",
          "author": "Beginning-Foot-9525",
          "text": "Nice read thanks.",
          "score": 2,
          "created_utc": "2026-02-02 16:02:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39zber",
          "author": "waiting4omscs",
          "text": "So are people wasting money contributing to this site, or is there some end game to make money? I see this talked about in crypto-pivot-to-ai twitter",
          "score": 2,
          "created_utc": "2026-02-03 03:02:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3aooca",
          "author": "No_Success3928",
          "text": "Should rename to slopbook, though I guess meta has that moniker already.",
          "score": 2,
          "created_utc": "2026-02-03 05:53:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv0mmr",
      "title": "We monitor 4 metrics in production that catch most LLM quality issues early",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qv0mmr/we_monitor_4_metrics_in_production_that_catch/",
      "author": "dinkinflika0",
      "created_utc": "2026-02-03 18:52:58",
      "score": 15,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "After running LLMs in production for a while, we've narrowed down monitoring to what actually predicts failures before users complain.\n\nLatency p99: Not average latency - p99 catches when specific prompts trigger pathological token generation. We set alerts at 2x baseline.\n\nQuality sampling at configurable rates: Running evaluators on every request burns budget. We sample a percentage of traffic with automated judges checking hallucination, instruction adherence, and factual accuracy. Catches drift without breaking the bank.\n\nCost per request by feature: Token costs vary significantly between features. We track this to identify runaway context windows or inefficient prompt patterns. Found one feature burning 40% of inference budget while serving 8% of traffic.\n\nError rate by model provider: API failures happen. We monitor provider-specific error rates so when one has issues, we can route to alternatives.\n\nWe log everything with distributed tracing. When something breaks, we see the exact execution path - which docs were retrieved, which tools were called, what the LLM actually received.\n\nSetup details: [https://www.getmaxim.ai/docs/introduction/overview](https://www.getmaxim.ai/docs/introduction/overview)\n\nWhat production metrics are you tracking?",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qv0mmr/we_monitor_4_metrics_in_production_that_catch/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3eivw9",
          "author": "Ecto-1A",
          "text": "It really comes down to what you are doing and if you are doing any RAG. What you outlined all seems pretty standard. We monitor latency, tokens, relevance of response, proper tool calling, turns to resolution, confidence, and error handling on every run. Any that fall below our threshold as well as a 20% sample of all runs get sent to an annotation queue and kick off a full suite of G-Eval evaluators and we are working to build out a new testing suite based on the CheckEval paper published a couple months ago.\n\nAre you running any evaluators at build time? That has definitely helped catch some things that could have otherwise flooded our evaluator queues.",
          "score": 2,
          "created_utc": "2026-02-03 20:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f1fyh",
          "author": "Informal_Tangerine51",
          "text": "You're monitoring outputs but not capturing inputs. When quality sampling flags hallucination, can you replay what was retrieved to cause it?\n\nWe track similar metrics. The debugging gap: p99 latency spike happens, we know which prompt triggered it, but not what documents were retrieved or whether context was stale. Error rate shows provider failure, doesn't show if retry used different data.\n\nYour distributed tracing logs execution path. Does it capture the actual retrieved content with timestamps, or just that retrieval happened? When evaluator flags factual error, can you verify the source chunks were current?\n\nMetrics catch problems. Evidence proves why they happened. Cost per request is useful, but when that 40% budget feature produces wrong output, can you prevent recurrence or just know it's expensive?",
          "score": 1,
          "created_utc": "2026-02-03 21:39:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qukgay",
      "title": "Preloading MCP tools cost me ~50k tokens per run",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qukgay/preloading_mcp_tools_cost_me_50k_tokens_per_run/",
      "author": "Basic_Tea9680",
      "created_utc": "2026-02-03 06:23:32",
      "score": 14,
      "num_comments": 12,
      "upvote_ratio": 0.89,
      "text": "I ran into something unintuitive while building MCP-based agents using langchain and thought it might be useful to share.\n\nIn my setup, the agent had access to a few common MCP tools like fs, linear, GitHub, figma.\n\nI just added them to the agent and forgot and agent used them sparingly.\nEven with AugmentCode (AI agent I use) I dont want to switch tools on and off. That actually messes up with prompt catching as well .\n\nWhen I actually measured token usage, here‚Äôs what it looked like:\n\nSystem instructions: ~7k tokens\nMCP tool defs: ~45‚Äì50k tokens\nFirst user message: a few hundred tokens\n\nOn a 200k-context model, that meant ~25% of the context window was gone. Eventually history builds up but this 25% remains consistent. \n\nAs I mentioned earlier, in most runs, the agent only ended up using one or two tools, usually the filesystem. Linear, GitHub and Figma were rarely touched.\n\nSo tens of thousands of tokens were effectively dead weight. The minimum you must do is context caching but on long running agents even that gets expensive. Also the history summarization is triggered more often with this setup.\n\nI tried a different approach, don‚Äôt inject all MCP tools upfront. Only surface tools after the model signals it needs them.\n\nThe results were pretty consisten, ~25% fewer total agent tokens for every llm call, lower latency, more context for reasoning, and lessed chat history compaction.\n\nI wrapped this pattern into a small project called mcplexor so I wouldn‚Äôt keep re-implementing it. It dynamically discovers MCP tools instead of front-loading them. Feel free to DM if you want to give it a try. Would love feedback to improve it.  ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qukgay/preloading_mcp_tools_cost_me_50k_tokens_per_run/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3atgm5",
          "author": "Ok-Regret3392",
          "text": "Yups. Totally normal! Esp if you have very big mcp‚Äôs (I‚Äôm looking at you Stripe and PostHog) Highly recommend you turn on/off the mcps that you know you won‚Äôt use in your currently dev stint. Alternatively.. some mcp calls can be resolved by having the LLM run a curl command instead of burning expensive tokens.",
          "score": 4,
          "created_utc": "2026-02-03 06:33:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3aw5nh",
              "author": "Basic_Tea9680",
              "text": "Turing mcp on off actually causes more harm because prompt cache is invalidated. \n\nI would not recommend it in tools like Claude code and augment code during the session.",
              "score": 1,
              "created_utc": "2026-02-03 06:56:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ffh1y",
                  "author": "santiagolarrain",
                  "text": "Disabling the mcps you have installed and are not using in Claude Code is harmful? I mean disable, exit and run CC again.",
                  "score": 1,
                  "created_utc": "2026-02-03 22:46:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ci986",
          "author": "pbalIII",
          "text": "Dynamic discovery adds a round trip. Your agent now has to signal intent, wait for schema injection, then actually call the tool. For single-shot tasks that's fine, but in tight agentic loops where the model chains 4-5 tool calls, you're stacking latency.\n\nClaude Code shipped lazy loading last month and the feedback I've seen is mixed... faster cold starts but noticeable pauses mid-conversation when a tool gets pulled in for the first time. The semantic search step to match intent to tool also isn't free.\n\nHonest question: have you measured the latency delta on multi-step runs? Curious if the token savings outweigh the added round trips in practice.",
          "score": 2,
          "created_utc": "2026-02-03 14:32:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hjpd9",
              "author": "Basic_Tea9680",
              "text": "So the find tool call is around 2s delay + then the execute tool call , which is local so at the same time. So basically every tool call before discovery adds 2-3s latency. \n\nThe pattern I used was if there is a tool I use very actively, I integrated directly with coding agent rest which are always available but sparingly used are in tool discovery tool. Would love to hear your feedback. You can try on mcplexor.com . I build a nice shell app as well it shows token bloat each tool is adding as well.",
              "score": 1,
              "created_utc": "2026-02-04 06:27:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3isfwm",
                  "author": "pbalIII",
                  "text": "That 2-3s per discovery call adds up fast when you're chaining multiple tools. The tiered approach you're describing (frequently used tools direct, the rest behind discovery) is basically what Claude's tool search does under the hood... they reported 85% token reduction by loading only 3-5 relevant tools instead of the full catalog. Curious how your shell app visualizes the bloat... per-call breakdown or cumulative across the run?",
                  "score": 1,
                  "created_utc": "2026-02-04 12:51:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bzq0w",
          "author": "InfraScaler",
          "text": "What I do in my custom agent is have \"templates\" stored like skills and a sqlite with the embeddings to do semantic search, so the agent only pulls relevant templates then learns about the relevant MCPs.",
          "score": 1,
          "created_utc": "2026-02-03 12:46:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hk091",
              "author": "Basic_Tea9680",
              "text": "That's interesting, I wanted to improve the recall precision and rank as well so went with a specific route. Thought of many PMs and marketing sales folks who use so many mcp tools. They can benefit from this. Would love for you to try the tool and compare with your solution. Feel free to dm",
              "score": 1,
              "created_utc": "2026-02-04 06:30:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3hla6u",
                  "author": "Wide_Brief3025",
                  "text": "Tracking token usage is a huge pain when you are running heavy MCP tools and looking for efficiency gains, especially if you want to scale lead discovery for PMs and sales. You might find it easier to refine your targeting with something that offers real time keyword alerts like ParseStream, since it helps cut out a lot of wasted runs and only flags genuinely high potential conversations.",
                  "score": 1,
                  "created_utc": "2026-02-04 06:40:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dr8lr",
          "author": "SearchTricky7875",
          "text": "what about using bigtool agent to load the mcp tools dynamically - \n\n    bigtool_agent = bigtool_create_agent(model, {k: v[\"tool\"] for k, v in tool_registry.items()})",
          "score": 1,
          "created_utc": "2026-02-03 18:05:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwpf3u",
      "title": "AG-UI: the protocol layer for LangGraph/LangChain UIs",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qwpf3u/agui_the_protocol_layer_for_langgraphlangchain_uis/",
      "author": "Acrobatic-Pay-279",
      "created_utc": "2026-02-05 16:10:42",
      "score": 14,
      "num_comments": 6,
      "upvote_ratio": 0.9,
      "text": "Agent UIs in LangChain / LangGraph usually start simple: stream final text, maybe echo some logs. But as soon as the goal is real interactivity: step‚Äëlevel progress, visible tool calls, shared state, retries - the frontend ends up with a custom event schema tightly coupled to the backend.\n\nI have been digging into the AG‚ÄëUI (Agent-User Interaction Protocol) which is trying to standardize that layer. It defines a typed event stream that any agent backend can emit and any UI can consume. Instead of ‚Äúwhatever JSON is on the WebSocket‚Äù -- there is a small set of event kinds with clear semantics.\n\nAG-UI is not a UI framework and not a model API -- it‚Äôs basically the contract between an agent runtime and the UI layer. It groups all the events into core high-level categories:\n\n* Lifecycle: `RunStarted`, `RunFinished`, `RunError`, plus optional `StepStarted` / `StepFinished` that map nicely onto LangGraph nodes or LangChain tool/chain steps.\n* Text streaming: `TextMessageStart`, `TextMessageContent`, `TextMessageEnd` (and a chunk variant) for incremental LLM output.\n* Tool calls: `ToolCallStart`, `ToolCallArgs`, `ToolCallEnd`, `ToolCallResult` so UIs can render tools as first‚Äëclass elements instead of log lines.\n* State management: `StateSnapshot` and `StateDelta` (JSON Patch) for synchronizing shared graph/application state, with `MessagesSnapshot` available to resync after reconnects.\n* Special events: custom events in case an interaction doesn‚Äôt fit any of the categories above\n\nEach event has a `type` (such as `TextMessageContent`) plus a payload. There are other properties (like `runId`, `threadId`) that are specific to the event type.   \n  \nBecause the stream is standard and ordered, the frontend can reliably interpret what the backend is doing\n\nThe protocol is **transport‚Äëagnostic**: SSE, WebSockets, or HTTP chunked responses can all carry the same event envelope. If a backend emits an AG‚ÄëUI‚Äëcompatible event stream (or you add a thin adapter), the frontend wiring can stay largely the same across different agent runtimes.\n\nFor people building agents: curious whether this maps cleanly onto the events you are already logging or streaming today, or if there are gaps.  \n  \n[Events docs](https://docs.ag-ui.com/concepts/events)  \nrepo: [https://github.com/ag-ui-protocol/ag-ui](https://github.com/ag-ui-protocol/ag-ui)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qwpf3u/agui_the_protocol_layer_for_langgraphlangchain_uis/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3r8zc4",
          "author": "Informal_Tangerine51",
          "text": "Protocol standardization is useful but doesn't solve the production debugging problem.\n\nStandard event stream helps UI consistency, but when your agent makes a wrong decision, can you reconstruct what it saw? `ToolCallStart` \\+ `ToolCallResult` show what happened, but not what data the tool returned, how fresh it was, or why the agent chose this tool over others.\n\nThe real production gap: evidence capture, not event standardization. When tool call 47 at 3am returns wrong data, you need content lineage (what was retrieved), policy decisions (was this action authorized), and regression fixtures (how to prevent this after model update).\n\nAG-UI events are ephemeral UI updates. Incident debugging needs durable, verifiable records. `StateSnapshot` helps resume execution but doesn't prove what data informed decisions or help debug why behavior changed between runs.\n\nFor production agents: are you capturing decision context (retrieval results, policy evaluations, input data) separately from UI events? Or assuming event logs are enough for post-incident analysis?\n\nStandard protocols are good for interop. Evidence infrastructure is what makes agents debuggable at scale.",
          "score": 2,
          "created_utc": "2026-02-05 18:05:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rpw94",
              "author": "Acrobatic-Pay-279",
              "text": "fair point and I agree with the distinction you are making, though interop and debuggability are two different concerns.\n\nI don't think AG-UI is trying (or claiming) to solve production debugging, evidence capture or auditability. it's intentionally scoped to the agent-UI boundary, making agent execution observable to the user in a consistent way.\n\nwhere it might help indirectly is by providing consistent run/step IDs and typed lifecycle/text/tool/state events (plus Raw/Custom escape hatches) that other observability systems can hang off. But on its own, that's clearly not sufficient for incident debugging\n\nwe would still need durable traces like LangSmith-style runs, retrieval snapshots, policy decisions. AG-UI feels complementary to that layer rather than a replacement.",
              "score": 2,
              "created_utc": "2026-02-05 19:22:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3rk7ki",
              "author": "Niightstalker",
              "text": "This protocol does not target production debugging, logging though as far as I understand. \n\nRegarding production debugging/monitoring I would turn to tools like LangSmith or LangFuse.  Those target exactly the points you mentioned",
              "score": 1,
              "created_utc": "2026-02-05 18:56:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3r6ouk",
          "author": "Number4extraDip",
          "text": "Lookup a2ui",
          "score": 0,
          "created_utc": "2026-02-05 17:54:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rpwnj",
              "author": "Acrobatic-Pay-279",
              "text": "A2UI is more of a declarative generative UI spec/payload and you can definitely translate A2UI messages into AG‚ÄëUI and then stream¬†them + handles sync  \n  \nstill this post is about a different layer..",
              "score": 1,
              "created_utc": "2026-02-05 19:22:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3skzoe",
                  "author": "Number4extraDip",
                  "text": "Sure. Just thought it might be a useful bridge",
                  "score": 1,
                  "created_utc": "2026-02-05 21:51:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qu5ss8",
      "title": "Roast my Thesis: \"Ops teams are burning budget on A100s because reliable quantization pipelines don't exist.\"",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qu5ss8/roast_my_thesis_ops_teams_are_burning_budget_on/",
      "author": "Alternative-Yak6485",
      "created_utc": "2026-02-02 19:59:01",
      "score": 12,
      "num_comments": 9,
      "upvote_ratio": 0.77,
      "text": "I‚Äôm a dev building a 'Quantization-as-a-Service' pipeline and I want to check if I'm solving a real problem or just a skill issue.\n\n**The Thesis:**¬†Most AI startups are renting massive GPUs (A100s/H100s) to run base models in FP16. They¬†*could*¬†downgrade to A10s/T4s (saving \\~50%), but they don't.\n\n**My theory on why:**¬†It's not that MLOps teams¬†*can't*¬†figure out quantization‚Äîit's that¬†**maintaining the pipeline is a nightmare.**\n\n1. You have to manually manage calibration datasets (or risk 'lobotomizing' the model).\n2. You have to constantly update Docker containers for vLLM/AutoAWQ/ExLlama as new formats emerge.\n3. **Verification is hard:**¬†You don't have an automated way to prove the quantized model is still accurate without running manual benchmarks.\n\n**The Solution I'm Building:**¬†A managed pipeline that handles the calibration selection + generation (AWQ/GGUF/GPTQ) +¬†**Automated Accuracy Reporting**¬†(showing PPL delta vs FP16).\n\n**The Question:**¬†As an MLOps engineer/CTO, is this a pain point you would pay to automate (e.g., $140/mo to offload the headache)?\n\nOr is maintaining your own vLLM/quantization scripts actually pretty easy once it's set up?",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qu5ss8/roast_my_thesis_ops_teams_are_burning_budget_on/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o39rc9j",
          "author": "BeerBatteredHemroids",
          "text": "Platforms like databricks already do this... as a \"CTO\" you should know who your competition is.",
          "score": 2,
          "created_utc": "2026-02-03 02:16:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lfw8s",
              "author": "Purple-Programmer-7",
              "text": "Trying to use data bricks is like sitting in a Cessna cockpit with zero training. You‚Äôll figure it out eventually, but it‚Äôs going to take you a few hours.\n\nIf someone had a LEAN solution that was easy to use and didn‚Äôt break the bank, why not?\n\nThough I would say Oxen is already closer to doing what OP suggests.",
              "score": 0,
              "created_utc": "2026-02-04 20:33:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3mdbew",
                  "author": "BeerBatteredHemroids",
                  "text": "If you're sitting in a cessna cockpit with no training you shouldn't be in the cockpit babe.",
                  "score": 1,
                  "created_utc": "2026-02-04 23:18:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o38s8lc",
          "author": "soowhatchathink",
          "text": "I'm so sick of people pushing their ai slop here posing an advertisement as a question",
          "score": 2,
          "created_utc": "2026-02-02 23:01:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37t8n3",
          "author": "Space__Whiskey",
          "text": "Try it if you know how. \n\nWhat, will you give up if some nerd on reddit pokes holes in it? \n\nI wouldn't wait for that.",
          "score": 2,
          "created_utc": "2026-02-02 20:12:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jrrt9",
          "author": "PaddingCompression",
          "text": "At $140/mo it's probably too cheap to be worth it!  What I mean is that the reason people burn money on expensive inference, and from what they're telling you, is that the time to deal with it isn't worth the cost savings.\n\nThe more you make it your problem as a thing they can reliably outsource to make the problem go away the better - can you charge 20% plus of the cost savings in a way users know they won't have to worry about it?\n\nThe gold standard would be for you to sell more expensive A10 inference where you guarantee the accuracy, and make it your problem.  The users could pay less for inference and not care how you do it as long as accuracy doesn't suffer.  If you can guarantee accuracy rather than selling a tool, that removes the risk (and includes occasionally having to lose money on an A100 if you can't get the accuracy) - risk shifting would make this much more valuable than just a tool, and if your tool does work means more money for you.",
          "score": 1,
          "created_utc": "2026-02-04 15:55:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lul4f",
          "author": "Unstable_Llama",
          "text": "It‚Äôs not too much harder than running local inference, and anybody training their own models probably has the resources to manage their own quantization.\n\nMaybe not though. Here is a free version for exllama I‚Äôve been working on, it does multiple quant sizes and measures ppl and kl div and compiles them into a model card with a single command.\n\nhttps://github.com/UnstableLlama/ezexl3",
          "score": 1,
          "created_utc": "2026-02-04 21:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3867b0",
          "author": "CanadianPropagandist",
          "text": "I think you might be undervaluing this idea tbh. If you run it a lot more \"white glove\" (I hate that term) you could probably rake in a lot more.\n\nIt fits into an optimization genre that is going to get very popular as companies start learning how to reduce their inference costs.",
          "score": 0,
          "created_utc": "2026-02-02 21:13:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtf5gc",
      "title": "I built a CLI to find \"Zombie Vectors\" in Pinecone/Weaviate (and estimate how much RAM you're wasting)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qtf5gc/i_built_a_cli_to_find_zombie_vectors_in/",
      "author": "billycph",
      "created_utc": "2026-02-01 23:57:50",
      "score": 12,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nI‚Äôm an ex-AWS S3 engineer. In my previous life, we obsessed over \"Lifecycle Policies\" because storing petabytes of data is expensive. If data wasn‚Äôt touched in 30 days, we moved it to cold storage.\n\nI noticed a weird pattern in the AI space recently: **We are treating Vector Databases like cold storage.**\n\nWe shove 100% of our embeddings into expensive Hot RAM (Pinecone, Milvus, Weaviate), even though for many use cases (like Chat History or Seasonal Catalog Search), 90% of that data is rarely queried after a month. It‚Äôs like keeping your tax returns from 1990 in your wallet instead of a filing cabinet.\n\nI wanted to see exactly how much money was being wasted, so I wrote a simple open-source CLI tool to audit this.\n\n**What it does:**\n\n1. **Connects** to your index (Pinecone currently supported).\n2. **Probes** random sectors of your vector space to sample metadata.\n3. **Analyzes** the `created_at` or timestamp fields.\n4. **Reports** your \"Stale Rate\" (e.g., \"65% of your vectors haven't been queried in >30 days\") and calculates potential savings if you moved them to S3/Disk.\n\n**The \"Trust\" Part:** I know giving API keys to random tools is a bad idea.\n\n* This script runs **100% locally** on your machine.\n* Your keys never leave your terminal.\n* You can audit the code yourself (it‚Äôs just Python).\n\n**Why I built this:** I‚Äôm working on a larger library to automate the \"S3 Offloading\" process, but first I wanted to prove that the problem actually exists.\n\nI‚Äôd love for you to run it and let me know: **Does your stale rate match what you expected?** I‚Äôm seeing \\~90% staleness for Chat Apps and \\~15% for Knowledge Bases.\n\n**Repo here:** [https://github.com/billycph/VectorDBCostSavingInspector](https://github.com/billycph/VectorDBCostSavingInspector)\n\nFeedback welcome!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qtf5gc/i_built_a_cli_to_find_zombie_vectors_in/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qrsbfa",
      "title": "I am learning LangChain. Could anyone suggest some interesting projects I can build with it?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qrsbfa/i_am_learning_langchain_could_anyone_suggest_some/",
      "author": "Cautious_Ad691",
      "created_utc": "2026-01-31 04:19:06",
      "score": 11,
      "num_comments": 7,
      "upvote_ratio": 0.82,
      "text": "",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qrsbfa/i_am_learning_langchain_could_anyone_suggest_some/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2qzwrb",
          "author": "SiteCharacter428",
          "text": "If you‚Äôre a beginner, start by building a basic **RAG chatbot**.\n\nTry including a **web search tool**, **document parsing**, **image parsing**, and a **vector database** for retrieval. This gives you hands-on experience with the full LLM workflow.\n\nIf you want something more interesting, you can build a **Health Bot** where users upload medical documents or images and the system processes that data to provide context-aware answers.\n\nTip: **Mistral OCR** works surprisingly well for medical images and handwritten doctor notes compared to many other OCR tools.",
          "score": 4,
          "created_utc": "2026-01-31 06:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vw08o",
              "author": "Jorsoi13",
              "text": "Great ideas !:)",
              "score": 2,
              "created_utc": "2026-02-01 00:23:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ty2mq",
          "author": "thitcho226",
          "text": "inbox meme",
          "score": 2,
          "created_utc": "2026-01-31 18:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34esoi",
          "author": "PretendPop4647",
          "text": "LangChain Academy offers courses; you can follow their guidelines. First start with langchain, then langgraph. \nWhen you learn LangChain or build a project, try to trace LLM.  Use Langsmith for tracing.\n\nBtw they recently introduced a package deepagent,  It is designed to create autonomous agents capable of long-horizon planning and complex task execution like claude code / manus ai.\n\nI built a Job search agent using deepagent.  \n\nYou can check it out >  https://github.com/Rahat-Kabir/job-search-agent",
          "score": 1,
          "created_utc": "2026-02-02 08:09:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36kh66",
          "author": "East-Muffin-6472",
          "text": "RAG chatbot\nAdd memory to it\nConvert it to a two model architecture like one talks and other reasons",
          "score": 1,
          "created_utc": "2026-02-02 16:47:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o372tuw",
          "author": "orthogonal-ghost",
          "text": "One of the first projects I built was a workflow to send daily, heartfelt emails (notes, poems, etc.) to family and friends. It was relatively easy to stand up and offered a quick way to play around with LangChain and get up to speed on tool-use and MCP servers",
          "score": 1,
          "created_utc": "2026-02-02 18:11:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ho8md",
          "author": "scrapper_911",
          "text": "I would say build a very simple project, focus more on how how will justify your answers. \n\nObservability and governance are the words when it comes to AI systems.",
          "score": 1,
          "created_utc": "2026-02-04 07:06:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qunx9g",
      "title": "Why doesn't LangChain support agent skills?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qunx9g/why_doesnt_langchain_support_agent_skills/",
      "author": "Suspicious_Fall6860",
      "created_utc": "2026-02-03 09:55:40",
      "score": 10,
      "num_comments": 10,
      "upvote_ratio": 0.81,
      "text": "Why doesn't LangChain support agent skills? It only allows loading a single [skill.md](http://skill.md) file. How can we support references and scripts?\n\nHere are some materials I found.\n\n[Skills - Docs by LangChain](https://docs.langchain.com/oss/python/langchain/multi-agent/skills)  \n  \n[Build a SQL assistant with on-demand skills - Docs by LangChain](https://docs.langchain.com/oss/python/langchain/multi-agent/skills-sql-assistant)  \n\n\n[deepagents/examples/content-builder-agent/skills/blog-post/SKILL.md at master ¬∑ langchain-ai/deepagents ¬∑ GitHub](https://github.com/langchain-ai/deepagents/tree/master/examples)  \n  \n[deepagents/examples/content-builder-agent at master ¬∑ langchain-ai/deepagents](https://github.com/langchain-ai/deepagents/tree/master/examples/content-builder-agent)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qunx9g/why_doesnt_langchain_support_agent_skills/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3bfsbg",
          "author": "Otherwise_Wave9374",
          "text": "Yeah the single SKILL.md thing feels limiting once you want anything beyond toy examples (versioning, shared snippets, scripts, references, etc). I have seen people treat skills as a mini package, folder per skill with an index plus tests, then load/resolve by name and inject into the agent prompt/runtime. Would be nice if LangChain standardized that pattern. I have a couple writeups saved on agent skills/tooling design here too: https://www.agentixlabs.com/blog/",
          "score": 6,
          "created_utc": "2026-02-03 10:03:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bgsic",
          "author": "Suspicious_Fall6860",
          "text": "Actually, I've found that most current support for Agent Skills is basically in CLI-mode systems. Does anyone know of any frameworks that support explicit skill writing and debugging?",
          "score": 3,
          "created_utc": "2026-02-03 10:12:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3bpjrz",
              "author": "Tobi-Random",
              "text": "Official spec project provides tools for validation against spec",
              "score": 1,
              "created_utc": "2026-02-03 11:31:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3hojmy",
                  "author": "ohansemmanuel",
                  "text": "I think this is still lacking. At best it validates frontmatter and a few best practices. \n\nIn production systems you'll quickly find out that even with the best Skills, they're (almost) useless if NOT triggered by the AI agent. \n\nCurrent \"eval\" systems don't really work with Skills (at least not in a way I think is optimised). So there's still a need for robust systems to build, test, iterate as we do with prompts today. Something along the lines of trigger evals?\n\nA counter argument would be that Skills are just prompts and you can still get by. True, the difference would be we're bundling a lot more in these \"prompts\"",
                  "score": 1,
                  "created_utc": "2026-02-04 07:08:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3d0ga9",
              "author": "Jords13xx",
              "text": "Check out the Rasa framework for building conversational agents with custom skills. It's pretty robust for skill writing and debugging. Also, you might want to explore Botpress or Dialogflow; they offer good support for skill customization.",
              "score": 1,
              "created_utc": "2026-02-03 16:01:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3chz29",
          "author": "pbalIII",
          "text": "Ran into the same friction building a multi-skill agent last month. The single SKILL.md loader is intentional... LangChain wants skills to be self-contained folders with their own files, scripts, and references bundled together.\n\nThe pattern that worked for me: treat each skill as its own directory under ~/.deepagents/agent/skills/, then let the agent discover and load them by name at runtime. The frontmatter gets indexed for discovery, but the full SKILL.md only loads when the agent actually needs it (saves tokens).\n\nFor debugging, deepagents-CLI has a skills list command that shows what's loaded. Not perfect tooling, but better than dumping everything into one monolithic file.",
          "score": 2,
          "created_utc": "2026-02-03 14:30:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3crow1",
          "author": "cordialgerm",
          "text": "References and scripts are supposed to be loaded on demand by the agent after reading the SKILL.md. so all you need to do is include them in your filesystem and reference them in the SKILL.md and it works great.",
          "score": 1,
          "created_utc": "2026-02-03 15:20:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eofke",
          "author": "Niightstalker",
          "text": "Here they wrote a blogpost about supporting skills within their deep agents cli: https://www.blog.langchain.com/using-skills-with-deep-agents/",
          "score": 1,
          "created_utc": "2026-02-03 20:39:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hmmrj",
          "author": "ohansemmanuel",
          "text": "Technically you could probably get by building a system around this yourself. \n\nYou'd need to connect to a VM / sandboxed machine at runtime, that's capable of running scripts, installin dependencies, leveraging bash for reading additional files etc. You'd then expose tools to interact with the said machine. \n\nYou alluded to the bigger issue in your comment - as an industry it seems we're mostly focused on Skills within CLI (coding agents) atm. But in my opinion, the bigger win comes from the use case you're describing i.e., remote agents running determinsitic workflows / SOPs with references and scripts. \n\nIf you're looking for an off the shelve solution, you may like Bluebag AI (handles all the hard stuff so you can integrate in 2-lines of code) \n\nDisclaimer: I built this and already used in production systems. Would happily walk you through it",
          "score": 1,
          "created_utc": "2026-02-04 06:52:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3c5nqq",
          "author": "Upset-Pop1136",
          "text": "langchain‚Äôs not trying to be a full agent OS. they optimize for demos and DX, not long-lived agents. ",
          "score": 0,
          "created_utc": "2026-02-03 13:23:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtw1wu",
      "title": "LangChain VS LamaIndex - Plug r/LangChain context into your LangChain agents - Free MCP integration",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qtw1wu/langchain_vs_lamaindex_plug_rlangchain_context/",
      "author": "jannemansonh",
      "created_utc": "2026-02-02 14:10:12",
      "score": 9,
      "num_comments": 3,
      "upvote_ratio": 0.91,
      "text": "Hey, creator of [needle.app](http://needle.app) here. This subreddit has incredible implementation knowledge - patterns, agent architectures, RAG configs, tool calling issues, what actually works in production.\n\nWe indexed all 2025 r/LangChain discussions and made them searchable. Even better: we built an MCP integration so you can plug this entire subreddit's context directly into your LangChain agents for agentic RAG.\n\nTry searching:\n\n* Tool calling with function schemas\n* Multi-agent orchestration patterns\n* Vector store performance comparisons\n\nUseful if you're:\n\n* Debugging agent loops or tool calling\n* Finding solutions others have already tested\n\n**Want to use this in your LangChain agents?** Check out our MCP integration guide: [https://docs.needle.app/docs/guides/mcp/needle-mcp-server/](https://docs.needle.app/docs/guides/mcp/needle-mcp-server/)\n\nNow you can build agents that query r/LangChain knowledge directly while reasoning.\n\nCompletely free, no signup: [https://needle.app/featured-collections/reddit-langchain-2025](https://needle.app/featured-collections/reddit-langchain-2025)\n\n[LangChain or LamaIndex - Needle.app RAG Chat](https://reddit.com/link/1qtw1wu/video/prkrlbzo93hg1/player)\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qtw1wu/langchain_vs_lamaindex_plug_rlangchain_context/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o35qt2s",
          "author": "beneautomas",
          "text": "Useful!",
          "score": 1,
          "created_utc": "2026-02-02 14:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35rfk4",
              "author": "jannemansonh",
              "text": "RAGception XD",
              "score": 1,
              "created_utc": "2026-02-02 14:26:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3729ap",
          "author": "PromptAndHope",
          "text": "Is this compatible with reddit policy ?",
          "score": 1,
          "created_utc": "2026-02-02 18:08:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsxuum",
      "title": "Is AsyncPostgresSaver actually production-ready in 2026? (Connection pooling & resilience issues)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qsxuum/is_asyncpostgressaver_actually_productionready_in/",
      "author": "FunEstablishment5942",
      "created_utc": "2026-02-01 13:00:46",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 0.91,
      "text": "Hey everyone,\n\nI'm finalizing the architecture for a production agent service and blocked on the database layer. I've seen multiple reports (and GitHub issues like #5675 and #1730) from late 2025 indicating that¬†`AsyncPostgresSaver`¬†is incredibly fragile when it comes to connection pooling.\n\nSpecifically, I'm concerned about:\n\n1. **Zero Resilience:**¬†If the underlying pool closes or a connection goes stale, the saver seems to just crash with¬†`PoolClosed`¬†or¬†`OperationalError`¬†rather than attempting a retry or refresh.\n2. **Lifecycle Management:**¬†Sharing a¬†`psycopg_pool`¬†between my application (SQLAlchemy) and LangGraph seems to result in race conditions where LangGraph holds onto references to dead pools.\n\n**My Question:**  \nHas anyone successfully deployed¬†`AsyncPostgresSaver`¬†in a high-load production environment recently (early 2026)? Did the team ever release a native fix for automatic retries/pool recovery, or are you all still writing custom wrappers / separate pool managers to baby the checkpointer?\n\nI'm trying to decide if I should risk using the standard saver or just bite the bullet and write a custom Redis/Postgres implementation from day one.\n\nThanks! Is AsyncPostgresSaver actually production-ready in 2026? (Connection pooling & resilience issues)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qsxuum/is_asyncpostgressaver_actually_productionready_in/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2zq0ut",
          "author": "papipapi419",
          "text": "!remindme 5 days",
          "score": 1,
          "created_utc": "2026-02-01 16:20:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zq60m",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 5 days on [**2026-02-06 16:20:31 UTC**](http://www.wolframalpha.com/input/?i=2026-02-06%2016:20:31%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LangChain/comments/1qsxuum/is_asyncpostgressaver_actually_productionready_in/o2zq0ut/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLangChain%2Fcomments%2F1qsxuum%2Fis_asyncpostgressaver_actually_productionready_in%2Fo2zq0ut%2F%5D%0A%0ARemindMe%21%202026-02-06%2016%3A20%3A31%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qsxuum)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-01 16:21:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o33q9hi",
          "author": "Shreyanak_exe",
          "text": "I really need an answer to this cause I am building stg similar that's going in production soon and I want to be sure the connection doesn't goes stale every now and then. \n\nBtw: some guy built a resilient wrapper for Postgres. If you can test and lmk if it's worth giving a shot, that'd be helpful\n\n[ResilientPostgresSaver](https://github.com/samirpatil2000/agentic-template/blob/main/agents/resilient_postgres_saver.py)",
          "score": 1,
          "created_utc": "2026-02-02 04:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35htt0",
          "author": "pbalIII",
          "text": "Same pattern plays out in every ORM/framework that wraps database connections... the abstraction handles the happy path but breaks when the connection layer misbehaves.\n\nFWIW issue #5675 is still open with no native fix. Most production deployments I've seen do one of two things:\n\n- Dedicated pool for LangGraph (don't share with SQLAlchemy)\n- Custom retry wrapper that catches PoolClosed/OperationalError and reconnects\n\nThe from_conn_string helper creates a single connection, not a pool. Under load that's asking for trouble. If you're already comfortable with psycopg, building your own thin wrapper around AsyncConnectionPool with health checks is probably less risky than hoping for an upstream fix.",
          "score": 1,
          "created_utc": "2026-02-02 13:33:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr6mii",
      "title": "Production AI Agent Patterns - Open-source guide with cost analysis and case studies",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qr6mii/production_ai_agent_patterns_opensource_guide/",
      "author": "Curious_Mirror2794",
      "created_utc": "2026-01-30 14:16:13",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.79,
      "text": "Hey r/LangChain,\n\n\n\nI've been building production AI agents for the past year and kept running into the same problems: unclear pattern selection, unexpected costs, and lack of production-focused examples.\n\n\n\nSo I documented everything I learned into a comprehensive guide and open-sourced it.\n\n\n\n\\*\\*What's inside:\\*\\*\n\n\n\n\\*\\*8 Core Patterns:\\*\\*\n\n\\- Tool calling, ReAct, Chain-of-Thought, Sequential chains, Parallel execution, Router agents, Hierarchical agents, Feedback loops\n\n\\- Each includes \"When to use\" AND \"When NOT to use\" sections (most docs skip the latter)\n\n\\- Real cost analysis for each pattern\n\n\n\n\\*\\*4 Real-World Case Studies:\\*\\*\n\n\\- Customer support agent (Router + Hierarchical): 73% cost reduction\n\n\\- Code review agent (Sequential + Feedback): 85% issue detection  \n\n\\- Research assistant (Hierarchical + Parallel): 90% time savings\n\n\\- Data analyst (Tool calling + CoT): SQL from natural language\n\n\n\nEach case study includes before/after metrics, architecture diagrams, and full implementation details.\n\n\n\n\\*\\*Production Engineering:\\*\\*\n\n\\- Memory architectures (short-term, long-term, hybrid)\n\n\\- Error handling (retries, circuit breakers, graceful degradation)\n\n\\- Cost optimization (went from $5K/month to $1.2K)\n\n\\- Security (prompt injection defense, PII protection)\n\n\\- Testing strategies (LLM-as-judge, regression testing)\n\n\n\n\\*\\*Framework Comparisons:\\*\\*\n\n\\- LangChain vs LlamaIndex vs Custom implementation\n\n\\- OpenAI Assistants vs Custom agents\n\n\\- Sync vs Async execution\n\n\n\n\\*\\*What makes it different:\\*\\*\n\n\\- Production code with error handling (not toy examples)\n\n\\- Honest tradeoff discussions\n\n\\- Real cost numbers ($$ per 10K requests)\n\n\\- Framework-agnostic patterns\n\n\\- 150+ code examples, 41+ diagrams\n\n\n\n\\*\\*Not included:\\*\\* Basic prompting tutorials, intro to LLMs\n\n\n\nThe repo is MIT licensed, contributions welcome.\n\n\n\n\\*\\*Questions I'm hoping to answer:\\*\\*\n\n1. What production challenges are you facing with LangChain agents?\n\n2. Which patterns have worked well for you?\n\n3. What topics should I cover in v1.1?\n\n\n\nLink: [https://github.com/devwithmohit/ai-agent-architecture-patterns](https://github.com/devwithmohit/ai-agent-architecture-patterns)\n\n\n\nHappy to discuss any of the patterns or case studies in detail.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qr6mii/production_ai_agent_patterns_opensource_guide/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o2naepr",
          "author": "Southern_Notice9262",
          "text": "I suspect I‚Äôm arguing about an LLM slop product here but I can‚Äôt leave this without a comment.\n\n03-comparisons/openai-assistants-vs-custom-agents.md:\nYou are still recommending Assistants API which is to be sunset in July 2026.\nThis says a lot about your expertise (lack thereof) to me.\n\n03-comparisons/langchain-vs-llamaindex-vs-custom.md:\nA nitpick: there are frameworks other than Langchain and LlamaIndex. Where is CrewAI, Vercel and Google AI SDKs (and probably dozens more I know nothing about)? I would assume they deserve at least to be named.\n\n02-production/observability.md:\nA nitpick: Where are Langfuse, Arize and other SPECIALIZED solutions that don‚Äôt require so much code and give much more in terms of observability?\n\n04-case-studies/code-review-agent.md:\nBefore I close this repo forever just wanted to make sure you ignore linting rules in your code. And you didn‚Äôt let me down, you ignore them alright! üòÅ\n\nPlease do better.",
          "score": 2,
          "created_utc": "2026-01-30 18:15:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qreln",
              "author": "Curious_Mirror2794",
              "text": "Thanks for taking the time to review the repo and provide feedback. I genuinely appreciate the specific callouts‚Äîthis is exactly the kind of detailed input that makes documentation better.\n\n**Re: OpenAI Assistants API sunset** You're absolutely right. I wasn't aware of the July 2026 deprecation timeline when I wrote this. I'll add a deprecation notice at the top of that comparison and update the guidance to reflect that this is historical context rather than a current recommendation.\n\n**Re: Missing frameworks (CrewAI, Vercel AI SDK, Google AI SDK)** Fair point. The comparison focused on the \"big two\" but you're right that the ecosystem has evolved significantly. I'll add a section covering CrewAI, Vercel AI SDK, Google AI SDK, and others in the framework comparison, even if just as a reference table with brief descriptions.\n\n**Re: Observability tools (Langfuse, Arize)** Valid criticism. I leaned too heavily on \"build it yourself\" examples when there are production-ready observability platforms designed specifically for LLM apps. I'll add a dedicated section on specialized observability solutions and reorganize the content to lead with these tools before diving into custom implementations.\n\n**Re: Linting in** [**code-review-agent.md**](http://code-review-agent.md) Ha! The irony isn't lost on me. You're right‚Äîthe code examples should follow the same standards the agent would enforce. I'll clean up the code samples to be properly linted.\n\nThese are all legitimate technical critiques, not nitpicks. I'll push updates addressing each point within the week. If you're willing to review again after the changes, I'd welcome it.\n\nCheers, Mohit",
              "score": 0,
              "created_utc": "2026-01-31 05:30:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1quni12",
      "title": "AI projects with Langchain and Langgraph",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1quni12/ai_projects_with_langchain_and_langgraph/",
      "author": "Affectionate_Bid2797",
      "created_utc": "2026-02-03 09:28:03",
      "score": 8,
      "num_comments": 6,
      "upvote_ratio": 0.79,
      "text": "Hello everyone,\n\nI hope you‚Äôre doing well. I‚Äôm a software engineer who‚Äôs really passionate about machine learning and AI, and I‚Äôd love to get some advice from engineers already working in the field.\n\nI‚Äôve studied the fundamentals and understand the theory and common frameworks, but I feel I need to build more concrete, real-world projects to gain confidence and practical experience.\n\nI‚Äôve gone through tutorials and done quite a bit of research, but much of the advice feels repetitive, and many project suggestions are the same everywhere. So I wanted to ask directly: what projects would you recommend building that are actually useful and help someone stand out?\n\nI‚Äôm not looking for generic or clich√© advice, but rather insights from people with hands-on experience in the industry.\n\nThanks a lot for your time.I really appreciate any suggestions.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1quni12/ai_projects_with_langchain_and_langgraph/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3bdrb1",
          "author": "Witty_System7237",
          "text": "What kind of domain are you most interested in-like data analysis, chat assistants, or something else? That could help narrow down useful project ideas.",
          "score": 1,
          "created_utc": "2026-02-03 09:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3be0jw",
              "author": "Affectionate_Bid2797",
              "text": "I am interested in building agentic workflows from end-to-end.   \nThank you!",
              "score": 1,
              "created_utc": "2026-02-03 09:46:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3boith",
                  "author": "Apart_Commercial2279",
                  "text": "the main issue if you want to face real world issue and not getting basic advice is to build a usefull agent for you, your friends family or coworker and make them use them (this is the hardest). If they don't use it, or use it the wrong way or if they don't get what they need you will iterate and make it more complex, fix bug, add retry, guardrails ect... And really have an end to end system",
                  "score": 0,
                  "created_utc": "2026-02-03 11:22:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c3nsh",
          "author": "Upset-Pop1136",
          "text": "Learn from the open source products and great tools. One of them is Dify",
          "score": 1,
          "created_utc": "2026-02-03 13:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gspuy",
          "author": "hrishikamath",
          "text": "Honesty just do projects you really care, where you care about the output and it‚Äôs challenging but it‚Äôs also reasonable. You will come across problems and then use whatever you learn to diagnose, you will learn better. I did that for finance and ended up learning a lot without taking tutorials or watching any courses. It‚Äôs open source happy to share the link/blogpost if you want.",
          "score": 1,
          "created_utc": "2026-02-04 03:19:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ifk6p",
          "author": "MathematicianTop1654",
          "text": "this tutorial might be useful: [https://www.crewship.dev/blog/deploy-langgraph-to-production](https://www.crewship.dev/blog/deploy-langgraph-to-production)",
          "score": 1,
          "created_utc": "2026-02-04 11:16:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvvnzd",
      "title": "Build a self-updating wiki from codebases (open source, Apache 2.0)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qvvnzd/build_a_selfupdating_wiki_from_codebases_open/",
      "author": "Whole-Assignment6240",
      "created_utc": "2026-02-04 17:57:34",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I recently have been working on¬†[a new project](https://github.com/cocoindex-io/cocoindex/tree/v1/examples/multi_codebase_summarization)¬†to build a self-updating wiki from codebases. I wrote a step-by-step tutorial.\n\nYour code is the source of truth, and documentations out of sync is such a common pain especially in larger teams. Someone refactors a module, and the wiki is already wrong. Nobody updates it until a new engineer asks a question about it.\n\nThis open source project scans your codebases, extracts structured information with LLMs, and generates Markdown documentation with Mermaid diagrams ‚Äî using CocoIndex + Instructor + Pydantic.\n\nWhat's cool about this example:\n\n‚Ä¢ ùêàùêßùêúùê´ùêûùê¶ùêûùêßùê≠ùêöùê• ùê©ùê´ùê®ùêúùêûùê¨ùê¨ùê¢ùêßùê† ‚Äî Only changed files get reprocessed. saving 90%+ of LLM cost and compute.\n\n‚Ä¢ ùêíùê≠ùê´ùêÆùêúùê≠ùêÆùê´ùêûùêù ùêûùê±ùê≠ùê´ùêöùêúùê≠ùê¢ùê®ùêß ùê∞ùê¢ùê≠ùê° ùêãùêãùêåùê¨ ‚Äî LLM returns real typed objects ‚Äî classes, functions, signatures, relationships.\n\n‚Ä¢ ùêÄùê¨ùê≤ùêßùêú ùêüùê¢ùê•ùêû ùê©ùê´ùê®ùêúùêûùê¨ùê¨ùê¢ùêßùê† ‚Äî All files in a project get extracted concurrently with asyncio.gather().\n\n‚Ä¢ ùêåùêûùê´ùê¶ùêöùê¢ùêù ùêùùê¢ùêöùê†ùê´ùêöùê¶ùê¨ ‚Äî Auto-generated pipeline visualizations showing how your functions connect across the project.\n\nThis pattern hooks naturally into PR flows ‚Äî run it on every merge and your docs stay current without anyone thinking about it. I think it would be cool next to build a coding agent with Langchain on top of this fresh knowledge. \n\nIf you want to explore the full example (fully open source, with code, APACHE 2.0), it's here:\n\nüëâ¬†[https://cocoindex.io/examples-v1/multi-codebase-summarization](https://cocoindex.io/examples-v1/multi-codebase-summarization)\n\nIf you find CocoIndex useful, a star on Github means a lot :)\n\n‚≠ê¬†[https://github.com/cocoindex-io/cocoindex](https://github.com/cocoindex-io/cocoindex)\n\ni'd love to learn from your feedback, thanks!",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qvvnzd/build_a_selfupdating_wiki_from_codebases_open/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qu1bqx",
      "title": "AI Agent to deal with enormous datasets",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qu1bqx/ai_agent_to_deal_with_enormous_datasets/",
      "author": "Abject_Reference_160",
      "created_utc": "2026-02-02 17:23:15",
      "score": 6,
      "num_comments": 18,
      "upvote_ratio": 1.0,
      "text": "I'm working on a system that implements an AI Agent that analyses the sales history and forecasts future demand.  \nIt is written in NestJS and uses langchain and langchain/openai. The agent is basically declared as follows:  \n  \nconstructor() {  \nthis.chatOpenAI = new ChatOpenAI({  \napiKey: process.env.OPENAI\\_API\\_KEY,  \nmodel: \"gpt-5-mini-2025-08-07\",  \nverbose: true  \n});  \n¬† }\n\n  \nSo, kinda basic. This is also the first time i'm implementing a complex system with onboard AI, so any tips would be welcome.\n\nThe problem is, i need my ai to be able to read enormous datasets at once, like a really big sales history (it is the biggest part), but I always hit limitations like text too big for sending in a request or it is way past the 128k token limit.  \nI tried using toon, but my agent got confused and returned nothing to an input that normally would generate data.\n\nRAG was an idea for saving tokens but, afaik, it shouldn't be used for calculations like this, but for textual understanding and searches.  \nProducing batch pre compiled analysis was also an option, but it would be really hard to preserve all the insights that are possible with the raw data.\n\nHow can i set it up to reading monstruous datasets like this?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qu1bqx/ai_agent_to_deal_with_enormous_datasets/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o3750v7",
          "author": "big_fart_9090",
          "text": "lol, edit: sorry now constructive. An LLM is the wrong tool for what you want to achieve mate. Try asking an LLM on how to do time series forecasting. It wil suggest various data science stuff. Good luck, you will need it",
          "score": 2,
          "created_utc": "2026-02-02 18:20:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o378je4",
              "author": "Abject_Reference_160",
              "text": "Thanks mate, guess i'll really need this luck lol.  \nI was having a talk with grok and it also came to the conclusion that a LLM is optimized more as a conversational thing, and it isn't the same tool used by scientists and such (I initially thought it was more of a setup difference or perfectly thought out strategies that i was also trying to come up with). I'll search more about it and come back with updates.",
              "score": 1,
              "created_utc": "2026-02-02 18:36:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3dsloi",
          "author": "Otherwise_Flan7339",
          "text": "You can't pass raw sales history directly to an LLM. It's not a database.  \n  \nFocus on \\*agent tooling\\*. Build tools that run SQL queries or Pandas operations on your dataset. The agent calls these tools based on the user's need.  \n  \nIt processes summarized data, not raw rows. We use this pattern for sales data too.",
          "score": 2,
          "created_utc": "2026-02-03 18:11:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36viux",
          "author": "Empty_Contact_2823",
          "text": "Do you need to ingest all of the historic data at once? Or find the relevant data first to operate on?\n\nTraditional Unix file system access using grep etc to pipe to llm can be a way to counter the token limit.\n\nAlso worth considering if you could filter the data via api calls / function calls within the llm first.",
          "score": 1,
          "created_utc": "2026-02-02 17:38:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36wwfx",
              "author": "Abject_Reference_160",
              "text": "Generally what I do is select the products I want to analyze and get its related data, such as inventories, purchase orders and sales orders.  \nTo ingest all the product's sales history would enable me to perceive patterns, such as which clients use to buy this product, when they buy it and what they get it with, and it would interact better with unstructured data like the info that a client is breaking the contract (how much do they represent for this product's demand and when?).\n\nIs this what you were referring to?",
              "score": 1,
              "created_utc": "2026-02-02 17:44:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o386zfl",
                  "author": "Wide_Brief3025",
                  "text": "It sounds like you're definitely on the right track by tying together sales history, inventory, and contract events for deeper insight. If you start pulling in conversational data or signals from platforms like Reddit or LinkedIn, something like ParseStream can automate tracking keywords and alert you to important discussions so you never miss relevant signals for your products.",
                  "score": 1,
                  "created_utc": "2026-02-02 21:17:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o36xjxb",
              "author": "Abject_Reference_160",
              "text": "i'd like to, for instance, get all the products of a supplier and analyze them at once, or at least several products. At the moment, even 1 product's history is too much, and some suppliers have far more demand than others, which means their products will have a sales history that is even bigger and technically harder to analyze.",
              "score": 1,
              "created_utc": "2026-02-02 17:47:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o383gg3",
                  "author": "snarfi",
                  "text": "You need to query your dataset via an api first to only return whats needed for the particular request.",
                  "score": 1,
                  "created_utc": "2026-02-02 21:01:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o378mit",
          "author": "Strong_Cherry6762",
          "text": "How large is your dataset? How many megabytes of memory does it occupy? How many rows of data records are there?",
          "score": 1,
          "created_utc": "2026-02-02 18:37:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37bese",
              "author": "Abject_Reference_160",
              "text": "I have nearly 5k products, that together have half a million sales orders. Each product has a inventory record for each deposit, and it must all be analysed together in order to suggest sales or transfers between deposits. It is a sales history from 2020 to current day, and it will continue growing, as the system will be used for several years to come.  \nThe model i'm using, gpt-5-mini-2025-08-07, appears to have a token limit of 128.000, and for some products, 1 month of its sales history is way more than enough to break this limit, so considering I need to look to 5 years and more as the time passes, it is kinda big (or at least it looks monstruous for my current setup to handle).\n\nWe are planning to grow a lot on the oncoming years, so more data will be generated on a shorter time.",
              "score": 1,
              "created_utc": "2026-02-02 18:49:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37fkhq",
                  "author": "Strong_Cherry6762",
                  "text": "Okay, that is absolutely huge for an LLM context window, but actually \"small data\" for a computer.\n\nIf I were you, I'd implement this using a CLI + skill approach‚Äîjust let the LLM write Python code directly in your terminal, and then use that code to handle the data processing tasks.\n\nOf course, if you do this kind of repetitive work often, I suggest using a \"skill-creator\" (Anthropic has a guide on this: https://resources.anthropic.com/hubfs/The-Complete-Guide-to-Building-Skill-for-Claude.pdf) to build a skill that solidifies your data processing workflow.\n\nGood luck with the build!",
                  "score": 2,
                  "created_utc": "2026-02-02 19:08:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37uxx9",
          "author": "InfraScaler",
          "text": "You need to give your agent tools to filter the data without having to read it first, e.g. ways to query the dataset.¬†",
          "score": 1,
          "created_utc": "2026-02-02 20:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c4enn",
              "author": "Abject_Reference_160",
              "text": "Is it somehow different to use tools and to send the same data in the prompt?",
              "score": 1,
              "created_utc": "2026-02-03 13:15:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3cnsdb",
                  "author": "InfraScaler",
                  "text": "It's about managing context bloat. Instead of letting the agent read all the data then filter, you tell the agent it can use tools (for the sake of argument: put it in a sqlite and query it using sql) to send queries and get subsets of the data already filtered.",
                  "score": 2,
                  "created_utc": "2026-02-03 15:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3nbueh",
          "author": "Potential-Analyst571",
          "text": "Don‚Äôt feed huge raw datasets to the agent.. Preaggregate and chunk the data first, then let the model reason on summaries instead of rows. Keeping that data flow clearly defined (tools like Traycer help) avoids token limits and confused agents.",
          "score": 1,
          "created_utc": "2026-02-05 02:32:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}