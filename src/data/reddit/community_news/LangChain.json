{
  "metadata": {
    "last_updated": "2026-01-27 16:59:04",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 48,
    "file_size_bytes": 91855
  },
  "items": [
    {
      "id": "1qmpjef",
      "title": "Do actual AI practitioners find the Clawdbot hype realistic?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qmpjef/do_actual_ai_practitioners_find_the_clawdbot_hype/",
      "author": "julsezerus",
      "created_utc": "2026-01-25 17:34:28",
      "score": 79,
      "num_comments": 35,
      "upvote_ratio": 0.94,
      "text": "I’m curious what people who actually work with AI think about the Clawdbot hype. \n\nHere’s my take:\n\nThe capabilities Clawdbot demonstrates aren’t particularly difficult to achieve technically - we can already make LLMs do most of what it’s doing. The real challenge has always been implementing proper security procedures and guardrails, not the core functionality itself.\n\nFrom what I can tell, Clawdbot is essentially burning through massive amounts of LLM tokens to accomplish certain tasks without much concern for security protocols. \n\nThat’s… not exactly groundbreaking? It’s more like “look what happens when you remove the safety rails and throw credits at it.”\n\nMaybe I’m missing something, but this doesn’t feel like the revolution people are making it out to be. It feels more like a demo of “what if we just didn’t worry about the hard parts?”\n\nWhat do people actually working in this space think? Am I being too cynical here, or is this hype as overblown as it seems?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmpjef/do_actual_ai_practitioners_find_the_clawdbot_hype/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1nm307",
          "author": "ImaginaryRea1ity",
          "text": "Saw the YT video of the guy hyping it up but I think all the marketing is paid.",
          "score": 13,
          "created_utc": "2026-01-25 17:43:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o94n7",
              "author": "gastro_psychic",
              "text": "Who is making money?",
              "score": 2,
              "created_utc": "2026-01-25 19:19:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p175w",
                  "author": "LiveBeyondNow",
                  "text": "The creator and the suppliers, Anthropic, YT etc",
                  "score": 2,
                  "created_utc": "2026-01-25 21:22:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1pl3v6",
          "author": "Hackerjurassicpark",
          "text": "More hype. Most likely paid marketing.",
          "score": 5,
          "created_utc": "2026-01-25 22:50:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qv0do",
              "author": "mediaempire45",
              "text": "Mranwhile the creator of the clawdbot is saying on X that nobody is checking out his \"sponsor\" link",
              "score": 2,
              "created_utc": "2026-01-26 02:35:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1rci5q",
                  "author": "Hackerjurassicpark",
                  "text": "They’re playing the long game… hyping up and creating massive visibility to add more users, the use those impressive user growth to justify a 1B valuation in their next seed round",
                  "score": 1,
                  "created_utc": "2026-01-26 04:13:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1r9f36",
          "author": "Proof-Sand-7157",
          "text": "What Clawdbot does is essentially the same as **Copilot/Cowork-style agents connected to channels like WhatsApp or Slack**.\n\nThere’s no particularly complex capability involved.  \nIt mainly feels impressive because **it’s open source**, so everything is visible and reproducible.",
          "score": 4,
          "created_utc": "2026-01-26 03:54:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wfsgw",
              "author": "laslog",
              "text": "And, unlike Copilot, it works.",
              "score": 2,
              "created_utc": "2026-01-26 21:48:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1r9wka",
          "author": "Zatkoma",
          "text": "Hype, let them some time to prove that is make sense... :)",
          "score": 2,
          "created_utc": "2026-01-26 03:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1tacxy",
          "author": "Educational_Bag_4003",
          "text": "Don't think the founder is out to make money. Look at all of his recent dev work and look at his background [https://github.com/steipete](https://github.com/steipete) Really don't think it is paid marketing pushing this...",
          "score": 2,
          "created_utc": "2026-01-26 13:19:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1vleje",
              "author": "auskadi",
              "text": "It's a great little tool. Lots of people here seem to be taking through their ...",
              "score": 2,
              "created_utc": "2026-01-26 19:34:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vxvzq",
          "author": "Significant-Sweet-53",
          "text": "https://preview.redd.it/tl5mnc7u6rfg1.jpeg?width=945&format=pjpg&auto=webp&s=eda45bcd2bf6a97b9844cee99223ccd2d2c9ce4b\n\nI just made a trimmed down version of this bot that uses Deepseek or Ollama, less noise and you can add your own skills easily, Ive added gog cli to test, controlling Google workspace from WhatsApp",
          "score": 2,
          "created_utc": "2026-01-26 20:29:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1w8mu9",
              "author": "Kubuli",
              "text": "Can you share your methods, results, limitations and suggestions?",
              "score": 1,
              "created_utc": "2026-01-26 21:17:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1w1j1w",
          "author": "Lonely-Elephant2130",
          "text": "Honestly spent an afternoon trying to set up ClawdBot and gave up - I'm not technical and the Mac Mini + local setup was way over my head. But I do love the idea of bringing AI into messaging apps. Been using something similar called Super Intern （https://www.superintern.ai/） lately - same concept of AI in your chat, but way simpler to get started. Just works in browser/Slack, no setup needed. Maybe I'm just not the target user for ClawdBot, but feels like there's a gap between \"impressive tech\" and \"actually usable for non-tech people.",
          "score": 1,
          "created_utc": "2026-01-26 20:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z6ksy",
          "author": "damanamathos",
          "text": "I created an AI Personal Assistant over Christmas and it's amazing — one of the best things I've created. I haven't used Clawdbot but have seen a bit, and did download the repo and get my AI PA to assess it vs what I already do, and it seemed pretty similar but probably a downgrade for me. So if you're not using any kind of AI assistant, it's probably worth checking out.",
          "score": 1,
          "created_utc": "2026-01-27 07:22:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1z6vji",
              "author": "damanamathos",
              "text": "I should add that my \"assistant\" isn't even that complicated. It's just Claude Code or OpenCode will a decent AGENTS file and specialised skills combined with custom-made CLI commands that let it access all my services so it can search and read email, create drafts, create images, etc from command line tools.",
              "score": 1,
              "created_utc": "2026-01-27 07:24:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o20t0q9",
          "author": "AccountEffective369",
          "text": "I haven't checked it out but that's why people are not looking to hire AI driven employees they still looking for individuals who knows processes comprehensively. Good Knowledge before trying the application itself.",
          "score": 1,
          "created_utc": "2026-01-27 14:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o4z7a",
          "author": "Not_a_doxxtor",
          "text": "We've had these Jarvis things for a while now\n\nSomeone paid for advertising",
          "score": 1,
          "created_utc": "2026-01-25 19:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1pb1md",
          "author": "cqzero",
          "text": "Does it even work on Windows? I saw just MacOS/iOS/Android. Not interested unless it's Windows (or even Linux)",
          "score": 1,
          "created_utc": "2026-01-25 22:05:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1sfm4t",
              "author": "4rtdud3",
              "text": "Just got it up and running under WSL (Ubuntu) on Win 11.",
              "score": 1,
              "created_utc": "2026-01-26 09:16:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1qezr6",
              "author": "almeidamarcell",
              "text": "are you 12?!",
              "score": -1,
              "created_utc": "2026-01-26 01:13:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1sfkan",
                  "author": "Sore6",
                  "text": "are you?",
                  "score": 0,
                  "created_utc": "2026-01-26 09:16:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1qnodi",
              "author": "PositiveShallot7191",
              "text": "lol its self hosted its not running on phones",
              "score": 0,
              "created_utc": "2026-01-26 01:58:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1uhk9w",
          "author": "Significant-Sweet-53",
          "text": "Paid-first assumptions",
          "score": 1,
          "created_utc": "2026-01-26 16:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nn0th",
          "author": "AykutSek",
          "text": "You’re not being cynical; you’re being realistic. Clawdbot feels like a high-speed car with no brakes. It’s exciting to watch until it hits a wall of security protocols or a massive API bill. The real breakthrough won't be 'doing things,' it will be doing things safely and efficiently within the chaos of real-world data.",
          "score": 0,
          "created_utc": "2026-01-25 17:47:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nndhy",
          "author": "Resident_Green8814",
          "text": "Spot on. From a GTM and product perspective, the 'revolution' here isn't technical brilliance, but the removal of friction by ignoring guardrails. Scaling an AI agent in an enterprise environment requires solving the 'hard parts' you mentioned: security, token efficiency, and reliability. Clawdbot is a great demo of potential, but a nightmare for risk management. We need sustainable innovation, not just credit-burning experiments.",
          "score": 0,
          "created_utc": "2026-01-25 17:49:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qmhxxi",
      "title": "Quantifying Hallucinations: By calculating a multi-dimensional 'Trust Score' for LLM outputs.",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qmhxxi",
      "author": "Charming_Group_2950",
      "created_utc": "2026-01-25 12:33:20",
      "score": 20,
      "num_comments": 0,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/LangChain/comments/1qmhxxi/quantifying_hallucinations_by_calculating_a/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qk2cv0",
      "title": "Could this architectural shift finally solve the \"Agent Reliability\" problem?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "author": "sophieximc",
      "created_utc": "2026-01-22 18:24:39",
      "score": 17,
      "num_comments": 7,
      "upvote_ratio": 0.84,
      "text": "As LangChain devs, we spend half our time writing OutputParsers, retry logic, and guardrails because LLMs are fundamentally probabilistic - they don't \"know\" they broke a constraint, they just guessed a token.\n\nI’ve been reading up on the new wave of [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models) (backed by LeCun), and the implication for Agents is huge.\n\nUnlike Transformers that generate text left-to-right (and often paint themselves into a corner), an EBM minimizes an \"energy function\" at inference time. It basically verifies if the output meets the constraints (like \"Must be valid JSON\" or \"Must not contradict previous step\") before returning the result.\n\nIf this works at scale, we might finally get agents that can handle complex multi-step logic without needing a dozen error-handling loops.\n\nCurious if anyone sees this replacing the current RAG/Chain-of-Thought meta for strict logic tasks?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o13k2t9",
          "author": "Better_Dress_8508",
          "text": "I'm afraid you are extrapolating too far. EBM-s are not deterministic either",
          "score": 2,
          "created_utc": "2026-01-22 19:06:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13olgo",
              "author": "sophieximc",
              "text": "They are still probabilistic - you're sampling from a distribution, not running a script.  \n  \nBut the inference dynamic is different. Instead of just rolling the dice once per token (autoregressive), you're iteratively refining the output to lower the energy. It’s less about being deterministic and more about having a native mechanism to \"reject\" nonsense before finalizing the output.",
              "score": 0,
              "created_utc": "2026-01-22 19:26:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o14a1vs",
          "author": "met0xff",
          "text": "You can use constrained generation using something like xgrammar or outlines for the json problem",
          "score": 1,
          "created_utc": "2026-01-22 21:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15hrda",
          "author": "USToffee",
          "text": "It's how I'm writing my agent. It basically has a semantic binding step at the start that determines what kind of artifacts it expects and only gives an answer if the tool calls satisfy this. At this point I'm not sure if it's any better or not. It still requires the LLM to guess what artifacts are needed from the prompt.",
          "score": 1,
          "created_utc": "2026-01-23 00:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bhy3m",
          "author": "pbalIII",
          "text": "So the real question is whether the inference-time optimization loop scales without blowing up latency. Logical Intelligence just announced Kona 1.0 with LeCun on the board, and their pitch is exactly this... learning by correcting mistakes rather than guessing tokens.\n\nThe catch is EBTs need to be trained from scratch. You can't fine-tune an existing foundation model into one. That's a brutal cold start when every team already has GPT-4 wrappers in production.\n\nFor strict JSON, constrained decoding (xgrammar, outlines) already solves it deterministically without the architecture swap. The interesting unlock would be multi-step logical consistency across tool calls, where autoregressive models keep painting themselves into corners. Still waiting to see benchmarks on that before swapping out the retry loops.",
          "score": 1,
          "created_utc": "2026-01-23 22:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13hgo0",
          "author": "Educational-Bison786",
          "text": "EBMs are definitely an interesting shift for agent reliability. While they might reduce some issues, I doubt they'll fully replace the need for robust evaluation and guardrails. You'll still want tools like Pydantic for strict schema validation. For comprehensive agent quality and measuring improvements, platforms like [Maxim AI](https://www.getmaxim.ai/) are crucial. Also don't forget solid prompt engineering.",
          "score": 0,
          "created_utc": "2026-01-22 18:54:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13od1f",
              "author": "sophieximc",
              "text": "Agreed, validation (like Pydantic) isn't going anywhere. But right now, we use guardrails to catch errors after they happen (and then trigger expensive retries). The promise of EBMs is that the model wouldn't generate the error in the first place because it contradicts the \"energy\" state. I want validation to be a safety net, not the main control loop",
              "score": 1,
              "created_utc": "2026-01-22 19:25:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qji1cc",
      "title": "LangChain + OpenWork + Docling + Milvus Holy Grail Setup",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qji1cc/langchain_openwork_docling_milvus_holy_grail_setup/",
      "author": "Clay_Ferguson",
      "created_utc": "2026-01-22 02:21:45",
      "score": 15,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "Hi guys. I was wondering if anyone knows of an open source project that incorporates the following technologies into a single RAG solution that people can just simply install and run. What I'm referring to here is a kind of \"Chat with your Documents\" type feature, where you scan a bunch of documents and then you can have a conversation with an AI about the documents (basic RAG).\n\n\n\n>\\* Openwork (LangChain Chat System, with Electron GUI Front end)\n\n>\\* Docling for Doc loading\n\n>\\* Milvus Vector DB  \n\n\n\n\nThis seems to be the holy grail that everyone is currently building right now (RAG systems), and I don't know if there's a popular project yet that incorporates all of the above into a single system people can just run without having to put together all the components themselves. When Openwork was recently released, that gets us 90% of the way to the finish line, but we just need a project that adds Docling and Milvus to finish it. It might be good to have a Docker Compose-base solution to this since there's several independent technologies that we're putting together.\n\n\n\nAny thoughts or ideas anyone has are greatly appreciate it. Thanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qji1cc/langchain_openwork_docling_milvus_holy_grail_setup/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0zfbhc",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 3,
          "created_utc": "2026-01-22 03:32:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zr28x",
              "author": "Clay_Ferguson",
              "text": "Not Strapi tho, but Openwork.",
              "score": 1,
              "created_utc": "2026-01-22 04:47:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjm96c",
      "title": "Multi-agents breakthrough",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "author": "crionuke",
      "created_utc": "2026-01-22 05:41:20",
      "score": 15,
      "num_comments": 11,
      "upvote_ratio": 0.81,
      "text": "ChatGPT and similar models have become universal tools, which is why they so quickly entered the daily lives of millions of people. We use them to search for information, work with text, learn new topics, and hold discussions.  \n  \nHowever, chats themselves are not agents. They cannot operate in the real or digital world: they do not make decisions, execute chains of tasks, interact with services, or carry work through to completion.  \n  \nFor this reason, companies have begun building their own agent and multi-agent systems. These systems help users apply for loans, buy tickets, plan vacations, or complete paperwork.  \n  \nBut almost all such solutions remain narrowly specialized. Each agent is tightly bound to predefined scenarios and cannot go beyond the logic embedded by its creators.  \n  \nBecause of this, the next major technological breakthrough will likely be the emergence of universal agent systems accessible to ordinary users.  \n  \nExternally, they may look almost the same: a familiar chat interface with a bot. Internally, however, they will represent complex self-organizing systems composed of many agents, capable of understanding user goals, autonomously building plans, selecting tools, and adapting to changing conditions.  \n  \nIn essence, this marks a transition from “answering prompts” to digital assistants that can act — and may even possess their own form of intent within the boundaries of achieving the user’s goals, rather than merely reacting to commands.  \n  \nGiven the current pace of development in large language models and agent frameworks, it is entirely possible that the first truly universal multi-agent systems will appear by the end of 2026.\n\n  \n**What are your thoughts on the next breakthrough in our field?**",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o103070",
          "author": "ChanceKale7861",
          "text": "Yep! I’m about to go FOSS with a 20 agent system of rust and python agents so we power users aren’t bound to API bullshit.",
          "score": 3,
          "created_utc": "2026-01-22 06:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10vgpt",
              "author": "crionuke",
              "text": "Interesting,\n\nis there anything you can share that we can already play with?",
              "score": 2,
              "created_utc": "2026-01-22 10:32:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12akg1",
                  "author": "ChanceKale7861",
                  "text": "I actually just finished that up yesterday, and myself along with 10-15 folks across business, SWE, enterprise architecture, etc. lots of folks I know have been working on projects, so, rolling to them first, and then if they are happy with where it’s at, I’m going to launch the website, and the tool. so, yes, but maybe in a week or two? need to ensure the things like file intake and generation work as designed, as well as whether the aspects like security and auditor agents orchestrate as designed and tested so far. Or like, for the folks I know in like recruiting, or sales, does it truly automate an aspects for them, like it has me. Which is where this stemmed from a couple weeks back.",
                  "score": 2,
                  "created_utc": "2026-01-22 15:42:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11a1mg",
          "author": "Number4extraDip",
          "text": "You misunderstand agents and infrastructure. There is no such thing as disembodied ai. Agents have specific architecture and defining components.\n\nYou wanna ground ai? Ground them in realtime data and telemetry\n\n[all ai is robotics](https://youtube.com/shorts/wTY2mY3XF1Y?si=QpiqBlUIK3WqNzNu)\n\nAnd multi agent systems are not complex if you think about it\n\n[heres a plug and play one copy pasta](https://github.com/vNeeL-code/ASI)",
          "score": 3,
          "created_utc": "2026-01-22 12:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10vs73",
          "author": "fabkosta",
          "text": "All of this is not new, the fantasies about such systems have been there 25 years ago. Just go pick up any book or article on muli-agent-systems from the early 2000s. What has changed today that, suddenly and miraculously, such systems can become true, although they could not 25 years ago? LLMs? GenAI? That's not enough, a lot more is required - and we did not solve the issues 25 years ago with other technology neither.\n\nIt's wild to see that nobody seems to want to learn anything from history.",
          "score": 2,
          "created_utc": "2026-01-22 10:35:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13h9cw",
          "author": "Aggressive_Bed7113",
          "text": "This post can be much shorter with only the last paragraph or last sentence.\n\nThis title made me think op will present some real breakthroughs, but it turns out the person has no idea either. Duh\n\nWhy do I want a universal agent that does mediocre stuffs in everything than a specialized agent in things I only care about?!",
          "score": 1,
          "created_utc": "2026-01-22 18:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13hrlg",
              "author": "crionuke",
              "text": "Nobody has",
              "score": 1,
              "created_utc": "2026-01-22 18:55:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o13i4l5",
                  "author": "Aggressive_Bed7113",
                  "text": "Then what’s the point of posting this?",
                  "score": 1,
                  "created_utc": "2026-01-22 18:57:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ahysn",
          "author": "LairBob",
          "text": "This is just ill-informed rambling.",
          "score": 1,
          "created_utc": "2026-01-23 19:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10u9do",
          "author": "PopPsychological4106",
          "text": "Wdym by \"truly universal\"?",
          "score": 0,
          "created_utc": "2026-01-22 10:21:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10v7xi",
              "author": "crionuke",
              "text": "I don’t have a one word term for this, but imagine systems capable of generating agent skills on the fly to handle a user request, even if those skills don’t exist beforehand, and refining them through a trial-and-error loop: develop → test → improve → … → use for the user’s task.",
              "score": 1,
              "created_utc": "2026-01-22 10:30:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qj9qms",
      "title": "Solved rate limiting on our agent workflow with multi-provider load balancing",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "author": "llamacoded",
      "created_utc": "2026-01-21 20:46:50",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "We run a codebase analysis agent that takes about 5 minutes per request. When we scaled to multiple concurrent users, we kept hitting rate limits; even the paid tiers from DeepInfra, Cerebras, and Google throttled us too hard. Queue got completely congested.\n\nTried Vercel AI Gateway thinking the endpoint pooling would help, but still broke down after \\~5 concurrent users. The issue was we were still hitting individual provider rate limits.\n\nTo tackle this we deployed an LLM gateway (Bifrost) that automatically load balances across multiple API keys and providers. When one key hits its limit, traffic routes to the others. We set it up with a few OpenAI and Anthropic keys.\n\nIntegration was just changing the base\\_url in our OpenAI SDK call. Took maybe 15-20 min total.\n\nNow we're handling 30+ concurrent users without throttling. No manual key rotation logic, no queue congestion.\n\nGithub if anyone needs: [https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0xn3ti",
          "author": "Mishuri",
          "text": "Or just use open router?",
          "score": 2,
          "created_utc": "2026-01-21 21:46:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xcho0",
          "author": "DanceWithEverything",
          "text": "Can I use a Claude max sub to oauth myself a token?",
          "score": 1,
          "created_utc": "2026-01-21 20:57:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk85pb",
      "title": "I built a system for generating and operating modular AI-enabled FastAPI apps after doing this for clients over and over",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qk85pb",
      "author": "Challseus",
      "created_utc": "2026-01-22 21:59:02",
      "score": 12,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk85pb/i_built_a_system_for_generating_and_operating/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1ql3ufd",
      "title": "Langchain In production",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "author": "niklbj",
      "created_utc": "2026-01-23 21:39:55",
      "score": 12,
      "num_comments": 28,
      "upvote_ratio": 0.88,
      "text": "HI guys, i've realized a lot of us are using langchain or building agents in some of personal or official projects that are in prod. Wanted to start a discord server specific for those of us who are building AI and agent applications in prod to talk about any issues, suggestions, or advice.\n\nHere's the server: [https://discord.gg/qJVQgX2z](https://discord.gg/qJVQgX2z). Feel free to join!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1bh85l",
          "author": "HawkingsLovechild",
          "text": "Langchain is neither lightweight nor mature enough to be dependable in production in my experience. Works fine for POCs but I would reject any PR that attempts to add it to our stack.\n\nEdit: I just checked and installing langchain installed 32 packages, taking 20mb.\n\n  \nEdit2: OP has had half a dozen posts removed in the last month for spam promoting some B2B saas LLM nonsense across various subreddits . Go build a product people actually wanna use bro.",
          "score": 10,
          "created_utc": "2026-01-23 22:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1biayp",
              "author": "AdditionalWeb107",
              "text": "I am generally framework-averse. The tight coupling, lack of interoperability between other frameworks, and no clear separation of concerns makes we very weary. For example, I am not sure why I am left to my own devices to solve all the plumbing work vs. it being implemented via some standards-based infrastructure.\n\nEdit; Talking about decoupling and separating plumbing from business logic https://github.com/katanemo/plano",
              "score": 4,
              "created_utc": "2026-01-23 22:05:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bp64c",
                  "author": "HawkingsLovechild",
                  "text": "I don't think Langchain is a dead project or anything, I love the enthusiasm. But I wouldn't have used FFMPEG in 2004. Nor would I trust this open source project at this point in its lifecycle, especially when the core - the web APIs it basically wraps, could and do change on a dime.\n\n  \nNone of this applies if you're building personal projects, but if you have thousands of users paying you money, it's a different story.",
                  "score": 3,
                  "created_utc": "2026-01-23 22:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bi6hj",
              "author": "niklbj",
              "text": "Interesting, i've seen a ton of startups especially in the earlier days - series A and before building agents using langchain but that makes sense. What framework do you guys use?\n\nRegardless, just updated server to be framework agnostic! It's now just about building and scaling agents in production",
              "score": 2,
              "created_utc": "2026-01-23 22:05:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bjxcz",
                  "author": "HawkingsLovechild",
                  "text": "I am in a startup myself as the tech lead. We don't need LLM frameworks. We write code that calls the APIs. They already did the hard work. Everything Langchain does you can do yourself in a hilariously short amount of time, with more control, tailored to your business needs. \n\n  \nI don't mean to sound like a dick but I genuinely have no idea what Langchain is solving for people. What problem does your company have that you determined it was easier to use Langchain for?",
                  "score": 4,
                  "created_utc": "2026-01-23 22:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1fjbnf",
              "author": "pizzababa21",
              "text": "I dont understand why 20mb is a problem",
              "score": 2,
              "created_utc": "2026-01-24 14:36:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d7btv",
              "author": "cuba_guy",
              "text": "Pretty tight ship over there, our nodejs monorepo has 8gb of node_modules and goes to prod multiple times a day :)",
              "score": 1,
              "created_utc": "2026-01-24 03:44:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1imizm",
              "author": "BurritoBashr",
              "text": "my company uses LangChain/Graph in production with LangSmith. It's a popular artisan shopping site",
              "score": 1,
              "created_utc": "2026-01-24 23:12:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1opbut",
              "author": "cmndr_spanky",
              "text": "Report him then",
              "score": 1,
              "created_utc": "2026-01-25 20:31:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bi7ze",
              "author": "usernotfoundo",
              "text": "What's the alternative to it? Is it not dependable because further updates could lead to currently implemented features being deprecated?",
              "score": 1,
              "created_utc": "2026-01-23 22:05:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bj5bo",
                  "author": "HawkingsLovechild",
                  "text": "Using the API provided by the LLM developers and writing your own wrapping code around it. It's not particularly difficult - I maintain such a system for my company and it's a single python library with the SDKs in question and the requests library. I also get greater control and can respond to updates to say, openAI the day they're rolled out rather than waiting. \n\n  \nWhat features does langchain provide you that you can't write yourself? It's not a particularly complicated package.",
                  "score": 6,
                  "created_utc": "2026-01-23 22:09:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1dbiyl",
          "author": "code_vlogger2003",
          "text": "Hey hi guys,  i already shipped the react style multi agents in the production using the langchain and it's currently serving in the production. Ok high level the end product of the pipeline is a detailed report which contains text, images and tables etc based on unstructured raw time series data. For the control and monitoring I have debugged their call backs and written detailed functions for precise calculation that match with manual calculation. This monitoring helps us to understand the costs of the api and believe me that on average for one detailed report it takes around 0.15 $ which the report includes the multi model calls too.",
          "score": 2,
          "created_utc": "2026-01-24 04:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bdiv6",
          "author": "AdditionalWeb107",
          "text": "This is cool - shouldn't the Langchain guys host and moderate this type of discord themselves?",
          "score": 1,
          "created_utc": "2026-01-23 21:43:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bh18a",
              "author": "mdrxy",
              "text": "We have a community slack! https://www.langchain.com/join-community",
              "score": 3,
              "created_utc": "2026-01-23 21:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bi7fy",
                  "author": "niklbj",
                  "text": "that's sick!",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bdv1e",
              "author": "niklbj",
              "text": "totally open to them doing so if anybody from Langchain wants to help moderate it! didn't see something like this out there, so thought I'd create one and handle it for now",
              "score": 2,
              "created_utc": "2026-01-23 21:44:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bevvc",
                  "author": "AdditionalWeb107",
                  "text": "I use stock python - so this wouldn't be a great fit for me personally, but I see the value. Thanks for creating it OP",
                  "score": 2,
                  "created_utc": "2026-01-23 21:49:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1uiews",
          "author": "pbalIII",
          "text": "Timing matters more than framework choice here. The 45% never-make-it-to-production stat floating around matches what I've seen... teams build POCs with LangChain, then strip it out when the 32-package dependency graph starts slowing deploys and the abstractions get in the way of a custom memory or retry pattern.\n\nThe counter-argument is observability. LangSmith alone is worth more than person-months of custom tracing work, and switching LLM providers with a one-line change saves real time during vendor negotiations.\n\nMy heuristic: if you're calling one model with a straightforward RAG pipeline, raw SDK wins. If you're juggling 3+ providers, need async multi-agent coordination, or want prod tracing out of the box, LangChain still earns its keep. The middle ground is messy.",
          "score": 1,
          "created_utc": "2026-01-26 16:48:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bj5i5",
          "author": "peejay2",
          "text": "I fw agno",
          "score": 0,
          "created_utc": "2026-01-23 22:09:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnqln9",
      "title": "A practical open-source repo for learning AI agents",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qnqln9/a_practical_opensource_repo_for_learning_ai_agents/",
      "author": "Creepy-Row970",
      "created_utc": "2026-01-26 19:43:49",
      "score": 11,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "A practical open-source repo for learning AI agents. I’ve contributed 10+ examples\n\nI’ve contributed 10+ agent examples to an open-source repo that’s grown into a solid reference for building AI agents.\n\nRepo:[ https://github.com/Arindam200/awesome-ai-apps](https://github.com/Arindam200/awesome-ai-apps)\n\nWhat makes it useful:\n\n* 70+ runnable agent projects, not toy demos\n* Same ideas built across different frameworks\n* Covers starter agents, MCP, memory, RAG, and multi-stage workflows\n\nFrameworks include LangChain, LangGraph, LlamaIndex, CrewAI, Agno, Google ADK, OpenAI Agents SDK, AWS Strands, and PydanticAI.\n\nSharing in case others here prefer learning agents by reading real code instead of theory.\n\n",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qnqln9/a_practical_opensource_repo_for_learning_ai_agents/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1vok23",
          "author": "Pristine_Shelter_28",
          "text": "are these live apps?",
          "score": 1,
          "created_utc": "2026-01-26 19:48:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qna46j",
      "title": "Best practice for managing LangGraph Postgres checkpoints for short-term memory in production?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/",
      "author": "Major_Ad7865",
      "created_utc": "2026-01-26 08:05:35",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "’m building a memory system for a chatbot using **LangGraph**.  \nRight now I’m focusing on **short-term memory**, backed by **PostgresSaver**.\n\nEvery state transition is stored in the `checkpoints` table. As expected, each user interaction (graph invocation / LLM call) creates multiple checkpoints, so the checkpoint data in checkpoints table grows **linearly with usage**.\n\nIn a production setup, what’s the recommended strategy for managing this growth?\n\nSpecifically:\n\n* Is it best practice to **keep only the last N checkpoints per** thread\\_id  and delete older ones?\n* How do people balance **resume/recovery safety** vs **database growth** at scale?\n\nFor context:\n\n* I already use conversation summarization, so older messages aren’t required for context\n* Checkpoints are mainly needed for short-term recovery and state continuity, not long-term memory\n* LangGraph can **resume from the last checkpoint**\n\nCurious how others handle this in real production systems.\n\nAdditionally in postgres langgraph creates 4 tables regarding checkpoints : checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1v6nu7",
          "author": "TextHour2838",
          "text": "You’re already thinking about this the right way: treat checkpoints as operational logs, not permanent memory, and prune aggressively.\n\n\n\nMain point: keep only a small, rolling window per thread (last N or last T minutes/hours) and purge the rest with a background job.\n\n\n\nWhat’s worked for us:\n\n\\- Per-thread policy: e.g., keep last 10–20 checkpoints or last 24h, whichever is smaller.\n\n\\- Time-based GC: daily job that deletes old checkpoints/checkpoint\\_writes/checkpoint\\_blobs by thread\\_id + created\\_at, in batches to avoid locks.\n\n\\- Promotion: anything you might need long-term (audit, analytics, durable memory) gets promoted into a separate, slimmer schema / vector store before you delete.\n\n\\- Safety: pair this with idempotent tools and a compensating-action log so you can replay from business events if a resume fails, not from ancient checkpoints.\n\n\n\nOn the tooling side, I’ve mixed Supabase and RDS for this, and for chatbots in ecom I’ve tried Gorgias and Intercom; Zipchat sits in that space too but handles the short-term vs long-term memory split for you so you don’t babysit raw checkpoint tables.\n\n\n\nSo: rolling window + periodic GC + promote anything important out of the checkpoint tables before pruning.",
          "score": 1,
          "created_utc": "2026-01-26 18:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1uya4l",
          "author": "AdditionalWeb107",
          "text": "This should be native to some substrate via durable APIs. Doing this by hand feels like a great way to mess it  up and also distract you from building your agent.",
          "score": 0,
          "created_utc": "2026-01-26 17:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql1m38",
      "title": "Open Source Serverless RAG Pipeline (Lambda + Bedrock) with React Component",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "author": "HatmanStack",
      "created_utc": "2026-01-23 20:14:08",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I built a fully serverless RAG pipeline to avoid idle server costs and container management.\n\nRepo: [https://github.com/HatmanStack/RAGStack-Lambda](https://github.com/HatmanStack/RAGStack-Lambda)\n\nDemo: [https://dhrmkxyt1t9pb.cloudfront.net](https://dhrmkxyt1t9pb.cloudfront.net)\n\n(Login: [guest@hatstack.fun](mailto:guest@hatstack.fun) / Guest@123)\n\nBlog: [https://portfolio.hatstack.fun/read/post/RAGStack-Lambda](https://portfolio.hatstack.fun/read/post/RAGStack-Lambda)\n\nKey Features:\n\n* Frontend: Drop-in <ragstack-chat> web component (React 19).\n* Multimodal: Uses Amazon Nova to embed text, images, and videos.\n* Zero Idle Costs: Pure Lambda/Step Functions/DynamoDB architecture.\n* MCP Support: Connects directly to Claude Desktop and Cursor.\n* No Control Plane: All resources deployed in your AWS Account.\n\nDeployment is one-click via CloudFormation. Feedback welcome.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkknp3",
      "title": "what are some suggestions you have on minimizing silent failures with langchain?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkknp3/what_are_some_suggestions_you_have_on_minimizing/",
      "author": "niklbj",
      "created_utc": "2026-01-23 07:41:22",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "sometimes our agents in prod seem to take some, for a lack of better terms, *interesting* decisions and then other times its a couple bad responses that causes a constant back and forth with users until it eventually gets to the right response. but usually our users don't report it because they're not outright failures and sometimes they go under the radar. \n\ndo you guys do something right now, any flows to best handle these situations? My assumption is it just about continuously tuning the prompts and then adaptign the code. Thinking of setting up observability as well!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkknp3/what_are_some_suggestions_you_have_on_minimizing/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o17aqw7",
          "author": "saurabhjain1592",
          "text": "What you’re describing is a classic “soft failure” pattern. Nothing crashes, but behavior degrades in ways users don’t explicitly report.\n\nIn our experience, prompt tuning alone rarely fixes this once agents are in prod. The issue is usually that the system treats all deviations as recoverable retries, so you get loops, drift, and slow convergence instead of clear failures.\n\nA few things that have helped teams reduce silent failures:\n- Make retries explicit and bounded. If an agent retries automatically without knowing why the previous step failed, you’re just amplifying noise.\n- Log decisions, not just inputs and outputs. When something feels “off” later, you want to know why a step was allowed to proceed.\n- Introduce step-level invariants. For example, “this tool call should only happen if X and Y are true,” rather than letting the model decide implicitly.\n- Treat back-and-forth with users as a signal. Repeated clarification loops are often silent failures in disguise.\n\n\nObservability helps, but only if it’s tied to execution state and decisions, not just traces. Otherwise you can see what happened without understanding why.\n\nCurious where you’re seeing the most drift today: tool selection, retries, or state/context getting lost across turns?",
          "score": 2,
          "created_utc": "2026-01-23 07:56:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1az9vz",
          "author": "Disastrous_Fox_3069",
          "text": "I've found this to be helpful for evaluating context of full conversation - https://docs.langchain.com/langsmith/online-evaluations-multi-turn. My best guess though is that there may be too much context/not enough instruction for the agent. Perhaps too many tools. What model are you using?",
          "score": 1,
          "created_utc": "2026-01-23 20:36:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bjx6e",
          "author": "pbalIII",
          "text": "Soft failures are the hardest to catch because your system looks healthy while making bad decisions.\n\nTwo patterns that helped us: step-level invariants (tool X only fires if conditions Y and Z are true, enforced in code) and treating repeated clarification loops as a signal worth logging.\n\nObservability helps, but the gap is usually prompt-completion linkage. You can see what happened without understanding why. LangSmith traces get you part of the way, but you still need to instrument decision points, not just inputs and outputs.",
          "score": 1,
          "created_utc": "2026-01-23 22:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1kd7ez",
          "author": "Revolutionary-Bet-58",
          "text": "I can highly recommend using an agent scanner prior to deployment for finding silent failures such as infinite loops, bad RCE, etc..",
          "score": 1,
          "created_utc": "2026-01-25 05:02:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj1r2z",
      "title": "Added Git-like versioning to LangChain agent contexts (open source)",
      "subreddit": "LangChain",
      "url": "https://github.com/ultracontext/ultracontext-node",
      "author": "Main_Payment_6430",
      "created_utc": "2026-01-21 15:59:44",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj1r2z/added_gitlike_versioning_to_langchain_agent/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qkyu82",
      "title": "New! ampersend added as an official LangChain integration",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "author": "kevinjonescreates",
      "created_utc": "2026-01-23 18:32:11",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.82,
      "text": "Hey everyone - ampersend just got added to the official LangChain integration docs.\n\nIf you're building agents that need to call external services or other agents, this lets them handle payments autonomously. When a remote agent requires payment, ampersend negotiates and executes the payment automatically via x402.\n\nSetup is straightforward - configure your wallet and treasurer, and your LangChain agent can discover remote agent capabilities, send messages, and pay for services without manual intervention. You set spend limits and policies upfront.\n\nUseful if you're building agents that need to:\n\n* Call paid APIs or data services\n* Use other specialized agents (research, analysis, etc)\n* Operate autonomously without constant human approval\n\nDocs:[ https://docs.langchain.com/oss/python/integrations/tools/ampersend](https://docs.langchain.com/oss/python/integrations/tools/ampersend)\n\nHappy to answer questions about the x402 integration or agent-to-agent payments.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkyu82/new_ampersend_added_as_an_official_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ab13a",
          "author": "Mammoth-Nectarine513",
          "text": "Hi , I want to use agent for payment. Do you think i can integrate? What are the pros and cons? \n\nMaybe we can discuss in dm?",
          "score": 1,
          "created_utc": "2026-01-23 18:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b4k3n",
              "author": "kevinjonescreates",
              "text": "Yes it would work great for payments. Using ampersend you can build buyer agents easily, with spending limits [https://docs.ampersend.ai/](https://docs.ampersend.ai/)\n\nHappy to help you if you need dm me!",
              "score": 1,
              "created_utc": "2026-01-23 21:01:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qkswe0",
      "title": "How to deploy a LangGraph server on Heroku",
      "subreddit": "LangChain",
      "url": "https://substack.com/home/post/p-184868546",
      "author": "AlexRenz",
      "created_utc": "2026-01-23 14:53:57",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qkswe0/how_to_deploy_a_langgraph_server_on_heroku/",
      "domain": "substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1cbm6u",
          "author": "shifra-dev",
          "text": "Awesome work on this!\n\nSharing a resource for deploying LangGraph on Render as well in case that's helpful for folks: [https://www.youtube.com/watch?v=Gq3CPLOGHPw](https://www.youtube.com/watch?v=Gq3CPLOGHPw)",
          "score": 2,
          "created_utc": "2026-01-24 00:39:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1f2nxi",
              "author": "AlexRenz",
              "text": "Nice, this is a great video 💪",
              "score": 1,
              "created_utc": "2026-01-24 12:56:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qinxsi",
      "title": "Advanced AI Program which also covers Langchain",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "author": "soundboardwithme",
      "created_utc": "2026-01-21 04:18:38",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "Hello Folks,\n\nI am not sure if this is the right sub, please be kind towards me if this is not the right sub.\n\nI have been really unwell and having health complications, due to which I am unable to continue my enrollment for an Advanced AI program. It's duration is 3 month and the investment is $ 700 \n\nI am in Eastern Standard Time ( EST ) and this program happens every weekend 11 AM To 2 PM IST, which is during midnight hours for me.\n\nIf I attend these LIVE sessions during midnight EST, I will increase the risk of cardio vascular disease, and I might fall dead because of my health situation. It's an intensive program, with clear learning outcomes.\n\nI tried to get a refund for this enrollment, but they would not agree to it, inspite of my risky health situation. All they could offer is swap my enrollment if I manage to find a person to join this program.\n\nThis is a sincere request and I apologize if I am posting in the wrong sub.\n\nAlso, I am not trying to promote this program in any way but I know that it's a good program for those who want to learn Agentic AI and build products.\n\nIf anyone is interested to learn and ready to take a look, I will be happy to ping you the details for consideration and help me swap the enrollment.\n\nHonestly, I am broke and my health situation is bad.\n\nAll I am trying to do is,heal and survive for the next few months.\n\nI have to prioritize my heath and my career goals have changed.\n\nAnd I only have a few months of savings left.\n\nPlease, this is a request to help me in any way possible.\n\nI was very hesistant to seek here for help.\n\nBecause of my health situation my plans have changed.\n\nHappy to DM you the details.\n\nIt's only one Spot.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qm2lrs",
      "title": "Unable to distinguish between reasoning text and final response in streaming mode with tool calls",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "author": "Dragonfruit-Eastern",
      "created_utc": "2026-01-24 23:32:33",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "When streaming messages from Claude (Anthropic models) in LangGraph, the model sometimes includes explanatory text before making tool calls (e.g., \"I'll get the weather information for both New York and San Francisco for you.\").\n\nThe problem is that these text chunks arrive before the tool\\_use content blocks, making it impossible to determine whether the streaming text is:\n\n1. Preliminary reasoning/thoughts that precede a tool call, or\n2. The actual final response to the user\n\nThis creates a challenge for UI rendering, as we cannot know whether to display the text immediately or wait to see if a tool call follows.\n\n**Expected Behavior:**\n\nEither:\n\n* Provide a way to identify which text chunks are associated with tool calls versus final responses during streaming, or\n* Offer a configuration option to disable these preliminary text chunks entirely when tools are being used, so only the tool calls and final responses are streamed\n\n**Current Workaround:**\n\nCurrently, we must wait until the complete message is received to determine the message type, which defeats the purpose of streaming for real-time UI updates.\n\n**Script**\n\n    from langchain_openai import ChatOpenAI\n    from langgraph.graph import StateGraph, add_messages\n    from langchain.tools import tool\n    from langchain_anthropic import ChatAnthropic\n    from typing import TypedDict, Annotated\n    \n    \n    class State(TypedDict):\n        messages: Annotated[list, add_messages]\n    \n    \n    # Create a simple tool\n    @tool\n    def get_weather(city: str) -> str:\n        \n    \"\"\"Get weather information for a city.\"\"\"\n        \n    weather_data = {\"New York\": \"Rainy, 65°F\", \"San Francisco\": \"Sunny, 70°F\", \"London\": \"Cloudy, 55°F\"}\n        return weather_data.get(city, f\"Weather data not available for {city}\")\n    \n    \n    from langgraph.prebuilt import ToolNode\n    \n    tools = [get_weather]\n    tool_node = ToolNode(tools)\n    \n    \n    # LLM node that can call tools\n    def llm_node(state: State):\n        llm = ChatAnthropic(\n            model=\"claude-sonnet-4-5-20250929\",\n            api_key=\"key\",\n        llm_with_tools = llm.bind_tools(tools)\n    \n        response = llm_with_tools.invoke(state[\"messages\"])\n        return {\"messages\": [response]}\n    \n    \n    # Build the graph\n    graph = StateGraph(State)\n    graph.add_node(\"llm\", llm_node)\n    graph.add_node(\"tools\", tool_node)\n    \n    \n    # Route: if the LLM calls a tool, go to tools node, otherwise end\n    def should_use_tools(state: State):\n        last_message = state[\"messages\"][-1]\n        # Check if the last message has tool calls\n        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n            return \"tools\"\n        return \"end\"\n    \n    \n    graph.set_entry_point(\"llm\")\n    graph.add_conditional_edges(\"llm\", should_use_tools, {\"tools\": \"tools\", \"end\": \"__end__\"})\n    graph.add_edge(\"tools\", \"llm\")  # After tools run, return to LLM\n    \n    compiled_graph = graph.compile()\n    \n    \n    if __name__ == \"__main__\":\n        # Stream and print all messages\n        from langchain.messages import HumanMessage\n    \n        initial_state = {\"messages\": [HumanMessage(content=\"What's the weather in New York and San Francisco?\")]}\n    \n        print(\"Streaming updates:\")\n        for event, type in compiled_graph.stream(initial_state, stream_mode=\"messages\"):\n            print(f\"{dict(event)}\")\n\nOutput\n\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': \"I'll get\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' the weather information for both New York and', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' San Francisco for you.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'input': {}, 'name': 'get_weather', 'type': 'tool_use', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': 'get_weather', 'args': {}, 'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': 'get_weather', 'args': '', 'id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '{\"city\"', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '{\"city\"', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': ': \"New Yor', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': ': \"New Yor', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': ': \"New Yor', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'k\"}', 'type': 'input_json_delta', 'index': 1}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'k\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'k\"}', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'input': {}, 'name': 'get_weather', 'type': 'tool_use', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': 'get_weather', 'args': {}, 'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': 'get_weather', 'args': '', 'id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '{\"', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '{\"', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'city\": ', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'city\": ', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'city\": ', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': '\"San F', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': '\"San F', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': '\"San F', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [{'partial_json': 'rancisco\"}', 'type': 'input_json_delta', 'index': 2}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [{'name': None, 'args': 'rancisco\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}], 'usage_metadata': None, 'tool_call_chunks': [{'name': None, 'args': 'rancisco\"}', 'id': None, 'index': 2, 'type': 'tool_call_chunk'}], 'chunk_position': None}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'tool_use', 'stop_sequence': None, 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-b80f-7a52-9447-9d18bb12c548', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 568, 'output_tokens': 108, 'total_tokens': 676, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, 'tool_call_chunks': [], 'chunk_position': 'last'}\n    {'content': 'Rainy, 65°F', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'get_weather', 'id': '92288d1a-8262-42d3-90eb-38d68206c0f7', 'tool_call_id': 'toolu_01Sz73zV5mpd4zrdThssKvnY', 'artifact': None, 'status': 'success'}\n    {'content': 'Sunny, 70°F', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'get_weather', 'id': 'c53f55a1-fc34-4b81-b8f3-59212983719f', 'tool_call_id': 'toolu_01Y8UrYNCRhYkiq9yubs1Ms7', 'artifact': None, 'status': 'success'}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': \"Here's the current\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' weather:', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': '\\n\\n-', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' **New York**: Rainy,', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' 65°F\\n- **San', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': ' Francisco**: Sunny, 70°', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [{'text': 'F', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None, 'tool_call_chunks': [], 'chunk_position': None}\n    {'content': [], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None, 'model_provider': 'anthropic'}, 'type': 'AIMessageChunk', 'name': None, 'id': 'lc_run--019bf1d8-bea8-76d3-bcb4-1985351168a8', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 754, 'output_tokens': 36, 'total_tokens': 790, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}, ' tool_call_chunks': [], 'chunk_position': 'last'}",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qm2lrs/unable_to_distinguish_between_reasoning_text_and/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1ja45b",
          "author": "TwistCrafty7858",
          "text": "which version of langchain are you using ? your code is not displaying the stream mode but i guess the stream mode « messages » allows you to get only llm output without any AIMessage tool call etc .",
          "score": 2,
          "created_utc": "2026-01-25 01:16:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1jfkdw",
          "author": "iso_what_you_did",
          "text": "This isn't a bug - it's how autoregressive models work.\n\n**The problem:** Claude generates text token-by-token. When it outputs \"I'll get the weather...\", it hasn't generated the tool call yet. The model doesn't know what's coming next - it's predicting one token at a time.\n\n**You're asking:** \"Can you label this text as 'preliminary' before the model decides to call a tool?\"\n\n**That's impossible.** The model hasn't made that decision yet when the text streams out.\n\n**Your actual solution is already in the output:**\n\n    python'stop_reason': 'tool_use'  # vs 'end_turn'\n\nWhen streaming completes, check the stop\\_reason. That tells you if tools were called.\n\n**Real options:**\n\n1. Buffer the stream until complete, then decide how to render\n2. Show the preliminary text (it's actually good UX - users see the model \"thinking\")\n3. Accept that streaming + tool calls means some uncertainty until completion",
          "score": 2,
          "created_utc": "2026-01-25 01:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1jmywj",
              "author": "Dragonfruit-Eastern",
              "text": "Thanks for your detailed answer. I use exactly the second option. I pretend it’s the main response until I get a tool use flag for that message id. But not sure about this is the best for UI. Because for example when I use Claude Sonnet in Pycharm Github Copilot extension, It can separate thinking/tool using explanations while it’s streaming on UI. Maybe they use another abstraction or algorithm to distinguish. That’s why I thought there might be a way.",
              "score": 1,
              "created_utc": "2026-01-25 02:27:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1kpbi4",
          "author": "Over_Krook",
          "text": "You pasted your hardcoded api key…",
          "score": 2,
          "created_utc": "2026-01-25 06:27:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iv0if",
          "author": "AdditionalWeb107",
          "text": "Please don't use LangcChain for this - just simply call the model APIs or use a passthrough proxy that gives you a unified API.   You don't want to be bound to a framework here, you want to be bound to an API. And I am not sure why you are using LangGraph for this use case of too calls?\n\nUse LangChain for modelling your business objects, not LLM calls.",
          "score": -2,
          "created_utc": "2026-01-24 23:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1j7ogg",
              "author": "Dragonfruit-Eastern",
              "text": "I get what you're saying, but my app supports multiple LLM providers (OpenAI, Gemini, Anthropic, etc.). Isn't that literally the point of LangChain - to abstract away the different APIs?\n\nI'm just using basic stuff: tool calling and streaming. Not doing anything complex with LangGraph, just the standard tool flow.\n\nIf I call each API directly, I'd have to write the same logic 3+ times for each provider. That's exactly what the framework is supposed to solve, no?",
              "score": 5,
              "created_utc": "2026-01-25 01:02:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1j873w",
                  "author": "AdditionalWeb107",
                  "text": "no you wouldn't you need to use a high-performance, high-throughput proxy that allows you write code ergonomically using any popular client (Anthropic, OpenAI) and common APIs (like v1/chat/completions or v1/messages. You could review liteLLM or [Plano](https://github.com/katanemo/plano). There are other options out there for the same use case.",
                  "score": 1,
                  "created_utc": "2026-01-25 01:05:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qjwa56",
      "title": "Most agents forget their purpose after a few runs. I built a way for them to \"learn\" from attacks (99.6% defense rate).",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjwa56/most_agents_forget_their_purpose_after_a_few_runs/",
      "author": "forevergeeks",
      "created_utc": "2026-01-22 14:41:31",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "Hi LangChainers,\n\nI’ve been working on a problem that most standard agent frameworks (like LangChain or AutoGen) struggle with: long-term consistency or what the industry calls \"statelessness.\"\n\nMost agents reset their \"alignment\" with every new session. If a user jailbreaks them once, the agent doesn't learn to be more defensive next time. It makes the same mistake twice.\n\nThe Solution: **Stateful Alignment Tracking** I built an open-source framework called **SAFi (Self-Alignment Framework Interface)**. The core innovation is a module that tracks the agent's coherence, detects drift, and provides live feedback to the model when it is going off-track.\n\n**The Stress Test** To test the system, I recently ran a public jailbreak challenge here on Reddit. I used a \"Socratic Tutor\" agent and challenged users to make it give direct answers or forget its purpose as a science/math tutor.\n\n* **Total Attacks:** 845\n* **Successful Jailbreaks:** 2\n* **Defense Rate:** 99.6%\n\nThe two \"successful\" jailbreaks were actually \"refusal answers\" for example, the agent said: *\"I won't tell you the answer to 2+2=4 because I want you to think!\"*\n\n**The Code** SAFi is 100% open source. You can find the repo, benchmarks, and raw logs here: **Repo:**[https://github.com/jnamaya/SAFi](https://github.com/jnamaya/SAFi)\n\nI'm looking for feedback from the builder community, especially on how you're handling stateful governance in your own agent stacks.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjwa56/most_agents_forget_their_purpose_after_a_few_runs/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qn6ydn",
      "title": "I built langgraph2slack - connect any LangGraph agent to Slack in 3 lines of code",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qn6ydn/i_built_langgraph2slack_connect_any_langgraph/",
      "author": "syasini",
      "created_utc": "2026-01-26 05:12:19",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "Hey everyone! I've been working on an open-source package called `langgraph2slack` that makes it super easy to deploy your **LangGraph** agents to **Slack**.\n\nHere's how you can set it up:\n\n    from langgraph2slack import SlackBot\n    bot = SlackBot()\n    app = bot.app\n\nThen add it to your langgraph.json:\n\n    {\n      \"dependencies\": [\"langgraph2slack\", \".\"],\n      \"graphs\": {\n        \"my-assistant\": \"./agent.py:app\"\n      },\n      \"http\": {\n        \"/events/slack\": \"slack/server:app\"\n      }\n    }\n\nThat's it!\n\nThen run `langgraph dev`, point your Slack app's event URL to it (ngrok works great for local testing), and you're done.\n\nhttps://reddit.com/link/1qn6ydn/video/pn3bxqh5mmfg1/player\n\n**The library currently handles**:\n\n* Real-time streaming responses (uses Slack's streaming API so users see tokens as they come in)\n* Thread management (conversation history is preserved)\n* Works with DMs and mentions in channels/threads\n* Optional feedback buttons that integrate directly with LangSmith\n* Input/output transformers if you need to customize messages before/after they hit your agent\n* Markdown to Slack formatting conversion\n* Image extraction from markdown responses\n\n**Why I built this:**\n\nNow that we're all building chatbots and agentic applications, one of the biggest challenges is getting them in front of users in a way that actually gets adopted. Most enterprise teams already live in Slack. So instead of asking people to context-switch to a separate web app, it makes sense to bring your agent to where they already are.\n\nThis was inspired by the `langgraph-messaging-integrations` repo which was a great reference, but I wanted something I could just pip install and have running in minutes without a ton of setup.\n\nLinks:\n\n* GitHub: [https://github.com/syasini/langgraph2slack](https://github.com/syasini/langgraph2slack)\n* PyPI: `pip install langgraph2slack`\n\nIt's MIT licensed, and I'd love for folks to try it out. If you end up using it or have ideas for improvements, let me know!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qn6ydn/i_built_langgraph2slack_connect_any_langgraph/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qo6uax",
      "title": "What It Actually Takes to Build a Context-Aware Multi-Agent AI System",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qo6uax/what_it_actually_takes_to_build_a_contextaware/",
      "author": "pretty_prit",
      "created_utc": "2026-01-27 07:05:33",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "Designing a multi-agent system with memory raises a different set of problems than most demos show.  \n  \nThe diagram below shows a simple multi-agent architecture I built to explore that gap.  \n  \nInstead of agents talking to each other directly, everything goes through an orchestration layer that handles:  \n\\-intent routing  \n\\-shared user context  \n\\-memory retrieval and compaction  \n  \nWhile designing this, a set of product questions surfaced that you don’t see in most demos  \n\\-What belongs in long-term memory vs. short-term history?  \n\\-When do you summarize context, and what do you risk losing?  \n\\-How do you keep multiple agents consistent as context evolves?  \n  \nI wrote a detailed breakdown of this architecture, including routing strategy, memory design, and the trade-offs this approach introduces.  \n  \n[https://medium.com/towards-artificial-intelligence/how-i-built-a-context-aware-multi-agent-wellness-system-a3eacbc33fe4?sk=c37c88e2f74aa9e5c2b2d681292d26c2](https://medium.com/towards-artificial-intelligence/how-i-built-a-context-aware-multi-agent-wellness-system-a3eacbc33fe4?sk=c37c88e2f74aa9e5c2b2d681292d26c2)  \n  \nIf you’re a PM, founder, or student trying to move beyond one-off agent demos, this might be useful.\n\nhttps://preview.redd.it/mr1w53kmcufg1.png?width=1838&format=png&auto=webp&s=e36245c419d44c006fdd8e3ff006c060eb320489\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qo6uax/what_it_actually_takes_to_build_a_contextaware/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1zgezp",
          "author": "DaRandomStoner",
          "text": "This looks pretty well put together... Is there a github repo we could check out?",
          "score": 1,
          "created_utc": "2026-01-27 08:51:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1zusom",
              "author": "pretty_prit",
              "text": "Thank you. the github link is there at the end of the article but posting here again - [https://github.com/pritha21/llm\\_projects/tree/main/wellness\\_langchain\\_app](https://github.com/pritha21/llm_projects/tree/main/wellness_langchain_app)",
              "score": 1,
              "created_utc": "2026-01-27 11:01:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1zmbdv",
          "author": "sleepnow",
          "text": "Good effort, but there is nothing at all new or particularly unique about this approach. ",
          "score": 1,
          "created_utc": "2026-01-27 09:46:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20aayx",
              "author": "pretty_prit",
              "text": "Maybe. But I was just exploring this topic, so its new for me.",
              "score": 1,
              "created_utc": "2026-01-27 12:55:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}