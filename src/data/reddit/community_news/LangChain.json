{
  "metadata": {
    "last_updated": "2026-01-24 08:42:05",
    "time_filter": "week",
    "subreddit": "LangChain",
    "total_items": 20,
    "total_comments": 52,
    "file_size_bytes": 90693
  },
  "items": [
    {
      "id": "1qfkeuf",
      "title": "We tested Vector RAG on a real production codebase (~1,300 files), and it didn‚Äôt work",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfkeuf/we_tested_vector_rag_on_a_real_production/",
      "author": "Julianna_Faddy",
      "created_utc": "2026-01-17 18:12:58",
      "score": 57,
      "num_comments": 35,
      "upvote_ratio": 0.86,
      "text": "Vector RAG has become the default pattern for coding agents: embed the code, store it in a vector DB, retrieve top-k chunks that it feels obvious to do so.\n\nWe tested this on a real production codebase (\\~1,300 files) and it mostly‚Ä¶ didn‚Äôt work.\n\nThe issue isn‚Äôt embeddings or models but we realized that **similarity is a bad proxy for relevance in code**.\n\nIn practice, vector RAG kept pulling:\n\n* test files instead of implementations\n* deprecated backups alongside the current code\n* unrelated files that just happened to share keywords\n\nSo the agent‚Äôs context window filled up with noise and reasoning got worse.\n\nhttps://preview.redd.it/39j5yotaaydg1.png?width=1430&format=png&auto=webp&s=7fd32a52a167a6b6f16e565874a2c5baab4ddc93\n\nWe compared this against an **agentic search approach using context tree** (structured, intent-aware navigation instead of similarity search). We won‚Äôt dump all the numbers here, but a few highlights:\n\n* **Orders of magnitude fewer tokens per query**\n* **Much higher precision on ‚Äúwhere is X implemented?‚Äù questions**\n* **More consistent answers for refactors and feature changes**\n\nVector RAG did slightly better on recall in some cases, but that mostly came from dumping more files into context, which turned out to be actively harmful for reasoning.\n\nThe takeaway for me:\n\nCode isn‚Äôt documentation but it's a graph with structure, boundaries, and dependencies. If being treated like a bag of words, it will break down fast once the repo gets large.\n\nI wrote a [detailed breakdown](https://www.byterover.dev/blog/why-vector-rag-fails-for-code-we-tested-it-on-1-300-files) of the experiment, failure modes, and why context trees work better for code (with full setup in this [repo ](https://github.com/RyanNg1403/agentic-search-vs-rag)and metrics) here if you want the full take.\n\nLet me know if you've found better approach",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfkeuf/we_tested_vector_rag_on_a_real_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o05cnsy",
          "author": "Disneyskidney",
          "text": "Interesting! Though I feel like the like the industry standard for RAG on a codebase has now become grep and other terminal commands. Would like to see it benchmarked against that, or see how they can work in tandem.",
          "score": 12,
          "created_utc": "2026-01-17 18:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05mce6",
              "author": "Challseus",
              "text": "I think that's the key. Combinations of semantic search/hybrid RAG, along with how agents build up context with grep/cat.",
              "score": 6,
              "created_utc": "2026-01-17 19:14:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o16v6ac",
              "author": "Julianna_Faddy",
              "text": "Yeah, that‚Äôs a fair take. Grep/ripgrep is still the real baseline for code, and we saw humans using it outperform vector RAG pretty consistently.\n\nWe don‚Äôt see this as replacing grep though. The win was using structure to decide *where* to search first, then letting grep do its thing inside that smaller slice. If you can‚Äôt beat ‚Äúsmart grep + intuition,‚Äù you‚Äôre probably not helping much anyway.",
              "score": 1,
              "created_utc": "2026-01-23 05:47:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o05kd0n",
          "author": "OnyxProyectoUno",
          "text": "Yeah this matches what I've seen. Vector similarity works when semantic proximity actually means relevance, which it does for docs but not for code.\n\nThe test file problem is brutal. Tests and implementations share so much vocabulary that embeddings can't distinguish them. Same with deprecated code sitting next to current versions. Structurally they're different, semantically they're nearly identical.\n\nYour context tree approach makes sense because code has explicit structure that embeddings throw away. Import graphs, call hierarchies, module boundaries. All that gets flattened into a vector.\n\nOne thing I'd add: the preprocessing step matters more than people realize. How you chunk code affects what gets retrieved. Function-level chunks vs file-level vs arbitrary token windows all produce different failure modes. I've been building [VectorFlow](https://vectorflow.dev/?utm_source=redditCP_i) to make that visible, being able to see what your chunks actually look like before embedding catches a lot of issues early.\n\nFor hybrid approaches, have you tried combining your tree navigation with vector search for specific cases? Like using structure for \"where is X implemented\" but falling back to similarity for \"find similar patterns to this function\"? Curious if there's a sweet spot.",
          "score": 7,
          "created_utc": "2026-01-17 19:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16vlbh",
              "author": "Julianna_Faddy",
              "text": "Yep, fully agree. Tests vs impls and deprecated code were exactly the cases that broke vector similarity for us. Semantics look the same, structure is totally different, and embeddings just miss that.\n\nOn hybrid approaches: yes, that‚Äôs where we landed. Use structure first to answer ‚Äúwhere do I look,‚Äù then optionally use similarity inside that scope for things like ‚Äúfind similar patterns.‚Äù Also +1 on chunking. Bad chunks will sink retrieval before it even starts.",
              "score": 1,
              "created_utc": "2026-01-23 05:50:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o05pwgl",
          "author": "lundrog",
          "text": "What I am currently using and made\n\nhttps://preview.redd.it/5vdslgfjoydg1.jpeg?width=2816&format=pjpg&auto=webp&s=9180d887ade94e5a92554342f734ec0be67a200d",
          "score": 3,
          "created_utc": "2026-01-17 19:31:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0aywxz",
              "author": "ExtentHot9139",
              "text": "Mmmh bloated no ?",
              "score": 2,
              "created_utc": "2026-01-18 15:33:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b29gt",
                  "author": "Crafty_Disk_7026",
                  "text": "ExtremelyZ. I garantee just running Claude in your codebase will give you better results than this mondtrosity",
                  "score": 3,
                  "created_utc": "2026-01-18 15:49:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06gven",
          "author": "kpgalligan",
          "text": "> Vector RAG has become the default pattern for coding agents\n\nHas it? I've been building a focused agent and haven't even touched it. Everything I've seen in the past year+ was \"don't use RAG\". The agents tend to find what they need directly. At least that's been my experience. If I wanted to do something like this, I'd probably start a distinct conversation, use RAG to potentially highlight some hits, have a model review the results and pull out what the original model actually wanted. Keeps the noise out of the main context.\n\nIn our case, the agent just uses a combination of file search tools. Not that I'd be opposed to trying something else, but RAG just seemed like it wouldn't do a whole lot better.\n\nWe have a similar solution for searching and grabbing web content. Some agents do a \"web fetch\" that grabs a URL, pushes it through a markdown converter, then returns the content. That can fill up the context with useless info. Instead, we have a \"research\" tool that takes a detailed description of what the LLM wants, does a web search and content download, then extracts what the model is actually looking for in a concise \"report\".",
          "score": 3,
          "created_utc": "2026-01-17 21:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16vs22",
              "author": "Julianna_Faddy",
              "text": "Fair pushback. ‚ÄúDefault‚Äù might be overstating it, but it‚Äôs definitely the most common *off-the-shelf* pattern people reach for when building coding agents, especially in frameworks and blog posts. Plenty of teams, like yours, skip it entirely and do just fine with direct file search.\n\nWhat you‚Äôre describing is basically the same principle we‚Äôre pushing. Keep noisy retrieval out of the main context, use tools to narrow and filter, and only pass back a distilled result. Dumping raw chunks, whether from code or the web, rarely helps compared to scoped or agent-driven search.",
              "score": 1,
              "created_utc": "2026-01-23 05:51:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o198968",
                  "author": "kpgalligan",
                  "text": "> but it‚Äôs definitely the most common off-the-shelf pattern people reach for when building coding agents, especially in frameworks and blog posts\n\nI think it *was*. I don't think it *is*. That's kind of what I was getting at. Through my work and research, I'd say very few coding agents do this today. Not saying you can't or shouldn't, but few do.\n\nResearch (from Claude, so check sources of course): https://gist.github.com/kpgalligan/bc9b9dd5cbbfd7a911fab644e63d12e6\n\nI tried pasting the whole thing, but Reddit said no. Anyway...\n\nWe used Roo as our agent engine for most of last year, before moving to LangChain/Graph. Roo does support that kind of indexing, but you need to enable it, and it's been in sort of an \"experimental limbo\" for a while. We never touched it.\n\nTo be fair, we use the Swift and Kotlin compiler tooling, rather than tree-sitter, for not just \"good\" structural understanding. Precise structural understanding. RAG would be completely pointless for our use case. But, it would be difficult to argue, based on current trends and evidence, that it is even a common approach at this point.",
                  "score": 1,
                  "created_utc": "2026-01-23 15:48:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06d9wc",
          "author": "CriticalBandicoot27",
          "text": "Firstly very insightful! I also had similar findings. For the code part i feel like the MIT rlm research paper seems promising to tackle the codebase problem. I am yet to implement it to see the actual results, but I feel like using chunks as a variable to test the actual relevance might fix most of these issues.",
          "score": 2,
          "created_utc": "2026-01-17 21:29:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o096xer",
          "author": "ClinchySphincter",
          "text": "is this an ad?",
          "score": 2,
          "created_utc": "2026-01-18 07:31:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a0ght",
              "author": "Glad-Champion5767",
              "text": "I've seen this exact post 1:1 a week ago or so. I thought i was getting a dejavu. Its definitely a bot post atleast, with some bot replies.",
              "score": 1,
              "created_utc": "2026-01-18 12:00:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09kten",
          "author": "WarlaxZ",
          "text": "If you want to solve this problem for code, you need to think like an ide. They didn't build up knowledge base of code, they added 'find references' and auto complete method name to existing ones, and automatic import etc. Refactoring and moving methods with a single click and pointing at a file. Solve these things and it will work better and more efficiently, as we've already been here many moons ago. I made a simple refactor mcp that accepted method name and method above and below to allow methods to be moved around files easily without needing to rewrite 3/4 of the file as a diff to great results, and there's so many things we already solved with ide's that have yet to be implemented for the new ai coding tools",
          "score": 2,
          "created_utc": "2026-01-18 09:38:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16w8ce",
              "author": "Julianna_Faddy",
              "text": "Totally agree. IDEs work because they lean on structure, not stored ‚Äúknowledge.‚Äù Things like find-refs, symbol resolution, imports, and refactors all come from having a real model of the code, not from similarity search.\n\nThat MCP refactor example is exactly the point. Small, precise, structure-aware ops beat dumping big diffs or context every time. There‚Äôs a lot of solved IDE tech that AI tools should just reuse instead of reinventing via embeddings.",
              "score": 1,
              "created_utc": "2026-01-23 05:55:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o18zb0w",
                  "author": "WarlaxZ",
                  "text": "for reference dumped it on github if anyone wants to use:\n\n[https://github.com/CodePulseHQ/llm-ide](https://github.com/CodePulseHQ/llm-ide)",
                  "score": 1,
                  "created_utc": "2026-01-23 15:06:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06s2rm",
          "author": "BeerBatteredHemroids",
          "text": "I've built a production vector rag application on over twice that amount of documents and it works just fine. You can't just slap a chatbot on a vector store and expect it to work out of the box. \n\nYou need smart prompting, reranking, good chunking strategy and a quality embedding model. Also, you should probably use a hybrid search combining similarity and keyword search.\n\nBasically, you need to be smarter than the tools you're working with boo",
          "score": 2,
          "created_utc": "2026-01-17 22:43:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wbx1",
              "author": "Julianna_Faddy",
              "text": "Yeah, that‚Äôs fair. We‚Äôre not saying vector RAG *can‚Äôt* work at all, just that the naive ‚Äúembed everything + top-k‚Äù setup breaks down fast for code if you‚Äôre not very deliberate.\n\nEven with good chunking, reranking, hybrids, etc., we still found similarity to be a weak signal for a lot of code questions compared to structure. If you invest heavily, you can make it usable. Our point was more that code pushes you toward IDE-like, structure-first approaches sooner than docs do. Different problem shape, different defaults.",
              "score": 1,
              "created_utc": "2026-01-23 05:55:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09c93h",
          "author": "-Cubie-",
          "text": "Honestly, I don't really buy it. Your big \"gain\" is 130x less token use. Now tell me: how would a different retrieval approach yield so much less tokens? You could, after all, have both approaches return the same number of documents. That would help make it a fair comparison.\n\nBut you don't do that.\n\nI think you spent much more time on optimizing your (presumably paid) product that you're advertising here and purposefully created a poor baseline so your product looks better.",
          "score": 1,
          "created_utc": "2026-01-18 08:19:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wfla",
              "author": "Julianna_Faddy",
              "text": "Fair point. The token gap wasn‚Äôt from us inflating vector RAG on purpose. Similarity search needed a much higher k to hit acceptable recall on code, while the structure-first approach could narrow to a small slice quickly.\n\nWe could force both to return the same number of files, but then vector RAG just missed more often. That said, the baseline criticism is fair and we should be clearer and more apples-to-apples in future benchmarks.",
              "score": 2,
              "created_utc": "2026-01-23 05:56:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0apoca",
          "author": "_thedeveloper",
          "text": "Interesting findings.\n\nFrom my experience, pure semantic similarity is almost guaranteed to fail at this scale. You really need a hybrid approach that combines metadata (paths, ownership, recency, file type, dependencies) with semantic signals to get anything reliable for code.\n\nPreprocessing also matters a lot here. Blind chunking or fixed-length chunks tend to bloat context and amplify noise, especially in large repos. Without structure-aware chunking, retrieval quality degrades quickly.\n\nAST-based approaches help, but they‚Äôre not sufficient on their own. Code understanding is repo-specific ‚Äî effective chunking and retrieval usually need to align with the project‚Äôs architecture and conventions. That means maintenance and institutional knowledge of the codebase become first-class concerns, not implementation details.\n\nCurious if you experimented with metadata-weighted retrieval or repo-aware chunking alongside the context tree approach.",
          "score": 1,
          "created_utc": "2026-01-18 14:46:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wknh",
              "author": "Julianna_Faddy",
              "text": "Yep, largely agree. We tried metadata-weighted retrieval and repo-aware chunking, and they helped, but mostly as incremental gains. The big shift was treating structure as the primary signal and letting metadata and semantics refine within that, not lead. Once retrieval aligns with the repo‚Äôs actual architecture, chunking and ASTs start working *with* you instead of fighting noise.",
              "score": 1,
              "created_utc": "2026-01-23 05:57:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ayszn",
          "author": "ExtentHot9139",
          "text": "Personally, I always craft my context window manually and ended automating it. I built code2prompt check it out.\n\nThe idea is simple: select relevant file, flatten them in a big file that you can just dump in a LLM chat.\n\nIt makes coding with agents stateless, semi auto and focused.",
          "score": 1,
          "created_utc": "2026-01-18 15:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wqbb",
              "author": "Julianna_Faddy",
              "text": "That makes a lot of sense. You basically turned the ‚Äúmanual context curation‚Äù that good devs already do into a tool, which avoids a ton of noisy automation. It‚Äôs very aligned with our experience that deliberate, scoped context beats any fully automatic retrieval once repos get non-trivial.",
              "score": 2,
              "created_utc": "2026-01-23 05:59:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o16xql6",
                  "author": "ExtentHot9139",
                  "text": "It's convenient but has limits.\n\nAnd I'm not sure how to improve it.\n\nFor instance, I have a .c2pconfig file at the root of my repo that gives the include patterns for the source without anything unnecessary.\n\nHowever, it happens that I want to dev or optimize a more focused feature and only need 3-5 files.\n\nThat moment I still have to craft the command e.g.\n\n`code2prompt src/frontend -i \"*claim_*,*main*\"`\n\nThat's still a lot better than manually copying or launching it on Claude code with 150k tokens in context already.\n\nI definitively would need to dev an extension for vscode to flatten opened tab with c2p. Or something similar, but I'm not sure it would be the best.\n\nAre you already using something for that usecase ? How do you handle it ?",
                  "score": 1,
                  "created_utc": "2026-01-23 06:06:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0b2ht5",
          "author": "Crafty_Disk_7026",
          "text": "You can not do RAG with code you need specialized format like ast so you can actually reason about the code.  Finding 2 functions with similar names that do completely different things is meaningless and the kind of garbage you'll get doing rag to understand code",
          "score": 1,
          "created_utc": "2026-01-18 15:50:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wnpf",
              "author": "Julianna_Faddy",
              "text": "Yeah, that‚Äôs basically the core issue. Raw RAG treats code like text, so you end up matching names instead of meaning. ASTs and symbol graphs let you reason about behavior and relationships, which is what actually matters. Similar names without structure are just noise, and embeddings alone can‚Äôt tell the difference.",
              "score": 1,
              "created_utc": "2026-01-23 05:58:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0g1tbi",
          "author": "Creepy-Row970",
          "text": "pretty interesting read",
          "score": 1,
          "created_utc": "2026-01-19 08:39:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r1f9n",
          "author": "Professional-Work684",
          "text": "We had similar issues with over 2k files (pdf) with medical policys and routines. We solved it by adding a postgres db as an index and contextual rag with a pgvector db. The pg index contained metadata and some context of the content of the files.¬†",
          "score": 1,
          "created_utc": "2026-01-20 22:28:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wme2",
              "author": "Julianna_Faddy",
              "text": "That makes sense, and it lines up with what we saw outside of code too. Once you add a real index with metadata and light context, retrieval stops being ‚Äúguessy‚Äù and starts being directed. For docs like medical policies, that structure maps much better to relevance than pure similarity, which is probably why the Postgres + pgvector combo worked well for you.",
              "score": 1,
              "created_utc": "2026-01-23 05:58:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0so2md",
          "author": "Sufficient-Pause9765",
          "text": "I found that RAG decreased performance unless agents were restricted to using it very, very sparingly.",
          "score": 1,
          "created_utc": "2026-01-21 03:56:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16wrnn",
              "author": "Julianna_Faddy",
              "text": "Same here. Once RAG fires too often, context quality drops fast and reasoning gets worse. Treating retrieval as an exception, not the default, made agents much more reliable for us too.",
              "score": 1,
              "created_utc": "2026-01-23 05:59:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o180jdn",
          "author": "BelottoBR",
          "text": "Not complex as the op example, but I tried to make a rag over Harry Potter books and it still miss a lot of simple Harry Potter questions",
          "score": 1,
          "created_utc": "2026-01-23 11:45:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgdgq5",
      "title": "LangGraph/workflows vs agents: I made a 2-page decision sheet. What would you change?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qgdgq5",
      "author": "OnlyProggingForFun",
      "created_utc": "2026-01-18 16:45:28",
      "score": 44,
      "num_comments": 6,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question | Help",
      "permalink": "https://reddit.com/r/LangChain/comments/1qgdgq5/langgraphworkflows_vs_agents_i_made_a_2page/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0be227",
          "author": "OnlyProggingForFun",
          "text": "If anyone wants the PDF version, I can share it directly too :)",
          "score": 1,
          "created_utc": "2026-01-18 16:45:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o0iw4x6",
          "author": "ayeaiai",
          "text": "u/ayeaiai Yes, please share the PDF version as well. Thank you.",
          "score": 1,
          "created_utc": "2026-01-19 18:49:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0iwyt4",
              "author": "OnlyProggingForFun",
              "text": "Of course, here it is in full: [https://drive.google.com/file/d/1HZ1m1NIymE-9eAqFW-sfSKsIoz5FztUL/view?usp=sharing](https://drive.google.com/file/d/1HZ1m1NIymE-9eAqFW-sfSKsIoz5FztUL/view?usp=sharing)",
              "score": 2,
              "created_utc": "2026-01-19 18:52:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0njpop",
          "author": "jaisanant",
          "text": "I have used orchestrator to delegate task to special agents.\nInside special agents there is supervisor-assistant pattern.",
          "score": 1,
          "created_utc": "2026-01-20 12:10:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ul6rt",
          "author": "MansiTibude",
          "text": "Thanks for sharing, are we allowed to download it?",
          "score": 1,
          "created_utc": "2026-01-21 13:14:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ule06",
              "author": "OnlyProggingForFun",
              "text": "Sure! I have it here as well in full with the webinar I made around it or in the drive link in the comment below :) \n\n[https://academy.towardsai.net/products/digital\\_downloads/agents-cheatsheet](https://academy.towardsai.net/products/digital_downloads/agents-cheatsheet)",
              "score": 1,
              "created_utc": "2026-01-21 13:16:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfcwe0",
      "title": "Really Bad Etiquette from Langchain maintainers",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfcwe0/really_bad_etiquette_from_langchain_maintainers/",
      "author": "Total-Chef-420",
      "created_utc": "2026-01-17 13:13:33",
      "score": 34,
      "num_comments": 18,
      "upvote_ratio": 0.87,
      "text": "I have tried contributing to langchain's ecosystem multiple times and both times my commits were taken by the maintainers, added a bunch of extra things on it and immediately raised a new PR without any kind of attribution.\n\nIs this how langchain expects people to contribute to their repository ?\n\n  \nThis has happened twice (and even maintainers acknowledged it)\n\n  \n1. [https://github.com/langchain-ai/deepagents/pull/713](https://github.com/langchain-ai/deepagents/pull/713)\n\n2. [https://github.com/langchain-ai/deepagentsjs/pull/84](https://github.com/langchain-ai/deepagentsjs/pull/84)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfcwe0/really_bad_etiquette_from_langchain_maintainers/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o042d9m",
          "author": "vtrivedy-lc",
          "text": "Hey OP, one of the maintainers from LangChain‚Äôs deepagents here, really sorry to hear that and our apologies.  Closing PRs and opening new ones that could‚Äôve been built on existing community PRs is never our intention.\n\nWe do get A LOT of PRs so it‚Äôs very possible we‚Äôve made this mistake and would love to make it right with proper attribution.  If you want to DM or link it, I‚Äôll take a look at how to give attribution.\n\nWe‚Äôre incredibly grateful for the awesome LangChain community, great contributions and ideas that push our libraries to be better for users.  Will try to make this right, sorry about the bad experience!",
          "score": 16,
          "created_utc": "2026-01-17 14:48:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04e1o6",
              "author": "Total-Chef-420",
              "text": "PR for deepagentsjs: [https://github.com/langchain-ai/deepagentsjs/pull/84](https://github.com/langchain-ai/deepagentsjs/pull/84)\n\n  \nPR for deepagents : [https://github.com/langchain-ai/deepagents/pull/713](https://github.com/langchain-ai/deepagents/pull/713)",
              "score": 13,
              "created_utc": "2026-01-17 15:47:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04fq6q",
                  "author": "vtrivedy-lc",
                  "text": "Thanks for linking!  See the PR across both, the deepagents one was a duplicate of a previous open PR that the team built on and added testing.  But totally see your frustration, we‚Äôll add attribution for the work!  \n\nAnd we will definitely be better in the future.  Would love feedback on the current PR process.  We‚Äôre exploring using discussions more to make sure that external PRs are linked directly to plans for implementing.  We love the PRs but understand it takes a lot of time and is then frustrating if the work isn‚Äôt used.  This way we can confirm the direction of the work.\n\nNothing decided but wanted to get feedback if anyone here has thoughts.",
                  "score": 5,
                  "created_utc": "2026-01-17 15:55:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04eks7",
                  "author": "TalosStalioux",
                  "text": "Upvoting for you",
                  "score": 1,
                  "created_utc": "2026-01-17 15:50:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03ngca",
          "author": "pokemonplayer2001",
          "text": "Do you have links to the PRs in question?",
          "score": 4,
          "created_utc": "2026-01-17 13:25:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04e708",
              "author": "Total-Chef-420",
              "text": "Yes, I have updated in the above comment",
              "score": -1,
              "created_utc": "2026-01-17 15:48:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0o0ub6",
          "author": "sydneyrunkle",
          "text": "Hey OP, thanks for raising! We really value community contributions.\n\n  \nI forgot to add you as a co-author when I merged my PR. I've corrected this mistake and added you here: https://github.com/langchain-ai/deepagents/pull/847.\n\n  \nThanks for your contributions -- we'd be more than happy to collaborate on future PRs :).",
          "score": 1,
          "created_utc": "2026-01-20 13:57:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o060khe",
          "author": "No_Inspection4415",
          "text": "Your PRs are pretty useless, to be honest.",
          "score": 0,
          "created_utc": "2026-01-17 20:24:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o061as9",
              "author": "Total-Chef-420",
              "text": "Simple yes, but useless no.\n\nThey fixed an issue which was open since multiple days.",
              "score": 1,
              "created_utc": "2026-01-17 20:27:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o06574y",
                  "author": "No_Inspection4415",
                  "text": "Isn't it [https://github.com/langchain-ai/deepagents/pull/612/files](https://github.com/langchain-ai/deepagents/pull/612/files) a different implementation? Did you run the validation they asked you to? Honestly, unless this fix is very difficult to find, having to work with \"your\" solution is not a net positive for them...\n\nWhatever, I do not like the framework anyway and I get your point, you did the research which is not complicated to do, but you did it. You do deserve credit, of course (not that being a part of this framework is a huge honor, it is not like you closed a PR for the K8s ;P).\n\nEdit: sorry, this [https://github.com/langchain-ai/deepagents/pull/803](https://github.com/langchain-ai/deepagents/pull/803) \\- they work really weirdly.",
                  "score": 0,
                  "created_utc": "2026-01-17 20:48:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qgekmg",
      "title": "fastapi-fullstack v0.1.15 released ‚Äì now with DeepAgents (LangChain's multi-agent framework) + HITL support!",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qgekmg/fastapifullstack_v0115_released_now_with/",
      "author": "VanillaOk4593",
      "created_utc": "2026-01-18 17:27:05",
      "score": 21,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hey r/LangChain,\n\nQuick recap for new folks: fastapi-fullstack is an open-source CLI generator (pip install fastapi-fullstack) that creates production-ready full-stack AI/LLM apps with FastAPI backend + optional Next.js 15 frontend. It supports PydanticAI, LangChain, LangGraph, CrewAI ‚Äì and now DeepAgents for advanced multi-agent systems.\n\n**v0.1.15 just released with full DeepAgents integration:**\n\n**Added:**\n\n* **DeepAgents as the fifth AI framework option** ‚Äì new --ai-framework deepagents CLI flag\n* Built-in tools for file ops (ls/read/write/edit/glob/grep), code execution (disabled by default for safety), and task management (todos/sub-agents)\n* StateBackend for in-memory file state\n* Skills support via DEEPAGENTS\\_SKILLS\\_PATHS env var\n\n**Human-in-the-Loop (HITL) features:**\n\n* Tool approval workflow: Users can approve/edit/reject tool calls (configurable via DEEPAGENTS\\_INTERRUPT\\_TOOLS)\n* Frontend dialog for reviewing/editing JSON args in real-time\n* WebSocket protocol for interrupts: Backend sends tool\\_approval\\_required, frontend responds with resume decisions\n\n**Fixed & improved:**\n\n* Type annotations across CrewAI handlers (from previous updates)\n* WebSocket disconnect handling during agent processing\n* Frontend timeline connectors and message grouping\n* 100% test coverage (720 statements, 0 missing) with tests for all DeepAgents events, stream edges, and disconnects\n\nThis makes building and deploying DeepAgents-powered apps (with HITL for safe, controlled execution) super straightforward ‚Äì perfect for complex, filesystem-aware agents.\n\nFull changelog: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template/blob/main/docs/CHANGELOG.md)  \nRepo: [https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template](https://github.com/vstorm-co/full-stack-fastapi-nextjs-llm-template)\n\nLangChain community ‚Äì how does DeepAgents + HITL fit your multi-agent projects? Any features to add? Contributions welcome! üöÄ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qgekmg/fastapifullstack_v0115_released_now_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0d557i",
          "author": "vtrivedy-lc",
          "text": "this is awesome! basically breathe fastapi and deepagents these days so love to see this :)\n\nif there‚Äôs any way we can make deepagents easier to dev on, would love to hear it!",
          "score": 2,
          "created_utc": "2026-01-18 21:52:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ol9so",
          "author": "Difficult-Suit-6516",
          "text": "Nice üëçüèª Would Love to see LangChain + OpenRouter Integration as those are my poison of choice right now",
          "score": 1,
          "created_utc": "2026-01-20 15:41:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qji1cc",
      "title": "LangChain + OpenWork + Docling + Milvus Holy Grail Setup",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qji1cc/langchain_openwork_docling_milvus_holy_grail_setup/",
      "author": "Clay_Ferguson",
      "created_utc": "2026-01-22 02:21:45",
      "score": 16,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "Hi guys. I was wondering if anyone knows of an open source project that incorporates the following technologies into a single RAG solution that people can just simply install and run. What I'm referring to here is a kind of \"Chat with your Documents\" type feature, where you scan a bunch of documents and then you can have a conversation with an AI about the documents (basic RAG).\n\n\n\n>\\* Openwork (LangChain Chat System, with Electron GUI Front end)\n\n>\\* Docling for Doc loading\n\n>\\* Milvus Vector DB  \n\n\n\n\nThis seems to be the holy grail that everyone is currently building right now (RAG systems), and I don't know if there's a popular project yet that incorporates all of the above into a single system people can just run without having to put together all the components themselves. When Openwork was recently released, that gets us 90% of the way to the finish line, but we just need a project that adds Docling and Milvus to finish it. It might be good to have a Docker Compose-base solution to this since there's several independent technologies that we're putting together.\n\n\n\nAny thoughts or ideas anyone has are greatly appreciate it. Thanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qji1cc/langchain_openwork_docling_milvus_holy_grail_setup/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0zfbhc",
          "author": "Hot_Substance_9432",
          "text": "Something like this? [https://zilliz.com/blog/build-rag-with-langchain-milvus-and-strapi](https://zilliz.com/blog/build-rag-with-langchain-milvus-and-strapi)",
          "score": 4,
          "created_utc": "2026-01-22 03:32:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zr28x",
              "author": "Clay_Ferguson",
              "text": "Not Strapi tho, but Openwork.",
              "score": 1,
              "created_utc": "2026-01-22 04:47:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0zvbcf",
          "author": "Hot_Substance_9432",
          "text": "Almost:)  [https://milvus.io/docs/build\\_RAG\\_with\\_milvus\\_and\\_docling.md](https://milvus.io/docs/build_RAG_with_milvus_and_docling.md)",
          "score": 2,
          "created_utc": "2026-01-22 05:16:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi5rmu",
      "title": "Deep Agents pattern: planning, delegation, file based state (wired up with CopilotKit)",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qi5rmu/deep_agents_pattern_planning_delegation_file/",
      "author": "pfthurley",
      "created_utc": "2026-01-20 16:29:34",
      "score": 16,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Most agents today are just ‚ÄúLLM in a loop + tools‚Äù. They are good at reasoning and works fine for short tasks. Over long-running tasks, they usually have no plan, lose context and their execution gets messy.\n\nMore capable agents like Claude Code and Manus get around this by following a common pattern: they plan first, externalize working context (files) and break work into isolated sub-tasks.\n\nDeep Agents from LangChain are really the next level, which essentially package this pattern into a reusable runtime. you call `create_deep_agent(...)` and get a StateGraph that:\n\n* plans explicitly\n* delegates work to sub-agents\n* keeps its state in files instead of bloating the prompt\n\nEach piece is implemented as middleware (To-do list middleware, Filesystem middleware, Subagent middleware).\n\nConceptually it looks like this:\n\n    User goal\n      ‚Üì\n    Deep Agent (LangGraph StateGraph)\n      ‚îú‚îÄ Plan: write_todos ‚Üí updates \"todos\" in state\n      ‚îú‚îÄ Delegate: task(...) ‚Üí runs a subagent with its own tool loop\n      ‚îú‚îÄ Context: ls/read_file/write_file/edit_file ‚Üí persists working notes/artifacts\n      ‚Üì\n    Final answer\n\nIt push key parts into explicit state (e.g. `todos` \\+ files + messages), but the main thing I noticed was visibility over frontend.\n\nI wired it up with CopilotKit - Infrastructure for building AI copilots into any app.\n\nIt keeps the frontend in sync with what the agent is doing by streaming events and state updates in real time (using AG-UI protocol under the hood).\n\nDeep Agents is really good at multi-step workflows & CopilotKit as the orchestration + UI layer. Check out the \"Job search assistant\" demo using this pattern.\n\nGitHub Repo: [https://github.com/CopilotKit/copilotkit-deepagents](https://github.com/CopilotKit/copilotkit-deepagents)  \nTutorial: [https://www.copilotkit.ai/blog/how-to-build-a-frontend-for-langchain-deep-agents-with-copilotkit](https://www.copilotkit.ai/blog/how-to-build-a-frontend-for-langchain-deep-agents-with-copilotkit)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qi5rmu/deep_agents_pattern_planning_delegation_file/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qjm96c",
      "title": "Multi-agents breakthrough",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "author": "crionuke",
      "created_utc": "2026-01-22 05:41:20",
      "score": 16,
      "num_comments": 11,
      "upvote_ratio": 0.81,
      "text": "ChatGPT and similar models have become universal tools, which is why they so quickly entered the daily lives of millions of people. We use them to search for information, work with text, learn new topics, and hold discussions.  \n  \nHowever, chats themselves are not agents. They cannot operate in the real or digital world: they do not make decisions, execute chains of tasks, interact with services, or carry work through to completion.  \n  \nFor this reason, companies have begun building their own agent and multi-agent systems. These systems help users apply for loans, buy tickets, plan vacations, or complete paperwork.  \n  \nBut almost all such solutions remain narrowly specialized. Each agent is tightly bound to predefined scenarios and cannot go beyond the logic embedded by its creators.  \n  \nBecause of this, the next major technological breakthrough will likely be the emergence of universal agent systems accessible to ordinary users.  \n  \nExternally, they may look almost the same: a familiar chat interface with a bot. Internally, however, they will represent complex self-organizing systems composed of many agents, capable of understanding user goals, autonomously building plans, selecting tools, and adapting to changing conditions.  \n  \nIn essence, this marks a transition from ‚Äúanswering prompts‚Äù to digital assistants that can act ‚Äî and may even possess their own form of intent within the boundaries of achieving the user‚Äôs goals, rather than merely reacting to commands.  \n  \nGiven the current pace of development in large language models and agent frameworks, it is entirely possible that the first truly universal multi-agent systems will appear by the end of 2026.\n\n  \n**What are your thoughts on the next breakthrough in our field?**",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjm96c/multiagents_breakthrough/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o103070",
          "author": "ChanceKale7861",
          "text": "Yep! I‚Äôm about to go FOSS with a 20 agent system of rust and python agents so we power users aren‚Äôt bound to API bullshit.",
          "score": 3,
          "created_utc": "2026-01-22 06:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10vgpt",
              "author": "crionuke",
              "text": "Interesting,\n\nis there anything you can share that we can already play with?",
              "score": 2,
              "created_utc": "2026-01-22 10:32:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12akg1",
                  "author": "ChanceKale7861",
                  "text": "I actually just finished that up yesterday, and myself along with 10-15 folks across business, SWE, enterprise architecture, etc. lots of folks I know have been working on projects, so, rolling to them first, and then if they are happy with where it‚Äôs at, I‚Äôm going to launch the website, and the tool. so, yes, but maybe in a week or two? need to ensure the things like file intake and generation work as designed, as well as whether the aspects like security and auditor agents orchestrate as designed and tested so far. Or like, for the folks I know in like recruiting, or sales, does it truly automate an aspects for them, like it has me. Which is where this stemmed from a couple weeks back.",
                  "score": 2,
                  "created_utc": "2026-01-22 15:42:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11a1mg",
          "author": "Number4extraDip",
          "text": "You misunderstand agents and infrastructure. There is no such thing as disembodied ai. Agents have specific architecture and defining components.\n\nYou wanna ground ai? Ground them in realtime data and telemetry\n\n[all ai is robotics](https://youtube.com/shorts/wTY2mY3XF1Y?si=QpiqBlUIK3WqNzNu)\n\nAnd multi agent systems are not complex if you think about it\n\n[heres a plug and play one copy pasta](https://github.com/vNeeL-code/ASI)",
          "score": 3,
          "created_utc": "2026-01-22 12:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10vs73",
          "author": "fabkosta",
          "text": "All of this is not new, the fantasies about such systems have been there 25 years ago. Just go pick up any book or article on muli-agent-systems from the early 2000s. What has changed today that, suddenly and miraculously, such systems can become true, although they could not 25 years ago? LLMs? GenAI? That's not enough, a lot more is required - and we did not solve the issues 25 years ago with other technology neither.\n\nIt's wild to see that nobody seems to want to learn anything from history.",
          "score": 1,
          "created_utc": "2026-01-22 10:35:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13h9cw",
          "author": "Aggressive_Bed7113",
          "text": "This post can be much shorter with only the last paragraph or last sentence.\n\nThis title made me think op will present some real breakthroughs, but it turns out the person has no idea either. Duh\n\nWhy do I want a universal agent that does mediocre stuffs in everything than a specialized agent in things I only care about?!",
          "score": 1,
          "created_utc": "2026-01-22 18:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13hrlg",
              "author": "crionuke",
              "text": "Nobody has",
              "score": 1,
              "created_utc": "2026-01-22 18:55:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o13i4l5",
                  "author": "Aggressive_Bed7113",
                  "text": "Then what‚Äôs the point of posting this?",
                  "score": 1,
                  "created_utc": "2026-01-22 18:57:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ahysn",
          "author": "LairBob",
          "text": "This is just ill-informed rambling.",
          "score": 1,
          "created_utc": "2026-01-23 19:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10u9do",
          "author": "PopPsychological4106",
          "text": "Wdym by \"truly universal\"?",
          "score": 0,
          "created_utc": "2026-01-22 10:21:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10v7xi",
              "author": "crionuke",
              "text": "I don‚Äôt have a one word term for this, but imagine systems capable of generating agent skills on the fly to handle a user request, even if those skills don‚Äôt exist beforehand, and refining them through a trial-and-error loop: develop ‚Üí test ‚Üí improve ‚Üí ‚Ä¶ ‚Üí use for the user‚Äôs task.",
              "score": 1,
              "created_utc": "2026-01-22 10:30:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qj9qms",
      "title": "Solved rate limiting on our agent workflow with multi-provider load balancing",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "author": "llamacoded",
      "created_utc": "2026-01-21 20:46:50",
      "score": 13,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "We run a codebase analysis agent that takes about 5 minutes per request. When we scaled to multiple concurrent users, we kept hitting rate limits; even the paid tiers from DeepInfra, Cerebras, and Google throttled us too hard. Queue got completely congested.\n\nTried Vercel AI Gateway thinking the endpoint pooling would help, but still broke down after \\~5 concurrent users. The issue was we were still hitting individual provider rate limits.\n\nTo tackle this we deployed an LLM gateway (Bifrost) that automatically load balances across multiple API keys and providers. When one key hits its limit, traffic routes to the others. We set it up with a few OpenAI and Anthropic keys.\n\nIntegration was just changing the base\\_url in our OpenAI SDK call. Took maybe 15-20 min total.\n\nNow we're handling 30+ concurrent users without throttling. No manual key rotation logic, no queue congestion.\n\nGithub if anyone needs:¬†[https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj9qms/solved_rate_limiting_on_our_agent_workflow_with/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0xn3ti",
          "author": "Mishuri",
          "text": "Or just use open router?",
          "score": 2,
          "created_utc": "2026-01-21 21:46:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xcho0",
          "author": "DanceWithEverything",
          "text": "Can I use a Claude max sub to oauth myself a token?",
          "score": 1,
          "created_utc": "2026-01-21 20:57:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk2cv0",
      "title": "Could this architectural shift finally solve the \"Agent Reliability\" problem?",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "author": "sophieximc",
      "created_utc": "2026-01-22 18:24:39",
      "score": 13,
      "num_comments": 7,
      "upvote_ratio": 0.79,
      "text": "As LangChain devs, we spend half our time writing OutputParsers, retry logic, and guardrails because LLMs are fundamentally probabilistic - they don't \"know\" they broke a constraint, they just guessed a token.\n\nI‚Äôve been reading up on the new wave of [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models) (backed by LeCun), and the implication for Agents is huge.\n\nUnlike Transformers that generate text left-to-right (and often paint themselves into a corner), an EBM minimizes an \"energy function\" at inference time. It basically verifies if the output meets the constraints (like \"Must be valid JSON\" or \"Must not contradict previous step\") before returning the result.\n\nIf this works at scale, we might finally get agents that can handle complex multi-step logic without needing a dozen error-handling loops.\n\nCurious if anyone sees this replacing the current RAG/Chain-of-Thought meta for strict logic tasks?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk2cv0/could_this_architectural_shift_finally_solve_the/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o13k2t9",
          "author": "Better_Dress_8508",
          "text": "I'm afraid you are extrapolating too far. EBM-s are not deterministic either",
          "score": 2,
          "created_utc": "2026-01-22 19:06:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13olgo",
              "author": "sophieximc",
              "text": "They are still probabilistic - you're sampling from a distribution, not running a script.  \n  \nBut the inference dynamic is different. Instead of just rolling the dice once per token (autoregressive), you're iteratively refining the output to lower the energy. It‚Äôs less about being deterministic and more about having a native mechanism to \"reject\" nonsense before finalizing the output.",
              "score": 0,
              "created_utc": "2026-01-22 19:26:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o14a1vs",
          "author": "met0xff",
          "text": "You can use constrained generation using something like xgrammar or outlines for the json problem",
          "score": 1,
          "created_utc": "2026-01-22 21:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15hrda",
          "author": "USToffee",
          "text": "It's how I'm writing my agent. It basically has a semantic binding step at the start that determines what kind of artifacts it expects and only gives an answer if the tool calls satisfy this. At this point I'm not sure if it's any better or not. It still requires the LLM to guess what artifacts are needed from the prompt.",
          "score": 1,
          "created_utc": "2026-01-23 00:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bhy3m",
          "author": "pbalIII",
          "text": "So the real question is whether the inference-time optimization loop scales without blowing up latency. Logical Intelligence just announced Kona 1.0 with LeCun on the board, and their pitch is exactly this... learning by correcting mistakes rather than guessing tokens.\n\nThe catch is EBTs need to be trained from scratch. You can't fine-tune an existing foundation model into one. That's a brutal cold start when every team already has GPT-4 wrappers in production.\n\nFor strict JSON, constrained decoding (xgrammar, outlines) already solves it deterministically without the architecture swap. The interesting unlock would be multi-step logical consistency across tool calls, where autoregressive models keep painting themselves into corners. Still waiting to see benchmarks on that before swapping out the retry loops.",
          "score": 1,
          "created_utc": "2026-01-23 22:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13hgo0",
          "author": "Educational-Bison786",
          "text": "EBMs are definitely an interesting shift for agent reliability. While they might reduce some issues, I doubt they'll fully replace the need for robust evaluation and guardrails. You'll still want tools like Pydantic for strict schema validation. For comprehensive agent quality and measuring improvements, platforms like [Maxim AI](https://www.getmaxim.ai/) are crucial. Also don't forget solid prompt engineering.",
          "score": 0,
          "created_utc": "2026-01-22 18:54:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13od1f",
              "author": "sophieximc",
              "text": "Agreed, validation (like Pydantic) isn't going anywhere. But right now, we use guardrails to catch errors after they happen (and then trigger expensive retries). The promise of EBMs is that the model wouldn't generate the error in the first place because it contradicts the \"energy\" state. I want validation to be a safety net, not the main control loop",
              "score": 1,
              "created_utc": "2026-01-22 19:25:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa9vd",
      "title": "Web Search APIs Are Becoming Core Infrastructure for AI",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfa9vd/web_search_apis_are_becoming_core_infrastructure/",
      "author": "codes_astro",
      "created_utc": "2026-01-17 10:52:21",
      "score": 10,
      "num_comments": 6,
      "upvote_ratio": 0.81,
      "text": "Web search used to be a ‚Äúnice-to-have‚Äù in software. With AI, it‚Äôs quickly becoming a requirement.\n\nLLMs are powerful, but without live data they can‚Äôt handle breaking news, current research, or fast-changing markets. At the same time, the traditional options developers relied on are disappearing, Google still doesn‚Äôt offer a truly open web search API and Bing Search API has now been retired in favor of Azure-tied solutions.\n\nI wrote a deep dive on how this gap is being filled by a new generation of AI-focused web search APIs, and why retrieval quality matters more than the model itself in RAG systems.\n\nThe article covers:\n\n* Why search is now core infrastructure for AI agents\n* Benchmarks like SimpleQA and FreshQA and what they actually tell us\n* How AI-first search APIs compare on accuracy, freshness, and latency\n* A breakdown of tools like Tavily, Exa, Valyu, Perplexity, Parallel and Linkup\n* Why general consumer search underperforms badly in AI workflows\n\nI‚Äôd love to hear from people actually building RAG or agent systems:\n\n* Which search APIs are you using today?\n* What tradeoffs have you run into around freshness vs latency vs cost?\n\nRead full writeup [here](https://mranand.substack.com/p/why-web-search-apis-are-becoming)\n\n",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qfa9vd/web_search_apis_are_becoming_core_infrastructure/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0542zt",
          "author": "Born_Owl7750",
          "text": "Currently using grounding with bing. But few limitations like you can only use it with a foundry agent service. Results are fine but too high level.\n\nTavily is something we are trying out as well",
          "score": 2,
          "created_utc": "2026-01-17 17:49:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09gx0m",
              "author": "codes_astro",
              "text": "Yes bing is too limited now, I have used tavily in early 2025 but I didn‚Äôt liked the responses, linkup and exa did better. Have to implement new web APIs to test which is better",
              "score": 2,
              "created_utc": "2026-01-18 09:02:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o09pbu6",
                  "author": "Born_Owl7750",
                  "text": "Nice, will try it out",
                  "score": 1,
                  "created_utc": "2026-01-18 10:20:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o09pcoc",
                  "author": "Born_Owl7750",
                  "text": "Nice, will try it out",
                  "score": 1,
                  "created_utc": "2026-01-18 10:20:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0b4vxx",
                  "author": "TheStanfordSimpLord",
                  "text": "\\+1 for linkup - works the best for me overall",
                  "score": 1,
                  "created_utc": "2026-01-18 16:02:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o128yz2",
                  "author": "Unhappy_Pass_2677",
                  "text": "Linkup is great. I like how there are many ways people are tackling web search now.",
                  "score": 1,
                  "created_utc": "2026-01-22 15:35:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhqw4u",
      "title": "AIMUG Builders Podcast - LangGraph orchestration w/ AWS agent core",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qhqw4u/aimug_builders_podcast_langgraph_orchestration_w/",
      "author": "colinmcnamara",
      "created_utc": "2026-01-20 04:11:26",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "Quick share for builders: Ep.6 digs into diffusion-model roots, then gets practical‚ÄîLangChain/LangGraph orchestration, ‚Äúskills‚Äù as a framework for agent workflows, context engineering, and production gotchas (incl. AWS agent core talk).   \nVideo if useful: [https://youtu.be/iSL-K4ytQNI?utm\\_source=Reddit&utm\\_medium=social&utm\\_campaign=members](https://youtu.be/iSL-K4ytQNI?utm_source=Reddit&utm_medium=social&utm_campaign=members)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qhqw4u/aimug_builders_podcast_langgraph_orchestration_w/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qk85pb",
      "title": "I built a system for generating and operating modular AI-enabled FastAPI apps after doing this for clients over and over",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/gallery/1qk85pb",
      "author": "Challseus",
      "created_utc": "2026-01-22 21:59:02",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qk85pb/i_built_a_system_for_generating_and_operating/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qhxuzz",
      "title": "LangSmith Agent Builder + MCP: What worked, what broke, and how I finally got MCP tools to show up",
      "subreddit": "LangChain",
      "url": "https://composio.dev/blog/how-to-langsmith-agent-builder",
      "author": "cyber_harsh",
      "created_utc": "2026-01-20 10:43:41",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/LangChain/comments/1qhxuzz/langsmith_agent_builder_mcp_what_worked_what/",
      "domain": "composio.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o0o7p64",
          "author": "sharsha315",
          "text": "That was a great insight. Thanks for sharing.",
          "score": 2,
          "created_utc": "2026-01-20 14:33:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o95rc",
              "author": "cyber_harsh",
              "text": "Welcome , I hope it's fixed soon, For now this is the answer from the founder himself.\n\nhttps://preview.redd.it/55rej0alnieg1.png?width=1080&format=png&auto=webp&s=95b2ee95fe0ac739571566b2c097716118ace58f",
              "score": 2,
              "created_utc": "2026-01-20 14:41:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfv8hd",
      "title": "I built an LLM router that cut my API costs by 60% - Open Source, Need feedback",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qfv8hd/i_built_an_llm_router_that_cut_my_api_costs_by_60/",
      "author": "Dense-Case-3615",
      "created_utc": "2026-01-18 01:37:43",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.91,
      "text": "I was spending $200/month on LLM API calls and built \\*\\*Cascade\\*\\* to reduce costs through intelligent routing.\n\n\\*\\*How it works:\\*\\*\n\n\\*   Trains a DistilBERT classifier on query complexity\n\n\\*   Routes simple queries to cheap models\n\n\\*   Routes complex queries to expensive models\n\n\\*   Adds semantic caching for duplicate-ish requests\n\n\\*\\*Results:\\*\\* $100 ‚Üí $40/month (60% reduction)\n\n\\*\\*Tech stack:\\*\\*\n\n\\*   FastAPI + OpenAI-compatible API\n\n\\*   ONNX Runtime for <20ms ML inference\n\n\\*   Qdrant for vector similarity search\n\n\\*   Redis for caching\n\n\\*   Docker for deployment\n\n\\*\\*Try it live (free):\\*\\*\n\n\n\ncurl -X POST [http://136.111.230.240:8000/v1/chat/completions](http://136.111.230.240:8000/v1/chat/completions) \\\\\n\n\\-H \"Content-Type: application/json\" \\\\\n\n\\-d '{\"model\":\"auto\",\"messages\":\\[{\"role\":\"user\",\"content\":\"Hello\"}\\]}'\n\n\\*\\*Dashboard:\\*\\* [https://cascade.ayushkm.com/](https://cascade.ayushkm.com/)\n\n\\*\\*GitHub:\\*\\* [https://github.com/ayushm98/cascade](https://github.com/ayushm98/cascade)\n\n\\*\\*I'm actively looking for feedback:\\*\\* Is there something I can do to improve the architecture or routing logic? What features would make this useful for your production workloads?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qfv8hd/i_built_an_llm_router_that_cut_my_api_costs_by_60/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0927i9",
          "author": "Key-Contact-6524",
          "text": "How much latency does this add as compared to normal request?",
          "score": 2,
          "created_utc": "2026-01-18 06:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fp5bh",
          "author": "Due_Midnight9580",
          "text": "Cool I was trying to build same üôÇ",
          "score": 1,
          "created_utc": "2026-01-19 06:46:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qinxsi",
      "title": "Advanced AI Program which also covers Langchain",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "author": "soundboardwithme",
      "created_utc": "2026-01-21 04:18:38",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hello Folks,\n\nI am not sure if this is the right sub, please be kind towards me if this is not the right sub.\n\nI have been really unwell and having health complications, due to which I am unable to continue my enrollment for an Advanced AI program. It's duration is 3 month and the investment is $ 700 \n\nI am in Eastern Standard Time ( EST ) and this program happens every weekend 11 AM To 2 PM IST, which is during midnight hours for me.\n\nIf I attend these LIVE sessions during midnight EST, I will increase the risk of cardio vascular disease, and I might fall dead because of my health situation. It's an intensive program, with clear learning outcomes.\n\nI tried to get a refund for this enrollment, but they would not agree to it, inspite of my risky health situation. All they could offer is swap my enrollment if I manage to find a person to join this program.\n\nThis is a sincere request and I apologize if I am posting in the wrong sub.\n\nAlso, I am not trying to promote this program in any way but I know that it's a good program for those who want to learn Agentic AI and build products.\n\nIf anyone is interested to learn and ready to take a look, I will be happy to ping you the details for consideration and help me swap the enrollment.\n\nHonestly, I am broke and my health situation is bad.\n\nAll I am trying to do is,heal and survive for the next few months.\n\nI have to prioritize my heath and my career goals have changed.\n\nAnd I only have a few months of savings left.\n\nPlease, this is a request to help me in any way possible.\n\nI was very hesistant to seek here for help.\n\nBecause of my health situation my plans have changed.\n\nHappy to DM you the details.\n\nIt's only one Spot.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qinxsi/advanced_ai_program_which_also_covers_langchain/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1ql3ufd",
      "title": "Langchain In production",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "author": "niklbj",
      "created_utc": "2026-01-23 21:39:55",
      "score": 8,
      "num_comments": 22,
      "upvote_ratio": 0.9,
      "text": "HI guys, i've realized a lot of us are using langchain or building agents in some of personal or official projects that are in prod. Wanted to start a discord server specific for those of us who are building AI and agent applications in prod to talk about any issues, suggestions, or advice.\n\nHere's the server: [https://discord.gg/qJVQgX2z](https://discord.gg/qJVQgX2z). Feel free to join!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql3ufd/langchain_in_production/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o1bh85l",
          "author": "HawkingsLovechild",
          "text": "Langchain is neither lightweight nor mature enough to be dependable in production in my experience. Works fine for POCs but I would reject any PR that attempts to add it to our stack.\n\nEdit: I just checked and installing langchain installed 32 packages, taking 20mb.\n\n  \nEdit2: OP has had half a dozen posts removed in the last month for spam promoting some B2B saas LLM nonsense across various subreddits . Go build a product people actually wanna use bro.",
          "score": 8,
          "created_utc": "2026-01-23 22:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1biayp",
              "author": "AdditionalWeb107",
              "text": "I am generally framework-averse. The tight coupling, lack of interoperability between other frameworks, and no clear separation of concerns makes we very weary. For example, I am not sure why I am left to my own devices to solve all the plumbing work vs. it being implemented via some standards-based infrastructure.",
              "score": 4,
              "created_utc": "2026-01-23 22:05:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bp64c",
                  "author": "HawkingsLovechild",
                  "text": "I don't think Langchain is a dead project or anything, I love the enthusiasm. But I wouldn't have used FFMPEG in 2004. Nor would I trust this open source project at this point in its lifecycle, especially when the core - the web APIs it basically wraps, could and do change on a dime.\n\n  \nNone of this applies if you're building personal projects, but if you have thousands of users paying you money, it's a different story.",
                  "score": 3,
                  "created_utc": "2026-01-23 22:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bi6hj",
              "author": "niklbj",
              "text": "Interesting, i've seen a ton of startups especially in the earlier days - series A and before building agents using langchain but that makes sense. What framework do you guys use?\n\nRegardless, just updated server to be framework agnostic! It's now just about building and scaling agents in production",
              "score": 1,
              "created_utc": "2026-01-23 22:05:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bjxcz",
                  "author": "HawkingsLovechild",
                  "text": "I am in a startup myself as the tech lead. We don't need LLM frameworks. We write code that calls the APIs. They already did the hard work. Everything Langchain does you can do yourself in a hilariously short amount of time, with more control, tailored to your business needs. \n\n  \nI don't mean to sound like a dick but I genuinely have no idea what Langchain is solving for people. What problem does your company have that you determined it was easier to use Langchain for?",
                  "score": 2,
                  "created_utc": "2026-01-23 22:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1d7btv",
              "author": "cuba_guy",
              "text": "Pretty tight ship over there, our nodejs monorepo has 8gb of node_modules and goes to prod multiple times a day :)",
              "score": 1,
              "created_utc": "2026-01-24 03:44:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bi7ze",
              "author": "usernotfoundo",
              "text": "What's the alternative to it? Is it not dependable because further updates could lead to currently implemented features being deprecated?",
              "score": 0,
              "created_utc": "2026-01-23 22:05:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bj5bo",
                  "author": "HawkingsLovechild",
                  "text": "Using the API provided by the LLM developers and writing your own wrapping code around it. It's not particularly difficult - I maintain such a system for my company and it's a single python library with the SDKs in question and the requests library. I also get greater control and can respond to updates to say, openAI the day they're rolled out rather than waiting. \n\n  \nWhat features does langchain provide you that you can't write yourself? It's not a particularly complicated package.",
                  "score": 3,
                  "created_utc": "2026-01-23 22:09:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1bdiv6",
          "author": "AdditionalWeb107",
          "text": "This is cool - shouldn't the Langchain guys host and moderate this type of discord themselves?",
          "score": 1,
          "created_utc": "2026-01-23 21:43:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1bh18a",
              "author": "mdrxy",
              "text": "We have a community slack! https://www.langchain.com/join-community",
              "score": 3,
              "created_utc": "2026-01-23 21:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bi7fy",
                  "author": "niklbj",
                  "text": "that's sick!",
                  "score": 1,
                  "created_utc": "2026-01-23 22:05:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bdv1e",
              "author": "niklbj",
              "text": "totally open to them doing so if anybody from Langchain wants to help moderate it! didn't see something like this out there, so thought I'd create one and handle it for now",
              "score": 2,
              "created_utc": "2026-01-23 21:44:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1bevvc",
                  "author": "AdditionalWeb107",
                  "text": "I use stock python - so this wouldn't be a great fit for me personally, but I see the value. Thanks for creating it OP",
                  "score": 2,
                  "created_utc": "2026-01-23 21:49:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1dbiyl",
          "author": "code_vlogger2003",
          "text": "Hey hi guys,  i already shipped the react style multi agents in the production using the langchain and it's currently serving in the production. Ok high level the end product of the pipeline is a detailed report which contains text, images and tables etc based on unstructured raw time series data. For the control and monitoring I have debugged their call backs and written detailed functions for precise calculation that match with manual calculation. This monitoring helps us to understand the costs of the api and believe me that on average for one detailed report it takes around 0.15 $ which the report includes the multi model calls too.",
          "score": 1,
          "created_utc": "2026-01-24 04:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bj5i5",
          "author": "peejay2",
          "text": "I fw agno",
          "score": 0,
          "created_utc": "2026-01-23 22:09:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg98n5",
      "title": "Stopped choosing between LangGraph and Claude SDK - using both solved my multi-agent headaches",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qg98n5/stopped_choosing_between_langgraph_and_claude_sdk/",
      "author": "Realistic-Quarter-47",
      "created_utc": "2026-01-18 13:57:50",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Spent weeks going back and forth. LangGraph for workflow control or Claude SDK for agent execution? Each had trade-offs that frustrated me.\n\nLangGraph gave me great routing and state management but fighting its agent loop felt wrong. Claude SDK made agents easy but I lost visibility into the workflow.\n\nThe fix: stop choosing. Use both.\n\nLangGraph handles orchestration - what runs when, conditional branching, state between nodes. Claude SDK handles agent execution inside each node - reasoning, tool calling, context.\n\nThey operate at different levels. Once I saw that, everything clicked.\n\nWrote up the pattern with working code: [article](https://www.khaledelfakharany.com/articles/langgraph-claude-sdk-integration?utm_source=reddit&utm_medium=social&utm_campaign=langgraph-claude-sdk&utm_content=langchain)\n\nBonus: I can now use different models per node. Haiku for quick decisions, Sonnet for analysis. Couldn't do that easily before.\n\nAnyone else running hybrid setups like this?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1qg98n5/stopped_choosing_between_langgraph_and_claude_sdk/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": [
        {
          "id": "o0go69i",
          "author": "shivmohith8",
          "text": "This actually makes sense because LangGraph is more like a directed cyclic graph framework that has some features specially made for AI applications and Claude Code sdk is made for agentic loop.",
          "score": 2,
          "created_utc": "2026-01-19 12:02:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oc7j9",
              "author": "Realistic-Quarter-47",
              "text": "the combination is just insane, I couldn't hold it",
              "score": 1,
              "created_utc": "2026-01-20 14:56:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0oamn8",
          "author": "Hey-Intent",
          "text": "I was planning to test this, thanks for sharing and for the time saved.",
          "score": 2,
          "created_utc": "2026-01-20 14:48:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ockww",
              "author": "Realistic-Quarter-47",
              "text": "You find this integration really useful, here is also a [workshop](https://www.khaledelfakharany.com/workshops/due-diligence?utm_source=reddit&utm_medium=social&utm_campaign=langgraph-claude-sdk&utm_content=langchain) that I did. it's free but I would appreciate your feedback.",
              "score": 1,
              "created_utc": "2026-01-20 14:58:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rw0w2",
          "author": "rshah4",
          "text": "I like this idea as well. I wonder if langgraph deep agents will better support this approach. It seems to make sense to take advantage of claude agents ability to work with files and code.",
          "score": 1,
          "created_utc": "2026-01-21 01:13:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql1m38",
      "title": "Open Source Serverless RAG Pipeline (Lambda + Bedrock) with React Component",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "author": "HatmanStack",
      "created_utc": "2026-01-23 20:14:08",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "I built a fully serverless RAG pipeline to avoid idle server costs and container management.\n\nRepo: [https://github.com/HatmanStack/RAGStack-Lambda](https://github.com/HatmanStack/RAGStack-Lambda)\n\nDemo: [https://dhrmkxyt1t9pb.cloudfront.net](https://dhrmkxyt1t9pb.cloudfront.net)\n\n(Login: [guest@hatstack.fun](mailto:guest@hatstack.fun) / Guest@123)\n\nBlog: [https://portfolio.hatstack.fun/read/post/RAGStack-Lambda](https://portfolio.hatstack.fun/read/post/RAGStack-Lambda)\n\nKey Features:\n\n* Frontend: Drop-in <ragstack-chat> web component (React 19).\n* Multimodal: Uses Amazon Nova to embed text, images, and videos.\n* Zero Idle Costs: Pure Lambda/Step Functions/DynamoDB architecture.\n* MCP Support: Connects directly to Claude Desktop and Cursor.\n* No Control Plane: All resources deployed in your AWS Account.\n\nDeployment is one-click via CloudFormation. Feedback welcome.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/LangChain/comments/1ql1m38/open_source_serverless_rag_pipeline_lambda/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qj1r2z",
      "title": "Added Git-like versioning to LangChain agent contexts (open source)",
      "subreddit": "LangChain",
      "url": "https://github.com/ultracontext/ultracontext-node",
      "author": "Main_Payment_6430",
      "created_utc": "2026-01-21 15:59:44",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resources",
      "permalink": "https://reddit.com/r/LangChain/comments/1qj1r2z/added_gitlike_versioning_to_langchain_agent/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qjwa56",
      "title": "Most agents forget their purpose after a few runs. I built a way for them to \"learn\" from attacks (99.6% defense rate).",
      "subreddit": "LangChain",
      "url": "https://www.reddit.com/r/LangChain/comments/1qjwa56/most_agents_forget_their_purpose_after_a_few_runs/",
      "author": "forevergeeks",
      "created_utc": "2026-01-22 14:41:31",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.73,
      "text": "Hi LangChainers,\n\nI‚Äôve been working on a problem that most standard agent frameworks (like LangChain or AutoGen) struggle with: long-term consistency or what the industry calls \"statelessness.\"\n\nMost agents reset their \"alignment\" with every new session. If a user jailbreaks them once, the agent doesn't learn to be more defensive next time. It makes the same mistake twice.\n\nThe Solution: **Stateful Alignment Tracking** I built an open-source framework called **SAFi (Self-Alignment Framework Interface)**. The core innovation is a module that tracks the agent's coherence, detects drift, and provides live feedback to the model when it is going off-track.\n\n**The Stress Test** To test the system, I recently ran a public jailbreak challenge here on Reddit. I used a \"Socratic Tutor\" agent and challenged users to make it give direct answers or forget its purpose as a science/math tutor.\n\n* **Total Attacks:** 845\n* **Successful Jailbreaks:** 2\n* **Defense Rate:** 99.6%\n\nThe two \"successful\" jailbreaks were actually \"refusal answers\" for example, the agent said: *\"I won't tell you the answer to 2+2=4 because I want you to think!\"*\n\n**The Code** SAFi is 100% open source. You can find the repo, benchmarks, and raw logs here: **Repo:**[https://github.com/jnamaya/SAFi](https://github.com/jnamaya/SAFi)\n\nI'm looking for feedback from the builder community, especially on how you're handling stateful governance in your own agent stacks.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LangChain/comments/1qjwa56/most_agents_forget_their_purpose_after_a_few_runs/",
      "domain": "self.LangChain",
      "is_self": true,
      "comments": []
    }
  ]
}