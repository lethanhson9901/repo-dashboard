{
  "metadata": {
    "last_updated": "2026-01-21 02:39:59",
    "time_filter": "week",
    "subreddit": "datascience",
    "total_items": 16,
    "total_comments": 162,
    "file_size_bytes": 177903
  },
  "items": [
    {
      "id": "1qh8z6e",
      "title": "Indeed: Tech Hiring Is Down 36%, But Data Scientist Jobs Held Steady",
      "subreddit": "datascience",
      "url": "https://www.interviewquery.com/p/indeed-tech-hiring-collapse-data-scientists-exception",
      "author": "warmeggnog",
      "created_utc": "2026-01-19 16:32:42",
      "score": 252,
      "num_comments": 43,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qh8z6e/indeed_tech_hiring_is_down_36_but_data_scientist/",
      "domain": "interviewquery.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0it57u",
          "author": "lordoflolcraft",
          "text": "Meanwhile applicants and new grads and outsiders trying to career change into DS are up (insert giant percentage here) percent",
          "score": 107,
          "created_utc": "2026-01-19 18:36:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jpxtx",
              "author": "RecognitionSignal425",
              "text": "\\*But Rejection of Data Scientist Jobs Held Steady",
              "score": 18,
              "created_utc": "2026-01-19 21:06:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0j7f4p",
              "author": "Zlatan13",
              "text": "Yeah lol, I'm had at least 500 rejections around September when I just figured I'd stop applying and focus more on networking within my company. Actual black hole",
              "score": 20,
              "created_utc": "2026-01-19 19:40:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0m0nfz",
              "author": "Palmquistador",
              "text": "Yep, hello. QA test automation engineer looking to make the jump to better waters.",
              "score": -1,
              "created_utc": "2026-01-20 04:30:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0j65h1",
          "author": "tits_mcgee_92",
          "text": "5 years data science experience. Masters degree in data science. I‚Äôve applied for 50 jobs and have only gotten three interviews. One of them ghosted me during the third round which was so odd",
          "score": 57,
          "created_utc": "2026-01-19 19:34:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jtlxf",
              "author": "snmnky9490",
              "text": "3 interviews out of 50 honestly seems pretty good for \"tech\" jobs these days",
              "score": 49,
              "created_utc": "2026-01-19 21:24:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0kzpbt",
              "author": "turbo_golf",
              "text": "6% app to interview is pretty good.\n\ni know the market has only gotten worse, but i applied for 400+ jobs in late 2024 and only got 4 interviews",
              "score": 20,
              "created_utc": "2026-01-20 01:03:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0m0pyo",
              "author": "Palmquistador",
              "text": "Well there‚Äôs zero hope for me then! ü§£",
              "score": 2,
              "created_utc": "2026-01-20 04:30:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pux4z",
              "author": "PuddyComb",
              "text": "Jesus.",
              "score": 2,
              "created_utc": "2026-01-20 19:10:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pv73b",
              "author": "PuddyComb",
              "text": "Welp. It's obviously time to fire everyone at LinkedIn.\n\nAgain.",
              "score": 2,
              "created_utc": "2026-01-20 19:11:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i7qe0",
          "author": "JesterOfAllTrades",
          "text": "I have ~2.5 years of experience in a well known (although not particularly known to be cutting edge) mega Corp with degrees from T10 universities. \n\nI've been applying for jobs and only really applied to like 30 so far but all rejections so far ü•≤ü•≤ I know 30 isn't much at all but I thought after my first job it would get a lot easier. Time to get back to the slog",
          "score": 49,
          "created_utc": "2026-01-19 17:00:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0imz8p",
              "author": "Watabich",
              "text": "What are you degrees in?",
              "score": 6,
              "created_utc": "2026-01-19 18:09:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0iovcv",
                  "author": "protonchase",
                  "text": "Also curious",
                  "score": 7,
                  "created_utc": "2026-01-19 18:17:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0kq8vt",
                  "author": "JesterOfAllTrades",
                  "text": "Sorry for the late reply but mathematics for both.",
                  "score": 3,
                  "created_utc": "2026-01-20 00:12:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0it1ys",
              "author": "pc_4_life",
              "text": "university you went to doesn‚Äôt really matter unless you are looking for internships. Stanford, MIT, etc might give your resume a longer look but that‚Äôs about it. 2.5 years still makes you relatively junior. market is better for mid/seniors. best thing you can do is customize your resume for the jobs you are applying to",
              "score": 2,
              "created_utc": "2026-01-19 18:35:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jm3c5",
                  "author": "Great_Northern_Beans",
                  "text": "Strongly disagree with a little bit of this. I'm a decade out of school now, and even still the university name on my degree (in the \"Stanford, MIT, etc. group; though I won't say which specifically) is heavily referenced to me in probably 50% of my interviews.¬†\n\nIt's actually crazy how many doors a brand name opens for otherwise middling candidates, like myself.",
                  "score": 23,
                  "created_utc": "2026-01-19 20:48:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0loh3v",
                  "author": "free_reezy",
                  "text": "At what point does someone become mid/senior? I‚Äôm going into year 9 and I gotta be honest I internally still feel like an entry-level guy even though I‚Äôm clearing 6 figures.",
                  "score": 1,
                  "created_utc": "2026-01-20 03:19:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0jtqrz",
              "author": "Inevitable-Pin-4507",
              "text": "You should try apps like Whileresume. You will probably get more chance to receive more interesting proposals",
              "score": 1,
              "created_utc": "2026-01-19 21:25:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iudwf",
          "author": "TA_poly_sci",
          "text": "Im sure this is in no way confounded by changes in the usage of Indeed as a platform. r datascience always delivering the best science.",
          "score": 17,
          "created_utc": "2026-01-19 18:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jglru",
          "author": "Big-Shake5075",
          "text": "Can someone find reference to this ‚Äúindeed study‚Äù? This article says DS is doing particularly bad by referring to ‚Äúindeed study‚Äù lol https://www.businessinsider.com/gruesome-tech-jobs-data-scientists-analytics-indeed-2025-11",
          "score": 2,
          "created_utc": "2026-01-19 20:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0k5e8q",
              "author": "save_the_panda_bears",
              "text": "https://www.hiringlab.org/2025/11/20/indeed-2026-us-jobs-hiring-trends-report/",
              "score": 2,
              "created_utc": "2026-01-19 22:22:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0naich",
                  "author": "Big-Shake5075",
                  "text": "This one does not even mention ds lol",
                  "score": 1,
                  "created_utc": "2026-01-20 10:56:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0livfm",
          "author": "Cheap_Scientist6984",
          "text": "This article smells.  Entry level DS hiring is not doing that well.  Same with SWE.  The entry level layer is evaporating and getting merged with Senior/Lower Middle Management.",
          "score": 2,
          "created_utc": "2026-01-20 02:48:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mdmrt",
              "author": "sailing_oceans",
              "text": "Entry level data science and swe jobs are being sent to India for $9 to $14 an hr unfortunately. \n\nThe opt f1 visa stuff is in the USA and it drags down incomes here.  I was recently forced to hire one of these visas because my company viewed them as a 0% leaving risk, a lower salary AND it‚Äôs like a ~15% discount since they don‚Äôt pay social security or Medicare.",
              "score": 3,
              "created_utc": "2026-01-20 06:01:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mh8vd",
                  "author": "Cheap_Scientist6984",
                  "text": "Fully aware.  Not even mentioning the pseudo-racist fact that these communities of people tend to be highly collectivist in culture and therefore don't like to contradict their managers.  It makes for talent that is almost slave like.",
                  "score": 2,
                  "created_utc": "2026-01-20 06:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qcwst",
              "author": "Atmosck",
              "text": "Entry level DS is a contradiction in terms. It's not an entry level role.",
              "score": 2,
              "created_utc": "2026-01-20 20:33:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0m4066",
          "author": "jobswithgptcom",
          "text": "More insights from my job search site: [https://jobswithgpt.com/blog/global\\_software-engineering\\_jobs\\_january\\_2026/](https://jobswithgpt.com/blog/global_software-engineering_jobs_january_2026/) lines up as I see python is top wanted skill.",
          "score": 2,
          "created_utc": "2026-01-20 04:52:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rghf4",
              "author": "HeyLookAStranger",
              "text": "lol",
              "score": 1,
              "created_utc": "2026-01-20 23:48:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mdwf4",
          "author": "Deep_Negotiation_672",
          "text": "Those non techs who are targeting data science jobs directly or transitioning their careers into DS roles directly, they should go first with data analyst roles, get experience of atleast 2-3yrs in this role then try to switch into DA role.",
          "score": 1,
          "created_utc": "2026-01-20 06:03:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qq40v",
          "author": "reward72",
          "text": "As an employer I‚Äôm not hiring as long the circus runs the show",
          "score": 1,
          "created_utc": "2026-01-20 21:34:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpz1b",
      "title": "Spent few days on case study only to get ghosted. Is it the market or just bad employer?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/",
      "author": "Lamp_Shade_Head",
      "created_utc": "2026-01-15 17:33:30",
      "score": 88,
      "num_comments": 28,
      "upvote_ratio": 0.91,
      "text": "I spent a few days working on a case study for a company and they completely ghosted me after I submitted it. It‚Äôs incredibly frustrating because I could have used that time for something more productive. With how bad the job market is, it feels like there‚Äôs no real choice but to go along with these ridiculous interview processes. The funniest part is that I didn‚Äôt even apply for the role. They reached out to me on LinkedIn.\n\nI‚Äôve decided that from now on I‚Äôm not doing case studies as part of interviews. Do any of you say no to case studies too?",
      "is_original_content": false,
      "link_flair_text": "Career | US",
      "permalink": "https://reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzrjj7j",
          "author": "avourakis",
          "text": "No matter the state of the market, ghosting a candidate after they had a call with you or invested any amount of time beyond just applying is a sign of a poorly mismanaged recruitment team. Sorry you had that experience.",
          "score": 99,
          "created_utc": "2026-01-15 17:39:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxhw6f",
              "author": "snmnky9490",
              "text": "That's just par for the course these days, especially lower level jobs",
              "score": 4,
              "created_utc": "2026-01-16 14:59:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrkxw3",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 140,
          "created_utc": "2026-01-15 17:45:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu4q11",
              "author": "RecognitionSignal425",
              "text": "That's why take home assignment should be done by AI. OP could just use time trying to reason and argument about the choice made by AI to sound reasonable.",
              "score": 13,
              "created_utc": "2026-01-16 01:08:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv0qm6",
                  "author": "ice-truck-drilla",
                  "text": "Valid use of AI. Take-homes are ridiculous. In my experience having a normal and respectful conversation with someone to discuss their experiences and the  job description is becoming antique.",
                  "score": 5,
                  "created_utc": "2026-01-16 04:10:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrnvqr",
              "author": "chandlerbing_stats",
              "text": "Which is funny cause AI probably atleast gets them close to an answer",
              "score": 4,
              "created_utc": "2026-01-15 17:58:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrnaxx",
          "author": "dlchira",
          "text": "\"The Market\" is absolutely never an excuse to do this to an applicant.",
          "score": 45,
          "created_utc": "2026-01-15 17:55:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzro5jy",
          "author": "2up1dn",
          "text": "I decided that if I don't get hired, that I'd put any such case studies on GitHub and on my blog. \n\nThat way it's not wasted time; it's an opportunity to showcase a quick project to another client or employer.",
          "score": 89,
          "created_utc": "2026-01-15 17:59:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrx3ga",
              "author": "kevliao1231",
              "text": "Also useful if the company steals your work",
              "score": 32,
              "created_utc": "2026-01-15 18:39:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs00h0",
              "author": "BeastModeKeeper",
              "text": "This is the way",
              "score": 21,
              "created_utc": "2026-01-15 18:52:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs586e",
              "author": "TheOneWhoSendsLetter",
              "text": " Never thought of that. Great tip.",
              "score": 14,
              "created_utc": "2026-01-15 19:15:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrv65j",
          "author": "and1984",
          "text": "which company was this so that we may all avoid it and shame them?  I am sorry for your experience.  That's horrible.",
          "score": 19,
          "created_utc": "2026-01-15 18:30:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrxle0",
          "author": "DubGrips",
          "text": "I was ghosted many times recently:\n\n* A large insurance company ghosted me during the offer negotiations. I had counter offered within their range (not aggressively either). I was working with an HR rep, who didn't show up for our negotiation call and then I got an email saying my application had been withdrawn. The Hiring Manager had no idea.\n* AirBnB ghosted me twice for 2 different positions with 2 different teams. I had been told that I had passed the round and then the recruiter stopped replying.\n* I was ghosted by Pinterest in September. Same thing: passed the technical screen, never heard back. Recruiter reached back out Monday of this week to schedule the next round.\n* Completed the entire process with Block. Recruiter was supposed to schedule a call with me and the Hiring Manager to discuss offer terms. Never got a call, never got an email response.\n\nIt's hard to not blame myself in some of these cases, like the insurance example since I did counter-offer them, but ghosting is a shitty practice and becoming all too common. I highly doubt any company is using code from a case study for themselves if they actually have existing Data Scientists. What's really happening is that the market is flooded with good candidates and they don't give a fuck about burning a bridge with you because someone just as good or possibly better will come along.",
          "score": 29,
          "created_utc": "2026-01-15 18:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs0hmq",
              "author": "Lamp_Shade_Head",
              "text": "Oh man that‚Äôs just terrible! I wouldn‚Äôt imagine companies like Airbnb or Block would ghost people. Did you end up finding a new job though? Also is it cool if I message you? I may have a block interview coming up.",
              "score": 3,
              "created_utc": "2026-01-15 18:54:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsbjjx",
                  "author": "DubGrips",
                  "text": "Yes I did! Senior Staff role, solid team, good company size, good product. Glad I held out honestly. Feel free to message me. Honestly, I cannot recommend Block. I have known a few former employees that all left due to rampant toxicity and poor WLB. I interviewed with them because my MO is to never turn anything down until the very end and see for myself. I had pretty bad vibes from the HM and a few others I interviewed with. I think my stats were:\n\n* 5 months total searching\n* 52 companies\n* 100% pass rate on technical screens\n* 100% pass rate on technical take home exams\n* I \"failed\" 5 HM screens, but quite frankly it would have never worked due to personality differences so that's fine.\n* A few ghostings randomly in the middle of rounds, so I will never know\n* 85% pass rate on presentations. I think the failures were my fault: I was either too verbose or too succinct for the given audience.\n* 14 offer rounds. 9 of those were \"we promoted someone from the inside\" or \"we had another candidate\". It was really upsetting to hear when it was due to another candidate and I have looked several of the companies up to see who they hired. In retrospect I am glad it didn't work out as they hired people who were more junior in experience, but prolific on spam posting on Medium and LinkedIn about their knowledge despite never having been in an actual role for longer than 2 years and never in a Senior or Staff role for more than 1.5. Their loss, not mine.\n* 5 quality offers. I passed on one due to insanely short relocation turnaround, another was too junior of a role and it did not align, and the other pass just a role that I honestly don't think I would have been happy in. The remaining 2 are the one I accepted and the one I mentioned above when I was ghosted.",
                  "score": 9,
                  "created_utc": "2026-01-15 19:44:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu4zax",
              "author": "RecognitionSignal425",
              "text": "> I highly doubt any company is using code from a case study for themselves if they actually have existing Data Scientists\n\nNot the code, but the aha moment from candidates' ideas (especially those with domain experience) can be a new Jira ticket for the team testing.",
              "score": 2,
              "created_utc": "2026-01-16 01:09:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrt7zm",
          "author": "volkoin",
          "text": "they are just absolute mfckers",
          "score": 10,
          "created_utc": "2026-01-15 18:22:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvekwe",
          "author": "AccordingWeight6019",
          "text": "This is unfortunately common, especially when case studies are used as a low-cost filter rather than a serious evaluation step. In many teams, the hiring process is not well owned, so candidates end up doing real work without anyone feeling responsible for closing the loop.\n\nSaying no to case studies is reasonable, but it depends on how they are framed. I am more comfortable when the scope is clearly time-boxed, discussed live, and obviously synthetic. If it looks like unpaid consulting or has unclear evaluation criteria, that is usually a signal about how the team treats candidates and, often, employees.\n\nThe market does amplify this behavior, but it is also a reflection of weak hiring discipline. In my experience, teams that value rigor tend to be more respectful of candidate time as well.",
          "score": 5,
          "created_utc": "2026-01-16 05:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztsve4",
          "author": "Accomplished-Eye-813",
          "text": "Definitely the employer. The market is trash right now, but that's still no excuse.",
          "score": 2,
          "created_utc": "2026-01-16 00:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuyrst",
          "author": "glowandgo_",
          "text": "I've seen more as a company quality signal than just the market. ghosting after unpaid work usually means either weak process or no real ownership on their side. the trade off people don‚Äôt mention is that case studies are often used when they dont know how else to evaluate, which is already a smell. i‚Äôve started pushing back unless there‚Äôs real context, timebox, and feedback baked in. interesting that they reached out first too, that makes it worse. saying no filters out some noise, even if it shrinks the funnel.,,,",
          "score": 2,
          "created_utc": "2026-01-16 03:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvewqt",
          "author": "patternpeeker",
          "text": "That frustration is very justified. Case studies can be reasonable when they are tightly scoped and followed by real feedback, but in practice they often turn into free labor or a filtering step no one bothers to close the loop on. A lot of companies also underestimate how much time they are asking for, especially when they initiate the outreach. I have started pushing back by asking for time limits, context on how it is evaluated, and whether there will be a live discussion afterward. If they cannot answer that, it is usually a signal about how they treat candidates more generally.",
          "score": 2,
          "created_utc": "2026-01-16 05:46:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvfx2m",
          "author": "thinking_byte",
          "text": "Ghosting after a multi day case study is just bad behavior, market or not. Reaching out to you and then disappearing makes it worse. I have seen more people push back lately, either asking for a smaller scoped exercise or a live working session instead. It is usually a decent signal anyway, teams that respect your time tend to show it early. Saying no filters out some opportunities, but it also filters out a lot of nonsense.",
          "score": 2,
          "created_utc": "2026-01-16 05:53:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwemue",
          "author": "dataflow_mapper",
          "text": "That sucks, and you are not overreacting. Being ghosted after unpaid work is a bad look regardless of the market, especially when they reached out to you first. A lot of teams use case studies as a lazy filter and then fail at basic follow up. Saying no is reasonable, or at least setting boundaries like time boxing it or asking for a live walkthrough instead. The market is rough, but that does not mean you have to accept disrespect as the price of entry.",
          "score": 2,
          "created_utc": "2026-01-16 10:58:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxtgcl",
          "author": "Double-Count-7545",
          "text": "They got free work from you üòû",
          "score": 2,
          "created_utc": "2026-01-16 15:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzbnos",
          "author": "jingle-bell-dog",
          "text": "Even if the markets bad, seems like this company‚Äôs respect of people‚Äôs time and culture is lacking, you might have dodged a bullet. Or as others said they want free labor",
          "score": 1,
          "created_utc": "2026-01-16 19:53:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qflxse",
      "title": "How the Kronecker product helped me get to benchmark performance.",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/",
      "author": "vercig09",
      "created_utc": "2026-01-17 19:10:03",
      "score": 46,
      "num_comments": 18,
      "upvote_ratio": 0.87,
      "text": "Hi everyone,\n\n  \nRecently had a common problem, where I had to improve the speed of my code 5x, to get to benchmark performance needed for production level code in my company.\n\nLong story short, OCR model scans a document and the goal is to identify which file from the folder with 100,000 files the scan is referring to.\n\n  \nI used a bag-of-words approach, where 100,000 files were encoded as a sparse matrix using scipy. To prepare the matrix, CountVectorizer from scikit-learn was used, so I ended up with a 100,000 x 60,000 sparse matrix. \n\nTo evaluate the number of shared words between the OCR results, and all files, there is a \"minimum\" method implemented, which performs element-wise minimum operation on matrices of the same shape. To use it, I had to convert the 1-dimensional vector encoding the word count in the new scan, to a huge matrix consisting of the same row 100,000 times.\n\nOne way to do it is to use the \"vstack\" from Scipy, but this turned out to be the bottleneck when I profiled the script. Got the feedback from the main engineer that it has to be below 100ms, and I was stuck at 250ms. \n\nLong story short, there is another way of creating a \"large\" sparse matrix with one row repeated, and that is to use the [kron](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.kron.html#scipy.sparse.kron) method (stands for \"Kronecker product\"). After implementing, inference time got cut to 80ms. \n\n  \nOf course, I left a lot of the details out because it would be too long, but the point is that a somewhat obscure fact from mathematics (I knew about the Kronecker product) got me the biggest performance boost.\n\nA.I. was pretty useful, but on its own wasn't enough to get me down below 100ms, had to do old style programming!!\n\n  \nAnyway, thanks for reading. I posted this because first I wanted to ask for help how to improve performance, but I saw that the rules don't allow for that. So instead, I'm writing about a neat solution that I found. ",
      "is_original_content": false,
      "link_flair_text": "Coding",
      "permalink": "https://reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o09442e",
          "author": "AccordingWeight6019",
          "text": "this is a nice example of where understanding the underlying linear algebra and sparse representations pays off more than tuning at the surface level. a lot of performance issues in applied ML end up being data movement problems rather than model problems, and vstacking that many rows is a classic trap. using a Kronecker construction to express repetition without materializing it is a good illustration of thinking in operators instead of arrays. I also like that this came out of profiling rather than guessing. In production settings, that mindset often matters more than any single trick.",
          "score": 9,
          "created_utc": "2026-01-18 07:06:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0amtzv",
              "author": "vercig09",
              "text": "thanks for the feedback :)\n\nto be honest, I started writing a prompt asking AI where it sees improvements in code, and immediately realized how silly that was, and just used the cProfile, figured out pretty quickly where I should focus on :)",
              "score": 2,
              "created_utc": "2026-01-18 14:30:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0fhxhe",
                  "author": "AccordingWeight6019",
                  "text": "Exactly, profiling first is always the way to go. It is easy to get distracted chasing smarter algorithms when the bottleneck is really in data layout or memory movement. Sparse representations and knowing which operations are cheap versus expensive can make all the difference, and Kronecker products are a neat example of that.",
                  "score": 1,
                  "created_utc": "2026-01-19 05:48:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09oczz",
          "author": "patternpeeker",
          "text": "Nice writeup. This is a good example of the hard part not being the model, but how you move data around at scale. In practice, a lot of ML code misses benchmarks because of exactly this kind of hidden allocation or replication step. I have seen similar wins from avoiding explicit expansion and letting linear algebra do the work implicitly. It also highlights why profiling matters more than clever modeling once you are in production. Out of curiosity, did you consider alternatives like inverted indices or pruning before the comparison, or was the latency budget tight enough that you needed to stay fully vectorized?",
          "score": 3,
          "created_utc": "2026-01-18 10:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b9dil",
              "author": "vercig09",
              "text": "Thanks for the response. This was my first iteration, still have some ideas to explore. For example, this is a classic example of a task which can be processed in parallel, because comparisons are independent of one another, so I really want to see what impact parallel computation will have.\n\nInverted indices might also be an interesting approach, thanks for the idea :) \n\nDidn't want to prune yet, because I didn't have issues with memory and didn't want to lose information",
              "score": 1,
              "created_utc": "2026-01-18 16:23:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0902e3",
          "author": "Zahlii",
          "text": "Why not do something like \ncv = CountVectorizer(binary=True)\nx_docs = cv.fit_transform() # N Docs x Words\nx_ocr = cv.transform() # 1 x Words\nsim = x_ocr.dot(x_docs.T) # 1 x N Docs\n\nOn binary data the dot will evaluate to # Words common between ocr and each doc vector?",
          "score": 2,
          "created_utc": "2026-01-18 06:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ant8g",
              "author": "vercig09",
              "text": "very interesting, thanks for sharing. With the dot product, I was worried that it wouldn't be able to handle \"multiplicity\" (how many times each word appears). In other words, I was worried it would either:\n\n1. just count how many INDIVIDUAL words are shared (word either appears in both documents, or not), so 1 or 0 for each word,\n\n2. it would overcount how may times the word appears. For example, if \"banana\" appears in the OCR 3 times, and in the original document 3 times, I thought the dot product would give 9.\n\nLooking at the documentation for \"CountVectorizer\", this is written for the \"binary\" parameter:  \n  \n\"**binary** bool, default=False\n\nIf True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.\"\n\nSo, I'm worried about the #1 case, but I'll explore in more detail",
              "score": 1,
              "created_utc": "2026-01-18 14:35:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0aw1im",
                  "author": "Zahlii",
                  "text": "I think the ‚Äûovercount‚Äú can be solved by using e.g TfIdf or using l2 norm - this way similarities are guaranteed to be in [-1,1], and with tfidf you also get a weighting on more specialized tokens",
                  "score": 2,
                  "created_utc": "2026-01-18 15:19:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zzq1",
          "author": "glowandgo_",
          "text": "this is a good example of where the real win comes from understanding the underlying ops, not just swapping libs. the kron trick makes sense once you think about how sparse structure is represented, but it‚Äôs not something most people reach for by default. in my experience, perf issues at this scale are almost always about avoiding materialization rather than making one function faster. also appreciate the point about ai tools, they help explore options, but they rarely have the context to spot these mathy shortcuts. nice writeup, this kind of detail is way more useful than generic ‚Äúoptimize your code‚Äù advice.,,,",
          "score": 2,
          "created_utc": "2026-01-18 11:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0boery",
              "author": "vercig09",
              "text": "thanks for reading :)",
              "score": 1,
              "created_utc": "2026-01-18 17:35:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a7px3",
          "author": "and1984",
          "text": "This is excellent info.  Are you able to shed light on how AI was useful but old-school coding came to the rescue?",
          "score": 2,
          "created_utc": "2026-01-18 12:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b2yxs",
              "author": "vercig09",
              "text": "Thank you :)\n\nI use Github Copilot which makes me much faster at writing code. I never accept suggestions with more than 2 lines, because 2 lines is my limit for what I can check quickly for accuracy. Once I developed the initial method, AI helped me get the inference time from 2 seconds to roughly 0.5s, but then it started going into circles, either suggesting things that don't work or stuff that doesn't impact the execution time.\n\n  \nSince I had to get down to 100ms, I decided to drop my initial approach, which was basically a \"for\" loop (comparing the generated text with each record from DB individually), and to try vectorization/matrix operations.\n\n  \nI knew about scikit-learn, so I was reading the documentation until I stumbled upon [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#countvectorizer), which can encode all DB records into a single sparse matrix. Key calculation was finding the number of shared words between the scanned document and each record in the database, which can easily be done with the [minimum](https://docs.scipy.org/doc/scipy-1.16.2/reference/generated/scipy.sparse.csr_matrix.minimum.html) function. The only thing missing was how to quickly run this function, because it requires two matrices of the same shape, but the OCR results is only a 1-dimensional sparse matrix. In order to generate a large matrix, AI suggested [vstack](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.vstack.html), which worked and got me down to roughly 250ms, without impacting accuracy. I ran the cProfile profiler on my script, and noticed that the vstack took the most time to execute, so I needed to cut it down. I was thinking about how to construct a large matrix where 1 row is repeated a number of times, reading scipy.sparse docs, looking for another option, and was very happy to see that the Kronecker product was implemented: [LINK](https://docs.scipy.org/doc/scipy-1.16.2/reference/generated/scipy.sparse.kron.html).\n\n  \nOverall, AI was pretty good, and it might have done more with better prompting, but I needed a significant change in approach, and I felt like I was just going in circles with AI, so had to rely on my own neural network",
              "score": 1,
              "created_utc": "2026-01-18 15:53:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bemt4",
          "author": "yaksnowball",
          "text": "Embed the content of the files with a sentence transformer, store the resulting embeddings in an index e.g using FAISS and do ANN retrieval to get the most similar files to the new OCR scan. It will be almost instant if you are just searching with 1 document. I guarantee less than 10ms easily.\n\nSparse lexical retrieval is very inconvenient for large amounts of documents hence why people have traditionally resorted to things like ElasticSearch or Apache SOLR to do this type of thing.",
          "score": 2,
          "created_utc": "2026-01-18 16:48:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bod84",
              "author": "vercig09",
              "text": "fair, thanks for the suggestion. wanted to first try this because some documents contain unique IDs, which can help immensely to determine the right card (but not every document has an ID as part of its contents), and I thought that this information would be lost in embedding (what would JFDOSDFF9358K be similar to).\n\nI definitely want to test embeddings, but first want to set the best \"time to beat\". I'm still counting on improvements from parallel computing",
              "score": 1,
              "created_utc": "2026-01-18 17:34:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kq6be",
          "author": "Dizzy-Midnight-6929",
          "text": "Thanks for sharing! Love these performance tricks",
          "score": 2,
          "created_utc": "2026-01-20 00:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bwjc7",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 1,
          "created_utc": "2026-01-18 18:12:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09ichl",
          "author": "nian2326076",
          "text": "I‚Äôve seen a lot of confusion and outdated info around Meta‚Äôs Data Scientist (Analytics) interview process, so I put together a practical, up-to-date playbook based on real candidate experiences and prep patterns that actually worked.",
          "score": -3,
          "created_utc": "2026-01-18 09:15:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd7eq3",
      "title": "Google DS interview",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qd7eq3/google_ds_interview/",
      "author": "No-Mud4063",
      "created_utc": "2026-01-15 02:34:52",
      "score": 31,
      "num_comments": 33,
      "upvote_ratio": 0.74,
      "text": "Have a Google Sr. DS interview coming up in a month. Has anyone taken it? tips?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qd7eq3/google_ds_interview/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzo6p6x",
          "author": "snowbirdnerd",
          "text": "I interviewed for a senior position with them 3 or 4 years ago. Studied for a couple of months, spent over a month interviewing with them. Was essentially promised the position and then next thing I heard was that the position has been terminated and they were no longer hiring for it.\n\n\nHopefully your experience goes better.¬†",
          "score": 72,
          "created_utc": "2026-01-15 04:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr8dhc",
              "author": "No-Mud4063",
              "text": "That sucks. Google seems like a good place to work with a good wlb",
              "score": 10,
              "created_utc": "2026-01-15 16:48:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0e3fv9",
              "author": "AdMysterious4157",
              "text": "That‚Äôs¬†really¬†unfortunate¬†‚Äî¬†I¬†didn‚Äôt¬†realize¬†this¬†happens¬†at¬†Google¬†too.",
              "score": 2,
              "created_utc": "2026-01-19 00:45:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs439f",
              "author": "Bloodrazor",
              "text": "Similar thing happened to me.  I had a referral and had interviews scheduled but then was told that there were 2 internal candidates that have moved far into the hiring process.  The recruiter then told me there was another opening at the same level that would be out in the next week.  After I followed up, they moved forward with a junior internal candidate.",
              "score": 1,
              "created_utc": "2026-01-15 19:10:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzofup9",
              "author": "timusw",
              "text": "What‚Äôd you prepare for? How‚Äôd you do it? What types of coding and technical questions did they ask",
              "score": 1,
              "created_utc": "2026-01-15 05:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzorlba",
                  "author": "snowbirdnerd",
                  "text": "What you need to study will depend on what part of the company you will be joining. I think the position I was applying for was something like loyalty economist. It was a statistics and experiment design heavy position which is essentially what I studied for my masters.¬†\n\n\nI brushed up on my general skills like SQL, Python, and Machine Learning, and then a deep dive into DOE.¬†\n\n\nThe first couple of interviews were essentially coding tests using Google Docs. They wanted to see how well you knew syntax from memory.¬†One interview was just about performing A/B testing and some basic DOE concepts.¬†\n\n\nTheir also was a case study where I had to talk through how to workout the problems with an existing system and what experiments I would run to determine the root cause.¬†\n\n\nAfter that it was just some culture and get to know people interviews.¬†\n\n\nI was pretty excited when they told me to expect an offer letter and crushed when I received the notification about the position being terminated.¬†\n\n\nThat was the last time I ever considered interviewing for a FAANG.¬†",
                  "score": 28,
                  "created_utc": "2026-01-15 06:49:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzocz79",
          "author": "KitchenTaste7229",
          "text": "Been some time since I took it, but I recall the SQL and Python questions being pretty standard (I'd say around medium-difficulty?). The behavioral questions were a bit tough ‚Äì but that's probably because I didn't invest more time into preparing for them, so make sure your prep's balanced. Also, my biggest struggle was the machine learning/applied modeling round; I didn't get enough practice whiteboarding & I may have missed being clear about trade-offs and constraints. Make sure to brush up on common [Google interview questions](https://www.interviewquery.com/interview-guides/google-data-scientist) for product sense/cases too, good luck!",
          "score": 19,
          "created_utc": "2026-01-15 04:54:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqhdme",
          "author": "citoboolin",
          "text": "research or product DS? If product, expect mostly SQL questions, if research, some python for sure. Then your standard data/ML fundamentals/statistics questions. I have only interviewed for a junior position though",
          "score": 12,
          "created_utc": "2026-01-15 14:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00s8ri",
              "author": "FinalRide7181",
              "text": "Not OP, i have just a quick question: do you need a phd for DS research or a pure master in math? I mean is master in cs (ml/dl/stats exams) and previous experience as data scientist enough?",
              "score": 1,
              "created_utc": "2026-01-17 00:16:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00vca7",
                  "author": "citoboolin",
                  "text": "everyone ive met that is ds research had a phd. from job postings ive seen they do make exceptions but you probably need a decent publication record and/or start as ds product and do an internal transfer or something",
                  "score": 1,
                  "created_utc": "2026-01-17 00:34:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzr8808",
              "author": "No-Mud4063",
              "text": "Research",
              "score": 1,
              "created_utc": "2026-01-15 16:48:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvuo5l",
          "author": "neo2551",
          "text": "For research:¬†\n\n- Python, nothing crazy but the trick is you have to code without any IDE help. Typical, map, filter, reduce operations with standard data structure (dicts, list, tuple, set).\n- Statistics: please, master stats 101, like seriously, the interview is a mixture of university exam question and how you would solve a real problem. The real challenge is about which topic you will get, ask for your HR contact to narrow down what you should know.\n\nSource: I went (successfully) through both product and research interview processes.",
          "score": 10,
          "created_utc": "2026-01-16 07:56:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00s84v",
              "author": "FinalRide7181",
              "text": "Not OP, i have just a quick question: do you need a phd for DS research or a pure master in math? I mean is master in cs (ml/dl/stats exams) and previous experience as data scientist enough?",
              "score": 1,
              "created_utc": "2026-01-17 00:16:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o02ck4b",
                  "author": "neo2551",
                  "text": "The only way to know is to interview: as I said, it is a fairly academic process with transparent content.\n\nReally my best advice is to master the basics of statistics and fundamentals. This might not give you the job, but for sure is a necessary condition.\n\nI know many DS researcher who had a political science and economics degree, in the end, Google decides who to hire based on interview performance, not degrees.\n\nThe trick is to get in the interview pipeline first.",
                  "score": 2,
                  "created_utc": "2026-01-17 06:37:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzshm3e",
          "author": "akornato",
          "text": "They'll push you hard on SQL and coding (expect LeetCode medium problems at minimum), statistical fundamentals, product sense, and your ability to design experiments and measurement frameworks. The bar is legitimately high, and you'll need to be sharp on all fronts. That said, a month is actually plenty of time to prepare if you're strategic about it. Focus on practicing common [Google data science interview questions](https://www.interviews.chat/questions/google-data-scientist) that cover A/B testing scenarios, metric design, and how you'd approach ambiguous business problems. Get comfortable explaining your thought process out loud since they care as much about how you think as what you know.\n\nThe good news is that Google's interview structure is fairly predictable, and there's tons of information available from others who've been through it. You should be drilling SQL queries daily, revisiting probability and statistics fundamentals, and doing mock interviews where you talk through case studies. The product sense rounds can feel intimidating, but they're really just testing if you can think like a data scientist who partners with product teams - how would you measure success for a feature, what metrics matter, what could go wrong. If you put in focused preparation over the next few weeks, you'll walk in ready. This is absolutely doable for someone at the senior level - just treat the prep like a sprint, not a marathon.",
          "score": 3,
          "created_utc": "2026-01-15 20:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsz8zu",
              "author": "No-Mud4063",
              "text": "i don't think they will ask for LC DSA. do they?",
              "score": 2,
              "created_utc": "2026-01-15 21:34:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzy40tr",
                  "author": "rahultach",
                  "text": "No they don‚Äôt, I don‚Äôt understand why people would want to answer questions they have no clue about and mislead folks on top of it",
                  "score": 2,
                  "created_utc": "2026-01-16 16:38:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzy3rqd",
              "author": "rahultach",
              "text": "If ever there was a confidently incorrect answer. They don‚Äôt ask Leetcode DSA type questions for Google DS interviews.",
              "score": 1,
              "created_utc": "2026-01-16 16:37:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0apv56",
              "author": "Helpful_ruben",
              "text": "u/akornato Error generating reply.",
              "score": 1,
              "created_utc": "2026-01-18 14:47:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxnt9i",
          "author": "dlchira",
          "text": "About 10-15 years ago a \"How to interview at Google\" list made the rounds online. One of the points that always stuck with me (for every interview setting, not just Google) was, \"Be honest about your skills. If you say you're a 10/10 in Python, we'll have Guido van Rossum interview you. Seriously.\"",
          "score": 1,
          "created_utc": "2026-01-16 15:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g2z6q",
          "author": "BayesCrusader",
          "text": "I did it a few years ago in Europe, and it was entirely stats questions. That could be due to my training though.\n\n\nThey seemed particularly interested in one of my past papers, so I think that's how I got noticed.\n\n\nI did terribly - just bricked it! It's definitely a challenging process, but the rewards look pretty amazing.¬†",
          "score": 1,
          "created_utc": "2026-01-19 08:50:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvo7un",
          "author": "boroughthoughts",
          "text": "I mean grind stata scratch SQL questions and look at the job description. Its going to differ by segment. I would imagine some data scientist are doing experimentation work and you'd probably awnt to know A/B testing etc. Others might be more stats/ml oriented. Its tech they probably have structured process. I will say that my recent tech data science interview have usually included one algorithm style leet code questions, which is usually what stumped me. Also google puts a six month cool down period if you fail.",
          "score": 1,
          "created_utc": "2026-01-16 07:00:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwll4v",
          "author": "keshaann",
          "text": "It's great that you have a Google Sr. DS interview coming up. Focusing on data structures, algorithms, and system design will be crucial, so consider reviewing key concepts and practicing coding problems relevant to the role.",
          "score": -2,
          "created_utc": "2026-01-16 11:53:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcp6k6",
      "title": "How far should I go with LeetCode topics for coding interviews?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qcp6k6/how_far_should_i_go_with_leetcode_topics_for/",
      "author": "Lamp_Shade_Head",
      "created_utc": "2026-01-14 14:49:18",
      "score": 25,
      "num_comments": 24,
      "upvote_ratio": 0.81,
      "text": "I recently started doing LeetCode to prep for coding interviews. So far I‚Äôve mostly been focusing on arrays, hash maps, strings, and patterns like two pointers, sliding window, and binary search.\n\nShould I move on to other topics like stacks, queues, and trees, or is this enough for now?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qcp6k6/how_far_should_i_go_with_leetcode_topics_for/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzjqg9u",
          "author": "hyperbola7",
          "text": "Companies do not restrict asking just some data structures. So you need to practice all types of questions ideally. Check the company tags to see what data structures your target company focuses more on.",
          "score": 23,
          "created_utc": "2026-01-14 14:55:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjxeo0",
              "author": "Lamp_Shade_Head",
              "text": "Gotcha, thank you!",
              "score": 2,
              "created_utc": "2026-01-14 15:29:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzlbzn4",
          "author": "ReferenceThin8790",
          "text": "AI Engineer: leetcode/neetcode DSA, up to heap and priority queues. The neetcode roadmap is pretty solid.\n\nData Scientist: leetcode pandas. Compliment with CodeSignal ML.",
          "score": 18,
          "created_utc": "2026-01-14 19:17:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv9mzy",
              "author": "sharklight-22",
              "text": "Adding to this, would recommend to go through Striver‚Äôs DP series particularly if you are planning to appear for FAANGs",
              "score": 3,
              "created_utc": "2026-01-16 05:09:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzl071n",
          "author": "michaeldoesdata",
          "text": "I would focus on knowing real skills and not how to solve stupid arbitrary puzzles.",
          "score": 14,
          "created_utc": "2026-01-14 18:24:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp7nu6",
              "author": "MadT3acher",
              "text": "Recruiter: so do you know Fizzbuzz?",
              "score": 7,
              "created_utc": "2026-01-15 09:19:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzv2w97",
              "author": "ice-truck-drilla",
              "text": "I've been in the r/cscareerquestions subreddit for a while, and man this comment is such a breath of fresh air. I should've checked out this subreddit sooner.",
              "score": 1,
              "created_utc": "2026-01-16 04:24:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzl93kn",
          "author": "Alarming_Concert_808",
          "text": "At some point the exact topic list matters less than being able to apply what you already know when it‚Äôs live. People cover all the right areas and still blank once they‚Äôre on a call explaining things out loud. I would even suggest you use interviewcoder or smth to cheat/just to stay oriented if their brain locks up. Studying more topics doesn‚Äôt always fix that part",
          "score": 7,
          "created_utc": "2026-01-14 19:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk4ezi",
          "author": "DubGrips",
          "text": "I was interviewing for Senior Staff and Principal level roles recently. I believe I had interviews with 52 companies, made the final round 14 times, 6 offers. I was never given a single leetcode problem. The closest I experienced was a so-so company asking me to write a K Means function from scratch but they also let me use Google.",
          "score": 9,
          "created_utc": "2026-01-14 16:01:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkaybm",
              "author": "jmomoney44",
              "text": "Was the process more talking through your mental approach then?",
              "score": 2,
              "created_utc": "2026-01-14 16:31:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkwrdp",
                  "author": "DubGrips",
                  "text": "Usually it was a lot more detailed case study deep dives where we discussed more complicated experimentation or modeling problems where experience and domain expertise matter more than if you can just do fairly basic coding or memorize random gotchas.",
                  "score": 8,
                  "created_utc": "2026-01-14 18:09:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzns60r",
          "author": "AccordingWeight6019",
          "text": "It depends a lot on the kinds of roles you are targeting and how interview-heavy they are. For data science and applied ML roles, arrays, hashing, and basic patterns cover a surprising amount of what actually comes up. Trees and graphs show up less often, but when they do, interviewers usually expect conceptual comfort rather than deep algorithmic tricks. I would prioritize being fluent at explaining your thinking and trade-offs over expanding into every topic. In practice, weak communication around simple problems hurts more than not knowing an obscure structure. If you do branch out, stacks and queues are usually the highest return before going much deeper.",
          "score": 1,
          "created_utc": "2026-01-15 02:41:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo4gn9",
          "author": "OneWolverine307",
          "text": "Know enough basics esp of SQL and Python where you can answer simple questions but before leetcode have some foundational knowledge.",
          "score": 1,
          "created_utc": "2026-01-15 03:56:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzubvvp",
          "author": "somyis",
          "text": "i think sticking to \"easy\" should be good for now, especially because of how much more they tend to focus on viz tools and stats",
          "score": 1,
          "created_utc": "2026-01-16 01:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv2my9",
          "author": "ice-truck-drilla",
          "text": "Personally, I stopped doing leetcode and still have a great job. I got it through a process of 2 interviews where we just spoke about my experiences and how they relate to the research my company was pursuing at the time. \n\nLeetcode is just memorizing short solutions to problem classes in the form of minimum examples. I think it has some marginal time-saving utility, but in truth I think it's a waste of time and doesn't build any important skills. I would much rather just look at a candidate's transcript and discuss what they learned in their coursework, which projects they've enjoyed, etc. I don't want some weird stressful interview process that incentivizes lying to outcompete other applicants.  \n\nI think the interview process of typical workplaces have become incredibly disrespectful to candidates and I prefer to not be a part of it.",
          "score": 1,
          "created_utc": "2026-01-16 04:22:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o014pyo",
          "author": "thinking_byte",
          "text": "What you have already covers a big chunk of what actually comes up. I‚Äôd add stacks and basic trees, not to go deep, but to be comfortable reading and modifying solutions. For data roles, interviews often care more about how you reason through data transformations and edge cases than exotic algorithms. I‚Äôve seen people over-index on grinding LeetCode and under-prepare for explaining trade-offs or debugging imperfect code. If you can solve medium problems in those core areas and talk clearly about your approach, you‚Äôre in good shape. Trees beyond basics usually have diminishing returns unless the role is very algorithm-heavy.",
          "score": 1,
          "created_utc": "2026-01-17 01:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkcrdq",
          "author": "Equal-Agency4623",
          "text": "If you‚Äôre preparing for MLE or ML Scientist interviews, you have to cover all the topics, including stacks, trees and queues. But if you‚Äôre interviewing for DS Analytics jobs, then you can stop at arrays, hash maps and strings.",
          "score": 1,
          "created_utc": "2026-01-14 16:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkwxap",
              "author": "DubGrips",
              "text": "In 13 years I've never been asked about any of this stuff and I've interviewed with and had offers at 5 of the \"Magnificent 7\".¬†",
              "score": 6,
              "created_utc": "2026-01-14 18:10:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlk5mq",
                  "author": "Equal-Agency4623",
                  "text": "What job titles did you interview for?",
                  "score": 3,
                  "created_utc": "2026-01-14 19:54:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzkqtl3",
              "author": "busybody124",
              "text": "I've never been asked about stacks, trees, queues, graphs, or DP in an MLE or DS interview. These questions are going to be more common for intro and mid-level general SWE roles.",
              "score": 1,
              "created_utc": "2026-01-14 17:43:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzks7wf",
                  "author": "Equal-Agency4623",
                  "text": "If you haven‚Äôt been asked those questions, then you haven‚Äôt interviewed for MLE or Applied Scientist roles in FAANGs or other big tech companies. Or you were just lucky to get an interviewer that didn‚Äôt care about it (which is rare).",
                  "score": 2,
                  "created_utc": "2026-01-14 17:49:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhiw2d",
      "title": "What signals make a non-traditional background credible in analytics hiring?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qhiw2d/what_signals_make_a_nontraditional_background/",
      "author": "DataAnalystWanabe",
      "created_utc": "2026-01-19 22:26:50",
      "score": 23,
      "num_comments": 16,
      "upvote_ratio": 0.81,
      "text": "I‚Äôm a PhD student in microbiology pivoting into analytics. I don‚Äôt have a formal degree in data science or statistics, but I do have years of research training and quantitative work. I‚Äôm actively upskilling and am currently working through DataCamp‚Äôs Associate Data Scientist with Python track, alongside building small projects. I intend on doing something similar for SQL and PowerBI. \n\nWhat I‚Äôm trying to understand from a hiring perspective is: What actually makes someone with a non-traditional background credible for an analytics role?\n\nIn particular, I‚Äôm unsure how much weight structured tracks like this really carry. Do you expect a career-switcher to ‚Äúcomplete the whole ladder‚Äù (e.g. finish a full Python track, then a full SQL track, then Power BI, etc.) before you have confidence in them? Or is credibility driven more by something else entirely?\n\nI‚Äôm trying to avoid empty credential-collecting and focus only on what materially changes your hiring decision. From your perspective, what concrete signals move a candidate like me from ‚Äúinteresting background‚Äù to ‚Äúthis person can actually do the job‚Äù?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qhiw2d/what_signals_make_a_nontraditional_background/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0koeft",
          "author": "dlchira",
          "text": "Computational neuroscience PhD who hires for DS roles weighing in. Structured data-science programs are not necessarily superior (and in many ways can be *inferior*) to highly quantitative STEM fields in terms of DS skills. Often it's up to the student to steer their experience in the lab toward computational approaches, big-data analytics, etc. If you're on a microbiology PhD track, you'll likely find yourself doing data collection, statistical analyses, problem solving, project management, etc. at a high level as a threshold of satisfying your course requirements, publishing in peer-reviewed journals, and defending your dissertation. What will set you apart if you want to be a DS *outside* the normal industries into which microbio PhDs tend to gravitate is your ability to link those skills to the business cases that your target industry cares about.\n\nI would **not care** if you finished some micro-certification on Data Camp or similar. That's pure noise, IMHO. As a STEM PhD I would want to read your publications and discuss your methods in the context of my industry.",
          "score": 19,
          "created_utc": "2026-01-20 00:02:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k95sj",
          "author": "Atmosck",
          "text": "I left a PhD program (math, and in particular NOT statistics) to become a data scientist. I credit every job I've gotten to having relevant personal projects I could talk intelligently about in interviews.\n\nFrom the other side of the zoom call, you're never going to find someone with all the skills you want when hiring for an entry or mid level role, so you don't really expect to. This is especially true when it comes to cloud tech, since that's so provider-specific. It just doesn't make sense to learn GCP, AWS and Azure before you have a job that needs one of them. What you're looking for when hiring is someone you think could learn what they need to know for the role.",
          "score": 21,
          "created_utc": "2026-01-19 22:41:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kaom9",
          "author": "MattDamonsTaco",
          "text": "I have a terribly non-standard background and I am a Senior DS and have worked in consulting, international banking, healthcare, FAANG, and more, all as a DS. I've been working specifically as a DS since 2015 but was working as a \"biometrician\" at a boutique environmental stats firm before that.\n\nEverything beyond my MS was in research, field work, and writing technical papers for peer review in fish and wildlife. I was an R expert (and still am, kinda) and although was not \"officially\" a statistician, I had a *very* deep background in mathematical modeling and frequentist stats. When I made the conscious decision to jump to \"industry\" instead of doing environmental work, I had the basics of SQL in my back pocket, thanks to having done a ton of data management at my boutique environmental firm.\n\n**What got me hired first was not the skillz but more how I approached a problem.** Bringing a different skill set to an organization is often times EXACTLY what a hiring manager wants, particularly if they get the signal that you're smart and can learn quickly. This is really all that matters: be smart and learn quickly and be able to show that you are or can do both. \n\nBe able to talk about models you know and how you could apply them. (For example, I applied nesting site fidelity models from sage grouse populations to predicting whether or new patients would return to a specific hospital. Same problem, different data and biz questions.) Be able to talk about how you apply stats. Be able to show how you write functions and think about how a model you've built locally could be handled by DevOps (or yourself) and moved into prod in \\[insert cloud provider of choice\\].\n\nAlthough Python is pretty much the currency of DS these days, there are still some R shops around and there are some good hiring managers left who are toolset agnostic, so long as the work is good and can be productionized. Python is easier to productionize and if you're already an R person, is pretty easy to pick up. Syntax differences can be funky, but aren't insurmountable.\n\nFeel free to reach out via DM with specific questions if you think I can help!",
          "score": 10,
          "created_utc": "2026-01-19 22:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0l0jgm",
          "author": "EsotericPrawn",
          "text": "I always look at anyone with an advanced research degree in the sciences when I look for data scientists. The ability to understand how to ask a research question and how to draw conclusions (or not) from data are, at least IMO, the hardest necessary skills to teach for a data science job. I also assume if you‚Äôre a PhD level researcher you have some level of coding experience.",
          "score": 3,
          "created_utc": "2026-01-20 01:08:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lbpv2",
          "author": "goodyousername",
          "text": "Im a DS Director. I look for people who are good at math. I don‚Äôt really care how they came about their math training, but to understand how the MO algorithms work is important for us. I do think most or all of our team has at least one degree in math or statistics, but we‚Äôve had a physicist, Econ and a comp sci PhD in the past. If they can carry a conversation about the linear algebra involved in ML, or how MLE works, that‚Äôs probably good enough for me.",
          "score": 2,
          "created_utc": "2026-01-20 02:09:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lhozd",
              "author": "anxiousnessgalore",
              "text": "So I would say that all of this comes when one is able to land an interview. Butting in here because I'm curious how one can signal that they *can* be interviewed for an open role based on a resume submitted online? (I also have a BS and MS in computational math, but I've struggled to land any interviews at all for data focused roles)",
              "score": 2,
              "created_utc": "2026-01-20 02:41:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0lq0be",
                  "author": "goodyousername",
                  "text": "Yeah good point, landing the interview in the first place is super competitive. We have one opening right now, and we closed to new applications after we hit 2400. So I did look for key phrases when narrowing down resumes, like ‚Äúmaximum likelihood‚Äù and ‚Äúlinear algebra‚Äù and several others. Then I‚Äôd look through all the returns and evaluate manually. So from that story, having some specific terminologies on the resume that align with ML foundations would have been helpful in this case. More generally though, I‚Äôm sure every hiring manager has different preferences so this can be a very hard thing to optimize.\n\n‚ÄúGeneralized Linear Model‚Äù or GLM was another term, for example, because it aligns closely with the work we do. Less than 20 people had that specific experience listed.",
                  "score": 1,
                  "created_utc": "2026-01-20 03:28:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0k8vkc",
          "author": "Single_Vacation427",
          "text": "If you are doing a PhD, saying that you are going to be able to do DS because you did DataCamp is going to be laughable. It's like trying to learn microbiology because you did some silly online certification.\n\nYou are still a student. Most universities have certifications in something useful that grad students can take, many places you can use your credits for a masters in a different field (albeit related) instead of using them for a masters in your field.\n\nYou could also take classes in statistics, etc. It's typically covered by the tuition remission. unless you are in some shitty program.\n\nI don't know about microbiology, but I'm assuming there has to be a subfield that's more based on experiments or modeling.\n\nThere are also some summer programs for PhD students on data science that have scholarships. Erdos institute has one but it's not the only one.",
          "score": 3,
          "created_utc": "2026-01-19 22:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kq7j8",
          "author": "varwave",
          "text": "Pick up a MS in biostatistics en route to the PhD or at least take the mathematics statistics sequences and some classes on applied uses of generalized linear models. Why not write your dissertation in something data heavy? Are you already studying in a medical center? If so network! Throwing out domain knowledge is pretty silly. \n\nGet good at programming. R might make more sense than Python in life sciences. Learn both. There‚Äôs so many opportunities to contribute to open source software in life sciences \n\nI work at a research hospital as a software developer with an emphasis on data. The PhDs in hospitals usually make more money in research than an entry data analyst. Working with collaborators that are statistically literate is a game changer in healthcare research",
          "score": 1,
          "created_utc": "2026-01-20 00:12:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lwz6v",
          "author": "thinking_byte",
          "text": "From the hiring side, the strongest signal is still applied work, not completed tracks. Structured courses are fine to build baseline skills, but they mostly answer ‚Äúdid you try‚Äù not ‚Äúcan you do the job.‚Äù What usually moves someone from interesting to credible is a small number of projects where the problem, data cleaning, assumptions, and decisions are clearly explained, ideally tied to a real question. Your research background actually helps a lot if you frame it as hypothesis driven analysis and messy data handling. I‚Äôve never expected a career switcher to finish every ladder, I care more that they can take a vague question and turn it into a usable insight without hand holding.",
          "score": 1,
          "created_utc": "2026-01-20 04:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8ehu",
          "author": "AccordingWeight6019",
          "text": "In my experience, certificates mostly signal baseline effort, not readiness. What moves the needle is seeing you take a vague question, work with imperfect data, and explain your assumptions and limits clearly. Also, research background can be a strong positive if you frame it that way.",
          "score": 1,
          "created_utc": "2026-01-20 05:22:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mra0z",
          "author": "Radiant-Composer2955",
          "text": "I pivoted from process technology and work ds occupations in the processing domain, in such niches the hiring is often less hard on ds skills if you have the business understanding of how to turn ds into profit.\n\nI would suggest finding a ds niche that is close to your phd work, do some private projects and focus on being able explain them to business people.",
          "score": 1,
          "created_utc": "2026-01-20 07:57:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nocgv",
          "author": "dataflow_mapper",
          "text": "From the hiring side, the biggest credibility signal is not finishing every possible course, it is evidence you can translate messy questions into analysis and explain the results clearly. A PhD already helps a lot there, especially if you can frame your research work in terms of data cleaning, assumptions, tradeoffs, and decision making. Structured tracks are fine to fill gaps, but nobody I know checks whether someone completed an entire ladder. One or two solid projects where you show end to end thinking, SQL pulls, Python analysis, and a clear takeaway matter way more. If you can talk through why you chose certain methods and what you would do differently with more time or data, that usually moves you from interesting to hireable.",
          "score": 1,
          "created_utc": "2026-01-20 12:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0np9gw",
          "author": "sharksnack3264",
          "text": "I'm in insurance data science. We basically do not care about the bootcamps. If you have a specifically data science degree we still are going to check your capabilities just the same as someone from a non traditional background because some programs don't have the technical rigor we need. Some of our best hires have come from academia grad programs and degrees.¬†\n\n\nWhat's most important is you have a solid foundation in applied maths and statistics and solid programming skills, can teach yourself new areas of statistics and programming well and quickly to keep up with the pace of change and that you have rock solid communication skills and can talk about technical ideas clearly and concisely to a range of audiences (from PhD backgrounds to someone whose last math class was in freshman year of undergrad). Subject matter expertise is important though. We teach it on the job, but with the current hiring environment someone who has that will always be a step ahead of anyone else.",
          "score": 1,
          "created_utc": "2026-01-20 12:49:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rwfho",
          "author": "MLEngDelivers",
          "text": "It depends on the role. If it‚Äôs a team that almost exclusively deploys stuff to prod, being a good programmer is #1, above ML knowledge for sure. \n\nIn rare cases, someone has been lacking but I‚Äôve made a bet on their intelligence and basically them being able to learn whatever in 90 days.",
          "score": 1,
          "created_utc": "2026-01-21 01:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ln9pn",
          "author": "Embiggens96",
          "text": "I'd prioritize experience with tools like power bi, tableau and stylebi over python and sql.",
          "score": -1,
          "created_utc": "2026-01-20 03:12:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd3z2h",
      "title": "Does anyone know how hard it is to work with the All of Us database?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qd3z2h/does_anyone_know_how_hard_it_is_to_work_with_the/",
      "author": "phymathnerd",
      "created_utc": "2026-01-15 00:04:42",
      "score": 18,
      "num_comments": 15,
      "upvote_ratio": 0.82,
      "text": "I have limited python proficiency but I can code well with R. I want to design a project that‚Äôll require me to collect patient data from the All of Us database. Does this sound like an unrealistic plan with my limited python proficiency?",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qd3z2h/does_anyone_know_how_hard_it_is_to_work_with_the/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzqdvql",
          "author": "dataflow_mapper",
          "text": "It‚Äôs not unrealistic, but there is a learning curve that has more to do with the platform than the analysis itself. Most of the friction comes from access controls, workbench setup, and understanding the data model rather than heavy Python work. You can absolutely stay R-first once you are inside the environment, plenty of people do.\n\nWhere Python tends to sneak in is for plumbing tasks or examples in the docs, not for the core analysis. If you are comfortable reading Python and tweaking snippets, you will probably be fine. The bigger investment is time spent getting approved, learning the cohort builder, and figuring out which tables actually answer your question.",
          "score": 3,
          "created_utc": "2026-01-15 14:26:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv0nq3",
          "author": "rteja1113",
          "text": "hey python is not that hard. I started my career with R, 11 years ago. Now, I extensively use python and I'm reasonably proficient at it. You can take help from Claude/ChatGpt to help you with that. These LLM tools are really good at writing python code for some reason. And also, I'm happy to collaborate as well if it's a personal project you are doing for fun.",
          "score": 2,
          "created_utc": "2026-01-16 04:09:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzovutu",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 4,
          "created_utc": "2026-01-15 07:27:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqeiya",
              "author": "pixieO",
              "text": "https://allofus.nih.gov/",
              "score": 1,
              "created_utc": "2026-01-15 14:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqq7l0",
          "author": "j262byuu",
          "text": "You shouldn‚Äôt have any issues. AoU does support R, but here are a few things to keep in mind:\n\nWatch your RAM: You can't increase the memory limit, so make sure your code is optimized and you aren't doing anything too memory-intensive.\n\nStick to Legacy: Don't use the new workspace they just launched last week. Stick to the legacy one for now.\n\nOMOP : AoU is based on a modified OMOP structure, so you can't just plug and play with standard OHDSI R packages.\n\nI personally found the demonstration workspaces very helpful, specifically the Nature Medicine step count one. Highly recommend checking that out as a template.",
          "score": 1,
          "created_utc": "2026-01-15 15:26:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznbunf",
          "author": "locolocust",
          "text": "If you can code well in R, you'd likely be able to pick Python up pretty quickly if you wanted to go that route. \n\nBut with that said, you can probably do it R fairly easily anyway. Just depends on what sort of API All of Us has.",
          "score": 1,
          "created_utc": "2026-01-15 01:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznotcq",
          "author": "dysregulation",
          "text": "Access to granular data will be a bigger hurdle than the coding, unless you‚Äôre already working with the data in an official capacity.",
          "score": 0,
          "created_utc": "2026-01-15 02:22:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpgxdw",
              "author": "Helpful_ruben",
              "text": "u/dysregulation Error generating reply.",
              "score": -4,
              "created_utc": "2026-01-15 10:47:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznpyx4",
          "author": "AccordingWeight6019",
          "text": "It depends on what you mean by work with it. The harder parts tend to be the access model, the data schema, and the analysis environment, not Python syntax itself. A lot of the workflow is opinionated and geared around their notebooks and tooling, which can be more friction than the actual modeling. If you are comfortable reasoning about messy clinical data and cohort definitions, the language gap is usually secondary. That said, you should expect some overhead translating examples and docs, since most are Python-first, so factor that into the project scope rather than assuming it is just a data pull and analysis step.",
          "score": 0,
          "created_utc": "2026-01-15 02:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznyvs0",
          "author": "Mr_iCanDoItAll",
          "text": "https://www.researchallofus.org/data-tools/data-access/\n\nI'd recommend just spending a couple of hours messing around trying to access the data and seeing if there's anything relevant for your project. You might not be able to access individual-level data though.",
          "score": 0,
          "created_utc": "2026-01-15 03:21:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzof8qq",
          "author": "patternpeeker",
          "text": "It is not unrealistic, but the difficulty is usually not Python syntax. In practice, working with All of Us is more about navigating access controls, data schemas, and the analysis environment than writing clever code. A lot of the workflow is constrained by their platform, and you end up adapting to how data is stored and queried rather than building things your own way.\n\nIf you are comfortable in R, that is usually fine for analysis and modeling. Where Python tends to show up more is in preprocessing pipelines or when you hit scale and performance limits. The harder part is understanding the cohort definitions, missingness, and clinical quirks in the data. Those issues will dominate your time more than the language choice.",
          "score": 0,
          "created_utc": "2026-01-15 05:10:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzonxvr",
          "author": "Independent-Row1545",
          "text": "I personally found it hard to work with massive datasets only because I use genomic data and it takes a looong time to just bring in the data to my working environment - but this might also just be me not knowing efficient codes. Otherwise I don‚Äôt find it that difficult if you already know how to code. Data access is documented pretty well.",
          "score": 0,
          "created_utc": "2026-01-15 06:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzornj8",
          "author": "SprinklesFresh5693",
          "text": "Python has plotnine which is a copy of ggplot2 and siuba which i believe is a copy of dplyr?",
          "score": -1,
          "created_utc": "2026-01-15 06:49:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh0m1y",
      "title": "Which role better prepares you for AI/ML and algorithm design?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/",
      "author": "Huge-Leek844",
      "created_utc": "2026-01-19 10:25:00",
      "score": 18,
      "num_comments": 6,
      "upvote_ratio": 0.91,
      "text": "Hi everyone,\n\nI‚Äôm a perception engineer in automotive and joined a new team about 6 months ago. Since then, my work has been split between two very different worlds:\n\n‚Ä¢ Debugging nasty customer issues and weird edge cases in complex algorithms\n‚Ä¢ C++ development on embedded systems (bug fixes, small features, integrations)\n\nNow my manager wants me to pick one path and specialize:\n\n1. Customer support and deep analysis\n   This is technically intense. I‚Äôm digging into edge cases, rare failures, and complex algorithm behavior. But most of the time I‚Äôm just tuning parameters, writing reports, and racing against brutal deadlines. Almost no real design or coding.\n\n2. Customer projects\n   More ownership and scope fewer fire drills. But a lot of it is integration work and following specs. Some algorithm implementation, but also the risk of spending months wiring things together.\n\nHere‚Äôs the problem:\nMy long-term goal is AI/ML and algorithm design. I want to build systems, not just debug them or glue components together.\n\nRight now, I‚Äôm worried about getting stuck in:\n\n\\* Support hell where I only troubleshoot\n\\* Or integration purgatory where I just implement specs\n\nIf you were in my shoes:\n\nWhich path actually helps you grow into AI/ML or algorithm roles?\nWhat would you push your manager for to avoid career stagnation?\n\nAny real-world advice would be hugely appreciated.\nThanks!\n\n",
      "is_original_content": false,
      "link_flair_text": "AI",
      "permalink": "https://reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0ggc2d",
          "author": "phoundlvr",
          "text": "Tell your boss your long term goals for your cater and ask their advice. Preface it with a statement acknowledging that you want to prepare yourself for your long term goal and that it‚Äôs okay that neither is the long term goal. Emphasize that you have a lot to learn and see both roles as valuable. \n\nBelieve it or not sharing long term career goals is a good thing, even if they‚Äôre outside of his team. Good managers will help you get there.",
          "score": 4,
          "created_utc": "2026-01-19 10:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hlztz",
          "author": "latent_threader",
          "text": "If your goal is AI/ML and algorithm design, the support-heavy path can help your intuition but it is easy to get pigeonholed there. You learn failure modes deeply, but you rarely get credit for creating new methods. The customer project path is usually better if you can negotiate real ownership of algorithm pieces instead of pure integration. I would push your manager for a hybrid role where you both design or prototype changes and then see them through deployment. Also ask explicitly how people on each path have moved into algorithm roles before. That answer tells you a lot.",
          "score": 2,
          "created_utc": "2026-01-19 15:22:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0poddu",
          "author": "eli_arad",
          "text": "Honestly, neither path really gets you to AI/ML. both sound like side quests that keep you ‚Äúuseful‚Äù but not growing. Debugging teaches pain tolerance, integration teaches patience, but neither builds real innovation muscle. If your manager actually cares about growth, they‚Äôd carve out time for R&D or internal prototyping, not force you to choose between two flavors of stagnation.",
          "score": 1,
          "created_utc": "2026-01-20 18:40:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gffuy",
          "author": "latent_signalcraft",
          "text": "if your goal is AI or algorithm design focus on which path gives you influence over problem framing and evaluation not just tasks. support work helps only if you are learning failure modes and shaping metrics otherwise it becomes reactive tuning. integration work helps only if you can question specs and validate whether the system actually works in the real world. i would push your manager for ownership of error analysis metric definition or design reviews because that is where algorithm designers are really developed.",
          "score": 1,
          "created_utc": "2026-01-19 10:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h6z3m",
          "author": "dataflow_mapper",
          "text": "If your end goal is AI/ML and algorithm design, I would bias toward the path that keeps you closest to building and modifying systems, even if it is not perfect. Deep support work teaches you how algorithms fail in the real world, which is valuable, but it can trap you in reactive mode with little room to design new things. Integration work at least keeps you writing code and understanding system boundaries, which is easier to evolve into ownership of algorithms later.\n\nThat said, the ideal move is usually not choosing one extreme. I would push your manager for explicit time or scope around algorithm ownership, even small pieces, validation logic, prototypes, or improvements rather than just glue work. Career stagnation tends to happen when your role stops producing artifacts that look like design or code. Debugging builds intuition, but building things is what usually gets you labeled as an algorithm engineer.",
          "score": 1,
          "created_utc": "2026-01-19 14:05:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8p3h",
          "author": "patternpeeker",
          "text": "If the goal is real AI or algorithm design, I would bias toward whichever path gets you closest to owning a problem end to end, even if the work feels less glamorous. Deep support work teaches you how and why algorithms fail in the wild, which is valuable, but it can stall if you never get to change the design that caused the failure. Pure integration has the opposite risk, you ship a lot but rarely make core decisions.\n\nIn practice, the people I see move into stronger ML or algorithm roles are the ones who combine failure analysis with proposing and implementing fixes. I would push your manager for a hybrid scope where you debug edge cases and then actually redesign or prototype changes, not just tune knobs or write reports. Titles matter less than whether you can point to concrete algorithmic decisions you made and systems you improved because of real-world behavior.",
          "score": 0,
          "created_utc": "2026-01-20 05:24:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi02sq",
      "title": "Safe space - what's one task you are willing to admit AI does better than 99% of DS?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qi02sq/safe_space_whats_one_task_you_are_willing_to/",
      "author": "Papa_Huggies",
      "created_utc": "2026-01-20 12:41:54",
      "score": 17,
      "num_comments": 63,
      "upvote_ratio": 0.59,
      "text": "Let's just admit any little function you believe AI does better, and will forever do better than 99% of DS\n\nYou know when you're data cleansing and you need a regex?\n\nYeah\n\nThe AI overlords got me beat on that.",
      "is_original_content": false,
      "link_flair_text": "AI",
      "permalink": "https://reddit.com/r/datascience/comments/1qi02sq/safe_space_whats_one_task_you_are_willing_to/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0nq0nt",
          "author": "PenguinSwordfighter",
          "text": "Creating LaTeX tables",
          "score": 79,
          "created_utc": "2026-01-20 12:54:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ohjyl",
              "author": "GamingTitBit",
              "text": "I actually have started using LaTeX again with AI. Hells no will I write it myself, but it does just look nicer!",
              "score": 10,
              "created_utc": "2026-01-20 15:23:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0qp8nq",
              "author": "Uncool_runnings",
              "text": "Latex in its entirety.\n\n\n20 page long notebook with vast numbers of graphs and tables?\n\n\n\"Turn this into a scientific report style latex document for me\"\n\n\nBeautiful.",
              "score": 5,
              "created_utc": "2026-01-20 21:30:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0r5phy",
                  "author": "sonicking12",
                  "text": "Do you write in Word and then use AI?",
                  "score": 2,
                  "created_utc": "2026-01-20 22:49:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0nq8t6",
          "author": "Radiant-Composer2955",
          "text": "- proper comments\n- documentation \n- write tests",
          "score": 121,
          "created_utc": "2026-01-20 12:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0obcgn",
              "author": "cy_kelly",
              "text": "I used it to generate unit tests for a project for the first time recently. Holy shit. Game changer. Some of them needed to be modified, it's not like you can just not review them, but it still saved me a *ton* of time and effort.",
              "score": 14,
              "created_utc": "2026-01-20 14:52:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0o1qr4",
              "author": "Empty_Search6446",
              "text": "READMEs it does okay but it is amazing for good docstrings",
              "score": 15,
              "created_utc": "2026-01-20 14:02:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0oojp4",
              "author": "Atmosck",
              "text": "Tests and docstrings sure, but hard disagree on comments. Unless you REALLY hold their hand about it, they produce way too many comments that are totally unnecessary, and often use didactic tone and 2nd person.",
              "score": 6,
              "created_utc": "2026-01-20 15:56:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0s98ev",
                  "author": "JimmyTheCrossEyedDog",
                  "text": "Agreed - I hate out of the box AI comments, they're so trivial.",
                  "score": 1,
                  "created_utc": "2026-01-21 02:29:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0nsn8n",
              "author": "OneBurnerStove",
              "text": "second the comments bit. I actually try to be more verbose yet concise and clear in key points with my comments now.\n\nWhich has led others to think the code was pure AI lol",
              "score": 6,
              "created_utc": "2026-01-20 13:10:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ras7i",
              "author": "Change-Able",
              "text": "Also proper variable and function naming",
              "score": 1,
              "created_utc": "2026-01-20 23:16:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nu8zr",
          "author": "MediumDrink12",
          "text": "I find most of the popular LLM are much better than the average DS when it comes to structuring ideas and concepts in an organized way.\n\nThis makes them an excellent tool for documentation but also investigating undocumented project which are so badly structured that the most expert MLE can't even figure out what the code is doing. It's a godsend when you are being asked to debug or even refactor some old project that no one is maintening.",
          "score": 36,
          "created_utc": "2026-01-20 13:20:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ohsxh",
              "author": "GamingTitBit",
              "text": "My only complaint is that they seem to hyper focus on multiple functions. Sometimes they write a function for the smallest thing that is only used within another function and doesn't need to be broken out and fragment your code. That and I've never seen an LLM choose to make a class instead of a function unless I explicitly tell it to",
              "score": 4,
              "created_utc": "2026-01-20 15:24:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rmk4b",
                  "author": "T_house",
                  "text": "Oh shit this might suddenly explain why I've seen code for papers in the last year or so with absolutely bonkers use of functions (regularly for minor things that are only done once, not really using arguments, and referencing global variables within the function itself)",
                  "score": 2,
                  "created_utc": "2026-01-21 00:21:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ox13n",
              "author": "amiles2233",
              "text": "I think this is the big one. It takes ideas that were normally just notebooks and structures them into more robust systems and packages. Nothing that wasn't doable prior, but was just very time consuming. I come from a statistical background not a software background, and when I'd try to architect these systems I'd make plenty of bonehead mistakes, LLMs quickly get my stuff to 'good enough' from a software perspective.",
              "score": 2,
              "created_utc": "2026-01-20 16:35:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ntbji",
          "author": "latent_threader",
          "text": "For me it‚Äôs turning vague stakeholder English into a first pass of SQL or pandas that actually runs. It‚Äôs rarely perfect, but it gets me 80 percent there faster than staring at a blank editor. I still don‚Äôt trust it with edge cases, but as a starting point it‚Äôs annoyingly good.",
          "score": 35,
          "created_utc": "2026-01-20 13:14:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nxutl",
              "author": "Zohan4K",
              "text": "I fucking love doing CTRL A,C,V into cursor everytime a stakeholder feels the need to narrate the story of mankind in an email rather than getting to the fucking point.",
              "score": 10,
              "created_utc": "2026-01-20 13:40:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0okvqz",
                  "author": "Greedy_Bar6676",
                  "text": "You ever get a pang of anxiety doing that, knowing that soon the stakeholder might just be asking an LLM instead of you?",
                  "score": 2,
                  "created_utc": "2026-01-20 15:39:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qtxa9",
              "author": "imamouseduhhh",
              "text": "Yes! I‚Äôve had a lot of luck using it to help me with stakeholder questions, but 0 luck in having stakeholders do it themselves - which I guess is good?",
              "score": 1,
              "created_utc": "2026-01-20 21:51:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nu8h0",
          "author": "nonamenomonet",
          "text": "Tbh I still don‚Äôt find LLM‚Äôs good enough for complicated data cleaning. It‚Äôs a good enough to start with but, I haven‚Äôt found it to be performant enough for all the edge cases.",
          "score": 9,
          "created_utc": "2026-01-20 13:20:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nv6db",
              "author": "MediumDrink12",
              "text": "I have found that if you are more explicit in what data issues you expect it to clean, it often times gives some good ideas along with some other less good ideas.\n\nI feel it's the most useful when you interact with it as if it was another human colleague. That means giving it enough context to grasp the issue you have and discuss with it instead of expecting it to find you the answer right away. I would expect a lot of people don't go beyond the first message though, as it is often very verbose.\n\nIt's also pretty good at piggy backing off your ideas. Sometimes I just have some vague idea of something and it will explore the idea deeper, suggesting improvements I haven't thought out.",
              "score": 4,
              "created_utc": "2026-01-20 13:25:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pdhkh",
              "author": "ogola89",
              "text": "Can you specify your use case here? I find this very difficult to accept as LLMs are kings at data cleaning though they can be heavy handed and make decisions you're not in line with having the company/project objectives in view.",
              "score": 1,
              "created_utc": "2026-01-20 17:51:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pdnzg",
                  "author": "nonamenomonet",
                  "text": "Cleaning addresses in CSV files mostly I actually created a package for it",
                  "score": 1,
                  "created_utc": "2026-01-20 17:52:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0o4dgb",
          "author": "kaladyr",
          "text": "Getting like 80% of the way there for visualizations, particularly animated visuals that stakeholders love but would take way too much of my time if I actually wrote out everything myself.",
          "score": 15,
          "created_utc": "2026-01-20 14:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oafc5",
              "author": "Pvt_Twinkietoes",
              "text": "Iterating through ideas. Getting to a simple MVP is way faster now.",
              "score": 1,
              "created_utc": "2026-01-20 14:47:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0s7mlj",
              "author": "SkipGram",
              "text": "Which program do you use for that? Like coding animations or powerpoint-type ones?",
              "score": 1,
              "created_utc": "2026-01-21 02:19:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0o62s9",
          "author": "ogola89",
          "text": "It does most things better than we are willing to admit. Short, complex tasks are where it excels. The only place it doesn't excell currently is things that take more memory and long term vision such as strategy, architecture, connections, taking into account edge cases in some data or identifying solutions to business logic.\n\nI've effectively become a middle manager of a junior DS who has dominated leet code and the math olympiad but can't find business opportunities as well as I can.\n\nCoding side, beats us hands down in speed and quality (data types, doc strings, organisation, algorithmic choice). Speaking for claude code here",
          "score": 8,
          "created_utc": "2026-01-20 14:25:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oquie",
              "author": "Commercial_Note_210",
              "text": "> It does most things better than we are willing to admit.\n\nI've been coming to terms with this in the last few weeks - coding assistants backed by Claude Code are significantly good. Parsing logs, any CLI command, any SQL writing, writing unit tests, documentation, and writing base code they just totally dominate. And I write shit prompts - not sure how good they would be with a good prompt.",
              "score": 3,
              "created_utc": "2026-01-20 16:07:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nwd08",
          "author": "ghostofkilgore",
          "text": "Anything that's basically a quick first pass at something, if you factor speed into it. For example, giving it an uncommented notebook and asking it to document or add comments. It'll do a good job of that extremely quickly. It'll probably have a better answer in a minute than 99% of DSs can do in an hour. The things is, that's where the AI ends. It won't create a better answer if you leave it for a day and ask again. A decent DS should be doing a better job than the AI if you give them a day to do the task.",
          "score": 3,
          "created_utc": "2026-01-20 13:32:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0onw10",
          "author": "Fun-Acanthocephala11",
          "text": "regex if you know how to prompt",
          "score": 2,
          "created_utc": "2026-01-20 15:53:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pxy4b",
          "author": "Iowatimetraveler",
          "text": "Organizing unstructured data.",
          "score": 2,
          "created_utc": "2026-01-20 19:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nos8a",
          "author": "Ok-Energy-9785",
          "text": "This doesn't make sense. Its like asking what does a truck do better than a babysitter. The two collaborate to make a quality product.",
          "score": 4,
          "created_utc": "2026-01-20 12:46:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ns4gd",
              "author": "nooptionleft",
              "text": "I know it's a humorous phrasing but now I'm curious what kind of final product (of whatever quality) could require a collaboration between a truck and a babysitter",
              "score": 11,
              "created_utc": "2026-01-20 13:07:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0nsc1c",
                  "author": "Ok-Energy-9785",
                  "text": "Transportation to the grocery store, to the doctor, to a play date, to McDonald's, going from point a to point b.",
                  "score": 3,
                  "created_utc": "2026-01-20 13:08:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0nru5b",
          "author": "Rootsyl",
          "text": "For documentation ai is a godsend.",
          "score": 1,
          "created_utc": "2026-01-20 13:05:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o5m0w",
          "author": "starfries",
          "text": "Yeah, they usually nail parsing code or do it way faster than I could.\n\n\nI won't say they get it right every time but I wouldn't have either.",
          "score": 1,
          "created_utc": "2026-01-20 14:22:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0odupl",
          "author": "Ibzclaw",
          "text": "Formatting for very basic stuff. Writing mermaid for fairly simple architectures.",
          "score": 1,
          "created_utc": "2026-01-20 15:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0og3nu",
          "author": "Nikkibraga",
          "text": "Readme.txt files",
          "score": 1,
          "created_utc": "2026-01-20 15:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qfd5k",
          "author": "Illustrious-Pound266",
          "text": "Coding.\n\nPeople don't want to admit it though because they feel threatened by it, so they rather live in ignorance bliss.",
          "score": 1,
          "created_utc": "2026-01-20 20:45:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qhhlr",
              "author": "Papa_Huggies",
              "text": "I still like to arrange all my workflows myself and I don't want it deciding which function to call etc. but things like a gross regex query or making a plt with all the labelling? You take it, robot",
              "score": 2,
              "created_utc": "2026-01-20 20:54:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qjrlz",
          "author": "koulourakiaAndCoffee",
          "text": "Create sample data and brainstorm.\n\nExample :  give me ten different ways to visualize this\n\nAnd also a second set if eyes .  Ask it to criticize your work.  \nAsk it to define it in laymen‚Äôs terms to .\n\nI give it 5 paragraphs of text and ask it ‚Äúhow can I explain this to explain how this will help a CEO in one sentence‚Äù",
          "score": 1,
          "created_utc": "2026-01-20 21:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qql31",
          "author": "pandasgorawr",
          "text": "Claude Code + Opus 4.5 absolutely destroys your average mid-career data scientist on coding, especially SQL and Python. 6-12 months more of improvements and I feel confident that it can do it better than 99% of DS. Instead of coding it's probably a better use of time to become a domain expert, and improve planning skills such as requirements gathering and writing pseudocode.",
          "score": 1,
          "created_utc": "2026-01-20 21:36:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qydw6",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 1,
          "created_utc": "2026-01-20 22:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qz7l0",
          "author": "Ok-Relation6854",
          "text": "Choosing good variable and dataframe names! üòÜ",
          "score": 1,
          "created_utc": "2026-01-20 22:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qzqxg",
          "author": "coffeecoffeecoffeee",
          "text": "Making matplotlib charts",
          "score": 1,
          "created_utc": "2026-01-20 22:19:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r1wvo",
          "author": "Imaginary-Corgi8136",
          "text": "Grammar and spelling and document review!",
          "score": 1,
          "created_utc": "2026-01-20 22:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r62p1",
          "author": "sonicking12",
          "text": "Better than Jamie Dimon on everything",
          "score": 1,
          "created_utc": "2026-01-20 22:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0raw9g",
          "author": "moonzl_rdt",
          "text": "Rapidly prototyping one-off code.   \nIf you need a script you're only going to use a few times, a quick visualisation to check something, etc. LLMs are ideal.",
          "score": 1,
          "created_utc": "2026-01-20 23:17:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rlsv9",
          "author": "DigoHiro",
          "text": "regex",
          "score": 1,
          "created_utc": "2026-01-21 00:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rs1nt",
          "author": "gBoostedMachinations",
          "text": "It produces basic code better than most of yall for sure haha.",
          "score": 1,
          "created_utc": "2026-01-21 00:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rtpip",
          "author": "canbooo",
          "text": "Brain storm (playing a rubber duck that talks back)",
          "score": 1,
          "created_utc": "2026-01-21 01:00:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ry9yq",
          "author": "zangler",
          "text": "Calculating... actually re-calculating sequential Bayesian posteriors...let it loose... discuss the results... boom... defensible model assumptions held in context and debated on contextualized merit... really fast.",
          "score": 1,
          "created_utc": "2026-01-21 01:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rynq6",
          "author": "Hertigan",
          "text": "The god damn plotly syntax\n\nAlso regex",
          "score": 1,
          "created_utc": "2026-01-21 01:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s3jfl",
          "author": "orz-_-orz",
          "text": "Regex, a really really complex regex",
          "score": 1,
          "created_utc": "2026-01-21 01:56:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s9hn6",
          "author": "inkeep",
          "text": "Creating MVPs for simulators and scenario planners.",
          "score": 1,
          "created_utc": "2026-01-21 02:30:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf9zxw",
      "title": "Is LLD commonly asked to ML Engineers?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/",
      "author": "FinalRide7181",
      "created_utc": "2026-01-17 10:36:09",
      "score": 16,
      "num_comments": 24,
      "upvote_ratio": 0.79,
      "text": "I am a last year student and i am currently studying for MLE interviews.\n\nMy focus at the moment is on DSA and basics of ML system design, but i was wondering if i should prepare also oop/design patterns/lld. Are they normally asked to ml engineers or rarely?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o032xxd",
          "author": "sometimes_angery",
          "text": "I'm an MLE and have no idea what LLD is.",
          "score": 25,
          "created_utc": "2026-01-17 10:41:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o095wy3",
              "author": "avourakis",
              "text": "They got me there too üòÖ",
              "score": 1,
              "created_utc": "2026-01-18 07:22:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0339sp",
              "author": "FinalRide7181",
              "text": "Low Level Design, like design classes for a system like parking lot using OOP classes, methods, inheritance, design patterns.",
              "score": 0,
              "created_utc": "2026-01-17 10:44:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o033h2s",
                  "author": "sometimes_angery",
                  "text": "Depends on the job I guess. Do they expect you to implement a system like parking lot? Cuz maybe that's not entirely an MLE job.",
                  "score": 3,
                  "created_utc": "2026-01-17 10:46:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o06554g",
              "author": "__mitra__",
              "text": "Same. Never had any company ask about OOP patterns or similar. Not that it's irrelevant, but I guess it's assumed you have a base understanding of it.",
              "score": 0,
              "created_utc": "2026-01-17 20:47:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0685up",
                  "author": "FinalRide7181",
                  "text": "I am doing an MS in stats with ml/dl focus. I know python and basic oop (class, attribute, method, inheritance, polymorph) but i am not a CS student, i dont really know design patterns/oop design.\n\nDo you think i should study them if i aim to be a MLE or i can skip them and focus on LC?",
                  "score": 1,
                  "created_utc": "2026-01-17 21:03:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o036gs4",
          "author": "Hungry_Age5375",
          "text": "Big tech asks LLD, real ML companies don't. Stick with ML system design - that's where the value is.",
          "score": 9,
          "created_utc": "2026-01-17 11:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o038gm9",
              "author": "FinalRide7181",
              "text": "So no need to do design patterns? \n\nI have been told that some companies ask them to swe, but for mle it is a different story right? Same for ai engineer?",
              "score": 1,
              "created_utc": "2026-01-17 11:32:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03edtc",
          "author": "patternpeeker",
          "text": "It depends a lot on how the team defines ‚ÄúML engineer.‚Äù In practice, if the role owns production code, services, or pipelines, some level of LLD and basic OOP shows up pretty often, even if it is not labeled that way. You might not get textbook design patterns, but you will get questions that test whether you can structure code that is testable, extendable, and not a one-off notebook. Teams that treat MLE as research plus glue care less about this, while platform or product-facing teams care a lot. I would not go deep into patterns for their own sake, but you should be comfortable explaining how you would design and evolve a small ML service or pipeline over time. That usually matters more than pure DSA once you are past the screen.",
          "score": 3,
          "created_utc": "2026-01-17 12:21:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04lxl4",
              "author": "FinalRide7181",
              "text": "Is it asked to juniors too or generally to people with at least a couple of years of experience?",
              "score": 1,
              "created_utc": "2026-01-17 16:24:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h4ji",
          "author": "dataflow_mapper",
          "text": "From what I have seen, it depends a lot on the company and how they define the MLE role. If the role is closer to software engineering with ML on top, then basic LLD and OOP concepts come up fairly often. Things like designing a feature pipeline class or structuring a training service.\n\nIf it is more research or modeling heavy, they usually focus more on ML fundamentals and system design at a higher level. I would not go deep into patterns, but being comfortable explaining clean class design, interfaces, and tradeoffs is a safe bet. It rarely hurts, and it can help you stand out when interviews lean practical.",
          "score": 2,
          "created_utc": "2026-01-17 12:42:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04k54r",
          "author": "madbadanddangerous",
          "text": "This job market is a dumpster fire. Anything and everything is on the table. I've been asked about low level CPU internals for ML engineer positions. I've been asked about NLP learning for robotic ML interviews. I've been asked to show how well I can vibe code, how to implement a custom loss function and code an ML model from scratch using only numpy, presentations on prior projects, tests, on-site projects. Once I was asked to code a live solution to a geology problem after getting a 15 minute PowerPoint presentation on geological processes. Another time, the interviewer handed me an unsolved problem in probability theory and asked me to solve it. \n\nYou can be asked anything even tangentially related to computing and then be graded on it. This job market is an experience in humiliation, superstition, cargo culting, rejection, and self-flagellation. \n\nJust do your best and hope you get lucky. Try not to sweat the rejection or let it affect your mental health too much. Companies are out of their minds right now, and we all need to remember that we are more than what they test for in a broken interview process.",
          "score": 1,
          "created_utc": "2026-01-17 16:16:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05honc",
          "author": "NoProfession6095",
          "text": "I will be starting to study Data Science and see where it lands me. I am BTech undergrad CSE 2025 passout and want to explore the domain. What should my first steps be?",
          "score": 1,
          "created_utc": "2026-01-17 18:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07ymo6",
          "author": "thinking_byte",
          "text": "From what I have seen, it depends a lot on the company and how close the role is to production work. Teams that treat MLEs as software engineers who happen to work on ML will care about LLD, clean interfaces, and basic design patterns. If the role is more research or modeling focused, it comes up far less.\n\nI would not go deep into academic OOP theory, but being comfortable explaining how you would structure a training pipeline, inference service, or feature store is useful. Even simple class design and separation of concerns goes a long way. The signal they usually want is whether you can build and maintain ML systems, not just train models once.",
          "score": 1,
          "created_utc": "2026-01-18 02:27:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o081isk",
              "author": "FinalRide7181",
              "text": "Is that mostly learned on the job? If it is then it is fine, what i was referring to was practicing parking lot/design patterns‚Ä¶ which is i think what you called ‚Äúacademic OOP theory‚Äù",
              "score": 1,
              "created_utc": "2026-01-18 02:42:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0dyi6h",
                  "author": "thinking_byte",
                  "text": "Yeah, that stuff is mostly learned on the job. Very few teams expect a new grad MLE to rattle off design patterns or do formal LLD like a backend interview. What they usually care about is whether you can reason about structure at a practical level.\n\nParking lot style questions are overkill for most MLE roles. A better use of time is being able to talk through how you‚Äôd organize code for training vs inference, how you‚Äôd keep things testable, and how you‚Äôd avoid everything turning into one giant script. If you can explain those tradeoffs clearly, that‚Äôs usually enough signal. The rest comes naturally once you‚Äôre maintaining real systems.",
                  "score": 1,
                  "created_utc": "2026-01-19 00:19:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0907wa",
          "author": "AccordingWeight6019",
          "text": "It really depends on how the company defines the MLE role. wherein in teams where MLEs are closer to software engineers who own production systems, some form of LLD or object design tends to come up, even if it is not framed explicitly as design patterns. In more research leaning or modeling focused roles, it is often secondary to data, modeling, and evaluation discussions. In practice, being able to reason about code structure, interfaces, and trade-offs usually matters more than memorizing patterns. job titles hide a lot of variation here, so the safest bet is to be comfortable explaining how you would structure a real system at a high level and at a code level.",
          "score": 1,
          "created_utc": "2026-01-18 06:32:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09928z",
              "author": "FinalRide7181",
              "text": "I mean if what is being asked is ml system design and oop for pipelines then it is fine. What i meant with LLD was design patterns and things like design parking lot, are these common for mle or almost only for traditional swe?",
              "score": 1,
              "created_utc": "2026-01-18 07:50:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09idfh",
          "author": "nian2326076",
          "text": "\n\nI'm an MLE¬†",
          "score": 1,
          "created_utc": "2026-01-18 09:15:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09isjf",
              "author": "FinalRide7181",
              "text": "Great! And what do you think about my question?",
              "score": 1,
              "created_utc": "2026-01-18 09:19:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bboq7",
          "author": "LeonhardEuler_",
          "text": "What do you do to prep for ML System design? I'm a new grad looking to go MLE",
          "score": 1,
          "created_utc": "2026-01-18 16:34:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o055gga",
          "author": "akornato",
          "text": "Low-level design questions are much less common for MLE roles than DSA and ML system design, but they do come up - especially at companies where MLEs are expected to write production code and work closely with software engineers. The reality is that it varies significantly by company and team. Big tech companies might throw in some OOP and design patterns questions to assess your software engineering fundamentals, but they're usually not the main focus. Smaller companies or places where the MLE role is closer to a traditional SWE role might dig deeper into LLD. If you're already solid on DSA and ML system design, spending maybe 20-30% of your remaining prep time on basic OOP principles and common design patterns is reasonable insurance, but don't let it take priority over your core MLE prep.\n\nThe good news is that you don't need to go as deep as a backend engineer would - just understand the fundamentals like SOLID principles, a handful of common patterns (factory, strategy, observer), and how to write clean, maintainable code. Most interviewers care more about seeing that you can structure code reasonably than testing whether you've memorized every design pattern. If you want help figuring out how to answer these kinds of questions when they do come up, I built [interview AI copilot](http://interviews.chat) to handle unexpected interview questions across all topics, including the occasional curveball LLD question in an MLE interview.",
          "score": 1,
          "created_utc": "2026-01-17 17:56:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qenpcq",
      "title": "Data analysis vs C++ feature design",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qenpcq/data_analysis_vs_c_feature_design/",
      "author": "Huge-Leek844",
      "created_utc": "2026-01-16 18:17:27",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Hi everyone,  \nI‚Äôm a radar signal processing engineer in automotive and started a small team six months ago. My work so far has been a mix of:  \n  \n1) Radar data analysis for bugs found in customers: performance issues, drop of detections, loss of tracking. I learnt about DSP and radar algorithms.  \n2) C++ coding: small implementations and bug fixes, embedded systems work (inter-core comms, debugging)  \nThe team is growing, so I need to choose one path to focus on. My manager suggested either continuing with:  \n  \n1) Customer support and data analysis, which is very complex and does require a decent understanding of algorithms and math but rarely involves making changes, at best only changing a few parameters. Tough deadlines here.   \nOR  \n2) Moving to C++ customer projects. I will have more scope, ownership and design but ranges from simple integration work to algorithm implementations. So i won't analyse super complex algorithms, and i could potentially work on boring integration topics for 6 months! Its very customer driven. Less deadlines.  \n  \nMy long-term goal is AI, ML, and general algorithm design. I want to build and design algorithms, not just tune parameters or implement specs.\n\n  \nWhich path would you choose to maximize growth toward AI and algorithm work, and how would you make it as useful as possible?  \nWhat kind of questions i could ask my manager?  \n  \nThank you.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qenpcq/data_analysis_vs_c_feature_design/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzyy177",
          "author": "Equal-Agency4623",
          "text": "Between options 3 and 4, I‚Äôll recommend option 4 because it opens door to more career opportunities for you. With that experience, you can work as a Research Engineer in AI labs where you implement novel algorithms. You can also work as a Quantitative Developer in quant hedge funds where you implement trading algos.",
          "score": 6,
          "created_utc": "2026-01-16 18:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02sqsw",
          "author": "AccordingWeight6019",
          "text": "Given your long-term goal, I would be biased toward the path that gives you ownership over problem formulation, even if the algorithms are simpler at first. Tuning parameters under deadline pressure builds intuition, but it rarely lets you define assumptions or failure modes, Which is what carries over to ML work. On the C++ side, the risk is getting stuck in integration, so the key question is whether you can own parts of the algorithmic design and not just implement specs. I would ask your manager how often each path involves proposing changes versus executing predefined solutions, and who is accountable when performance degrades. the skill that transfers best to AI work is not a specific tool, but the habit of reasoning about trade-offs and system behavior end to end.",
          "score": 3,
          "created_utc": "2026-01-17 09:05:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02knfj",
          "author": "SkillSalt9362",
          "text": "1. I would go for AI ML but also consider my interest \n\n2. building side projects are non negotiable, it helps to improve our skills work on algorithms and more!!",
          "score": 2,
          "created_utc": "2026-01-17 07:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05iq6q",
          "author": "DiligentSlice5151",
          "text": "What  is hard about Customer support and data analysis?",
          "score": 0,
          "created_utc": "2026-01-17 18:57:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05j12h",
              "author": "DiligentSlice5151",
              "text": "Do you mean blackbox data analysis?",
              "score": 0,
              "created_utc": "2026-01-17 18:58:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgv0ij",
      "title": "Weekly Entering & Transitioning - Thread 19 Jan, 2026 - 26 Jan, 2026",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/",
      "author": "AutoModerator",
      "created_utc": "2026-01-19 05:01:45",
      "score": 10,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0ff9tm",
          "author": "Yang-Geum-myeong",
          "text": "Hi everyone,\n\nI‚Äôm at a career crossroads and would appreciate some grounded advice. I have 5 years of experience in the insurance/reinsurance domain, working in catastrophe modeling, risk analytics, data cleaning, and geocoding using in house tools. My work has involved heavy data analysis, stakeholder interaction, and translating model outputs into business insights.\n\nI want to change domains and am evaluating two paths:\n\n1. MS abroad 2026 (Data Science / Analytics / related tech programs)\n2. MBA in India (to pivot into consulting / strategy / management roles)\n\nMy key questions: For someone at 5 years experience, which path offers a more realistic and sustainable domain switch? How do recruiters view prior domain experience in each case? Any regrets from people who chose MS vs MBA (or vice versa)? Are there risks of being ‚Äúoverqualified but underexperienced‚Äù in either path? My priority is long-term career satisfaction and growth, not just immediate compensation.\n\nThanks in advance...would really value insights from people who‚Äôve faced a similar situation.",
          "score": 3,
          "created_utc": "2026-01-19 05:28:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fc0k0",
          "author": "Magnum_Opus7",
          "text": "Learning resource, especially for Maths",
          "score": 1,
          "created_utc": "2026-01-19 05:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fh6q8",
          "author": "AccordingWeight6019",
          "text": "One pattern I see a lot is people over-optimizing for tools instead of problem framing. Early on, it helps to focus on core stats, data wrangling, and being able to explain why a model should exist at all. Small end to end projects where you define the question, deal with messy data, and communicate trade-offs tend to be more valuable than stacking certificates. the transition is usually less about learning one more library and more about demonstrating how you think about data in context.",
          "score": 1,
          "created_utc": "2026-01-19 05:42:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fi2xs",
              "author": "Due-Experience-382",
              "text": "Any resources for the project part?",
              "score": 1,
              "created_utc": "2026-01-19 05:49:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iqkhz",
          "author": "Sea_Name4846",
          "text": "I'm a junior in university and I want to apply to internships. My major is data science. Where should I apply?",
          "score": 1,
          "created_utc": "2026-01-19 18:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p0l70",
              "author": "Dry-Enthusiasm-2775",
              "text": "anyone here successfully transitioned from another field into data science recently?",
              "score": 1,
              "created_utc": "2026-01-20 16:52:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhldsg",
      "title": "Using logistic regression to probabilistically audit customer‚Äìtransformer matches (utility GIS / SAP / AMI data)",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qhldsg/using_logistic_regression_to_probabilistically/",
      "author": "Zestyclose_Candy6313",
      "created_utc": "2026-01-20 00:06:17",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nI‚Äôm currently working on a project using utility asset data (GIS / SAP / AMI) and I‚Äôm exploring whether this is a solid use case for introducing ML into a¬†**customer-to-transformer matching audit**¬†problem. The goal is to ensure that meters (each associated with a customer) are connected to the correct transformer.\n\n# Important context\n\n* Current customer ‚Üí transformer associations are driven by a¬†**location ID**¬†containing circuit, address/road, and company (opco).\n* After an initial analysis, some associations appear wrong, but¬†**ground truth is partial**¬†and validation is expensive (field work).\n* The goal is¬†**NOT**¬†to auto-assign transformers.\n* The goal is to¬†**prioritize which existing matches are most likely wrong**.\n\nI‚Äôm leaning toward framing this as a¬†**probabilistic risk scoring**¬†problem rather than a hard classification task, with something like¬†**logistic regression**¬†as a first model due to interpretability and governance needs.\n\n# Initial checks / predictors under consideration\n\n**1) Distance**\n\n* Binary distance thresholds (e.g., >550 ft)\n* Whether the assigned transformer is the¬†**nearest**¬†transformer\n* Distance ratio: distance to assigned vs. nearest transformer (e.g., nearest is 10 ft away but assigned is 500 ft away)\n\n**2) Voltage consistency**\n\n* Identifying customers with similar service voltage\n* Using voltage consistency as a signal to flag unlikely associations (challenging due to very high customer volume)\n\nModel output to be: \n\nP(current customer ‚Üí transformer match is wrong)\n\n\n\nThis probability would be used to define operational tiers (auto-safe, monitor, desktop review, field validation).\n\n# Questions\n\n1. Does¬†**logistic regression**¬†make sense as a first model for this type of probabilistic audit problem?\n2. Any pitfalls when relying heavily on¬†**distance + voltage**¬†as primary predictors?\n3. When people move beyond logistic regression here, is it usually¬†**tree-based models + calibration**?\n4. Any advice on¬†**threshold / tier design**¬†when labels are noisy and incomplete?",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qhldsg/using_logistic_regression_to_probabilistically/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0kpmhd",
          "author": "Electrical-Window170",
          "text": "This sounds like a solid approach - logistic regression is perfect for interpretable risk scoring when you need to explain decisions to utility folks\n\n  \nDistance ratios are way more informative than absolute distance thresholds, and voltage consistency is clutch if you can get clean data on it. Just watch out for geographic clustering effects messing with your distance assumptions (like rural vs urban transformer density)\n\n  \nFor thresholds with noisy labels, start conservative and let the field validation feedback tune your cutoffs over time rather than trying to optimize on incomplete ground truth upfront",
          "score": 2,
          "created_utc": "2026-01-20 00:09:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0krmxv",
          "author": "trustme1maDR",
          "text": "You need a ground truth for your outcome variable (right/wrong match) to be able to train your model..at least for an unbiased sample of your data. It's unclear if you actually have this - you said partial.¬†",
          "score": 2,
          "created_utc": "2026-01-20 00:20:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ksy0b",
              "author": "Zestyclose_Candy6313",
              "text": "That‚Äôs a very fair point and definitely not claiming to have full or perfect ground truth. For most associations, correctness is  uncertain unless there‚Äôs been field validation (which is very costly). The way I‚Äôm thinking about it is to¬†only train on a subset of high-confidence labels: confirmed field corrections where available, plus some very strong inferred cases (like extreme distance ratios with a clearly closer viable transformer). Everything in the gray area would stay unlabeled and only be scored. The intent is to rank/prioritize review, not to auto-correct matches. The new field validation would feed back as additional high-confidence labels, so the model and thresholds can be tuned iteratively",
              "score": 2,
              "created_utc": "2026-01-20 00:27:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ntqvr",
          "author": "latent_threader",
          "text": "Logistic regression makes a lot of sense as a first pass if the goal is prioritization and explainability, not auto-fixing. Distance and voltage are strong signals, but they‚Äôre noisy and can be ‚Äúwrong for the right reasons,‚Äù so I‚Äôd treat the output as a risk score, not truth. In practice people often move to tree models later for interactions, but good calibration and tiering around review capacity usually matter more than model complexity.",
          "score": 2,
          "created_utc": "2026-01-20 13:17:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhnugu",
      "title": "To those who work in SaaS, what projects and analyses does your data team primarily work on?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qhnugu/to_those_who_work_in_saas_what_projects_and/",
      "author": "Augustevsky",
      "created_utc": "2026-01-20 01:52:44",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "Background:\n\n- CPA with ~5 years of experience \n\n- Finishing my MS in Statistics in a few months\n\nThe company I work for is maturing with the data it handles. In the near future, it will be a good time to get some experience under my belt by helping out with data projects. So what are your takes on good projects to help out on and maybe spear point?",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qhnugu/to_those_who_work_in_saas_what_projects_and/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0mfiiv",
          "author": "AccordingWeight6019",
          "text": "In SaaS, a lot of the high-impact work is around understanding user behavior and retention. Projects that combine cohort analysis, funnel tracking, and feature usage tend to teach both the technical side and the business trade-offs. Forecasting revenue or churn can also be useful, especially if you can link it back to actionable insights. Anything where you can move from data to a clear recommendation usually gets noticed and is a great experience.",
          "score": 4,
          "created_utc": "2026-01-20 06:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lmpsa",
          "author": "Dizzy-Midnight-6929",
          "text": "Those that align with your companies P&L. That could be sales, marketing, finance, costs, pricing, product, testing, or just getting the data into a platform so that you enable others to do these things and provide value. What does your company do? What's their product?",
          "score": 3,
          "created_utc": "2026-01-20 03:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m3tkw",
              "author": "Augustevsky",
              "text": "Streamline cloud services",
              "score": 1,
              "created_utc": "2026-01-20 04:50:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mxbs5",
          "author": "sinki_ai",
          "text": "In SaaS, the core work involves managing data pipelines from sources like Salesforce and Stripe. These are often fragile because upstream schema changes break downstream tables.\n\nThe primary focus is on churn prediction and unit economics. Calculating the exact compute cost per customer is a major project, as mapping cloud spend back to specific users is difficult. Most of the job is ensuring data quality rather than building complex models.",
          "score": 2,
          "created_utc": "2026-01-20 08:54:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rhw7m",
          "author": "nian2326076",
          "text": "A/B testings to make decisions",
          "score": 1,
          "created_utc": "2026-01-20 23:55:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi33t8",
      "title": "Claude Code supports Local LLMs",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qi33t8/claude_code_supports_local_llms/",
      "author": "Technical-Love-8479",
      "created_utc": "2026-01-20 14:51:39",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 0.67,
      "text": "Claude Code now supports local llms (tool calling LLMs) via Ollama. The documentation is mentioned here : [https://ollama.com/blog/claude](https://ollama.com/blog/claude)\n\nvideo demo : [https://youtu.be/vn4zWEu0RhU?si=jhDsPQm8JYsLWWZ\\_](https://youtu.be/vn4zWEu0RhU?si=jhDsPQm8JYsLWWZ_)\n\nhttps://preview.redd.it/0ilcwl22pieg1.png?width=1890&format=png&auto=webp&s=e79ff0fa282b3c48eaf735a4fd6f86d1fc276adb\n\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/datascience/comments/1qi33t8/claude_code_supports_local_llms/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0qkqfd",
          "author": "Pbjtime1",
          "text": "Huge.",
          "score": 1,
          "created_utc": "2026-01-20 21:09:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdrqh6",
      "title": "LLM for document search",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/",
      "author": "Few-Strawberry2764",
      "created_utc": "2026-01-15 18:35:27",
      "score": 1,
      "num_comments": 30,
      "upvote_ratio": 0.52,
      "text": "My boss wants to have an LLM in house for document searches. I've convinced him that we'll only use it for identifying relevant documents due to the risk of hallucinations, and not perform calculations and the like. So for example, finding all PDF files related to customer X, product Y between 2023-2025.\n\nBecause of legal concerns it'll have to be hosted locally and air gapped. I've only used Gemini. Does anyone have experience or suggestions about picking a vendor for this type of application? I'm familiar with CNNs but have zero interest in building or training a LLM myself. ",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzt86ly",
          "author": "UltimateWeevil",
          "text": "What is he actually asking you to solve? It‚Äôs probably more a NLP type task like TF-IDF + cosine similarity or a BM25 keyword matching task. \n\nFeels like a LLM is overkill unless he wants some kind of intelligent capability to query the contents. If so I‚Äôd suggest looking into Ollama for local hosting a LLM as you can choose pretty much any model you want and run a vectorDB like Chroma for you RAG element. You‚Äôll need to make sure you get your chunking done correctly and if you can nail your metadata tags it‚Äôll help massively for retrieval.",
          "score": 24,
          "created_utc": "2026-01-15 22:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztl888",
              "author": "DiligentSlice5151",
              "text": "second this ! All this for some PDFs.  Why?",
              "score": 5,
              "created_utc": "2026-01-15 23:22:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09mtqk",
                  "author": "Tricky_Math_5381",
                  "text": "Maybe the documents are very scattered or mixed? Idk too little information but maybe you want something like\n\nHey what DIN standards are relevant for the elements we get from producer a?\n\nA llm could maybe be useful for that",
                  "score": 1,
                  "created_utc": "2026-01-18 09:57:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs3opa",
          "author": "Rockingtits",
          "text": "Start with basic semantic similarity vector search and then into more advanced rag techniques like hybrid search, deep research and graphRAG.¬†\n\nIf you don‚Äôt need to generate an answer you can do a lot with a local model, it‚Äôs just doing embeddings essentially.\n\n\nYou‚Äôre gonna need a clever process for ingesting your documents unless they are squeaky clean also.¬†",
          "score": 25,
          "created_utc": "2026-01-15 19:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzslaxk",
              "author": "DiligentSlice5151",
              "text": " Yes and Yes on document cleaning  and database management.",
              "score": 7,
              "created_utc": "2026-01-15 20:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzswc8h",
          "author": "DFW_BjornFree",
          "text": "Why do you need an LLM? Just do a mixture of elastic search with similarity search.¬†\n\n\nLet users search for defined words / phrases or let them type a few sentences that get passed into a similarity search model that scores documents by match and returns them past a threshold¬†",
          "score": 6,
          "created_utc": "2026-01-15 21:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu8mj7",
          "author": "autumnotter",
          "text": "You're trying to do document search, and llm doesn't do that in the way you're thinking.¬†\n\n\nEffectively you want to do something like OCR, turning PDFs and images into unstructured text, then chunk the text, compute embeddings and vectorize, and then store in a vector database.¬†\n\n\nFrom there you can do document similarity search by querying the vector database. An agentic system can make that query and then return the retrieved context, sharing it with an LLM, which is usually called RAG.\n\n\nYou don't actually need an LLM to do document similarity search.\n\n\nI'm not familiar with vendors that you might use to do this locally, so I can't help you there.",
          "score": 7,
          "created_utc": "2026-01-16 01:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsm13a",
          "author": "Wishwehadtimemachine",
          "text": "LLM + RAG here no?",
          "score": 3,
          "created_utc": "2026-01-15 20:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsgv39",
          "author": "TaiChuanDoAddct",
          "text": "Are you in a microsoft or google environment? What your boss actually wants is a RAG, and they're honestly not hard or expensive to set up in these environments unless you need 1000% perfect results every time. \n\nMiscrosoft Azure, for example, let's you point an LLM at a sharepoint and tell it to RAG the contents and the connect it to an agent. it's pretty easy.",
          "score": 5,
          "created_utc": "2026-01-15 20:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs3ltl",
          "author": "Some-Librarian-8528",
          "text": "I'm a bit confused why he wants an LLM. Is it just to enable natural language searches? What's wrong with the current system? What's your budget for running it?",
          "score": 3,
          "created_utc": "2026-01-15 19:08:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs9lkt",
              "author": "Few-Strawberry2764",
              "text": "This is my second week on the job and I'm not sure if there is an existing system. Frankly I think he only wants it because \"AI\".",
              "score": 7,
              "created_utc": "2026-01-15 19:35:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzse3h5",
                  "author": "portmanteaudition",
                  "text": "Budget? Doing this properly for 1 person requires tens of thousands of dollars typically. For a large team, hundreds.",
                  "score": -1,
                  "created_utc": "2026-01-15 19:56:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs8f04",
          "author": "letsTalkDude",
          "text": "Why do you need an llm for search a document or even read it.  It is a straightforward nlp.\n\nCan you explain why r u looking for llm",
          "score": 2,
          "created_utc": "2026-01-15 19:30:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsa4xs",
              "author": "Few-Strawberry2764",
              "text": "I'm pretty sure he wants an LLM because he's drunk the AI Kool aid. But after we put a bunch of safety guard rails on usage, it's hard to see how it's meaningfully different from a ctrl F search.",
              "score": 1,
              "created_utc": "2026-01-15 19:38:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsdq7t",
          "author": "portmanteaudition",
          "text": "If you want it all local etc. you will need a fairly powerful in-house server with a large amount of VRAM/GDDR and CPU cores. You can use pretty much any LLM for this, although for local I'd recommend open source models like ollama since you have a decent likelihood of maintanence at 0 cost. All of these models are pre-trained and you can do RAG-like stuff. You just pass them the docs (or set up an OCR front end to do so first) and explain what you want. Inference is where you are going to run into issues hardware-wise - bigger models will tend to be better but require more powerful servers. If your boss just wants this for e.g. a couple of laptops, he is deeply mistaken- he",
          "score": 1,
          "created_utc": "2026-01-15 19:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvhw8n",
          "author": "AccordingWeight6019",
          "text": "For that use case, the hard part is usually not the model but the retrieval layer around it. If the goal is document identification rather than synthesis, you want something that does embeddings well, is stable, and can be deployed on prem without surprises. The LLM then mostly acts as a query interpreter on top of search.\n\nI would evaluate options based on how transparent the retrieval is, how much control you have over chunking and metadata filters, and how predictable the outputs are under edge cases. In practice, simpler models paired with a solid vector store and strict prompting often outperform larger models for legal or compliance constrained setups. The risk is less hallucination and more overconfidence, so strong guardrails and evaluation matter more than raw model capability.",
          "score": 1,
          "created_utc": "2026-01-16 06:09:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw5tn3",
          "author": "latent_threader",
          "text": "For that use case you probably do not want ‚Äúdocument search with an LLM‚Äù so much as classic retrieval plus embeddings. The LLM can sit on top just to interpret the query, not to answer it.\n\nMost teams I have seen in similar legal setups run a local embedding model, index chunks in something like a vector store, and retrieve PDFs by similarity plus metadata filters. The model never needs to see the whole corpus at once, and hallucination risk stays low because you are only ranking documents. The hard parts tend to be chunking, metadata hygiene, and evaluation, not the LLM itself.",
          "score": 1,
          "created_utc": "2026-01-16 09:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxjah4",
          "author": "Voiceofshit",
          "text": "If I'm understanding you correctly, I think you can just do that with a custom copilot agent.\n\n***after you've indexed your current database. Copilot should only be interpreting the human aspect of what they're asking for, then activating whatever hardcoded search function you have for the appropriate documentation with the relevant information. I would only use it as a wrapper for a robust search function that looks pretty and makes it easy to interact with. Lots of people in the comments have good ideas on how to actually implement the search feature. But installing the AI wrapper will make you look like an AI god and make it dummy proof for leadership to interact with.",
          "score": 1,
          "created_utc": "2026-01-16 15:06:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kyy0z",
          "author": "slashdave",
          "text": ">finding all PDF files related to customer X, product Y between 2023-2025\n\nYou mean... like a simple index? Maybe you can start with deploying an ordinary indexer? Stick it on a RAG if someone wants to waste money on an LLM prompt.",
          "score": 1,
          "created_utc": "2026-01-20 00:59:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0le0pq",
          "author": "whodis123",
          "text": "We have experience with air gapped rag and elastic systems.",
          "score": 1,
          "created_utc": "2026-01-20 02:21:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrym1v",
          "author": "DiligentSlice5151",
          "text": " You can use automation to query it. Many companies are essentially just 'wrappers' for Gemini or ChatGPT; however, for local implementation, you would need to use DeepSeek to connect to your database.     Vendor wise  you need someone that specializes in database to search query.  Will you be the one maintaining the LLM after setup ?",
          "score": 1,
          "created_utc": "2026-01-15 18:45:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsl3oo",
          "author": "Perfektio",
          "text": "This is one of the least knowledgeable posts I‚Äôve seen in a while on this sub. You can literally google this in 5 minutes, this is such a common thing to build as it has been the original enterprise hype for the past 4 years.",
          "score": 0,
          "created_utc": "2026-01-15 20:28:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs0xwt",
          "author": "Single_Vacation427",
          "text": "Ugh? LLM search is being used a lot, so even if there is some hallucination, there are was to reduce that and also, what is the risk exactly? Clicking on a document and realizing it was not helpful. \n\nWhat are the legal concerns exactly?\n\nYou don't train an LLM yourself. It's not necessary for search. LLM is just part of the system, which usually includes RAG or something of the sort.\n\nDon't get me wrong, I'm not into the \"Let's use LLM magic\" products, but your post is incredibly ignorant about the space.",
          "score": -2,
          "created_utc": "2026-01-15 18:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztle9z",
          "author": "DiligentSlice5151",
          "text": "This needs to be a film lol :)",
          "score": 0,
          "created_utc": "2026-01-15 23:23:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx1u4g",
          "author": "BearVegetable5339",
          "text": "This is a very grown-up LLM use case because you're treating it as a retrieval and navigation layer, not an oracle. Air-gapped hosting plus legal concerns means the vendor should be judged on deployment model, security posture, and how well they do citation-grounded retrieval over your PDFs. A good system should default to returning filenames, dates, and relevant passages with page references, and it should be comfortable saying no relevant documents found instead of guessing. Your example query is basically metadata filtering plus semantic search, so chunking, embeddings, and indexing quality will matter more than model size. People who've used products like Spellbook, AI Lawyer, CoCounsel often end up caring less about the model and more about the workflow: can you verify in one click and audit what happened. If you keep it retrieval-only and enforce always show sources, you're already avoiding the most common disaster mode.",
          "score": 0,
          "created_utc": "2026-01-16 13:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzry7x6",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -2,
          "created_utc": "2026-01-15 18:44:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs3vqn",
              "author": "Rockingtits",
              "text": "It‚Äôs not airgapped like op said and I‚Äôve found it to be absolutely rubbish in practice.¬†\n\nIt‚Äôs fine for finding a document in sharepoint but actual retrieval within documents is beyond bad",
              "score": 3,
              "created_utc": "2026-01-15 19:09:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}