{
  "metadata": {
    "last_updated": "2026-02-17 17:24:28",
    "time_filter": "week",
    "subreddit": "datascience",
    "total_items": 14,
    "total_comments": 150,
    "file_size_bytes": 168115
  },
  "items": [
    {
      "id": "1r21ce9",
      "title": "New Study Finds AI May Be Leading to “Workload Creep” in Tech",
      "subreddit": "datascience",
      "url": "https://www.interviewquery.com/p/ai-workload-creep-tech-workers-study",
      "author": "warmeggnog",
      "created_utc": "2026-02-11 16:05:00",
      "score": 392,
      "num_comments": 41,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r21ce9/new_study_finds_ai_may_be_leading_to_workload/",
      "domain": "interviewquery.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4tmc73",
          "author": "Volcano_Jones",
          "text": "Of course. Even if AI does save time, that savings isn't passed on to the actual workers. Increased efficiency either means workers end up doing more tasks in the same time, or the company reaps the benefits by reducing headcounts. As everyone has known all along, labor will never see any benefit from efficiency and productivity gains created by technology.",
          "score": 508,
          "created_utc": "2026-02-11 16:25:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ttfwt",
              "author": "InherentlyJuxt",
              "text": "When the cotton gin was invented slave labor rates increased.",
              "score": 126,
              "created_utc": "2026-02-11 16:58:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4u2223",
              "author": "Thoughtulism",
              "text": "Yep, waiting my for pay raise for being twice as efficient! \n\nThe pay raise will come any day, right, right? ..... Right?",
              "score": 61,
              "created_utc": "2026-02-11 17:39:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4xikyf",
                  "author": "Expensive_Culture_46",
                  "text": "*narrator voiceover* \n\n“And such never came”",
                  "score": 7,
                  "created_utc": "2026-02-12 04:53:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o50eduw",
                  "author": "hiimresting",
                  "text": "Not only that. If you take inflation into account, the ratio of effective pay to efficiency looks even worse.",
                  "score": 2,
                  "created_utc": "2026-02-12 17:05:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4u2b5m",
              "author": "Welcome2B_Here",
              "text": "[Jevons paradox](https://en.wikipedia.org/wiki/Jevons_paradox).",
              "score": 15,
              "created_utc": "2026-02-11 17:40:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55qf8o",
              "author": "Lord_Skellig",
              "text": "Just so it's clear to everyone, labour doesn't see the benefits under a capitalist system. There are places where labouring in the general sense has been reduced by technology. Household chores have been greatly lessened in the last century by the invention of the washing machine, dishwasher, etc. But that is working for a concrete end goal. When the goal is to accumulate profit, the work will always expand to fit the capacity of the working people. No \"labour-saving\" device will ever reduce work, it will only accelerate the exponential consumption of our planet's resources.",
              "score": 5,
              "created_utc": "2026-02-13 13:17:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55wkvg",
                  "author": "Volcano_Jones",
                  "text": "Well said.",
                  "score": 2,
                  "created_utc": "2026-02-13 13:51:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o52oumc",
              "author": "wuttang13",
              "text": "For upper management AI only means  \n1. What other work can we give them? \n Vs.  \n2. How many people can we cut?",
              "score": 5,
              "created_utc": "2026-02-12 23:47:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56xtvg",
                  "author": "ErcoleBellucci",
                  "text": "If you have acute observation, AI can replace anyone except managers or CEOs",
                  "score": 1,
                  "created_utc": "2026-02-13 16:55:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4wsbx1",
              "author": "ashiamate",
              "text": "Not until unions make a resurgence",
              "score": 10,
              "created_utc": "2026-02-12 02:03:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4xw318",
              "author": "VulfSki",
              "text": "No shit. That's the point.",
              "score": 1,
              "created_utc": "2026-02-12 06:45:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4vnx4m",
              "author": "hyperactivedog",
              "text": "Labor sees benefits in proportion to how supply and demand stack up. \n\nPoverty rates (let’s say $3/day income) are basically 0 in advanced economies. \n\nAI has the potential to radically skew supply and demand though.",
              "score": -15,
              "created_utc": "2026-02-11 22:13:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tui2q",
          "author": "EntropyRX",
          "text": "Can we acknowledge that despite the MASSIVE advancements in software and AI over the last decade, the working conditions of tech employees have gotten WORSE instead of better?\n\nYou really need to understand that is not a technology problem.",
          "score": 145,
          "created_utc": "2026-02-11 17:03:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uatas",
              "author": "dillanthumous",
              "text": "Silicon Valley Libertarians gaslit developers decades ago into believing they shouldn't unionise.",
              "score": 54,
              "created_utc": "2026-02-11 18:19:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4up78c",
                  "author": "smokingkrills",
                  "text": "And spent a lot of money and time promoting everyone and their mother to get a CS degree/attend a bootcamp/teach themselves to code. \n\nWith a greater supply of labor, they can lower wages",
                  "score": 35,
                  "created_utc": "2026-02-11 19:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4w509o",
          "author": "gpbayes",
          "text": "Guess who is now a full stack software engineer instead of a data scientist due to company needs? This guy. Guess who doesn’t know JavaScript like at all, this guy",
          "score": 46,
          "created_utc": "2026-02-11 23:44:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zdfjx",
              "author": "burn_in_flames",
              "text": "Guess who is a DevOps engineer writing production pipelines for other people's ChatGPT'd analytics instead of doing data science and algorithm development.... Guess who doesn't know a thing about Kubernetes but does know a lot about remote sensing, this guy",
              "score": 10,
              "created_utc": "2026-02-12 14:04:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4y42ui",
              "author": "SakishimaHabu",
              "text": "I'll trade you",
              "score": 1,
              "created_utc": "2026-02-12 08:00:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tmecl",
          "author": "The-original-spuggy",
          "text": "Of course, cuz every advancement in technology has been the same. Increase productivity, continue to work the same amount, or more, because if you don't do it your competitor will. So what we're left with is a foot on the gas pedal instead of a smooth cruise control",
          "score": 72,
          "created_utc": "2026-02-11 16:25:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tvs02",
          "author": "Tasty-Window",
          "text": "yes how haven't people realized....new tech doesn't mean less time for humans to work, it means the market expects more in the time you do work.\n\nFor example, if you work 40 hours a week, you aren't going to work 10 hours at the same pay if you now get 4x as done. You will work 40 hours a week and be expected to maintain 4x your previous output.\n\nThe top 1% will capture any gains.",
          "score": 33,
          "created_utc": "2026-02-11 17:09:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ttib7",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 30,
          "created_utc": "2026-02-11 16:58:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xjonl",
              "author": "resnet152",
              "text": "Bold of you to assume that \"artisanal refactoring\" is a hirable skill heading into 2027.",
              "score": 12,
              "created_utc": "2026-02-12 05:01:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4vfpbe",
          "author": "goopuslang",
          "text": "This was happening well before AI lmao",
          "score": 8,
          "created_utc": "2026-02-11 21:34:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tsyv9",
          "author": "purposefulCA",
          "text": "No surprises there. Any automation benefits the factory owner, not the worker.",
          "score": 9,
          "created_utc": "2026-02-11 16:56:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tidej",
          "author": "protonchase",
          "text": "Doesn’t take a study to realize that.",
          "score": 16,
          "created_utc": "2026-02-11 16:07:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tmmkn",
              "author": "GoBuffaloes",
              "text": "You guys aren't clocking out at noon because AI finished all of your work??",
              "score": 20,
              "created_utc": "2026-02-11 16:26:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tu7ls",
          "author": "AAAAAARG-plop",
          "text": "Anyone have a link or citation to the “multi-month field study by UC Berkeley researchers” they’re referring to?",
          "score": 8,
          "created_utc": "2026-02-11 17:02:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yg9fy",
              "author": "webhyperion",
              "text": "It's not published yet I guess. Couldn't find it.",
              "score": 2,
              "created_utc": "2026-02-12 10:00:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z1x59",
          "author": "Flince",
          "text": "The cause of working creep is capitalism, not AI. This problem is not inherent to AI. If data science bro (no offense to anyone who is not) would just read/study on labor/economics/history they will see that the utopia they envision with AI CANNOT exist n the current regime. I laughed my arse off when I told them that \"maybe you should not say to artist that if they don't adapt they will die and actually study the problem ?\" and they shrugged, and now they are seeing massive layoff and their junior cannot find job.",
          "score": 2,
          "created_utc": "2026-02-12 12:57:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xkqm3",
          "author": "Remote-Telephone-682",
          "text": "The most obvious statement of all time",
          "score": 1,
          "created_utc": "2026-02-12 05:09:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xw1nw",
          "author": "VulfSki",
          "text": "Maybe? Definitely",
          "score": 1,
          "created_utc": "2026-02-12 06:45:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z7yv2",
          "author": "penguinzb1",
          "text": "not surprised. we're seeing this too — the expectation now is that since tools can help you should be able to handle more projects simultaneously. productivity gains get absorbed by increased scope rather than reduced workload. ends up feeling like you're doing the same amount of actual thinking but with more context switching",
          "score": 1,
          "created_utc": "2026-02-12 13:34:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o502h8j",
          "author": "RedPandaExplorer",
          "text": "Everyone is using AI to generate emails that aren't read, that are summarized by other AI. it just leads to dozens of pages of text no one reads and adds to the overall strain of running the company.\n\nIf AI, by default, was VERY brief, it might be useful. But that's not what happens, people generate gigantic documents",
          "score": 1,
          "created_utc": "2026-02-12 16:09:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50lfhd",
          "author": "ForeverEconomy8969",
          "text": "There's a term for that. It's called \"technical debt\". ",
          "score": 1,
          "created_utc": "2026-02-12 17:38:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51qrty",
          "author": "PNW_Uncle_Iroh",
          "text": "Someone really needed to conduct a study to learn this?",
          "score": 1,
          "created_utc": "2026-02-12 20:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54c6gc",
          "author": "DaxyTech",
          "text": "I've seen this play out firsthand on data teams -- the moment you automate one part of a pipeline, the expectation shifts to well now you can take on three more projects simultaneously. The cognitive switching cost point is especially real. Before AI tooling, I'd spend a full morning on a single analysis. Now there's this implicit pressure to have multiple workstreams going because the AI handles the grunt work. But the thinking work -- framing the right question, validating assumptions, communicating results to stakeholders -- that hasn't gotten faster at all. What I've found helpful is being very explicit with leadership about the difference between AI made step 3 faster and the entire project takes less time. Those are very different statements, and conflating them is exactly how workload creep sneaks in. Our team started doing weekly scope reviews specifically to catch scope creep disguised as efficiency gains and it's made a real difference.",
          "score": 1,
          "created_utc": "2026-02-13 06:14:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5czzg7",
          "author": "Appropriate-Plan-695",
          "text": "You need laws not capitalism/ technological advance labour rights/conditions. If you’re contract says 35h, that’s what you have (if the law gives you enough power to enforce it).",
          "score": 1,
          "created_utc": "2026-02-14 16:25:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vxbn4",
          "author": "jesusonoro",
          "text": "every productivity tool in history has been pitched as \"you'll work less\" and every single time it just means \"you'll do more in the same hours for the same pay.\" this is the assembly line conversation again with a shinier wrapper.",
          "score": 1,
          "created_utc": "2026-02-17 16:10:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w4ypr",
          "author": "Emotional-Sundae4075",
          "text": "“Essentially, AI reduces friction per task, but expands the number of tasks and expectations.”\n\nYour welcome",
          "score": 1,
          "created_utc": "2026-02-11 23:44:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x0nwj",
          "author": "tashibum",
          "text": "No shit lol",
          "score": 0,
          "created_utc": "2026-02-12 02:52:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1qo10",
      "title": "[Advice/Vent] How to coach an insular and combative science team",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r1qo10/advicevent_how_to_coach_an_insular_and_combative/",
      "author": "TalkIcy2357",
      "created_utc": "2026-02-11 07:12:53",
      "score": 71,
      "num_comments": 33,
      "upvote_ratio": 0.93,
      "text": "My startup was acquired by a legacy enterprise. We were primarily acquired for our technical talent and some high growth ML products they see as a strategic threat. \n\nTheir ML team is entirely entry-level and struggling badly. They have very poor fundamentals around labeling training data, build systems without strong business cases, and ignore reasonable feedback from engineering partners regarding latency and safe deployment patterns. \n\nI am staff level MLE and have been asked to up level this team. I’ve tried the following:\n\n\\- Being inquisitive and asking them to explain design decisions \n\n\\- walking them through our systems and discussing the good/bad/ugly\n\n\\- being vulnerable about past decisions that were suboptimal\n\n\\- offering to provide feedback before design review with cross functional partners\n\nNone of this has worked. I am mostly ignored. When I point out something obvious (e.g 12 second latency is unacceptable for live inference) they claim there is no time to fix it. They write dozens of pages of documents that do not have answers to simple questions (what ML algorithms are you using? What data do you need at inference time? What systems rely on your responses).  They then claim no one is knowledgeable enough to understand their approach. It seems like when something doesn’t go their way they just stonewall and gaslight.\n\nI personally have never dealt with this before. I’m curious if anyone has coached a team to unlearn these behaviors and heal cross functional relationships.\n\nMy advice right now is to break apart the team and either help them find non-ML roles internally or let them go. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r1qo10/advicevent_how_to_coach_an_insular_and_combative/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o4s7qcs",
          "author": "patternpeeker",
          "text": "this sounds more like an incentive and ownership issue than pure skill. if there are no hard constraints around latency, reliability, or business impact, they can ignore feedback. sometimes things only change when slas and deployment gates are enforced by leadership. without that backing, coaching alone rarely fixes behavior.",
          "score": 44,
          "created_utc": "2026-02-11 11:42:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tcngi",
              "author": "TalkIcy2357",
              "text": "This a good point. There are deployment gates / SLAs enforced by cross functional teams. I wonder if I ask the ML team to come up with their own SLAs and share with partners if that helps partnership go more smoothly.",
              "score": 9,
              "created_utc": "2026-02-11 15:40:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4uetfd",
                  "author": "RecognitionSignal425",
                  "text": "yes, you should work with leaders to set up some non-negotiable framework and standards. Start with the culture, but don't frame it as the enforcement, rather encourage them to test it as experiment for few months. ",
                  "score": 6,
                  "created_utc": "2026-02-11 18:38:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zrqax",
                  "author": "_Joab_",
                  "text": "Only if you feel they won't (or can't) game the new system. If they can, they probably will, for nothing more than maintaining the status quo of easy work and low accountability.\n\nYou described them as headstrong people - you have to plan accordingly.",
                  "score": 1,
                  "created_utc": "2026-02-12 15:18:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4sd4lz",
              "author": "Vrulth",
              "text": "Yes, from my experience as long as ther e is no clear ownership and accountability everything is bound to fail.\nGuess in op shoes I would review team topology and put more ds in stream-aligned teams where they will be accountable to a north star metric.\n\nThat's easier said than done though.",
              "score": 7,
              "created_utc": "2026-02-11 12:22:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zu4bm",
                  "author": "_Joab_",
                  "text": "I'm yet to meet a corporate DS team that felt significant ownership. It often devolves into a theoretical exercise and initiatives frequently fail due to that mentality. It's a special kind of challenge to manage a bunch of PHDs from my experience.",
                  "score": 3,
                  "created_utc": "2026-02-12 15:30:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rl61r",
          "author": "beansAnalyst",
          "text": "If this is causing real friction, make it visible to them. Take them to a stakeholder connect and put them on a spot -\"Hey, where in documentation can we find this?\"\n\nThis will solve the insular part. Combative is something you fix with regular catch-ups over tea.",
          "score": 64,
          "created_utc": "2026-02-11 08:16:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zv9rp",
              "author": "_Joab_",
              "text": "I think OP's beyond that point - they've proven to be resistant to changes in the status quo and aggressively so. In my opinion he has to get a bit combative with assigning responsibility and ownership, follow up frequently, and let the chips fall where they may. It's likely some of them will leave and IMO that's for the best if you actually want to get stuff done properly in a timely fashion.\n\nTea break catch-ups are also important in this scenario. You have to let them complain and push back otherwise you're just being a tyrant.",
              "score": 1,
              "created_utc": "2026-02-12 15:36:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sr6uu",
          "author": "No-Director-1568",
          "text": "Clarifying question here - what authority comes(to you) with this ask to up-level this team?\n\n",
          "score": 11,
          "created_utc": "2026-02-11 13:49:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tdkld",
              "author": "TalkIcy2357",
              "text": "I can stop projects and push folks out of the ML team. They can find another internal role or depart the company.",
              "score": 9,
              "created_utc": "2026-02-11 15:44:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tg38n",
                  "author": "ifyouknowwhatimeanx",
                  "text": "Oh yea, then from your other responses it sounds like it might be time to start putting people on the spot. Hopefully in an effective and constructive way, of course. But it sounds like you are a thoughtful leader to begin with.",
                  "score": 7,
                  "created_utc": "2026-02-11 15:56:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4tofj9",
                  "author": "No-Director-1568",
                  "text": "I suspect intentional or not you are being set up to fail.\n\nWhat are the outcomes or key results that define you having 'leveled-up' this team?\n\n",
                  "score": 6,
                  "created_utc": "2026-02-11 16:35:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rhfm7",
          "author": "AcolyteOfAnalysis",
          "text": "IMHO, First comes the stick, only then the carrot. If you are a leader, you do indeed consult your subordinates when making decisions, but in the end you postulate the correct decision/standard and start prosecuting those not following orders. It's that simple. If they disagree with you and have nothing to lose from ignoring your orders, then you will achieve nothing. If you don't have the right to enforce, then you are not a leader. \n\nYes, it is preferable to establish a deeper connection and mutual understanding with your coworkers. But that's not your job, and that's what you don't have time for. Your job is to get shit done. Mutual understanding will come later if you were kind but just.",
          "score": 31,
          "created_utc": "2026-02-11 07:41:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4savyu",
              "author": "Kasyx709",
              "text": "Speaking as a program manager, 100% this. Call a meeting, outline the issues, and set the new course. Ideally bring in a second person you trust to help coordinate and run things with you.",
              "score": 10,
              "created_utc": "2026-02-11 12:06:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4teaia",
              "author": "TalkIcy2357",
              "text": "This is good feedback. Im likely being too nice.",
              "score": 4,
              "created_utc": "2026-02-11 15:48:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4w69ik",
              "author": "cIDor",
              "text": "This. Be assertive, and if need be, do a talent evaluation and get rid of the low performers, assuming you have authority to make these decisions. \n\nAlso, just prototype and show them how it’s done instead of telling them.",
              "score": 1,
              "created_utc": "2026-02-11 23:51:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4rk8at",
              "author": "tongEntong",
              "text": "I’ll stab this kind of manager in the back where he doesn’t give a shit about anything other than “getting job done”, inhumane selfish prick and should be replaced by AI",
              "score": -15,
              "created_utc": "2026-02-11 08:07:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4svs9r",
                  "author": "RobfromHB",
                  "text": "The employees are effectively sabotaging the company. That’s not defensible.",
                  "score": 4,
                  "created_utc": "2026-02-11 14:14:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4rkxaa",
                  "author": "AcolyteOfAnalysis",
                  "text": "How is it inhumane? The primary goal of an employee is too earn money to the company, that's what their salary is for. There is no selfishness or hatred here. Just that a company is de facto dysfunctional if management cannot stir the direction the tech is going.",
                  "score": 8,
                  "created_utc": "2026-02-11 08:14:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tmjeg",
          "author": "snowbirdnerd",
          "text": "Sometimes you just have to clean house. Especially when dealing with a toxic culture. If you are in charge of these people and they are flat out ignoring you that's completely unacceptable, especially with the lengths you have gone to try to guide them. \n\n\nIt sucks but often you can't cure a toxic culture without a full reset. ",
          "score": 4,
          "created_utc": "2026-02-11 16:26:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uc7g0",
          "author": "anonamen",
          "text": "Sounds like you know the answer. They're not listening to you because they don't think anything is going to happen if they don't. They need to understand that something is going to happen to them. \n\nMaybe obvious, but do they know that you have the kind of authority that you do? It can be easy to miss that a senior IC is actually in a quasi-management role, controls jobs, titles, etc. There's never an easy way to explain this to people, but if the quiet approach has failed, maybe meet with them as a group, explain that you've been empowered to fix some issues with the team, and that you need to see some specific changes.  \n\nPossible middle-ground to getting rid of them all is to set up some challenge projects. Clear goals that meet clear needs, with clear metrics. Assign to the local \"experts\". Give them support and time to execute. If they fail, they go. \n\nAll that said, if you're allowed to get rid of them all and can quickly replace the team, just do it. They're dumb enough to fail to realize that you're in control of their future and lazy/stupid enough to fail to listen to you and adapt. Middle-ground solution can apply to anyone whom that statement doesn't describe accurately. ",
          "score": 4,
          "created_utc": "2026-02-11 18:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xnekj",
          "author": "AccordingWeight6019",
          "text": "This sounds less like a knowledge gap and more like unclear incentives and decision rights.\n\nIf latency, deployment safety, and documentation standards are optional, they will continue to be deprioritized. I would make production constraints explicit and structural, require latency targets, define inference inputs, and clear ownership for sign off. Once standards are tied to readiness for deployment, the discussion shifts from opinion to criteria.\n\nIf behavior remains combative after that, it is likely a leadership and accountability issue rather than a coaching one.",
          "score": 2,
          "created_utc": "2026-02-12 05:30:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c8vcf",
          "author": "Dangerous_Media_2218",
          "text": "Some good advice here. I'd recommend coming in more firm with them. If they send you a multi-page document that doesn't answer the question, send it back and in writing respond with, \"this document doesn't answer the key questions, which are [x]. There is extraneous info in the document including a, b, and c. Please cut it down to Y pages, focusing on the core questions.\"\n\n\nStonewalling and gaslighting is toxic, so you can try having a 1:1 conversation with the key offenders, discussing their behavior. This has to be done carefully and factually, and document, document, document each conversation. \n\n\nFrankly, you probably can't turn this type of behavior around. I've been around the block enough times to know that this isn't the kind of employee you want (the exception being that in a toxic management environment, employee behavior can appear toxic when it's really just survival). You're probably better off helping them move on to a role that's  a better fit. But you want to carefully CYA in the meantime, so they can't use anything against you. There's a good chance they will try that. ",
          "score": 2,
          "created_utc": "2026-02-14 13:57:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4t1ne2",
          "author": "Dull-Appointment-398",
          "text": "Damn Id kill to have you on our team :/",
          "score": 2,
          "created_utc": "2026-02-11 14:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t5anr",
              "author": "nico_rose",
              "text": "For real. This sounds like my job. It's exhausting",
              "score": 3,
              "created_utc": "2026-02-11 15:04:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ulk44",
          "author": "categoricalset",
          "text": "Few thoughts \n\n- at high level there are only a few options I believe: do it yourself to show the example, upskill, hire, or fire with the last being a last resort when all else fails. \n\n- you are being too nice i feel. In the end the org needs to be able to execute and this DS org sounds incompetent or ignorant or both. Go to the powers that be and point the problems out with documentation- use this to make the case for my previous (eg hire new head reporting to you) \n\n- in general adapt your approach to who you are dealing with. Some people are incompetent but they do not know this. Some lack even the humility to listen to others. Based on who you are dealing with, adapt. Identify people in the team that are open to feedback and learning. Speak to them. \n\n- Be careful not to over generalize- in my experience this type of issue mainly is due to management, which means you are probably best off hiring into your own org. \n\nGood luck!",
          "score": 1,
          "created_utc": "2026-02-11 19:09:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v4jvw",
          "author": "PrettyClient9073",
          "text": "I wrote a really sarcastic Medium article about this very problem. In the end, no matter what they do, if you get them to push their code into GIT nightly, the problem is largely mitigated. They will use personal computers and hide code everywhere. I saw a science team go so far as to build a secret Hadoop cluster so that they didn’t have to follow governance for a major Fortune 50 Company. This mentality and arrogance is burned into their psyche from college forward. Come down hard on them with policy and governance and don’t negotiate. This isn’t about teambuilding. It’s about the business owning the property they paid to develop. Fuck those scientists.",
          "score": 1,
          "created_utc": "2026-02-11 20:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5235g9",
          "author": "DaxyTech",
          "text": "The labeling and training data fundamentals issue you mentioned is actually one of the most impactful places to start. In my experience, teams that struggle with deployment quality almost always have upstream data problems they never diagnosed.\n\nA practical approach: introduce a lightweight data quality review as a gate before any model training begins. This means documenting the labeling methodology, measuring inter-annotator agreement, tracking data provenance, and validating that the training distribution actually reflects production conditions. When teams are forced to answer basic questions like 'what is the label error rate in this dataset' or 'how was this training data sampled,' it naturally surfaces the gaps in their process without it feeling like a personal critique.\n\nThe documentation problem you describe often stems from teams building models in isolation from the data pipeline. Once you tie data quality metrics to deployment readiness criteria, the documentation becomes functional rather than performative. Teams start writing useful docs because they need them to pass their own gates, not because someone told them to.",
          "score": 1,
          "created_utc": "2026-02-12 21:52:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sllxo",
          "author": "Itfromb1t",
          "text": "That’s incredible",
          "score": 1,
          "created_utc": "2026-02-17 02:04:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tdynx",
          "author": "SP_Vinod",
          "text": "This is an issue not so much of skill, but rather of responsibility and ownership. The team that ignores latency, won’t call out an algorithm, and hides behind documentation, shows a total absence of product thinking and business alignment. Coaching won’t fix that. \n\nBefore fracturing the team, I would establish firm operating principles (which include latency limits, design review checkpoints, model cards that accompany a deployment, and other documented standards) that relate directly to both revenue and risk. Those who choose to meet the standards will remain, and those who don’t will be forced to leave.",
          "score": 1,
          "created_utc": "2026-02-17 05:08:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6jv0m",
      "title": "Been failing interviews, is it possible my current job is as good as it gets?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r6jv0m/been_failing_interviews_is_it_possible_my_current/",
      "author": "quite--average",
      "created_utc": "2026-02-16 19:49:06",
      "score": 62,
      "num_comments": 29,
      "upvote_ratio": 0.87,
      "text": "I’ve been interviewing for the past few months across big tech, hedge funds and startups. Out of 8 companies, I’ve only made it to one onsite and almost got the offer. The rest were rejections at the hiring manager or technical rounds, and one role got filled before I could even finish the technical interviews.\n\nI’ve definitely been taking notes and improving each time, but data science interviews feel so different from company to company that it’s hard to prepare in a consistent way and build momentum.\n\nIt’s really getting to me now and I have started wondering if maybe I’m just not good enough to land a higher paying role, and if my current job might be my ceiling. For context, I’m targeting senior data scientist (ML) roles in a very high cost of living area.\n\nWould appreciate hearing from others who’ve been through something similar.",
      "is_original_content": false,
      "link_flair_text": "Career | US",
      "permalink": "https://reddit.com/r/datascience/comments/1r6jv0m/been_failing_interviews_is_it_possible_my_current/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o5qp0e3",
          "author": "Ecstatic_Bee6067",
          "text": "It's a rougher economy than many official sources will confirm. I don't think your situation is far from the norm.",
          "score": 117,
          "created_utc": "2026-02-16 19:57:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5quepv",
          "author": "NotSynthx",
          "text": "Only 8?\n\n\nThis a grind homie, you gotta put in more apps. You got this",
          "score": 54,
          "created_utc": "2026-02-16 20:23:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qpe39",
          "author": "ghostofkilgore",
          "text": "I think it's pretty natural that interview success isn't some smooth line through your career. You probably got into a groove of being successful for mid roles and now that you're looking to step up to senior, I think it's natural that you'll find it tougher, for a while at least. I don't think that means you've hit a ceiling in your career, it probably just means you've got a bit to go before you come across as a very strong senior candidate.\n\nEverything suggests that it's also a failry tight jobs market at the moment so that's probably making it feel a bit tougher than it should. Companies aren't struggling to find enough candidates who tick 90%+ of their boxes, so decent candidates who're maybe hitting 70-80% are getting squeezed.",
          "score": 48,
          "created_utc": "2026-02-16 19:58:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5upzu4",
              "author": "RecognitionSignal425",
              "text": "It's more about interviewer right now focus on 'less risky' hire rather than 'grow' hire. In that mindset, almost everything interviewee say gets mentally scored.\n\nWhen an interviewer is optimizing for risk minimization instead of growth potential, they are scanning for downside signals, not upside.\n\nOf course, not all of them are being trained for this style of interview. ",
              "score": 1,
              "created_utc": "2026-02-17 12:11:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qosmr",
          "author": "Financial_Wait2125",
          "text": "What types of questions being asked by them?\n\nI interview folks and have taken interviews across the board. I always look for adaptability unless the role is hyper specific. I like to see how the candidate approaches the issue.",
          "score": 14,
          "created_utc": "2026-02-16 19:56:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5rtpix",
              "author": "starktonny11",
              "text": "I feel this is overstated, still getting rejected for small mistakes even though you show how you are approaching problems. None of the feedback i got mentioned i wasnt goong on good direction or my approach was wrong, all were like small mistakes  i made or less tome left to explain in depth which could have been infered easily as nerves of interviews. They want the perfect candidates who makes 0 mistakes\n\nEdit: so i am saying is majority of time you gotta make 0 mistakes to get the offer",
              "score": 7,
              "created_utc": "2026-02-16 23:21:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5tkekw",
                  "author": "Financial_Wait2125",
                  "text": "You’re right, I over simplified it. A lot of the roles I hire for are either multi-domain or multifaceted where the approaches are needed to be broad. \n\nI am curious about yours, it sounds as if they had a picture perfect person they were looking for or wanted to doc at the first issue they could. I’m sorry you got that, usually I try to look past the nerves or schedule another round to see if they get past it. \n\nI think when jobs are posted, the recruiters want job skills that are unobtainable or what someone told them they “have” to have. Interviewing sucks, I get it.",
                  "score": 1,
                  "created_utc": "2026-02-17 05:59:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5qzzyd",
          "author": "Slow_Tap_2885",
          "text": "Honestly, 1 onsite out of 8 for senior ML roles isn’t bad. That’s a competitive level, especially for big tech and hedge funds. At senior level, interviews aren’t about just knowing models. They’re testing judgment, tradeoffs, product thinking, and how you communicate under pressure. The fact that you’re reaching HM and technical rounds means you’re in range. It’s probably refinement, not a hard ceiling. Senior jumps are selective and small gaps matter more. That doesn’t mean you’re not good enough. It just means the bar is high.",
          "score": 21,
          "created_utc": "2026-02-16 20:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qqvzi",
          "author": "Beginning_Cup7065",
          "text": "Are the roles in a different domain compared to your current role?\n\nIf you’re working as an analytics DS and you’re applying to an ML role, then you can face this issue. Also if you’re working as a DS ML in risk and you’re applying to DS ML role in rec sys, you’ll also face this problem. \n\nAs you get more senior, domain expertise matters more than anything else.",
          "score": 9,
          "created_utc": "2026-02-16 20:06:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qrekz",
          "author": "neo2551",
          "text": "Focus on what you like, and master the basics.\n\nYou will hit one interview or a job that will just be perfect for you, because you invested your energy mastering the topic. \n\nEnjoy the process, and things will play out.\n\nThat being said, learn SQL, at least you will have a shot at FAANG.",
          "score": 5,
          "created_utc": "2026-02-16 20:08:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qsy0m",
          "author": "coreybenny",
          "text": "Real talk. You may not be ready for a senior ds role. That isn't something against you but more to do with you need to continue to develop.  It's a process that everyone goes through and at different rates continue to learn and build skills and it'll come",
          "score": 6,
          "created_utc": "2026-02-16 20:16:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rwlye",
          "author": "Optimal_Speed_361",
          "text": "No it’s not you. And even if it were, judging by your introspection skills, you’re not dumb. If dumb people make it into high paying jobs, then you can too. Keep trying, work on your confidence, that might be it.",
          "score": 2,
          "created_utc": "2026-02-16 23:38:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5twpw4",
              "author": "CluckingLucky",
              "text": "Hey, thanks. I’m not OP, but everyone needed to hear this.",
              "score": 1,
              "created_utc": "2026-02-17 07:47:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qy6wz",
          "author": "mufflonicus",
          "text": "Try asking for advice on how to improve once you get rejected. You might get specific meaningful advice.\n\nBroaden your horizon, learn other components or domains or get some certifications. Something to make you stick out above the pack.",
          "score": 1,
          "created_utc": "2026-02-16 20:42:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r2lax",
          "author": "jesusonoro",
          "text": "8 companies is barely a sample size honestly. the part that makes DS interviews brutal is every company invents their own format from scratch so you cant build muscle memory the way SWE people can with leetcode. its more of a format lottery than a skill test",
          "score": 1,
          "created_utc": "2026-02-16 21:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rylof",
          "author": "ShapedSilver",
          "text": "It’s a tough economy, truly a different world than just a few years ago. These sound like pretty competitive places so they probably had a lot of applications in a few hours. I wouldn’t take it personally, it’s just going to be more grinding than we’re accustomed to for a little bit",
          "score": 1,
          "created_utc": "2026-02-16 23:49:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rz8r4",
          "author": "tongEntong",
          "text": "Me too mate🥲🥲🥲, also i heard only 20% of DS project actually went through (the rest failed sustained/ long term in production - even after months cooking it up, esp big companies w money to spend) is it true?",
          "score": 1,
          "created_utc": "2026-02-16 23:53:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s513l",
          "author": "mikethomas4th",
          "text": ">I’m targeting senior data scientist (ML) roles in a very high cost of living area.\n\nTheres only going to be so many positions total available at that level. This is why many transition from technical roles to leadership to make more money.",
          "score": 1,
          "created_utc": "2026-02-17 00:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sb9mh",
          "author": "Intrepid-Self-3578",
          "text": "I have attended many more interviews than you lot of them stopped responding after few rounds or final round now they are coming back so don't worry. companies are still under lot of uncertainty. ",
          "score": 1,
          "created_utc": "2026-02-17 01:02:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sv62k",
          "author": "zangler",
          "text": "DM me your resume.",
          "score": 1,
          "created_utc": "2026-02-17 03:02:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t5e7z",
          "author": "AccordingWeight6019",
          "text": "Rejections happen to everyone. 8 interviews are still early. Focus on structured prep, track patterns in feedback, and keep iterating. Your current job isn’t necessarily your ceiling. ",
          "score": 1,
          "created_utc": "2026-02-17 04:08:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tcrz9",
          "author": "KnowledgeExciting627",
          "text": "Eight companies with one onsite and a near offer is not failure. It’s variance.\n\nSenior ML roles, especially in high cost of living markets, are brutally competitive right now. You’re often competing against people who already worked at big tech or have very tightly aligned domain experience. Small differences get amplified at that level.\n\nThe fact that you almost closed an offer tells you something important. You’re in range. This isn’t “not good enough.” It’s calibration and positioning.\n\nData science interviews feel inconsistent because they are. Some emphasize modeling depth, some product sense, some experimentation, some system design, some coding. You can’t perfectly prepare for all of them, but you can pattern match after enough reps. If you’re taking notes and iterating, you’re doing the right thing.\n\nYour current job being your ceiling is a psychological conclusion, not an evidence-based one. Your data says:\n\n* You’re clearing some screens.\n* You’re reaching onsites.\n* You were close to an offer.\n\nThat’s a profile that converts with refinement, not a dead end.\n\nIf you want to tighten your odds, focus on:\n\n* Clear, metric-driven impact stories.\n* Strong framing of tradeoffs and experimentation.\n* Senior-level ownership narratives, not just modeling details.\n\nPlateaus feel permanent when you’re in them. They usually aren’t.",
          "score": 0,
          "created_utc": "2026-02-17 05:00:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qs2mi",
          "author": "Sufficient_Art2594",
          "text": "Stop preparing for the interview, start preparing more credentials. Degrees, certs, projects, etc. You dont have to ace an interview if you can adequately demonstrate passion and capacity to learn.   \n  \nValue-add isnt always about the best one-to-one match, its about holistic understanding of strategic glidepath. ",
          "score": -8,
          "created_utc": "2026-02-16 20:12:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qy8tg",
              "author": "hyperactivedog",
              "text": "This is false if the goal is faang and similar. Each company has a mostly standardized set of interview formats and they’re coachable. \n\nThe mental model I use is it’s like cramming for a final that the teacher provided a set of sample questions for. \n\nAnd you’re the guy saying to get certs. \n\nNo one cares about certs if you fail doing a basic coding question. No one cares about certs if you can’t describe a real world scenario you tackled. \n\nCerts help you get a recruiter call. They do very little past that.",
              "score": 3,
              "created_utc": "2026-02-16 20:42:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5r0mxv",
                  "author": "Sufficient_Art2594",
                  "text": "I'm not saying you can get certs and then do fuck-else. I'm saying certs and your actual grasp of concepts and materials help illustrate capacity. \n\n\nGood luck standing out against the hundreds if not thousands of others that built your same mental model and \"studied for the test\"... You bring no intangibles to add value and you'll get washed in the sea of recruits with the exact same mentality. Resumes and skills pass the lowest bar, standout strategic value-add gets you an offer, and the easiest way to broadcast that is with breadth of knowledge and holistic understanding of the space. ",
                  "score": 0,
                  "created_utc": "2026-02-16 20:54:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r2flqg",
      "title": "Meta ds - interview",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r2flqg/meta_ds_interview/",
      "author": "No-Mud4063",
      "created_utc": "2026-02-12 01:07:26",
      "score": 60,
      "num_comments": 24,
      "upvote_ratio": 0.84,
      "text": "I just read on blind that meta is squeezing its ds team and plans to automate it completely in a year. Can anyone, working with meta confirm if true? I have an upcoming interview for product analytics position and I am wondering if I should take it if it is a hire for fire positon?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r2flqg/meta_ds_interview/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o4wjril",
          "author": "Single_Vacation427",
          "text": "That doesn't make a lot of sense given that they do a lot of deep dives and analyze trade-offs for product decisions.\n\nBut I don't know internally how they work, though.\n\nEdit: I will say that what I've heard is that some teams/orgs are more toxic that others, with people working 60 hour weeks. I don't see them firing anyone there because how would thinks get done? Even if you automate some work, it would just bring it down to people working regular hours.\n\nAnyway, I'm always finding ways to automate my work or remove bottlenecks, unnecessary work, but that does not mean I have less work. I have less boring work and can spend time on more things that matter.",
          "score": 55,
          "created_utc": "2026-02-12 01:10:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wk0jh",
              "author": "No-Mud4063",
              "text": "from what i heard, their experimentation platform is already automated to a large extent, running t tests and such",
              "score": 9,
              "created_utc": "2026-02-12 01:12:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4wl1t1",
                  "author": "Single_Vacation427",
                  "text": "That's the case in most places",
                  "score": 31,
                  "created_utc": "2026-02-12 01:18:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4wlhox",
                  "author": "gpbuilder",
                  "text": "That’s literally most big tech companies for the past 10 years, no one is manually doing t-tests",
                  "score": 36,
                  "created_utc": "2026-02-12 01:21:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4wq5hm",
          "author": "anomnib",
          "text": "Meta seems like the last place to do this (I used to work there). DS at Meta have more influence over strategy than any other big place I’ve worked. \n\nI can see them automating their data analysts, but their DS function like quant PMs. \n\n\nI would more expect this where DS are just seen as numbers people. \n\nOn the other hand, I was at Meta before Zuck rebranded himself",
          "score": 46,
          "created_utc": "2026-02-12 01:50:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xsp38",
              "author": "TopStatistician7394",
              "text": "Yeah good luck automating the million alignment meetings, goal and target setting negotiations etc etc ",
              "score": 14,
              "created_utc": "2026-02-12 06:15:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xusfi",
          "author": "No-Mud4063",
          "text": "well.. thanks for the replies. i got humbled quite a bit here. leaving the post here in case anyone hears similar rumors",
          "score": 18,
          "created_utc": "2026-02-12 06:33:58",
          "is_submitter": true,
          "replies": [
            {
              "id": "o4xwbjr",
              "author": "TesseB",
              "text": "Your positive response to that is a great quality. Good luck with your interviews!",
              "score": 15,
              "created_utc": "2026-02-12 06:47:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xu5yt",
          "author": "DukeRioba",
          "text": "I work in tech (not Meta but similar-scale), and these rumors pop up every quarter. Yes, data teams get pressure to automate repetitive tasks, but that doesn’t mean analysts get fired. It usually means the job evolves, not disappears.",
          "score": 15,
          "created_utc": "2026-02-12 06:28:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wsar5",
          "author": "Yourdataisunclean",
          "text": "I would pay money to watch them try to do this.",
          "score": 12,
          "created_utc": "2026-02-12 02:02:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x702g",
          "author": "slappster1",
          "text": "It’s not true, but you are expected to use AI heavily to automate workflows.",
          "score": 4,
          "created_utc": "2026-02-12 03:32:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wln2x",
          "author": "gpbuilder",
          "text": "And you just believe that? Lol",
          "score": 6,
          "created_utc": "2026-02-12 01:22:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wnlyc",
              "author": "No-Mud4063",
              "text": "it does track to some extent. the ds roles in amazon are dwindling down. they are being refactored into either as/sde or bie/business analyst. at the same level, there are roughly 5-10x sde and as positions than DS positions in amazon.  so it is not too crazy that meta might be heading down that path too. ",
              "score": -3,
              "created_utc": "2026-02-12 01:34:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4wux1e",
                  "author": "Single_Vacation427",
                  "text": "Amazon was never big on data science. It's mostly a new-ish role and rare role there. They mostly have that business engineering something and then applied scientist. It's weird that way. ",
                  "score": 10,
                  "created_utc": "2026-02-12 02:18:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5626m8",
          "author": "patternpeeker",
          "text": "i can’t speak to internal plans, but rumors about “fully automating ds” tend to ignore how much product analytics is about framing problems and influencing decisions. even if tooling improves, someone still has to define metrics, debug data issues, and connect analysis to product moves. if u’re worried, use the interview to ask how they see the role evolving and what problems the team actually owns. that will tell u more than blind posts.",
          "score": 3,
          "created_utc": "2026-02-13 14:21:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51uq8b",
          "author": "Cptcongcong",
          "text": "I work at Meta and frequent blind. Blind is where people go to circlejerk. I’d be surprised if even 20% of the things said on there is true.",
          "score": 2,
          "created_utc": "2026-02-12 21:12:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51vcci",
              "author": "No-Mud4063",
              "text": "Are you a ds at meta? Asking to see if there is any mle for a ds position in meta or if its just ab testing",
              "score": 1,
              "created_utc": "2026-02-12 21:15:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o51vjhl",
                  "author": "Cptcongcong",
                  "text": "No, MLE. But have a couple of DS friends",
                  "score": 1,
                  "created_utc": "2026-02-12 21:16:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o54cs3v",
          "author": "DaxyTech",
          "text": "Here are a few things that might help: (1) For the product case, practice structuring answers as: clarify metric > decompose into components > hypothesize > recommend experiment. They want to see you think like a product DS, not just a stats person. (2) SQL round is honestly more about window functions and edge cases than complexity - practice self-joins, CASE WHEN aggregations, and handling NULLs properly. (3) The behavioral round matters more than people think. Use STAR format and have 2-3 stories about cross-functional influence and handling ambiguity. (4) For experimentation, know interference effects, ratio vs. non-ratio metrics, and when you'd choose something other than a standard A/B test. Good luck - the process is long but fair if you prepare systematically.",
          "score": 2,
          "created_utc": "2026-02-13 06:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uqy3i",
          "author": "Cute_Intention6347",
          "text": "I saw similar posts about Meta restructuring parts of the DS/analytics teams, lots of rumors floating around. From my experience and what I’ve seen shared on Blind/Glassdoor:\n\n**• Big tech often reorganizes teams frequently**, which doesn’t automatically mean a “hire-to-fire” situation.  \n**• Some teams get more automation tools, but that usually shifts work rather than eliminates it.**  \n**• Product analytics is often tied closely to business decisions and strategy, so those roles tend to be more stable than pure ops/data-entry DS roles.**\n\nThat said, things can vary a lot by team and manager. Best options if you’re unsure:\n\n1. Ask your Meta recruiter directly what the role’s long-term priorities are and how the team fits into broader goals.\n2. See if you can talk to someone currently on the team (LinkedIn or Reddit AMAs can help).\n\nI wouldn’t assume it’s a guaranteed “hire for fire,” but definitely ask clarifying questions so you can decide for yourself.",
          "score": 1,
          "created_utc": "2026-02-17 12:18:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r40g4p",
      "title": "What differentiates a high impact analytics function from one that just produces dashboards?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r40g4p/what_differentiates_a_high_impact_analytics/",
      "author": "Proof_Wrap_2150",
      "created_utc": "2026-02-13 20:38:23",
      "score": 58,
      "num_comments": 29,
      "upvote_ratio": 0.89,
      "text": "I’m curious to hear from folks who’ve worked inside or alongside analytics teams. In your experience, what actually separates analytics groups that influence business decisions from those that mostly deliver reporting?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r40g4p/what_differentiates_a_high_impact_analytics/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o588etv",
          "author": "durable-racoon",
          "text": "1 empowering self-serve analytics\n\n2 \\*deciding\\* what to analyze, and saying \\*no\\* to requests, rather than being an IT function that takes tickets users submit and completes them. saying 'no we dont think there's enough business value in that analysis, unless you can show us otherwise'\n\n3 having really, really smart people that can do cutting edge things that no one else at the company is doing.\n\n4 back to point 1: if you're already empowering self-serve analytics, then basic data analytics tasks dont NEED to be done by your team. You become the commandos only deployed for the most technically demanding jobs.\n\n5 You can also take charge of the organizations data strategy at a company wide level or department level. cant analyze data if there's no data to analyze.\n\nbuilding relationships is KEY. So is actually participating in the work your customers are doing, you have to GEMBA.\n\nof course doing those 'support ticket' jobs is how you build relationshps so there IS a balance.\n\nthen you know what exists, what real work needs to be done, and you can make it happen.\n\nyou need to work with people and alongside them and empower them in various ways (classes, daily meetings, they teach you how to do THEIR job, you teach them analytics, you create self serve analytics dashboards, and more!)  \nInstead of, like, someone makes a request, 2 weeks later you give them a dashboard and no conversation happens. thats really bad.\n\nif you're an IT org you're going to be laid off when its time to cut costs. if you want impact you have to go find it and you have to say no to low impact things, obviously. it requires a very brave charming and well connected dept leader\n\nas data analytics becomes incerasingly democratized, 'just' doing analytics isnt enough anymore\n\nEDIT: also\n\nFrameoutputs around decisions, not data. The highest-impact analytics teams orient their work around a specific decision that needs to be made. shift from descriptive to prescriptive. You always need to ask 'but how does this add value to the company?'\n\nClose the loop. Track whether your recommendations were implemented and what happened afterward.",
          "score": 39,
          "created_utc": "2026-02-13 20:42:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5addy5",
              "author": "MostlyHereForKeKs",
              "text": "Don’t respond to this post or posts like it. Check the post history - this account is putting up multiple low-effort posts an hour. It’s spam. ",
              "score": 20,
              "created_utc": "2026-02-14 04:16:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5tepfc",
              "author": "SP_Vinod",
              "text": "You're deducing the right thing but allow me to fine-tune your thinking with what I know actually works in practice rather than in theory.\n\nIn my enterprise data management journey demonstrates that the major turning point was the change from reactive IT ticket-taker to value-oriented data partner. The real breakthrough was not analytics but rather the reframed mission of “We make data business ready.” This simple reframing helped the team transition from order takers to proprietors of business results.\n\nLet’s get to the point:\n\nSelf-serve is non-negotiable. If your team is still doing elementary reporting, you are a cost center. Mature teams consolidate key data assets, standardize offerings, and enable business autonomy. Your most valuable talent should be reserved for the highest impact work.\n\nSaying no is leading. If there is no obvious decision, revenue, cost, or risk mitigation for your analysis, just don’t do it. High impact teams manage demand like a service portfolio (think Pareto) rather than a ticket queue.\n\nYou cannot operationalize without data relationships. The “virtual data team” model was successful because while they were embedded, they spoke the business language, and data was used as a means to an end, not as a means of control. \n\nFraming around decisions vs dashboards. Real evolution is from reactive > proactive > predictive. Descriptive analytics without ownership of decisions is entertaining intellectually.\n\nClose the loop. If you’re not tracking adoption and business outcome after delivery, you’re doing theater.\n\nOne more uncomfortable truth: as analytics become democratized, “being good at analysis” is table stakes. Your differentiation is owning data strategy, enterprise data foundations, and actionable data IP, not designing dashboards.\n\nImpact is about courage, discipline on prioritization, and intimacy with the business. Anything below that, you are just expensive reporting IT.",
              "score": 2,
              "created_utc": "2026-02-17 05:14:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5vchqs",
                  "author": "durable-racoon",
                  "text": "yep, mission statements are important too. we had one. very good comment, all of it!",
                  "score": 1,
                  "created_utc": "2026-02-17 14:26:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5a44pf",
              "author": "naholt01",
              "text": "Number 2 is key. All the rest falls out of that one if you do it right tbh",
              "score": 1,
              "created_utc": "2026-02-14 03:12:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5abwwa",
                  "author": "durable-racoon",
                  "text": "yeah but its really hard. people do NOT like hearing no and you do have to say yes to low-value things sometimes. if upper leadership views your org as a ticketing organization and a business expense, its a tooth and nail fight to change that culture. To some people its akin to hearing their IT support department telling them \"its not worth our time to investigate your issue, sorry\"",
                  "score": 1,
                  "created_utc": "2026-02-14 04:06:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o59a9k4",
              "author": "Proof_Wrap_2150",
              "text": "Thank you this is great!",
              "score": 0,
              "created_utc": "2026-02-14 00:04:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5j1a11",
                  "author": "mayorofdumb",
                  "text": "Multiple people need to able to understand and use a dashboard. So many are just built. I can create a great dashboard but it's always adhoc because you get random questions. It's keeping things tight and organized with millions of records",
                  "score": 1,
                  "created_utc": "2026-02-15 16:20:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5am08o",
          "author": "Upset-Chemist-4063",
          "text": "Levels to analytics impact\n\n1. Answering adhoc questions from a stakeholder\n2. Providing a tool (self serve dashboard) that enables stakeholders to answer questions about a specific business area\n3. Building knowledge in a specific domain (marketing, finance, product) to understand existing reporting gaps and proactively building said reports and sharing with stakeholders to support their initiatives/roadmaps (already developed without much of your input)\n4. Working directly with stakeholders to identify key initiatives to guide product roadmap (where you actually start being more of a data partner / consultant)\n5. Operating primarily @ step 4, but doing adhoc work of the lower steps about 20/30% of the time. \n\nAt a certain point, you’re borderline a data pm va just analyst. You want your stakeholders to see you as a value add in terms of strategy vs just giving them numbers to questions",
          "score": 5,
          "created_utc": "2026-02-14 05:22:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5imiak",
              "author": "brhkim",
              "text": "This is a solid typology. There's a big, big, big difference between being reactive (\"hey they want X, and I have no input into that besides doing it for them\") and being strategic, proactive (\"hey, I know they \\*will\\* want X, so let me get into a conversation with them and see if we can't steer them towards Y which will be better for all these reasons that they'll love\"). Your points on 3 and 4 really hit on the latter!",
              "score": 1,
              "created_utc": "2026-02-15 15:07:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5j6mp0",
                  "author": "Upset-Chemist-4063",
                  "text": "Yeah coming from staff level, the expectation is you operate at 4. Nobody really cares about getting a nice new perfected dashboard with all the cool filters and widgets. \n\nThe truth is not all stakeholders you have will be data savvy, so they’ll need a lot of hand holding when understanding and interpreting metrics and/or results of initiatives/experiments. \n\nWhen they are data savvy, you need to be able to operate and communicate almost at their level of expertise in order to have more productive discussions about opportunity sizing, impact, and tradeoffs (design, development time from Eng, and any other factors that need alignment before the execution of a project begins). That’s partly why I frame it as operating as a data partner.",
                  "score": 2,
                  "created_utc": "2026-02-15 16:46:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o598x3x",
          "author": "MostlyHereForKeKs",
          "text": "The analysis subs are being overwhelmed with “What does this two-word-1234 account ask?”, spam - can the mods please step up?",
          "score": 9,
          "created_utc": "2026-02-13 23:56:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ac2q0",
              "author": "durable-racoon",
              "text": "im confused by your comment, I thought the post had some good and rarely asked questions",
              "score": 7,
              "created_utc": "2026-02-14 04:07:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ad2ua",
                  "author": "MostlyHereForKeKs",
                  "text": "First - check the post history.\n\nMultiple post per hour like\n“What technical foundations matter most when enabling analytics at scale?”\nOr\n“What does People Analytics work actually look like week-to-week?”\n\n2 - there is nothing rare or interesting *at all* about the question asked.  It’s engagement bait. ",
                  "score": 8,
                  "created_utc": "2026-02-14 04:14:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o59d3h9",
          "author": "Statement_Next",
          "text": "Probably just the health of the company or whether there is true need for analytics.",
          "score": 2,
          "created_utc": "2026-02-14 00:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59pekl",
          "author": "Ok-Energy-9785",
          "text": "One that has a proactive goal to answer ambiguous questions the business needs to resolve strategic initiatives",
          "score": 1,
          "created_utc": "2026-02-14 01:37:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dscd8",
              "author": "Helpful_ruben",
              "text": "u/Ok-Energy-9785 Error generating reply.",
              "score": 1,
              "created_utc": "2026-02-14 18:47:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5e0lfa",
                  "author": "Ok-Energy-9785",
                  "text": "That's weird",
                  "score": 1,
                  "created_utc": "2026-02-14 19:29:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bef6i",
          "author": "AccordingWeight6019",
          "text": "The biggest difference is ownership and integration. Teams that just produce dashboards are often downstream. They get requests and deliver visualizations. High impact analytics functions are upstream: they help define the questions, design experiments or analyses, and work iteratively with stakeholders to shape decisions.\n\nAnother factor is context and actionability. It’s not enough to show trends; high impact teams translate insights into concrete recommendations, quantify trade offs, and anticipate how leadership will act on them. In practice, this often means being embedded in decision workflows rather than operating as a separate reporting function.",
          "score": 1,
          "created_utc": "2026-02-14 09:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bx4sh",
          "author": "patternpeeker",
          "text": "the teams that actually influence decisions tend to embed analytics in the workflow, not just hand out dashboards. they push insights that get acted on, follow up on impact, and tweak models based on feedback. dashboards alone rarely move the needle.",
          "score": 1,
          "created_utc": "2026-02-14 12:37:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d6are",
          "author": "Calm-Huckleberry-601",
          "text": "One thing that would differentiate is building solutions, dynamic and continuous reporting. \nAlso, one where they're able to work with complex and ever changing requirements. Especially that involving unstructured data. \nSometimes analysis is based on both internal and external data. Dashboarding is a step after that.",
          "score": 1,
          "created_utc": "2026-02-14 16:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d7per",
          "author": "DisgruntledMilennial",
          "text": "Honest question, do people actaully look at dashboards? I have this presumption that people look at them a handful of times and then put it on the back burner.\n\nTo question though, I'd say the former goes about their work in a botique/polished manner and the latter does what they are told to do.",
          "score": 1,
          "created_utc": "2026-02-14 17:03:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5faxgr",
          "author": "davecrist",
          "text": "DIY never works like you expect.  Every time we talk with customers they demand flexible configuration and the ability to build their own visualizations and components. \n\nAnd every time no one changes the configuration to anything other than ‘everything’ and they never, ever build their own components or modify the existing visualizations beyond changing the left-to-right order of columns. Never.",
          "score": 1,
          "created_utc": "2026-02-14 23:49:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m6twe",
          "author": "Fluffy-Ad3768",
          "text": "The ones that drive decisions, not just report on them. We built an analytics system that doesn't just produce dashboards — it makes autonomous trading decisions. 5 AI models analyze data, debate the interpretation, and execute. That's the extreme end, but the principle applies everywhere: high-impact analytics closes the loop between insight and action. If your analytics output requires a human to interpret and act on it, you're leaving value on the table.",
          "score": 1,
          "created_utc": "2026-02-16 02:29:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nh948",
          "author": "PublicViolinist2338",
          "text": "A lot of it has to do with business politics. I have seen situations where the tool worked perfectly fine from a technical perspective, but where it never ends up getting implemented because it risks automating a set of functions that may lead people to lose their jobs",
          "score": 1,
          "created_utc": "2026-02-16 08:33:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vwjzg",
          "author": "jesusonoro",
          "text": "whether the analytics person is in the room when the decision gets made or just gets a jira ticket after. high impact teams frame questions, dashboard factories answer them.",
          "score": 1,
          "created_utc": "2026-02-17 16:07:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59ei5p",
          "author": "Current-Ad1688",
          "text": "Why do you think \"just producing dashboards\" is not high impact. Depends what's in the dashboards obviously",
          "score": -1,
          "created_utc": "2026-02-14 00:29:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6klm4",
      "title": "Current role only does data science 1/4 of the year",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r6klm4/current_role_only_does_data_science_14_of_the_year/",
      "author": "Tenet_Bull",
      "created_utc": "2026-02-16 20:16:04",
      "score": 57,
      "num_comments": 26,
      "upvote_ratio": 0.89,
      "text": "Title. The rest of the year I’m more doing data engineering/software engineering/business analyst type stuff. (I know that’s a lot of different fields but trust me). Will this hinder my long term career? I plan to stay here for 5 years so they pay for my grad program and vest my 401k. As of now I’m basically creating one xgboost model a year and just doing analysis for the rest of the year based off that model. (Hard to explain without explaining my entire job, basically we are the stakeholders of our own models in a way, with oversight of course). I’m just worried in 5 years when I apply to new jobs I won’t be able to talk about much data science. Our team wants to do more sexy stuff like computer vision but we are too busy with regulatory fillings that it’s never a priority. The good news is I have great job security because of this. The bad news is I don’t do any experimentation or “fun” data science. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r6klm4/current_role_only_does_data_science_14_of_the_year/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o5qupdu",
          "author": "kater543",
          "text": "Join the club",
          "score": 84,
          "created_utc": "2026-02-16 20:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qv3zw",
          "author": "Particular_Prior8376",
          "text": "Data science/ machine learning cannot stand on its own when it comes to solving a business problem. It is created on a solid foundation of data engineering and analytics. 25% of time spent on building a model is more or less ideal. When looking for candidates companies don’t look for the ones who coded the most number of models, they look for people who can understand the business, frame a problem properly, can create a robust data pipeline and then train a model, can evaluate a model not just on the usual metrics but also on the impact on the business. Trust me, this is the best experience you are getting",
          "score": 97,
          "created_utc": "2026-02-16 20:27:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r604h",
              "author": "Tenet_Bull",
              "text": "Thanks, looks like my situation is pretty normal then?",
              "score": 9,
              "created_utc": "2026-02-16 21:20:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ra591",
                  "author": "Particular_Prior8376",
                  "text": "I think so, I would suggest keep one finger( figuratively speaking) on ml models so that you are designated as a data scientist, but use other fingers to explore other streams, you will have so many skills to solve problems with.",
                  "score": 3,
                  "created_utc": "2026-02-16 21:40:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5s0xj1",
                  "author": "pm_me_your_smth",
                  "text": "Not the one you're replying to, but take any internet advice with a grain of salt. Data science is is very broad field, job expectations vary greatly between companies and teams, and everyone is speaking only from their personal perspective.\n\nWill play a devil's advocate here where the opposite is true. If you want to be closer to machine learning than data analytics, then experience with model training/experimentation/iteration is more important (including all the data work too) vs business analysis etc. If your experience consists of just a simple train-and-done model once a year, that will hurt your chances for such jobs and it will not be \"the best experience you are getting\". \n\nEverything depends on your specific career targets whether it's best to stay or leave. There's no objectively correct path here, contrary to what the \"trust me\" guy above said.",
                  "score": 2,
                  "created_utc": "2026-02-17 00:03:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5tanwz",
              "author": "SryUsrNameIsTaken",
              "text": "Yeah agreed. That kind of role is fast tracking yourself to system architect/tech lead with a lot of ml chops. Or a director if you’re more interested in managing. Throw in some devops and enough frontend to prototype and you’d be well rounded for something like that if you’re interested. Those types of roles require you to know enough about everything to make it work.",
              "score": 2,
              "created_utc": "2026-02-17 04:44:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5rpbb4",
          "author": "ArchimedesBathSalts",
          "text": "I think you misunderstand the nature of the field you are in. ML algorithms are overrepresented in education but a small fraction of what matters in the job.",
          "score": 11,
          "created_utc": "2026-02-16 22:57:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qv5ph",
          "author": "Single_Vacation427",
          "text": "You can do things on the side. Block work time to do your own project.\n\nAlso, it won't hurt you in interviews as long as you have good stories about your job. They are not going to ask you a play by play of your time there.  Even a 'data analyst' type work can have a lot of impact.",
          "score": 11,
          "created_utc": "2026-02-16 20:27:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r5nnh",
              "author": "Tenet_Bull",
              "text": "Thanks, I think my grad program can fill in the role of data science side projects too",
              "score": 2,
              "created_utc": "2026-02-16 21:18:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qv08f",
          "author": "Euphoric-Advance8995",
          "text": "Whatever job you have, regardless of profession: the more you do stuff that you enjoy the happier you’ll be AND SEPARATELY the more you do stuff that will be relevant in the future the more you’re going to stay relevant. \n\nIf your goal is career progression as an IC and you are working on stuff you don’t enjoy or think will be relevant then for sure you’re stunted. I won’t argue that one of ML vs SWE vs analytics is more automatable bc nobody can tell at this point (tho certainly everyone has their own opinions). \n\nIf you want to be doing DS bc you enjoy it or think it’s more relevant I would find ways to carve out side projects and demonstrate business impact to justify the investment.",
          "score": 4,
          "created_utc": "2026-02-16 20:26:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r0cpt",
          "author": "Beginning_Cup7065",
          "text": "Focus more on building domain expertise. In 5 years, you’ll be applying to mid or senior level roles and domain expertise is what matters the most in those interviews.\n\nWhat is the domain of your team? Is it rec sys? If yes, read papers and use SoTA approaches for each model you build. When interviewing for new roles, focus only on rec sys roles and, your hiring manager will be mostly concerned on how you solved the business problems using latest methods. They wont care about whether you built an object detection model with Computer Vision.\n\nIf you keep chasing shiny names - CV today, NLP tomorrow, you won’t build enough experience in one domain to compete for senior roles in 5 years.\n\nAlso, don’t waste your time doing side projects, except if you have interest in that area",
          "score": 3,
          "created_utc": "2026-02-16 20:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qzcw3",
          "author": "Tells_only_truth",
          "text": "Sounds about right tbh",
          "score": 2,
          "created_utc": "2026-02-16 20:48:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s1h73",
          "author": "torsorz",
          "text": "It's nice to hear this is somewhat common, haha. I started a new role in data science a few months ago and I've done literally zero data science, but learning lots about maintaining data pipelines and so on (which is nice because it's basically impossible to find a personal project that involves implementing an actual automated pipeline).",
          "score": 2,
          "created_utc": "2026-02-17 00:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r0gc7",
          "author": "Potential_Swimmer580",
          "text": "Unless you’re in a research based role this seems the norm for most of us. In my experience these last few years at least there’s been a shift from less analytics to more SWE",
          "score": 1,
          "created_utc": "2026-02-16 20:53:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sv8xj",
          "author": "Pvt_Twinkietoes",
          "text": "Lucky! I'm building automation pipeline most of the time!",
          "score": 1,
          "created_utc": "2026-02-17 03:02:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sydca",
          "author": "AccordingWeight6019",
          "text": "Good perspective. Real data science is often more about ownership and impact than constant model building. Staying intentional about growth and documenting real outcomes is what keeps the experience valuable long term. ",
          "score": 1,
          "created_utc": "2026-02-17 03:22:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tchqd",
          "author": "KnowledgeExciting627",
          "text": "It won’t hurt you automatically, but it can if you’re passive about it.\n\nIf you spend five years building one XGBoost model a year and mostly doing maintenance and reporting, you’ll drift toward analytics / applied data / platform work rather than core data science. That’s not bad, but it’s different from experimental ML or research-heavy roles.\n\nThe bigger risk isn’t the lack of “sexy” projects. It’s the lack of experimentation, model iteration, and measurable impact stories. That’s what future DS interviews will probe.\n\nIf the job gives you stability, grad funding, and 401k vesting, that’s real value. Just make sure you deliberately build depth on the side. Improve the modeling pipeline, add evaluation rigor, experiment offline, contribute to something ML-heavy internally, or run personal projects.\n\nFive stable years with no growth is risky. Five stable years with intentional skill building is powerful.",
          "score": 1,
          "created_utc": "2026-02-17 04:58:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tflrc",
          "author": "Embarrassed_Army_670",
          "text": "Nice to hear I’m not the only who experiences this",
          "score": 1,
          "created_utc": "2026-02-17 05:21:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u0jxh",
          "author": "the_Wallie",
          "text": "* morpheus voice * welcome to the real world. ",
          "score": 1,
          "created_utc": "2026-02-17 08:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u59bx",
          "author": "Ghost-Rider_117",
          "text": "honestly this sounds pretty normal for most DS roles tbh. the \"pure\" ML research job is kinda rare outside of big tech or research labs. most of us spend a ton of time on pipelines, data quality, stakeholder management, etc.\n\n\n\nthat said - if you're worried about your skills getting rusty, maybe carve out some side project time? even just kaggle competitions or contributing to open source can keep your modeling sharp. plus having that github activity helps when job hunting later.\n\n\n\nthe variety might actually be a good thing for your career long-term - being able to build AND deploy models is super valuablehonestly this sounds pretty normal for most DS roles tbh. the \"pure\" ML research job is kinda rare outside of big tech or research labs. most of us spend a ton of time on pipelines, data quality, stakeholder management, etc.\n\n\n\nthat said - if you're worried about your skills getting rusty, maybe carve out some side project time? even just kaggle competitions or contributing to open source can keep your modeling sharp. plus having that github activity helps when job hunting later.\n\n\n\nthe variety might actually be a good thing for your career long-term - being able to build AND deploy models is super valuable",
          "score": 1,
          "created_utc": "2026-02-17 09:08:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uq7fu",
          "author": "Lord_Skellig",
          "text": "I feel ya. I just left a job because I was sick of doing analysis on xgboost models, and really wanted to do more deep learning again.",
          "score": 1,
          "created_utc": "2026-02-17 12:12:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uyeux",
          "author": "jesusonoro",
          "text": "the 75% thats not modeling is honestly what makes you hireable. every DS candidate can fit xgboost, way fewer can own the pipeline end to end and actually talk to the business about it",
          "score": 1,
          "created_utc": "2026-02-17 13:07:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uyt27",
          "author": "patternpeeker",
          "text": "i’d say it won’t ruin u, but in five years u might have a thin portfolio of pure data science work. if u want to move later, maybe find ways to sneak in small projects that show experimentation",
          "score": 1,
          "created_utc": "2026-02-17 13:09:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w3f8m",
          "author": "madbadanddangerous",
          "text": "I've been dismayed by the lack of data science and machine learning I've done in my career, after spending so much time and effort getting into the field. Mostly it's programming work to enable data science, or just programming in general. As well as meetings and keeping all the bureaucrats happy (especially in enterprise jobs). My startup experience was more fun but also super crazy, and even then, not all that much ML/DS work. At this point, I'm not sure how many data scientists are actually sciencing any data",
          "score": 1,
          "created_utc": "2026-02-17 16:42:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w6w4w",
          "author": "Bananana_man",
          "text": "Sounds pretty normal to me. And on top of it you’ll be vested and had your program paid for. I’m in a very similar situation after 3 years. Just try doing some personal projects and continue to learn. Just because your done with school/program doesn’t mean you can’t learn independently",
          "score": 1,
          "created_utc": "2026-02-17 16:59:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r1aj6",
          "author": "BodybuilderUpbeat786",
          "text": "Join an investment bank, the engineering side is abstracted away from us, I use Pandas every day at JPMC (obviously depends on the team you join).",
          "score": 0,
          "created_utc": "2026-02-16 20:57:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r53jy3",
      "title": "Best technique for training models on a sample of data?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r53jy3/best_technique_for_training_models_on_a_sample_of/",
      "author": "RobertWF_47",
      "created_utc": "2026-02-15 02:54:52",
      "score": 37,
      "num_comments": 24,
      "upvote_ratio": 0.89,
      "text": "Due to memory limits on my work computer I'm unable to train machine learning models on our entire analysis dataset. Given my data is highly imbalanced I'm under-sampling from the majority class of the binary outcome. \n\nWhat is the proper method to train ML models on sampled data with cross-validation and holdout data?\n\nAfter training on my under-sampled data should I do a final test on a portion of \"unsampled data\" to choose the best ML model?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r53jy3/best_technique_for_training_models_on_a_sample_of/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o5h69oy",
          "author": "AccordingWeight6019",
          "text": "Key rule: only sample the training data, never validation or test data. Split first, keep validation and holdout sets in the original imbalanced distribution, then apply under sampling inside each CV training fold. Select models based on performance on the untouched validation data, and do the final evaluation once on a fully unsampled holdout set. ",
          "score": 30,
          "created_utc": "2026-02-15 08:17:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5kgvut",
              "author": "Specialist-Gur-601",
              "text": "Depends on the situation. What you say is true when you consider each datapoint to have the same weight. Sometimes this is not true, a false positive can be much more costly than a false negative, or vice versa.\n\nIdeally you would want to factor this with sample weights and adjusted metrics (F-beta for instance), but if somehow you are restrained by memory or compute time, undersampling, even the test set, can be the most practical solution.",
              "score": 5,
              "created_utc": "2026-02-15 20:34:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5nqlpt",
                  "author": "AccordingWeight6019",
                  "text": "That’s a fair point. If memory or compute constraints are severe, under sampling the test set can be practical, but it changes what your metrics actually measure. If you do that, make sure to report that the evaluation reflects the sampled distribution and, if possible, complement it with weighted metrics or approximate evaluation on a subset of the full distribution. This way, you at least understand how performance might differ in the real world class balance. ",
                  "score": 1,
                  "created_utc": "2026-02-16 10:02:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5g43gs",
          "author": "TheTresStateArea",
          "text": "Your final test needs to be on unsampled data.",
          "score": 23,
          "created_utc": "2026-02-15 02:59:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5g8wcz",
              "author": "RobertWF_47",
              "text": "Presumably not on each of the CV testing folds but on the holdout dataset?",
              "score": 4,
              "created_utc": "2026-02-15 03:32:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5gd3m0",
                  "author": "TheTresStateArea",
                  "text": "Ultimately your model lives and she's on real world application, so yes the holdout.",
                  "score": 10,
                  "created_utc": "2026-02-15 04:03:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hkogt",
          "author": "patternpeeker",
          "text": "keep the sampling inside each cv fold, not before the split. under-sample only the training portion, then validate on untouched data with the real class imbalance. also keep a final holdout with the original distribution and use it once at the end. otherwise your metrics will look better than reality.",
          "score": 4,
          "created_utc": "2026-02-15 10:36:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hscp5",
          "author": "[deleted]",
          "text": "If you care about the accuracy of your predicted probabilities, undersampling or oversampling will affect the accuracy of your predicted probabilities. You’ll need to perform post-training model calibration to correct this issue.",
          "score": 3,
          "created_utc": "2026-02-15 11:47:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k5xib",
              "author": "RobertWF_47",
              "text": "I'm willing to have inaccurate predicted probabilities as long as rank is preserved for selecting the best threshold for predicting the 0/1 class. In that case is it ok to undersample?",
              "score": 0,
              "created_utc": "2026-02-15 19:38:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hvdnu",
          "author": "pppeer",
          "text": "In addition to what is mentioned, probably also good to approach your problem as a scoring problem rather than a classification problem and use metrics such as AUC. At minimum, if you are making hard labeling decisions or expecting a probability rather than a score, calibrate the models on the unsampled data.",
          "score": 2,
          "created_utc": "2026-02-15 12:13:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i0l9a",
          "author": "Ty4Readin",
          "text": "As a general rule of thumb, undersampling any class is NOT a good idea. It almost always does worse in practice if you are using the correct loss function/evaluation metrics.\n\nBut, if you are going to do it, then you should only ever do it on the training dataset, never the validation set or test set.\n\nI think there are 2 better solutions for your situation:\n\n1. Subsample the entire dataset (not just one class)\n\n2. Use a model that can support training from disk. For example neural networks are very easy to train any dataset size due to batch loading. I think there are also some implementations for other models to support similar as well.\n\n\nOne other possible option is to undersample one class, but weight it higher in the loss to counter the undersampling. But I would treat this as a hyperparameter and see if it even performs any better than just subsampling the entire dataset.",
          "score": 2,
          "created_utc": "2026-02-15 12:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k737c",
              "author": "RobertWF_47",
              "text": "I'm ok with predicted probabilities being inaccurate due to undersampling, as long as I can make reasonable predictions of the outcome class (0/1) by selecting a threshold. \n\nIf you're saying undersampling of the training data will produce worse predictions then I may have to reconsider undersampling.",
              "score": 1,
              "created_utc": "2026-02-15 19:44:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5kjriy",
                  "author": "Ty4Readin",
                  "text": "Undersampling is likely to produce worse in multiple regards, including the ordering of highest risk samples with a threshold.\n\nAs a general rule, my default be not to over or undersample any class.\n\nIf you are curious, you can treat it as a hyperparameter and see which performs better in CV. Just make sure your validation and test sets are not undersampled at all.",
                  "score": 3,
                  "created_utc": "2026-02-15 20:49:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5l70pt",
          "author": "giridharaddagalla",
          "text": "Hey, totally get the memory constraints, that's a common pain point! For under sampling imbalanced data with CV, a good approach is to perform the sampling \\*within\\* each fold of your cross validation. This way, your validation sets remain representative of the real world distribution (or at least the original imbalanced distribution), and your training sets get the balanced sampling. For your final test, yeah, testing on a portion of \\*unsampled\\* data is definitely the way to go. It gives you the most realistic performance estimate of how your chosen model will fare on unseen, real data. Some folks even do a weighted evaluation on that holdout set to account for the original class imbalance, which can be super insightful.",
          "score": 2,
          "created_utc": "2026-02-15 22:51:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lhrxu",
          "author": "Ghost-Rider_117",
          "text": "yeah I've dealt with this before - stratified sampling is definitely your friend here. make sure your sample reflects the class distribution properly, then do your train/test split on that sampled data. one thing that helped me was using SMOTE or other synthetic sampling techniques after you split, so you're not leaking info between train and validation sets. good luck!",
          "score": 2,
          "created_utc": "2026-02-15 23:54:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pf9no",
          "author": "RB_7",
          "text": "There’s lots of sampling discussion here, which is fine, but if you’re just doing log reg / xgboost then it would be a lot simpler and more robust to just write a training loop that batches through your dataset from disk, loading a bit into memory at a time, updating the weights, and then loading the next batch. \n\nThen you can use the whole dataset, and not worry at all about sampling routines.",
          "score": 2,
          "created_utc": "2026-02-16 16:23:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5q0w5q",
              "author": "RobertWF_47",
              "text": "That's a possibility I should consider.\n\nHowever my data is quite scarce: 76,000 events vs. 31M non-events for the outcome I'm predicting. Plus many of the predictors are extremely imbalanced as well. My worry is running many ML models on small subsets does not return the same robust predictions as an all-data model, but rather an average of many sub-optimal models.",
              "score": 1,
              "created_utc": "2026-02-16 18:04:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5t03mj",
                  "author": "Wellwisher513",
                  "text": "If you're using xgboost, is recommend looking into using a polars lazy dataframe. I used it for a binary classification problem last week and it worked quite well, letting me train on roughly a terabyte of data in a cluster with 700gb of ram. It's a little finicky and you need your packages to be up to date, but once I figured it out, it worked great. Worth noting that automl doesn't support it, you'll have to use optuna for any tuning. \n\n\nIf you're using any other model type though, that might not be your best bet, as polars support is still pretty new. \n\n\nAs for over/under sampling, it might be worth looking into using weights.",
                  "score": 2,
                  "created_utc": "2026-02-17 03:33:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5q535p",
                  "author": "RB_7",
                  "text": "I mean, think about how SDG works and ask yourself if batching from disk is any different.",
                  "score": 1,
                  "created_utc": "2026-02-16 18:23:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5od08x",
          "author": "VelvetCactus01",
          "text": "Use stratified sampling to preserve class distribution. Train on your sample, validate on holdout, test final on untouched data. That's the framework.",
          "score": 1,
          "created_utc": "2026-02-16 13:05:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i5joj",
          "author": "PublicViolinist2338",
          "text": "It depends a lot on your situation, are you training neural networks or using something based on the Scikit API? In any case train/val/test splitting is crucial, but the implementation depends",
          "score": 1,
          "created_utc": "2026-02-15 13:29:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jm7m6",
              "author": "RobertWF_47",
              "text": "Probably not neural networks - penalized logistic regression, xgboost, maybe SVM.",
              "score": 1,
              "created_utc": "2026-02-15 18:02:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jui8h",
                  "author": "PublicViolinist2338",
                  "text": "Alright, it's actually not trivial to implement in that case. XGBoost and similar libraries typically want you to load the whole train data into memory before you call .fit. They have a solution: [https://xgboost.readthedocs.io/en/stable/tutorials/external\\_memory.html](https://xgboost.readthedocs.io/en/stable/tutorials/external_memory.html), but I am not sure about other scikit libraries\n\n",
                  "score": 2,
                  "created_utc": "2026-02-15 18:42:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r40rd2",
      "title": "Where do you see HR/People Analytics evolving over the next 5 years?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r40rd2/where_do_you_see_hrpeople_analytics_evolving_over/",
      "author": "Proof_Wrap_2150",
      "created_utc": "2026-02-13 20:50:35",
      "score": 25,
      "num_comments": 12,
      "upvote_ratio": 0.82,
      "text": "Curious how practitioners see the field shifting, particularly around:\n\n* AI integration\n* Predictive workforce modeling\n* Skills-based org design\n* Ethical boundaries\n* Data ownership changes\n* HR decision automation\n\nWhat capabilities do you think will define leading functions going forward?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r40rd2/where_do_you_see_hrpeople_analytics_evolving_over/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o58b8wi",
          "author": "JamesDaquiri",
          "text": "Probably a post better suited for r/humanresources as I can’t image there are many PA professionals here. Probably a lot of people who think HR are evil puppet masters or something. \n\nTo your post, it’s just impossible to say. Things are evolving quickly- so I don’t have any input on tools or methodology changes. \n\nBut I will say (and this applies to most domains), being able to show your value and communicate strategic insights that are actually incorporated is and will be a make or break for the field. You have to be technical, persuasive, and privy to building and maintaining professional relationships if you want to thrive in this niche. Being a people-person with data skills and a background in the domain (HRM, IO psych) is what companies are after right now, and I don’t see that changing.\n\nEdit: also, I don’t think automated HR decision making should now nor ever go beyond algorithmic resume parsing and pre-hire assessment scoring. With how much red tape (and rightfully so) exists in labor practices, the “human-in-the-loop” aspect of automation/AI is more crucial than other domains.",
          "score": 21,
          "created_utc": "2026-02-13 20:57:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59aiym",
              "author": "Proof_Wrap_2150",
              "text": "Thank you for your response!",
              "score": 1,
              "created_utc": "2026-02-14 00:06:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o58bj5d",
          "author": "Trick-Interaction396",
          "text": "I think you mean Clanker Analytics",
          "score": 24,
          "created_utc": "2026-02-13 20:58:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58d8r6",
          "author": "coconut48282736",
          "text": "I work as a DS in people analytics at a F500. As far as I see it, I don’t see a roadmap for automation of decisions as a result of AI, but there is a clear road to use DS and AI to recommend, facilitate, and create self serve data engines for HR leaders. I’m an IC though, not a manager.\n\nThe current path I see for 5 years is less human interaction needed to make data pulls/aggregations. More emphasis on creating generalizable tools that let HR leaders make all those decisions themselves without needed interaction from a DS. DS will likely focus on more complex experimentation and modeling.",
          "score": 6,
          "created_utc": "2026-02-13 21:07:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k3q8j",
              "author": "jgmz-",
              "text": "Was also a DS in people analytics for sometime. I agree with your last point - internal audience segmentation and predictive modeling will continue to be common applications in the domain. I think in 5 years, decision sciences as a whole will become more valuable after AI has solved reporting (or at least made more accessible) for the simpler analysis pipelines.",
              "score": 1,
              "created_utc": "2026-02-15 19:27:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d5ks7",
          "author": "AIAlchemy",
          "text": "There are 2 parallel trends because of AI. 1) Like any other functions HR managers become more self sufficient with pulling data and making analysis without relying on an analyst or data scientist. They can also do a lot more analysis and faster than before. However not everyone is qualified to interpret the data. 2) The workforce is changing at a rapid pace, and what skills used to matter (technical) don't matter as much with the help of AI but judgment and people skills are still in limited quantity. So HR has a critical role to play in rethinking how the workforce needs to evolve (hiring, training performance reviews....)",
          "score": 2,
          "created_utc": "2026-02-14 16:53:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a9gg8",
          "author": "jdnhansen",
          "text": "Imagine that all HR teams have cheap access to coding skills and interns. In that world, you would value people who can effectively made good decisions about what to do with an abundance of coding/intern labor. I expect somewhat smaller HR teams with more experienced practitioners. On the Analytics side, you want people with a mix of tech skills, industry expertise, and communication/collaboration skills. \n\nI lead a small people science team, and we are using AI to build new solutions in-house. It’s mostly AI assistance with coding (eg R/Python/SQL/terminal), but we just brought on board a new AI agent solution, and that seems very powerful, too.",
          "score": 1,
          "created_utc": "2026-02-14 03:48:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hw33s",
          "author": "pppeer",
          "text": "This is a broad question, but recruitment is definitely a priority areas such as defense, energy and utility market and other understaffed markets. Another one is agents and workflows for HR services, lots of opportunities for streamliming and optimizing all people and employee related workflows through centralized platforms, with AI embedded. Finally, the HR area is rife with all forms of knowlede portals/bass, so in the short term there is a lot of appetite for RAG-type applications (\"what are my company holidays?\" \"Can I do company sponsored volunteering work? \" etc).",
          "score": 1,
          "created_utc": "2026-02-15 12:19:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mkkw6",
          "author": "DFW_BjornFree",
          "text": "Surprised you didn't mention anything about workplace monitoring or behavioral analytics.\n\n\nPA at my employer builds internal employee segments based upon user data collected from services like MS365, github, keys typed, and then other stuff like badge in / out, working extra hours, etc. \n\n\nBasically they determine what is normal for a certain role at a certain level because they have tons of employees at that level and they can map what good looks like to annual review ratings. Sure reviews don't map perfectly but there is correlation and they essentially use it to flag people who compared to their peers, don't appear to be very productive and this plays into giving feedback to organizational leaders and is part of what helps justify a PIP (but it isn't want triggers or causes a pip in itself)\n\n\nA persons manager isn't likely high enough to know many details but they will get feedback from their orgs leadership that it seems like xyz person isn't working much and it's basically the managers job to explain why / deffend it or else agree that the person has been slacking. \n\n\nPersonally, I actually kind of like it but that's because I have no issue working while I am at work and we all know what it feels like to have someone that both doesn't pull their weight and then also doesn't try. \n\n\nAt some point, you're too senior for some of the things to apply but that's where employee segments come into play.\n\n\nThey do care a lot though about time in the office though and managers are asked to keep notes in the system if they gave an employee special permission like being able to leave before 3 to pick up a kid and then working for a bit once they're home. In any case, they just identify things where manager input is needed to justify so if you're on good terms with leadership you're fine even if the system thinks you're underperforming however if you're on bad terms with them and you get flagged for slacking you could be screwed.",
          "score": 1,
          "created_utc": "2026-02-16 04:01:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qeht5",
          "author": "Key-Boat-7519",
          "text": "Leading functions are going to be the ones that own fewer, higher‑stakes questions end to end, not the ones with the fanciest models. Think “who we hire, how we pay, who we keep” with clear financial impact, ethics guardrails, and change ownership. AI will mostly be workflow and decision support: nudging managers, surfacing risk, and automating boring admin, while humans arbitrate tradeoffs. Real edge will be in stitching data across HRIS, ATS, L&D, and equity/comp tools like Workday, Greenhouse, and Cake Equity so you can model scenarios and show the CFO hard tradeoffs, not just dashboards. That ability to connect decisions to business outcomes will define the leaders.",
          "score": 1,
          "created_utc": "2026-02-16 19:06:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ubzkp",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 1,
          "created_utc": "2026-02-17 10:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d1e3a",
          "author": "Cheap_Scientist6984",
          "text": "They will get better at hiring who they want and the office will start to look like the Bunker in Fallout where everyone is microchipped to be a super agreeable woman.  ",
          "score": 0,
          "created_utc": "2026-02-14 16:32:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r24okt",
      "title": "Rescaling logistic regression predictions for under-sampled data?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r24okt/rescaling_logistic_regression_predictions_for/",
      "author": "RobertWF_47",
      "created_utc": "2026-02-11 18:05:18",
      "score": 24,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "I'm building a predictive model for a large dataset with a binary 0/1 outcome that is heavily imbalanced.\n\nI'm under-sampling records from the majority outcome class (the 0s) in order to fit the data into my computer's memory prior to fitting a logistic regression model.\n\nBecause of the under-sampling, do I need to rescale the model's probability predictions when choosing the optimal threshold or is the scale arbitrary?",
      "is_original_content": false,
      "link_flair_text": "ML",
      "permalink": "https://reddit.com/r/datascience/comments/1r24okt/rescaling_logistic_regression_predictions_for/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o4ub72f",
          "author": "Lamp_Shade_Head",
          "text": "My first question would honestly be why you decided to sample the data in the first place. Did you try building a model on the full dataset as it is?\n\nIn my field we regularly deal with less than a 1 percent bad rate, and I have yet to see anyone rely on under or over sampling in practice. Usually the approach is to build the model on the original data, generate a precision recall curve or another metric that fits the use case, and then choose a probability threshold based on that.\n\nIf you really feel the need to adjust for class imbalance, I would lean toward using sampling weights rather than actually under sampling or over sampling the data.",
          "score": 22,
          "created_utc": "2026-02-11 18:21:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ugl8v",
              "author": "RobertWF_47",
              "text": "Thank you. Yes, normally I wouldn't sample the data, but in this case the analysis dataset is too big to fit into our memory for analysis so we have to resort to sampling. And the data is imbalanced, 74K events out of 31M records (0.24%), with several hundred binary predictors which are also sparse.",
              "score": 6,
              "created_utc": "2026-02-11 18:46:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4uloz7",
                  "author": "Lamp_Shade_Head",
                  "text": "That makes sense. For your question, I think if you use down sampling but do NOT use sampling weights, the interpretation might change. But if you  do downsample and use sampling weights during model fit, the probability interpretation will not change since the effective class distribution is restored as weights are used in the loss function.\n\nSomeone Please feel free to correct if I am wrong.",
                  "score": 9,
                  "created_utc": "2026-02-11 19:10:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4wwlnk",
                  "author": "hyperactivedog",
                  "text": "Figure out your max data size, down sample uke majority until you're there. \n\nOr do quantile binning and weight by counts.",
                  "score": 3,
                  "created_utc": "2026-02-12 02:28:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4xsjvu",
                  "author": "ArcticGlaceon",
                  "text": "Why can't you sample proportionately for each class?",
                  "score": 2,
                  "created_utc": "2026-02-12 06:14:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4va434",
          "author": "Infinitedmg",
          "text": "You should never undersample unless you've run into compute/memory limitations. There's no good statistical reason to undersample.\n\nIf you did undersample, you only need to tweak the intercept term such that the predicted mean probability matches the mean of the overall dataset. In the case of undersampling, you would need to lower the intercept term, as you have inflated the occurrence of the positive class.",
          "score": 6,
          "created_utc": "2026-02-11 21:07:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ubn7g",
          "author": "occamsphasor",
          "text": "It really depends more on what the decision boundary looks like… I would start by doing some plotting and looking at precision and recall for the underrepresented class and go from there.",
          "score": 4,
          "created_utc": "2026-02-11 18:23:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uhaj9",
              "author": "RobertWF_47",
              "text": "That's what I'm thinking - using a precision-recall curve to select the threshold.",
              "score": 2,
              "created_utc": "2026-02-11 18:49:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xokbl",
                  "author": "ConsistentLynx2317",
                  "text": "Question, would you use a precision recall curve or an roc-auc curve to choose potential threshold? I’m still new sorry. Why the p/r curve?",
                  "score": 3,
                  "created_utc": "2026-02-12 05:40:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vctwh",
          "author": "DefinitelyNotActuary",
          "text": "Doesn’t matter what the scaling is if you only care about the predictions. It will move the probabilities around but ultimately the order of your observations from a predicted probability standpoint is not changed. If you actually use probabilities you will need to calibrate with something like betacal or other technique.",
          "score": 3,
          "created_utc": "2026-02-11 21:20:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wtyak",
          "author": "orz-_-orz",
          "text": "Model calibration",
          "score": 2,
          "created_utc": "2026-02-12 02:12:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wwdc7",
          "author": "hyperactivedog",
          "text": "I haven't needed to worry about sampling much with xgboost and similar for binary classification problems. It's only really a probably if you've got a billion or so observations and/or hundreds of features. \n\nI do have one pipeline that samples down the largest class (out of a dozen) until I'm down to 50m observations but that's more about memory management than statistical performance.",
          "score": 2,
          "created_utc": "2026-02-12 02:27:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y013s",
          "author": "rsambasivan",
          "text": "There are two approaches I am aware of to solve this:  \n(1) Use resampling to address the imbalance (check out imblearn if you are using python)\n\n(2) Work with the imbalance (assuming that you are not in like outlier territory, where you have 5 records for the minority class and 1 million for the majority class), then recaliberate your classifier. So this means build your classifier with your favorite algorithm, logistic, random-forest, xg-boost, whatever gives you a decent performance on a test set, recaliberate it - sklearn has isotonic regression and platt scaling, choose the one one that gives you the best result.\n\nPractically, in these kind of problems, you need to understand and determine the trade off between the false positive rate and the false negative rate. This is in relation to picking a threshold for classifying an example as a positive - 0.5 won't be optimal. In a marketing application, false positives may be one you control, in a health care setting (screening for a disease), a false negative is what you control. But to get back to your question, if you choose to work with the imbalance, then recalibration usually helps. Good luck",
          "score": 2,
          "created_utc": "2026-02-12 07:21:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yopvr",
          "author": "patternpeeker",
          "text": "if u under sample, the predicted probabilities won’t reflect the true base rate. the ranking may still work, but calibration will be off unless u correct for the original class prior. using class weights is often cleaner if memory allows.",
          "score": 2,
          "created_utc": "2026-02-12 11:18:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54cfny",
          "author": "DaxyTech",
          "text": "Great question -- this trips people up more often than you'd think. When you undersample your majority class, you shift the base rate in your training data, so the raw predicted probabilities are no longer calibrated to the true population distribution. The standard correction is Platt scaling or the offset adjustment. For logistic regression: p\\_corrected = p\\_model / (p\\_model + (1 - p\\_model) \\* (beta\\_0 / beta\\_1)) where beta\\_0 is the negative class sampling rate and beta\\_1 is the positive class sampling rate. I'd also recommend calibration curves (sklearn.calibration.calibration\\_curve) before and after correction. Isotonic regression calibration works well if the relationship isn't cleanly monotonic. Watch out: if undersampling is aggressive (like 1:1 on a 99:1 problem), even the correction might not fully recover calibration at extremes. Consider SMOTE or a weighted loss function instead.",
          "score": 2,
          "created_utc": "2026-02-13 06:16:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56joms",
              "author": "RobertWF_47",
              "text": "Thank you! For prediction (not causal inference) the scale of the predicted probabilities is shifted when undersampling but the order remains the same, right? So when choosing an optimal threshold to predict 1 vs 0 the Platt scaling isn't necessary?",
              "score": 1,
              "created_utc": "2026-02-13 15:48:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o55nxb7",
          "author": "Comfortable_Newt_655",
          "text": "that is a really common problem\n\n",
          "score": 2,
          "created_utc": "2026-02-13 13:02:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3gi4p",
      "title": "What would you do with this task, and how long would it take you to do it?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r3gi4p/what_would_you_do_with_this_task_and_how_long/",
      "author": "TheTresStateArea",
      "created_utc": "2026-02-13 05:14:42",
      "score": 11,
      "num_comments": 11,
      "upvote_ratio": 0.69,
      "text": "I'm going to describe a situation as specifically as I can. I am curious what people would do in this situation, I worry that I complicate things for myself. I'm describing the whole task as it was described to me and then as I discovered it.\n\nUltimately, I'm here to ask you, **what do you do, and how long does it take you to do it?**\n\n\nI started a new role this month, I am new to advertising modeling methods like mmm, so I am reading a lot about how to apply the methods specific to mmm in R and python, I use VScode, I don't have a github copilot license, I get to use copilot through windows office license. Although this task did not involve modeling, I do want to ask about that kind of task another day if this goes over well.\n\n\n##### The task\n5, excel sheets are to be provided. You are told that this is a clients data that was given to another party for some other analysis and augmentation. This is a quality assurance task. The previous process was as follows;\n\n##### the data\n* the data structure: 1 workbook per industry for 5 industries\n* 4 workbooks had 1 tab, 1 workbook had 3 tabs\n* each tab had a table that had a date column in days, 2 categorical columns advertising_partner, line_of_business and at least 2 numeric columns per work book.\n* some times data is updated from our side and the partner has to redownload the data and reprocess and share again\n\n##### the process\n* this is done once per client, per quarter (but it's just this client for now)\n* open each workbook\n* navigate to each tab\n* the data is in a \"controllable\" table\n\n |   | | | | |\n---|---|---| ---|---|---|\nbing| bing | | |\nhome | home | | |\nimpressions | spend | | partner dropdown| line of business dropdown\n\n* where bing and home are controlled with drop down toggles, with a combination of 3-4 categories each.\n* compare with data that is to be downloaded from a tableau dashboard\n* end state: the comparison of the metrics in tableau to the excel tables to ensure that \"the numbers are the same\"\n* the categories presented map 1 to 1 with the data you have downloaded from tableau\n* aggregate the data in a pivot table, select the matching categories, make sure the values match\n\n\n\n#### additional info about the file\n*  the summary table is a complicated sumproduct look up table against an extremely wide table hidden to the left. the summary table can start as early as AK and as late as FE.\n* there are 2 broadly different formats of underlying data in the 5 notebooks, with small structure differences between the group of 3.\n\n###### in the group of 3\n* the structure of this wide table is similar to the summary table with categories in the column headers describing the metric below it. but with additional categories like region, which is the same value for every column header. 1 of these tables has 1 more header category than the other 2\n* the left most columns have 1 category each, there are 3 date columns for day, quarter.\n\n\n| | | | | | |\n|---|---|----|----| ---- | ---- | ---- | ---- |\n| | | | \n| | REGION |  | USA | USA | USA\n| | PARTNER | | bing  | bing | google |\n| | LOB | | home | home | auto |\n|  |  |  | impressions | spend | ...etc|\n| date | quarter|  | impressions| spend | ...etc|\n| 2023-01-01 | q1|  | 1| 2 | ...etc |\n| 2023-01-02 | q1|  | 3| 4 | ...etc |\n\n\n###### in the group of 2\n\n* the left most categories are actually the categorical headers in the group of 3, and the metrics, the values in each category mach\n* the dates are now the headers of this very wide table\n* the header labels are separated from the start of the values by 1 column\n* there is an empty row immediately below the final row for column headers.\n\n\n| | | | | | | |\n|---|---|----|----| ---- | ---- | ---- | ---- | ---- |\n| | | | date Label| | 2023-01-01 | 2023-01-02 |\n| | | | year| | 2023 | 2023 |\n| | | | quarter| | q1 | q1 | \n| blank row | | | | | | |\n| REGION | PARTNER | LOB | measure| | | |\n| blank row | | | | | | |\n| US | bing | home | impressions |  | 1 | 3| \n| US | bing | home | spend |  | 2 | 4 | \n| US | google | auto | ...etc | | ...etc | ... etc|\n\n\nThe question is, what do you do, and how long does it take you to do it?\n\nI am being honest here, I wrote out this explaination basically in the order in which I was introduced to the information and how I discovered it. *(Oh it's easy if it's all the same format even if it's weird, oh there are 2-ish different formatted files)*\n\nthe meeting of this task ended at 11:00AM. I saw this copy paste manual etl project and I simply didn't want to do it. So I outlined my task by identifying the elements of the table, column name ranges, value ranges, stacked / pivoted column ranges, etc... for an R script to extract that data. by passing the ranges of that content to an argument `make_clean_table(left_columns=\"B4:E4\", header_dims=c(..etc))` and functions that extract that convert that excel range into the correct position in the table to extract that element. Then the data was transformed to create a tidy long table.\n\nthe function gets passed once per notebook extracting the data from each worksheet, building a single table with the columns for the workbook industry, the category in the tab, partner, line of business, spend, impressions, etc...\n\nIMO; ideally (if I *have* to check their data in excel that is), I'd like the partner to redo their report so that I received a workbook with the underlying data in a traditionally tabular form and their reporting page to use power query and table references and not cell ranges and formula.",
      "is_original_content": false,
      "link_flair_text": "Analysis",
      "permalink": "https://reddit.com/r/datascience/comments/1r3gi4p/what_would_you_do_with_this_task_and_how_long/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o545z6h",
          "author": "AnnuallySimple",
          "text": "Honestly this sounds like absolute hell 💀 \n\n  \nI would've done exactly what you did - write a script to parse those nightmare Excel files rather than manually clicking through dropdowns and comparing values. The fact that they have two completely different formats mixed in there just screams \"someone cobbled this together over years without any standardization\"\n\n  \nFor time estimate, probably would've taken me a full day to write the R functions to handle both formats, especially with all those hidden columns and weird sumproduct lookups. The manual way they wanted? That's easily 2-3 days of mind-numbing work that you'd probably mess up anyway\n\n  \nYour suggestion about getting the partner to standardize their output is spot on - this whole setup feels like technical debt that everyone's just living with because \"that's how we've always done it\" 😂",
          "score": 20,
          "created_utc": "2026-02-13 05:24:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o549cza",
              "author": "dash_44",
              "text": "Yea this sounds awful and you know none of these files will be the same format the next time OP receives them.",
              "score": 4,
              "created_utc": "2026-02-13 05:51:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54bbqk",
                  "author": "TheTresStateArea",
                  "text": "That's a good concern, I checked the previous quarter's files before I started to see if they were the same as this quarters version of them, and they were thankfully.",
                  "score": 3,
                  "created_utc": "2026-02-13 06:07:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5470j4",
              "author": "TheTresStateArea",
              "text": "I don't think the mmm projects will be less complicated lol",
              "score": 3,
              "created_utc": "2026-02-13 05:32:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o54j5dv",
          "author": "gocurl",
          "text": "That looks like pure etl fun!\nIf it was a one-off i would go dirty and hopefully do this in a day with the objective to merge all and create one single table.\nThe problem is to \"scale\" this for more workbooks, and also for next time.\nSome orher options: do the etl with other tools like KMINE, power-bi or n8n to create your workflow.\nGood luck!",
          "score": 13,
          "created_utc": "2026-02-13 07:14:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a432c",
          "author": "Key_Post9255",
          "text": "Create a modular pipeline if you can. Each module a spreadsheet. Then create a wiring module. I would avoid different notebooks as it keeps things messy and difficult to replicate/scale.",
          "score": 3,
          "created_utc": "2026-02-14 03:11:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bf2w1",
              "author": "BrettPitt4711",
              "text": "This is the way. It can be fine to start with different notebooks just to be able to focus on a single thing at a time but later combine them to a clean unified solution.",
              "score": 1,
              "created_utc": "2026-02-14 09:52:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55ntwi",
          "author": "Comfortable_Newt_655",
          "text": "that sound really hard",
          "score": 1,
          "created_utc": "2026-02-13 13:01:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qcwfv",
          "author": "DaxyTech",
          "text": "You absolutely made the right call scripting this out. For recurring quarterly QA tasks like this, the automation ROI pays for itself after the second run and you eliminate the human error risk that comes with manually cross-referencing pivot tables across workbooks. One thing I'd add: consider building a lightweight validation layer that automatically flags discrepancies above a threshold rather than just extracting data. Pull the Tableau data programmatically (most deployments support data export via REST API or tabcmd), run your R extraction on the Excel files, then compute and log the diffs. That way QA becomes a single-command operation. For the format inconsistency across workbooks, I'd recommend abstracting your parser so each workbook type maps to a config rather than hardcoding ranges. If the partner changes their format next quarter, you just update the config instead of rewriting logic. Biggest time sink is usually the initial format discovery, which sounds like what took most of your day. Once encoded, subsequent quarters should be 30 min max.",
          "score": 1,
          "created_utc": "2026-02-16 18:59:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v5fue",
          "author": "AbrocomaAny8436",
          "text": "Your instinct to refuse the manual copy-paste was 100% correct. But your execution (the R script) is a thermodynamic trap.\n\nYou wrote a script that relies on hardcoded cell ranges (`left_columns=\"B4:E4\"`). The moment the client adds a new region or line of business, your script will read the wrong columns, the QA will fail, and you will spend your Friday debugging ETL code for a formatting change.\n\nYou are treating their Excel file as a **Data Transport Layer**. They are treating it as a **Presentation Layer** (basically a digital PDF). Never write custom ETL scripts against a presentation layer.\n\n**Here is what you actually do, and how long it takes:**\n\n**1. The Short-Term Fix (30 minutes): Use Power Query.** Drop R for this. Excel has Power Query built-in. Point PQ at the folder containing the 5 workbooks. Tell it to grab the hidden raw data tables, select the category columns, and click 'Unpivot Other Columns'. It natively handles the wide-to-long transformation dynamically. If they add 10 new columns next quarter, Power Query unpivots them automatically without breaking.\n\n**2. The Long-Term Fix (10 minutes): The Data Contract.** You mentioned you are moving into MMM (Marketing Mix Modeling). MMM requires pristine time-series data. You cannot build MMM models on sumproduct presentation tabs. Send this email to the partner: *'To ensure automated QA and ingest for our MMM modeling, we can no longer accept pivoted presentation workbooks. Moving forward, please export the raw underlying data as a flat CSV in the following format: Date | Partner | Region | LOB | Impressions | Spend.'*\n\nThey are pulling this data from a SQL database or a dashboard before they mangle it into Excel. It is actually *easier* for them to give you a flat CSV.\n\nDo not become the maintainer of a brittle R script that parses hidden Excel tables. Enforce the data contract, or use Power Query if you are forced to ingest garbage.",
          "score": 0,
          "created_utc": "2026-02-17 13:48:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vlm2g",
              "author": "TheTresStateArea",
              "text": "Man you didn't even read the post before you fed it to copilot or whatever.",
              "score": 1,
              "created_utc": "2026-02-17 15:13:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3zq14",
      "title": "Mock interviews",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r3zq14/mock_interviews/",
      "author": "No-Mud4063",
      "created_utc": "2026-02-13 20:10:21",
      "score": 10,
      "num_comments": 8,
      "upvote_ratio": 0.92,
      "text": "Any other platform like prepfully for mock interviews from faang ds? Prepfully charges a lot. Any other place?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r3zq14/mock_interviews/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o5bxzbg",
          "author": "polarkyle19",
          "text": "I would like to know if you find any",
          "score": 7,
          "created_utc": "2026-02-14 12:44:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o582phk",
          "author": "Forsaken-File9993",
          "text": "pramp is free option but quality can be inconsistent, also check if your university has career services that do mock interviews",
          "score": 2,
          "created_utc": "2026-02-13 20:14:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g1i16",
          "author": "[deleted]",
          "text": "Stratascratch.",
          "score": 1,
          "created_utc": "2026-02-15 02:41:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5g1ybu",
              "author": "No-Mud4063",
              "text": "for mock interviews? ",
              "score": 0,
              "created_utc": "2026-02-15 02:44:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5g27fg",
                  "author": "[deleted]",
                  "text": "Yess!! It's actually one of the best one. And ask you questions based on the company you chose.",
                  "score": 1,
                  "created_utc": "2026-02-15 02:46:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r60jl0",
      "title": "Weekly Entering & Transitioning - Thread 16 Feb, 2026 - 23 Feb, 2026",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r60jl0/weekly_entering_transitioning_thread_16_feb_2026/",
      "author": "AutoModerator",
      "created_utc": "2026-02-16 05:01:10",
      "score": 8,
      "num_comments": 9,
      "upvote_ratio": 0.84,
      "text": " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/datascience/comments/1r60jl0/weekly_entering_transitioning_thread_16_feb_2026/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o5nofgz",
          "author": "AccordingWeight6019",
          "text": "If you’re transitioning into data science, one useful focus is learning the full workflow rather than stacking courses. Try to get comfortable with: problem framing → data cleaning → simple modeling → evaluation → communicating results. Many people over index on advanced models when most real work is messy data and decision support.\n\nA good progression is:\n\n* statistics + SQL + Python fundamentals\n* exploratory analysis and visualization\n* classical ML (regression, trees, validation)\n* one or two end to end portfolio projects with clear business questions\n\nHiring tends to reward evidence that you can take ambiguous data and produce actionable insight more than knowledge of specific algorithms.",
          "score": 2,
          "created_utc": "2026-02-16 09:42:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5odyg0",
              "author": "Due-Experience-382",
              "text": "how important is it to know the math behind the ML models, in detail?\n\nI'm learning Linear Regression but in great detail, and the professor is going deeply into the mathematics behind it, it is interesting, no doubt, but how does it change a perspective from one who has no mathematical knowledge with someone who has learned in great detail?",
              "score": 1,
              "created_utc": "2026-02-16 13:11:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nizfy",
          "author": "PublicViolinist2338",
          "text": "I have an opportunity to pursue a PhD in data science. In the long-term, is it worth it in 2026 to get the extra expertise, or should I try to find a job directly?",
          "score": 1,
          "created_utc": "2026-02-16 08:50:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nv1e9",
              "author": "pm_me_your_smth",
              "text": "A phd is a huge commitment, both effort and time wise. You need to be pretty invested in it (for whatever personal reason as long as it's solid). If you're doing it only to get a job later, then I'd recommend against it.",
              "score": 3,
              "created_utc": "2026-02-16 10:43:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5q84ow",
              "author": "2apple-pie2",
              "text": "Do not get a PhD just to get a job. Especially in a field with an unknown future like DS\n\nIf you want to get a PhD, pursue something you are passionate about first and foremost. A lot can change in 5-6 years and don’t expect a job/professorship waiting for you at the end.",
              "score": 2,
              "created_utc": "2026-02-16 18:37:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pta0z",
          "author": "Mathblasta",
          "text": "I'm about to graduate with a DS degree. It's been a lot more of a survey/broad overview than an in depth degree. I'm hoping to get started as a data analyst. \n\nRight now I feel like I have a decent grasp of Python and SQL, and after 10 years in ops management, a pretty good understanding of business processes. \n\nWhat I'd like to get more understanding of is data cleaning and processing. Are there any good courses/resources y'all could recommend for that?\n\nClasses now are focused on data warehousing and ML. What other skills should I make sure to have a grasp of to improve my chances of being able to find a job when I graduate?",
          "score": 1,
          "created_utc": "2026-02-16 17:28:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5snc4y",
          "author": "Worldly-Relation-108",
          "text": "Is there any api that can get hotel prices in Philippines easily?\n\n",
          "score": 1,
          "created_utc": "2026-02-17 02:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r19st",
          "author": "ddp26",
          "text": "Claude Code is pretty slick for data science. Who's using it? Is it helpful?",
          "score": 1,
          "created_utc": "2026-02-16 20:57:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2argg",
      "title": "Anyone ever work with Meta data?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1r2argg/anyone_ever_work_with_meta_data/",
      "author": "gengarvibes",
      "created_utc": "2026-02-11 21:49:23",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.77,
      "text": "specifically looking to try and attribute ads to conversions. the clean room solutions that Meta supports seems really expensive. anyone ever spend enough money to get exposure logs or maybe even use a CRM to help attribution?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r2argg/anyone_ever_work_with_meta_data/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o4vlgmo",
          "author": "appletothesauce",
          "text": "Pretty sure Cambridge Analytica wrote the handbook on working with Meta data. Unbeatable attribution, terrible exit strategy.",
          "score": 30,
          "created_utc": "2026-02-11 22:01:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vm6uv",
              "author": "gengarvibes",
              "text": "lol but Meta knee jerked and have since made it nearly impossible to get anything out of their platform ",
              "score": 4,
              "created_utc": "2026-02-11 22:05:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4wkcue",
                  "author": "appletothesauce",
                  "text": "You can try their platform incrementality measurement if you have CAPI set up instead of using a clean room but they still won't give you the raw data and you have to trust their calcs. If you are a national advertiser and spend enough, you could also try a geo test, shakostats com has a good tool for designing and calculating results for these tests. It's difficult to trust their on platform incrementality tests as it is like a student grading their own homework. Just look at the recommendations in the ad platforms, they want you to broaden your reach, just use AI for targeting, and spend more $$$ with them.",
                  "score": 2,
                  "created_utc": "2026-02-12 01:14:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vnf0r",
          "author": "Single_Vacation427",
          "text": "I'm pretty sure there are some research papers from professors that worked with Meta. I'd start there and maybe they have replication data without identifiers.",
          "score": 4,
          "created_utc": "2026-02-11 22:11:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vq6p7",
          "author": "Artistic-Comb-5932",
          "text": "I worked there for a few months. Don't want to dox myself but it was pretty horrible and sick place. The data depends on the project but it's all about eye balls and young kids'eye balls....",
          "score": 5,
          "created_utc": "2026-02-11 22:25:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w3jy3",
              "author": "Yourdataisunclean",
              "text": "[Don't forget the 17-strike policy for sex trafficking.  ](https://www.theverge.com/news/827658/meta-17-strike-policy-sex-trafficking-testimony-lawsuit)",
              "score": 7,
              "created_utc": "2026-02-11 23:36:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r1966a",
      "title": "2026 State of Data Engineering Survey",
      "subreddit": "datascience",
      "url": "https://joereis.github.io/practical_data_data_eng_survey/",
      "author": "Bazencourt",
      "created_utc": "2026-02-10 18:41:56",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1r1966a/2026_state_of_data_engineering_survey/",
      "domain": "joereis.github.io",
      "is_self": false,
      "comments": [
        {
          "id": "o5lbcr5",
          "author": "giridharaddagalla",
          "text": "This is awesome! I love that they released the raw data too. So much potential for deeper dives beyond just the summaries. Definitely going to check this out. Thanks for sharing!",
          "score": 2,
          "created_utc": "2026-02-15 23:15:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}