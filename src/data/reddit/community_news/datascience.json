{
  "metadata": {
    "last_updated": "2026-01-22 08:58:07",
    "time_filter": "week",
    "subreddit": "datascience",
    "total_items": 18,
    "total_comments": 184,
    "file_size_bytes": 189864
  },
  "items": [
    {
      "id": "1qh8z6e",
      "title": "Indeed: Tech Hiring Is Down 36%, But Data Scientist Jobs Held Steady",
      "subreddit": "datascience",
      "url": "https://www.interviewquery.com/p/indeed-tech-hiring-collapse-data-scientists-exception",
      "author": "warmeggnog",
      "created_utc": "2026-01-19 16:32:42",
      "score": 276,
      "num_comments": 44,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qh8z6e/indeed_tech_hiring_is_down_36_but_data_scientist/",
      "domain": "interviewquery.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0it57u",
          "author": "lordoflolcraft",
          "text": "Meanwhile applicants and new grads and outsiders trying to career change into DS are up (insert giant percentage here) percent",
          "score": 115,
          "created_utc": "2026-01-19 18:36:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jpxtx",
              "author": "RecognitionSignal425",
              "text": "\\*But Rejection of Data Scientist Jobs Held Steady",
              "score": 23,
              "created_utc": "2026-01-19 21:06:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0j7f4p",
              "author": "Zlatan13",
              "text": "Yeah lol, I'm had at least 500 rejections around September when I just figured I'd stop applying and focus more on networking within my company. Actual black hole",
              "score": 23,
              "created_utc": "2026-01-19 19:40:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0m0nfz",
              "author": "Palmquistador",
              "text": "Yep, hello. QA test automation engineer looking to make the jump to better waters.",
              "score": -1,
              "created_utc": "2026-01-20 04:30:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0j65h1",
          "author": "tits_mcgee_92",
          "text": "5 years data science experience. Masters degree in data science. I‚Äôve applied for 50 jobs and have only gotten three interviews. One of them ghosted me during the third round which was so odd",
          "score": 66,
          "created_utc": "2026-01-19 19:34:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jtlxf",
              "author": "snmnky9490",
              "text": "3 interviews out of 50 honestly seems pretty good for \"tech\" jobs these days",
              "score": 61,
              "created_utc": "2026-01-19 21:24:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0kzpbt",
              "author": "turbo_golf",
              "text": "6% app to interview is pretty good.\n\ni know the market has only gotten worse, but i applied for 400+ jobs in late 2024 and only got 4 interviews",
              "score": 22,
              "created_utc": "2026-01-20 01:03:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0m0pyo",
              "author": "Palmquistador",
              "text": "Well there‚Äôs zero hope for me then! ü§£",
              "score": 2,
              "created_utc": "2026-01-20 04:30:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pux4z",
              "author": "PuddyComb",
              "text": "Jesus.",
              "score": 2,
              "created_utc": "2026-01-20 19:10:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pv73b",
              "author": "PuddyComb",
              "text": "Welp. It's obviously time to fire everyone at LinkedIn.\n\nAgain.",
              "score": 2,
              "created_utc": "2026-01-20 19:11:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i7qe0",
          "author": "JesterOfAllTrades",
          "text": "I have ~2.5 years of experience in a well known (although not particularly known to be cutting edge) mega Corp with degrees from T10 universities. \n\nI've been applying for jobs and only really applied to like 30 so far but all rejections so far ü•≤ü•≤ I know 30 isn't much at all but I thought after my first job it would get a lot easier. Time to get back to the slog",
          "score": 54,
          "created_utc": "2026-01-19 17:00:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0imz8p",
              "author": "Watabich",
              "text": "What are you degrees in?",
              "score": 6,
              "created_utc": "2026-01-19 18:09:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0iovcv",
                  "author": "protonchase",
                  "text": "Also curious",
                  "score": 7,
                  "created_utc": "2026-01-19 18:17:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0kq8vt",
                  "author": "JesterOfAllTrades",
                  "text": "Sorry for the late reply but mathematics for both.",
                  "score": 3,
                  "created_utc": "2026-01-20 00:12:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0it1ys",
              "author": "pc_4_life",
              "text": "university you went to doesn‚Äôt really matter unless you are looking for internships. Stanford, MIT, etc might give your resume a longer look but that‚Äôs about it. 2.5 years still makes you relatively junior. market is better for mid/seniors. best thing you can do is customize your resume for the jobs you are applying to",
              "score": 2,
              "created_utc": "2026-01-19 18:35:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jm3c5",
                  "author": "Great_Northern_Beans",
                  "text": "Strongly disagree with a little bit of this. I'm a decade out of school now, and even still the university name on my degree (in the \"Stanford, MIT, etc. group; though I won't say which specifically) is heavily referenced to me in probably 50% of my interviews.¬†\n\nIt's actually crazy how many doors a brand name opens for otherwise middling candidates, like myself.",
                  "score": 21,
                  "created_utc": "2026-01-19 20:48:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0loh3v",
                  "author": "free_reezy",
                  "text": "At what point does someone become mid/senior? I‚Äôm going into year 9 and I gotta be honest I internally still feel like an entry-level guy even though I‚Äôm clearing 6 figures.",
                  "score": 1,
                  "created_utc": "2026-01-20 03:19:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0jtqrz",
              "author": "Inevitable-Pin-4507",
              "text": "You should try apps like Whileresume. You will probably get more chance to receive more interesting proposals",
              "score": 1,
              "created_utc": "2026-01-19 21:25:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iudwf",
          "author": "TA_poly_sci",
          "text": "Im sure this is in no way confounded by changes in the usage of Indeed as a platform. r datascience always delivering the best science.",
          "score": 18,
          "created_utc": "2026-01-19 18:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jglru",
          "author": "Big-Shake5075",
          "text": "Can someone find reference to this ‚Äúindeed study‚Äù? This article says DS is doing particularly bad by referring to ‚Äúindeed study‚Äù lol https://www.businessinsider.com/gruesome-tech-jobs-data-scientists-analytics-indeed-2025-11",
          "score": 2,
          "created_utc": "2026-01-19 20:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0k5e8q",
              "author": "save_the_panda_bears",
              "text": "https://www.hiringlab.org/2025/11/20/indeed-2026-us-jobs-hiring-trends-report/",
              "score": 2,
              "created_utc": "2026-01-19 22:22:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0naich",
                  "author": "Big-Shake5075",
                  "text": "This one does not even mention ds lol",
                  "score": 1,
                  "created_utc": "2026-01-20 10:56:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0livfm",
          "author": "Cheap_Scientist6984",
          "text": "This article smells.  Entry level DS hiring is not doing that well.  Same with SWE.  The entry level layer is evaporating and getting merged with Senior/Lower Middle Management.",
          "score": 2,
          "created_utc": "2026-01-20 02:48:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mdmrt",
              "author": "sailing_oceans",
              "text": "Entry level data science and swe jobs are being sent to India for $9 to $14 an hr unfortunately. \n\nThe opt f1 visa stuff is in the USA and it drags down incomes here.  I was recently forced to hire one of these visas because my company viewed them as a 0% leaving risk, a lower salary AND it‚Äôs like a ~15% discount since they don‚Äôt pay social security or Medicare.",
              "score": 4,
              "created_utc": "2026-01-20 06:01:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mh8vd",
                  "author": "Cheap_Scientist6984",
                  "text": "Fully aware.  Not even mentioning the pseudo-racist fact that these communities of people tend to be highly collectivist in culture and therefore don't like to contradict their managers.  It makes for talent that is almost slave like.",
                  "score": 2,
                  "created_utc": "2026-01-20 06:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qcwst",
              "author": "Atmosck",
              "text": "Entry level DS is a contradiction in terms. It's not an entry level role.",
              "score": 3,
              "created_utc": "2026-01-20 20:33:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mdwf4",
          "author": "Deep_Negotiation_672",
          "text": "Those non techs who are targeting data science jobs directly or transitioning their careers into DS roles directly, they should go first with data analyst roles, get experience of atleast 2-3yrs in this role then try to switch into DA role.",
          "score": 2,
          "created_utc": "2026-01-20 06:03:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m4066",
          "author": "jobswithgptcom",
          "text": "More insights from my job search site: [https://jobswithgpt.com/blog/global\\_software-engineering\\_jobs\\_january\\_2026/](https://jobswithgpt.com/blog/global_software-engineering_jobs_january_2026/) lines up as I see python is top wanted skill.",
          "score": 2,
          "created_utc": "2026-01-20 04:52:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rghf4",
              "author": "HeyLookAStranger",
              "text": "lol",
              "score": 1,
              "created_utc": "2026-01-20 23:48:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qq40v",
          "author": "reward72",
          "text": "As an employer I‚Äôm not hiring as long the circus runs the show",
          "score": 1,
          "created_utc": "2026-01-20 21:34:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpz1b",
      "title": "Spent few days on case study only to get ghosted. Is it the market or just bad employer?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/",
      "author": "Lamp_Shade_Head",
      "created_utc": "2026-01-15 17:33:30",
      "score": 85,
      "num_comments": 28,
      "upvote_ratio": 0.91,
      "text": "I spent a few days working on a case study for a company and they completely ghosted me after I submitted it. It‚Äôs incredibly frustrating because I could have used that time for something more productive. With how bad the job market is, it feels like there‚Äôs no real choice but to go along with these ridiculous interview processes. The funniest part is that I didn‚Äôt even apply for the role. They reached out to me on LinkedIn.\n\nI‚Äôve decided that from now on I‚Äôm not doing case studies as part of interviews. Do any of you say no to case studies too?",
      "is_original_content": false,
      "link_flair_text": "Career | US",
      "permalink": "https://reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzrjj7j",
          "author": "avourakis",
          "text": "No matter the state of the market, ghosting a candidate after they had a call with you or invested any amount of time beyond just applying is a sign of a poorly mismanaged recruitment team. Sorry you had that experience.",
          "score": 100,
          "created_utc": "2026-01-15 17:39:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxhw6f",
              "author": "snmnky9490",
              "text": "That's just par for the course these days, especially lower level jobs",
              "score": 4,
              "created_utc": "2026-01-16 14:59:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrkxw3",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 141,
          "created_utc": "2026-01-15 17:45:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu4q11",
              "author": "RecognitionSignal425",
              "text": "That's why take home assignment should be done by AI. OP could just use time trying to reason and argument about the choice made by AI to sound reasonable.",
              "score": 13,
              "created_utc": "2026-01-16 01:08:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv0qm6",
                  "author": "ice-truck-drilla",
                  "text": "Valid use of AI. Take-homes are ridiculous. In my experience having a normal and respectful conversation with someone to discuss their experiences and the  job description is becoming antique.",
                  "score": 3,
                  "created_utc": "2026-01-16 04:10:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrnvqr",
              "author": "chandlerbing_stats",
              "text": "Which is funny cause AI probably atleast gets them close to an answer",
              "score": 3,
              "created_utc": "2026-01-15 17:58:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrnaxx",
          "author": "dlchira",
          "text": "\"The Market\" is absolutely never an excuse to do this to an applicant.",
          "score": 44,
          "created_utc": "2026-01-15 17:55:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzro5jy",
          "author": "2up1dn",
          "text": "I decided that if I don't get hired, that I'd put any such case studies on GitHub and on my blog. \n\nThat way it's not wasted time; it's an opportunity to showcase a quick project to another client or employer.",
          "score": 88,
          "created_utc": "2026-01-15 17:59:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrx3ga",
              "author": "kevliao1231",
              "text": "Also useful if the company steals your work",
              "score": 30,
              "created_utc": "2026-01-15 18:39:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs00h0",
              "author": "BeastModeKeeper",
              "text": "This is the way",
              "score": 22,
              "created_utc": "2026-01-15 18:52:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs586e",
              "author": "TheOneWhoSendsLetter",
              "text": " Never thought of that. Great tip.",
              "score": 15,
              "created_utc": "2026-01-15 19:15:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrv65j",
          "author": "and1984",
          "text": "which company was this so that we may all avoid it and shame them?  I am sorry for your experience.  That's horrible.",
          "score": 20,
          "created_utc": "2026-01-15 18:30:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrxle0",
          "author": "DubGrips",
          "text": "I was ghosted many times recently:\n\n* A large insurance company ghosted me during the offer negotiations. I had counter offered within their range (not aggressively either). I was working with an HR rep, who didn't show up for our negotiation call and then I got an email saying my application had been withdrawn. The Hiring Manager had no idea.\n* AirBnB ghosted me twice for 2 different positions with 2 different teams. I had been told that I had passed the round and then the recruiter stopped replying.\n* I was ghosted by Pinterest in September. Same thing: passed the technical screen, never heard back. Recruiter reached back out Monday of this week to schedule the next round.\n* Completed the entire process with Block. Recruiter was supposed to schedule a call with me and the Hiring Manager to discuss offer terms. Never got a call, never got an email response.\n\nIt's hard to not blame myself in some of these cases, like the insurance example since I did counter-offer them, but ghosting is a shitty practice and becoming all too common. I highly doubt any company is using code from a case study for themselves if they actually have existing Data Scientists. What's really happening is that the market is flooded with good candidates and they don't give a fuck about burning a bridge with you because someone just as good or possibly better will come along.",
          "score": 28,
          "created_utc": "2026-01-15 18:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs0hmq",
              "author": "Lamp_Shade_Head",
              "text": "Oh man that‚Äôs just terrible! I wouldn‚Äôt imagine companies like Airbnb or Block would ghost people. Did you end up finding a new job though? Also is it cool if I message you? I may have a block interview coming up.",
              "score": 3,
              "created_utc": "2026-01-15 18:54:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsbjjx",
                  "author": "DubGrips",
                  "text": "Yes I did! Senior Staff role, solid team, good company size, good product. Glad I held out honestly. Feel free to message me. Honestly, I cannot recommend Block. I have known a few former employees that all left due to rampant toxicity and poor WLB. I interviewed with them because my MO is to never turn anything down until the very end and see for myself. I had pretty bad vibes from the HM and a few others I interviewed with. I think my stats were:\n\n* 5 months total searching\n* 52 companies\n* 100% pass rate on technical screens\n* 100% pass rate on technical take home exams\n* I \"failed\" 5 HM screens, but quite frankly it would have never worked due to personality differences so that's fine.\n* A few ghostings randomly in the middle of rounds, so I will never know\n* 85% pass rate on presentations. I think the failures were my fault: I was either too verbose or too succinct for the given audience.\n* 14 offer rounds. 9 of those were \"we promoted someone from the inside\" or \"we had another candidate\". It was really upsetting to hear when it was due to another candidate and I have looked several of the companies up to see who they hired. In retrospect I am glad it didn't work out as they hired people who were more junior in experience, but prolific on spam posting on Medium and LinkedIn about their knowledge despite never having been in an actual role for longer than 2 years and never in a Senior or Staff role for more than 1.5. Their loss, not mine.\n* 5 quality offers. I passed on one due to insanely short relocation turnaround, another was too junior of a role and it did not align, and the other pass just a role that I honestly don't think I would have been happy in. The remaining 2 are the one I accepted and the one I mentioned above when I was ghosted.",
                  "score": 8,
                  "created_utc": "2026-01-15 19:44:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu4zax",
              "author": "RecognitionSignal425",
              "text": "> I highly doubt any company is using code from a case study for themselves if they actually have existing Data Scientists\n\nNot the code, but the aha moment from candidates' ideas (especially those with domain experience) can be a new Jira ticket for the team testing.",
              "score": 2,
              "created_utc": "2026-01-16 01:09:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrt7zm",
          "author": "volkoin",
          "text": "they are just absolute mfckers",
          "score": 9,
          "created_utc": "2026-01-15 18:22:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvekwe",
          "author": "AccordingWeight6019",
          "text": "This is unfortunately common, especially when case studies are used as a low-cost filter rather than a serious evaluation step. In many teams, the hiring process is not well owned, so candidates end up doing real work without anyone feeling responsible for closing the loop.\n\nSaying no to case studies is reasonable, but it depends on how they are framed. I am more comfortable when the scope is clearly time-boxed, discussed live, and obviously synthetic. If it looks like unpaid consulting or has unclear evaluation criteria, that is usually a signal about how the team treats candidates and, often, employees.\n\nThe market does amplify this behavior, but it is also a reflection of weak hiring discipline. In my experience, teams that value rigor tend to be more respectful of candidate time as well.",
          "score": 4,
          "created_utc": "2026-01-16 05:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztsve4",
          "author": "Accomplished-Eye-813",
          "text": "Definitely the employer. The market is trash right now, but that's still no excuse.",
          "score": 2,
          "created_utc": "2026-01-16 00:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuyrst",
          "author": "glowandgo_",
          "text": "I've seen more as a company quality signal than just the market. ghosting after unpaid work usually means either weak process or no real ownership on their side. the trade off people don‚Äôt mention is that case studies are often used when they dont know how else to evaluate, which is already a smell. i‚Äôve started pushing back unless there‚Äôs real context, timebox, and feedback baked in. interesting that they reached out first too, that makes it worse. saying no filters out some noise, even if it shrinks the funnel.,,,",
          "score": 2,
          "created_utc": "2026-01-16 03:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvewqt",
          "author": "patternpeeker",
          "text": "That frustration is very justified. Case studies can be reasonable when they are tightly scoped and followed by real feedback, but in practice they often turn into free labor or a filtering step no one bothers to close the loop on. A lot of companies also underestimate how much time they are asking for, especially when they initiate the outreach. I have started pushing back by asking for time limits, context on how it is evaluated, and whether there will be a live discussion afterward. If they cannot answer that, it is usually a signal about how they treat candidates more generally.",
          "score": 2,
          "created_utc": "2026-01-16 05:46:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvfx2m",
          "author": "thinking_byte",
          "text": "Ghosting after a multi day case study is just bad behavior, market or not. Reaching out to you and then disappearing makes it worse. I have seen more people push back lately, either asking for a smaller scoped exercise or a live working session instead. It is usually a decent signal anyway, teams that respect your time tend to show it early. Saying no filters out some opportunities, but it also filters out a lot of nonsense.",
          "score": 2,
          "created_utc": "2026-01-16 05:53:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwemue",
          "author": "dataflow_mapper",
          "text": "That sucks, and you are not overreacting. Being ghosted after unpaid work is a bad look regardless of the market, especially when they reached out to you first. A lot of teams use case studies as a lazy filter and then fail at basic follow up. Saying no is reasonable, or at least setting boundaries like time boxing it or asking for a live walkthrough instead. The market is rough, but that does not mean you have to accept disrespect as the price of entry.",
          "score": 2,
          "created_utc": "2026-01-16 10:58:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxtgcl",
          "author": "Double-Count-7545",
          "text": "They got free work from you üòû",
          "score": 2,
          "created_utc": "2026-01-16 15:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzbnos",
          "author": "jingle-bell-dog",
          "text": "Even if the markets bad, seems like this company‚Äôs respect of people‚Äôs time and culture is lacking, you might have dodged a bullet. Or as others said they want free labor",
          "score": 1,
          "created_utc": "2026-01-16 19:53:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi02sq",
      "title": "Safe space - what's one task you are willing to admit AI does better than 99% of DS?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qi02sq/safe_space_whats_one_task_you_are_willing_to/",
      "author": "Papa_Huggies",
      "created_utc": "2026-01-20 12:41:54",
      "score": 61,
      "num_comments": 92,
      "upvote_ratio": 0.72,
      "text": "Let's just admit any little function you believe AI does better, and will forever do better than 99% of DS\n\nYou know when you're data cleansing and you need a regex?\n\nYeah\n\nThe AI overlords got me beat on that.",
      "is_original_content": false,
      "link_flair_text": "AI",
      "permalink": "https://reddit.com/r/datascience/comments/1qi02sq/safe_space_whats_one_task_you_are_willing_to/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0nq0nt",
          "author": "PenguinSwordfighter",
          "text": "Creating LaTeX tables",
          "score": 147,
          "created_utc": "2026-01-20 12:54:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ohjyl",
              "author": "GamingTitBit",
              "text": "I actually have started using LaTeX again with AI. Hells no will I write it myself, but it does just look nicer!",
              "score": 28,
              "created_utc": "2026-01-20 15:23:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0qp8nq",
              "author": "Uncool_runnings",
              "text": "Latex in its entirety.\n\n\n20 page long notebook with vast numbers of graphs and tables?\n\n\n\"Turn this into a scientific report style latex document for me\"\n\n\nBeautiful.",
              "score": 21,
              "created_utc": "2026-01-20 21:30:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0r5phy",
                  "author": "sonicking12",
                  "text": "Do you write in Word and then use AI?",
                  "score": 3,
                  "created_utc": "2026-01-20 22:49:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ta20h",
              "author": "Mescallan",
              "text": "also better at regex than i ever will be",
              "score": 5,
              "created_utc": "2026-01-21 06:37:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nq8t6",
          "author": "Radiant-Composer2955",
          "text": "- proper comments\n- documentation \n- write tests",
          "score": 149,
          "created_utc": "2026-01-20 12:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0obcgn",
              "author": "cy_kelly",
              "text": "I used it to generate unit tests for a project for the first time recently. Holy shit. Game changer. Some of them needed to be modified, it's not like you can just not review them, but it still saved me a *ton* of time and effort.",
              "score": 23,
              "created_utc": "2026-01-20 14:52:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0o1qr4",
              "author": "Empty_Search6446",
              "text": "READMEs it does okay but it is amazing for good docstrings",
              "score": 22,
              "created_utc": "2026-01-20 14:02:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0oojp4",
              "author": "Atmosck",
              "text": "Tests and docstrings sure, but hard disagree on comments. Unless you REALLY hold their hand about it, they produce way too many comments that are totally unnecessary, and often use didactic tone and 2nd person.",
              "score": 8,
              "created_utc": "2026-01-20 15:56:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0s98ev",
                  "author": "JimmyTheCrossEyedDog",
                  "text": "Agreed - I hate out of the box AI comments, they're so trivial.",
                  "score": 3,
                  "created_utc": "2026-01-21 02:29:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0yzhau",
                  "author": "iloveartichokes",
                  "text": "Yes you have to teach it how to write comments in your style, then the prompt can be reused and it becomes useful.",
                  "score": 1,
                  "created_utc": "2026-01-22 02:01:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0nsn8n",
              "author": "OneBurnerStove",
              "text": "second the comments bit. I actually try to be more verbose yet concise and clear in key points with my comments now.\n\nWhich has led others to think the code was pure AI lol",
              "score": 6,
              "created_utc": "2026-01-20 13:10:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ras7i",
              "author": "Change-Able",
              "text": "Also proper variable and function naming",
              "score": 2,
              "created_utc": "2026-01-20 23:16:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nu8zr",
          "author": "MediumDrink12",
          "text": "I find most of the popular LLM are much better than the average DS when it comes to structuring ideas and concepts in an organized way.\n\nThis makes them an excellent tool for documentation but also investigating undocumented project which are so badly structured that the most expert MLE can't even figure out what the code is doing. It's a godsend when you are being asked to debug or even refactor some old project that no one is maintening.",
          "score": 61,
          "created_utc": "2026-01-20 13:20:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ox13n",
              "author": "amiles2233",
              "text": "I think this is the big one. It takes ideas that were normally just notebooks and structures them into more robust systems and packages. Nothing that wasn't doable prior, but was just very time consuming. I come from a statistical background not a software background, and when I'd try to architect these systems I'd make plenty of bonehead mistakes, LLMs quickly get my stuff to 'good enough' from a software perspective.",
              "score": 8,
              "created_utc": "2026-01-20 16:35:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ohsxh",
              "author": "GamingTitBit",
              "text": "My only complaint is that they seem to hyper focus on multiple functions. Sometimes they write a function for the smallest thing that is only used within another function and doesn't need to be broken out and fragment your code. That and I've never seen an LLM choose to make a class instead of a function unless I explicitly tell it to",
              "score": 8,
              "created_utc": "2026-01-20 15:24:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rmk4b",
                  "author": "T_house",
                  "text": "Oh shit this might suddenly explain why I've seen code for papers in the last year or so with absolutely bonkers use of functions (regularly for minor things that are only done once, not really using arguments, and referencing global variables within the function itself)",
                  "score": 2,
                  "created_utc": "2026-01-21 00:21:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0u8bdn",
              "author": "aegismuzuz",
              "text": "I agree. When you stare at 2,000 lines of spaghetti code with no docs, your brain goes into panic or procrastination mode. AI acts as a decompressor: it breaks that monolith into digestible chunks of logic. I don't use it to solve the task for me, but to explain the context in 30 seconds instead of 3 hours of reading code. It is hands down the best tool for legacy onboarding",
              "score": 3,
              "created_utc": "2026-01-21 11:47:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ntbji",
          "author": "latent_threader",
          "text": "For me it‚Äôs turning vague stakeholder English into a first pass of SQL or pandas that actually runs. It‚Äôs rarely perfect, but it gets me 80 percent there faster than staring at a blank editor. I still don‚Äôt trust it with edge cases, but as a starting point it‚Äôs annoyingly good.",
          "score": 51,
          "created_utc": "2026-01-20 13:14:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nxutl",
              "author": "Zohan4K",
              "text": "I fucking love doing CTRL A,C,V into cursor everytime a stakeholder feels the need to narrate the story of mankind in an email rather than getting to the fucking point.",
              "score": 14,
              "created_utc": "2026-01-20 13:40:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0okvqz",
                  "author": "Greedy_Bar6676",
                  "text": "You ever get a pang of anxiety doing that, knowing that soon the stakeholder might just be asking an LLM instead of you?",
                  "score": 2,
                  "created_utc": "2026-01-20 15:39:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qtxa9",
              "author": "imamouseduhhh",
              "text": "Yes! I‚Äôve had a lot of luck using it to help me with stakeholder questions, but 0 luck in having stakeholders do it themselves - which I guess is good?",
              "score": 1,
              "created_utc": "2026-01-20 21:51:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nu8h0",
          "author": "nonamenomonet",
          "text": "Tbh I still don‚Äôt find LLM‚Äôs good enough for complicated data cleaning. It‚Äôs a good enough to start with but, I haven‚Äôt found it to be performant enough for all the edge cases.",
          "score": 16,
          "created_utc": "2026-01-20 13:20:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nv6db",
              "author": "MediumDrink12",
              "text": "I have found that if you are more explicit in what data issues you expect it to clean, it often times gives some good ideas along with some other less good ideas.\n\nI feel it's the most useful when you interact with it as if it was another human colleague. That means giving it enough context to grasp the issue you have and discuss with it instead of expecting it to find you the answer right away. I would expect a lot of people don't go beyond the first message though, as it is often very verbose.\n\nIt's also pretty good at piggy backing off your ideas. Sometimes I just have some vague idea of something and it will explore the idea deeper, suggesting improvements I haven't thought out.",
              "score": 7,
              "created_utc": "2026-01-20 13:25:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pdhkh",
              "author": "ogola89",
              "text": "Can you specify your use case here? I find this very difficult to accept as LLMs are kings at data cleaning though they can be heavy handed and make decisions you're not in line with having the company/project objectives in view.",
              "score": 1,
              "created_utc": "2026-01-20 17:51:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pdnzg",
                  "author": "nonamenomonet",
                  "text": "Cleaning addresses in CSV files mostly I actually created a package for it",
                  "score": 0,
                  "created_utc": "2026-01-20 17:52:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0yzs7r",
              "author": "iloveartichokes",
              "text": "It's not great if you ask it too much, but if you give examples of exactly what you want to clean and how you want the output to look, it's great.",
              "score": 1,
              "created_utc": "2026-01-22 02:03:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0o4dgb",
          "author": "kaladyr",
          "text": "Getting like 80% of the way there for visualizations, particularly animated visuals that stakeholders love but would take way too much of my time if I actually wrote out everything myself.",
          "score": 24,
          "created_utc": "2026-01-20 14:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oafc5",
              "author": "Pvt_Twinkietoes",
              "text": "Iterating through ideas. Getting to a simple MVP is way faster now.",
              "score": 3,
              "created_utc": "2026-01-20 14:47:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0s7mlj",
              "author": "SkipGram",
              "text": "Which program do you use for that? Like coding animations or powerpoint-type ones?",
              "score": 1,
              "created_utc": "2026-01-21 02:19:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0w6loq",
                  "author": "kaladyr",
                  "text": "Matplotlib animations.",
                  "score": 1,
                  "created_utc": "2026-01-21 17:50:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0upeej",
              "author": "Current-Ad1688",
              "text": "Yeah this is definitely where I've found it best. Make a little app to explore how this model behaves or something. Used to take me a few hours at least. Asked codex and it just did it and it worked. Obviously I want to be the one who interprets that and decides how to change my model to stop it being stupid, but it's quite good at making little tools for me to find those things.",
              "score": 1,
              "created_utc": "2026-01-21 13:39:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0o62s9",
          "author": "ogola89",
          "text": "It does most things better than we are willing to admit. Short, complex tasks are where it excels. The only place it doesn't excell currently is things that take more memory and long term vision such as strategy, architecture, connections, taking into account edge cases in some data or identifying solutions to business logic.\n\nI've effectively become a middle manager of a junior DS who has dominated leet code and the math olympiad but can't find business opportunities as well as I can.\n\nCoding side, beats us hands down in speed and quality (data types, doc strings, organisation, algorithmic choice). Speaking for claude code here",
          "score": 10,
          "created_utc": "2026-01-20 14:25:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oquie",
              "author": "Commercial_Note_210",
              "text": "> It does most things better than we are willing to admit.\n\nI've been coming to terms with this in the last few weeks - coding assistants backed by Claude Code are significantly good. Parsing logs, any CLI command, any SQL writing, writing unit tests, documentation, and writing base code they just totally dominate. And I write shit prompts - not sure how good they would be with a good prompt.",
              "score": 3,
              "created_utc": "2026-01-20 16:07:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0onw10",
          "author": "Fun-Acanthocephala11",
          "text": "regex if you know how to prompt",
          "score": 5,
          "created_utc": "2026-01-20 15:53:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nwd08",
          "author": "ghostofkilgore",
          "text": "Anything that's basically a quick first pass at something, if you factor speed into it. For example, giving it an uncommented notebook and asking it to document or add comments. It'll do a good job of that extremely quickly. It'll probably have a better answer in a minute than 99% of DSs can do in an hour. The things is, that's where the AI ends. It won't create a better answer if you leave it for a day and ask again. A decent DS should be doing a better job than the AI if you give them a day to do the task.",
          "score": 4,
          "created_utc": "2026-01-20 13:32:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pxy4b",
          "author": "Iowatimetraveler",
          "text": "Organizing unstructured data.",
          "score": 3,
          "created_utc": "2026-01-20 19:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qql31",
          "author": "pandasgorawr",
          "text": "Claude Code + Opus 4.5 absolutely destroys your average mid-career data scientist on coding, especially SQL and Python. 6-12 months more of improvements and I feel confident that it can do it better than 99% of DS. Instead of coding it's probably a better use of time to become a domain expert, and improve planning skills such as requirements gathering and writing pseudocode.",
          "score": 3,
          "created_utc": "2026-01-20 21:36:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nru5b",
          "author": "Rootsyl",
          "text": "For documentation ai is a godsend.",
          "score": 2,
          "created_utc": "2026-01-20 13:05:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0og3nu",
          "author": "Nikkibraga",
          "text": "Readme.txt files",
          "score": 2,
          "created_utc": "2026-01-20 15:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qjrlz",
          "author": "koulourakiaAndCoffee",
          "text": "Create sample data and brainstorm.\n\nExample :  give me ten different ways to visualize this\n\nAnd also a second set if eyes .  Ask it to criticize your work.  \nAsk it to define it in laymen‚Äôs terms to .\n\nI give it 5 paragraphs of text and ask it ‚Äúhow can I explain this to explain how this will help a CEO in one sentence‚Äù",
          "score": 2,
          "created_utc": "2026-01-20 21:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qydw6",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 2,
          "created_utc": "2026-01-20 22:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qzqxg",
          "author": "coffeecoffeecoffeee",
          "text": "Making matplotlib charts",
          "score": 2,
          "created_utc": "2026-01-20 22:19:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0raw9g",
          "author": "moonzl_rdt",
          "text": "Rapidly prototyping one-off code.   \nIf you need a script you're only going to use a few times, a quick visualisation to check something, etc. LLMs are ideal.",
          "score": 2,
          "created_utc": "2026-01-20 23:17:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rtpip",
          "author": "canbooo",
          "text": "Brain storm (playing a rubber duck that talks back)",
          "score": 2,
          "created_utc": "2026-01-21 01:00:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u7xh4",
          "author": "aegismuzuz",
          "text": "Matplotlib boilerplate. Seriously, I've been in DS for god knows how many years, and I still can't remember how to rotate X-axis labels 45 degrees without googling. Or how to tweak subplot\\_adjust so the legend doesn't overlap the plot. AI does this on the first try. You just write: plot a histogram, make it purple, add a trendline, and label the axes properly - It saves me 15 minutes of furious googling on every single chart",
          "score": 2,
          "created_utc": "2026-01-21 11:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nos8a",
          "author": "Ok-Energy-9785",
          "text": "This doesn't make sense. Its like asking what does a truck do better than a babysitter. The two collaborate to make a quality product.",
          "score": 5,
          "created_utc": "2026-01-20 12:46:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ns4gd",
              "author": "nooptionleft",
              "text": "I know it's a humorous phrasing but now I'm curious what kind of final product (of whatever quality) could require a collaboration between a truck and a babysitter",
              "score": 12,
              "created_utc": "2026-01-20 13:07:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0nsc1c",
                  "author": "Ok-Energy-9785",
                  "text": "Transportation to the grocery store, to the doctor, to a play date, to McDonald's, going from point a to point b.",
                  "score": 4,
                  "created_utc": "2026-01-20 13:08:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0o5m0w",
          "author": "starfries",
          "text": "Yeah, they usually nail parsing code or do it way faster than I could.\n\n\nI won't say they get it right every time but I wouldn't have either.",
          "score": 1,
          "created_utc": "2026-01-20 14:22:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0odupl",
          "author": "Ibzclaw",
          "text": "Formatting for very basic stuff. Writing mermaid for fairly simple architectures.",
          "score": 1,
          "created_utc": "2026-01-20 15:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qz7l0",
          "author": "Ok-Relation6854",
          "text": "Choosing good variable and dataframe names! üòÜ",
          "score": 1,
          "created_utc": "2026-01-20 22:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r1wvo",
          "author": "Imaginary-Corgi8136",
          "text": "Grammar and spelling and document review!",
          "score": 1,
          "created_utc": "2026-01-20 22:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r62p1",
          "author": "sonicking12",
          "text": "Better than Jamie Dimon on everything",
          "score": 1,
          "created_utc": "2026-01-20 22:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rlsv9",
          "author": "DigoHiro",
          "text": "regex",
          "score": 1,
          "created_utc": "2026-01-21 00:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rs1nt",
          "author": "gBoostedMachinations",
          "text": "It produces basic code better than most of yall for sure haha.",
          "score": 1,
          "created_utc": "2026-01-21 00:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ry9yq",
          "author": "zangler",
          "text": "Calculating... actually re-calculating sequential Bayesian posteriors...let it loose... discuss the results... boom... defensible model assumptions held in context and debated on contextualized merit... really fast.",
          "score": 1,
          "created_utc": "2026-01-21 01:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rynq6",
          "author": "Hertigan",
          "text": "The god damn plotly syntax\n\nAlso regex",
          "score": 1,
          "created_utc": "2026-01-21 01:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s3jfl",
          "author": "orz-_-orz",
          "text": "Regex, a really really complex regex",
          "score": 1,
          "created_utc": "2026-01-21 01:56:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s9hn6",
          "author": "inkeep",
          "text": "Creating MVPs for simulators and scenario planners.",
          "score": 1,
          "created_utc": "2026-01-21 02:30:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0si8c7",
          "author": "13ass13ass",
          "text": "I had Claude code analyze some old data science code bases circa 2020 of mine and it gave me a C-, C, and B- for three of my main projects. Just sayin maybe we remember the before-times with rose colored glasses.",
          "score": 1,
          "created_utc": "2026-01-21 03:21:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0skodf",
          "author": "rawdfarva",
          "text": "regular expressions",
          "score": 1,
          "created_utc": "2026-01-21 03:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sl27p",
          "author": "killthatbohr",
          "text": "Create high level ideas for code and help me brainstorm",
          "score": 1,
          "created_utc": "2026-01-21 03:38:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ss6uf",
          "author": "smick",
          "text": "Split testing. I started using abee pro and it‚Äôs kinda crazy.",
          "score": 1,
          "created_utc": "2026-01-21 04:23:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ssu38",
          "author": "Biscuit_5321",
          "text": "Hey",
          "score": 1,
          "created_utc": "2026-01-21 04:28:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0szo2b",
          "author": "Easy_Cable6224",
          "text": "Reading through the comments most said commenting, documentation and structuring, now I am curious what can DS do better than AI, surely there exists something that DS is better at",
          "score": 1,
          "created_utc": "2026-01-21 05:15:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0uccva",
              "author": "aegismuzuz",
              "text": "Problem Formulation. AI can optimize a metric perfectly, but only a human can say, \"wait, optimizing this metric will churn customers in six months, we are solving the wrong problem\". AI solves the equation, the human defines which equation to solve. \n\nPlus AI can't walk over to data engineers, negotiate access, and figure out why the pipeline broke on a Friday night",
              "score": 2,
              "created_utc": "2026-01-21 12:17:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0t7h88",
              "author": "Papa_Huggies",
              "text": "I'm consistently better at selecting the best parameters for a model?",
              "score": 1,
              "created_utc": "2026-01-21 06:15:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0te0v7",
          "author": "AccordingWeight6019",
          "text": "For me, it is the first pass at turning a vague idea into working scaffolding. Things like sketching a baseline pipeline, translating a math idea into code, or writing defensive data checks, I would otherwise procrastinate on. It is rarely optimal, but it is often good enough to surface the real problems faster. The value is less about correctness and more about reducing friction early, which a lot of experienced DS still underestimate.",
          "score": 1,
          "created_utc": "2026-01-21 07:11:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u44gt",
          "author": "CapitalPhi",
          "text": "Coding.",
          "score": 1,
          "created_utc": "2026-01-21 11:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uj9g1",
          "author": "patternpeeker",
          "text": "Regex and one-off data munging is a big one for me too. Also turning vague business questions into a first pass of SQL or a rough feature idea, especially when the schema is messy. That said, it usually falls apart once the data has real edge cases or the definition needs to hold up over time. The last 10 percent, where assumptions matter and mistakes get expensive, is still very human.",
          "score": 1,
          "created_utc": "2026-01-21 13:03:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uli5p",
          "author": "notna17",
          "text": "All of them.",
          "score": 1,
          "created_utc": "2026-01-21 13:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wc7bn",
          "author": "Accomplished-Eye-813",
          "text": "Regex",
          "score": 1,
          "created_utc": "2026-01-21 18:15:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0x2n2o",
          "author": "RenaissanceScientist",
          "text": "Regex for sure, but you still need to test it for edge cases, and know what it‚Äôs doing",
          "score": 1,
          "created_utc": "2026-01-21 20:13:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0zmkuh",
          "author": "Training_Butterfly70",
          "text": "System design",
          "score": 1,
          "created_utc": "2026-01-22 04:17:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10k6il",
          "author": "localkinegrind",
          "text": "i can admit that ai is doing better with testing errors, documnation, and simple animations.",
          "score": 1,
          "created_utc": "2026-01-22 08:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qfd5k",
          "author": "Illustrious-Pound266",
          "text": "Coding.\n\nPeople don't want to admit it though because they feel threatened by it, so they rather live in ignorance bliss.",
          "score": 0,
          "created_utc": "2026-01-20 20:45:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qhhlr",
              "author": "Papa_Huggies",
              "text": "I still like to arrange all my workflows myself and I don't want it deciding which function to call etc. but things like a gross regex query or making a plt with all the labelling? You take it, robot",
              "score": 3,
              "created_utc": "2026-01-20 20:54:36",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0z04h8",
              "author": "iloveartichokes",
              "text": "Only if you already know what you want out of the code.",
              "score": 0,
              "created_utc": "2026-01-22 02:05:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0z12os",
                  "author": "Illustrious-Pound266",
                  "text": "Well yes, obviously. If you yourself don't know what you want, then you can have the world's best human coder next to you and he/she will not be of great help.",
                  "score": 1,
                  "created_utc": "2026-01-22 02:10:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qja2xv",
      "title": "Best and worst companies for DS in 2026?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qja2xv/best_and_worst_companies_for_ds_in_2026/",
      "author": "LeaguePrototype",
      "created_utc": "2026-01-21 20:59:43",
      "score": 60,
      "num_comments": 27,
      "upvote_ratio": 0.94,
      "text": "I might be losing my big tech job soon, so looking for inputs on trends in the industry for where to apply next with 3-5 YOE.\n\nDoes anyone have recommendations for what companies/industries to look into and what to avoid in 2026?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qja2xv/best_and_worst_companies_for_ds_in_2026/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0xu8w4",
          "author": "averagebear_003",
          "text": "Best: Whichever hires me\n\nWorst: Whichever doesn't",
          "score": 80,
          "created_utc": "2026-01-21 22:19:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0y3iqs",
              "author": "mamaBiskothu",
              "text": "Or maybe the opposite",
              "score": 13,
              "created_utc": "2026-01-21 23:06:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0xe0a2",
          "author": "gpbayes",
          "text": "No to Home Depot, meta, Amazon",
          "score": 53,
          "created_utc": "2026-01-21 21:04:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xl76v",
              "author": "chandlerbing_stats",
              "text": "Can you give just 1 sentence explaining why for each?",
              "score": 17,
              "created_utc": "2026-01-21 21:37:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0xq6nz",
                  "author": "SwitchOrganic",
                  "text": "Home Depot has popped up a few times in this sub:\n\n* https://www.reddit.com/r/datascience/comments/16hw3lu/one_company_you_should_never_work_for_home_depot/\n* https://www.reddit.com/r/datascience/comments/1aglh3p/what_is_data_science_like_at_home_depot/\n* https://old.reddit.com/r/datascience/comments/xar94w/ds_at_home_depot/\n\nAs for Meta and Amazon I'm guessing because of their work (PIP) culture and/or personal objections to the morality of working at Meta.\n\nI'm not sure what the current rep is, but Meta used to be known as an amazing place for data science with a strong culture of being genuinely data-driven. They were like the standard when it came to data science and analytics.",
                  "score": 31,
                  "created_utc": "2026-01-21 22:00:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0xt200",
              "author": "RecognitionSignal425",
              "text": "what's meta with amazon?",
              "score": -1,
              "created_utc": "2026-01-21 22:13:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0y9ilg",
                  "author": "goddog420",
                  "text": "He couldn‚Äôt get into those. I‚Äôve worked at both and it‚Äôs been great.",
                  "score": 4,
                  "created_utc": "2026-01-21 23:38:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0xern6",
          "author": "Equal-Agency4623",
          "text": "Experiences are team/org dependent. A company may have a bad culture but a specific org within that company might be cool. Focus more on finding good teams instead of labeling 50K+ size companies as good or bad.",
          "score": 49,
          "created_utc": "2026-01-21 21:08:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y4ld8",
          "author": "G-R-A-V-I-T-Y",
          "text": "Website based companies (Zillow, Chewy, Pinterest etc) tend to at least provide a foundation that CAN support a healthy DS culture, in part because there is so much data to work with. However I second the previous comments here about experience being largely (~60%) driven by org and team. So the beyond avoiding publicly-known-to-be-terrible companies, it‚Äôs probably best to understand for yourself what you really value in a manager and in a team. For instance for me, I need a manager to either be smarter or kinder than I am, preferably both. Good luck!",
          "score": 26,
          "created_utc": "2026-01-21 23:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xwfw2",
          "author": "No_Ant_5064",
          "text": "Honestly man I don't know if you have the luxury of being picky right now. Take what you can get, and if the place sucks at least it buys you time till your next move.",
          "score": 23,
          "created_utc": "2026-01-21 22:30:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xk99x",
          "author": "analisto",
          "text": "Avoid Merck. This place is a dumpster fire for DS.",
          "score": 9,
          "created_utc": "2026-01-21 21:33:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ygikn",
              "author": "YupItsMoi",
              "text": "Can you elaborate more (please)?",
              "score": 2,
              "created_utc": "2026-01-22 00:16:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0zk9as",
                  "author": "analisto",
                  "text": "Low maturity data engineering culture - it affects downstream stuff like analytics and ds, severe understaffing (everything is self service which slows down your work and makes you take up tasks that are WELL outside ds), high attritition rate has led to lack of instituitional knowledge, compliance hurdles",
                  "score": 3,
                  "created_utc": "2026-01-22 04:02:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0yly20",
          "author": "Expensive_Culture_46",
          "text": "Be very careful with small tiny ‚Äústart ups‚Äù. ChatGPT has basically lowered the bar to ‚Äúidiot with a computer and a 401k‚Äù to start trying to live their ‚ÄúI‚Äôm gonna be Steve Jobs‚Äù dream. I‚Äôm dealing with it now and these folks are a nightmare. \n\nThink fully AI drafted contracts that are literally impossible to complete because what it asks for doesn‚Äôt even exist. They under charge and under estimate the labor and time because they have a lot of competition. \n\nIt‚Äôs gross and weird.",
          "score": 5,
          "created_utc": "2026-01-22 00:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10b0pg",
          "author": "AccordingWeight6019",
          "text": "I am skeptical of best and worst lists because the variance within a company is often larger than across companies. What seems to matter more is whether DS is tied to a real decision loop or just reporting. Teams where models inform or automate something concrete tend to have better incentives around data quality, infra, and career growth. In contrast, roles that sit downstream of the product with vague impact tend to get squeezed when budgets tighten. For 2026 specifically, I would look less at sector labels and more at signals like ownership of metrics, iteration speed, and whether DS is involved before decisions are made. Those usually tell you more than the brand name.",
          "score": 2,
          "created_utc": "2026-01-22 07:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xfx96",
          "author": "Arnechos",
          "text": "Worst - Rockwell (internal business side)",
          "score": 2,
          "created_utc": "2026-01-21 21:13:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xw3ay",
              "author": "DFW_BjornFree",
              "text": "Why are people downvoting you?¬†",
              "score": 2,
              "created_utc": "2026-01-21 22:28:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0yrdma",
                  "author": "sceadu",
                  "text": "didn't specify best or worst",
                  "score": 6,
                  "created_utc": "2026-01-22 01:15:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0xk33y",
          "author": "vamsi0502",
          "text": "What kind of DS work are you interested in?",
          "score": 0,
          "created_utc": "2026-01-21 21:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xhway",
          "author": "Gsustv",
          "text": "Best for DS in 2026: smaller AI startups like Anthropic or Scale AI - real model work without FAANG bureaucracy. Worst: banks and pharma, endless compliance kills projects fast. Friend jumped from JPMorgan to Perplexity, doubled impact overnight.",
          "score": -31,
          "created_utc": "2026-01-21 21:22:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xjcyn",
              "author": "ExoSpectra",
              "text": "Nice LLM output",
              "score": 32,
              "created_utc": "2026-01-21 21:28:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0xwi01",
                  "author": "DFW_BjornFree",
                  "text": "Right? I feel like banks have always been a safe place for the less sexy data science.¬†\n\n\nYou're okay doing regression, clustering, boosted trees, A/B testing, and various analytics for most problems then banks are almost ideal.¬†",
                  "score": 8,
                  "created_utc": "2026-01-21 22:30:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o101h4g",
              "author": "realXstrawarot",
              "text": "Doubled impact overnight? Lmao stfu, please",
              "score": 2,
              "created_utc": "2026-01-22 06:03:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qflxse",
      "title": "How the Kronecker product helped me get to benchmark performance.",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/",
      "author": "vercig09",
      "created_utc": "2026-01-17 19:10:03",
      "score": 50,
      "num_comments": 19,
      "upvote_ratio": 0.89,
      "text": "Hi everyone,\n\n  \nRecently had a common problem, where I had to improve the speed of my code 5x, to get to benchmark performance needed for production level code in my company.\n\nLong story short, OCR model scans a document and the goal is to identify which file from the folder with 100,000 files the scan is referring to.\n\n  \nI used a bag-of-words approach, where 100,000 files were encoded as a sparse matrix using scipy. To prepare the matrix, CountVectorizer from scikit-learn was used, so I ended up with a 100,000 x 60,000 sparse matrix. \n\nTo evaluate the number of shared words between the OCR results, and all files, there is a \"minimum\" method implemented, which performs element-wise minimum operation on matrices of the same shape. To use it, I had to convert the 1-dimensional vector encoding the word count in the new scan, to a huge matrix consisting of the same row 100,000 times.\n\nOne way to do it is to use the \"vstack\" from Scipy, but this turned out to be the bottleneck when I profiled the script. Got the feedback from the main engineer that it has to be below 100ms, and I was stuck at 250ms. \n\nLong story short, there is another way of creating a \"large\" sparse matrix with one row repeated, and that is to use the [kron](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.kron.html#scipy.sparse.kron) method (stands for \"Kronecker product\"). After implementing, inference time got cut to 80ms. \n\n  \nOf course, I left a lot of the details out because it would be too long, but the point is that a somewhat obscure fact from mathematics (I knew about the Kronecker product) got me the biggest performance boost.\n\nA.I. was pretty useful, but on its own wasn't enough to get me down below 100ms, had to do old style programming!!\n\n  \nAnyway, thanks for reading. I posted this because first I wanted to ask for help how to improve performance, but I saw that the rules don't allow for that. So instead, I'm writing about a neat solution that I found. ",
      "is_original_content": false,
      "link_flair_text": "Coding",
      "permalink": "https://reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o09442e",
          "author": "AccordingWeight6019",
          "text": "this is a nice example of where understanding the underlying linear algebra and sparse representations pays off more than tuning at the surface level. a lot of performance issues in applied ML end up being data movement problems rather than model problems, and vstacking that many rows is a classic trap. using a Kronecker construction to express repetition without materializing it is a good illustration of thinking in operators instead of arrays. I also like that this came out of profiling rather than guessing. In production settings, that mindset often matters more than any single trick.",
          "score": 10,
          "created_utc": "2026-01-18 07:06:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0amtzv",
              "author": "vercig09",
              "text": "thanks for the feedback :)\n\nto be honest, I started writing a prompt asking AI where it sees improvements in code, and immediately realized how silly that was, and just used the cProfile, figured out pretty quickly where I should focus on :)",
              "score": 2,
              "created_utc": "2026-01-18 14:30:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0fhxhe",
                  "author": "AccordingWeight6019",
                  "text": "Exactly, profiling first is always the way to go. It is easy to get distracted chasing smarter algorithms when the bottleneck is really in data layout or memory movement. Sparse representations and knowing which operations are cheap versus expensive can make all the difference, and Kronecker products are a neat example of that.",
                  "score": 1,
                  "created_utc": "2026-01-19 05:48:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09oczz",
          "author": "patternpeeker",
          "text": "Nice writeup. This is a good example of the hard part not being the model, but how you move data around at scale. In practice, a lot of ML code misses benchmarks because of exactly this kind of hidden allocation or replication step. I have seen similar wins from avoiding explicit expansion and letting linear algebra do the work implicitly. It also highlights why profiling matters more than clever modeling once you are in production. Out of curiosity, did you consider alternatives like inverted indices or pruning before the comparison, or was the latency budget tight enough that you needed to stay fully vectorized?",
          "score": 3,
          "created_utc": "2026-01-18 10:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b9dil",
              "author": "vercig09",
              "text": "Thanks for the response. This was my first iteration, still have some ideas to explore. For example, this is a classic example of a task which can be processed in parallel, because comparisons are independent of one another, so I really want to see what impact parallel computation will have.\n\nInverted indices might also be an interesting approach, thanks for the idea :) \n\nDidn't want to prune yet, because I didn't have issues with memory and didn't want to lose information",
              "score": 1,
              "created_utc": "2026-01-18 16:23:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0902e3",
          "author": "Zahlii",
          "text": "Why not do something like \ncv = CountVectorizer(binary=True)\nx_docs = cv.fit_transform() # N Docs x Words\nx_ocr = cv.transform() # 1 x Words\nsim = x_ocr.dot(x_docs.T) # 1 x N Docs\n\nOn binary data the dot will evaluate to # Words common between ocr and each doc vector?",
          "score": 2,
          "created_utc": "2026-01-18 06:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ant8g",
              "author": "vercig09",
              "text": "very interesting, thanks for sharing. With the dot product, I was worried that it wouldn't be able to handle \"multiplicity\" (how many times each word appears). In other words, I was worried it would either:\n\n1. just count how many INDIVIDUAL words are shared (word either appears in both documents, or not), so 1 or 0 for each word,\n\n2. it would overcount how may times the word appears. For example, if \"banana\" appears in the OCR 3 times, and in the original document 3 times, I thought the dot product would give 9.\n\nLooking at the documentation for \"CountVectorizer\", this is written for the \"binary\" parameter:  \n  \n\"**binary** bool, default=False\n\nIf True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.\"\n\nSo, I'm worried about the #1 case, but I'll explore in more detail",
              "score": 1,
              "created_utc": "2026-01-18 14:35:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0aw1im",
                  "author": "Zahlii",
                  "text": "I think the ‚Äûovercount‚Äú can be solved by using e.g TfIdf or using l2 norm - this way similarities are guaranteed to be in [-1,1], and with tfidf you also get a weighting on more specialized tokens",
                  "score": 2,
                  "created_utc": "2026-01-18 15:19:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zzq1",
          "author": "glowandgo_",
          "text": "this is a good example of where the real win comes from understanding the underlying ops, not just swapping libs. the kron trick makes sense once you think about how sparse structure is represented, but it‚Äôs not something most people reach for by default. in my experience, perf issues at this scale are almost always about avoiding materialization rather than making one function faster. also appreciate the point about ai tools, they help explore options, but they rarely have the context to spot these mathy shortcuts. nice writeup, this kind of detail is way more useful than generic ‚Äúoptimize your code‚Äù advice.,,,",
          "score": 2,
          "created_utc": "2026-01-18 11:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0boery",
              "author": "vercig09",
              "text": "thanks for reading :)",
              "score": 1,
              "created_utc": "2026-01-18 17:35:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a7px3",
          "author": "and1984",
          "text": "This is excellent info.  Are you able to shed light on how AI was useful but old-school coding came to the rescue?",
          "score": 2,
          "created_utc": "2026-01-18 12:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b2yxs",
              "author": "vercig09",
              "text": "Thank you :)\n\nI use Github Copilot which makes me much faster at writing code. I never accept suggestions with more than 2 lines, because 2 lines is my limit for what I can check quickly for accuracy. Once I developed the initial method, AI helped me get the inference time from 2 seconds to roughly 0.5s, but then it started going into circles, either suggesting things that don't work or stuff that doesn't impact the execution time.\n\n  \nSince I had to get down to 100ms, I decided to drop my initial approach, which was basically a \"for\" loop (comparing the generated text with each record from DB individually), and to try vectorization/matrix operations.\n\n  \nI knew about scikit-learn, so I was reading the documentation until I stumbled upon [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#countvectorizer), which can encode all DB records into a single sparse matrix. Key calculation was finding the number of shared words between the scanned document and each record in the database, which can easily be done with the [minimum](https://docs.scipy.org/doc/scipy-1.16.2/reference/generated/scipy.sparse.csr_matrix.minimum.html) function. The only thing missing was how to quickly run this function, because it requires two matrices of the same shape, but the OCR results is only a 1-dimensional sparse matrix. In order to generate a large matrix, AI suggested [vstack](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.vstack.html), which worked and got me down to roughly 250ms, without impacting accuracy. I ran the cProfile profiler on my script, and noticed that the vstack took the most time to execute, so I needed to cut it down. I was thinking about how to construct a large matrix where 1 row is repeated a number of times, reading scipy.sparse docs, looking for another option, and was very happy to see that the Kronecker product was implemented: [LINK](https://docs.scipy.org/doc/scipy-1.16.2/reference/generated/scipy.sparse.kron.html).\n\n  \nOverall, AI was pretty good, and it might have done more with better prompting, but I needed a significant change in approach, and I felt like I was just going in circles with AI, so had to rely on my own neural network",
              "score": 1,
              "created_utc": "2026-01-18 15:53:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bemt4",
          "author": "yaksnowball",
          "text": "Embed the content of the files with a sentence transformer, store the resulting embeddings in an index e.g using FAISS and do ANN retrieval to get the most similar files to the new OCR scan. It will be almost instant if you are just searching with 1 document. I guarantee less than 10ms easily.\n\nSparse lexical retrieval is very inconvenient for large amounts of documents hence why people have traditionally resorted to things like ElasticSearch or Apache SOLR to do this type of thing.",
          "score": 2,
          "created_utc": "2026-01-18 16:48:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bod84",
              "author": "vercig09",
              "text": "fair, thanks for the suggestion. wanted to first try this because some documents contain unique IDs, which can help immensely to determine the right card (but not every document has an ID as part of its contents), and I thought that this information would be lost in embedding (what would JFDOSDFF9358K be similar to).\n\nI definitely want to test embeddings, but first want to set the best \"time to beat\". I'm still counting on improvements from parallel computing",
              "score": 1,
              "created_utc": "2026-01-18 17:34:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kq6be",
          "author": "Dizzy-Midnight-6929",
          "text": "Thanks for sharing! Love these performance tricks",
          "score": 2,
          "created_utc": "2026-01-20 00:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xdggm",
          "author": "eli_arad",
          "text": "sometimes, a bit of obscure math knowledge can make a huge difference",
          "score": 2,
          "created_utc": "2026-01-21 21:02:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bwjc7",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 1,
          "created_utc": "2026-01-18 18:12:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09ichl",
          "author": "nian2326076",
          "text": "I‚Äôve seen a lot of confusion and outdated info around Meta‚Äôs Data Scientist (Analytics) interview process, so I put together a practical, up-to-date playbook based on real candidate experiences and prep patterns that actually worked.",
          "score": -3,
          "created_utc": "2026-01-18 09:15:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhiw2d",
      "title": "What signals make a non-traditional background credible in analytics hiring?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qhiw2d/what_signals_make_a_nontraditional_background/",
      "author": "DataAnalystWanabe",
      "created_utc": "2026-01-19 22:26:50",
      "score": 31,
      "num_comments": 18,
      "upvote_ratio": 0.84,
      "text": "I‚Äôm a PhD student in microbiology pivoting into analytics. I don‚Äôt have a formal degree in data science or statistics, but I do have years of research training and quantitative work. I‚Äôm actively upskilling and am currently working through DataCamp‚Äôs Associate Data Scientist with Python track, alongside building small projects. I intend on doing something similar for SQL and PowerBI. \n\nWhat I‚Äôm trying to understand from a hiring perspective is: What actually makes someone with a non-traditional background credible for an analytics role?\n\nIn particular, I‚Äôm unsure how much weight structured tracks like this really carry. Do you expect a career-switcher to ‚Äúcomplete the whole ladder‚Äù (e.g. finish a full Python track, then a full SQL track, then Power BI, etc.) before you have confidence in them? Or is credibility driven more by something else entirely?\n\nI‚Äôm trying to avoid empty credential-collecting and focus only on what materially changes your hiring decision. From your perspective, what concrete signals move a candidate like me from ‚Äúinteresting background‚Äù to ‚Äúthis person can actually do the job‚Äù?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qhiw2d/what_signals_make_a_nontraditional_background/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0koeft",
          "author": "dlchira",
          "text": "Computational neuroscience PhD who hires for DS roles weighing in. Structured data-science programs are not necessarily superior (and in many ways can be *inferior*) to highly quantitative STEM fields in terms of DS skills. Often it's up to the student to steer their experience in the lab toward computational approaches, big-data analytics, etc. If you're on a microbiology PhD track, you'll likely find yourself doing data collection, statistical analyses, problem solving, project management, etc. at a high level as a threshold of satisfying your course requirements, publishing in peer-reviewed journals, and defending your dissertation. What will set you apart if you want to be a DS *outside* the normal industries into which microbio PhDs tend to gravitate is your ability to link those skills to the business cases that your target industry cares about.\n\nI would **not care** if you finished some micro-certification on Data Camp or similar. That's pure noise, IMHO. As a STEM PhD I would want to read your publications and discuss your methods in the context of my industry.",
          "score": 19,
          "created_utc": "2026-01-20 00:02:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k95sj",
          "author": "Atmosck",
          "text": "I left a PhD program (math, and in particular NOT statistics) to become a data scientist. I credit every job I've gotten to having relevant personal projects I could talk intelligently about in interviews.\n\nFrom the other side of the zoom call, you're never going to find someone with all the skills you want when hiring for an entry or mid level role, so you don't really expect to. This is especially true when it comes to cloud tech, since that's so provider-specific. It just doesn't make sense to learn GCP, AWS and Azure before you have a job that needs one of them. What you're looking for when hiring is someone you think could learn what they need to know for the role.",
          "score": 22,
          "created_utc": "2026-01-19 22:41:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kaom9",
          "author": "MattDamonsTaco",
          "text": "I have a terribly non-standard background and I am a Senior DS and have worked in consulting, international banking, healthcare, FAANG, and more, all as a DS. I've been working specifically as a DS since 2015 but was working as a \"biometrician\" at a boutique environmental stats firm before that.\n\nEverything beyond my MS was in research, field work, and writing technical papers for peer review in fish and wildlife. I was an R expert (and still am, kinda) and although was not \"officially\" a statistician, I had a *very* deep background in mathematical modeling and frequentist stats. When I made the conscious decision to jump to \"industry\" instead of doing environmental work, I had the basics of SQL in my back pocket, thanks to having done a ton of data management at my boutique environmental firm.\n\n**What got me hired first was not the skillz but more how I approached a problem.** Bringing a different skill set to an organization is often times EXACTLY what a hiring manager wants, particularly if they get the signal that you're smart and can learn quickly. This is really all that matters: be smart and learn quickly and be able to show that you are or can do both. \n\nBe able to talk about models you know and how you could apply them. (For example, I applied nesting site fidelity models from sage grouse populations to predicting whether or new patients would return to a specific hospital. Same problem, different data and biz questions.) Be able to talk about how you apply stats. Be able to show how you write functions and think about how a model you've built locally could be handled by DevOps (or yourself) and moved into prod in \\[insert cloud provider of choice\\].\n\nAlthough Python is pretty much the currency of DS these days, there are still some R shops around and there are some good hiring managers left who are toolset agnostic, so long as the work is good and can be productionized. Python is easier to productionize and if you're already an R person, is pretty easy to pick up. Syntax differences can be funky, but aren't insurmountable.\n\nFeel free to reach out via DM with specific questions if you think I can help!",
          "score": 13,
          "created_utc": "2026-01-19 22:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0l0jgm",
          "author": "EsotericPrawn",
          "text": "I always look at anyone with an advanced research degree in the sciences when I look for data scientists. The ability to understand how to ask a research question and how to draw conclusions (or not) from data are, at least IMO, the hardest necessary skills to teach for a data science job. I also assume if you‚Äôre a PhD level researcher you have some level of coding experience.",
          "score": 4,
          "created_utc": "2026-01-20 01:08:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lbpv2",
          "author": "goodyousername",
          "text": "Im a DS Director. I look for people who are good at math. I don‚Äôt really care how they came about their math training, but to understand how the ML algorithms work is important for us. I do think most or all of our team has at least one degree in math or statistics, but we‚Äôve had a physicist, Econ and a comp sci PhD in the past. If they can carry a conversation about the linear algebra involved in ML, or how MLE works, that‚Äôs probably good enough for me.",
          "score": 2,
          "created_utc": "2026-01-20 02:09:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lhozd",
              "author": "anxiousnessgalore",
              "text": "So I would say that all of this comes when one is able to land an interview. Butting in here because I'm curious how one can signal that they *can* be interviewed for an open role based on a resume submitted online? (I also have a BS and MS in computational math, but I've struggled to land any interviews at all for data focused roles)",
              "score": 2,
              "created_utc": "2026-01-20 02:41:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0lq0be",
                  "author": "goodyousername",
                  "text": "Yeah good point, landing the interview in the first place is super competitive. We have one opening right now, and we closed to new applications after we hit 2400. So I did look for key phrases when narrowing down resumes, like ‚Äúmaximum likelihood‚Äù and ‚Äúlinear algebra‚Äù and several others. Then I‚Äôd look through all the returns and evaluate manually. So from that story, having some specific terminologies on the resume that align with ML foundations would have been helpful in this case. More generally though, I‚Äôm sure every hiring manager has different preferences so this can be a very hard thing to optimize.\n\n‚ÄúGeneralized Linear Model‚Äù or GLM was another term, for example, because it aligns closely with the work we do. Less than 20 people had that specific experience listed.",
                  "score": 2,
                  "created_utc": "2026-01-20 03:28:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0lwz6v",
          "author": "thinking_byte",
          "text": "From the hiring side, the strongest signal is still applied work, not completed tracks. Structured courses are fine to build baseline skills, but they mostly answer ‚Äúdid you try‚Äù not ‚Äúcan you do the job.‚Äù What usually moves someone from interesting to credible is a small number of projects where the problem, data cleaning, assumptions, and decisions are clearly explained, ideally tied to a real question. Your research background actually helps a lot if you frame it as hypothesis driven analysis and messy data handling. I‚Äôve never expected a career switcher to finish every ladder, I care more that they can take a vague question and turn it into a usable insight without hand holding.",
          "score": 2,
          "created_utc": "2026-01-20 04:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mra0z",
          "author": "Radiant-Composer2955",
          "text": "I pivoted from process technology and work ds occupations in the processing domain, in such niches the hiring is often less hard on ds skills if you have the business understanding of how to turn ds into profit.\n\nI would suggest finding a ds niche that is close to your phd work, do some private projects and focus on being able explain them to business people.",
          "score": 2,
          "created_utc": "2026-01-20 07:57:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nocgv",
          "author": "dataflow_mapper",
          "text": "From the hiring side, the biggest credibility signal is not finishing every possible course, it is evidence you can translate messy questions into analysis and explain the results clearly. A PhD already helps a lot there, especially if you can frame your research work in terms of data cleaning, assumptions, tradeoffs, and decision making. Structured tracks are fine to fill gaps, but nobody I know checks whether someone completed an entire ladder. One or two solid projects where you show end to end thinking, SQL pulls, Python analysis, and a clear takeaway matter way more. If you can talk through why you chose certain methods and what you would do differently with more time or data, that usually moves you from interesting to hireable.",
          "score": 2,
          "created_utc": "2026-01-20 12:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k8vkc",
          "author": "Single_Vacation427",
          "text": "If you are doing a PhD, saying that you are going to be able to do DS because you did DataCamp is going to be laughable. It's like trying to learn microbiology because you did some silly online certification.\n\nYou are still a student. Most universities have certifications in something useful that grad students can take, many places you can use your credits for a masters in a different field (albeit related) instead of using them for a masters in your field.\n\nYou could also take classes in statistics, etc. It's typically covered by the tuition remission. unless you are in some shitty program.\n\nI don't know about microbiology, but I'm assuming there has to be a subfield that's more based on experiments or modeling.\n\nThere are also some summer programs for PhD students on data science that have scholarships. Erdos institute has one but it's not the only one.",
          "score": 3,
          "created_utc": "2026-01-19 22:40:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kq7j8",
          "author": "varwave",
          "text": "Pick up a MS in biostatistics en route to the PhD or at least take the mathematics statistics sequences and some classes on applied uses of generalized linear models. Why not write your dissertation in something data heavy? Are you already studying in a medical center? If so network! Throwing out domain knowledge is pretty silly. \n\nGet good at programming. R might make more sense than Python in life sciences. Learn both. There‚Äôs so many opportunities to contribute to open source software in life sciences \n\nI work at a research hospital as a software developer with an emphasis on data. The PhDs in hospitals usually make more money in research than an entry data analyst. Working with collaborators that are statistically literate is a game changer in healthcare research",
          "score": 1,
          "created_utc": "2026-01-20 00:12:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8ehu",
          "author": "AccordingWeight6019",
          "text": "In my experience, certificates mostly signal baseline effort, not readiness. What moves the needle is seeing you take a vague question, work with imperfect data, and explain your assumptions and limits clearly. Also, research background can be a strong positive if you frame it that way.",
          "score": 1,
          "created_utc": "2026-01-20 05:22:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0np9gw",
          "author": "sharksnack3264",
          "text": "I'm in insurance data science. We basically do not care about the bootcamps. If you have a specifically data science degree we still are going to check your capabilities just the same as someone from a non traditional background because some programs don't have the technical rigor we need. Some of our best hires have come from academia grad programs and degrees.¬†\n\n\nWhat's most important is you have a solid foundation in applied maths and statistics and solid programming skills, can teach yourself new areas of statistics and programming well and quickly to keep up with the pace of change and that you have rock solid communication skills and can talk about technical ideas clearly and concisely to a range of audiences (from PhD backgrounds to someone whose last math class was in freshman year of undergrad). Subject matter expertise is important though. We teach it on the job, but with the current hiring environment someone who has that will always be a step ahead of anyone else.",
          "score": 1,
          "created_utc": "2026-01-20 12:49:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rwfho",
          "author": "MLEngDelivers",
          "text": "It depends on the role. If it‚Äôs a team that almost exclusively deploys stuff to prod, being a good programmer is #1, above ML knowledge for sure. \n\nIn rare cases, someone has been lacking but I‚Äôve made a bet on their intelligence and basically them being able to learn whatever in 90 days.",
          "score": 1,
          "created_utc": "2026-01-21 01:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tdbee",
          "author": "thro0away12",
          "text": "I would try to really leverage your microbiology background and look for analytics jobs related to that. People like the idea of somebody who can understand the business ie: stakeholders and having the background enables you to do that. With quant skills, you‚Äôre already pretty much there but you still probably need a little bit of the ‚ÄúSWE‚Äù mindset in creating projects or workflows that are reproducible. Try to have something in your GitHub. It‚Äôs a tough job market out there so do keep in mind that if you‚Äôre trying to enter, it may take longer. But don‚Äôt try to pivot to something totally unrelated like fintech or what have you because with an unrelated degree, it won‚Äôt align. Also, it‚Äôs worth probably applying to a certain company in a different role and do an internal transfer if a position opens up.",
          "score": 1,
          "created_utc": "2026-01-21 07:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xtm6a",
          "author": "TheGoodNoBad",
          "text": "As of right now‚Ä¶ it‚Äôs tough to say because even those with the proper credentials and plenty of years of experience from big companies like META, MSFT, Amazon, etc are looking for jobs too because of the AI shakeup. You‚Äôre effectively competing against both college graduates with aligned degrees and seniors who have analytics down to the back of their hands for the same junior, mid, and senior level positions. The game has changed and a single bootcamp will not guarantee anything like it did 10 years ago",
          "score": 1,
          "created_utc": "2026-01-21 22:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ln9pn",
          "author": "Embiggens96",
          "text": "I'd prioritize experience with tools like power bi, tableau and stylebi over python and sql.",
          "score": -1,
          "created_utc": "2026-01-20 03:12:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qinepv",
      "title": "Looking for Group",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qinepv/looking_for_group/",
      "author": "Expensive_Culture_46",
      "created_utc": "2026-01-21 03:53:36",
      "score": 21,
      "num_comments": 14,
      "upvote_ratio": 0.96,
      "text": "Hello all,\n\nI am looking for any useful and free email subscriptions to various data analytics/ data science information. Doesn‚Äôt matter if it‚Äôs from a platform like snowflake or just a substack. \n\nLet me know and suggest away.",
      "is_original_content": false,
      "link_flair_text": "Career | US",
      "permalink": "https://reddit.com/r/datascience/comments/1qinepv/looking_for_group/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0sz0sc",
          "author": "Lady_Data_Scientist",
          "text": "https://www.datascienceweekly.org/\n\nhttps://dataanalysis.substack.com/\n\nhttps://www.morgandepenbusch.com/\n\nhttps://datastoryteller.substack.com/",
          "score": 10,
          "created_utc": "2026-01-21 05:10:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0utbge",
              "author": "Expensive_Culture_46",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-01-21 14:00:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t4bib",
          "author": "AccordingWeight6019",
          "text": "I have found it more useful to be selective rather than subscribe broadly. A lot of newsletters recycle the same surface level content and add noise. The ones that tend to stick are narrowly scoped and opinionated, usually written by practitioners reflecting on real projects rather than trends. It can also help to follow a few long-form blogs or lab posts directly instead of inbox digests. curious what level you are aiming for, practical workflows or more research and theory.",
          "score": 5,
          "created_utc": "2026-01-21 05:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tdh5h",
              "author": "tongEntong",
              "text": "Any example of those opinionated interesting newsletters/ post?",
              "score": 3,
              "created_utc": "2026-01-21 07:06:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o10e65o",
                  "author": "AccordingWeight6019",
                  "text": "A few I‚Äôve found useful are ones where the author walks through a real dataset or deployment rather than just summarizing papers. Lab blogs from companies like DeepMind, FAIR, or OpenAI often include detailed experiments and reflections. On the newsletter side, some independent practitioners share full project retrospectives, including mistakes and trade-offs. the key is to look for posts that explain *why* decisions were made, not just what was done.",
                  "score": 1,
                  "created_utc": "2026-01-22 07:51:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0utrtt",
              "author": "Expensive_Culture_46",
              "text": "Thank you! Agree with real projects being more valuable.",
              "score": 2,
              "created_utc": "2026-01-21 14:02:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o10enuc",
                  "author": "AccordingWeight6019",
                  "text": "Exactly. Once you start seeing how someone actually tackled a problem end to end, the decisions, trade-offs, and unexpected bumps, that‚Äôs where most of the learning happens. Abstract summaries or curated lists rarely capture that nuance, so focusing on a few detailed case studies or project write-ups can be much more insightful than trying to follow everything.",
                  "score": 1,
                  "created_utc": "2026-01-22 07:56:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0x9ry2",
          "author": "nian2326076",
          "text": "Join Prachub Community",
          "score": 2,
          "created_utc": "2026-01-21 20:45:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0yk5k0",
              "author": "Expensive_Culture_46",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-01-22 00:35:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0u2f1f",
          "author": "EvilWrks",
          "text": "We also run **Evilworks** (data science + real projects + ‚Äúno-BS‚Äù explanations). If you prefer **video**, that‚Äôs the channel. If you prefer **text**, we post write-ups on our blog too. Youtube channel is [https://www.youtube.com/@Evilwrks](https://www.youtube.com/@Evilwrks) and our blog would be  [https://www.evilworks.com/blog](https://www.evilworks.com/blog)",
          "score": 1,
          "created_utc": "2026-01-21 10:59:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ut8hl",
              "author": "Expensive_Culture_46",
              "text": "Thank you!",
              "score": 2,
              "created_utc": "2026-01-21 13:59:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0x0w9t",
          "author": "InformalTackle236",
          "text": "I know of some youtube channels that helped me to learn a lot, if you are interested please DM :)",
          "score": 1,
          "created_utc": "2026-01-21 20:05:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ykb6a",
              "author": "Expensive_Culture_46",
              "text": "Oooh. Interesting. I will message you!",
              "score": 1,
              "created_utc": "2026-01-22 00:36:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ze62t",
          "author": "normee",
          "text": "I'm a big fan of the [Data Elixir](https://dataelixir.com/) weekly free newsletter. The content is well-curated and summarized and spans a broad range of topics without being overwhelming link dumps. Most weeks there's at least one or two pieces I'm clicking on.",
          "score": 1,
          "created_utc": "2026-01-22 03:25:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh0m1y",
      "title": "Which role better prepares you for AI/ML and algorithm design?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/",
      "author": "Huge-Leek844",
      "created_utc": "2026-01-19 10:25:00",
      "score": 19,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "Hi everyone,\n\nI‚Äôm a perception engineer in automotive and joined a new team about 6 months ago. Since then, my work has been split between two very different worlds:\n\n‚Ä¢ Debugging nasty customer issues and weird edge cases in complex algorithms\n‚Ä¢ C++ development on embedded systems (bug fixes, small features, integrations)\n\nNow my manager wants me to pick one path and specialize:\n\n1. Customer support and deep analysis\n   This is technically intense. I‚Äôm digging into edge cases, rare failures, and complex algorithm behavior. But most of the time I‚Äôm just tuning parameters, writing reports, and racing against brutal deadlines. Almost no real design or coding.\n\n2. Customer projects\n   More ownership and scope fewer fire drills. But a lot of it is integration work and following specs. Some algorithm implementation, but also the risk of spending months wiring things together.\n\nHere‚Äôs the problem:\nMy long-term goal is AI/ML and algorithm design. I want to build systems, not just debug them or glue components together.\n\nRight now, I‚Äôm worried about getting stuck in:\n\n\\* Support hell where I only troubleshoot\n\\* Or integration purgatory where I just implement specs\n\nIf you were in my shoes:\n\nWhich path actually helps you grow into AI/ML or algorithm roles?\nWhat would you push your manager for to avoid career stagnation?\n\nAny real-world advice would be hugely appreciated.\nThanks!\n\n",
      "is_original_content": false,
      "link_flair_text": "AI",
      "permalink": "https://reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0ggc2d",
          "author": "phoundlvr",
          "text": "Tell your boss your long term goals for your cater and ask their advice. Preface it with a statement acknowledging that you want to prepare yourself for your long term goal and that it‚Äôs okay that neither is the long term goal. Emphasize that you have a lot to learn and see both roles as valuable. \n\nBelieve it or not sharing long term career goals is a good thing, even if they‚Äôre outside of his team. Good managers will help you get there.",
          "score": 5,
          "created_utc": "2026-01-19 10:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hlztz",
          "author": "latent_threader",
          "text": "If your goal is AI/ML and algorithm design, the support-heavy path can help your intuition but it is easy to get pigeonholed there. You learn failure modes deeply, but you rarely get credit for creating new methods. The customer project path is usually better if you can negotiate real ownership of algorithm pieces instead of pure integration. I would push your manager for a hybrid role where you both design or prototype changes and then see them through deployment. Also ask explicitly how people on each path have moved into algorithm roles before. That answer tells you a lot.",
          "score": 3,
          "created_utc": "2026-01-19 15:22:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0poddu",
          "author": "eli_arad",
          "text": "Honestly, neither path really gets you to AI/ML. both sound like side quests that keep you ‚Äúuseful‚Äù but not growing. Debugging teaches pain tolerance, integration teaches patience, but neither builds real innovation muscle. If your manager actually cares about growth, they‚Äôd carve out time for R&D or internal prototyping, not force you to choose between two flavors of stagnation.",
          "score": 2,
          "created_utc": "2026-01-20 18:40:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tt4mc",
          "author": "LobsterNext4373",
          "text": "The role that best prepares you for AI/ML and algorithm design is the one that consistently forces you to frame ambiguous problems, build models under constraints, and translate algorithms into real decisions not the one that only optimizes code or reports metrics.\n\nFrom a Mu Sigma decision-sciences perspective, preparation for AI/ML is less about job titles and more about decision ownership and modeling depth.",
          "score": 1,
          "created_utc": "2026-01-21 09:34:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wklpr",
          "author": "BookOk9901",
          "text": "A training program from industry mentors, real projects with code and professionals to guide you",
          "score": 1,
          "created_utc": "2026-01-21 18:51:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gffuy",
          "author": "latent_signalcraft",
          "text": "if your goal is AI or algorithm design focus on which path gives you influence over problem framing and evaluation not just tasks. support work helps only if you are learning failure modes and shaping metrics otherwise it becomes reactive tuning. integration work helps only if you can question specs and validate whether the system actually works in the real world. i would push your manager for ownership of error analysis metric definition or design reviews because that is where algorithm designers are really developed.",
          "score": 1,
          "created_utc": "2026-01-19 10:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h6z3m",
          "author": "dataflow_mapper",
          "text": "If your end goal is AI/ML and algorithm design, I would bias toward the path that keeps you closest to building and modifying systems, even if it is not perfect. Deep support work teaches you how algorithms fail in the real world, which is valuable, but it can trap you in reactive mode with little room to design new things. Integration work at least keeps you writing code and understanding system boundaries, which is easier to evolve into ownership of algorithms later.\n\nThat said, the ideal move is usually not choosing one extreme. I would push your manager for explicit time or scope around algorithm ownership, even small pieces, validation logic, prototypes, or improvements rather than just glue work. Career stagnation tends to happen when your role stops producing artifacts that look like design or code. Debugging builds intuition, but building things is what usually gets you labeled as an algorithm engineer.",
          "score": 1,
          "created_utc": "2026-01-19 14:05:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8p3h",
          "author": "patternpeeker",
          "text": "If the goal is real AI or algorithm design, I would bias toward whichever path gets you closest to owning a problem end to end, even if the work feels less glamorous. Deep support work teaches you how and why algorithms fail in the wild, which is valuable, but it can stall if you never get to change the design that caused the failure. Pure integration has the opposite risk, you ship a lot but rarely make core decisions.\n\nIn practice, the people I see move into stronger ML or algorithm roles are the ones who combine failure analysis with proposing and implementing fixes. I would push your manager for a hybrid scope where you debug edge cases and then actually redesign or prototype changes, not just tune knobs or write reports. Titles matter less than whether you can point to concrete algorithmic decisions you made and systems you improved because of real-world behavior.",
          "score": 0,
          "created_utc": "2026-01-20 05:24:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf9zxw",
      "title": "Is LLD commonly asked to ML Engineers?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/",
      "author": "FinalRide7181",
      "created_utc": "2026-01-17 10:36:09",
      "score": 15,
      "num_comments": 24,
      "upvote_ratio": 0.76,
      "text": "I am a last year student and i am currently studying for MLE interviews.\n\nMy focus at the moment is on DSA and basics of ML system design, but i was wondering if i should prepare also oop/design patterns/lld. Are they normally asked to ml engineers or rarely?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o032xxd",
          "author": "sometimes_angery",
          "text": "I'm an MLE and have no idea what LLD is.",
          "score": 25,
          "created_utc": "2026-01-17 10:41:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o095wy3",
              "author": "avourakis",
              "text": "They got me there too üòÖ",
              "score": 1,
              "created_utc": "2026-01-18 07:22:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0339sp",
              "author": "FinalRide7181",
              "text": "Low Level Design, like design classes for a system like parking lot using OOP classes, methods, inheritance, design patterns.",
              "score": 0,
              "created_utc": "2026-01-17 10:44:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o033h2s",
                  "author": "sometimes_angery",
                  "text": "Depends on the job I guess. Do they expect you to implement a system like parking lot? Cuz maybe that's not entirely an MLE job.",
                  "score": 3,
                  "created_utc": "2026-01-17 10:46:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o06554g",
              "author": "__mitra__",
              "text": "Same. Never had any company ask about OOP patterns or similar. Not that it's irrelevant, but I guess it's assumed you have a base understanding of it.",
              "score": 0,
              "created_utc": "2026-01-17 20:47:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0685up",
                  "author": "FinalRide7181",
                  "text": "I am doing an MS in stats with ml/dl focus. I know python and basic oop (class, attribute, method, inheritance, polymorph) but i am not a CS student, i dont really know design patterns/oop design.\n\nDo you think i should study them if i aim to be a MLE or i can skip them and focus on LC?",
                  "score": 1,
                  "created_utc": "2026-01-17 21:03:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o036gs4",
          "author": "Hungry_Age5375",
          "text": "Big tech asks LLD, real ML companies don't. Stick with ML system design - that's where the value is.",
          "score": 9,
          "created_utc": "2026-01-17 11:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o038gm9",
              "author": "FinalRide7181",
              "text": "So no need to do design patterns? \n\nI have been told that some companies ask them to swe, but for mle it is a different story right? Same for ai engineer?",
              "score": 1,
              "created_utc": "2026-01-17 11:32:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03edtc",
          "author": "patternpeeker",
          "text": "It depends a lot on how the team defines ‚ÄúML engineer.‚Äù In practice, if the role owns production code, services, or pipelines, some level of LLD and basic OOP shows up pretty often, even if it is not labeled that way. You might not get textbook design patterns, but you will get questions that test whether you can structure code that is testable, extendable, and not a one-off notebook. Teams that treat MLE as research plus glue care less about this, while platform or product-facing teams care a lot. I would not go deep into patterns for their own sake, but you should be comfortable explaining how you would design and evolve a small ML service or pipeline over time. That usually matters more than pure DSA once you are past the screen.",
          "score": 3,
          "created_utc": "2026-01-17 12:21:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04lxl4",
              "author": "FinalRide7181",
              "text": "Is it asked to juniors too or generally to people with at least a couple of years of experience?",
              "score": 1,
              "created_utc": "2026-01-17 16:24:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h4ji",
          "author": "dataflow_mapper",
          "text": "From what I have seen, it depends a lot on the company and how they define the MLE role. If the role is closer to software engineering with ML on top, then basic LLD and OOP concepts come up fairly often. Things like designing a feature pipeline class or structuring a training service.\n\nIf it is more research or modeling heavy, they usually focus more on ML fundamentals and system design at a higher level. I would not go deep into patterns, but being comfortable explaining clean class design, interfaces, and tradeoffs is a safe bet. It rarely hurts, and it can help you stand out when interviews lean practical.",
          "score": 2,
          "created_utc": "2026-01-17 12:42:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04k54r",
          "author": "madbadanddangerous",
          "text": "This job market is a dumpster fire. Anything and everything is on the table. I've been asked about low level CPU internals for ML engineer positions. I've been asked about NLP learning for robotic ML interviews. I've been asked to show how well I can vibe code, how to implement a custom loss function and code an ML model from scratch using only numpy, presentations on prior projects, tests, on-site projects. Once I was asked to code a live solution to a geology problem after getting a 15 minute PowerPoint presentation on geological processes. Another time, the interviewer handed me an unsolved problem in probability theory and asked me to solve it. \n\nYou can be asked anything even tangentially related to computing and then be graded on it. This job market is an experience in humiliation, superstition, cargo culting, rejection, and self-flagellation. \n\nJust do your best and hope you get lucky. Try not to sweat the rejection or let it affect your mental health too much. Companies are out of their minds right now, and we all need to remember that we are more than what they test for in a broken interview process.",
          "score": 1,
          "created_utc": "2026-01-17 16:16:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05honc",
          "author": "NoProfession6095",
          "text": "I will be starting to study Data Science and see where it lands me. I am BTech undergrad CSE 2025 passout and want to explore the domain. What should my first steps be?",
          "score": 1,
          "created_utc": "2026-01-17 18:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07ymo6",
          "author": "thinking_byte",
          "text": "From what I have seen, it depends a lot on the company and how close the role is to production work. Teams that treat MLEs as software engineers who happen to work on ML will care about LLD, clean interfaces, and basic design patterns. If the role is more research or modeling focused, it comes up far less.\n\nI would not go deep into academic OOP theory, but being comfortable explaining how you would structure a training pipeline, inference service, or feature store is useful. Even simple class design and separation of concerns goes a long way. The signal they usually want is whether you can build and maintain ML systems, not just train models once.",
          "score": 1,
          "created_utc": "2026-01-18 02:27:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o081isk",
              "author": "FinalRide7181",
              "text": "Is that mostly learned on the job? If it is then it is fine, what i was referring to was practicing parking lot/design patterns‚Ä¶ which is i think what you called ‚Äúacademic OOP theory‚Äù",
              "score": 1,
              "created_utc": "2026-01-18 02:42:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0dyi6h",
                  "author": "thinking_byte",
                  "text": "Yeah, that stuff is mostly learned on the job. Very few teams expect a new grad MLE to rattle off design patterns or do formal LLD like a backend interview. What they usually care about is whether you can reason about structure at a practical level.\n\nParking lot style questions are overkill for most MLE roles. A better use of time is being able to talk through how you‚Äôd organize code for training vs inference, how you‚Äôd keep things testable, and how you‚Äôd avoid everything turning into one giant script. If you can explain those tradeoffs clearly, that‚Äôs usually enough signal. The rest comes naturally once you‚Äôre maintaining real systems.",
                  "score": 1,
                  "created_utc": "2026-01-19 00:19:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0907wa",
          "author": "AccordingWeight6019",
          "text": "It really depends on how the company defines the MLE role. wherein in teams where MLEs are closer to software engineers who own production systems, some form of LLD or object design tends to come up, even if it is not framed explicitly as design patterns. In more research leaning or modeling focused roles, it is often secondary to data, modeling, and evaluation discussions. In practice, being able to reason about code structure, interfaces, and trade-offs usually matters more than memorizing patterns. job titles hide a lot of variation here, so the safest bet is to be comfortable explaining how you would structure a real system at a high level and at a code level.",
          "score": 1,
          "created_utc": "2026-01-18 06:32:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09928z",
              "author": "FinalRide7181",
              "text": "I mean if what is being asked is ml system design and oop for pipelines then it is fine. What i meant with LLD was design patterns and things like design parking lot, are these common for mle or almost only for traditional swe?",
              "score": 1,
              "created_utc": "2026-01-18 07:50:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09idfh",
          "author": "nian2326076",
          "text": "\n\nI'm an MLE¬†",
          "score": 1,
          "created_utc": "2026-01-18 09:15:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09isjf",
              "author": "FinalRide7181",
              "text": "Great! And what do you think about my question?",
              "score": 1,
              "created_utc": "2026-01-18 09:19:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bboq7",
          "author": "LeonhardEuler_",
          "text": "What do you do to prep for ML System design? I'm a new grad looking to go MLE",
          "score": 1,
          "created_utc": "2026-01-18 16:34:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o055gga",
          "author": "akornato",
          "text": "Low-level design questions are much less common for MLE roles than DSA and ML system design, but they do come up - especially at companies where MLEs are expected to write production code and work closely with software engineers. The reality is that it varies significantly by company and team. Big tech companies might throw in some OOP and design patterns questions to assess your software engineering fundamentals, but they're usually not the main focus. Smaller companies or places where the MLE role is closer to a traditional SWE role might dig deeper into LLD. If you're already solid on DSA and ML system design, spending maybe 20-30% of your remaining prep time on basic OOP principles and common design patterns is reasonable insurance, but don't let it take priority over your core MLE prep.\n\nThe good news is that you don't need to go as deep as a backend engineer would - just understand the fundamentals like SOLID principles, a handful of common patterns (factory, strategy, observer), and how to write clean, maintainable code. Most interviewers care more about seeing that you can structure code reasonably than testing whether you've memorized every design pattern. If you want help figuring out how to answer these kinds of questions when they do come up, I built [interview AI copilot](http://interviews.chat) to handle unexpected interview questions across all topics, including the occasional curveball LLD question in an MLE interview.",
          "score": 1,
          "created_utc": "2026-01-17 17:56:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qenpcq",
      "title": "Data analysis vs C++ feature design",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qenpcq/data_analysis_vs_c_feature_design/",
      "author": "Huge-Leek844",
      "created_utc": "2026-01-16 18:17:27",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Hi everyone,  \nI‚Äôm a radar signal processing engineer in automotive and started a small team six months ago. My work so far has been a mix of:  \n  \n1) Radar data analysis for bugs found in customers: performance issues, drop of detections, loss of tracking. I learnt about DSP and radar algorithms.  \n2) C++ coding: small implementations and bug fixes, embedded systems work (inter-core comms, debugging)  \nThe team is growing, so I need to choose one path to focus on. My manager suggested either continuing with:  \n  \n1) Customer support and data analysis, which is very complex and does require a decent understanding of algorithms and math but rarely involves making changes, at best only changing a few parameters. Tough deadlines here.   \nOR  \n2) Moving to C++ customer projects. I will have more scope, ownership and design but ranges from simple integration work to algorithm implementations. So i won't analyse super complex algorithms, and i could potentially work on boring integration topics for 6 months! Its very customer driven. Less deadlines.  \n  \nMy long-term goal is AI, ML, and general algorithm design. I want to build and design algorithms, not just tune parameters or implement specs.\n\n  \nWhich path would you choose to maximize growth toward AI and algorithm work, and how would you make it as useful as possible?  \nWhat kind of questions i could ask my manager?  \n  \nThank you.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qenpcq/data_analysis_vs_c_feature_design/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzyy177",
          "author": "Equal-Agency4623",
          "text": "Between options 3 and 4, I‚Äôll recommend option 4 because it opens door to more career opportunities for you. With that experience, you can work as a Research Engineer in AI labs where you implement novel algorithms. You can also work as a Quantitative Developer in quant hedge funds where you implement trading algos.",
          "score": 6,
          "created_utc": "2026-01-16 18:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02sqsw",
          "author": "AccordingWeight6019",
          "text": "Given your long-term goal, I would be biased toward the path that gives you ownership over problem formulation, even if the algorithms are simpler at first. Tuning parameters under deadline pressure builds intuition, but it rarely lets you define assumptions or failure modes, Which is what carries over to ML work. On the C++ side, the risk is getting stuck in integration, so the key question is whether you can own parts of the algorithmic design and not just implement specs. I would ask your manager how often each path involves proposing changes versus executing predefined solutions, and who is accountable when performance degrades. the skill that transfers best to AI work is not a specific tool, but the habit of reasoning about trade-offs and system behavior end to end.",
          "score": 3,
          "created_utc": "2026-01-17 09:05:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02knfj",
          "author": "SkillSalt9362",
          "text": "1. I would go for AI ML but also consider my interest \n\n2. building side projects are non negotiable, it helps to improve our skills work on algorithms and more!!",
          "score": 2,
          "created_utc": "2026-01-17 07:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05iq6q",
          "author": "DiligentSlice5151",
          "text": "What  is hard about Customer support and data analysis?",
          "score": 0,
          "created_utc": "2026-01-17 18:57:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05j12h",
              "author": "DiligentSlice5151",
              "text": "Do you mean blackbox data analysis?",
              "score": 0,
              "created_utc": "2026-01-17 18:58:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhldsg",
      "title": "Using logistic regression to probabilistically audit customer‚Äìtransformer matches (utility GIS / SAP / AMI data)",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qhldsg/using_logistic_regression_to_probabilistically/",
      "author": "Zestyclose_Candy6313",
      "created_utc": "2026-01-20 00:06:17",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nI‚Äôm currently working on a project using utility asset data (GIS / SAP / AMI) and I‚Äôm exploring whether this is a solid use case for introducing ML into a¬†**customer-to-transformer matching audit**¬†problem. The goal is to ensure that meters (each associated with a customer) are connected to the correct transformer.\n\n# Important context\n\n* Current customer ‚Üí transformer associations are driven by a¬†**location ID**¬†containing circuit, address/road, and company (opco).\n* After an initial analysis, some associations appear wrong, but¬†**ground truth is partial**¬†and validation is expensive (field work).\n* The goal is¬†**NOT**¬†to auto-assign transformers.\n* The goal is to¬†**prioritize which existing matches are most likely wrong**.\n\nI‚Äôm leaning toward framing this as a¬†**probabilistic risk scoring**¬†problem rather than a hard classification task, with something like¬†**logistic regression**¬†as a first model due to interpretability and governance needs.\n\n# Initial checks / predictors under consideration\n\n**1) Distance**\n\n* Binary distance thresholds (e.g., >550 ft)\n* Whether the assigned transformer is the¬†**nearest**¬†transformer\n* Distance ratio: distance to assigned vs. nearest transformer (e.g., nearest is 10 ft away but assigned is 500 ft away)\n\n**2) Voltage consistency**\n\n* Identifying customers with similar service voltage\n* Using voltage consistency as a signal to flag unlikely associations (challenging due to very high customer volume)\n\nModel output to be: \n\nP(current customer ‚Üí transformer match is wrong)\n\n\n\nThis probability would be used to define operational tiers (auto-safe, monitor, desktop review, field validation).\n\n# Questions\n\n1. Does¬†**logistic regression**¬†make sense as a first model for this type of probabilistic audit problem?\n2. Any pitfalls when relying heavily on¬†**distance + voltage**¬†as primary predictors?\n3. When people move beyond logistic regression here, is it usually¬†**tree-based models + calibration**?\n4. Any advice on¬†**threshold / tier design**¬†when labels are noisy and incomplete?",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qhldsg/using_logistic_regression_to_probabilistically/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0kpmhd",
          "author": "Electrical-Window170",
          "text": "This sounds like a solid approach - logistic regression is perfect for interpretable risk scoring when you need to explain decisions to utility folks\n\n  \nDistance ratios are way more informative than absolute distance thresholds, and voltage consistency is clutch if you can get clean data on it. Just watch out for geographic clustering effects messing with your distance assumptions (like rural vs urban transformer density)\n\n  \nFor thresholds with noisy labels, start conservative and let the field validation feedback tune your cutoffs over time rather than trying to optimize on incomplete ground truth upfront",
          "score": 2,
          "created_utc": "2026-01-20 00:09:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0krmxv",
          "author": "trustme1maDR",
          "text": "You need a ground truth for your outcome variable (right/wrong match) to be able to train your model..at least for an unbiased sample of your data. It's unclear if you actually have this - you said partial.¬†",
          "score": 2,
          "created_utc": "2026-01-20 00:20:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ksy0b",
              "author": "Zestyclose_Candy6313",
              "text": "That‚Äôs a very fair point and definitely not claiming to have full or perfect ground truth. For most associations, correctness is  uncertain unless there‚Äôs been field validation (which is very costly). The way I‚Äôm thinking about it is to¬†only train on a subset of high-confidence labels: confirmed field corrections where available, plus some very strong inferred cases (like extreme distance ratios with a clearly closer viable transformer). Everything in the gray area would stay unlabeled and only be scored. The intent is to rank/prioritize review, not to auto-correct matches. The new field validation would feed back as additional high-confidence labels, so the model and thresholds can be tuned iteratively",
              "score": 2,
              "created_utc": "2026-01-20 00:27:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ntqvr",
          "author": "latent_threader",
          "text": "Logistic regression makes a lot of sense as a first pass if the goal is prioritization and explainability, not auto-fixing. Distance and voltage are strong signals, but they‚Äôre noisy and can be ‚Äúwrong for the right reasons,‚Äù so I‚Äôd treat the output as a risk score, not truth. In practice people often move to tree models later for interactions, but good calibration and tiering around review capacity usually matter more than model complexity.",
          "score": 2,
          "created_utc": "2026-01-20 13:17:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjkko5",
      "title": "What‚Äôs your Full stack data scientist story.",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qjkko5/whats_your_full_stack_data_scientist_story/",
      "author": "dead_n_alive",
      "created_utc": "2026-01-22 04:17:56",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.78,
      "text": "Data scientists label has been applied with a broad brush in some company data scientists mostly do analytics, some do mostly stat and quant type work, some make models but limited to notebooks and so on. \n\nIt‚Äôs seems logical to be at a startup company or a small team in order to become a full-stack data scientist. Full stack in a sense: ideation-to POC -to Production.\n\nMy experience (mid size US company \\~2000 employees) mostly has been talking with the product clients (internal and external), decide on models and approach, training and testing models and putting the tested version python scripts into git, data engineering/production team clones and implements it. \n\nWhat is your story and what do you suggest getting more exposure to the DATA ENG side to become a full stack data scientist?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qjkko5/whats_your_full_stack_data_scientist_story/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0zrybf",
          "author": "DukeRioba",
          "text": "Full stack is mostly about ownership, not title. When I owned a model end-to-end, I was forced to learn logging, monitoring, and deployment. Before that, I was just a notebook person",
          "score": 13,
          "created_utc": "2026-01-22 04:53:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0zt5bg",
          "author": "ChemicalGreedy945",
          "text": "I like pancakes, full stack.",
          "score": 6,
          "created_utc": "2026-01-22 05:01:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0zx0v0",
          "author": "VictoryMotel",
          "text": "Once I got paid half up front and that was a half stack,.then I got the full thing, that was a full stack.",
          "score": 5,
          "created_utc": "2026-01-22 05:29:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o107ql0",
          "author": "AccordingWeight6019",
          "text": "I think a lot of this comes down to how a team defines full stack. In many orgs, the handoff you describe is the intentional boundary, not a personal gap. You can learn a lot by owning the last mile for a small system, even if it is unglamorous monitoring, data validation, or retraining logic. Startups can compress these roles, but rigor often gets traded for speed, so you end up learning workarounds more than good systems. the question I always ask is whether the model actually ships and stays alive six months later. If you want more data eng exposure, it usually helps to frame it as reliability and iteration, not career development. That tends to get buy-in faster.",
          "score": 1,
          "created_utc": "2026-01-22 06:54:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10e8f6",
          "author": "Vrulth",
          "text": "Fullstack data science in a feature team revolves around 6 tracks:\n\n- product, what business problem do you solve, \n- data, as a consumer and a producer, with pipelines, tests and governance\n- project management, agile stuff in short \n- science, your usual stuff\n- engineering, make your stuff work at scale\n- accountability, you monitore your system health (observability, finops, tokens...), your metrics data (ndcg...) and business.\n\nFor an example of a story of those tracks applied in a \"you build it, you run it\" spirited data heavy feature team:\nhttps://medium.com/adeo-tech/you-build-it-you-run-it-a-practical-example-from-a-data-science-team-2f4853854684",
          "score": 1,
          "created_utc": "2026-01-22 07:52:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgv0ij",
      "title": "Weekly Entering & Transitioning - Thread 19 Jan, 2026 - 26 Jan, 2026",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/",
      "author": "AutoModerator",
      "created_utc": "2026-01-19 05:01:45",
      "score": 9,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0ff9tm",
          "author": "Yang-Geum-myeong",
          "text": "Hi everyone,\n\nI‚Äôm at a career crossroads and would appreciate some grounded advice. I have 5 years of experience in the insurance/reinsurance domain, working in catastrophe modeling, risk analytics, data cleaning, and geocoding using in house tools. My work has involved heavy data analysis, stakeholder interaction, and translating model outputs into business insights.\n\nI want to change domains and am evaluating two paths:\n\n1. MS abroad 2026 (Data Science / Analytics / related tech programs)\n2. MBA in India (to pivot into consulting / strategy / management roles)\n\nMy key questions: For someone at 5 years experience, which path offers a more realistic and sustainable domain switch? How do recruiters view prior domain experience in each case? Any regrets from people who chose MS vs MBA (or vice versa)? Are there risks of being ‚Äúoverqualified but underexperienced‚Äù in either path? My priority is long-term career satisfaction and growth, not just immediate compensation.\n\nThanks in advance...would really value insights from people who‚Äôve faced a similar situation.",
          "score": 3,
          "created_utc": "2026-01-19 05:28:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fc0k0",
          "author": "Magnum_Opus7",
          "text": "Learning resource, especially for Maths",
          "score": 1,
          "created_utc": "2026-01-19 05:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fh6q8",
          "author": "AccordingWeight6019",
          "text": "One pattern I see a lot is people over-optimizing for tools instead of problem framing. Early on, it helps to focus on core stats, data wrangling, and being able to explain why a model should exist at all. Small end to end projects where you define the question, deal with messy data, and communicate trade-offs tend to be more valuable than stacking certificates. the transition is usually less about learning one more library and more about demonstrating how you think about data in context.",
          "score": 1,
          "created_utc": "2026-01-19 05:42:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fi2xs",
              "author": "Due-Experience-382",
              "text": "Any resources for the project part?",
              "score": 1,
              "created_utc": "2026-01-19 05:49:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iqkhz",
          "author": "Sea_Name4846",
          "text": "I'm a junior in university and I want to apply to internships. My major is data science. Where should I apply?",
          "score": 1,
          "created_utc": "2026-01-19 18:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p0l70",
              "author": "Dry-Enthusiasm-2775",
              "text": "anyone here successfully transitioned from another field into data science recently?",
              "score": 0,
              "created_utc": "2026-01-20 16:52:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhnugu",
      "title": "To those who work in SaaS, what projects and analyses does your data team primarily work on?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qhnugu/to_those_who_work_in_saas_what_projects_and/",
      "author": "Augustevsky",
      "created_utc": "2026-01-20 01:52:44",
      "score": 9,
      "num_comments": 5,
      "upvote_ratio": 0.85,
      "text": "Background:\n\n- CPA with ~5 years of experience \n\n- Finishing my MS in Statistics in a few months\n\nThe company I work for is maturing with the data it handles. In the near future, it will be a good time to get some experience under my belt by helping out with data projects. So what are your takes on good projects to help out on and maybe spear point?",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qhnugu/to_those_who_work_in_saas_what_projects_and/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0mfiiv",
          "author": "AccordingWeight6019",
          "text": "In SaaS, a lot of the high-impact work is around understanding user behavior and retention. Projects that combine cohort analysis, funnel tracking, and feature usage tend to teach both the technical side and the business trade-offs. Forecasting revenue or churn can also be useful, especially if you can link it back to actionable insights. Anything where you can move from data to a clear recommendation usually gets noticed and is a great experience.",
          "score": 5,
          "created_utc": "2026-01-20 06:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lmpsa",
          "author": "Dizzy-Midnight-6929",
          "text": "Those that align with your companies P&L. That could be sales, marketing, finance, costs, pricing, product, testing, or just getting the data into a platform so that you enable others to do these things and provide value. What does your company do? What's their product?",
          "score": 3,
          "created_utc": "2026-01-20 03:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m3tkw",
              "author": "Augustevsky",
              "text": "Streamline cloud services",
              "score": 1,
              "created_utc": "2026-01-20 04:50:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mxbs5",
          "author": "sinki_ai",
          "text": "In SaaS, the core work involves managing data pipelines from sources like Salesforce and Stripe. These are often fragile because upstream schema changes break downstream tables.\n\nThe primary focus is on churn prediction and unit economics. Calculating the exact compute cost per customer is a major project, as mapping cloud spend back to specific users is difficult. Most of the job is ensuring data quality rather than building complex models.",
          "score": 2,
          "created_utc": "2026-01-20 08:54:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rhw7m",
          "author": "nian2326076",
          "text": "A/B testings to make decisions",
          "score": 1,
          "created_utc": "2026-01-20 23:55:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi33t8",
      "title": "Claude Code supports Local LLMs",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qi33t8/claude_code_supports_local_llms/",
      "author": "Technical-Love-8479",
      "created_utc": "2026-01-20 14:51:39",
      "score": 9,
      "num_comments": 3,
      "upvote_ratio": 0.77,
      "text": "Claude Code now supports local llms (tool calling LLMs) via Ollama. The documentation is mentioned here : [https://ollama.com/blog/claude](https://ollama.com/blog/claude)\n\nvideo demo : [https://youtu.be/vn4zWEu0RhU?si=jhDsPQm8JYsLWWZ\\_](https://youtu.be/vn4zWEu0RhU?si=jhDsPQm8JYsLWWZ_)\n\nhttps://preview.redd.it/0ilcwl22pieg1.png?width=1890&format=png&auto=webp&s=e79ff0fa282b3c48eaf735a4fd6f86d1fc276adb\n\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/datascience/comments/1qi33t8/claude_code_supports_local_llms/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0qkqfd",
          "author": "Pbjtime1",
          "text": "Huge.",
          "score": 3,
          "created_utc": "2026-01-20 21:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v0cpt",
          "author": "AendraSpades",
          "text": "Does it work with llama.cpp server instead of ollama?",
          "score": 1,
          "created_utc": "2026-01-21 14:37:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjoqu2",
      "title": "Do you still use notebooks in DS?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qjoqu2/do_you_still_use_notebooks_in_ds/",
      "author": "codiecutie",
      "created_utc": "2026-01-22 08:03:11",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I work as a data scientist and I usually build models in a notebook and then create them into a python script for deployment. Lately, I‚Äôve been wondering if this is the most efficient approach and I‚Äôm curious to learn about any hacks, workflows or processes you use to speed things up or stay organized.\n\nEspecially now that AI tools are everywhere and GenAI still not great at working with notebooks.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qjoqu2/do_you_still_use_notebooks_in_ds/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o10gh41",
          "author": "Ibra_63",
          "text": "I exclusively use notebooks for exploratory data analysis",
          "score": 2,
          "created_utc": "2026-01-22 08:12:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10gkbk",
          "author": "EstablishmentHead569",
          "text": "I don‚Äôt think anyone should restrict themselves when it comes to developments / production workflows.\n\nIf notebooks is easy and fast for quick POC, by all means.\n\nPersonally, I prefer pure Python scripts for production stuffs as our tech stack includes API, CICD, orchestration tools such as airflow and kubeflow.",
          "score": 2,
          "created_utc": "2026-01-22 08:13:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi4mn8",
      "title": "How common is econometrics/causal inf?",
      "subreddit": "datascience",
      "url": "/r/analytics/comments/1qi4lyd/how_common_is_econometricscausal_inf/",
      "author": "ConnectionNaive5133",
      "created_utc": "2026-01-20 15:48:18",
      "score": 4,
      "num_comments": 19,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qi4mn8/how_common_is_econometricscausal_inf/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "o0op7xl",
          "author": "michael-recast",
          "text": "Extremely common and IMO causal inference is the most important skill for \"analytics\" since what people really care about is causal relationships.\n\nMachine learning and prediction are basically a totally separate field with separate applications (also interesting!) but anyone doing \"data analytics\" is effectively doing causal inference.",
          "score": 30,
          "created_utc": "2026-01-20 15:59:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pocj5",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 8,
              "created_utc": "2026-01-20 18:40:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0q28v3",
                  "author": "ianitic",
                  "text": "Yup, almost anyone that I know that does causal inference or econometrics typically has a data scientist title over an analyst title. Like you say, data analysts are usually only doing descriptive analytics.",
                  "score": 5,
                  "created_utc": "2026-01-20 19:43:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0real9",
                  "author": "michael-recast",
                  "text": "idk i guess i'd say that the best analysts take a \"causal inference \" lens to what they're doing and are actively trying to help the business differentiate between pure correlation and actual causation. So you are probably right that descriptively lots of data analysts don't do any causal inference at all, but I'd maintain that if a data analyst wants to improve their impact at their organization, taking a more complete approach to thinking about causal inference (what are the mechanisms driving the relationships they see) is the best way for them to increase their impact and unlock more career opportunities.\n\nIt doesn't need to even be super rigorous applications, but understanding why a diff-in-diff works the way it does is super helpful for unlocking bigger impacts as a data analyst.",
                  "score": 1,
                  "created_utc": "2026-01-20 23:35:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0opjhn",
          "author": "BingoTheBerserker",
          "text": "Common enough. My role is mostly causal inference, not like a hardcore economist at Amazon though. \n\nMostly design experiments (simple a/b tests and more complex geo testing using markets) and design studies that can be answered through causal inference techniques when experiments are not feasible.\n\nHaven‚Äôt applied to a new role because I‚Äôm reasonably satisfied but when I look I do see postings tailored to my specific experience. \n\nI‚Äôm in marketing and pricing data science role",
          "score": 11,
          "created_utc": "2026-01-20 16:01:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pmecd",
              "author": "AdamsFei",
              "text": "Very interesting! Can you share some causation analysis models / keywords for a newbie?",
              "score": 3,
              "created_utc": "2026-01-20 18:32:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pfrjm",
          "author": "Dizzy-Midnight-6929",
          "text": "Very common in the marketing analytics space. A/B testing, media mix modeling (causal regression model, often bayesian and can include DAGs https://www.pymc-marketing.io/en/latest/notebooks/mmm/mmm\\_counterfactuals.html), geo testing (DiD, counterfactuals, synthetic controls, etc.), interrupted time series analysis, propensity modeling (and inverse propensity score), bias correction, switchback testing, and so much more. For many brands, measuring ROI of marketing efforts is paramount",
          "score": 4,
          "created_utc": "2026-01-20 18:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qcgt3",
              "author": "Dizzy-Midnight-6929",
              "text": "Also created this repo for resources on this topic [https://github.com/shakostats/Awesome-Marketing-Science](https://github.com/shakostats/Awesome-Marketing-Science) . give it a star if you find it useful and submit issues or PRs or comment with any additions that are missing!",
              "score": 1,
              "created_utc": "2026-01-20 20:31:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0qkv1x",
                  "author": "BingoTheBerserker",
                  "text": "Did you make this? This is an amazing repo. I have bits and pieces of this saved in my local work folder for things I've worked/am working on but having this all in one place is pretty sick",
                  "score": 1,
                  "created_utc": "2026-01-20 21:10:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0prmo1",
          "author": "Artistic-Comb-5932",
          "text": "1) descriptive analytics\n2) statistical inference\n3) machine learning \n4) causal inference \n\nPick your own adventure",
          "score": 3,
          "created_utc": "2026-01-20 18:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pbgri",
          "author": "Maintob",
          "text": "Extremely common, at least in the gaming industry",
          "score": 1,
          "created_utc": "2026-01-20 17:42:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rhryb",
          "author": "nian2326076",
          "text": "I would say extremely common\\~",
          "score": 1,
          "created_utc": "2026-01-20 23:55:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0u2qes",
          "author": "sinki_ai",
          "text": "They‚Äôre not the default in most analytics roles, but they‚Äôre fairly common in mature orgs where experimentation is limited or expensive (marketing, pricing, marketplaces, policy, growth). Most teams still rely on descriptive stats or simple A/B tests, so causal methods are often a differentiator rather than a baseline skill. The techniques themselves transfer well; what varies is how much rigor a company supports. Framed as real-world impact estimation under constraints, this experience is very marketable.",
          "score": 1,
          "created_utc": "2026-01-21 11:02:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wvtjk",
          "author": "BlueStonefruit",
          "text": "I've been job hunting recently, looking at hundreds of postings, and I'm seeing causal inference listed as a desired qualification more and more often. Seeing as this is a lagging indicator I would bet it happens at a good number of companies. \n\nAs someone else mentioned, answering causal questions is essentially always what people are interested in. When we do descriptive statistics we are often doing this implicitly",
          "score": 1,
          "created_utc": "2026-01-21 19:42:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdrqh6",
      "title": "LLM for document search",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/",
      "author": "Few-Strawberry2764",
      "created_utc": "2026-01-15 18:35:27",
      "score": 3,
      "num_comments": 30,
      "upvote_ratio": 0.57,
      "text": "My boss wants to have an LLM in house for document searches. I've convinced him that we'll only use it for identifying relevant documents due to the risk of hallucinations, and not perform calculations and the like. So for example, finding all PDF files related to customer X, product Y between 2023-2025.\n\nBecause of legal concerns it'll have to be hosted locally and air gapped. I've only used Gemini. Does anyone have experience or suggestions about picking a vendor for this type of application? I'm familiar with CNNs but have zero interest in building or training a LLM myself. ",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzt86ly",
          "author": "UltimateWeevil",
          "text": "What is he actually asking you to solve? It‚Äôs probably more a NLP type task like TF-IDF + cosine similarity or a BM25 keyword matching task. \n\nFeels like a LLM is overkill unless he wants some kind of intelligent capability to query the contents. If so I‚Äôd suggest looking into Ollama for local hosting a LLM as you can choose pretty much any model you want and run a vectorDB like Chroma for you RAG element. You‚Äôll need to make sure you get your chunking done correctly and if you can nail your metadata tags it‚Äôll help massively for retrieval.",
          "score": 22,
          "created_utc": "2026-01-15 22:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztl888",
              "author": "DiligentSlice5151",
              "text": "second this ! All this for some PDFs.  Why?",
              "score": 5,
              "created_utc": "2026-01-15 23:22:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09mtqk",
                  "author": "Tricky_Math_5381",
                  "text": "Maybe the documents are very scattered or mixed? Idk too little information but maybe you want something like\n\nHey what DIN standards are relevant for the elements we get from producer a?\n\nA llm could maybe be useful for that",
                  "score": 1,
                  "created_utc": "2026-01-18 09:57:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs3opa",
          "author": "Rockingtits",
          "text": "Start with basic semantic similarity vector search and then into more advanced rag techniques like hybrid search, deep research and graphRAG.¬†\n\nIf you don‚Äôt need to generate an answer you can do a lot with a local model, it‚Äôs just doing embeddings essentially.\n\n\nYou‚Äôre gonna need a clever process for ingesting your documents unless they are squeaky clean also.¬†",
          "score": 28,
          "created_utc": "2026-01-15 19:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzslaxk",
              "author": "DiligentSlice5151",
              "text": " Yes and Yes on document cleaning  and database management.",
              "score": 6,
              "created_utc": "2026-01-15 20:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzswc8h",
          "author": "DFW_BjornFree",
          "text": "Why do you need an LLM? Just do a mixture of elastic search with similarity search.¬†\n\n\nLet users search for defined words / phrases or let them type a few sentences that get passed into a similarity search model that scores documents by match and returns them past a threshold¬†",
          "score": 6,
          "created_utc": "2026-01-15 21:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu8mj7",
          "author": "autumnotter",
          "text": "You're trying to do document search, and llm doesn't do that in the way you're thinking.¬†\n\n\nEffectively you want to do something like OCR, turning PDFs and images into unstructured text, then chunk the text, compute embeddings and vectorize, and then store in a vector database.¬†\n\n\nFrom there you can do document similarity search by querying the vector database. An agentic system can make that query and then return the retrieved context, sharing it with an LLM, which is usually called RAG.\n\n\nYou don't actually need an LLM to do document similarity search.\n\n\nI'm not familiar with vendors that you might use to do this locally, so I can't help you there.",
          "score": 5,
          "created_utc": "2026-01-16 01:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsm13a",
          "author": "Wishwehadtimemachine",
          "text": "LLM + RAG here no?",
          "score": 3,
          "created_utc": "2026-01-15 20:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsgv39",
          "author": "TaiChuanDoAddct",
          "text": "Are you in a microsoft or google environment? What your boss actually wants is a RAG, and they're honestly not hard or expensive to set up in these environments unless you need 1000% perfect results every time. \n\nMiscrosoft Azure, for example, let's you point an LLM at a sharepoint and tell it to RAG the contents and the connect it to an agent. it's pretty easy.",
          "score": 4,
          "created_utc": "2026-01-15 20:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs3ltl",
          "author": "Some-Librarian-8528",
          "text": "I'm a bit confused why he wants an LLM. Is it just to enable natural language searches? What's wrong with the current system? What's your budget for running it?",
          "score": 3,
          "created_utc": "2026-01-15 19:08:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs9lkt",
              "author": "Few-Strawberry2764",
              "text": "This is my second week on the job and I'm not sure if there is an existing system. Frankly I think he only wants it because \"AI\".",
              "score": 7,
              "created_utc": "2026-01-15 19:35:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzse3h5",
                  "author": "portmanteaudition",
                  "text": "Budget? Doing this properly for 1 person requires tens of thousands of dollars typically. For a large team, hundreds.",
                  "score": -1,
                  "created_utc": "2026-01-15 19:56:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs8f04",
          "author": "letsTalkDude",
          "text": "Why do you need an llm for search a document or even read it.  It is a straightforward nlp.\n\nCan you explain why r u looking for llm",
          "score": 2,
          "created_utc": "2026-01-15 19:30:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsa4xs",
              "author": "Few-Strawberry2764",
              "text": "I'm pretty sure he wants an LLM because he's drunk the AI Kool aid. But after we put a bunch of safety guard rails on usage, it's hard to see how it's meaningfully different from a ctrl F search.",
              "score": 3,
              "created_utc": "2026-01-15 19:38:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsdq7t",
          "author": "portmanteaudition",
          "text": "If you want it all local etc. you will need a fairly powerful in-house server with a large amount of VRAM/GDDR and CPU cores. You can use pretty much any LLM for this, although for local I'd recommend open source models like ollama since you have a decent likelihood of maintanence at 0 cost. All of these models are pre-trained and you can do RAG-like stuff. You just pass them the docs (or set up an OCR front end to do so first) and explain what you want. Inference is where you are going to run into issues hardware-wise - bigger models will tend to be better but require more powerful servers. If your boss just wants this for e.g. a couple of laptops, he is deeply mistaken- he",
          "score": 1,
          "created_utc": "2026-01-15 19:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvhw8n",
          "author": "AccordingWeight6019",
          "text": "For that use case, the hard part is usually not the model but the retrieval layer around it. If the goal is document identification rather than synthesis, you want something that does embeddings well, is stable, and can be deployed on prem without surprises. The LLM then mostly acts as a query interpreter on top of search.\n\nI would evaluate options based on how transparent the retrieval is, how much control you have over chunking and metadata filters, and how predictable the outputs are under edge cases. In practice, simpler models paired with a solid vector store and strict prompting often outperform larger models for legal or compliance constrained setups. The risk is less hallucination and more overconfidence, so strong guardrails and evaluation matter more than raw model capability.",
          "score": 1,
          "created_utc": "2026-01-16 06:09:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw5tn3",
          "author": "latent_threader",
          "text": "For that use case you probably do not want ‚Äúdocument search with an LLM‚Äù so much as classic retrieval plus embeddings. The LLM can sit on top just to interpret the query, not to answer it.\n\nMost teams I have seen in similar legal setups run a local embedding model, index chunks in something like a vector store, and retrieve PDFs by similarity plus metadata filters. The model never needs to see the whole corpus at once, and hallucination risk stays low because you are only ranking documents. The hard parts tend to be chunking, metadata hygiene, and evaluation, not the LLM itself.",
          "score": 1,
          "created_utc": "2026-01-16 09:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxjah4",
          "author": "Voiceofshit",
          "text": "If I'm understanding you correctly, I think you can just do that with a custom copilot agent.\n\n***after you've indexed your current database. Copilot should only be interpreting the human aspect of what they're asking for, then activating whatever hardcoded search function you have for the appropriate documentation with the relevant information. I would only use it as a wrapper for a robust search function that looks pretty and makes it easy to interact with. Lots of people in the comments have good ideas on how to actually implement the search feature. But installing the AI wrapper will make you look like an AI god and make it dummy proof for leadership to interact with.",
          "score": 1,
          "created_utc": "2026-01-16 15:06:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kyy0z",
          "author": "slashdave",
          "text": ">finding all PDF files related to customer X, product Y between 2023-2025\n\nYou mean... like a simple index? Maybe you can start with deploying an ordinary indexer? Stick it on a RAG if someone wants to waste money on an LLM prompt.",
          "score": 1,
          "created_utc": "2026-01-20 00:59:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0le0pq",
          "author": "whodis123",
          "text": "We have experience with air gapped rag and elastic systems.",
          "score": 1,
          "created_utc": "2026-01-20 02:21:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrym1v",
          "author": "DiligentSlice5151",
          "text": " You can use automation to query it. Many companies are essentially just 'wrappers' for Gemini or ChatGPT; however, for local implementation, you would need to use DeepSeek to connect to your database.     Vendor wise  you need someone that specializes in database to search query.  Will you be the one maintaining the LLM after setup ?",
          "score": 2,
          "created_utc": "2026-01-15 18:45:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsl3oo",
          "author": "Perfektio",
          "text": "This is one of the least knowledgeable posts I‚Äôve seen in a while on this sub. You can literally google this in 5 minutes, this is such a common thing to build as it has been the original enterprise hype for the past 4 years.",
          "score": 0,
          "created_utc": "2026-01-15 20:28:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs0xwt",
          "author": "Single_Vacation427",
          "text": "Ugh? LLM search is being used a lot, so even if there is some hallucination, there are was to reduce that and also, what is the risk exactly? Clicking on a document and realizing it was not helpful. \n\nWhat are the legal concerns exactly?\n\nYou don't train an LLM yourself. It's not necessary for search. LLM is just part of the system, which usually includes RAG or something of the sort.\n\nDon't get me wrong, I'm not into the \"Let's use LLM magic\" products, but your post is incredibly ignorant about the space.",
          "score": -1,
          "created_utc": "2026-01-15 18:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztle9z",
          "author": "DiligentSlice5151",
          "text": "This needs to be a film lol :)",
          "score": 0,
          "created_utc": "2026-01-15 23:23:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx1u4g",
          "author": "BearVegetable5339",
          "text": "This is a very grown-up LLM use case because you're treating it as a retrieval and navigation layer, not an oracle. Air-gapped hosting plus legal concerns means the vendor should be judged on deployment model, security posture, and how well they do citation-grounded retrieval over your PDFs. A good system should default to returning filenames, dates, and relevant passages with page references, and it should be comfortable saying no relevant documents found instead of guessing. Your example query is basically metadata filtering plus semantic search, so chunking, embeddings, and indexing quality will matter more than model size. People who've used products like Spellbook, AI Lawyer, CoCounsel often end up caring less about the model and more about the workflow: can you verify in one click and audit what happened. If you keep it retrieval-only and enforce always show sources, you're already avoiding the most common disaster mode.",
          "score": 0,
          "created_utc": "2026-01-16 13:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzry7x6",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-01-15 18:44:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs3vqn",
              "author": "Rockingtits",
              "text": "It‚Äôs not airgapped like op said and I‚Äôve found it to be absolutely rubbish in practice.¬†\n\nIt‚Äôs fine for finding a document in sharepoint but actual retrieval within documents is beyond bad",
              "score": 3,
              "created_utc": "2026-01-15 19:09:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}