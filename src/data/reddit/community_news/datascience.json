{
  "metadata": {
    "last_updated": "2026-01-20 08:59:58",
    "time_filter": "week",
    "subreddit": "datascience",
    "total_items": 13,
    "total_comments": 130,
    "file_size_bytes": 151643
  },
  "items": [
    {
      "id": "1qh8z6e",
      "title": "Indeed: Tech Hiring Is Down 36%, But Data Scientist Jobs Held Steady",
      "subreddit": "datascience",
      "url": "https://www.interviewquery.com/p/indeed-tech-hiring-collapse-data-scientists-exception",
      "author": "warmeggnog",
      "created_utc": "2026-01-19 16:32:42",
      "score": 187,
      "num_comments": 35,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qh8z6e/indeed_tech_hiring_is_down_36_but_data_scientist/",
      "domain": "interviewquery.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0it57u",
          "author": "lordoflolcraft",
          "text": "Meanwhile applicants and new grads and outsiders trying to career change into DS are up (insert giant percentage here) percent",
          "score": 68,
          "created_utc": "2026-01-19 18:36:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j7f4p",
              "author": "Zlatan13",
              "text": "Yeah lol, I'm had at least 500 rejections around September when I just figured I'd stop applying and focus more on networking within my company. Actual black hole",
              "score": 16,
              "created_utc": "2026-01-19 19:40:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0jpxtx",
              "author": "RecognitionSignal425",
              "text": "\\*But Rejection of Data Scientist Jobs Held Steady",
              "score": 11,
              "created_utc": "2026-01-19 21:06:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0m0nfz",
              "author": "Palmquistador",
              "text": "Yep, hello. QA test automation engineer looking to make the jump to better waters.",
              "score": 0,
              "created_utc": "2026-01-20 04:30:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0j65h1",
          "author": "tits_mcgee_92",
          "text": "5 years data science experience. Masters degree in data science. I‚Äôve applied for 50 jobs and have only gotten three interviews. One of them ghosted me during the third round which was so odd",
          "score": 32,
          "created_utc": "2026-01-19 19:34:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jtlxf",
              "author": "snmnky9490",
              "text": "3 interviews out of 50 honestly seems pretty good for \"tech\" jobs these days",
              "score": 33,
              "created_utc": "2026-01-19 21:24:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0kzpbt",
              "author": "turbo_golf",
              "text": "6% app to interview is pretty good.\n\ni know the market has only gotten worse, but i applied for 400+ jobs in late 2024 and only got 4 interviews",
              "score": 10,
              "created_utc": "2026-01-20 01:03:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0m0pyo",
              "author": "Palmquistador",
              "text": "Well there‚Äôs zero hope for me then! ü§£",
              "score": 1,
              "created_utc": "2026-01-20 04:30:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i7qe0",
          "author": "JesterOfAllTrades",
          "text": "I have ~2.5 years of experience in a well known (although not particularly known to be cutting edge) mega Corp with degrees from T10 universities. \n\nI've been applying for jobs and only really applied to like 30 so far but all rejections so far ü•≤ü•≤ I know 30 isn't much at all but I thought after my first job it would get a lot easier. Time to get back to the slog",
          "score": 43,
          "created_utc": "2026-01-19 17:00:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0imz8p",
              "author": "Watabich",
              "text": "What are you degrees in?",
              "score": 6,
              "created_utc": "2026-01-19 18:09:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0iovcv",
                  "author": "protonchase",
                  "text": "Also curious",
                  "score": 6,
                  "created_utc": "2026-01-19 18:17:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0kq8vt",
                  "author": "JesterOfAllTrades",
                  "text": "Sorry for the late reply but mathematics for both.",
                  "score": 3,
                  "created_utc": "2026-01-20 00:12:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0jtqrz",
              "author": "Inevitable-Pin-4507",
              "text": "You should try apps like Whileresume. You will probably get more chance to receive more interesting proposals",
              "score": 1,
              "created_utc": "2026-01-19 21:25:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0it1ys",
              "author": "pc_4_life",
              "text": "university you went to doesn‚Äôt really matter unless you are looking for internships. Stanford, MIT, etc might give your resume a longer look but that‚Äôs about it. 2.5 years still makes you relatively junior. market is better for mid/seniors. best thing you can do is customize your resume for the jobs you are applying to",
              "score": 2,
              "created_utc": "2026-01-19 18:35:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0jm3c5",
                  "author": "Great_Northern_Beans",
                  "text": "Strongly disagree with a little bit of this. I'm a decade out of school now, and even still the university name on my degree (in the \"Stanford, MIT, etc. group; though I won't say which specifically) is heavily referenced to me in probably 50% of my interviews.¬†\n\nIt's actually crazy how many doors a brand name opens for otherwise middling candidates, like myself.",
                  "score": 19,
                  "created_utc": "2026-01-19 20:48:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0loh3v",
                  "author": "free_reezy",
                  "text": "At what point does someone become mid/senior? I‚Äôm going into year 9 and I gotta be honest I internally still feel like an entry-level guy even though I‚Äôm clearing 6 figures.",
                  "score": 1,
                  "created_utc": "2026-01-20 03:19:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0iudwf",
          "author": "TA_poly_sci",
          "text": "Im sure this is in no way confounded by changes in the usage of Indeed as a platform. r datascience always delivering the best science.",
          "score": 18,
          "created_utc": "2026-01-19 18:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jglru",
          "author": "Big-Shake5075",
          "text": "Can someone find reference to this ‚Äúindeed study‚Äù? This article says DS is doing particularly bad by referring to ‚Äúindeed study‚Äù lol https://www.businessinsider.com/gruesome-tech-jobs-data-scientists-analytics-indeed-2025-11",
          "score": 1,
          "created_utc": "2026-01-19 20:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0k5e8q",
              "author": "save_the_panda_bears",
              "text": "https://www.hiringlab.org/2025/11/20/indeed-2026-us-jobs-hiring-trends-report/",
              "score": 3,
              "created_utc": "2026-01-19 22:22:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0livfm",
          "author": "Cheap_Scientist6984",
          "text": "This article smells.  Entry level DS hiring is not doing that well.  Same with SWE.  The entry level layer is evaporating and getting merged with Senior/Lower Middle Management.",
          "score": 1,
          "created_utc": "2026-01-20 02:48:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mdmrt",
              "author": "sailing_oceans",
              "text": "Entry level data science and swe jobs are being sent to India for $9 to $14 an hr unfortunately. \n\nThe opt f1 visa stuff is in the USA and it drags down incomes here.  I was recently forced to hire one of these visas because my company viewed them as a 0% leaving risk, a lower salary AND it‚Äôs like a ~15% discount since they don‚Äôt pay social security or Medicare.",
              "score": 1,
              "created_utc": "2026-01-20 06:01:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mh8vd",
                  "author": "Cheap_Scientist6984",
                  "text": "Fully aware.  Not even mentioning the pseudo-racist fact that these communities of people tend to be highly collectivist in culture and therefore don't like to contradict their managers.  It makes for talent that is almost slave like.",
                  "score": 1,
                  "created_utc": "2026-01-20 06:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0m4066",
          "author": "jobswithgptcom",
          "text": "More insights from my job search site: [https://jobswithgpt.com/blog/global\\_software-engineering\\_jobs\\_january\\_2026/](https://jobswithgpt.com/blog/global_software-engineering_jobs_january_2026/) lines up as I see python is top wanted skill.",
          "score": 1,
          "created_utc": "2026-01-20 04:52:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mdwf4",
          "author": "Deep_Negotiation_672",
          "text": "Those non techs who are targeting data science jobs directly or transitioning their careers into DS roles directly, they should go first with data analyst roles, get experience of atleast 2-3yrs in this role then try to switch into DA role.",
          "score": 1,
          "created_utc": "2026-01-20 06:03:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpz1b",
      "title": "Spent few days on case study only to get ghosted. Is it the market or just bad employer?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/",
      "author": "Lamp_Shade_Head",
      "created_utc": "2026-01-15 17:33:30",
      "score": 88,
      "num_comments": 28,
      "upvote_ratio": 0.91,
      "text": "I spent a few days working on a case study for a company and they completely ghosted me after I submitted it. It‚Äôs incredibly frustrating because I could have used that time for something more productive. With how bad the job market is, it feels like there‚Äôs no real choice but to go along with these ridiculous interview processes. The funniest part is that I didn‚Äôt even apply for the role. They reached out to me on LinkedIn.\n\nI‚Äôve decided that from now on I‚Äôm not doing case studies as part of interviews. Do any of you say no to case studies too?",
      "is_original_content": false,
      "link_flair_text": "Career | US",
      "permalink": "https://reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzrjj7j",
          "author": "avourakis",
          "text": "No matter the state of the market, ghosting a candidate after they had a call with you or invested any amount of time beyond just applying is a sign of a poorly mismanaged recruitment team. Sorry you had that experience.",
          "score": 95,
          "created_utc": "2026-01-15 17:39:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxhw6f",
              "author": "snmnky9490",
              "text": "That's just par for the course these days, especially lower level jobs",
              "score": 4,
              "created_utc": "2026-01-16 14:59:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrkxw3",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 141,
          "created_utc": "2026-01-15 17:45:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu4q11",
              "author": "RecognitionSignal425",
              "text": "That's why take home assignment should be done by AI. OP could just use time trying to reason and argument about the choice made by AI to sound reasonable.",
              "score": 13,
              "created_utc": "2026-01-16 01:08:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv0qm6",
                  "author": "ice-truck-drilla",
                  "text": "Valid use of AI. Take-homes are ridiculous. In my experience having a normal and respectful conversation with someone to discuss their experiences and the  job description is becoming antique.",
                  "score": 4,
                  "created_utc": "2026-01-16 04:10:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrnvqr",
              "author": "chandlerbing_stats",
              "text": "Which is funny cause AI probably atleast gets them close to an answer",
              "score": 3,
              "created_utc": "2026-01-15 17:58:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrnaxx",
          "author": "dlchira",
          "text": "\"The Market\" is absolutely never an excuse to do this to an applicant.",
          "score": 46,
          "created_utc": "2026-01-15 17:55:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzro5jy",
          "author": "2up1dn",
          "text": "I decided that if I don't get hired, that I'd put any such case studies on GitHub and on my blog. \n\nThat way it's not wasted time; it's an opportunity to showcase a quick project to another client or employer.",
          "score": 89,
          "created_utc": "2026-01-15 17:59:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrx3ga",
              "author": "kevliao1231",
              "text": "Also useful if the company steals your work",
              "score": 32,
              "created_utc": "2026-01-15 18:39:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs00h0",
              "author": "BeastModeKeeper",
              "text": "This is the way",
              "score": 21,
              "created_utc": "2026-01-15 18:52:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs586e",
              "author": "TheOneWhoSendsLetter",
              "text": " Never thought of that. Great tip.",
              "score": 15,
              "created_utc": "2026-01-15 19:15:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrv65j",
          "author": "and1984",
          "text": "which company was this so that we may all avoid it and shame them?  I am sorry for your experience.  That's horrible.",
          "score": 19,
          "created_utc": "2026-01-15 18:30:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrxle0",
          "author": "DubGrips",
          "text": "I was ghosted many times recently:\n\n* A large insurance company ghosted me during the offer negotiations. I had counter offered within their range (not aggressively either). I was working with an HR rep, who didn't show up for our negotiation call and then I got an email saying my application had been withdrawn. The Hiring Manager had no idea.\n* AirBnB ghosted me twice for 2 different positions with 2 different teams. I had been told that I had passed the round and then the recruiter stopped replying.\n* I was ghosted by Pinterest in September. Same thing: passed the technical screen, never heard back. Recruiter reached back out Monday of this week to schedule the next round.\n* Completed the entire process with Block. Recruiter was supposed to schedule a call with me and the Hiring Manager to discuss offer terms. Never got a call, never got an email response.\n\nIt's hard to not blame myself in some of these cases, like the insurance example since I did counter-offer them, but ghosting is a shitty practice and becoming all too common. I highly doubt any company is using code from a case study for themselves if they actually have existing Data Scientists. What's really happening is that the market is flooded with good candidates and they don't give a fuck about burning a bridge with you because someone just as good or possibly better will come along.",
          "score": 29,
          "created_utc": "2026-01-15 18:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs0hmq",
              "author": "Lamp_Shade_Head",
              "text": "Oh man that‚Äôs just terrible! I wouldn‚Äôt imagine companies like Airbnb or Block would ghost people. Did you end up finding a new job though? Also is it cool if I message you? I may have a block interview coming up.",
              "score": 3,
              "created_utc": "2026-01-15 18:54:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsbjjx",
                  "author": "DubGrips",
                  "text": "Yes I did! Senior Staff role, solid team, good company size, good product. Glad I held out honestly. Feel free to message me. Honestly, I cannot recommend Block. I have known a few former employees that all left due to rampant toxicity and poor WLB. I interviewed with them because my MO is to never turn anything down until the very end and see for myself. I had pretty bad vibes from the HM and a few others I interviewed with. I think my stats were:\n\n* 5 months total searching\n* 52 companies\n* 100% pass rate on technical screens\n* 100% pass rate on technical take home exams\n* I \"failed\" 5 HM screens, but quite frankly it would have never worked due to personality differences so that's fine.\n* A few ghostings randomly in the middle of rounds, so I will never know\n* 85% pass rate on presentations. I think the failures were my fault: I was either too verbose or too succinct for the given audience.\n* 14 offer rounds. 9 of those were \"we promoted someone from the inside\" or \"we had another candidate\". It was really upsetting to hear when it was due to another candidate and I have looked several of the companies up to see who they hired. In retrospect I am glad it didn't work out as they hired people who were more junior in experience, but prolific on spam posting on Medium and LinkedIn about their knowledge despite never having been in an actual role for longer than 2 years and never in a Senior or Staff role for more than 1.5. Their loss, not mine.\n* 5 quality offers. I passed on one due to insanely short relocation turnaround, another was too junior of a role and it did not align, and the other pass just a role that I honestly don't think I would have been happy in. The remaining 2 are the one I accepted and the one I mentioned above when I was ghosted.",
                  "score": 8,
                  "created_utc": "2026-01-15 19:44:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu4zax",
              "author": "RecognitionSignal425",
              "text": "> I highly doubt any company is using code from a case study for themselves if they actually have existing Data Scientists\n\nNot the code, but the aha moment from candidates' ideas (especially those with domain experience) can be a new Jira ticket for the team testing.",
              "score": 2,
              "created_utc": "2026-01-16 01:09:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrt7zm",
          "author": "volkoin",
          "text": "they are just absolute mfckers",
          "score": 9,
          "created_utc": "2026-01-15 18:22:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvekwe",
          "author": "AccordingWeight6019",
          "text": "This is unfortunately common, especially when case studies are used as a low-cost filter rather than a serious evaluation step. In many teams, the hiring process is not well owned, so candidates end up doing real work without anyone feeling responsible for closing the loop.\n\nSaying no to case studies is reasonable, but it depends on how they are framed. I am more comfortable when the scope is clearly time-boxed, discussed live, and obviously synthetic. If it looks like unpaid consulting or has unclear evaluation criteria, that is usually a signal about how the team treats candidates and, often, employees.\n\nThe market does amplify this behavior, but it is also a reflection of weak hiring discipline. In my experience, teams that value rigor tend to be more respectful of candidate time as well.",
          "score": 4,
          "created_utc": "2026-01-16 05:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztsve4",
          "author": "Accomplished-Eye-813",
          "text": "Definitely the employer. The market is trash right now, but that's still no excuse.",
          "score": 2,
          "created_utc": "2026-01-16 00:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuyrst",
          "author": "glowandgo_",
          "text": "I've seen more as a company quality signal than just the market. ghosting after unpaid work usually means either weak process or no real ownership on their side. the trade off people don‚Äôt mention is that case studies are often used when they dont know how else to evaluate, which is already a smell. i‚Äôve started pushing back unless there‚Äôs real context, timebox, and feedback baked in. interesting that they reached out first too, that makes it worse. saying no filters out some noise, even if it shrinks the funnel.,,,",
          "score": 2,
          "created_utc": "2026-01-16 03:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvewqt",
          "author": "patternpeeker",
          "text": "That frustration is very justified. Case studies can be reasonable when they are tightly scoped and followed by real feedback, but in practice they often turn into free labor or a filtering step no one bothers to close the loop on. A lot of companies also underestimate how much time they are asking for, especially when they initiate the outreach. I have started pushing back by asking for time limits, context on how it is evaluated, and whether there will be a live discussion afterward. If they cannot answer that, it is usually a signal about how they treat candidates more generally.",
          "score": 2,
          "created_utc": "2026-01-16 05:46:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvfx2m",
          "author": "thinking_byte",
          "text": "Ghosting after a multi day case study is just bad behavior, market or not. Reaching out to you and then disappearing makes it worse. I have seen more people push back lately, either asking for a smaller scoped exercise or a live working session instead. It is usually a decent signal anyway, teams that respect your time tend to show it early. Saying no filters out some opportunities, but it also filters out a lot of nonsense.",
          "score": 2,
          "created_utc": "2026-01-16 05:53:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwemue",
          "author": "dataflow_mapper",
          "text": "That sucks, and you are not overreacting. Being ghosted after unpaid work is a bad look regardless of the market, especially when they reached out to you first. A lot of teams use case studies as a lazy filter and then fail at basic follow up. Saying no is reasonable, or at least setting boundaries like time boxing it or asking for a live walkthrough instead. The market is rough, but that does not mean you have to accept disrespect as the price of entry.",
          "score": 2,
          "created_utc": "2026-01-16 10:58:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxtgcl",
          "author": "Double-Count-7545",
          "text": "They got free work from you üòû",
          "score": 2,
          "created_utc": "2026-01-16 15:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzbnos",
          "author": "jingle-bell-dog",
          "text": "Even if the markets bad, seems like this company‚Äôs respect of people‚Äôs time and culture is lacking, you might have dodged a bullet. Or as others said they want free labor",
          "score": 1,
          "created_utc": "2026-01-16 19:53:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbx8bd",
      "title": "There are several odd things in this analysis.",
      "subreddit": "datascience",
      "url": "https://i.redd.it/cydd3klvf5dg1.png",
      "author": "Ale_Campoy",
      "created_utc": "2026-01-13 17:24:54",
      "score": 55,
      "num_comments": 23,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Analysis",
      "permalink": "https://reddit.com/r/datascience/comments/1qbx8bd/there_are_several_odd_things_in_this_analysis/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzdvnud",
          "author": "Dorkbot1",
          "text": "Just by eye balling it, it looks like the red curve is fit to the blue data and the blue curve is fit to the combined red and blue data sets. But also this feels like what hypothesis testing is for, so they probably should just do that and skip this figure",
          "score": 71,
          "created_utc": "2026-01-13 17:32:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzecr9g",
              "author": "Ale_Campoy",
              "text": "I also have guessed that. But even changing that, how is it that the pvalue is so small. I would never be so certain that the 2 distributions are so different right?",
              "score": 3,
              "created_utc": "2026-01-13 18:48:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzeieuf",
                  "author": "f4k3pl4stic",
                  "text": "Depends on the sample size. Those are overlapping g but different distributions. I can easily see the means being different",
                  "score": 21,
                  "created_utc": "2026-01-13 19:14:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nziwkqn",
                  "author": "seesplease",
                  "text": "Because of pseudoreplication. They're likely counting cells from the same patient as independent, which is not true but unfortunately common in biology. See this manuscript: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010061",
                  "score": 3,
                  "created_utc": "2026-01-14 11:58:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhxbls",
                  "author": "schokoyoko",
                  "text": "statistical test may not have been carried out on log transformed data.",
                  "score": 1,
                  "created_utc": "2026-01-14 06:39:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzpbaz8",
              "author": "Monkey_College",
              "text": "They would probably still use the wrong data in hypothesis testing. Might even be worse and claim \"statistical significance according to 0.05\" and invalidate all their claims.",
              "score": 1,
              "created_utc": "2026-01-15 09:54:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzdvirx",
          "author": "Iron_Naz",
          "text": "My guess is that they've simply applied a kernel density estimation on the data which does not match the histograms. Most likely because the data is skewed and not symmetrical",
          "score": 14,
          "created_utc": "2026-01-13 17:31:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nze4fog",
          "author": "rihd",
          "text": "Yeah something funny going on!\n\nlog10(.179) is around -.747, log10(.388) \\~= -.4. \n\nSo the reported values match the *fitted* curves. But the fitted curves don't match the histograms - as another commenter said, it looks like the means were swapped across groups, but not the variance",
          "score": 13,
          "created_utc": "2026-01-13 18:12:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzheguw",
          "author": "ararelitus",
          "text": "Putting aside curve-fitting issues, I would be concerned that they have ignored potential cell- and subject-level random effects. I don't see any information on the statistical test, but it seems like such a small p-value could only be obtained assuming independence between all measurements.",
          "score": 3,
          "created_utc": "2026-01-14 04:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nze1wfq",
          "author": "Adorable-Emotion4320",
          "text": "I wonder if they first estimated it, and when plotting made a mistake. The mean of the blue distribution seems to plotted with the red curve, but using the standard deviation of the blue distribution¬†",
          "score": 2,
          "created_utc": "2026-01-13 18:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzeddx8",
              "author": "Ale_Campoy",
              "text": "But even then, the curve should be at least closer to the bars for a good fitting.",
              "score": 2,
              "created_utc": "2026-01-13 18:51:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzh9d4l",
          "author": "Complete_Dud",
          "text": "I wonder if that blue bit of mass at -2.25 doesn‚Äôt shift the blue fitted curve left. Clearly, the blue histogram is not from a Gaussian distribution and it seems they are forcing in a Gaussian curve, so‚Ä¶",
          "score": 2,
          "created_utc": "2026-01-14 03:44:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhzvo0",
          "author": "Ghost-Rider_117",
          "text": "yeah something seems off with the curve fitting here. if you're comparing two populations that should be distinct, forcing them into normal distributions might be hiding the actual biological variation. might be worth trying a non-parametric test or at least checking the residuals to see if normal is even appropriate. also that p-value being so tiny makes me wonder about sample size issues or if there's batch effects in play",
          "score": 2,
          "created_utc": "2026-01-14 07:01:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi7j57",
          "author": "reddit_wisd0m",
          "text": "The underlying question is whether a statistically significant difference exists between these 2 populations, thereby allowing for the rejection of the null hypothesis, which I strongly doubt is feasible. Regrettably, this information is not included in the caption.",
          "score": 2,
          "created_utc": "2026-01-14 08:11:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj7o0s",
          "author": "thefringthing",
          "text": "Did they publish the data? Can you request it from the authors?",
          "score": 2,
          "created_utc": "2026-01-14 13:14:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03vmxd",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 1,
          "created_utc": "2026-01-17 14:12:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdwrce",
          "author": "AffectionateMotor724",
          "text": "The graph definitely looks weird, but I do not get your points of the means being misleading. \n\nBased on the plot, the mean of the red curve IS higher than the mean of the blue curve since its center point is more to the right. The altitude of the plot is just showing the population concentration around the mean.",
          "score": -2,
          "created_utc": "2026-01-13 17:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze59e8",
              "author": "Deto",
              "text": "Based on the curves, but based on the bars, the red-group's mean should really be lower.",
              "score": 5,
              "created_utc": "2026-01-13 18:15:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzegpm3",
                  "author": "AffectionateMotor724",
                  "text": "I really saw the colors the other way around.\n\nLong day today.",
                  "score": 1,
                  "created_utc": "2026-01-13 19:06:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qflxse",
      "title": "How the Kronecker product helped me get to benchmark performance.",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/",
      "author": "vercig09",
      "created_utc": "2026-01-17 19:10:03",
      "score": 46,
      "num_comments": 18,
      "upvote_ratio": 0.88,
      "text": "Hi everyone,\n\n  \nRecently had a common problem, where I had to improve the speed of my code 5x, to get to benchmark performance needed for production level code in my company.\n\nLong story short, OCR model scans a document and the goal is to identify which file from the folder with 100,000 files the scan is referring to.\n\n  \nI used a bag-of-words approach, where 100,000 files were encoded as a sparse matrix using scipy. To prepare the matrix, CountVectorizer from scikit-learn was used, so I ended up with a 100,000 x 60,000 sparse matrix. \n\nTo evaluate the number of shared words between the OCR results, and all files, there is a \"minimum\" method implemented, which performs element-wise minimum operation on matrices of the same shape. To use it, I had to convert the 1-dimensional vector encoding the word count in the new scan, to a huge matrix consisting of the same row 100,000 times.\n\nOne way to do it is to use the \"vstack\" from Scipy, but this turned out to be the bottleneck when I profiled the script. Got the feedback from the main engineer that it has to be below 100ms, and I was stuck at 250ms. \n\nLong story short, there is another way of creating a \"large\" sparse matrix with one row repeated, and that is to use the [kron](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.kron.html#scipy.sparse.kron) method (stands for \"Kronecker product\"). After implementing, inference time got cut to 80ms. \n\n  \nOf course, I left a lot of the details out because it would be too long, but the point is that a somewhat obscure fact from mathematics (I knew about the Kronecker product) got me the biggest performance boost.\n\nA.I. was pretty useful, but on its own wasn't enough to get me down below 100ms, had to do old style programming!!\n\n  \nAnyway, thanks for reading. I posted this because first I wanted to ask for help how to improve performance, but I saw that the rules don't allow for that. So instead, I'm writing about a neat solution that I found. ",
      "is_original_content": false,
      "link_flair_text": "Coding",
      "permalink": "https://reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o09442e",
          "author": "AccordingWeight6019",
          "text": "this is a nice example of where understanding the underlying linear algebra and sparse representations pays off more than tuning at the surface level. a lot of performance issues in applied ML end up being data movement problems rather than model problems, and vstacking that many rows is a classic trap. using a Kronecker construction to express repetition without materializing it is a good illustration of thinking in operators instead of arrays. I also like that this came out of profiling rather than guessing. In production settings, that mindset often matters more than any single trick.",
          "score": 9,
          "created_utc": "2026-01-18 07:06:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0amtzv",
              "author": "vercig09",
              "text": "thanks for the feedback :)\n\nto be honest, I started writing a prompt asking AI where it sees improvements in code, and immediately realized how silly that was, and just used the cProfile, figured out pretty quickly where I should focus on :)",
              "score": 2,
              "created_utc": "2026-01-18 14:30:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0fhxhe",
                  "author": "AccordingWeight6019",
                  "text": "Exactly, profiling first is always the way to go. It is easy to get distracted chasing smarter algorithms when the bottleneck is really in data layout or memory movement. Sparse representations and knowing which operations are cheap versus expensive can make all the difference, and Kronecker products are a neat example of that.",
                  "score": 1,
                  "created_utc": "2026-01-19 05:48:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09oczz",
          "author": "patternpeeker",
          "text": "Nice writeup. This is a good example of the hard part not being the model, but how you move data around at scale. In practice, a lot of ML code misses benchmarks because of exactly this kind of hidden allocation or replication step. I have seen similar wins from avoiding explicit expansion and letting linear algebra do the work implicitly. It also highlights why profiling matters more than clever modeling once you are in production. Out of curiosity, did you consider alternatives like inverted indices or pruning before the comparison, or was the latency budget tight enough that you needed to stay fully vectorized?",
          "score": 3,
          "created_utc": "2026-01-18 10:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b9dil",
              "author": "vercig09",
              "text": "Thanks for the response. This was my first iteration, still have some ideas to explore. For example, this is a classic example of a task which can be processed in parallel, because comparisons are independent of one another, so I really want to see what impact parallel computation will have.\n\nInverted indices might also be an interesting approach, thanks for the idea :) \n\nDidn't want to prune yet, because I didn't have issues with memory and didn't want to lose information",
              "score": 1,
              "created_utc": "2026-01-18 16:23:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0902e3",
          "author": "Zahlii",
          "text": "Why not do something like \ncv = CountVectorizer(binary=True)\nx_docs = cv.fit_transform() # N Docs x Words\nx_ocr = cv.transform() # 1 x Words\nsim = x_ocr.dot(x_docs.T) # 1 x N Docs\n\nOn binary data the dot will evaluate to # Words common between ocr and each doc vector?",
          "score": 2,
          "created_utc": "2026-01-18 06:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ant8g",
              "author": "vercig09",
              "text": "very interesting, thanks for sharing. With the dot product, I was worried that it wouldn't be able to handle \"multiplicity\" (how many times each word appears). In other words, I was worried it would either:\n\n1. just count how many INDIVIDUAL words are shared (word either appears in both documents, or not), so 1 or 0 for each word,\n\n2. it would overcount how may times the word appears. For example, if \"banana\" appears in the OCR 3 times, and in the original document 3 times, I thought the dot product would give 9.\n\nLooking at the documentation for \"CountVectorizer\", this is written for the \"binary\" parameter:  \n  \n\"**binary** bool, default=False\n\nIf True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.\"\n\nSo, I'm worried about the #1 case, but I'll explore in more detail",
              "score": 1,
              "created_utc": "2026-01-18 14:35:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0aw1im",
                  "author": "Zahlii",
                  "text": "I think the ‚Äûovercount‚Äú can be solved by using e.g TfIdf or using l2 norm - this way similarities are guaranteed to be in [-1,1], and with tfidf you also get a weighting on more specialized tokens",
                  "score": 2,
                  "created_utc": "2026-01-18 15:19:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zzq1",
          "author": "glowandgo_",
          "text": "this is a good example of where the real win comes from understanding the underlying ops, not just swapping libs. the kron trick makes sense once you think about how sparse structure is represented, but it‚Äôs not something most people reach for by default. in my experience, perf issues at this scale are almost always about avoiding materialization rather than making one function faster. also appreciate the point about ai tools, they help explore options, but they rarely have the context to spot these mathy shortcuts. nice writeup, this kind of detail is way more useful than generic ‚Äúoptimize your code‚Äù advice.,,,",
          "score": 2,
          "created_utc": "2026-01-18 11:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0boery",
              "author": "vercig09",
              "text": "thanks for reading :)",
              "score": 1,
              "created_utc": "2026-01-18 17:35:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a7px3",
          "author": "and1984",
          "text": "This is excellent info.  Are you able to shed light on how AI was useful but old-school coding came to the rescue?",
          "score": 2,
          "created_utc": "2026-01-18 12:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b2yxs",
              "author": "vercig09",
              "text": "Thank you :)\n\nI use Github Copilot which makes me much faster at writing code. I never accept suggestions with more than 2 lines, because 2 lines is my limit for what I can check quickly for accuracy. Once I developed the initial method, AI helped me get the inference time from 2 seconds to roughly 0.5s, but then it started going into circles, either suggesting things that don't work or stuff that doesn't impact the execution time.\n\n  \nSince I had to get down to 100ms, I decided to drop my initial approach, which was basically a \"for\" loop (comparing the generated text with each record from DB individually), and to try vectorization/matrix operations.\n\n  \nI knew about scikit-learn, so I was reading the documentation until I stumbled upon [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#countvectorizer), which can encode all DB records into a single sparse matrix. Key calculation was finding the number of shared words between the scanned document and each record in the database, which can easily be done with the [minimum](https://docs.scipy.org/doc/scipy-1.16.2/reference/generated/scipy.sparse.csr_matrix.minimum.html) function. The only thing missing was how to quickly run this function, because it requires two matrices of the same shape, but the OCR results is only a 1-dimensional sparse matrix. In order to generate a large matrix, AI suggested [vstack](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.vstack.html), which worked and got me down to roughly 250ms, without impacting accuracy. I ran the cProfile profiler on my script, and noticed that the vstack took the most time to execute, so I needed to cut it down. I was thinking about how to construct a large matrix where 1 row is repeated a number of times, reading scipy.sparse docs, looking for another option, and was very happy to see that the Kronecker product was implemented: [LINK](https://docs.scipy.org/doc/scipy-1.16.2/reference/generated/scipy.sparse.kron.html).\n\n  \nOverall, AI was pretty good, and it might have done more with better prompting, but I needed a significant change in approach, and I felt like I was just going in circles with AI, so had to rely on my own neural network",
              "score": 1,
              "created_utc": "2026-01-18 15:53:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bemt4",
          "author": "yaksnowball",
          "text": "Embed the content of the files with a sentence transformer, store the resulting embeddings in an index e.g using FAISS and do ANN retrieval to get the most similar files to the new OCR scan. It will be almost instant if you are just searching with 1 document. I guarantee less than 10ms easily.\n\nSparse lexical retrieval is very inconvenient for large amounts of documents hence why people have traditionally resorted to things like ElasticSearch or Apache SOLR to do this type of thing.",
          "score": 2,
          "created_utc": "2026-01-18 16:48:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bod84",
              "author": "vercig09",
              "text": "fair, thanks for the suggestion. wanted to first try this because some documents contain unique IDs, which can help immensely to determine the right card (but not every document has an ID as part of its contents), and I thought that this information would be lost in embedding (what would JFDOSDFF9358K be similar to).\n\nI definitely want to test embeddings, but first want to set the best \"time to beat\". I'm still counting on improvements from parallel computing",
              "score": 1,
              "created_utc": "2026-01-18 17:34:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kq6be",
          "author": "Dizzy-Midnight-6929",
          "text": "Thanks for sharing! Love these performance tricks",
          "score": 2,
          "created_utc": "2026-01-20 00:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bwjc7",
          "author": "Helpful_ruben",
          "text": "Error generating reply.",
          "score": 1,
          "created_utc": "2026-01-18 18:12:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09ichl",
          "author": "nian2326076",
          "text": "I‚Äôve seen a lot of confusion and outdated info around Meta‚Äôs Data Scientist (Analytics) interview process, so I put together a practical, up-to-date playbook based on real candidate experiences and prep patterns that actually worked.",
          "score": -3,
          "created_utc": "2026-01-18 09:15:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbtoyf",
      "title": "Looking for advice on switching domain/industry",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qbtoyf/looking_for_advice_on_switching_domainindustry/",
      "author": "BlueSubaruCrew",
      "created_utc": "2026-01-13 15:05:52",
      "score": 37,
      "num_comments": 30,
      "upvote_ratio": 0.93,
      "text": "Hello everyone, I am currently a data scientist with 4.5 yoe and work in aerospace/defense in the DC area. I am about to finish the Georgia tech OMSCS program and am going to start looking for new positions relatively soon. I would like to find something outside of defense. However, given how often I see domain and industry knowledge heralded as this all important thing in posts here, I am under the impression that switching to a different industry or domain in DS is quite difficult. This is likely especially true in my case as going from government/contracting to the private sector is likely harder than the other way around.\n\n\nAs far as technical skills, I feel pretty confident in the standard python DS stack (numpy/pandas/matplotlib) as well as some of the ML/DL libraries (XGBoost/PyTorch) as I use them at work regularly. I also use SQL and other certain other things that come up on job ads such as git, Linux, and Apache Airflow. The main technical gap I feel that I have is that I don‚Äôt use cloud at all for my job but I am currently studying for one of the AWS certification exams so that should hopefully help at least a little bit. There are a couple other things here and there I should probably brush up on such as Spark and Docker/kubernetes but I do have basic knowledge of those things.\n\nI would be grateful if anyone here had any tips on what I can do to improve my chances at positions in different industries. The only thing I could think of off the bat is to think of an industry or domain I am interested in and try to do a project related to that industry so I could put it on my resume. I would probably prefer something in banking/finance or economics but am open to other areas.",
      "is_original_content": false,
      "link_flair_text": "Career | US",
      "permalink": "https://reddit.com/r/datascience/comments/1qbtoyf/looking_for_advice_on_switching_domainindustry/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzdj9dj",
          "author": "mikethomas4th",
          "text": "I have worked for 5 different companies in the past 12 years and all 5 were in completely different industries.\n\nYou don't need to do anything special. You need to pitch your experience in the context of the industry you are applying for. Talk about the similarities not the differences. If *they* bring up the differences, pitch it as a positive, that you have unique experience that no other candidate can offer.",
          "score": 17,
          "created_utc": "2026-01-13 16:23:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdmdsp",
              "author": "exdlunatic",
              "text": "Could you share more about ways you figure out how to pitch your experience in the context of a new industry? I find that quite challenging for my lack of knowledge of the industry, and would appreciate some pointers!",
              "score": 3,
              "created_utc": "2026-01-13 16:37:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzdsitv",
                  "author": "mikethomas4th",
                  "text": "You're going to need to do some research ahead of that interview. You can't just walk in and say \"I don't know anything about this entire field\". \n\nAI & Google are your friends. Ask ChatGPT \"what are the major KPI's in X industry\". \"What systems are typically used in X Industry\". \"Compare X Industry to Defense from a data perspective.\" spend some time on it and it will pay off when you can talk confidently.",
                  "score": 4,
                  "created_utc": "2026-01-13 17:17:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzdwiw5",
              "author": "BlueSubaruCrew",
              "text": "That is reassuring. Of those 5, were any in industries you'd recommend avoiding?",
              "score": 2,
              "created_utc": "2026-01-13 17:36:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nze2mjs",
                  "author": "mikethomas4th",
                  "text": "Not really, but industry determines work culture a lot I've found. So it depends what you like.",
                  "score": 1,
                  "created_utc": "2026-01-13 18:04:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzg0b2e",
              "author": "EJHllz",
              "text": "How have you handled the initial onboarding of each of the different industries? I‚Äôve done a similar thing but I always find the first few months quite challenging",
              "score": 1,
              "created_utc": "2026-01-13 23:31:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzg2q4w",
                  "author": "mikethomas4th",
                  "text": "First few months are challenging at any new job. Its just part of the deal. It can take a full 6 months to a year to truly feel comfortable anywhere.",
                  "score": 1,
                  "created_utc": "2026-01-13 23:44:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzdba9y",
          "author": "kater543",
          "text": "Domain knowledge only takes you that last mile, most companies don‚Äôt see it as a major barrier. The key thing will be if your projects are spoken about in a way that can potentially apply to their use cases, your stack matches their stack(like 60-80%), and they like you. \n\nTesting for domain knowledge specifics means they are targeting for a certain type of DS that you wouldn‚Äôt fit anyway without experience in the industry. You won‚Äôt find out which positions those are until you‚Äôre deep in the interview, but that‚Äôs just luck.  Vast majority of situations that won‚Äôt be a problem you have to deal with.",
          "score": 9,
          "created_utc": "2026-01-13 15:47:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd4e83",
          "author": "newrockstyle",
          "text": "I would suggest you to try your hands on doing a small project in your target industry, highlighting transferable skills and learning key tools like cloud/spark to ease the switch.",
          "score": 6,
          "created_utc": "2026-01-13 15:14:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdszzw",
              "author": "BlueSubaruCrew",
              "text": "That's kind of what I was thinking. Hardest part I guess would be finding a decent dataset of way of obtaining data to do something non-trivial. I don't want to do the regular \"find some static dataset, do EDA in jupyter notebook, fit XGBoost and call it a day\" type project that seems very common and probably does more harm than good.",
              "score": 6,
              "created_utc": "2026-01-13 17:19:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzdpj33",
          "author": "Equal-Agency4623",
          "text": "Domain experience is not a significant factor when switching to mid-level or below roles. But for senior+ levels, it is the most important factor because you‚Äôll be expected to lead mid and junior level scientists. \n\nAt 4.5 years of experience, you‚Äôre in the mid-level range (Senior is 6 years of experience). I‚Äôd recommend the following steps:\n\n- Identify your target domain. Your target domain could be a science domain like recsys or dynamic pricing. It could also be a business domain like marketing or operations\n\n- Do one project (not more than one) that tackles a common problem in your target domain. Build a good GitHub repo for this project and use the readme section to explain this project in detail using the STAR format. Your hiring managers may not read your GitHub before the interview, but doing this will give you sufficient knowledge to explain this project in the interview when assessed for science depth\n\n- Decide whether you want to be DS or MLE/AS. If you want to be MLE/AS, do Leetcode and be comfortable with it. Also, practice ML design",
          "score": 3,
          "created_utc": "2026-01-13 16:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze7zzj",
              "author": "BlueSubaruCrew",
              "text": "In your third bullet point, what is AS?",
              "score": 1,
              "created_utc": "2026-01-13 18:27:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzevgc8",
                  "author": "Equal-Agency4623",
                  "text": "Applied Scientist. That is the title some companies call their ML Engineers/ML Scientists",
                  "score": 1,
                  "created_utc": "2026-01-13 20:13:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzd4yjz",
          "author": "Careful-Review4207",
          "text": "Switching domains is easier than it looks. Domain knowledge helps, but it‚Äôs rarely the deal-breaker. Most teams hire you for how you think and build, not because you already know their business inside out.\n\nI‚Äôve switched domains myself, and what mattered wasn‚Äôt the industry label, it was showing I could deliver end-to-end work. Once recruiters saw real projects and outcomes, the ‚Äúbut you‚Äôre from X industry‚Äù concern faded fast.\n\nThink of domain like learning traffic rules in a new country. You already know how to drive. You just need a short adjustment period, not a new license.\n\nWhat helped me was framing my experience clearly in one place so people focused on skills, not background. A simple portfolio that tells your story makes this much easier, something like this: [https://saramitchell.professionalsite.me/](https://saramitchell.professionalsite.me/)\n\nFunny truth: companies say ‚Äúdomain knowledge is critical,‚Äù then happily hire someone who learns it in 90 days.\n\nIf you add one finance-related project and a bit of cloud exposure, you‚Äôre already qualified enough to make the jump.",
          "score": 5,
          "created_utc": "2026-01-13 15:17:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd9lxz",
              "author": "ExoSpectra",
              "text": "while this is a good comment substantively, not sure why you needed to run through an LLM before posting? just undermines the credibility",
              "score": 2,
              "created_utc": "2026-01-13 15:39:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzde025",
                  "author": "ArabSays",
                  "text": "Based on their past comments and account activity, they seem to be a content creator with streaks of LLM comments",
                  "score": 2,
                  "created_utc": "2026-01-13 15:59:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhvpk2",
                  "author": "mezzpezz",
                  "text": "How could you tell?",
                  "score": 1,
                  "created_utc": "2026-01-14 06:25:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzdtfc7",
              "author": "BlueSubaruCrew",
              "text": "I've thought about that last part a few times. If someone is capable of learning all the technical stuff I feel like they should be capable of picking up the industry knowledge relatively quickly. Although it's obviously preferable to choose someone who already knows it.",
              "score": 1,
              "created_utc": "2026-01-13 17:21:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzio97o",
          "author": "AccordingWeight6019",
          "text": "The domain knowledge thing gets overstated a bit, especially once you are past junior level. In practice, most teams care whether you can take a messy problem, make reasonable assumptions, and ship something that holds up in production. Coming from defense can be a harder narrative sell, but it helps to frame your work in terms of decision impact, constraints, and iteration rather than the domain itself. Private sector interviews often probe how you handle ambiguity and trade-offs more than whether you know the industry already. Small, targeted projects can help, but only if they mirror how the work actually gets used, not just a polished notebook. I would also pay attention to how teams talk about experimentation and deployment, since that usually signals whether your background will translate cleanly.",
          "score": 1,
          "created_utc": "2026-01-14 10:50:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziw35m",
          "author": "dataflow_mapper",
          "text": "Switching domains is usually easier than it looks on this sub. Domain knowledge matters, but it is rarely the gating factor people make it out to be, especially once you are past the junior stage.\n\nWhat tends to transfer well is problem framing, modeling judgment, and the ability to explain tradeoffs to non technical stakeholders. Those skills show up in every industry. Defense to private sector is less about relearning math and more about adapting to different incentives, timelines, and risk tolerance.\n\nTargeted projects can help, but I would not over index on them. Hiring managers usually care more about whether you have taken messy problems to production and owned outcomes. If you can translate your experience in those terms and show curiosity about the new domain, most teams are willing to teach you the rest.",
          "score": 1,
          "created_utc": "2026-01-14 11:55:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlw9dy",
          "author": "e-cosmic",
          "text": "Why change ? Spacex about to reverse merge into Tsla. You be making bank if you know how to position yourseld",
          "score": 1,
          "created_utc": "2026-01-14 20:49:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoaild",
          "author": "skeerp",
          "text": "I did the same transition. You have a lot skills dont sell yourself short. I assume you have solved a lot of different, compels problems being a contractor. You are more competitive than someone who got a shit boring analyst job that made 2 dashboards in a year. \n\nItll take a lot of applications, but everything does now with the bots and spam on every job board. Hang in there.",
          "score": 1,
          "created_utc": "2026-01-15 04:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0aa5iw",
          "author": "bvallieres",
          "text": "Agree domain is important but not a deal breaker. I‚Äôm hiring for a role in pharma but honestly prioritizing DS skills first. Anyone interested DM please‚Ä¶",
          "score": 1,
          "created_utc": "2026-01-18 13:14:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0aadi9",
          "author": "NeedleworkerIcy4293",
          "text": "\nDomain switching isn‚Äôt about knowing the industry already ‚Äî it‚Äôs about showing you can learn fast and apply patterns. Your DS stack is strong, and AWS + a couple applied projects will close most gaps.\n\nIf you‚Äôre serious about banking/finance, fwiw I‚Äôve got VP-level folks (20+ years) in banking and finance in my network who‚Äôve helped people make this exact move. They know what hiring managers actually look for beyond buzzwords.\n\nIf you want, DM me ‚Äî happy to connect you or guide you on how to build industry-grade projects that actually resonate with finance teams.",
          "score": 1,
          "created_utc": "2026-01-18 13:15:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzd58b8",
          "author": "forbiscuit",
          "text": "It‚Äôs not much about technical, rather its lack of domain experience in other industries.\n\nWe‚Äôre a Consumer/customer facing firm, and we had some good interviews with people from aerospace/defense (polymers/materials/drone tech), but they‚Äôve always flopped on product sense/customer sense interviews.\n\nWe‚Äôve routed most of them to more operational analytics or hardware QA analytics because they really had a good grasp of signals/mechanical/material science knowledge. And not surprising most employees I know from ex-defense are in supply chain, ops or AIML research.\n\nTLDR: Draw on your domain expertise to target roles in other industries that are closest to your current domain knowledge. Let your current domain expertise serve as an ‚Äúin‚Äù to that industry.",
          "score": 0,
          "created_utc": "2026-01-13 15:18:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzd6790",
              "author": "forbiscuit",
              "text": "In this job market, with the current state of competition, banking and finance will be an uphill battle for you unless you‚Äôre ok with downleveling. \n\nThat domain has had a history of very standard hiring practice of hiring from MBA target schools or hiring from other baking/finance sectors because the candidates are aware of everything behind the scenes for banking/finance from regulations, fraud, sensitive data, etc. Not to mention knowing to speak the same language as other financiers given their background when talking about different assets and what the mechanics of each then are.",
              "score": 0,
              "created_utc": "2026-01-13 15:23:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qd7eq3",
      "title": "Google DS interview",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qd7eq3/google_ds_interview/",
      "author": "No-Mud4063",
      "created_utc": "2026-01-15 02:34:52",
      "score": 27,
      "num_comments": 33,
      "upvote_ratio": 0.71,
      "text": "Have a Google Sr. DS interview coming up in a month. Has anyone taken it? tips?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qd7eq3/google_ds_interview/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzo6p6x",
          "author": "snowbirdnerd",
          "text": "I interviewed for a senior position with them 3 or 4 years ago. Studied for a couple of months, spent over a month interviewing with them. Was essentially promised the position and then next thing I heard was that the position has been terminated and they were no longer hiring for it.\n\n\nHopefully your experience goes better.¬†",
          "score": 75,
          "created_utc": "2026-01-15 04:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr8dhc",
              "author": "No-Mud4063",
              "text": "That sucks. Google seems like a good place to work with a good wlb",
              "score": 10,
              "created_utc": "2026-01-15 16:48:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0e3fv9",
              "author": "AdMysterious4157",
              "text": "That‚Äôs¬†really¬†unfortunate¬†‚Äî¬†I¬†didn‚Äôt¬†realize¬†this¬†happens¬†at¬†Google¬†too.",
              "score": 2,
              "created_utc": "2026-01-19 00:45:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs439f",
              "author": "Bloodrazor",
              "text": "Similar thing happened to me.  I had a referral and had interviews scheduled but then was told that there were 2 internal candidates that have moved far into the hiring process.  The recruiter then told me there was another opening at the same level that would be out in the next week.  After I followed up, they moved forward with a junior internal candidate.",
              "score": 1,
              "created_utc": "2026-01-15 19:10:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzofup9",
              "author": "timusw",
              "text": "What‚Äôd you prepare for? How‚Äôd you do it? What types of coding and technical questions did they ask",
              "score": 1,
              "created_utc": "2026-01-15 05:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzorlba",
                  "author": "snowbirdnerd",
                  "text": "What you need to study will depend on what part of the company you will be joining. I think the position I was applying for was something like loyalty economist. It was a statistics and experiment design heavy position which is essentially what I studied for my masters.¬†\n\n\nI brushed up on my general skills like SQL, Python, and Machine Learning, and then a deep dive into DOE.¬†\n\n\nThe first couple of interviews were essentially coding tests using Google Docs. They wanted to see how well you knew syntax from memory.¬†One interview was just about performing A/B testing and some basic DOE concepts.¬†\n\n\nTheir also was a case study where I had to talk through how to workout the problems with an existing system and what experiments I would run to determine the root cause.¬†\n\n\nAfter that it was just some culture and get to know people interviews.¬†\n\n\nI was pretty excited when they told me to expect an offer letter and crushed when I received the notification about the position being terminated.¬†\n\n\nThat was the last time I ever considered interviewing for a FAANG.¬†",
                  "score": 28,
                  "created_utc": "2026-01-15 06:49:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzocz79",
          "author": "KitchenTaste7229",
          "text": "Been some time since I took it, but I recall the SQL and Python questions being pretty standard (I'd say around medium-difficulty?). The behavioral questions were a bit tough ‚Äì but that's probably because I didn't invest more time into preparing for them, so make sure your prep's balanced. Also, my biggest struggle was the machine learning/applied modeling round; I didn't get enough practice whiteboarding & I may have missed being clear about trade-offs and constraints. Make sure to brush up on common [Google interview questions](https://www.interviewquery.com/interview-guides/google-data-scientist) for product sense/cases too, good luck!",
          "score": 19,
          "created_utc": "2026-01-15 04:54:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqhdme",
          "author": "citoboolin",
          "text": "research or product DS? If product, expect mostly SQL questions, if research, some python for sure. Then your standard data/ML fundamentals/statistics questions. I have only interviewed for a junior position though",
          "score": 13,
          "created_utc": "2026-01-15 14:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00s8ri",
              "author": "FinalRide7181",
              "text": "Not OP, i have just a quick question: do you need a phd for DS research or a pure master in math? I mean is master in cs (ml/dl/stats exams) and previous experience as data scientist enough?",
              "score": 1,
              "created_utc": "2026-01-17 00:16:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00vca7",
                  "author": "citoboolin",
                  "text": "everyone ive met that is ds research had a phd. from job postings ive seen they do make exceptions but you probably need a decent publication record and/or start as ds product and do an internal transfer or something",
                  "score": 1,
                  "created_utc": "2026-01-17 00:34:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzr8808",
              "author": "No-Mud4063",
              "text": "Research",
              "score": 1,
              "created_utc": "2026-01-15 16:48:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvuo5l",
          "author": "neo2551",
          "text": "For research:¬†\n\n- Python, nothing crazy but the trick is you have to code without any IDE help. Typical, map, filter, reduce operations with standard data structure (dicts, list, tuple, set).\n- Statistics: please, master stats 101, like seriously, the interview is a mixture of university exam question and how you would solve a real problem. The real challenge is about which topic you will get, ask for your HR contact to narrow down what you should know.\n\nSource: I went (successfully) through both product and research interview processes.",
          "score": 12,
          "created_utc": "2026-01-16 07:56:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00s84v",
              "author": "FinalRide7181",
              "text": "Not OP, i have just a quick question: do you need a phd for DS research or a pure master in math? I mean is master in cs (ml/dl/stats exams) and previous experience as data scientist enough?",
              "score": 1,
              "created_utc": "2026-01-17 00:16:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o02ck4b",
                  "author": "neo2551",
                  "text": "The only way to know is to interview: as I said, it is a fairly academic process with transparent content.\n\nReally my best advice is to master the basics of statistics and fundamentals. This might not give you the job, but for sure is a necessary condition.\n\nI know many DS researcher who had a political science and economics degree, in the end, Google decides who to hire based on interview performance, not degrees.\n\nThe trick is to get in the interview pipeline first.",
                  "score": 2,
                  "created_utc": "2026-01-17 06:37:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzshm3e",
          "author": "akornato",
          "text": "They'll push you hard on SQL and coding (expect LeetCode medium problems at minimum), statistical fundamentals, product sense, and your ability to design experiments and measurement frameworks. The bar is legitimately high, and you'll need to be sharp on all fronts. That said, a month is actually plenty of time to prepare if you're strategic about it. Focus on practicing common [Google data science interview questions](https://www.interviews.chat/questions/google-data-scientist) that cover A/B testing scenarios, metric design, and how you'd approach ambiguous business problems. Get comfortable explaining your thought process out loud since they care as much about how you think as what you know.\n\nThe good news is that Google's interview structure is fairly predictable, and there's tons of information available from others who've been through it. You should be drilling SQL queries daily, revisiting probability and statistics fundamentals, and doing mock interviews where you talk through case studies. The product sense rounds can feel intimidating, but they're really just testing if you can think like a data scientist who partners with product teams - how would you measure success for a feature, what metrics matter, what could go wrong. If you put in focused preparation over the next few weeks, you'll walk in ready. This is absolutely doable for someone at the senior level - just treat the prep like a sprint, not a marathon.",
          "score": 3,
          "created_utc": "2026-01-15 20:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsz8zu",
              "author": "No-Mud4063",
              "text": "i don't think they will ask for LC DSA. do they?",
              "score": 2,
              "created_utc": "2026-01-15 21:34:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzy40tr",
                  "author": "rahultach",
                  "text": "No they don‚Äôt, I don‚Äôt understand why people would want to answer questions they have no clue about and mislead folks on top of it",
                  "score": 2,
                  "created_utc": "2026-01-16 16:38:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzy3rqd",
              "author": "rahultach",
              "text": "If ever there was a confidently incorrect answer. They don‚Äôt ask Leetcode DSA type questions for Google DS interviews.",
              "score": 1,
              "created_utc": "2026-01-16 16:37:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0apv56",
              "author": "Helpful_ruben",
              "text": "u/akornato Error generating reply.",
              "score": 1,
              "created_utc": "2026-01-18 14:47:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxnt9i",
          "author": "dlchira",
          "text": "About 10-15 years ago a \"How to interview at Google\" list made the rounds online. One of the points that always stuck with me (for every interview setting, not just Google) was, \"Be honest about your skills. If you say you're a 10/10 in Python, we'll have Guido van Rossum interview you. Seriously.\"",
          "score": 1,
          "created_utc": "2026-01-16 15:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g2z6q",
          "author": "BayesCrusader",
          "text": "I did it a few years ago in Europe, and it was entirely stats questions. That could be due to my training though.\n\n\nThey seemed particularly interested in one of my past papers, so I think that's how I got noticed.\n\n\nI did terribly - just bricked it! It's definitely a challenging process, but the rewards look pretty amazing.¬†",
          "score": 1,
          "created_utc": "2026-01-19 08:50:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvo7un",
          "author": "boroughthoughts",
          "text": "I mean grind stata scratch SQL questions and look at the job description. Its going to differ by segment. I would imagine some data scientist are doing experimentation work and you'd probably awnt to know A/B testing etc. Others might be more stats/ml oriented. Its tech they probably have structured process. I will say that my recent tech data science interview have usually included one algorithm style leet code questions, which is usually what stumped me. Also google puts a six month cool down period if you fail.",
          "score": 1,
          "created_utc": "2026-01-16 07:00:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwll4v",
          "author": "keshaann",
          "text": "It's great that you have a Google Sr. DS interview coming up. Focusing on data structures, algorithms, and system design will be crucial, so consider reviewing key concepts and practicing coding problems relevant to the role.",
          "score": -2,
          "created_utc": "2026-01-16 11:53:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcp6k6",
      "title": "How far should I go with LeetCode topics for coding interviews?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qcp6k6/how_far_should_i_go_with_leetcode_topics_for/",
      "author": "Lamp_Shade_Head",
      "created_utc": "2026-01-14 14:49:18",
      "score": 25,
      "num_comments": 24,
      "upvote_ratio": 0.81,
      "text": "I recently started doing LeetCode to prep for coding interviews. So far I‚Äôve mostly been focusing on arrays, hash maps, strings, and patterns like two pointers, sliding window, and binary search.\n\nShould I move on to other topics like stacks, queues, and trees, or is this enough for now?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qcp6k6/how_far_should_i_go_with_leetcode_topics_for/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzjqg9u",
          "author": "hyperbola7",
          "text": "Companies do not restrict asking just some data structures. So you need to practice all types of questions ideally. Check the company tags to see what data structures your target company focuses more on.",
          "score": 23,
          "created_utc": "2026-01-14 14:55:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjxeo0",
              "author": "Lamp_Shade_Head",
              "text": "Gotcha, thank you!",
              "score": 2,
              "created_utc": "2026-01-14 15:29:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzlbzn4",
          "author": "ReferenceThin8790",
          "text": "AI Engineer: leetcode/neetcode DSA, up to heap and priority queues. The neetcode roadmap is pretty solid.\n\nData Scientist: leetcode pandas. Compliment with CodeSignal ML.",
          "score": 17,
          "created_utc": "2026-01-14 19:17:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv9mzy",
              "author": "sharklight-22",
              "text": "Adding to this, would recommend to go through Striver‚Äôs DP series particularly if you are planning to appear for FAANGs",
              "score": 3,
              "created_utc": "2026-01-16 05:09:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzl071n",
          "author": "michaeldoesdata",
          "text": "I would focus on knowing real skills and not how to solve stupid arbitrary puzzles.",
          "score": 14,
          "created_utc": "2026-01-14 18:24:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp7nu6",
              "author": "MadT3acher",
              "text": "Recruiter: so do you know Fizzbuzz?",
              "score": 7,
              "created_utc": "2026-01-15 09:19:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzv2w97",
              "author": "ice-truck-drilla",
              "text": "I've been in the r/cscareerquestions subreddit for a while, and man this comment is such a breath of fresh air. I should've checked out this subreddit sooner.",
              "score": 1,
              "created_utc": "2026-01-16 04:24:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzl93kn",
          "author": "Alarming_Concert_808",
          "text": "At some point the exact topic list matters less than being able to apply what you already know when it‚Äôs live. People cover all the right areas and still blank once they‚Äôre on a call explaining things out loud. I would even suggest you use interviewcoder or smth to cheat/just to stay oriented if their brain locks up. Studying more topics doesn‚Äôt always fix that part",
          "score": 8,
          "created_utc": "2026-01-14 19:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk4ezi",
          "author": "DubGrips",
          "text": "I was interviewing for Senior Staff and Principal level roles recently. I believe I had interviews with 52 companies, made the final round 14 times, 6 offers. I was never given a single leetcode problem. The closest I experienced was a so-so company asking me to write a K Means function from scratch but they also let me use Google.",
          "score": 9,
          "created_utc": "2026-01-14 16:01:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkaybm",
              "author": "jmomoney44",
              "text": "Was the process more talking through your mental approach then?",
              "score": 2,
              "created_utc": "2026-01-14 16:31:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkwrdp",
                  "author": "DubGrips",
                  "text": "Usually it was a lot more detailed case study deep dives where we discussed more complicated experimentation or modeling problems where experience and domain expertise matter more than if you can just do fairly basic coding or memorize random gotchas.",
                  "score": 7,
                  "created_utc": "2026-01-14 18:09:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzns60r",
          "author": "AccordingWeight6019",
          "text": "It depends a lot on the kinds of roles you are targeting and how interview-heavy they are. For data science and applied ML roles, arrays, hashing, and basic patterns cover a surprising amount of what actually comes up. Trees and graphs show up less often, but when they do, interviewers usually expect conceptual comfort rather than deep algorithmic tricks. I would prioritize being fluent at explaining your thinking and trade-offs over expanding into every topic. In practice, weak communication around simple problems hurts more than not knowing an obscure structure. If you do branch out, stacks and queues are usually the highest return before going much deeper.",
          "score": 1,
          "created_utc": "2026-01-15 02:41:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo4gn9",
          "author": "OneWolverine307",
          "text": "Know enough basics esp of SQL and Python where you can answer simple questions but before leetcode have some foundational knowledge.",
          "score": 1,
          "created_utc": "2026-01-15 03:56:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzubvvp",
          "author": "somyis",
          "text": "i think sticking to \"easy\" should be good for now, especially because of how much more they tend to focus on viz tools and stats",
          "score": 1,
          "created_utc": "2026-01-16 01:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv2my9",
          "author": "ice-truck-drilla",
          "text": "Personally, I stopped doing leetcode and still have a great job. I got it through a process of 2 interviews where we just spoke about my experiences and how they relate to the research my company was pursuing at the time. \n\nLeetcode is just memorizing short solutions to problem classes in the form of minimum examples. I think it has some marginal time-saving utility, but in truth I think it's a waste of time and doesn't build any important skills. I would much rather just look at a candidate's transcript and discuss what they learned in their coursework, which projects they've enjoyed, etc. I don't want some weird stressful interview process that incentivizes lying to outcompete other applicants.  \n\nI think the interview process of typical workplaces have become incredibly disrespectful to candidates and I prefer to not be a part of it.",
          "score": 1,
          "created_utc": "2026-01-16 04:22:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o014pyo",
          "author": "thinking_byte",
          "text": "What you have already covers a big chunk of what actually comes up. I‚Äôd add stacks and basic trees, not to go deep, but to be comfortable reading and modifying solutions. For data roles, interviews often care more about how you reason through data transformations and edge cases than exotic algorithms. I‚Äôve seen people over-index on grinding LeetCode and under-prepare for explaining trade-offs or debugging imperfect code. If you can solve medium problems in those core areas and talk clearly about your approach, you‚Äôre in good shape. Trees beyond basics usually have diminishing returns unless the role is very algorithm-heavy.",
          "score": 1,
          "created_utc": "2026-01-17 01:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkcrdq",
          "author": "Equal-Agency4623",
          "text": "If you‚Äôre preparing for MLE or ML Scientist interviews, you have to cover all the topics, including stacks, trees and queues. But if you‚Äôre interviewing for DS Analytics jobs, then you can stop at arrays, hash maps and strings.",
          "score": 1,
          "created_utc": "2026-01-14 16:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkwxap",
              "author": "DubGrips",
              "text": "In 13 years I've never been asked about any of this stuff and I've interviewed with and had offers at 5 of the \"Magnificent 7\".¬†",
              "score": 6,
              "created_utc": "2026-01-14 18:10:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlk5mq",
                  "author": "Equal-Agency4623",
                  "text": "What job titles did you interview for?",
                  "score": 3,
                  "created_utc": "2026-01-14 19:54:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzkqtl3",
              "author": "busybody124",
              "text": "I've never been asked about stacks, trees, queues, graphs, or DP in an MLE or DS interview. These questions are going to be more common for intro and mid-level general SWE roles.",
              "score": 1,
              "created_utc": "2026-01-14 17:43:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzks7wf",
                  "author": "Equal-Agency4623",
                  "text": "If you haven‚Äôt been asked those questions, then you haven‚Äôt interviewed for MLE or Applied Scientist roles in FAANGs or other big tech companies. Or you were just lucky to get an interviewer that didn‚Äôt care about it (which is rare).",
                  "score": 2,
                  "created_utc": "2026-01-14 17:49:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qd3z2h",
      "title": "Does anyone know how hard it is to work with the All of Us database?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qd3z2h/does_anyone_know_how_hard_it_is_to_work_with_the/",
      "author": "phymathnerd",
      "created_utc": "2026-01-15 00:04:42",
      "score": 19,
      "num_comments": 15,
      "upvote_ratio": 0.84,
      "text": "I have limited python proficiency but I can code well with R. I want to design a project that‚Äôll require me to collect patient data from the All of Us database. Does this sound like an unrealistic plan with my limited python proficiency?",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qd3z2h/does_anyone_know_how_hard_it_is_to_work_with_the/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzqdvql",
          "author": "dataflow_mapper",
          "text": "It‚Äôs not unrealistic, but there is a learning curve that has more to do with the platform than the analysis itself. Most of the friction comes from access controls, workbench setup, and understanding the data model rather than heavy Python work. You can absolutely stay R-first once you are inside the environment, plenty of people do.\n\nWhere Python tends to sneak in is for plumbing tasks or examples in the docs, not for the core analysis. If you are comfortable reading Python and tweaking snippets, you will probably be fine. The bigger investment is time spent getting approved, learning the cohort builder, and figuring out which tables actually answer your question.",
          "score": 3,
          "created_utc": "2026-01-15 14:26:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv0nq3",
          "author": "rteja1113",
          "text": "hey python is not that hard. I started my career with R, 11 years ago. Now, I extensively use python and I'm reasonably proficient at it. You can take help from Claude/ChatGpt to help you with that. These LLM tools are really good at writing python code for some reason. And also, I'm happy to collaborate as well if it's a personal project you are doing for fun.",
          "score": 2,
          "created_utc": "2026-01-16 04:09:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzovutu",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-01-15 07:27:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqeiya",
              "author": "pixieO",
              "text": "https://allofus.nih.gov/",
              "score": 1,
              "created_utc": "2026-01-15 14:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqq7l0",
          "author": "j262byuu",
          "text": "You shouldn‚Äôt have any issues. AoU does support R, but here are a few things to keep in mind:\n\nWatch your RAM: You can't increase the memory limit, so make sure your code is optimized and you aren't doing anything too memory-intensive.\n\nStick to Legacy: Don't use the new workspace they just launched last week. Stick to the legacy one for now.\n\nOMOP : AoU is based on a modified OMOP structure, so you can't just plug and play with standard OHDSI R packages.\n\nI personally found the demonstration workspaces very helpful, specifically the Nature Medicine step count one. Highly recommend checking that out as a template.",
          "score": 1,
          "created_utc": "2026-01-15 15:26:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznbunf",
          "author": "locolocust",
          "text": "If you can code well in R, you'd likely be able to pick Python up pretty quickly if you wanted to go that route. \n\nBut with that said, you can probably do it R fairly easily anyway. Just depends on what sort of API All of Us has.",
          "score": 1,
          "created_utc": "2026-01-15 01:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznotcq",
          "author": "dysregulation",
          "text": "Access to granular data will be a bigger hurdle than the coding, unless you‚Äôre already working with the data in an official capacity.",
          "score": 0,
          "created_utc": "2026-01-15 02:22:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpgxdw",
              "author": "Helpful_ruben",
              "text": "u/dysregulation Error generating reply.",
              "score": -4,
              "created_utc": "2026-01-15 10:47:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznpyx4",
          "author": "AccordingWeight6019",
          "text": "It depends on what you mean by work with it. The harder parts tend to be the access model, the data schema, and the analysis environment, not Python syntax itself. A lot of the workflow is opinionated and geared around their notebooks and tooling, which can be more friction than the actual modeling. If you are comfortable reasoning about messy clinical data and cohort definitions, the language gap is usually secondary. That said, you should expect some overhead translating examples and docs, since most are Python-first, so factor that into the project scope rather than assuming it is just a data pull and analysis step.",
          "score": 0,
          "created_utc": "2026-01-15 02:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznyvs0",
          "author": "Mr_iCanDoItAll",
          "text": "https://www.researchallofus.org/data-tools/data-access/\n\nI'd recommend just spending a couple of hours messing around trying to access the data and seeing if there's anything relevant for your project. You might not be able to access individual-level data though.",
          "score": 0,
          "created_utc": "2026-01-15 03:21:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzof8qq",
          "author": "patternpeeker",
          "text": "It is not unrealistic, but the difficulty is usually not Python syntax. In practice, working with All of Us is more about navigating access controls, data schemas, and the analysis environment than writing clever code. A lot of the workflow is constrained by their platform, and you end up adapting to how data is stored and queried rather than building things your own way.\n\nIf you are comfortable in R, that is usually fine for analysis and modeling. Where Python tends to show up more is in preprocessing pipelines or when you hit scale and performance limits. The harder part is understanding the cohort definitions, missingness, and clinical quirks in the data. Those issues will dominate your time more than the language choice.",
          "score": 0,
          "created_utc": "2026-01-15 05:10:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzonxvr",
          "author": "Independent-Row1545",
          "text": "I personally found it hard to work with massive datasets only because I use genomic data and it takes a looong time to just bring in the data to my working environment - but this might also just be me not knowing efficient codes. Otherwise I don‚Äôt find it that difficult if you already know how to code. Data access is documented pretty well.",
          "score": 0,
          "created_utc": "2026-01-15 06:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzornj8",
          "author": "SprinklesFresh5693",
          "text": "Python has plotnine which is a copy of ggplot2 and siuba which i believe is a copy of dplyr?",
          "score": -1,
          "created_utc": "2026-01-15 06:49:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh0m1y",
      "title": "Which role better prepares you for AI/ML and algorithm design?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/",
      "author": "Huge-Leek844",
      "created_utc": "2026-01-19 10:25:00",
      "score": 17,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "Hi everyone,\n\nI‚Äôm a perception engineer in automotive and joined a new team about 6 months ago. Since then, my work has been split between two very different worlds:\n\n‚Ä¢ Debugging nasty customer issues and weird edge cases in complex algorithms\n‚Ä¢ C++ development on embedded systems (bug fixes, small features, integrations)\n\nNow my manager wants me to pick one path and specialize:\n\n1. Customer support and deep analysis\n   This is technically intense. I‚Äôm digging into edge cases, rare failures, and complex algorithm behavior. But most of the time I‚Äôm just tuning parameters, writing reports, and racing against brutal deadlines. Almost no real design or coding.\n\n2. Customer projects\n   More ownership and scope fewer fire drills. But a lot of it is integration work and following specs. Some algorithm implementation, but also the risk of spending months wiring things together.\n\nHere‚Äôs the problem:\nMy long-term goal is AI/ML and algorithm design. I want to build systems, not just debug them or glue components together.\n\nRight now, I‚Äôm worried about getting stuck in:\n\n\\* Support hell where I only troubleshoot\n\\* Or integration purgatory where I just implement specs\n\nIf you were in my shoes:\n\nWhich path actually helps you grow into AI/ML or algorithm roles?\nWhat would you push your manager for to avoid career stagnation?\n\nAny real-world advice would be hugely appreciated.\nThanks!\n\n",
      "is_original_content": false,
      "link_flair_text": "AI",
      "permalink": "https://reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0ggc2d",
          "author": "phoundlvr",
          "text": "Tell your boss your long term goals for your cater and ask their advice. Preface it with a statement acknowledging that you want to prepare yourself for your long term goal and that it‚Äôs okay that neither is the long term goal. Emphasize that you have a lot to learn and see both roles as valuable. \n\nBelieve it or not sharing long term career goals is a good thing, even if they‚Äôre outside of his team. Good managers will help you get there.",
          "score": 3,
          "created_utc": "2026-01-19 10:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hlztz",
          "author": "latent_threader",
          "text": "If your goal is AI/ML and algorithm design, the support-heavy path can help your intuition but it is easy to get pigeonholed there. You learn failure modes deeply, but you rarely get credit for creating new methods. The customer project path is usually better if you can negotiate real ownership of algorithm pieces instead of pure integration. I would push your manager for a hybrid role where you both design or prototype changes and then see them through deployment. Also ask explicitly how people on each path have moved into algorithm roles before. That answer tells you a lot.",
          "score": 2,
          "created_utc": "2026-01-19 15:22:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8p3h",
          "author": "patternpeeker",
          "text": "If the goal is real AI or algorithm design, I would bias toward whichever path gets you closest to owning a problem end to end, even if the work feels less glamorous. Deep support work teaches you how and why algorithms fail in the wild, which is valuable, but it can stall if you never get to change the design that caused the failure. Pure integration has the opposite risk, you ship a lot but rarely make core decisions.\n\nIn practice, the people I see move into stronger ML or algorithm roles are the ones who combine failure analysis with proposing and implementing fixes. I would push your manager for a hybrid scope where you debug edge cases and then actually redesign or prototype changes, not just tune knobs or write reports. Titles matter less than whether you can point to concrete algorithmic decisions you made and systems you improved because of real-world behavior.",
          "score": 1,
          "created_utc": "2026-01-20 05:24:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gffuy",
          "author": "latent_signalcraft",
          "text": "if your goal is AI or algorithm design focus on which path gives you influence over problem framing and evaluation not just tasks. support work helps only if you are learning failure modes and shaping metrics otherwise it becomes reactive tuning. integration work helps only if you can question specs and validate whether the system actually works in the real world. i would push your manager for ownership of error analysis metric definition or design reviews because that is where algorithm designers are really developed.",
          "score": 1,
          "created_utc": "2026-01-19 10:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h6z3m",
          "author": "dataflow_mapper",
          "text": "If your end goal is AI/ML and algorithm design, I would bias toward the path that keeps you closest to building and modifying systems, even if it is not perfect. Deep support work teaches you how algorithms fail in the real world, which is valuable, but it can trap you in reactive mode with little room to design new things. Integration work at least keeps you writing code and understanding system boundaries, which is easier to evolve into ownership of algorithms later.\n\nThat said, the ideal move is usually not choosing one extreme. I would push your manager for explicit time or scope around algorithm ownership, even small pieces, validation logic, prototypes, or improvements rather than just glue work. Career stagnation tends to happen when your role stops producing artifacts that look like design or code. Debugging builds intuition, but building things is what usually gets you labeled as an algorithm engineer.",
          "score": 1,
          "created_utc": "2026-01-19 14:05:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf9zxw",
      "title": "Is LLD commonly asked to ML Engineers?",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/",
      "author": "FinalRide7181",
      "created_utc": "2026-01-17 10:36:09",
      "score": 15,
      "num_comments": 24,
      "upvote_ratio": 0.76,
      "text": "I am a last year student and i am currently studying for MLE interviews.\n\nMy focus at the moment is on DSA and basics of ML system design, but i was wondering if i should prepare also oop/design patterns/lld. Are they normally asked to ml engineers or rarely?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o032xxd",
          "author": "sometimes_angery",
          "text": "I'm an MLE and have no idea what LLD is.",
          "score": 27,
          "created_utc": "2026-01-17 10:41:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o095wy3",
              "author": "avourakis",
              "text": "They got me there too üòÖ",
              "score": 1,
              "created_utc": "2026-01-18 07:22:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0339sp",
              "author": "FinalRide7181",
              "text": "Low Level Design, like design classes for a system like parking lot using OOP classes, methods, inheritance, design patterns.",
              "score": 0,
              "created_utc": "2026-01-17 10:44:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o033h2s",
                  "author": "sometimes_angery",
                  "text": "Depends on the job I guess. Do they expect you to implement a system like parking lot? Cuz maybe that's not entirely an MLE job.",
                  "score": 3,
                  "created_utc": "2026-01-17 10:46:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o06554g",
              "author": "__mitra__",
              "text": "Same. Never had any company ask about OOP patterns or similar. Not that it's irrelevant, but I guess it's assumed you have a base understanding of it.",
              "score": 0,
              "created_utc": "2026-01-17 20:47:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0685up",
                  "author": "FinalRide7181",
                  "text": "I am doing an MS in stats with ml/dl focus. I know python and basic oop (class, attribute, method, inheritance, polymorph) but i am not a CS student, i dont really know design patterns/oop design.\n\nDo you think i should study them if i aim to be a MLE or i can skip them and focus on LC?",
                  "score": 1,
                  "created_utc": "2026-01-17 21:03:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o036gs4",
          "author": "Hungry_Age5375",
          "text": "Big tech asks LLD, real ML companies don't. Stick with ML system design - that's where the value is.",
          "score": 9,
          "created_utc": "2026-01-17 11:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o038gm9",
              "author": "FinalRide7181",
              "text": "So no need to do design patterns? \n\nI have been told that some companies ask them to swe, but for mle it is a different story right? Same for ai engineer?",
              "score": 1,
              "created_utc": "2026-01-17 11:32:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03edtc",
          "author": "patternpeeker",
          "text": "It depends a lot on how the team defines ‚ÄúML engineer.‚Äù In practice, if the role owns production code, services, or pipelines, some level of LLD and basic OOP shows up pretty often, even if it is not labeled that way. You might not get textbook design patterns, but you will get questions that test whether you can structure code that is testable, extendable, and not a one-off notebook. Teams that treat MLE as research plus glue care less about this, while platform or product-facing teams care a lot. I would not go deep into patterns for their own sake, but you should be comfortable explaining how you would design and evolve a small ML service or pipeline over time. That usually matters more than pure DSA once you are past the screen.",
          "score": 3,
          "created_utc": "2026-01-17 12:21:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04lxl4",
              "author": "FinalRide7181",
              "text": "Is it asked to juniors too or generally to people with at least a couple of years of experience?",
              "score": 1,
              "created_utc": "2026-01-17 16:24:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h4ji",
          "author": "dataflow_mapper",
          "text": "From what I have seen, it depends a lot on the company and how they define the MLE role. If the role is closer to software engineering with ML on top, then basic LLD and OOP concepts come up fairly often. Things like designing a feature pipeline class or structuring a training service.\n\nIf it is more research or modeling heavy, they usually focus more on ML fundamentals and system design at a higher level. I would not go deep into patterns, but being comfortable explaining clean class design, interfaces, and tradeoffs is a safe bet. It rarely hurts, and it can help you stand out when interviews lean practical.",
          "score": 2,
          "created_utc": "2026-01-17 12:42:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04k54r",
          "author": "madbadanddangerous",
          "text": "This job market is a dumpster fire. Anything and everything is on the table. I've been asked about low level CPU internals for ML engineer positions. I've been asked about NLP learning for robotic ML interviews. I've been asked to show how well I can vibe code, how to implement a custom loss function and code an ML model from scratch using only numpy, presentations on prior projects, tests, on-site projects. Once I was asked to code a live solution to a geology problem after getting a 15 minute PowerPoint presentation on geological processes. Another time, the interviewer handed me an unsolved problem in probability theory and asked me to solve it. \n\nYou can be asked anything even tangentially related to computing and then be graded on it. This job market is an experience in humiliation, superstition, cargo culting, rejection, and self-flagellation. \n\nJust do your best and hope you get lucky. Try not to sweat the rejection or let it affect your mental health too much. Companies are out of their minds right now, and we all need to remember that we are more than what they test for in a broken interview process.",
          "score": 1,
          "created_utc": "2026-01-17 16:16:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05honc",
          "author": "NoProfession6095",
          "text": "I will be starting to study Data Science and see where it lands me. I am BTech undergrad CSE 2025 passout and want to explore the domain. What should my first steps be?",
          "score": 1,
          "created_utc": "2026-01-17 18:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07ymo6",
          "author": "thinking_byte",
          "text": "From what I have seen, it depends a lot on the company and how close the role is to production work. Teams that treat MLEs as software engineers who happen to work on ML will care about LLD, clean interfaces, and basic design patterns. If the role is more research or modeling focused, it comes up far less.\n\nI would not go deep into academic OOP theory, but being comfortable explaining how you would structure a training pipeline, inference service, or feature store is useful. Even simple class design and separation of concerns goes a long way. The signal they usually want is whether you can build and maintain ML systems, not just train models once.",
          "score": 1,
          "created_utc": "2026-01-18 02:27:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o081isk",
              "author": "FinalRide7181",
              "text": "Is that mostly learned on the job? If it is then it is fine, what i was referring to was practicing parking lot/design patterns‚Ä¶ which is i think what you called ‚Äúacademic OOP theory‚Äù",
              "score": 1,
              "created_utc": "2026-01-18 02:42:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0dyi6h",
                  "author": "thinking_byte",
                  "text": "Yeah, that stuff is mostly learned on the job. Very few teams expect a new grad MLE to rattle off design patterns or do formal LLD like a backend interview. What they usually care about is whether you can reason about structure at a practical level.\n\nParking lot style questions are overkill for most MLE roles. A better use of time is being able to talk through how you‚Äôd organize code for training vs inference, how you‚Äôd keep things testable, and how you‚Äôd avoid everything turning into one giant script. If you can explain those tradeoffs clearly, that‚Äôs usually enough signal. The rest comes naturally once you‚Äôre maintaining real systems.",
                  "score": 1,
                  "created_utc": "2026-01-19 00:19:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0907wa",
          "author": "AccordingWeight6019",
          "text": "It really depends on how the company defines the MLE role. wherein in teams where MLEs are closer to software engineers who own production systems, some form of LLD or object design tends to come up, even if it is not framed explicitly as design patterns. In more research leaning or modeling focused roles, it is often secondary to data, modeling, and evaluation discussions. In practice, being able to reason about code structure, interfaces, and trade-offs usually matters more than memorizing patterns. job titles hide a lot of variation here, so the safest bet is to be comfortable explaining how you would structure a real system at a high level and at a code level.",
          "score": 1,
          "created_utc": "2026-01-18 06:32:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09928z",
              "author": "FinalRide7181",
              "text": "I mean if what is being asked is ml system design and oop for pipelines then it is fine. What i meant with LLD was design patterns and things like design parking lot, are these common for mle or almost only for traditional swe?",
              "score": 1,
              "created_utc": "2026-01-18 07:50:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09idfh",
          "author": "nian2326076",
          "text": "\n\nI'm an MLE¬†",
          "score": 1,
          "created_utc": "2026-01-18 09:15:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09isjf",
              "author": "FinalRide7181",
              "text": "Great! And what do you think about my question?",
              "score": 1,
              "created_utc": "2026-01-18 09:19:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bboq7",
          "author": "LeonhardEuler_",
          "text": "What do you do to prep for ML System design? I'm a new grad looking to go MLE",
          "score": 1,
          "created_utc": "2026-01-18 16:34:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o055gga",
          "author": "akornato",
          "text": "Low-level design questions are much less common for MLE roles than DSA and ML system design, but they do come up - especially at companies where MLEs are expected to write production code and work closely with software engineers. The reality is that it varies significantly by company and team. Big tech companies might throw in some OOP and design patterns questions to assess your software engineering fundamentals, but they're usually not the main focus. Smaller companies or places where the MLE role is closer to a traditional SWE role might dig deeper into LLD. If you're already solid on DSA and ML system design, spending maybe 20-30% of your remaining prep time on basic OOP principles and common design patterns is reasonable insurance, but don't let it take priority over your core MLE prep.\n\nThe good news is that you don't need to go as deep as a backend engineer would - just understand the fundamentals like SOLID principles, a handful of common patterns (factory, strategy, observer), and how to write clean, maintainable code. Most interviewers care more about seeing that you can structure code reasonably than testing whether you've memorized every design pattern. If you want help figuring out how to answer these kinds of questions when they do come up, I built [interview AI copilot](http://interviews.chat) to handle unexpected interview questions across all topics, including the occasional curveball LLD question in an MLE interview.",
          "score": 1,
          "created_utc": "2026-01-17 17:56:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qenpcq",
      "title": "Data analysis vs C++ feature design",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qenpcq/data_analysis_vs_c_feature_design/",
      "author": "Huge-Leek844",
      "created_utc": "2026-01-16 18:17:27",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Hi everyone,  \nI‚Äôm a radar signal processing engineer in automotive and started a small team six months ago. My work so far has been a mix of:  \n  \n1) Radar data analysis for bugs found in customers: performance issues, drop of detections, loss of tracking. I learnt about DSP and radar algorithms.  \n2) C++ coding: small implementations and bug fixes, embedded systems work (inter-core comms, debugging)  \nThe team is growing, so I need to choose one path to focus on. My manager suggested either continuing with:  \n  \n1) Customer support and data analysis, which is very complex and does require a decent understanding of algorithms and math but rarely involves making changes, at best only changing a few parameters. Tough deadlines here.   \nOR  \n2) Moving to C++ customer projects. I will have more scope, ownership and design but ranges from simple integration work to algorithm implementations. So i won't analyse super complex algorithms, and i could potentially work on boring integration topics for 6 months! Its very customer driven. Less deadlines.  \n  \nMy long-term goal is AI, ML, and general algorithm design. I want to build and design algorithms, not just tune parameters or implement specs.\n\n  \nWhich path would you choose to maximize growth toward AI and algorithm work, and how would you make it as useful as possible?  \nWhat kind of questions i could ask my manager?  \n  \nThank you.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/datascience/comments/1qenpcq/data_analysis_vs_c_feature_design/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzyy177",
          "author": "Equal-Agency4623",
          "text": "Between options 3 and 4, I‚Äôll recommend option 4 because it opens door to more career opportunities for you. With that experience, you can work as a Research Engineer in AI labs where you implement novel algorithms. You can also work as a Quantitative Developer in quant hedge funds where you implement trading algos.",
          "score": 6,
          "created_utc": "2026-01-16 18:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02sqsw",
          "author": "AccordingWeight6019",
          "text": "Given your long-term goal, I would be biased toward the path that gives you ownership over problem formulation, even if the algorithms are simpler at first. Tuning parameters under deadline pressure builds intuition, but it rarely lets you define assumptions or failure modes, Which is what carries over to ML work. On the C++ side, the risk is getting stuck in integration, so the key question is whether you can own parts of the algorithmic design and not just implement specs. I would ask your manager how often each path involves proposing changes versus executing predefined solutions, and who is accountable when performance degrades. the skill that transfers best to AI work is not a specific tool, but the habit of reasoning about trade-offs and system behavior end to end.",
          "score": 3,
          "created_utc": "2026-01-17 09:05:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02knfj",
          "author": "SkillSalt9362",
          "text": "1. I would go for AI ML but also consider my interest \n\n2. building side projects are non negotiable, it helps to improve our skills work on algorithms and more!!",
          "score": 2,
          "created_utc": "2026-01-17 07:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05iq6q",
          "author": "DiligentSlice5151",
          "text": "What  is hard about Customer support and data analysis?",
          "score": 0,
          "created_utc": "2026-01-17 18:57:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05j12h",
              "author": "DiligentSlice5151",
              "text": "Do you mean blackbox data analysis?",
              "score": 0,
              "created_utc": "2026-01-17 18:58:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgv0ij",
      "title": "Weekly Entering & Transitioning - Thread 19 Jan, 2026 - 26 Jan, 2026",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/",
      "author": "AutoModerator",
      "created_utc": "2026-01-19 05:01:45",
      "score": 9,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "o0ff9tm",
          "author": "Yang-Geum-myeong",
          "text": "Hi everyone,\n\nI‚Äôm at a career crossroads and would appreciate some grounded advice. I have 5 years of experience in the insurance/reinsurance domain, working in catastrophe modeling, risk analytics, data cleaning, and geocoding using in house tools. My work has involved heavy data analysis, stakeholder interaction, and translating model outputs into business insights.\n\nI want to change domains and am evaluating two paths:\n\n1. MS abroad 2026 (Data Science / Analytics / related tech programs)\n2. MBA in India (to pivot into consulting / strategy / management roles)\n\nMy key questions: For someone at 5 years experience, which path offers a more realistic and sustainable domain switch? How do recruiters view prior domain experience in each case? Any regrets from people who chose MS vs MBA (or vice versa)? Are there risks of being ‚Äúoverqualified but underexperienced‚Äù in either path? My priority is long-term career satisfaction and growth, not just immediate compensation.\n\nThanks in advance...would really value insights from people who‚Äôve faced a similar situation.",
          "score": 2,
          "created_utc": "2026-01-19 05:28:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fc0k0",
          "author": "Magnum_Opus7",
          "text": "Learning resource, especially for Maths",
          "score": 1,
          "created_utc": "2026-01-19 05:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fh6q8",
          "author": "AccordingWeight6019",
          "text": "One pattern I see a lot is people over-optimizing for tools instead of problem framing. Early on, it helps to focus on core stats, data wrangling, and being able to explain why a model should exist at all. Small end to end projects where you define the question, deal with messy data, and communicate trade-offs tend to be more valuable than stacking certificates. the transition is usually less about learning one more library and more about demonstrating how you think about data in context.",
          "score": 1,
          "created_utc": "2026-01-19 05:42:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fi2xs",
              "author": "Due-Experience-382",
              "text": "Any resources for the project part?",
              "score": 1,
              "created_utc": "2026-01-19 05:49:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iqkhz",
          "author": "Sea_Name4846",
          "text": "I'm a junior in university and I want to apply to internships. My major is data science. Where should I apply?",
          "score": 1,
          "created_utc": "2026-01-19 18:24:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdrqh6",
      "title": "LLM for document search",
      "subreddit": "datascience",
      "url": "https://www.reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/",
      "author": "Few-Strawberry2764",
      "created_utc": "2026-01-15 18:35:27",
      "score": 2,
      "num_comments": 30,
      "upvote_ratio": 0.54,
      "text": "My boss wants to have an LLM in house for document searches. I've convinced him that we'll only use it for identifying relevant documents due to the risk of hallucinations, and not perform calculations and the like. So for example, finding all PDF files related to customer X, product Y between 2023-2025.\n\nBecause of legal concerns it'll have to be hosted locally and air gapped. I've only used Gemini. Does anyone have experience or suggestions about picking a vendor for this type of application? I'm familiar with CNNs but have zero interest in building or training a LLM myself. ",
      "is_original_content": false,
      "link_flair_text": "Projects",
      "permalink": "https://reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/",
      "domain": "self.datascience",
      "is_self": true,
      "comments": [
        {
          "id": "nzt86ly",
          "author": "UltimateWeevil",
          "text": "What is he actually asking you to solve? It‚Äôs probably more a NLP type task like TF-IDF + cosine similarity or a BM25 keyword matching task. \n\nFeels like a LLM is overkill unless he wants some kind of intelligent capability to query the contents. If so I‚Äôd suggest looking into Ollama for local hosting a LLM as you can choose pretty much any model you want and run a vectorDB like Chroma for you RAG element. You‚Äôll need to make sure you get your chunking done correctly and if you can nail your metadata tags it‚Äôll help massively for retrieval.",
          "score": 24,
          "created_utc": "2026-01-15 22:15:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztl888",
              "author": "DiligentSlice5151",
              "text": "second this ! All this for some PDFs.  Why?",
              "score": 4,
              "created_utc": "2026-01-15 23:22:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09mtqk",
                  "author": "Tricky_Math_5381",
                  "text": "Maybe the documents are very scattered or mixed? Idk too little information but maybe you want something like\n\nHey what DIN standards are relevant for the elements we get from producer a?\n\nA llm could maybe be useful for that",
                  "score": 1,
                  "created_utc": "2026-01-18 09:57:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs3opa",
          "author": "Rockingtits",
          "text": "Start with basic semantic similarity vector search and then into more advanced rag techniques like hybrid search, deep research and graphRAG.¬†\n\nIf you don‚Äôt need to generate an answer you can do a lot with a local model, it‚Äôs just doing embeddings essentially.\n\n\nYou‚Äôre gonna need a clever process for ingesting your documents unless they are squeaky clean also.¬†",
          "score": 26,
          "created_utc": "2026-01-15 19:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzslaxk",
              "author": "DiligentSlice5151",
              "text": " Yes and Yes on document cleaning  and database management.",
              "score": 6,
              "created_utc": "2026-01-15 20:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzswc8h",
          "author": "DFW_BjornFree",
          "text": "Why do you need an LLM? Just do a mixture of elastic search with similarity search.¬†\n\n\nLet users search for defined words / phrases or let them type a few sentences that get passed into a similarity search model that scores documents by match and returns them past a threshold¬†",
          "score": 7,
          "created_utc": "2026-01-15 21:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu8mj7",
          "author": "autumnotter",
          "text": "You're trying to do document search, and llm doesn't do that in the way you're thinking.¬†\n\n\nEffectively you want to do something like OCR, turning PDFs and images into unstructured text, then chunk the text, compute embeddings and vectorize, and then store in a vector database.¬†\n\n\nFrom there you can do document similarity search by querying the vector database. An agentic system can make that query and then return the retrieved context, sharing it with an LLM, which is usually called RAG.\n\n\nYou don't actually need an LLM to do document similarity search.\n\n\nI'm not familiar with vendors that you might use to do this locally, so I can't help you there.",
          "score": 6,
          "created_utc": "2026-01-16 01:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsm13a",
          "author": "Wishwehadtimemachine",
          "text": "LLM + RAG here no?",
          "score": 3,
          "created_utc": "2026-01-15 20:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsgv39",
          "author": "TaiChuanDoAddct",
          "text": "Are you in a microsoft or google environment? What your boss actually wants is a RAG, and they're honestly not hard or expensive to set up in these environments unless you need 1000% perfect results every time. \n\nMiscrosoft Azure, for example, let's you point an LLM at a sharepoint and tell it to RAG the contents and the connect it to an agent. it's pretty easy.",
          "score": 5,
          "created_utc": "2026-01-15 20:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs3ltl",
          "author": "Some-Librarian-8528",
          "text": "I'm a bit confused why he wants an LLM. Is it just to enable natural language searches? What's wrong with the current system? What's your budget for running it?",
          "score": 3,
          "created_utc": "2026-01-15 19:08:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs9lkt",
              "author": "Few-Strawberry2764",
              "text": "This is my second week on the job and I'm not sure if there is an existing system. Frankly I think he only wants it because \"AI\".",
              "score": 6,
              "created_utc": "2026-01-15 19:35:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzse3h5",
                  "author": "portmanteaudition",
                  "text": "Budget? Doing this properly for 1 person requires tens of thousands of dollars typically. For a large team, hundreds.",
                  "score": -1,
                  "created_utc": "2026-01-15 19:56:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs8f04",
          "author": "letsTalkDude",
          "text": "Why do you need an llm for search a document or even read it.  It is a straightforward nlp.\n\nCan you explain why r u looking for llm",
          "score": 2,
          "created_utc": "2026-01-15 19:30:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsa4xs",
              "author": "Few-Strawberry2764",
              "text": "I'm pretty sure he wants an LLM because he's drunk the AI Kool aid. But after we put a bunch of safety guard rails on usage, it's hard to see how it's meaningfully different from a ctrl F search.",
              "score": 1,
              "created_utc": "2026-01-15 19:38:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsdq7t",
          "author": "portmanteaudition",
          "text": "If you want it all local etc. you will need a fairly powerful in-house server with a large amount of VRAM/GDDR and CPU cores. You can use pretty much any LLM for this, although for local I'd recommend open source models like ollama since you have a decent likelihood of maintanence at 0 cost. All of these models are pre-trained and you can do RAG-like stuff. You just pass them the docs (or set up an OCR front end to do so first) and explain what you want. Inference is where you are going to run into issues hardware-wise - bigger models will tend to be better but require more powerful servers. If your boss just wants this for e.g. a couple of laptops, he is deeply mistaken- he",
          "score": 1,
          "created_utc": "2026-01-15 19:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvhw8n",
          "author": "AccordingWeight6019",
          "text": "For that use case, the hard part is usually not the model but the retrieval layer around it. If the goal is document identification rather than synthesis, you want something that does embeddings well, is stable, and can be deployed on prem without surprises. The LLM then mostly acts as a query interpreter on top of search.\n\nI would evaluate options based on how transparent the retrieval is, how much control you have over chunking and metadata filters, and how predictable the outputs are under edge cases. In practice, simpler models paired with a solid vector store and strict prompting often outperform larger models for legal or compliance constrained setups. The risk is less hallucination and more overconfidence, so strong guardrails and evaluation matter more than raw model capability.",
          "score": 1,
          "created_utc": "2026-01-16 06:09:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw5tn3",
          "author": "latent_threader",
          "text": "For that use case you probably do not want ‚Äúdocument search with an LLM‚Äù so much as classic retrieval plus embeddings. The LLM can sit on top just to interpret the query, not to answer it.\n\nMost teams I have seen in similar legal setups run a local embedding model, index chunks in something like a vector store, and retrieve PDFs by similarity plus metadata filters. The model never needs to see the whole corpus at once, and hallucination risk stays low because you are only ranking documents. The hard parts tend to be chunking, metadata hygiene, and evaluation, not the LLM itself.",
          "score": 1,
          "created_utc": "2026-01-16 09:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxjah4",
          "author": "Voiceofshit",
          "text": "If I'm understanding you correctly, I think you can just do that with a custom copilot agent.\n\n***after you've indexed your current database. Copilot should only be interpreting the human aspect of what they're asking for, then activating whatever hardcoded search function you have for the appropriate documentation with the relevant information. I would only use it as a wrapper for a robust search function that looks pretty and makes it easy to interact with. Lots of people in the comments have good ideas on how to actually implement the search feature. But installing the AI wrapper will make you look like an AI god and make it dummy proof for leadership to interact with.",
          "score": 1,
          "created_utc": "2026-01-16 15:06:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kyy0z",
          "author": "slashdave",
          "text": ">finding all PDF files related to customer X, product Y between 2023-2025\n\nYou mean... like a simple index? Maybe you can start with deploying an ordinary indexer? Stick it on a RAG if someone wants to waste money on an LLM prompt.",
          "score": 1,
          "created_utc": "2026-01-20 00:59:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0le0pq",
          "author": "whodis123",
          "text": "We have experience with air gapped rag and elastic systems.",
          "score": 1,
          "created_utc": "2026-01-20 02:21:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrym1v",
          "author": "DiligentSlice5151",
          "text": " You can use automation to query it. Many companies are essentially just 'wrappers' for Gemini or ChatGPT; however, for local implementation, you would need to use DeepSeek to connect to your database.     Vendor wise  you need someone that specializes in database to search query.  Will you be the one maintaining the LLM after setup ?",
          "score": 1,
          "created_utc": "2026-01-15 18:45:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsl3oo",
          "author": "Perfektio",
          "text": "This is one of the least knowledgeable posts I‚Äôve seen in a while on this sub. You can literally google this in 5 minutes, this is such a common thing to build as it has been the original enterprise hype for the past 4 years.",
          "score": 0,
          "created_utc": "2026-01-15 20:28:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs0xwt",
          "author": "Single_Vacation427",
          "text": "Ugh? LLM search is being used a lot, so even if there is some hallucination, there are was to reduce that and also, what is the risk exactly? Clicking on a document and realizing it was not helpful. \n\nWhat are the legal concerns exactly?\n\nYou don't train an LLM yourself. It's not necessary for search. LLM is just part of the system, which usually includes RAG or something of the sort.\n\nDon't get me wrong, I'm not into the \"Let's use LLM magic\" products, but your post is incredibly ignorant about the space.",
          "score": -1,
          "created_utc": "2026-01-15 18:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztle9z",
          "author": "DiligentSlice5151",
          "text": "This needs to be a film lol :)",
          "score": 0,
          "created_utc": "2026-01-15 23:23:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx1u4g",
          "author": "BearVegetable5339",
          "text": "This is a very grown-up LLM use case because you're treating it as a retrieval and navigation layer, not an oracle. Air-gapped hosting plus legal concerns means the vendor should be judged on deployment model, security posture, and how well they do citation-grounded retrieval over your PDFs. A good system should default to returning filenames, dates, and relevant passages with page references, and it should be comfortable saying no relevant documents found instead of guessing. Your example query is basically metadata filtering plus semantic search, so chunking, embeddings, and indexing quality will matter more than model size. People who've used products like Spellbook, AI Lawyer, CoCounsel often end up caring less about the model and more about the workflow: can you verify in one click and audit what happened. If you keep it retrieval-only and enforce always show sources, you're already avoiding the most common disaster mode.",
          "score": 0,
          "created_utc": "2026-01-16 13:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzry7x6",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-01-15 18:44:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs3vqn",
              "author": "Rockingtits",
              "text": "It‚Äôs not airgapped like op said and I‚Äôve found it to be absolutely rubbish in practice.¬†\n\nIt‚Äôs fine for finding a document in sharepoint but actual retrieval within documents is beyond bad",
              "score": 3,
              "created_utc": "2026-01-15 19:09:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}