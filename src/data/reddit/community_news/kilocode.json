{
  "metadata": {
    "last_updated": "2026-02-01 03:27:24",
    "time_filter": "week",
    "subreddit": "kilocode",
    "total_items": 18,
    "total_comments": 64,
    "file_size_bytes": 71352
  },
  "items": [
    {
      "id": "1qq9b2s",
      "title": "Cline Acqui-hired by OpenAI?",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/iew15gdfoagg1.png",
      "author": "btkilo520",
      "created_utc": "2026-01-29 14:00:16",
      "score": 24,
      "num_comments": 11,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qq9b2s/cline_acquihired_by_openai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2fnjax",
          "author": "Esongs-eth",
          "text": "i think This looks like a classic acqui-hire. Great outcome for the Cline team i must say  but it usually means the open source project loses momentum once the core builders move on. Interesting to see Kilo positioning itself as the “keep it open and community-owned” alternative. good move IMO..",
          "score": 4,
          "created_utc": "2026-01-29 16:21:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f6jzd",
          "author": "AdityaSinghTomar",
          "text": "When will the results of this 'Kilo Champion Program' be released?",
          "score": 3,
          "created_utc": "2026-01-29 15:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2fgx3d",
              "author": "btkilo520",
              "text": "Early next week!",
              "score": 3,
              "created_utc": "2026-01-29 15:51:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2fn3cv",
          "author": "AbbreviationsOk6975",
          "text": "XDDD  \nTake a look at it. Competition wants to take CLine's tricks & tips internal implementation. Bold move! And cheap way to get something good.,",
          "score": 1,
          "created_utc": "2026-01-29 16:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gslah",
          "author": "Mayanktaker",
          "text": "OpenAI already going to lose everything next year.",
          "score": 1,
          "created_utc": "2026-01-29 19:26:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ksx58",
              "author": "Separate-Hedgehog388",
              "text": "Ppl have been saying that since 2022, yet it's only going higher",
              "score": 1,
              "created_utc": "2026-01-30 10:04:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ktm7n",
                  "author": "Mayanktaker",
                  "text": "This time sam Altman said this",
                  "score": 1,
                  "created_utc": "2026-01-30 10:10:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2f4en0",
          "author": "ttreyr",
          "text": "If a large AI company wanted to acquire you, you'd immediately be jumping for joy.",
          "score": 1,
          "created_utc": "2026-01-29 14:54:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2fauj2",
              "author": "fragment_me",
              "text": "Theyre using this event as an opportunity to promote their own brand. It’s actually quite smart.",
              "score": 5,
              "created_utc": "2026-01-29 15:24:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2femww",
                  "author": "TheSyntaxSlayer",
                  "text": "Hella hypocritical though. And definitely makes them look even shadier/more opportunistic. If you need to rely on tactics this low, you probably don't have a good product lol",
                  "score": -1,
                  "created_utc": "2026-01-29 15:41:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqzlpu",
      "title": "Im getting a very bad impression of Kilo so far - am I wrong?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qqzlpu/im_getting_a_very_bad_impression_of_kilo_so_far/",
      "author": "janusr",
      "created_utc": "2026-01-30 08:11:41",
      "score": 24,
      "num_comments": 25,
      "upvote_ratio": 0.82,
      "text": "I might be completely off track here on what meaningful contribution Kilo adds feature wise, so please correct me if I have the wrong idea of the timeline here:\n\n1. Cline develops Coding agent extension\n\n2. Roo Code forks it, adds nice new features\n\n3. Kilo forks Roo, doesn't contribute much but heavily invests in putting adds everywhere.\n\n4. Kilo, although no apparent technical reason, storms the usage charts, while Cline slowly becomes irrelevant. Fortunately, the cline team is receiving some compensation for their work in return for OpenAI now wanting to employ them.\n\n5. Kilo shamelessly puts up more ads about this, proudly mentions commitment to open source and some other perks for cline contributors, while now having the monopoly on the paid plan part of the product they mostly didn’t create.\n\nJust needed to get his off my chest as I see these ads all the time and it just seems so wrong. But again, this is more of a question than a statement. I really wonder if there is a part of the bigger picture I'm not seeing.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qqzlpu/im_getting_a_very_bad_impression_of_kilo_so_far/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o2koovt",
          "author": "IvoDOtMK",
          "text": "my 2 cents here. most of what you're talking about is pretty much standard practice in Open source.  Your frustration with the ads is subjective but gives them results (they are VC backed after all).   \nI'd look at the actual commit history and feature releases rather than the marketing when evaluating their contribution. they've shipped features that didn't exist upstream, they've been transparent about merging upstream changes from Cline and Roo while adding their own features.   \nThe Cline team joining OpenAI was their own career choice, not something Kilo caused.",
          "score": 15,
          "created_utc": "2026-01-30 09:25:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lmyfp",
              "author": "yowmamasita",
              "text": "But why shit on the progenitor? \n\nRoo Code got popular because of what is \"--dangerously-skip-permissions\" in Claude Code now which is, at that time, Cline didn't want. Also what is something Kilo Code is offering that is \"revolutionary\" that it deserved a fork?",
              "score": 3,
              "created_utc": "2026-01-30 13:39:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2mdxwp",
                  "author": "darkwingdankest",
                  "text": "did Kilo add the indexing or was that a Roo feature? supposedly Kilo merges in Cline and Roo features continuously while Roo has gone its own direction. I will say Kilo's ability to edit files without taking editor focus is its biggest selling point for me. Lately it has been buggy to the point that it's unusable",
                  "score": 2,
                  "created_utc": "2026-01-30 15:51:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2r430r",
                  "author": "mcowger",
                  "text": "Did you ever try to contribute to Roo?\n\nIf you had, you’d know why - the Roo team is pretty insular about their codebase, and for a very long time actively refused great ideas that they would later reimplement.  \n\nThat’s fine, of course, based on the licenses.   But getting anything done on Roo that wasn’t a trivial edit meant a fork was necessary to do anything.",
                  "score": 2,
                  "created_utc": "2026-01-31 07:16:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2naoi0",
              "author": "trupix",
              "text": "FYI not the entire team",
              "score": 3,
              "created_utc": "2026-01-30 18:16:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ky2gb",
          "author": "sand_scooper",
          "text": "They do have the users and that is the most valuable thing. And currently it seems like only kilo code is getting the stealth models or free model previews like kimi 2.5 and minimax 2.1. I notice that Roo Code doesn't have any stealth or any preview models anymore. \n\nI'll say it's because it has the most users that's why it gets these model previews. So it's kind of a network effect going on.\n\nIt's nice to be able to easily test almost all models. But then again GitHub Copilot or Windsurf already offers all of the best models. \n\nIf I guess the reason is simple the free models like grok code fast that made kilo code seem to be popular based on the stats. \n\nAnd they do advertise aggressively on social media. \n\nThat's probably why. Although I'm not a fan of them  focusing so much on making new crap side quests projects every few weeks. While never properly addressing or taking accountability for those tool call errors. They say the standard copy paste reply saying it shouldn't happen, then asking you to report the bug and nothing happens.",
          "score": 5,
          "created_utc": "2026-01-30 10:49:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ljm2l",
              "author": "Rare-Hotel6267",
              "text": "Every time i try a stealth or free model on either cline, roo, or killo, they always fail so miserably that i uninstall them until the next free promotion, then the same happens again",
              "score": 4,
              "created_utc": "2026-01-30 13:21:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2l13lx",
              "author": "Rubbeman",
              "text": "@hannesrudolph crying in his sleep",
              "score": 0,
              "created_utc": "2026-01-30 11:14:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2r3rkj",
          "author": "mcowger",
          "text": "Doesn’t contribute much?\n\nI think you may be missing some history.  Things that came to kilo before Roo.  \n\n* At least half a dozen providers (many that Roo still doesn’t support\n* native function calling (Roo eventually caught up here, by borrowing much of Kilo’s initial implementation). \n* automatic provider fallback \n* to do tool\n* orchestrator mode\n* system notifications \n* enterprise login / sso \n* inline price data\n* task timeline \n* got change indexing",
          "score": 3,
          "created_utc": "2026-01-31 07:13:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l7af4",
          "author": "Nulligun",
          "text": "Cause the others guys tried to charge twenty bucks a month so I could press ok while taking a shit. Fuck roo!",
          "score": 4,
          "created_utc": "2026-01-30 12:02:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2me054",
              "author": "darkwingdankest",
              "text": "BYOM",
              "score": 1,
              "created_utc": "2026-01-30 15:51:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2q1q6j",
              "author": "hannesrudolph",
              "text": "That’s free. Nice try.",
              "score": 1,
              "created_utc": "2026-01-31 02:39:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2syn5a",
          "author": "MorningFew1574",
          "text": "Even though I love Kilocode and all the new features, the extension never works in the long run. Either it spits out errors or just keeps looping in to oblivion. Kinda disappointed as they have some great features but the models even opus fails within the extension",
          "score": 1,
          "created_utc": "2026-01-31 15:40:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kkcw3",
          "author": "ahhteaahh",
          "text": "How does open code compare?",
          "score": 1,
          "created_utc": "2026-01-30 08:45:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kmqfq",
              "author": "ozzie123",
              "text": "isn't opencode is taking CLI route like Claude Code? While Kilo is more like cursor?",
              "score": 0,
              "created_utc": "2026-01-30 09:07:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ljw40",
                  "author": "Rare-Hotel6267",
                  "text": "Kilo is an extension. Opencode is cli. Cursor is ide. Claude code is cli.",
                  "score": 1,
                  "created_utc": "2026-01-30 13:23:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2n0ch9",
          "author": "trupix",
          "text": "Cline will not fade away. While others focus on tearing down competitors, Cline stays heads-down building strategic partnerships and giving back to the community through its new grant program.",
          "score": 1,
          "created_utc": "2026-01-30 17:31:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mys4g",
          "author": "neggbird",
          "text": "Kilo just worked in the way Cursor was working for me, or at least more in the direction. But Cline always felt jank. It had that sloppy open source feel of GIMP and other open source projects",
          "score": 0,
          "created_utc": "2026-01-30 17:24:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qodevm",
      "title": "Kimi K2.5 is Free in Kilo Code For One Week",
      "subreddit": "kilocode",
      "url": "https://blog.kilo.ai/p/were-making-kimi-k25-free-for-one",
      "author": "alokin_09",
      "created_utc": "2026-01-27 13:10:23",
      "score": 20,
      "num_comments": 11,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qodevm/kimi_k25_is_free_in_kilo_code_for_one_week/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o25ezzw",
          "author": "jakegh",
          "text": "Immediate errors on tool use, prompt was \"read agents.md\". \n\nC'mon, guys. Test it to check that it works in your harness before inviting people to check out.\n\n    \"model\": \"moonshotai/kimi-k2.5:free\",\n    \"details\": \"Error reading file unknown: The \\\"paths[1]\\\" argument must be of type string. Received undefined\"\n\nThen later on, when trying to compact context. Kilo was unable to recover from this after multiple tries, killing my attempt to use it with Kimi K2.5 dead.\n\n```\nKiloCode completion error: {\"error\":{\"message\":\"thinking is enabled but reasoning_content is missing in assistant tool call message at index 2\",\"type\":\"invalid_request_error\"}}\n```",
          "score": 3,
          "created_utc": "2026-01-28 03:36:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26t3r0",
              "author": "jorritposthuma",
              "text": "Come on, give them some slack. Things move so fast, and sometimes they break.",
              "score": 1,
              "created_utc": "2026-01-28 10:03:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2cvgmy",
          "author": "spaceSpott",
          "text": "really good model, been using it in a project today",
          "score": 2,
          "created_utc": "2026-01-29 04:56:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20wv3e",
          "author": "Cocoa_Pug",
          "text": "Quick question was this the Giga Potato model?",
          "score": 1,
          "created_utc": "2026-01-27 14:54:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o21scxq",
              "author": "ggGeorge713",
              "text": "Would love to know that too!",
              "score": 1,
              "created_utc": "2026-01-27 17:14:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o299jfh",
          "author": "hawkibinkman",
          "text": "Anyway to get the kilocode api key free?",
          "score": 1,
          "created_utc": "2026-01-28 18:06:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ulu82",
              "author": "Mayanktaker",
              "text": "Its free already",
              "score": 1,
              "created_utc": "2026-01-31 20:24:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2dwpte",
          "author": "dxcore_35",
          "text": "No vision capabilites!",
          "score": 1,
          "created_utc": "2026-01-29 10:11:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ulp1r",
              "author": "Mayanktaker",
              "text": "They have",
              "score": 1,
              "created_utc": "2026-01-31 20:23:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2eskzb",
          "author": "assassinofnames",
          "text": "I used it on the Kilo Code CLI for a very simple task and it sucked. Couldn't make a few changes to a React TSX file. Couldn't fix TypeScript build errors and tried to delete the file. I daily drive Qwen-Code CLI and GLM 4.7 on Claude Code and I've built whole projects with them. They're waay better than this.",
          "score": 1,
          "created_utc": "2026-01-29 13:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f1dg9",
              "author": "pjcdz",
              "text": "same over here",
              "score": 1,
              "created_utc": "2026-01-29 14:39:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qocqdo",
      "title": "Kimi k2.5",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/mqbeavw80wfg1.jpeg",
      "author": "ReasonableReindeer24",
      "created_utc": "2026-01-27 12:39:36",
      "score": 17,
      "num_comments": 5,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qocqdo/kimi_k25/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o20klyn",
          "author": "ObeyTheRapper",
          "text": "It's one of the best open weight models. My only criticism is that in Kilo, if something doesn't go exactly right (like a tool call fails) it tends to give up pretty quickly instead of trying a different way.",
          "score": 3,
          "created_utc": "2026-01-27 13:53:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20q6u0",
          "author": "Zulfiqaar",
          "text": "Is this giga potato?",
          "score": 2,
          "created_utc": "2026-01-27 14:21:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20qgo5",
              "author": "ReasonableReindeer24",
              "text": "kimi k2.5 free on kilo with same name",
              "score": 3,
              "created_utc": "2026-01-27 14:23:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2k2631",
              "author": "No_Key5701",
              "text": "giga potato is most likely doubao seed code",
              "score": 2,
              "created_utc": "2026-01-30 06:10:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o240hnw",
          "author": "bytesnbobs",
          "text": "Keep getting loads of 400 errors but when it works it's pretty fast and accurate so far",
          "score": 1,
          "created_utc": "2026-01-27 23:12:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp19gi",
      "title": "OpenAI ChatGPT Plus/Pro works really well in Kilo",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qp19gi/openai_chatgpt_pluspro_works_really_well_in_kilo/",
      "author": "Cocoa_Pug",
      "created_utc": "2026-01-28 04:22:37",
      "score": 10,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I’ve had ChatGPT Plus for a while and I typically use the chat bot for just my daily chats. I started using Kilo a few months ago and fell in love but mainly used the Sonnet via Bedrock with my AWS account (which gets pricey) or GLM from the ZAI coding plan. \n\nI tried Codex 5.2 and it does a really good job in Kilo and I’m glad I can save on token costs now too. \n\nI also like o3 for architect mode. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qp19gi/openai_chatgpt_pluspro_works_really_well_in_kilo/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o26km9y",
          "author": "GodAtum",
          "text": "How do you tell how many tokens you have left?",
          "score": 2,
          "created_utc": "2026-01-28 08:44:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2bmcyq",
          "author": "RedditSellsMyInfo",
          "text": "Do you have issues with roles and backend prompts that Kilo injects? It created some issues for me. Felt a bit over engineered and caused a few issues",
          "score": 1,
          "created_utc": "2026-01-29 00:36:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq8vva",
      "title": "Was Cline just acqui-hired by OpenAI?",
      "subreddit": "kilocode",
      "url": "https://blog.kilo.ai/p/cline-just-acqui-hired",
      "author": "alokin_09",
      "created_utc": "2026-01-29 13:42:35",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qq8vva/was_cline_just_acquihired_by_openai/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o2k8uj1",
          "author": "1993s-Batman",
          "text": "Yes, that seems to be the case.",
          "score": 1,
          "created_utc": "2026-01-30 07:04:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnvplm",
      "title": "MODEL_NO_TOOLS_USED",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qnvplm/model_no_tools_used/",
      "author": "mixoadrian",
      "created_utc": "2026-01-26 22:46:10",
      "score": 9,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "https://preview.redd.it/b5ttmgczurfg1.png?width=672&format=png&auto=webp&s=89065caf61814168057b7bbce9e22e9e23caef26\n\n1. deepseek-r1:14b\n2. glm4:latest\n3. codellama:13b-instruct\n4. llama3.1:8b\n5. deepseek-r1:8b\n6. deepseek-coder-v2:latest\n7. devstral-small-2:latest\n8. gemma2:2b\n9. gpt-oss:latest\n10. qwen3:32b\n11. deepseek-coder:33b\n12. gemma3:12b\n13. mistral-nemo:latest\n14. llama3.1:latest\n15. qwen3-coder:30b\n\nthe above are the models i got, ran with ollama.  \nit seemed none of them work with kilo code, will alwaus run into error MODEL\\_NO\\_TOOLS\\_USED after a few interactions.\n\nfor each Architect, Code, Debug, Orchestral modes, which should i pick that would acutally work? any other opensource model i should use instead? \n\nThis is frustrating. Or I also tried to switch to use openai competible as provider with same models, same result.\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qnvplm/model_no_tools_used/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1xwwfu",
          "author": "FutureHack007",
          "text": "It could be that your models are degrading into those types of errors when context is managed carefully. Try using the Orchestrator mode to break the task into subtasks with small scope to keep the AI model context small. Most open weight models have small context windows that must be managed carefully, especially when running locally.\n\nChoosing a context size is a model load time parameter (Check Ollama docs). In most cases it's better to use lower quantization models to free up VRAM for the correct context size for the task. Local models do work, especially if they are trained for tool use. Try using the GLM 4.7 Flash model if you have the hardware to run it.",
          "score": 3,
          "created_utc": "2026-01-27 02:18:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xxrab",
              "author": "mixoadrian",
              "text": "I already do exactly that and still won’t work. Even in orchestra mode it tried to do some tool calling that fails. However if I pick the very same model on cloud and provider set to use kilo gateway, it works. So I am curious if there’s some api calls that  aren’t recognised by ollama or sth else I missed.",
              "score": 1,
              "created_utc": "2026-01-27 02:23:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o23c47w",
                  "author": "FutureHack007",
                  "text": "I occasionally use Kilo Code with local models (Qwen3 Coder, GPT-OSS-20B, GLM 4.7 Flash) via LM Studio (which I find more usable than Ollama) and it works well. Tuning your model load and inference parameters is the secret to success. Also, use models that are trained for tool use\n\nhttps://preview.redd.it/3a28w3mtkyfg1.png?width=868&format=png&auto=webp&s=e566c8f202eb8692b81c392c4541c0a766215522\n\n",
                  "score": 1,
                  "created_utc": "2026-01-27 21:18:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1xq0a4",
          "author": "Aggressive_Special25",
          "text": "Should have spoken to me before you did all those tests\nI find the same happening to me.....",
          "score": 2,
          "created_utc": "2026-01-27 01:40:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xsbpu",
              "author": "mixoadrian",
              "text": "I just started trying to use kilo, so I don’t know if it’s just me or local LLMs(ollama) never have worked, unless everyone else using cloud models? I also tried switching provider setting to OpenAI compatible api to load ollama, back in some said that might work but no they don’t. Did you find any fixes yet? Have the local models worked on your machine before?",
              "score": 1,
              "created_utc": "2026-01-27 01:53:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o207sm8",
                  "author": "Aggressive_Special25",
                  "text": "No local models don't work for me through kilo code. It generates rubbish. If I speak to the Ai and copy the code it produces its fine. But open source models through kilo code don't work for me.",
                  "score": 1,
                  "created_utc": "2026-01-27 12:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1z1m0v",
          "author": "msrdatha",
          "text": "Try running the models with llama.cpp and see if it helps.",
          "score": 1,
          "created_utc": "2026-01-27 06:40:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23bdsv",
              "author": "FutureHack007",
              "text": "Or LM Studio, which is an awesome front-end to llama.cpp (better than Ollama IMHO)",
              "score": 1,
              "created_utc": "2026-01-27 21:15:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o244rsr",
                  "author": "[deleted]",
                  "text": "Agreed, LM studio is pretty goated and the UI is pretty nice tbh, no complaints I can think of.",
                  "score": 1,
                  "created_utc": "2026-01-27 23:34:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2at8ve",
          "author": "Muted-Celebration-47",
          "text": "try glm4.7 flash",
          "score": 1,
          "created_utc": "2026-01-28 22:10:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2t9c6r",
              "author": "FutureHack007",
              "text": "I told a cloud frontier model my tech stack and asked it for ideal user provided model parameters (temperature, top\\_p, top\\_k, etc.) and to create an AI model benchmark that tests my coding model for hallucinations, syntax, code concepts, etc. I then ran that benchmark against GLM 4.7 Flash Q6 on LM Studio, took the output and fed it back to the cloud frontier model to judge which uncovered some concerning results. I then fed the same benchmark to cloud GLM 4.7 (non-flash), and it came back wits encouraging results (it scored higher than Kimi K2.5 also). Unless you have boatloads of VRAM to run unquantized local models, expect some loss in quality and compensate with tools that enforce listing, formatting, coding standards, etc. ",
              "score": 1,
              "created_utc": "2026-01-31 16:32:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqgnz0",
      "title": "kimi k2.5  Provider Error · 400",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/u2ejiy9zzbgg1.jpeg",
      "author": "korino11",
      "created_utc": "2026-01-29 18:26:49",
      "score": 9,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qqgnz0/kimi_k25_provider_error_400/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2h5413",
          "author": "Infamous-Elk-6825",
          "text": "same",
          "score": 2,
          "created_utc": "2026-01-29 20:26:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i40lq",
          "author": "djme2k",
          "text": "me too same problem",
          "score": 2,
          "created_utc": "2026-01-29 23:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2irif4",
          "author": "gchello921",
          "text": "same",
          "score": 2,
          "created_utc": "2026-01-30 01:24:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2izstr",
          "author": "Scott_Malkinsons",
          "text": "Working again, for me at least.",
          "score": 2,
          "created_utc": "2026-01-30 02:10:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lri8c",
          "author": "Reudiga",
          "text": "Yeah, it's not usable... It's really pointless to offer Kimi for free for a week if it doesn't work.",
          "score": 2,
          "created_utc": "2026-01-30 14:03:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qgb8i",
          "author": "AdResident780",
          "text": "Same here! It says try again after some time.",
          "score": 2,
          "created_utc": "2026-01-31 04:10:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gizyp",
          "author": "korino11",
          "text": "https://preview.redd.it/vf6udbkr2cgg1.jpeg?width=529&format=pjpg&auto=webp&s=d0947c3d068ec3701a76d636dfbc0a2054784f96",
          "score": 1,
          "created_utc": "2026-01-29 18:42:13",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2kl54g",
              "author": "LigiaZanchet",
              "text": "Hello u/korino11   \nThanks for sharing the screenshot.  \nWhat’s happening is **context overflow**. The model you’re using (`moonshotai/kimi-k2.5:free`) has a **hard context limit (\\~262k tokens)**, and your current session is exceeding that because **too many / too large files are open and being indexed**.  \n  \nWorkaround (quick fix)\n\n* Close some large files or folders you don’t need right now\n* Narrow the scope of the project (work on a subfolder instead of the whole repo)\n* Restart the session after closing files so the context is rebuilt smaller\n\nOnce the active context drops below the model limit, the error goes away.",
              "score": 2,
              "created_utc": "2026-01-30 08:53:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2lzv4y",
                  "author": "korino11",
                  "text": "No it doesnt! Becouse ALL that exacly i have done on a KIMI CLi. Same model...same tasks, same files. Problem in kilo",
                  "score": 1,
                  "created_utc": "2026-01-30 14:45:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2inqlf",
          "author": "Embarrassed_Bread_16",
          "text": "tbh im having same problem, the thing is kilo code doesnt allow for changing name in anthropic provider, so im using roo code until they solve it, i dont encounter errors\n\nhttps://preview.redd.it/5fpwc2xoydgg1.png?width=543&format=png&auto=webp&s=b9166c02c160634788c41090300e4c2611b815d9",
          "score": 1,
          "created_utc": "2026-01-30 01:03:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kllrh",
          "author": "LigiaZanchet",
          "text": "Hello everyone, I apologize for the issues you’re experiencing.   \nIf anyone encounters an error **different from the one shared in the thread.**  \nThis will help me understand the situation better and assist you more quickly.\n\nFor context: our team is actively working on **Kimi K2** to make the experience more stable and predictable.  \nReally appreciate everyone flagging issues and helping us improve this.  \n Thanks!",
          "score": 1,
          "created_utc": "2026-01-30 08:57:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wfnpd",
          "author": "ChickenShieeeeeet",
          "text": "Same issue",
          "score": 1,
          "created_utc": "2026-02-01 02:19:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qm918f",
      "title": "Sonnet 4.5 with 1 milions context windows",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qm918f/sonnet_45_with_1_milions_context_windows/",
      "author": "ReasonableReindeer24",
      "created_utc": "2026-01-25 04:20:45",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "it this model good for long coding task?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qm918f/sonnet_45_with_1_milions_context_windows/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1ko8wr",
          "author": "Cocoa_Pug",
          "text": "I thought it only had the 200k context window? I’ve only used it through Kilo Gateway and AWS bedrock. \n\n\nI do feel like almost every model degrades in quality when it passes around 100k tokens in context.",
          "score": 3,
          "created_utc": "2026-01-25 06:19:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kwre0",
              "author": "ReasonableReindeer24",
              "text": "yeah , from kilo gateway with 1m token for sure",
              "score": 2,
              "created_utc": "2026-01-25 07:28:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1lnnh7",
          "author": "Unlucky_Quote6394",
          "text": "I’ve been using it to create a custom LMS and, so far, it’s handling everything really well.  The 1m context window has made a massive difference and it’s one of the reasons I’ve been using Kilo",
          "score": 2,
          "created_utc": "2026-01-25 11:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1m2ked",
          "author": "kkingsbe",
          "text": "Sonnet is very expensive. I’ve been rocking glm-4.7",
          "score": 1,
          "created_utc": "2026-01-25 13:17:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1mypnl",
              "author": "ReasonableReindeer24",
              "text": "I know this but sonnet is better than glm 4.7 for complex task but not simple",
              "score": 2,
              "created_utc": "2026-01-25 16:03:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpf6nu",
      "title": "Kilo Code for JetBrains with Z.ai provider is not listing the glm-4.7-flash model",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qpf6nu/kilo_code_for_jetbrains_with_zai_provider_is_not/",
      "author": "delmicio",
      "created_utc": "2026-01-28 15:56:45",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Hi, I’m trying to use the glm‑4.7‑flash model that [Z.ai](http://Z.ai) announced a few weeks ago, but it isn’t listed in the Kilo Code integration yet. \n\n* glm-4.5\n* glm-4.5-air\n* glm-4.5-x\n* glm-4.5-airx\n* glm-4.5-flash\n* gIm-4.5v\n* gIm-4.6\n* glm-4.6v\n* glm-4.6v-flash\n* gIm-4.7\n* glm-4-32b-0414-128k\n\nI’m on the latest version of the extension. Kilo Code version: 4.150.0\n\nI want to use the fastest model available in the Enhance Prompt tool, so I’m targeting a flash model instead of the main one. \n\nDoes anyone know how to fix this? Is it officially unsupported by Kilo Code?  \n\n[version](https://preview.redd.it/klo50ksi24gg1.png?width=802&format=png&auto=webp&s=bee9c422dc2f18ab2dd9117da749412a09aa81fe)\n\n[Provider settings](https://preview.redd.it/tgab59yr34gg1.png?width=1262&format=png&auto=webp&s=4ebd0fc59ef9cd3a3d8bdab41e49c209612e9ca5)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qpf6nu/kilo_code_for_jetbrains_with_zai_provider_is_not/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o2b2kky",
          "author": "kira61",
          "text": "https://preview.redd.it/96tk4xuy66gg1.png?width=600&format=png&auto=webp&s=2fafb23aefdfcf255464170433540c38e4f3b472\n\nIt is listed for me in vscode",
          "score": 2,
          "created_utc": "2026-01-28 22:54:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2b6vym",
              "author": "delmicio",
              "text": "Sorry to be direct, but your reply is irrelevant. My issue is unrelated to VS Code; it looks like you’re looking at the Kilo Gateway, while the problem lies with the [Z.ai](http://Z.ai) provider.",
              "score": 1,
              "created_utc": "2026-01-28 23:16:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2c5qhk",
                  "author": "mcowger",
                  "text": "This is because the Zai team chose not to implement dynamic model fetching in the kilo provider, so it requires a code update.  \n\nEither they or someone else would need to contribute the manual model update or implement dynamic fetching.",
                  "score": 2,
                  "created_utc": "2026-01-29 02:22:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o299xph",
          "author": "Key-Singer1732",
          "text": "I would like to try to use the Flash or FlashX version as well, to speed up coding for faster turnaround, and let the normal GLM 4.7 do the code review",
          "score": 1,
          "created_utc": "2026-01-28 18:07:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ep1b6",
          "author": "kkingsbe",
          "text": "I’ve noticed 4.7-flash isn’t available when using the z.ai subscription through kilo. Not sure if this is the same issue",
          "score": 1,
          "created_utc": "2026-01-29 13:35:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qo1qkw",
      "title": "Crypto payments suddenly disabled",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qo1qkw/crypto_payments_suddenly_disabled/",
      "author": "DepartmentHungry7781",
      "created_utc": "2026-01-27 02:54:59",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "Hey, does anyone know why the crypto payment option suddenly disappeared? I really wanted to pay with crypto and now it’s just gone.\n\nhttps://preview.redd.it/adcht6ws3tfg1.png?width=1335&format=png&auto=webp&s=0e05514f55c9a5a96b4481d5abc5a700d188892e\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qo1qkw/crypto_payments_suddenly_disabled/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1zk9qp",
          "author": "LigiaZanchet",
          "text": "Hey! Great question.   \nHonestly, we had to make a tough call: crypto accounted for less than 1% of our total revenue. As much as we’d love to keep every payment option open, the engineering hours required to maintain it just didn't make sense compared to building features the other 99% of our users are asking for.\n\nWe’re keeping an eye on the space, though. If the demand picks back up, we’re definitely open to revisiting it.",
          "score": 3,
          "created_utc": "2026-01-27 09:27:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqu7lh",
      "title": "Parallel Agents - VS Code",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qqu7lh/parallel_agents_vs_code/",
      "author": "Knight_of_Valour",
      "created_utc": "2026-01-30 03:25:53",
      "score": 6,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Hey guys,\n\nI am using Kilo (VS code) daily for at least 5 months now and I really like it. The navigation between sessions is very smooth and the facility to create custom agents makes the workflow much easier. Context compact also is very intuitive.\n\nHowever, clearly the product is limited by the incapacity to execute these agents in parallel. For my use case, this is a bottleneck. Even for lighter users, the speed that this adds, taking into consideration the models with XThinking, is a huge win for the UX.\n\nI'm not saying that everything have to be parallelized, but at least the context gathering could be. \n\nDoes anyone know if there is a forecast to add this feature of parallel execution?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qqu7lh/parallel_agents_vs_code/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o2jij0b",
          "author": "Solonotix",
          "text": "I believe there is an Orchestrator mode you can install from the marketplace. I never used it, but I remember seeing it as an option. This was before Cursor came out with its worktree-oriented parallel workers, so it stood out to me back then as a novel approach.\n\nThat said, I think Cursor specifically has the right idea for parallel workers, by keeping them isolated to their own separate branches. Otherwise, there is a high chance of the parallel agents stepping on each others' work",
          "score": 2,
          "created_utc": "2026-01-30 03:56:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lbzq5",
          "author": "Chaosblast",
          "text": "I have been using Orchestrator recently to use their agent mode. But tbh I found it quite confusing, hard to trace, and it makes me lose track of the main task, which is important. I don't like it that much and struggle to see the benefit of it.\n\nI feel inclined to try Claude Code or Codex and see if they handle it better.\n\nAnswering your question, I think you're missing the Orchestrator mode. Look for it in the settings. It does what you're asking.",
          "score": 1,
          "created_utc": "2026-01-30 12:35:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2o24jv",
              "author": "Knight_of_Valour",
              "text": "Hello there. Actually im talking about the orchestrator. It can't handle parallel agents nust sequential ones",
              "score": 1,
              "created_utc": "2026-01-30 20:20:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ofx2o",
                  "author": "Chaosblast",
                  "text": "Ah yeah, maybe you're right. It really feels like it's sequential indeed. And very messy imho.",
                  "score": 1,
                  "created_utc": "2026-01-30 21:25:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2lvkr9",
          "author": "hlacik",
          "text": "You are in vscode you can open multiple vscode windows of same workspace..\n\nThat allows you to run kilocode on same codebase in parallel",
          "score": 1,
          "created_utc": "2026-01-30 14:24:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2o1vea",
              "author": "Knight_of_Valour",
              "text": "I do already do that. That is not the problem. The orchestrator model do not handle parallel agents.",
              "score": 1,
              "created_utc": "2026-01-30 20:19:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2on5y4",
                  "author": "hlacik",
                  "text": "[https://kilo.ai/features/parallel-agents-ide](https://kilo.ai/features/parallel-agents-ide)",
                  "score": 2,
                  "created_utc": "2026-01-30 22:00:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rwznx",
          "author": "involvex",
          "text": "Tried cli --parallel command . My cli got stuck , was not able to  close with ctrl c or escape or anything. After rebooting my terminal and node ( I waited for like 15 min, thought  it might is working but ui froze) , I had a git worktree in a random as folder  . ( That was a clean copy of my repo but with missing some hooks I believe) But the worktree was untouched/ edited . \n\nNow I have a worktree that is somehow buggy and I was scared to delete the folder .  Unsure about the parallel mode",
          "score": 1,
          "created_utc": "2026-01-31 11:46:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k9nqx",
          "author": "iru786",
          "text": "I am testing kilo code as well for vibe coding and I see that they have implemented similar option now. However it's only when you select agent manager and from there you can select the number of workers. The max limit is 4 at the moment.\nTo be honest, I have not tried the functionality as yet.",
          "score": 0,
          "created_utc": "2026-01-30 07:11:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr3sni",
      "title": "Introducing Local Code Reviews: One Click from Your IDE",
      "subreddit": "kilocode",
      "url": "https://blog.kilo.ai/p/introducing-local-code-reviews-one",
      "author": "alokin_09",
      "created_utc": "2026-01-30 12:13:36",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qr3sni/introducing_local_code_reviews_one_click_from/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o2mbqo9",
          "author": "lilbittygoddamnman",
          "text": "Has anybody used this yet? I just switched it on this morning, but haven't had a chance to use it yet. What model gives the best bang for your buck?",
          "score": 1,
          "created_utc": "2026-01-30 15:41:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mxn6b",
              "author": "zekusmaximus",
              "text": "I’m using the free giga potato model today and it seems to be working. Got this suggestion which was helpful and something I wouldn’t have thought of:\n\nSUGGESTION: Add aria-label to checklist items for better accessibility\n\nConsider adding descriptive aria-labels to checklist items to improve accessibility for screen reader users. The current implementation only shows a ✓ or ✗, which doesn't provide context about what each item represents.",
              "score": 1,
              "created_utc": "2026-01-30 17:18:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2si8bl",
                  "author": "lilbittygoddamnman",
                  "text": "I confess, I don't even know what an aria-label is but I think I understand in the context of your post. Does the gigapotato model work pretty good? Has it leaked yet whose model this is?",
                  "score": 1,
                  "created_utc": "2026-01-31 14:13:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qm89cm",
      "title": "Selected for the OSS Sponsorship Program - NOW WHAT?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qm89cm/selected_for_the_oss_sponsorship_program_now_what/",
      "author": "FoldOutrageous5532",
      "created_utc": "2026-01-25 03:43:04",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Thrilled to get the email. I promptly complied with the requirements, which were enabling github and code reviews.  Now what? I sent an email response and haven't heard anything.  \n\nWHAT HAPPENS NOW? \n\nThanks.\n\n|Kilo OSS Sponsorship Offer|\n|:-|\n\n\n|Congratulations! You've been selected for the **Kilo OSS Sponsorship Program** at the **Seed tier**.You've been added as the **Owner** of a new Kilo Enterprise Organization. Your sponsorship includes:**• 5 Enterprise Seats (a $9,000 value)**|\n|:-|\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qm89cm/selected_for_the_oss_sponsorship_program_now_what/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1lbcap",
          "author": "btkilo520",
          "text": "Hey @FoldOutrageous5532!\n\nIf you’ve enabled the GitHub integration and Code Reviews, you’re all set!\n\nYou can go ahead and invite up to 4 other teammates and enjoy Kilo Enterprise, which includes the features listed here:\n\nhttps://kilo.ai/docs/plans/about\n\nQuick clarification: the Seed sponsorship tier includes access to Kilo Enterprise (security features, team management, and ROI dashboards) rather than Kilo Credits.\n\nThe $9,000 figure represents the annual value of Kilo Enterprise subscription, not a credit package.\n\nApologies if that was unclear- but stay tuned for more updates on the benefits of your OSS Sponsorship Program tier soon!\n\n ",
          "score": 3,
          "created_utc": "2026-01-25 09:35:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nc2nb",
              "author": "FoldOutrageous5532",
              "text": "Oh. Thanks for the clarification. That's certainly not exciting to me as a single developer.  I don't have anyone to invite. The one thing I would use is credits, which is the one thing it doesn't include. So it's a nothing-burger for me I guess! Oh well. I was excited for a couple of days. 😜",
              "score": 1,
              "created_utc": "2026-01-25 17:00:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1nfjgf",
                  "author": "btkilo520",
                  "text": "I’d love to learn more about what we could offer outside of credits (there are many sponsored projects in the Seed tier) to get you excited again! \n\nAnother thing that I didn’t mention in my earlier response, is that we will soon promote all of our OSS-sponsored projects in a directory on our website, and to the Kilo Community (many of which are open source contributors)",
                  "score": 1,
                  "created_utc": "2026-01-25 17:15:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qn0ooq",
      "title": "How do I remove a Kilo account?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qn0ooq/how_do_i_remove_a_kilo_account/",
      "author": "Marek_Marianowicz",
      "created_utc": "2026-01-26 00:30:04",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I can't find a way to delete my account. Can someone help me with that?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qn0ooq/how_do_i_remove_a_kilo_account/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1sfgpx",
          "author": "LigiaZanchet",
          "text": "Hello u/Marek_Marianowicz,  \nPlease email [hi@kilocode.ai](mailto:hi@kilocode.ai) to request account deletion.",
          "score": 1,
          "created_utc": "2026-01-26 09:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ssfy0",
              "author": "Marek_Marianowicz",
              "text": "Thank you.",
              "score": 1,
              "created_utc": "2026-01-26 11:11:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmqc6i",
      "title": "AWS Bedrock rate limits?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qmqc6i/aws_bedrock_rate_limits/",
      "author": "GodAtum",
      "created_utc": "2026-01-25 18:03:01",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I’ve been trying to use Bedrock with Kilo but keep getting errors to do with the rate limit. What can I do?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qmqc6i/aws_bedrock_rate_limits/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1o4tks",
          "author": "Cocoa_Pug",
          "text": "What model? I’ve experienced this too with Opus via kilo and also outside of kilo using AWS bedrock. I think it’s just the way bedrock works. Maybe a quota ticket can be submitted with AWS support",
          "score": 2,
          "created_utc": "2026-01-25 19:00:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o86xa",
              "author": "GodAtum",
              "text": "Qwen3 Coder 480B A35B",
              "score": 1,
              "created_utc": "2026-01-25 19:15:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qo9b0g",
      "title": "Does Kilo support Github Copilot?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qo9b0g/does_kilo_support_github_copilot/",
      "author": "Cryptolien",
      "created_utc": "2026-01-27 09:33:48",
      "score": 3,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "I use Kilo in Cursor and wonder if Kilo can auth Github Copilot account as LLM provider to access to their models? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qo9b0g/does_kilo_support_github_copilot/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1zpsy9",
          "author": "shaonline",
          "text": "Sadly no, I think they generally don't implement any Oauth stuff for providers.",
          "score": 1,
          "created_utc": "2026-01-27 10:18:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22ox24",
              "author": "rmaxdev",
              "text": "Is it a limitation or their side or providers ?",
              "score": 1,
              "created_utc": "2026-01-27 19:34:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o22pef0",
                  "author": "shaonline",
                  "text": "It's all on KiloCode, open source projects like OpenCode have Oauth implementations for Copilot or OpenAI ChatGPT subscriptions (for Codex).",
                  "score": 1,
                  "created_utc": "2026-01-27 19:36:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o231h05",
          "author": "LigiaZanchet",
          "text": "Hey Cryptolien   \nNot yet! We don't currently support GitHub Copilot as an LLM provider. I've passed this along to the team. Thanks for the suggestion!",
          "score": 1,
          "created_utc": "2026-01-27 20:30:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28xltv",
              "author": "mcowger",
              "text": "Yes you do.  That’s exactly what the VSCode LM  provider achieves.  \n\nhttps://kilo.ai/docs/ai-providers/vscode-lm",
              "score": 1,
              "created_utc": "2026-01-28 17:14:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2dly46",
                  "author": "LigiaZanchet",
                  "text": "Thanks, Matt!",
                  "score": 1,
                  "created_utc": "2026-01-29 08:31:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qr68xo",
      "title": "Kimi K2.5 is ultra slow",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qr68xo/kimi_k25_is_ultra_slow/",
      "author": "Reudiga",
      "created_utc": "2026-01-30 14:01:15",
      "score": 2,
      "num_comments": 22,
      "upvote_ratio": 0.67,
      "text": "Hi, i hear that we can try Kimi K2.5 as the release in Kilo code for free.\n\nSo i downloaded kilo code, trying kimi k2.5 but its so ultra slow... that is not usable for me.  \n1 Command needs 5-10 minutes for API Request... Status.\n\nWhat is that? I dont know how to try it within the 1 free week if that is so damn slow. I would never buy kilo code if that is so slow.\n\nIt's a real shame, because the day after tomorrow I have to decide what to subscribe to next, as my Github CoPilot subscription is expiring.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qr68xo/kimi_k25_is_ultra_slow/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o2ltufu",
          "author": "hlacik",
          "text": "Yeah if you check YouTube yesterday ton of so called AI vibe coders gurus made a video about kimi k2.5 being best in whole galaxy and if you are not using it your dinosaur. \n\nRewind to today and here you go , poor kimi is terribly overloaded feeding young generation with their best weather app in world",
          "score": 3,
          "created_utc": "2026-01-30 14:15:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lwg1x",
              "author": "ELPascalito",
              "text": "The free endpoint in Kilo has nothing to do with the official provider, paying customers obviously get ~100 tps depending on the provider",
              "score": 0,
              "created_utc": "2026-01-30 14:28:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2lybvf",
                  "author": "hlacik",
                  "text": "It has everything with that.\nAnd yes since kimi is open-source there are other providers. I have user chutes in past and it is terribly slow\n\nBut when we are talking about free kimi it is definitely provided by kimi provider (official provider)\n\nYou are refereing to other than official providers.\n\nOpen router is not provider but gateway to providers",
                  "score": 1,
                  "created_utc": "2026-01-30 14:38:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2lsrzw",
          "author": "Solonotix",
          "text": "Kilo Code is still preferable over GitHub CoPilot, if for nothing else than usage-based pricing. Subscriptions like Codex and Claude cost you even when not in use, even if that rate is highly subsidized. Kilo Code by contrast only bills you for usage, so I've got $50 in tokens waiting for me, rather than stressing over a $20/month subscription going to waste.",
          "score": 3,
          "created_utc": "2026-01-30 14:10:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2m52ij",
              "author": "lilbittygoddamnman",
              "text": "I'm willing to put up with some of Kilo Code's shortcomings because I find it very useful. Plus I like that I can use free models for most things.",
              "score": 3,
              "created_utc": "2026-01-30 15:10:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2n4u9x",
              "author": "Reudiga",
              "text": "Yeah but not that easy to calculate. If you just use Opus what i used before, (so thats the reason why i wanna try Kimi K2.5), than you are cheaper with Github Copilot. You reach 50$ really fast with Kilo Code what i calculated.",
              "score": 1,
              "created_utc": "2026-01-30 17:51:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2nw49i",
                  "author": "Solonotix",
                  "text": "Well sure, picking the most expensive model with reasoning is going to drain your budget rapidly. If you pick a slimmer model with lower cost, like Grok Code Fast 1 ($0.20/M input, $1.50/M output) or GLM 4.7 ($0.40/M input, $1.50/M output), then you're probably going to get a lot more per dollar spent. Looking at OpenRouter, Claude Opus 4.5 right now is $5/M input, $25/M output, so more than 10x the cost of the two I listed.\n\nIt's also important to be selective with reasoning. Some models can perform exceptionally well without reasoning. This means they may cost more per token, but they consume far fewer tokens per request than a reasoning model. Usually, I leave reasoning disabled except for things like debugging terminal output, where the added processing is justified.",
                  "score": 1,
                  "created_utc": "2026-01-30 19:52:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2lved4",
          "author": "shaonline",
          "text": "You are using the free version in which case it's not surprising, the poor thing gets overloaded. I use via OpenRouter and some providers reach 100 toks/s.",
          "score": 1,
          "created_utc": "2026-01-30 14:23:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2no1un",
              "author": "Conscious-Expert-455",
              "text": "Which OpenRouter LM do you use? Which are the best?",
              "score": 1,
              "created_utc": "2026-01-30 19:15:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2o3349",
                  "author": "shaonline",
                  "text": "As far as Kimi K2.5 goes, fireworks seems to be the best. OpenCode (not sure if I'm allowed to mention competitors here) has it for free through that very same provider for now.",
                  "score": 1,
                  "created_utc": "2026-01-30 20:24:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2m5wr4",
          "author": "ReasonableReindeer24",
          "text": "Too much usage",
          "score": 1,
          "created_utc": "2026-01-30 15:14:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mjmvb",
          "author": "RedditSellsMyInfo",
          "text": "It's been incredibly fast for me. I'm also on the Tier 2 plan which is faster. It could be a combination of their servers getting overloaded and kilo code somehow slowing it down.",
          "score": 1,
          "created_utc": "2026-01-30 16:16:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mstg0",
              "author": "Reudiga",
              "text": "Sounds good but I will but pay something if I see how slow it is.",
              "score": 1,
              "created_utc": "2026-01-30 16:57:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2r23j9",
          "author": "AppealSame4367",
          "text": "OP: \"Mimimi whree is my free fast AI!\"\n\nDid you ever outgrow kindergarden?",
          "score": 1,
          "created_utc": "2026-01-31 06:58:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2vspp7",
          "author": "Bob5k",
          "text": "Native Kimi provider is slow. I'm using [synthetic](https://synthetic.new/?referral=IDyp75aoQpW9YFt) as my main driver since they exist under the name - and as they're routing Kimi via fireworks now it's consistently hitting up to 80/90 tps for me (living in Europe so peak is at a different time than us tho). \nCan't be happier as i already did a shitload of work with Kimi.",
          "score": 1,
          "created_utc": "2026-02-01 00:05:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}