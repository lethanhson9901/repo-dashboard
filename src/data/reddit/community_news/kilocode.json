{
  "metadata": {
    "last_updated": "2026-02-22 16:47:29",
    "time_filter": "week",
    "subreddit": "kilocode",
    "total_items": 12,
    "total_comments": 50,
    "file_size_bytes": 53384
  },
  "items": [
    {
      "id": "1r5v6ul",
      "title": "hey kilo team. is this a joke?",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/q3pklwrl6rjg1.jpeg",
      "author": "Emergency-Tune32",
      "created_utc": "2026-02-16 00:42:51",
      "score": 103,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r5v6ul/hey_kilo_team_is_this_a_joke/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5m9l2z",
          "author": "zer0evolution",
          "text": "i help to upvote, hope it will resolve quickly",
          "score": 11,
          "created_utc": "2026-02-16 02:47:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ma4fm",
              "author": "Emergency-Tune32",
              "text": "thank youðŸ™",
              "score": 3,
              "created_utc": "2026-02-16 02:50:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nv6si",
          "author": "LigiaZanchet",
          "text": "Hello u/Emergency-Tune32  \nFirst, I want to sincerely apologize for the disturbance and the delay in getting back to you. We encountered some technical issues with the **Kilo Pass** system yesterday. While we were able to resolve the root cause within the same day, I know it was frustrating to see your credits missing in the meantime. The [PR](https://github.com/Kilo-Org/cloud/pull/201), in case you want to validate. \n\n**I have just confirmed that the credits have been successfully added to your account.** Please refresh your dashboard, and you should see them reflected there now!\n\nIf anyone else is still experiencing issues with their Kilo Pass credits, please don't hesitate to reach out to us directly at [**hi@kilocode.ai**](mailto:hi@kilocode.ai) so we can look into your specific account manually.\n\nThank you for your patience and for being a day-one subscriber! ðŸš€",
          "score": 9,
          "created_utc": "2026-02-16 10:45:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nwnd7",
              "author": "Emergency-Tune32",
              "text": "still dont get the 50% bonus, nothing changed",
              "score": 1,
              "created_utc": "2026-02-16 10:58:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5nxjly",
                  "author": "LigiaZanchet",
                  "text": "Hey u/Emergency-Tune32 I took a look at your account! Just to clarify how the **Kilo Pass** works: your 50% bonus credits are automatically applied **after** your base credits are fully used for the month.  \nSince you still have a balance of base credits remaining, the bonus hasn't been unlocked yet. Once those hit zero, your free bonus credits will be automatically applied. ",
                  "score": 5,
                  "created_utc": "2026-02-16 11:06:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5myqlr",
          "author": "MaybeDisliked",
          "text": "They've resolved it for me, seems like a wide spread issue. Think they are fixing this!",
          "score": 3,
          "created_utc": "2026-02-16 05:47:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nif6x",
          "author": "SourceCodeplz",
          "text": "Ridiculous! You'd think they would write some tests and catch \"edge\" cases like this?",
          "score": 3,
          "created_utc": "2026-02-16 08:44:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m6xfv",
          "author": "thejinx0r",
          "text": "The 50% bonus was a first month promo. \n50% bonus are for yearly.\nThe bonus increases monthly until +40%",
          "score": 1,
          "created_utc": "2026-02-16 02:29:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5m87ve",
              "author": "Emergency-Tune32",
              "text": "https://preview.redd.it/08o4h247rrjg1.jpeg?width=1179&format=pjpg&auto=webp&s=9219008ac4ca9cfe5b452366ec35a190b118ead7",
              "score": 6,
              "created_utc": "2026-02-16 02:38:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5mbe27",
                  "author": "thejinx0r",
                  "text": "That sucks. \nI had asked support when I signed up and they said it would be automatic. If it wasn't automatic to reach back out",
                  "score": 1,
                  "created_utc": "2026-02-16 02:58:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5v5hno",
          "author": "MrKBC",
          "text": "Slowly but surely the subscription based AI IDEs will start to crumble...",
          "score": 0,
          "created_utc": "2026-02-17 13:48:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8csw7",
      "title": "Kilo Gateway is now open for any appâ€”heres what happened to usage",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/7lammabs1bkg1.png",
      "author": "brennydenny",
      "created_utc": "2026-02-18 19:32:16",
      "score": 35,
      "num_comments": 12,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r8csw7/kilo_gateway_is_now_open_for_any_appheres_what/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o644pku",
          "author": "Peregoon",
          "text": "I installed Kilo extension in Antigravity after I got locked up into 7 days quota prison for Gemini Pro and Claude and so far I tried GLM5 and it was a good experience, little slow at times but good.",
          "score": 3,
          "created_utc": "2026-02-18 20:00:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64giic",
          "author": "ChauPelotudo",
          "text": "I don't use kilo but got this thread recommended. Is this like openrouter? Can you choose different providers?\n\nEdit: Regarding cache, I'm seeing   \nCache Read Price: $0.00 per 1M tokens. Is that correct? cache read is free?",
          "score": 2,
          "created_utc": "2026-02-18 20:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65i7rs",
          "author": "Competitive-Baby-231",
          "text": "Honestly? Thank you. Its been a blessing.",
          "score": 2,
          "created_utc": "2026-02-19 00:01:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69dszd",
          "author": "QazaqMarketing",
          "text": "Nice! Is it possible to use it in Openclaw?",
          "score": 2,
          "created_utc": "2026-02-19 16:01:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69ijvb",
              "author": "mcowger",
              "text": "Yup!",
              "score": 2,
              "created_utc": "2026-02-19 16:24:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bjhh7",
              "author": "brennydenny",
              "text": "Yes - check out [https://blog.kilo.ai/p/kilo-gateway-supercharges-moltbot-fka-clawdbot?utm\\_source=publication-search](https://blog.kilo.ai/p/kilo-gateway-supercharges-moltbot-fka-clawdbot?utm_source=publication-search) \n\nAnd coming soon: [https://github.com/openclaw/openclaw/pull/20212](https://github.com/openclaw/openclaw/pull/20212)",
              "score": 2,
              "created_utc": "2026-02-19 22:15:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6411sa",
          "author": "Zyj",
          "text": "What models gained the most?",
          "score": 1,
          "created_utc": "2026-02-18 19:43:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o641evx",
              "author": "brennydenny",
              "text": "Unsurprisingly mostly the free ones! [https://kilo.ai/leaderboard#daily](https://kilo.ai/leaderboard#daily)",
              "score": 2,
              "created_utc": "2026-02-18 19:45:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o650a94",
          "author": "hiddenswordmastaa",
          "text": "Finally! I stopped using GUI extensions for vibing since I'm constantly switching between different IDE's, and I use a vertical monitor setup which shrinks down the horizontal space even further (maybe considerable as a feature request?), and kilo cli is not mature enough compared to opencode. Also openclaw usage with kilo gateway is another point of freedom as well. This is a huge win for me!",
          "score": 1,
          "created_utc": "2026-02-18 22:27:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o651jxh",
              "author": "hiddenswordmastaa",
              "text": "Oh, I guess I haven't installed the latest version of kilo cli, now it seems like it matched with latest opencode nvm, my mistake",
              "score": 4,
              "created_utc": "2026-02-18 22:33:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o66zynk",
          "author": "Mayanktaker",
          "text": "You mean we can use this in copilot via openai extension?",
          "score": 1,
          "created_utc": "2026-02-19 05:30:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69in2y",
          "author": "mcowger",
          "text": "The only thing missing from kilogateway now is proper messages and embeddings pass through.",
          "score": 1,
          "created_utc": "2026-02-19 16:24:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r77zru",
      "title": "Grok Code Fast 1 is back, itâ€™s optimized, and itâ€™s free in Kilo for a limited time.",
      "subreddit": "kilocode",
      "url": "https://blog.kilo.ai/p/grok-code-fast-optimized",
      "author": "alokin_09",
      "created_utc": "2026-02-17 14:49:36",
      "score": 25,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r77zru/grok_code_fast_1_is_back_its_optimized_and_its/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o5vjg24",
          "author": "MultiBotRun",
          "text": "It was one of the best surprises Iâ€™ve ever had with an LLM. Excellent results and very fast. When it was free, I used it all the time, and I even continued after it became paid. This is a fantastic surprise. Congratulations, KiloCode.\n\nI also ran real tests comparing Grok Code Fast 1 with zml 4.7, kimi 2.5, qwen3 coder next, and minimax-m2.1. I gave all of them the exact same task: build a production-ready FastAPI Python API with full CRUD, JWT authentication, role-based authorization, Pydantic validation, modular structure, security best practices, rate limiting, CORS, password hashing, and a final security checklist.\n\nGrok was the only one that delivered fully working code. All the others had errors, and in many cases, not easy ones to fix. For real development work, the difference was huge.",
          "score": 5,
          "created_utc": "2026-02-17 15:02:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vkqow",
              "author": "Connect_Nerve_6499",
              "text": "do you use different models for different agents, did you use orchestration mode for that ?\n\n",
              "score": 1,
              "created_utc": "2026-02-17 15:09:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xuxvf",
                  "author": "MultiBotRun",
                  "text": "Just a same prompt in kilocode Architect/Code with each LLM.   \nI wanted to measure the number of tokens used, the cost, the time taken, and the quality of the generated code. ",
                  "score": 1,
                  "created_utc": "2026-02-17 21:42:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xuo7b",
          "author": "noctrex",
          "text": "So if they changed it, shouldn't it be called Grok Code Fast 2 ?\n\nI'll never understand these companies who update their models and don't change the version numbers.",
          "score": 1,
          "created_utc": "2026-02-17 21:40:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o617f0b",
              "author": "MultiBotRun",
              "text": "Kilocode optimized Grok Code Fast 1 purely via inference-time test-time compute scaling (dynamic compute allocation per request), is not an official xAI update.",
              "score": 1,
              "created_utc": "2026-02-18 11:02:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o67hzcd",
          "author": "Mayanktaker",
          "text": "Its gone now.",
          "score": 1,
          "created_utc": "2026-02-19 08:04:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra4wun",
      "title": "Mixed feelings",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/xx1oy75t8pkg1.png",
      "author": "Complex-Concern7890",
      "created_utc": "2026-02-20 19:26:59",
      "score": 12,
      "num_comments": 14,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1ra4wun/mixed_feelings/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6hf9t6",
          "author": "Diligent_Net4349",
          "text": "> cheap models\n\nimo with ChatGPT and Claude itâ€™s better to use the subscription. that said, Kimi / GLM have been good in my experience.",
          "score": 5,
          "created_utc": "2026-02-20 20:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ho52s",
          "author": "FutureHack007",
          "text": "GPT and Anthropic subscriptions are a great deal because they subsidize inference cost to achieve tool lock-in. Development tool evolution is moving fast and many developers are jumping from tool to tool when they leapfrog each other. Anthropic has started prohibiting model use from anything other than Claude Code. Food for thought. Meanwhile, you can enjoy the freedom of unlimited frontier open-weight models for $8/mo. (Nano-GPT subscription) AND get to jump to newer models at a faster rate (e.g. K2.5 last week, GLM 5 this week).",
          "score": 1,
          "created_utc": "2026-02-20 20:55:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6j6ibe",
              "author": "HornyEagles",
              "text": "People need to stop recommending Nano-GPT in its current state of play. Its NOT reliable for coding with any of these tools. Youâ€™re better off PAYG. Iâ€™m holding people accountable for sharing nano GPT without fairly bringing up reliability concerns with that platform.",
              "score": 1,
              "created_utc": "2026-02-21 01:57:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6lalyg",
                  "author": "_mannen_",
                  "text": "Feel free to share your concerns so that we can learn.Â ",
                  "score": 1,
                  "created_utc": "2026-02-21 12:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ilqy6",
          "author": "Medical-Diver-4601",
          "text": "I wonder if it is a Kilo Code issue or just the fact that you are using the API key and not subscription. Itâ€™s well known that those providers subsidize subscriptions. The question is whether another tool using API token (Claude Code, Open Code, etc) would have resulted in the same cost for the same task.",
          "score": 1,
          "created_utc": "2026-02-20 23:52:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6k517y",
              "author": "dsvost",
              "text": "Yeah, 2.8m input tokens is not small. Kilo Code has a known specific by putting way more stuff into context. There is orchestration pattern was published here somewhere by one of Kilo Code maintainers or developers which probably can help reduce context usage. And i did try compare with OpenCode results on similar tasks and they were kinda similar. So, my conclusion that Kilo Code can be really good for really bigger complex tasks, otherwise cost if PAYG is not justified. I really think Kilo Code just need introduce something like \"Lite mode\" where what they put in context is greatly decreased.",
              "score": 2,
              "created_utc": "2026-02-21 05:59:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6nutq1",
          "author": "SnooPickles6818",
          "text": "They have nice prompts inside, but nothing really stops you from taking that prompts and using them as commands in any other IDE. They works as good for me in opencode, but somehow consume at least 10 times less tokens. And you can connect your copilot or ChatGPT Plus subscription there.Â \nYou can easily ask model to rephrase prompt in any AI, or make a dedicated command for it, or just put rephrasing as basic instruction.\n\nSomething in kilocode makes it burn tokens as hell, compared to copilot, opencode or Claude code\n\n",
          "score": 1,
          "created_utc": "2026-02-21 20:50:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q8r0i",
          "author": "Alarming_Low4014",
          "text": "why not use KiloCode Gateway API?",
          "score": 1,
          "created_utc": "2026-02-22 05:55:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qi4rz",
          "author": "crusoe",
          "text": "Kilocode has poor token efficiency.",
          "score": 1,
          "created_utc": "2026-02-22 07:20:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hbb6h",
          "author": "alexeiz",
          "text": "Try to do this change yourself and see how long it takes you.  Then you can decide if the time you saved was worth $6.\n\nGiven the number of changed lines (+202 -4), it's a pretty big change.",
          "score": 1,
          "created_utc": "2026-02-20 19:52:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6he8nx",
              "author": "Complex-Concern7890",
              "text": "I do not disagree. I would be ready to pay 10x for this kind of capabilities without question. The question however was compared to GitHub Copilot or ChatGPT subscriptions which offer around 10 - 20 times more with the same price and how Kilo Code can compete with that? I am sure that in future they will 10x their subscriptions as it would align the value and the business costs, but for now Kilo Code seems like a bad deal. I understand the free and really cheap Chinese model paradigm where Kilo Code is perfect, but against Claude, Codex, Copilot, there does not seem to be any play?",
              "score": 3,
              "created_utc": "2026-02-20 20:06:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6hfzg4",
              "author": "Tank_Gloomy",
              "text": "202 lines is supposed to be a big change? .-.",
              "score": 0,
              "created_utc": "2026-02-20 20:14:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hj6xa",
                  "author": "alexeiz",
                  "text": "You've ever written code yourself?",
                  "score": 2,
                  "created_utc": "2026-02-20 20:30:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r70a0c",
      "title": "Annoying Kilo ads",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1r70a0c/annoying_kilo_ads/",
      "author": "Mayanktaker",
      "created_utc": "2026-02-17 08:08:14",
      "score": 11,
      "num_comments": 12,
      "upvote_ratio": 0.83,
      "text": "I am seeing annoying kilo code ads all over reddit and instagram too. Mostly about GLM 5. the funny part is that i still cant use free glm 5 on kilo because i am getting rate limit error for my kilo code api. but other free and paid models working fine. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r70a0c/annoying_kilo_ads/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o5ub445",
          "author": "McKing_07",
          "text": "well, would you look at that :')\n\nhttps://preview.redd.it/02g0wurr31kg1.jpeg?width=1440&format=pjpg&auto=webp&s=80ee8b8aefacab41c842753cec4b821ce8de17c7",
          "score": 9,
          "created_utc": "2026-02-17 10:04:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ubo08",
              "author": "Mayanktaker",
              "text": "ðŸ˜¹ðŸ˜¹ðŸ˜¹ðŸ˜¹ðŸ˜¹",
              "score": 2,
              "created_utc": "2026-02-17 10:09:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vzwxi",
          "author": "alexeiz",
          "text": "I learned today that they have grok-code-fast-1 for free again.  So their ads are not completely useless. They actually try to stay relevant.",
          "score": 6,
          "created_utc": "2026-02-17 16:23:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5z8t8b",
              "author": "Medical-Diver-4601",
              "text": "Nice. Iâ€™ve been using that model with an API key using the xAI provider. For some reason, it doesnâ€™t work for me with BYOK through Kilo Gateway. How do I use it for free?",
              "score": 1,
              "created_utc": "2026-02-18 02:04:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o609oxp",
                  "author": "alexeiz",
                  "text": "> How do I use it for free?\n\nJust choose that model in Kilo.\nhttps://blog.kilo.ai/p/grok-code-fast-optimized",
                  "score": 1,
                  "created_utc": "2026-02-18 06:00:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5w3ppj",
          "author": "Tank_Gloomy",
          "text": "Brother, it's free, it's not meant for you to build a full product and ship to prod, it's just to let you try it out and see if it'd work out on your workflow.",
          "score": 2,
          "created_utc": "2026-02-17 16:43:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ycxpb",
              "author": "Ironhelmet44",
              "text": "What do you suggest for building prod ready products then",
              "score": 1,
              "created_utc": "2026-02-17 23:12:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u8r8u",
          "author": "SnooGuavas1875",
          "text": "Fill out the issue for Kilo Code, because they don't scan Reddit 24/7.",
          "score": 1,
          "created_utc": "2026-02-17 09:43:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5u8w2z",
              "author": "Mayanktaker",
              "text": "They do. And that's what i like.",
              "score": 1,
              "created_utc": "2026-02-17 09:44:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ufb78",
                  "author": "LigiaZanchet",
                  "text": "Hey u/Mayanktaker. Really sorry about the ads.  \n  \nAbout those rate limits, our thresholds are generally high, so most users donâ€™t run into them.   \nIâ€™m usually lurking here on Reddit, but to actually fix this, I need to see your logs.  \nIâ€™m happy to dig into this for you! Could you send a quick note to **hi@kilocode.ai**? Just mention your Reddit username so I can link the two, and Iâ€™ll jump on it immediately to see what's triggering those limits.  \nSee ya there! ðŸš€",
                  "score": 5,
                  "created_utc": "2026-02-17 10:43:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5u940j",
                  "author": "SnooGuavas1875",
                  "text": "I agree. But as a tech company, they need to track your found issue in a Jira-like system. A filled ticket is the source for it, and if it was created, they should not ignore it. (It's either a known issue, new, or not a bug.)",
                  "score": 1,
                  "created_utc": "2026-02-17 09:46:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1ralcmj",
      "title": "Over $1000 in Opus 4.6 Charges with KiloCode",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1ralcmj/over_1000_in_opus_46_charges_with_kilocode/",
      "author": "mortdiggiddy",
      "created_utc": "2026-02-21 07:53:09",
      "score": 9,
      "num_comments": 16,
      "upvote_ratio": 0.77,
      "text": "There is something very wrong with the way the charging operates on 4.6. The context window is 1M tokens, 5x that of Opus 4.5.\n\nAs the context window grows and the token usage approachâ€™s 500k, each API call gets progressively more expensive.\n\nOnce the context window reaches maybe 700k, some API calls can reach upward of $7.00 - $10.00 per call. The average instruction or task with kilo code may use anywhere from 5-10 API calls while exploring your code base.\n\nThis seems like a flaw in the metering.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1ralcmj/over_1000_in_opus_46_charges_with_kilocode/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o6kmpwz",
          "author": "noctrex",
          "text": "Every time the model makes an API call, it processes the entire conversation history, and the cost of these cache reads scales with both the context length and the number of calls. This creates aÂ **quadratic cost growth,** not linear, meaning long-running sessions become exponentially more expensive.\n\nThat's why it's better to start with a fresh context.\n\nCreate a detailed agents file that will have a correct description of the project as possible.\n\nAlso tell your model to create some diagrams to help it.\n\nHave a clear project structure and skeleton in your description and then start with a fresh context.\n\nThis will always be cheaper.\n\nI keep my context around 100-150k, on all models.",
          "score": 10,
          "created_utc": "2026-02-21 08:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ks8mg",
              "author": "robogame_dev",
              "text": "Orchestrator mode is my go-to for this.\n\nInstruct orchestrator to break out the task into small chunks for sub-agents to execute.",
              "score": 5,
              "created_utc": "2026-02-21 09:40:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6l1tku",
                  "author": "evia89",
                  "text": "I didnt liked what default does. Wish we had https://github.com/obra/superpowers\n\nThat one gets small atomic tasks in TDD red green format",
                  "score": 3,
                  "created_utc": "2026-02-21 11:13:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6l1y62",
              "author": "evia89",
              "text": "For cheaper, like glm47, I would stay under 64k",
              "score": 1,
              "created_utc": "2026-02-21 11:14:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kpfm8",
          "author": "Fair-Spring9113",
          "text": "if your going to spend 1k on opus, PLEASE PLEASE PLEASE for the love of god get a claude max 5x or 20x, they give around 13.5x the amount that api gives for the same price",
          "score": 8,
          "created_utc": "2026-02-21 09:12:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6klsdk",
          "author": "sand_scooper",
          "text": "Use Claude Max $200 Plan. Paying API pricing gets expensive very quickly!",
          "score": 7,
          "created_utc": "2026-02-21 08:36:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ksinf",
          "author": "robogame_dev",
          "text": "Sounds like somethingâ€™s wrong, you shouldnâ€™t need more than 200k context - I bet most of that context is not needed for the task. Try orchestrator mode to break out sub-agents with fresh contexts for sub-tasks.\n\nMaybe kilo knows the model can handle 1M context and its scaling all the context management thresholds up, if so, Iâ€™d turn that off and run it at a lower connect length.g",
          "score": 4,
          "created_utc": "2026-02-21 09:43:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kjzlh",
          "author": "Bob5k",
          "text": "have in mind opus is hella expensive model to just use it via paid api. ",
          "score": 3,
          "created_utc": "2026-02-21 08:18:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kii2o",
          "author": "bulbulito-bayagyag",
          "text": "Even their API is always giving 400 error. Then suddenly a sudden surge of cost after it resumes.",
          "score": 2,
          "created_utc": "2026-02-21 08:03:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ll9uj",
          "author": "higgsfielddecay",
          "text": "You must be looking at a huge existing codebase and trying to get it all into context when it explores it. If that's the case (and I've never done this) you might try having it explore and document things module by module and summarize where to find what at the top level. Make sure when it plans out tasks it figures out where it needs to touch things by walking down that documentation from the top level index. Just a thought.",
          "score": 2,
          "created_utc": "2026-02-21 13:45:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6oagpm",
          "author": "fNightmare",
          "text": "what do you expect? you are moving tons of tokens in every turn, and at 700k tokens the performance should be so bad that I wonder you are not condensing or starting new chats more often, it just degrades the experience, let alone how expensive it gets, which is your main concern",
          "score": 1,
          "created_utc": "2026-02-21 22:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ovovv",
          "author": "lundrog",
          "text": "Get a rag server / mcp and make mcp write to memory calls and then clear context and recall",
          "score": 1,
          "created_utc": "2026-02-22 00:19:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p5mv8",
          "author": "forkbomb7",
          "text": "I recommend trying out Memory Bank within Cline to help maintain context across sessions, youâ€™ll reduce costs significantly https://docs.cline.bot/features/memory-bank#memory-bank",
          "score": 1,
          "created_utc": "2026-02-22 01:20:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lad6h",
          "author": "Keep-Darwin-Going",
          "text": "Perhaps stop using kilocode? Most of this third party solution is inferior to the native one.",
          "score": -1,
          "created_utc": "2026-02-21 12:28:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6o9rha",
              "author": "fNightmare",
              "text": "this has nothing to do with kilo, if you pay per token in the api, you get charged per token",
              "score": 1,
              "created_utc": "2026-02-21 22:09:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6oozrb",
              "author": "Orinks",
              "text": "The native one is overrated. Its explore and finding capabilities are slow. Love subagents and now worktree support, has awesome features but it's not the best.",
              "score": 1,
              "created_utc": "2026-02-21 23:37:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rakxju",
      "title": "Love the free models ! Tried it out on a small Personal project I had. Would the 20$ plan be enough for this kind of usage ?",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/gieq0r4gvskg1.png",
      "author": "Asleep_Fruit_3181",
      "created_utc": "2026-02-21 07:28:02",
      "score": 8,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1rakxju/love_the_free_models_tried_it_out_on_a_small/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6khsuk",
          "author": "shaonline",
          "text": "Depends on the model's pricing, going by the ballpark estimate (input tokens * input tokens pricing) and GLM 5's input tokens pricing (currently 30 cents for some reason but typically more like $1) might be a little tough with $25-30 ish of API credits if you intend on using that model. As it stands you might get more value from a coding plan that gives a lot of API quota (e.g. Codex).",
          "score": 3,
          "created_utc": "2026-02-21 07:57:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6keun3",
          "author": "Asleep_Fruit_3181",
          "text": "Used GLM 5 Free",
          "score": 1,
          "created_utc": "2026-02-21 07:28:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6l1gpm",
          "author": "evia89",
          "text": "Codex $20 till April. If u really strapped for $ use g2a/plati.market/etc cheaper business sub ($5)\n\nthats best value imo",
          "score": 1,
          "created_utc": "2026-02-21 11:10:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6mvl74",
              "author": "adams_me",
              "text": "Business sub for which service exactly? I looked at the offers at Plati some time ago and ended up with an opinion, that all of them are less valuable than just subscribing to a provider directly, seems I wrong about this? Thanks in advance",
              "score": 1,
              "created_utc": "2026-02-21 17:51:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6mwhb6",
                  "author": "evia89",
                  "text": "https://plati.market/itm/chatgpt-5-team-plan-invite-on-you-email-30-days-bonus/5366683\n\nhttps://plati.market/itm/chatgpt-business-team-1month-gpt-5-pro-fast-invite/5564351\n\n~~https://plati.market/itm/chatgpt-go-private-account-1-year/5526345~~\n\n---\n\nMy friend used one of these",
                  "score": 1,
                  "created_utc": "2026-02-21 17:56:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6o05rk",
              "author": "Dazzling_Meaning9226",
              "text": "Codex is absolute garbage for coding. To give you a hint of how things work in codex: When you upload a file directly to the app (which is locally installed on your machine), the agent spends a good amount of output on simply \\*finding the path of the file you just uploaded\\*. So even thought you literally just \"uploaded\" the file, and the app should already have the file, not only does it \\*not have the actual file to use\\*, but it doesnt even know what it's path is. It will spend about 3 minutes running random searches on your machine to find the file.",
              "score": 1,
              "created_utc": "2026-02-21 21:18:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6o6sbo",
                  "author": "evia89",
                  "text": "It works fine. Opus46 maybe better for pure vibecoing but codex is fine. I also use much weaker model glm47 and it can do 90% tasks just fine\n\nI only code, prepare texts and RP with LLM",
                  "score": 1,
                  "created_utc": "2026-02-21 21:54:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6o8hhg",
                  "author": "adams_me",
                  "text": "Interesting, I've seen many opposing opinions in r/ClaudeCode a while ago, for [example](https://www.reddit.com/r/ClaudeCode/s/fp7fVKhUBV). Many people wrote about quitting to Codex recently, as I see (idk why every single one of them wanna notify the Claude community about this, but as is). It seems like the best solution is to test it myself and form opinion based on real tasks. Anyway, thanks for the info!",
                  "score": 1,
                  "created_utc": "2026-02-21 22:03:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6oqe53",
                  "author": "Prudent_Plantain839",
                  "text": "Nobody gives a shit about your experience with the codex app lmao how does the provided tools by some app make the entire model trash ? Ever used something sane like an tui coding program? This is some tool issue which only you experience",
                  "score": 1,
                  "created_utc": "2026-02-21 23:46:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r8ahu4",
      "title": "Is anyone actually successfully chaining OpenCode into Kilo Code without manual copy pasting?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1r8ahu4/is_anyone_actually_successfully_chaining_opencode/",
      "author": "LooseHistorian6413",
      "created_utc": "2026-02-18 18:09:00",
      "score": 6,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "Iâ€™ve been trying to optimize my agent workflow because Kilo Code takes forever to handle basic scaffolding tasks. My goal was simple: use **OpenCode** to blast out the initial project structure (since itâ€™s way faster for scaffolding) and then hand that context over to **Kilo Code** to handle the complex logic and heavy lifting.\n\nIn theory, this should be the perfect \"best of both worlds\" setup. In practice, the handoff is a nightmare.\n\nEvery time I try to bridge them, I hit friction. The context doesn't transfer cleanly, or I have to manually massage the output from OpenCode before Kilo can even understand what's going on. I eventually just give up and go back to doing it manually or sticking to one slow tool, which defeats the whole point.\n\nIâ€™m starting to feel like Iâ€™m the only one dumb enough to try this hybrid workflow.\n\n* Has anyone actually managed to get a stable pipeline running between these two?\n* Are you using a specific middleman script to format the handoff, or just raw-dogging the copy-paste like I am?\n* Or did you just try it, realize the interoperability was broken, and move on?\n\nJust trying to figure out if there is a \"clean\" way to get them to talk to each other, or if I'm just wasting my time trying to optimize this.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r8ahu4/is_anyone_actually_successfully_chaining_opencode/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o67gf69",
          "author": "jackai7",
          "text": "Have you tried /init command in kilo-cli? It summarise the project, I guess?",
          "score": 2,
          "created_utc": "2026-02-19 07:49:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65odc8",
          "author": "hlacik",
          "text": "Use kilo-cli . It's their fork of opencode with same modes as kilocode plugin uses.\n\nWhat else do you need ?",
          "score": 1,
          "created_utc": "2026-02-19 00:35:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65soc9",
              "author": "LooseHistorian6413",
              "text": "Thanks for the advice! I tried OpenCode CLI but it felt kind of intimidating. But I will give Kilo CLI a proper shot.",
              "score": 1,
              "created_utc": "2026-02-19 01:00:00",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o67gagm",
              "author": "jackai7",
              "text": "It's fork but you can't integrate oh-my-opencode into kilocli",
              "score": 1,
              "created_utc": "2026-02-19 07:48:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6h0ipq",
          "author": "FutureHack007",
          "text": "To pass task/workflow context between models and IDEs/CLIs, it can be handy to use independent scaffolding such as BMAD. It works well with the Kilo Code extension and CLI. More info here: [https://github.com/bmad-code-org/BMAD-METHOD](https://github.com/bmad-code-org/BMAD-METHOD)",
          "score": 1,
          "created_utc": "2026-02-20 19:00:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hgnf4",
          "author": "LigiaZanchet",
          "text": "Hi u/LooseHistorian6413   \nSince we are a fork of **OpenCode**, you'll find the environment familiar, but Iâ€™d highly recommend giving our **CLI** a spin!   \nCheck more about it [here](https://kilo.ai/docs/code-with-ai/platforms/cli)   \n",
          "score": 1,
          "created_utc": "2026-02-20 20:18:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63gtna",
          "author": "Fantastic-Breath2416",
          "text": "Legion X â€” Internal LLM + Multi-Agent Orchestration Legion now runs on a local LLM, fully integrated into its multi-agent Parliament System. PROMETHEUS routes. CASSANDRA challenges with counter-evidence. ATHENA audits the final synthesis. 16 grounded datasets. Semantic search live. Internal inference. No external dependency required.\n\nðŸ”Ž Try the LLM: [https://nothumanallowed.com/search](https://nothumanallowed.com/search)\n\nðŸ“¦ GitHub: [https://github.com/adoslabsproject-gif/nothumanallowed/](https://github.com/adoslabsproject-gif/nothumanallowed/)\n\nhttps://preview.redd.it/j75nvhtunakg1.png?width=1024&format=png&auto=webp&s=03a71b919949d0297100e0a3aa71463a1e8e3984",
          "score": -4,
          "created_utc": "2026-02-18 18:13:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9w3b6",
      "title": "Auto Model is now available in Kilo Code. Has anyone tried it?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1r9w3b6/auto_model_is_now_available_in_kilo_code_has/",
      "author": "alokin_09",
      "created_utc": "2026-02-20 13:59:43",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Not sure if you noticed, but an[ auto model feature](https://blog.kilo.ai/p/auto-model-picks-the-right-ai-model) has been available in Kilo for a few days. Basically it uses your existing work modes as signals to route each request to the right model:\n\n* Planning and reasoning tasks (Architect, Orchestrator, Ask, Plan modes) â†’ Claude Opus 4.6 for complex system design and multi-step thinking\n* Implementation work (Code, Build, Debug, Explore modes) â†’ Claude Sonnet 4.5 for fast, cost-effective code writing and editing\n\nYou just switch modes like you normally would and Auto Model handles the model selection in the background. \n\nCurious if anyone's tried it yet - what are your first impressions? Is it actually helpful?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r9w3b6/auto_model_is_now_available_in_kilo_code_has/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r5vnsy",
      "title": "Day 5 of building the worst website possible (2 days left to go)",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1r5vnsy/day_5_of_building_the_worst_website_possible_2/",
      "author": "Rik_Roaring",
      "created_utc": "2026-02-16 01:04:50",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I'm building an AI ugly sweater generator. It is coming along terribly, which means perfectly.\n\nI used Kilo App builder to build it  \n  \nI did it for free using the free Minimax model  \n  \nI hope I did Clark Griswold proud!\n\nCheck it out here: [https://fresh-reed-4538.d.kiloapps.io/](https://fresh-reed-4538.d.kiloapps.io/)\n\nAs for why I did this,  Kilo is running the Worst Website Ever Hackathon through Wednesday. So 2 days left to show off something truly arresting to the well trained eye! \n\nPrizes: Mac Mini for the winner, $500 cash, people's choice award. All built with the App Builder (free).\n\nMore details here: [kilo.codes/worstwebsite](http://kilo.codes/worstwebsite)  or come chat with me about it in the Discord! \n\n(quick note- I am on the community team so while I can participate, I can't win. I'm just doing it for love of the game! )",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r5vnsy/day_5_of_building_the_worst_website_possible_2/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o5n3urh",
          "author": "Scott_Malkinsons",
          "text": "Too bad the app builder is complete and total garbage. Kilo seems to be going off in too many directions, they want to be the 'everything AI' company but it's failing; hard.\n\nThings like the VS Code plugin, awesome.\n\nTheir app builder, garbage. Even something simple as reverting changes doesn't exist, and if you can't basically one shot it, it either never loads the preview site or any slight change causes the entire website to change.\n\nOther things, iOS app, etc. Y'all ever going launch it?\n\nCloud Agents, guys. Do one thing well, seriously. Not mediocre everything. If y'all weren't offering free new models, I'd have dumped Kilo a long time ago. The value proposition isn't form having good stuff, it's you got free stuff. That's a hard way to build a business.",
          "score": 2,
          "created_utc": "2026-02-16 06:30:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7vp2a",
      "title": "Concurrent Session Keep Changing - Limit Reduced from 5 to 3 for GLM 5",
      "subreddit": "kilocode",
      "url": "/r/ZaiGLM/comments/1r7vojy/concurrent_session_keep_changing_limit_reduced/",
      "author": "santhiprakashb",
      "created_utc": "2026-02-18 06:37:20",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1r7vp2a/concurrent_session_keep_changing_limit_reduced/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "o6935mz",
          "author": "Active-Plate-9212",
          "text": "same",
          "score": 1,
          "created_utc": "2026-02-19 15:08:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbjhrw",
      "title": "Is it possible to connect Kilo Code to a custom API (e.g. DigitalOcean Gradient)?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1rbjhrw/is_it_possible_to_connect_kilo_code_to_a_custom/",
      "author": "_WhiteAngel_",
      "created_utc": "2026-02-22 11:26:32",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Is it possible to connect Kilo Code to a custom API (e.g. DigitalOcean Gradient)?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1rbjhrw/is_it_possible_to_connect_kilo_code_to_a_custom/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o6rcye4",
          "author": "social_tech_10",
          "text": "KiloCode is compatible with any OpenAI API endpoint. I spent a few minutes trying to figure out if the DigitalOcean API is OpenAI-compatible, and didn't find it clearly stated anywhere in their docs if it was or was not.  However, Kimi K2 using web-search found that they have two APIs, and the one for inference is OpenAI-compatible, and the other API, which is for DigitalOcean cloud management, can be used through MCP.",
          "score": 1,
          "created_utc": "2026-02-22 12:10:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6reob2",
              "author": "_WhiteAngel_",
              "text": "Thhanks for the insights. I will check what  OpenAPI protocol is and will verify whether DO is actually compatible",
              "score": 1,
              "created_utc": "2026-02-22 12:24:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}