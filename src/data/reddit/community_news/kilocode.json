{
  "metadata": {
    "last_updated": "2026-01-29 02:49:02",
    "time_filter": "week",
    "subreddit": "kilocode",
    "total_items": 13,
    "total_comments": 33,
    "file_size_bytes": 42798
  },
  "items": [
    {
      "id": "1qodevm",
      "title": "Kimi K2.5 is Free in Kilo Code For One Week",
      "subreddit": "kilocode",
      "url": "https://blog.kilo.ai/p/were-making-kimi-k25-free-for-one",
      "author": "alokin_09",
      "created_utc": "2026-01-27 13:10:23",
      "score": 17,
      "num_comments": 6,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qodevm/kimi_k25_is_free_in_kilo_code_for_one_week/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o25ezzw",
          "author": "jakegh",
          "text": "Immediate errors on tool use, prompt was \"read agents.md\". \n\nC'mon, guys. Test it to check that it works in your harness before inviting people to check out.\n\n    \"model\": \"moonshotai/kimi-k2.5:free\",\n    \"details\": \"Error reading file unknown: The \\\"paths[1]\\\" argument must be of type string. Received undefined\"\n\nThen later on, when trying to compact context. Kilo was unable to recover from this after multiple tries, killing my attempt to use it with Kimi K2.5 dead.\n\n```\nKiloCode completion error: {\"error\":{\"message\":\"thinking is enabled but reasoning_content is missing in assistant tool call message at index 2\",\"type\":\"invalid_request_error\"}}\n```",
          "score": 3,
          "created_utc": "2026-01-28 03:36:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26t3r0",
              "author": "jorritposthuma",
              "text": "Come on, give them some slack. Things move so fast, and sometimes they break.",
              "score": 1,
              "created_utc": "2026-01-28 10:03:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o20wv3e",
          "author": "Cocoa_Pug",
          "text": "Quick question was this the Giga Potato model?",
          "score": 1,
          "created_utc": "2026-01-27 14:54:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o21scxq",
              "author": "ggGeorge713",
              "text": "Would love to know that too!",
              "score": 1,
              "created_utc": "2026-01-27 17:14:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o221l51",
              "author": "sand_scooper",
              "text": "No way. Giga potato is absolutely useless. The worst stealth model I've seen so far.\n\nKimi 2.5 seems to be at least functional.",
              "score": 1,
              "created_utc": "2026-01-27 17:54:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o299jfh",
          "author": "hawkibinkman",
          "text": "Anyway to get the kilocode api key free?",
          "score": 1,
          "created_utc": "2026-01-28 18:06:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qocqdo",
      "title": "Kimi k2.5",
      "subreddit": "kilocode",
      "url": "https://i.redd.it/mqbeavw80wfg1.jpeg",
      "author": "ReasonableReindeer24",
      "created_utc": "2026-01-27 12:39:36",
      "score": 15,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qocqdo/kimi_k25/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o20klyn",
          "author": "ObeyTheRapper",
          "text": "It's one of the best open weight models. My only criticism is that in Kilo, if something doesn't go exactly right (like a tool call fails) it tends to give up pretty quickly instead of trying a different way.",
          "score": 3,
          "created_utc": "2026-01-27 13:53:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20q6u0",
          "author": "Zulfiqaar",
          "text": "Is this giga potato?",
          "score": 2,
          "created_utc": "2026-01-27 14:21:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o20qgo5",
              "author": "ReasonableReindeer24",
              "text": "kimi k2.5 free on kilo with same name",
              "score": 2,
              "created_utc": "2026-01-27 14:23:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o240hnw",
          "author": "bytesnbobs",
          "text": "Keep getting loads of 400 errors but when it works it's pretty fast and accurate so far",
          "score": 1,
          "created_utc": "2026-01-27 23:12:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o25j4qh",
          "author": "sand_scooper",
          "text": "I've used Kilo Code a lot and VS Code a lot. And when I tested Kimi 2.5 it actually crashed so hard my screen went black. It's the first time I've seen a BSOD on Windows 11.  Then I tested it again and VS code actually crashed. VS code has never crashed before and I've used all sorts of extensions.\n\nMaybe I just got unlucky and this was all coincidence. Or maybe this is actually a Kimi 2.5 problem.\n\nI did continue to test it later and it was able to do stuff like plan out refactoring, identify critical performance issues with my web app. And execute it step by step according to a MD.\n\nVery difficult to tell if it's actually good or not. The API request is unpredictable. Sometimes it takes very long to respond. Sometimes it just shows a random error 400 or something.\n\nSad, I was hoping to finally see one decent model to subscribe to. Felt really scammed by GLM previously all that fake hype and fake comments.",
          "score": 1,
          "created_utc": "2026-01-28 04:00:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnvplm",
      "title": "MODEL_NO_TOOLS_USED",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qnvplm/model_no_tools_used/",
      "author": "mixoadrian",
      "created_utc": "2026-01-26 22:46:10",
      "score": 9,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "https://preview.redd.it/b5ttmgczurfg1.png?width=672&format=png&auto=webp&s=89065caf61814168057b7bbce9e22e9e23caef26\n\n1. deepseek-r1:14b\n2. glm4:latest\n3. codellama:13b-instruct\n4. llama3.1:8b\n5. deepseek-r1:8b\n6. deepseek-coder-v2:latest\n7. devstral-small-2:latest\n8. gemma2:2b\n9. gpt-oss:latest\n10. qwen3:32b\n11. deepseek-coder:33b\n12. gemma3:12b\n13. mistral-nemo:latest\n14. llama3.1:latest\n15. qwen3-coder:30b\n\nthe above are the models i got, ran with ollama.  \nit seemed none of them work with kilo code, will alwaus run into error MODEL\\_NO\\_TOOLS\\_USED after a few interactions.\n\nfor each Architect, Code, Debug, Orchestral modes, which should i pick that would acutally work? any other opensource model i should use instead? \n\nThis is frustrating. Or I also tried to switch to use openai competible as provider with same models, same result.\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qnvplm/model_no_tools_used/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1xwwfu",
          "author": "FutureHack007",
          "text": "It could be that your models are degrading into those types of errors when context is managed carefully. Try using the Orchestrator mode to break the task into subtasks with small scope to keep the AI model context small. Most open weight models have small context windows that must be managed carefully, especially when running locally.\n\nChoosing a context size is a model load time parameter (Check Ollama docs). In most cases it's better to use lower quantization models to free up VRAM for the correct context size for the task. Local models do work, especially if they are trained for tool use. Try using the GLM 4.7 Flash model if you have the hardware to run it.",
          "score": 3,
          "created_utc": "2026-01-27 02:18:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xxrab",
              "author": "mixoadrian",
              "text": "I already do exactly that and still won‚Äôt work. Even in orchestra mode it tried to do some tool calling that fails. However if I pick the very same model on cloud and provider set to use kilo gateway, it works. So I am curious if there‚Äôs some api calls that  aren‚Äôt recognised by ollama or sth else I missed.",
              "score": 1,
              "created_utc": "2026-01-27 02:23:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o23c47w",
                  "author": "FutureHack007",
                  "text": "I occasionally use Kilo Code with local models (Qwen3 Coder, GPT-OSS-20B, GLM 4.7 Flash) via LM Studio (which I find more usable than Ollama) and it works well. Tuning your model load and inference parameters is the secret to success. Also, use models that are trained for tool use\n\nhttps://preview.redd.it/3a28w3mtkyfg1.png?width=868&format=png&auto=webp&s=e566c8f202eb8692b81c392c4541c0a766215522\n\n",
                  "score": 1,
                  "created_utc": "2026-01-27 21:18:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1xq0a4",
          "author": "Aggressive_Special25",
          "text": "Should have spoken to me before you did all those tests\nI find the same happening to me.....",
          "score": 2,
          "created_utc": "2026-01-27 01:40:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xsbpu",
              "author": "mixoadrian",
              "text": "I just started trying to use kilo, so I don‚Äôt know if it‚Äôs just me or local LLMs(ollama) never have worked, unless everyone else using cloud models? I also tried switching provider setting to OpenAI compatible api to load ollama, back in some said that might work but no they don‚Äôt. Did you find any fixes yet? Have the local models worked on your machine before?",
              "score": 1,
              "created_utc": "2026-01-27 01:53:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o207sm8",
                  "author": "Aggressive_Special25",
                  "text": "No local models don't work for me through kilo code. It generates rubbish. If I speak to the Ai and copy the code it produces its fine. But open source models through kilo code don't work for me.",
                  "score": 1,
                  "created_utc": "2026-01-27 12:39:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1z1m0v",
          "author": "msrdatha",
          "text": "Try running the models with llama.cpp and see if it helps.",
          "score": 1,
          "created_utc": "2026-01-27 06:40:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23bdsv",
              "author": "FutureHack007",
              "text": "Or LM Studio, which is an awesome front-end to llama.cpp (better than Ollama IMHO)",
              "score": 1,
              "created_utc": "2026-01-27 21:15:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o244rsr",
                  "author": "AuthorSpirited7812",
                  "text": "Agreed, LM studio is pretty goated and the UI is pretty nice tbh, no complaints I can think of.",
                  "score": 1,
                  "created_utc": "2026-01-27 23:34:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2at8ve",
          "author": "Muted-Celebration-47",
          "text": "try glm4.7 flash",
          "score": 1,
          "created_utc": "2026-01-28 22:10:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qm918f",
      "title": "Sonnet 4.5 with 1 milions context windows",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qm918f/sonnet_45_with_1_milions_context_windows/",
      "author": "ReasonableReindeer24",
      "created_utc": "2026-01-25 04:20:45",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "it this model good for long coding task?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qm918f/sonnet_45_with_1_milions_context_windows/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1ko8wr",
          "author": "Cocoa_Pug",
          "text": "I thought it only had the 200k context window? I‚Äôve only used it through Kilo Gateway and AWS bedrock. \n\n\nI do feel like almost every model degrades in quality when it passes around 100k tokens in context.",
          "score": 3,
          "created_utc": "2026-01-25 06:19:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kwre0",
              "author": "ReasonableReindeer24",
              "text": "yeah , from kilo gateway with 1m token for sure",
              "score": 2,
              "created_utc": "2026-01-25 07:28:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1lnnh7",
          "author": "Unlucky_Quote6394",
          "text": "I‚Äôve been using it to create a custom LMS and, so far, it‚Äôs handling everything really well.  The 1m context window has made a massive difference and it‚Äôs one of the reasons I‚Äôve been using Kilo",
          "score": 2,
          "created_utc": "2026-01-25 11:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1m2ked",
          "author": "kkingsbe",
          "text": "Sonnet is very expensive. I‚Äôve been rocking glm-4.7",
          "score": 1,
          "created_utc": "2026-01-25 13:17:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1mypnl",
              "author": "ReasonableReindeer24",
              "text": "I know this but sonnet is better than glm 4.7 for complex task but not simple",
              "score": 2,
              "created_utc": "2026-01-25 16:03:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qp19gi",
      "title": "OpenAI ChatGPT Plus/Pro works really well in Kilo",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qp19gi/openai_chatgpt_pluspro_works_really_well_in_kilo/",
      "author": "Cocoa_Pug",
      "created_utc": "2026-01-28 04:22:37",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I‚Äôve had ChatGPT Plus for a while and I typically use the chat bot for just my daily chats. I started using Kilo a few months ago and fell in love but mainly used the Sonnet via Bedrock with my AWS account (which gets pricey) or GLM from the ZAI coding plan. \n\nI tried Codex 5.2 and it does a really good job in Kilo and I‚Äôm glad I can save on token costs now too. \n\nI also like o3 for architect mode. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qp19gi/openai_chatgpt_pluspro_works_really_well_in_kilo/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o26km9y",
          "author": "GodAtum",
          "text": "How do you tell how many tokens you have left?",
          "score": 2,
          "created_utc": "2026-01-28 08:44:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2bmcyq",
          "author": "RedditSellsMyInfo",
          "text": "Do you have issues with roles and backend prompts that Kilo injects? It created some issues for me. Felt a bit over engineered and caused a few issues",
          "score": 1,
          "created_utc": "2026-01-29 00:36:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpf6nu",
      "title": "Kilo Code for JetBrains with Z.ai provider is not listing the glm-4.7-flash model",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qpf6nu/kilo_code_for_jetbrains_with_zai_provider_is_not/",
      "author": "delmicio",
      "created_utc": "2026-01-28 15:56:45",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Hi, I‚Äôm trying to use the glm‚Äë4.7‚Äëflash model that [Z.ai](http://Z.ai) announced a few weeks ago, but it isn‚Äôt listed in the Kilo Code integration yet. \n\n* glm-4.5\n* glm-4.5-air\n* glm-4.5-x\n* glm-4.5-airx\n* glm-4.5-flash\n* gIm-4.5v\n* gIm-4.6\n* glm-4.6v\n* glm-4.6v-flash\n* gIm-4.7\n* glm-4-32b-0414-128k\n\nI‚Äôm on the latest version of the extension. Kilo Code version: 4.150.0\n\nI want to use the fastest model available in the Enhance Prompt tool, so I‚Äôm targeting a flash model instead of the main one. \n\nDoes anyone know how to fix this? Is it officially unsupported by Kilo Code?  \n\n[version](https://preview.redd.it/klo50ksi24gg1.png?width=802&format=png&auto=webp&s=bee9c422dc2f18ab2dd9117da749412a09aa81fe)\n\n[Provider settings](https://preview.redd.it/tgab59yr34gg1.png?width=1262&format=png&auto=webp&s=4ebd0fc59ef9cd3a3d8bdab41e49c209612e9ca5)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qpf6nu/kilo_code_for_jetbrains_with_zai_provider_is_not/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o2b2kky",
          "author": "kira61",
          "text": "https://preview.redd.it/96tk4xuy66gg1.png?width=600&format=png&auto=webp&s=2fafb23aefdfcf255464170433540c38e4f3b472\n\nIt is listed for me in vscode",
          "score": 2,
          "created_utc": "2026-01-28 22:54:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2b6vym",
              "author": "delmicio",
              "text": "Sorry to be direct, but your reply is irrelevant. My issue is unrelated to VS‚ÄØCode; it looks like you‚Äôre looking at the Kilo Gateway, while the problem lies with the [Z.ai](http://Z.ai) provider.",
              "score": 1,
              "created_utc": "2026-01-28 23:16:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2c5qhk",
                  "author": "mcowger",
                  "text": "This is because the Zai team chose not to implement dynamic model fetching in the kilo provider, so it requires a code update.  \n\nEither they or someone else would need to contribute the manual model update or implement dynamic fetching.",
                  "score": 1,
                  "created_utc": "2026-01-29 02:22:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o299xph",
          "author": "Key-Singer1732",
          "text": "I would like to try to use the Flash or FlashX version as well, to speed up coding for faster turnaround, and let the normal GLM 4.7 do the code review",
          "score": 1,
          "created_utc": "2026-01-28 18:07:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjuyk0",
      "title": "The Free Ride is REALLY Over",
      "subreddit": "kilocode",
      "url": "https://blog.kilo.ai/p/grok-code-free-ride-is-really-over",
      "author": "alokin_09",
      "created_utc": "2026-01-22 13:47:09",
      "score": 6,
      "num_comments": 24,
      "upvote_ratio": 0.64,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qjuyk0/the_free_ride_is_really_over/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o127kaq",
          "author": "MaybeDisliked",
          "text": "I got Kilo's Pass and loving it so far!",
          "score": 2,
          "created_utc": "2026-01-22 15:28:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14rsxn",
              "author": "IvoDOtMK",
              "text": "Yeah Kilo pass looks like a winner to me as well.",
              "score": 2,
              "created_utc": "2026-01-22 22:33:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ekir9",
          "author": "logicalish",
          "text": "I find Kilocode‚Äôs marketing to be super disingenuous - gives me serious scammy vibes. You guys literally promote and push free options like Grok Code, but simultaneously act like you‚Äôre geniuses for also having a paid aggregated credits plan as an alternative. The irony is astounding - but you guys have been this way since the beginning, so I shouldn‚Äôt be surprised.",
          "score": 2,
          "created_utc": "2026-01-24 10:25:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1fgud6",
              "author": "Cocoa_Pug",
              "text": "Grok code was free for almost 6 months and kilo does have other free model options.",
              "score": 2,
              "created_utc": "2026-01-24 14:22:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1fhe3l",
                  "author": "logicalish",
                  "text": "Yep, literally my point. Them offering free models and getting people hooked to KiloCode is OK, but Grok making their free offering paid (after it helped KC get tons of users) is a ‚Äúrug pull‚Äù - hence, disingenuous.",
                  "score": 1,
                  "created_utc": "2026-01-24 14:26:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1tynx1",
              "author": "brennydenny",
              "text": "Look I'm a Kilo Code marketer, and wrote this article, so I'm biased, surely - but isn't part of the point of Kilo Code (and any of the open source tools like Roo or Cline or OpenCode or name one) that you have the freedom to use any model you want? That is where the \"marketing speak\" comes in here...but honestly I do feel like that's the benefit you get. \n\nLike I'm not sure what your alternative is here, and I'm really trying to figure that out. We had a model that was offered for free to us - should we have \\*not\\* offered it for free to our users? Even when we do charge for models, we charge at cost...so we don't make any money off that inference in the end either.\n\nThe plan for us and all of those others, as far as I can tell, is to make money on enterprises, not on individual developers.",
              "score": 1,
              "created_utc": "2026-01-26 15:22:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1udfuz",
                  "author": "logicalish",
                  "text": "I appreciate you responding, but I‚Äôve explained my point of view already on a parallel thread of replies to my comment.\n\nThe entire point I‚Äôm trying to make is that you need to tone down the language and framing you‚Äôre using (or rather prompting into your AI article generator/editor) - currently it sounds really unprofessional. Do not indirectly criticize your competitors, lots of whom are doing mostly the same things you are doing (as you admit). Acknowledge that you‚Äôre not the only option with pay-per-token, moreso given you forked and merge changes from a variety of nearly-identical solutions. Do not call your free inference providers as ‚Äúrug pulls‚Äù when they start charging. You and them (as was their intent) have gained users and data from the free runs they provided - as the data shows, KC users were the largest users of Grok Code, and I‚Äôm sure tons of new users showed up to make that happen. Be kind in your messaging and marketing - that‚Äôs my ask.",
                  "score": 1,
                  "created_utc": "2026-01-26 16:27:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o13ppv4",
          "author": "Outrageous-Story3325",
          "text": "opencode \n\n![gif](giphy|GpyS1lJXJYupG)",
          "score": 1,
          "created_utc": "2026-01-22 19:31:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18p4lx",
              "author": "ELPascalito",
              "text": "Afaik OpenCode will also remove Grok Code, they're already planning removal of¬† MiniMax and GLM 4.7 too, time to pay up¬†",
              "score": 2,
              "created_utc": "2026-01-23 14:15:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1dc7d1",
                  "author": "inevitabledeath3",
                  "text": "I've run minimax locally. They aren't that hard.",
                  "score": 1,
                  "created_utc": "2026-01-24 04:16:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fulis",
                  "author": "TheRedPHANTOM212",
                  "text": "Hii! I messaged you",
                  "score": 1,
                  "created_utc": "2026-01-24 15:34:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1eb1d6",
          "author": "digit1024",
          "text": "people often brings TINA argument(there is no alternative)\nBut there is. We should look at optimalizations and first of all open-source models!\nWe cannot rely only on 5 big AI companies, one of them driven by mad man As a  humanity. What if in 2 years they will bring prices up 5 times? \nDo not get hooked. Look fo alternatives. Do not hook to ecosystem.  And if you are from outside of USA, you should really think twice.",
          "score": 1,
          "created_utc": "2026-01-24 08:57:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1hk3nn",
          "author": "Technical_Set_8431",
          "text": "If I wanted to use Claude Code inside of Kilo Code will an API key work, or would I also need a $20/month Claude Pro subscription? Thanks",
          "score": 1,
          "created_utc": "2026-01-24 20:07:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1l7tg3",
          "author": "No_Success3928",
          "text": "Or you could subscribe to synthetic that has multiple models, excellent tech support and no scummy business practices.",
          "score": 1,
          "created_utc": "2026-01-25 09:04:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14t68s",
          "author": "discattho",
          "text": "Good, let grok die while generating nazi salutes with its loser owner. Time to use something real",
          "score": 0,
          "created_utc": "2026-01-22 22:42:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1tvtcm",
              "author": "higgsfielddecay",
              "text": "Thought you'd have been swarmed by Musk simps. You got lucky.",
              "score": 2,
              "created_utc": "2026-01-26 15:09:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ut6xx",
                  "author": "discattho",
                  "text": "I got several threats of people going \"I'LL USE GROK JUST TO PISS YOU OFF LUEWL\". \n\nAs if using a terrible product is going to make ME suffer. Nobody in my professional circle uses Grok for anything. Literally no edge case where it's better than anything out there.",
                  "score": 1,
                  "created_utc": "2026-01-26 17:34:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1hy65u",
              "author": "Umademedothis2u",
              "text": "Crap like that makes me want to use grok just to piss in your pool",
              "score": 1,
              "created_utc": "2026-01-24 21:14:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1i98lv",
                  "author": "discattho",
                  "text": "Idgaf what you use. Use the inferior shit if you want. Grok is not better at any one thing other models don‚Äôt beat it by significant margin.",
                  "score": 2,
                  "created_utc": "2026-01-24 22:06:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qo1qkw",
      "title": "Crypto payments suddenly disabled",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qo1qkw/crypto_payments_suddenly_disabled/",
      "author": "DepartmentHungry7781",
      "created_utc": "2026-01-27 02:54:59",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "Hey, does anyone know why the crypto payment option suddenly disappeared? I really wanted to pay with crypto and now it‚Äôs just gone.\n\nhttps://preview.redd.it/adcht6ws3tfg1.png?width=1335&format=png&auto=webp&s=0e05514f55c9a5a96b4481d5abc5a700d188892e\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qo1qkw/crypto_payments_suddenly_disabled/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1zk9qp",
          "author": "LigiaZanchet",
          "text": "Hey! Great question.   \nHonestly, we had to make a tough call: crypto accounted for less than 1% of our total revenue. As much as we‚Äôd love to keep every payment option open, the engineering hours required to maintain it just didn't make sense compared to building features the other 99% of our users are asking for.\n\nWe‚Äôre keeping an eye on the space, though. If the demand picks back up, we‚Äôre definitely open to revisiting it.",
          "score": 3,
          "created_utc": "2026-01-27 09:27:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qm89cm",
      "title": "Selected for the OSS Sponsorship Program - NOW WHAT?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qm89cm/selected_for_the_oss_sponsorship_program_now_what/",
      "author": "FoldOutrageous5532",
      "created_utc": "2026-01-25 03:43:04",
      "score": 4,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Thrilled to get the email. I promptly complied with the requirements, which were enabling github and code reviews.  Now what? I sent an email response and haven't heard anything.  \n\nWHAT HAPPENS NOW? \n\nThanks.\n\n|Kilo¬†OSS Sponsorship Offer|\n|:-|\n\n\n|Congratulations! You've been selected for the¬†**Kilo¬†OSS Sponsorship Program**¬†at the¬†**Seed tier**.You've been added as the¬†**Owner**¬†of a new¬†Kilo¬†Enterprise Organization. Your sponsorship includes:**‚Ä¢ 5 Enterprise Seats (a $9,000 value)**|\n|:-|\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qm89cm/selected_for_the_oss_sponsorship_program_now_what/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1lbcap",
          "author": "btkilo520",
          "text": "Hey @FoldOutrageous5532!\n\nIf you‚Äôve enabled the GitHub integration and Code Reviews, you‚Äôre all set!\n\nYou can go ahead and invite up to 4 other teammates and enjoy Kilo Enterprise, which includes the features listed here:\n\nhttps://kilo.ai/docs/plans/about\n\nQuick clarification: the Seed sponsorship tier includes access to Kilo Enterprise (security features, team management, and ROI dashboards) rather than Kilo Credits.\n\nThe $9,000 figure represents the annual value of Kilo Enterprise subscription, not a credit package.\n\nApologies if that was unclear- but stay tuned for more updates on the benefits of your OSS Sponsorship Program tier soon!\n\n¬†",
          "score": 3,
          "created_utc": "2026-01-25 09:35:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nc2nb",
              "author": "FoldOutrageous5532",
              "text": "Oh. Thanks for the clarification. That's certainly not exciting to me as a single developer.  I don't have anyone to invite. The one thing I would use is credits, which is the one thing it doesn't include. So it's a nothing-burger for me I guess! Oh well. I was excited for a couple of days. üòú",
              "score": 1,
              "created_utc": "2026-01-25 17:00:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1nfjgf",
                  "author": "btkilo520",
                  "text": "I‚Äôd love to learn more about what we could offer outside of credits (there are many sponsored projects in the Seed tier) to get you excited again!¬†\n\nAnother thing that I didn‚Äôt mention in my earlier response, is that we will soon promote all of our OSS-sponsored projects in a directory on our website, and to the Kilo Community (many of which are open source contributors)",
                  "score": 1,
                  "created_utc": "2026-01-25 17:15:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qlvvu2",
      "title": "Installation needs work",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qlvvu2/installation_needs_work/",
      "author": "Dense_Ad9924",
      "created_utc": "2026-01-24 19:11:57",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 0.81,
      "text": "So I bought into the hype.  Installed kilo code on my Ubuntu 24 machine.  \nChose Ollama and a local model 'Qwen3 coder'.  \nKilo code just hangs to the point where even trying to change models (/model) just hangs.  If this is going to take off, it needs to be easily installed.  I gave up.  I like claude code just fine.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qlvvu2/installation_needs_work/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1o9rce",
          "author": "tauplim",
          "text": "I had my Kilo Code installed on Linux Mint 21.  But before that I had to install VS Code and add Kilo Code as a plugin.\n\nI have problems installing VS code, so in the end I installed VS Codium, the open source version of VS Code.  No problems adding Kilo Code.\n\nLove Kilo Code.",
          "score": 2,
          "created_utc": "2026-01-25 19:22:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1sevxu",
          "author": "LigiaZanchet",
          "text": "Hey Dense,\n\nSorry about that. What version of Kilo and what IDE are you using? We might be able to help you.   \nYou are always welcome to reach out at [hi@kilo.ai](mailto:hi@kilo.ai)",
          "score": 1,
          "created_utc": "2026-01-26 09:09:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qn0ooq",
      "title": "How do I remove a Kilo account?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qn0ooq/how_do_i_remove_a_kilo_account/",
      "author": "Marek_Marianowicz",
      "created_utc": "2026-01-26 00:30:04",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I can't find a way to delete my account. Can someone help me with that?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qn0ooq/how_do_i_remove_a_kilo_account/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1sfgpx",
          "author": "LigiaZanchet",
          "text": "Hello u/Marek_Marianowicz,  \nPlease email [hi@kilocode.ai](mailto:hi@kilocode.ai) to request account deletion.",
          "score": 1,
          "created_utc": "2026-01-26 09:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ssfy0",
              "author": "Marek_Marianowicz",
              "text": "Thank you.",
              "score": 1,
              "created_utc": "2026-01-26 11:11:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmqc6i",
      "title": "AWS Bedrock rate limits?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qmqc6i/aws_bedrock_rate_limits/",
      "author": "GodAtum",
      "created_utc": "2026-01-25 18:03:01",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I‚Äôve been trying to use Bedrock with Kilo but keep getting errors to do with the rate limit. What can I do?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qmqc6i/aws_bedrock_rate_limits/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1o4tks",
          "author": "Cocoa_Pug",
          "text": "What model? I‚Äôve experienced this too with Opus via kilo and also outside of kilo using AWS bedrock. I think it‚Äôs just the way bedrock works. Maybe a quota ticket can be submitted with AWS support",
          "score": 2,
          "created_utc": "2026-01-25 19:00:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o86xa",
              "author": "GodAtum",
              "text": "Qwen3 Coder 480B A35B",
              "score": 1,
              "created_utc": "2026-01-25 19:15:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qo9b0g",
      "title": "Does Kilo support Github Copilot?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1qo9b0g/does_kilo_support_github_copilot/",
      "author": "Cryptolien",
      "created_utc": "2026-01-27 09:33:48",
      "score": 3,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "I use Kilo in Cursor and wonder if Kilo can auth Github Copilot account as LLM provider to access to their models? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1qo9b0g/does_kilo_support_github_copilot/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "o1zpsy9",
          "author": "shaonline",
          "text": "Sadly no, I think they generally don't implement any Oauth stuff for providers.",
          "score": 1,
          "created_utc": "2026-01-27 10:18:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22ox24",
              "author": "rmaxdev",
              "text": "Is it a limitation or their side or providers ?",
              "score": 1,
              "created_utc": "2026-01-27 19:34:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o22pef0",
                  "author": "shaonline",
                  "text": "It's all on KiloCode, open source projects like OpenCode have Oauth implementations for Copilot or OpenAI ChatGPT subscriptions (for Codex).",
                  "score": 1,
                  "created_utc": "2026-01-27 19:36:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o231h05",
          "author": "LigiaZanchet",
          "text": "Hey Cryptolien   \nNot yet! We don't currently support GitHub Copilot as an LLM provider. I've passed this along to the team. Thanks for the suggestion!",
          "score": 1,
          "created_utc": "2026-01-27 20:30:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28xltv",
              "author": "mcowger",
              "text": "Yes you do.  That‚Äôs exactly what the VSCode LM  provider achieves.  \n\nhttps://kilo.ai/docs/ai-providers/vscode-lm",
              "score": 1,
              "created_utc": "2026-01-28 17:14:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}