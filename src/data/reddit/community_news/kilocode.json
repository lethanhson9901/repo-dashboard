{
  "metadata": {
    "last_updated": "2026-01-05 08:59:58",
    "time_filter": "week",
    "subreddit": "kilocode",
    "total_items": 6,
    "total_comments": 20,
    "file_size_bytes": 26693
  },
  "items": [
    {
      "id": "1pyr4s0",
      "title": "GLM 4.7 vs Gemini: Architecture and Cost Trade-offs",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1pyr4s0/glm_47_vs_gemini_architecture_and_cost_tradeoffs/",
      "author": "Unfair-Tie2631",
      "created_utc": "2025-12-29 16:44:38",
      "score": 28,
      "num_comments": 29,
      "upvote_ratio": 0.97,
      "text": "I tested several model combinations in Kilo Code. Before the release of GLM 4.7, I mainly used Gemini 3 Flash for all modes, with solid results. I was highly enthusiastic about the release of GLM, but after many cycles of fixing bug after bug, it became clear that GLM 4.7 was not on par with Gemini in terms of architecture. Gemini was able to produce a functional prototype with just a few iterations.\n\nHowever, since GLM 4.7 is significantly more economical, especially with its API subscription plan, I tested a configuration that proves very effective: Gemini 3 Flash for all modes except code, where GLM 4.7 performs perfectly. For small feature architecture, Gemini 3 Flash is sufficient. For full project architecture or large features, I switch to Opus 4.5, but costs escalate rapidly.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1pyr4s0/glm_47_vs_gemini_architecture_and_cost_tradeoffs/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "nwltx3f",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 11,
          "created_utc": "2025-12-29 20:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoqfjt",
              "author": "Mayanktaker",
              "text": "All other models sucks. Only gpt, gemini and claude works. Other models are just time pass in kilo. If you are serious about projects then don't waste time with other models.",
              "score": 3,
              "created_utc": "2025-12-30 06:07:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwows2r",
                  "author": "Unfair-Tie2631",
                  "text": "That was true not long ago, but now GLM 4.7 is a serious competitor at a much lower cost.\n\nhttps://preview.redd.it/fztr91q6iaag1.jpeg?width=1206&format=pjpg&auto=webp&s=2c307cb69ae42e68082d16706c2416ed07f03bda",
                  "score": 0,
                  "created_utc": "2025-12-30 07:00:25",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpemhe",
              "author": "RMCPhoto",
              "text": "Opus in kilocode is seriously wild...   As far as I'm concerned kilocode is not really for primary development.   I use it for data extraction, searching code, documentation or messing around a bit, but with the number of errors compared to the proper agentic coders it may end up being more expensive to use flash or glm than just springing for the real deal. \n\nEnd of the day, of you're using this for professional work or even to save time - just do the very useful math of \"what would I pay myself per hour\".    This ends up being helpful in all sorts of decision making, but to me it felt pretty clear here.",
              "score": 2,
              "created_utc": "2025-12-30 09:45:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwnu1pq",
              "author": "yuyuyang1997",
              "text": "Just gotten used to Kilo as my AI agent.",
              "score": 1,
              "created_utc": "2025-12-30 02:41:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlcdue",
          "author": "uxkelby",
          "text": "GLM 4.7 coding plan is doing a good job at architecture my app, I mix it with GPT 5 api",
          "score": 3,
          "created_utc": "2025-12-29 18:57:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwopgs5",
              "author": "MorningFew1574",
              "text": "Agreed",
              "score": 1,
              "created_utc": "2025-12-30 05:59:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpews9",
              "author": "RMCPhoto",
              "text": "What do you see as the biggest strengths of GLM 4.7?   And what about weaknesses?  \n\nArchitecture?  It could be.  Definitely good for an alternative perspective at least.   But then what about longer contexts and fixing bugs?  Imo it has the classic llm issue of suffering a lot from any incorrect code in the context whether it wrote it in a prior iteration or even when tasked to resolve a bug.",
              "score": 1,
              "created_utc": "2025-12-30 09:47:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt4e3v",
          "author": "AppealSame4367",
          "text": "I think its very telling that the big OSS / Chinese models are now better than Claude, GPT, Gemini 1 year ago but they are still \"not enough\" to be considered useful, although they are cheaper.\n\nJust emphasizes where AI will go: It must always be the newest, best model. Otherwise people will feel like they are loosing and wasting their time. It's in our nature and that's why this AI revolution will continue to go as fast and crazy as possible.",
          "score": 3,
          "created_utc": "2025-12-30 22:04:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl3ina",
          "author": "Hisma",
          "text": "Sad to hear that assessment of GLM 4.7. It seems to be the consensus that while GLM 4.7 is a very intelligent model, it goes off the rails in longer multi turn context sessions and breaks stuff / hallucinates. Have you tried Minimax M2. 1 yet? I used M2 for a while and was impressed with how well it could stay on task even over long context. It's great at instruction following and tool calling. I wonder if used M2.1 over GLM 4.7 you'd get better results.",
          "score": 2,
          "created_utc": "2025-12-29 18:17:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwl4nzf",
              "author": "Unfair-Tie2631",
              "text": "Before GLM 4.7, I had briefly tested M2.1. It seemed to make fewer architectural mistakes, whereas GLM 4.7 showed a stronger sense for feature ideation. A possible approach would be to use M2.1 as the architect and GLM 4.7 as the coder, but I doubt this setup would reach the level of Gemini 3 Flash. I hope that one day a Chinese model will be trained exclusively for architecture; that would be exceptional.",
              "score": 5,
              "created_utc": "2025-12-29 18:22:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwl5tvu",
                  "author": "Erebea01",
                  "text": "Have you tried deepseek 3.2 for architect mode?",
                  "score": 1,
                  "created_utc": "2025-12-29 18:27:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwoa0wh",
                  "author": "No_Success3928",
                  "text": "I have noticed the same! I am using m2.1 as architect and glm 4.7 as coder and it works really well",
                  "score": 1,
                  "created_utc": "2025-12-30 04:13:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwo9nq5",
          "author": "No_Success3928",
          "text": "Gemini is amazing for UI/UX stuff",
          "score": 1,
          "created_utc": "2025-12-30 04:11:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwobusv",
          "author": "Vozer_bros",
          "text": "both of them are good for all features, but dont try to make feature batch hold too many businesses",
          "score": 1,
          "created_utc": "2025-12-30 04:24:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwr1jip",
          "author": "sbayit",
          "text": "The combination of GLM 4.7 and Deepseek 3.2 is the most effective pairing.",
          "score": 1,
          "created_utc": "2025-12-30 16:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr2xkm",
              "author": "Unfair-Tie2631",
              "text": "Tu utilises lequel dans quel mode ?",
              "score": 1,
              "created_utc": "2025-12-30 16:19:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx8vfos",
                  "author": "sbayit",
                  "text": "Deepseek in planning mode and GLM 4.7 in building mode, utilizing Opencode from its own server, not Openrouter.",
                  "score": 1,
                  "created_utc": "2026-01-02 12:55:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwymy3o",
          "author": "Royal-Huckleberry943",
          "text": "Tried it out with claude code, Its pretty decent, I got the Pro plan, but look out for the concurrency limit per plan for glm coding plans: lite - 2, pro - 5, max - 40 (concurrent requests limit) . Join their discord, discuss with other people then buy if you feel its worth it.   \nYou get an extra 10% discount on top of the 60% Christmas Offer with my referral:   \n[https://z.ai/subscribe?ic=AJJOVACC4X](https://z.ai/subscribe?ic=AJJOVACC4X)",
          "score": 1,
          "created_utc": "2025-12-31 19:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8a572",
              "author": "East-Present-6347",
              "text": "Where are you getting that concurrency limit request information? And, is that for all models?",
              "score": 1,
              "created_utc": "2026-01-02 09:54:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyqswe",
          "author": "Royal-Huckleberry943",
          "text": "It needs more detailed plan and handholding. Budget worthy. Tried it out with claude code, Its pretty good, I got the Pro plan, mainly use it as the workhorse with other models for planning, reviewing. Its for people who want to conserve their budget, might need a stronger model to break through some complex places where it loops and gets stuck. But look out for the concurrency limit per plan for glm coding plans: lite - 2, pro - 5, max - 40 (concurrent requests limit) . Join their discord, discuss with other people then buy if you feel its worth it.  \nGet an extra 10% discount on top of the 60% Christmas Offer with my referral:  \n[https://z.ai/subscribe?ic=AJJOVACC4X](https://z.ai/subscribe?ic=AJJOVACC4X)",
          "score": 1,
          "created_utc": "2025-12-31 19:33:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyo737",
      "title": "A CodeRabbit Alternative for 2026: Code Reviews in Kilo",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1pyo737/a_coderabbit_alternative_for_2026_code_reviews_in/",
      "author": "alokin_09",
      "created_utc": "2025-12-29 14:51:37",
      "score": 15,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Most AI code review tools lock you into their AI stack. They pick the model, they decide when to upgrade, and you get whatever theyâ€™ve configured. \n\nOn the other hand, code reviews in Kilo are built on a different premise.Â \n\nSo, how does Kilo Code reveiws stack against CodeRabbit? \n\n**Pricing**\n\nCodeRabbit chargesÂ $24 per seat per month for code reviews only.\n\nKilo works on per-token pricing at the cost set by model providers. You pay for the reviews you run, which means you donâ€™t leave money on the table, and you donâ€™t hit invisible rate limits or downgrades when you surpass an arbitrary usage limit.\n\n**Workflow**  \n  \nCodeRabbit is a standalone code review product. It does one thing, and you add it to your existing pile of dev tools.\n\nKiloâ€™sÂ Code ReviewsÂ is part of the Kilo platform, the same environment where youâ€™re already writing code, debugging, and deploying. Your reviews happen alongside: \n\n* Agentic Engineering with specialized modes for implementation, architecture, debugging, and orchestration in the IDE or CLI\n* Cloud Agents for accessing Kilo without using your local machine\n* App Builder for prototyping with a live preview\n* Kilo Sessions that sync across VS Code, JetBrains, CLI, and web\n* Kilo Deploy for one-click shipping when the review passes\n* Managed Indexing for context-aware reviews that understand your codebase \n\nIf anyoneâ€™s interested, hereâ€™s a **more detailed breakdown and comparison**:  \n[https://blog.kilo.ai/p/code-review-alternative-2026]() \n\nQuestion: Anyone whoâ€™s tried multiple AI code review tools, what turned out to matter, and what was mostly noise?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1pyo737/a_coderabbit_alternative_for_2026_code_reviews_in/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "nwk0wpf",
          "author": "Solonotix",
          "text": "Do you have a proposed workflow for using Kilo Code for code review? I've used it to write a change log before, but haven't quite figured out a good way to prompt for a full code review\n\nEdit: Ah, I see. This is promoting a new feature on the Enterprise side. Cool to see.",
          "score": 1,
          "created_utc": "2025-12-29 15:14:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwogak2",
          "author": "ttreyr",
          "text": "\\> Kilo works on per-token pricing at the cost set by model providers.\n\nthat means u will pay more if your code is more. and cursor also has the review fuction.",
          "score": 1,
          "created_utc": "2025-12-30 04:53:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwcrdt",
          "author": "aviboy2006",
          "text": "Does it work like extension or different ?",
          "score": 1,
          "created_utc": "2025-12-31 11:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7kawh",
          "author": "tdehnke",
          "text": "Iâ€™d like the Kilo reviews to just reply with issues and suggestions.  None of the this is good etc,",
          "score": 1,
          "created_utc": "2026-01-02 05:58:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q215pw",
      "title": "Win $500 of AI usage credits in Kilo. ðŸš€",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1q215pw/win_500_of_ai_usage_credits_in_kilo/",
      "author": "alokin_09",
      "created_utc": "2026-01-02 15:15:29",
      "score": 10,
      "num_comments": 3,
      "upvote_ratio": 0.82,
      "text": "Excited to share this. \n\nThe team is running a Kilo App Builder Challenge, and itâ€™s basically â€œship something cool, win credits.\n\n**Prizes**\n\n* 1st: **$500 Kilo Credits**\n* 2nd: **$250 Kilo Credits**\n* 3rd: **$100 Kilo Credits**\n\n**How to enter**\n\n1. Build + deploy: [**app.kilo.ai/app-builder**](http://app.kilo.ai/app-builder)\n2. Share a short build video *or* your deployed app link\n3. Submit via the form -> [https://form.typeform.com/to/kArx1YTS?typeform](https://form.typeform.com/to/kArx1YTS?typeform) \n\nIf youâ€™re joining: what are you building? Something useful, or something stupid-fun? \n\nWould love to see some examples in the thread :)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1q215pw/win_500_of_ai_usage_credits_in_kilo/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "nx9xppk",
          "author": "FoldOutrageous5532",
          "text": "I'm learning guitar, so I used Kilo builder to build a guitar scale utility. It's quite useful!\n\nhttps://preview.redd.it/qfrxj0jqpyag1.png?width=2412&format=png&auto=webp&s=b8b52da389e58ad32aa9de6653fe6048f700c2cb\n\n[https://ef892a59-e15c-4eaf-97af-a15bc90ecd86.builder.kiloapps.io/](https://ef892a59-e15c-4eaf-97af-a15bc90ecd86.builder.kiloapps.io/)",
          "score": 3,
          "created_utc": "2026-01-02 16:25:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbowtr",
              "author": "TraditionalDrawer998",
              "text": "Very cool! Did you submit this to the App Builder Challenge?",
              "score": 2,
              "created_utc": "2026-01-02 21:24:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbsj4z",
                  "author": "Hairy-Initiative-870",
                  "text": "Yes!",
                  "score": 2,
                  "created_utc": "2026-01-02 21:41:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q0k74f",
      "title": "Trying a 2B model in local",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1q0k74f/trying_a_2b_model_in_local/",
      "author": "Affectionate_Plant57",
      "created_utc": "2025-12-31 18:40:44",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I saw the new **lfm2-2.6b-exp** model and was amazed to know it has the same intelligence as gpt-4. I run it in LM studio with 4GB context window. However, it gives me these errors so I guess it's not exactly the same. Can someone explain what's happening exactly? I'm very curious to understand the differences and the whys. Thanks\n\nhttps://preview.redd.it/gmkijgai3lag1.png?width=607&format=png&auto=webp&s=28dca8e8f80f78a1ef6514aa960c8620fe067b7f\n\n    Kilo Code tried to use apply_diff without value for required parameter 'path'. If this error keep reoccuring, please disable Editing Through Diffs in Advanced Settings. Retrying...",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1q0k74f/trying_a_2b_model_in_local/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "nwyij3q",
          "author": "inevitabledeath3",
          "text": "The answer is in the screenshot to be honest. You need to use a smarter model. No matter what the marketing claims a 2.6B parameter model is not going to be good enough for most coding tasks or comparable to GPT-4, and it looks like it's failing to execute tool calls correctly. The context window for that model is fairly limited and you are likely using a quantized (dumber) version as well. You *might* get some use out of it by switching from XML to JSON/native tool calling or vice versa, but chances are it's not going to work well. You really need at least a 24B parameter model like Devstral 2 or larger like Qwen 3 Coder 30B A3B for agentic coding, ideally bigger and smarter. If you don't have powerful enough hardware you can get good models for cheap or even free through a variety of providers including synthetic, openrouter, or minimax. Minimax M2 model is currently free on open router and would work better, or even Grok Code Fast 1 which is also free I believe.",
          "score": 5,
          "created_utc": "2025-12-31 18:50:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx795o5",
          "author": "Mayanktaker",
          "text": "I get this error frequently and with model like glm, minimax, qwen code etc and stopped using kilo. My glm subscription is working fine with cline, sadly not with kilo.",
          "score": 1,
          "created_utc": "2026-01-02 04:38:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2ce58",
      "title": "Web UI",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1q2ce58/web_ui/",
      "author": "Technical_Set_8431",
      "created_utc": "2026-01-02 22:15:13",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "When you say that Kilo also works in a Web UI, do you mean Jet Brains?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1q2ce58/web_ui/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "nxf12ql",
          "author": "Scott_Malkinsons",
          "text": "They (because I've never said anything to you) likely mean they go on kilo's website, login, and use the cloud app builder. [https://kilo.ai/features/cloud-agents](https://kilo.ai/features/cloud-agents)",
          "score": 3,
          "created_utc": "2026-01-03 10:30:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfexm6",
              "author": "Technical_Set_8431",
              "text": "Thanks, Scott",
              "score": 1,
              "created_utc": "2026-01-03 12:24:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxco9z8",
          "author": "Tiny-Sink-9290",
          "text": "JetBrains.. the IDE? That's not web. That's Java Swing.",
          "score": 2,
          "created_utc": "2026-01-03 00:29:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1533x",
      "title": "do workflows work?  not for me, please help?",
      "subreddit": "kilocode",
      "url": "https://www.reddit.com/r/kilocode/comments/1q1533x/do_workflows_work_not_for_me_please_help/",
      "author": "travislaborde",
      "created_utc": "2026-01-01 14:12:32",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I am trying to create and use a workflow.  I've changed my \"syntax\" quite a few times, but I always end up with the same problem:\n- I see Kilo Code starting an \"API Request....\"\n- that request just \"spins\" forever\n- the usage meter shows 0 tokens being used\n- finally I click the \"Cancel\" button\n- I get a popup notification saying \"Task file not found for task ID: {whatever}\n- Kilo Code is locked up now...\n- I have to restart VSCode to \"try again\"\n\nThe file is currently named \"tdd.md\" and looks like this:\n\n```\n# TDD Workflow\n\nYou are helping.  Follow these steps:\n\n1. run the tests using `execute_command` with `make test`\n```\n\nObviously too simple to be valuable yet but that's only because I've trimmed it down repeatedly to try and figure out what is wrong.\n\nI am on Manjaro Linux using VSCode.  KiloCode runs fine otherwise, as far as I can tell.  I use it every day and love it.  I'm just trying to expand in to workflows.\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/kilocode/comments/1q1533x/do_workflows_work_not_for_me_please_help/",
      "domain": "self.kilocode",
      "is_self": true,
      "comments": [
        {
          "id": "nx351sz",
          "author": "LigiaZanchet",
          "text": "Hello    \nSorry about that.  \nHave you tried using different models to confirm?   \nI also recommend you test something very simple, like the workflow for new project creation available in our [docs](https://kilo.ai/docs/features/slash-commands/workflows)  \nPlease let us know if that works.",
          "score": 1,
          "created_utc": "2026-01-01 15:01:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3b3n9",
              "author": "travislaborde",
              "text": "Thanks for such a quick response!  Wow that speaks well of your team, OMG!\n\nI found that the problem was due to a conflict with another VSCode Extension.  \"Todo Tree.\"  It doesn't seem obvious to me how there is shared functionality between that and Kilo Workflows, but that was the problem.  I've disabled the Todo Tree extension and will be discontinuing it's use.\n\nIt makes me wonder if it might be a good idea to add a FAQ for Kilo that mentions any known conflicts with other VSCode extensions.  Thanks again!",
              "score": 3,
              "created_utc": "2026-01-01 15:37:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx81fqf",
                  "author": "LigiaZanchet",
                  "text": "Hey Travis, thanks for sharing that. I love the idea of a public FAQ, for sure, that would be helpful for all our users, especially in cases like yours. I'll keep you posted.",
                  "score": 2,
                  "created_utc": "2026-01-02 08:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx3anq9",
          "author": "travislaborde",
          "text": "Solved!  It turns out that there is a conflict with another VSCode extension that I had: Todo Tree.\n\nDisabling that made the Kilo Code workflow work right away.  FYI.",
          "score": 1,
          "created_utc": "2026-01-01 15:34:37",
          "is_submitter": true,
          "replies": []
        }
      ]
    }
  ]
}