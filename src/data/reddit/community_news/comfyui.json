{
  "metadata": {
    "last_updated": "2026-02-03 17:18:12",
    "time_filter": "week",
    "subreddit": "comfyui",
    "total_items": 20,
    "total_comments": 252,
    "file_size_bytes": 248127
  },
  "items": [
    {
      "id": "1qtogey",
      "title": "How Was This Made?",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/4j8urmh891hg1",
      "author": "OneArm90",
      "created_utc": "2026-02-02 07:23:02",
      "score": 264,
      "num_comments": 37,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1qtogey/how_was_this_made/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o34cwdu",
          "author": "Helpful-Birthday-388",
          "text": "Impressive!",
          "score": 15,
          "created_utc": "2026-02-02 07:51:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36aemf",
              "author": "rwa2",
              "text": "Why do I have a sudden hankering for some fresh-baked painas tamores?",
              "score": 1,
              "created_utc": "2026-02-02 16:00:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34ckko",
          "author": "GeroldMeisinger",
          "text": "there was a recent post on video style transfer [https://www.reddit.com/r/StableDiffusion/comments/1qr5tpf/telestyle\\_contentpreserving\\_style\\_transfer\\_in](https://www.reddit.com/r/StableDiffusion/comments/1qr5tpf/telestyle_contentpreserving_style_transfer_in)",
          "score": 24,
          "created_utc": "2026-02-02 07:48:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34pas5",
              "author": "OneArm90",
              "text": "Wow so get a real video footage and place a style on top of it right? I'm still figuring out if it can make the video smooth and consistent like the uploaded video!",
              "score": 8,
              "created_utc": "2026-02-02 09:51:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o35ugre",
                  "author": "AbletonUser333",
                  "text": "There are Loras that can help connect one image to the last so it looks pretty consistent. What's far more interesting is how they did this without AI nearly 30 years ago for What Dreams May Come, and it actually looked better:\n\nhttps://www.youtube.com/watch?v=moycIs9zmRc",
                  "score": 5,
                  "created_utc": "2026-02-02 14:42:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34jkbq",
          "author": "ANR2ME",
          "text": "It looks like painting turned into video with a bit of realism ü§î",
          "score": 5,
          "created_utc": "2026-02-02 08:55:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34ohuy",
          "author": "x8code",
          "text": "Wow, that is awesome. Also, Sarah Brightman is the music. I've listened to her for many years.",
          "score": 3,
          "created_utc": "2026-02-02 09:43:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34z35e",
          "author": "nomadoor",
          "text": "Yeah, there are probably a few ways to do it. Style transfer is one route, but they might‚Äôve just stylized the first frame first and then animated from that. If it‚Äôs something like LTX-2, maybe it‚Äôs I2V with an IC-LoRA control (like Depth) to guide the motion‚Ä¶ ",
          "score": 3,
          "created_utc": "2026-02-02 11:21:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o370vql",
              "author": "nomadoor",
              "text": "I thought this might be simple style transfer at first, but I‚Äôm not so sure anymore. I can‚Äôt find the original video it was converted from, and since this seems to be an AI contest entry, there‚Äôs a chance something more advanced was involved‚Äîlike adding flowers or changing the outfit. \n\nTools like Runway Aleph can handle this kind of editing, but I don‚Äôt remember any open-source technique that can reach similar quality.\n\nI tried doing what I could with LTX-2 as well, and the quality isn‚Äôt even close.\n\nhttps://i.redd.it/13fhn4n7f4hg1.gif",
              "score": 2,
              "created_utc": "2026-02-02 18:02:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34c2ic",
          "author": "jalbust",
          "text": "Probably driving it with a wan vace model. Not too crazy. I was trying out something along those lines but more abstract https://youtu.be/q4z-PJH6RH4?si=Rwt6Dw8Jtuacb5Pg \n\nCan you share the link to og post?",
          "score": 4,
          "created_utc": "2026-02-02 07:44:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34cq6t",
              "author": "OneArm90",
              "text": "Hey really appreciate the reply. I've been asking everywhere but only dead ends... this account 'ÂπªÂ¢ÉLab' is mostly active on Chinese social media so couldn't really find anything through Google. It's mainly active on Douyin (Chinese TikTok) but I cannot access it as it only allows Chinese Phone Number to create an account.\n\nI found his other account in Xiaohongxu which I managed to pass through the account creation process and here the [Link](https://www.xiaohongshu.com/user/profile/6538e8bf0000000006006c19?xsec_token=YBe18Kv3Eszj321ffCwPOZsQqJzNceJqLrll-Sz5oxE2A%3D&xsec_source=app_share&xhsshare=&shareRedId=OD85RTc4PUI2NzUyOTgwNjg5OTc2OD1M&apptime=1770018562&share_id=1f5e088702ba466ba0feeb1fc18f5865&share_channel=copy_link)!",
              "score": 1,
              "created_utc": "2026-02-02 07:50:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o34d9sl",
                  "author": "jalbust",
                  "text": "My best guess : he is taking a frame from a video(photorealistic) > styling it using nano or any image edit model > using that along with some control net to restyle . Are you looking to recreate this?",
                  "score": 2,
                  "created_utc": "2026-02-02 07:55:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o34p234",
                  "author": "Practical-Nerve-2262",
                  "text": " You're here to advertise, aren't you, my fellow countryman?",
                  "score": 2,
                  "created_utc": "2026-02-02 09:49:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o37zst5",
                  "author": "drank2much",
                  "text": "Link required an account even after I X out the request. I had better luck [here](https://www.douyin.com/user/MS4wLjABAAAA9pNx-1THjH2ib0TGnpCQYBHUHK_Cnfj7KVk4yrlb5zAUkeWs4I-2PShgxDa20doG) after X out of request.",
                  "score": 1,
                  "created_utc": "2026-02-02 20:43:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o364bg5",
              "author": "aiyakisoba",
              "text": "Found on bilibili too https://b23.tv/IDTrDzx",
              "score": 1,
              "created_utc": "2026-02-02 15:32:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34qrj6",
          "author": "Woisek",
          "text": "You never saw [https://www.imdb.com/title/tt3262342/](https://www.imdb.com/title/tt3262342/) and admired how they did this?",
          "score": 4,
          "created_utc": "2026-02-02 10:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36yrqu",
          "author": "GregBahm",
          "text": "Some posters are saying style transfer but that would create a very choppy result frame to frame.\n\nYou should be able to achieve this just by Wan 2.2 image-to-video. They probably put \"wind blowing\" i the prompt. Hence all the random wind blowing.\n\nYou could maybe do it with a starting image and ending image for more control, and then use something like Qwen Image edit to make the target image. But since it's just random people milling about, you probably don't need a second image.",
          "score": 2,
          "created_utc": "2026-02-02 17:52:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36zrnj",
              "author": "OneArm90",
              "text": "Wow! Thanks for the tips... let me try it on Higgfields before I get down in ComfyUI. I'll get back to you on this!",
              "score": 1,
              "created_utc": "2026-02-02 17:57:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o382dqn",
          "author": "drank2much",
          "text": "You might want to check with /u/mueducationresearch I thought their submission [Bloom](https://www.reddit.com/r/aivideo/comments/1nhjgfj/bloom/) was impressive and it was made with Wan! If you go through their submission history there are a lot of similar styles, but with stronger painting effect.",
          "score": 2,
          "created_utc": "2026-02-02 20:55:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38a4ko",
              "author": "OneArm90",
              "text": "Yo... damn what is this! Going down the rabbit hole... all of them are insane?! I gotta find what their workflow was like! Thank you so much!",
              "score": 2,
              "created_utc": "2026-02-02 21:32:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bqgd7",
          "author": "SmileThroughTear",
          "text": "midjourneyÔºå using Claude Monet¬¥s painting style",
          "score": 2,
          "created_utc": "2026-02-03 11:38:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36q6n9",
          "author": "XiRw",
          "text": "Painting comes to life. What an excellent idea",
          "score": 1,
          "created_utc": "2026-02-02 17:13:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37suei",
          "author": "Impressive-Egg8835",
          "text": "Perfect!",
          "score": 1,
          "created_utc": "2026-02-02 20:10:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o389bda",
          "author": "Mythril_Zombie",
          "text": "By throwing Enya into a wind tunnel.",
          "score": 1,
          "created_utc": "2026-02-02 21:28:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38z6sn",
          "author": "9090906",
          "text": "For me, its i2v workflow, for the first few frames i can see the sharp details then sunddenly the details disappears.",
          "score": 1,
          "created_utc": "2026-02-02 23:39:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o369j6a",
          "author": "EconomySerious",
          "text": "i see some russian painters paintings used as start images, just as easy as that",
          "score": 0,
          "created_utc": "2026-02-02 15:56:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36i1xq",
          "author": "Swimming_Dragonfly72",
          "text": "Europe before Islamic revolution",
          "score": -2,
          "created_utc": "2026-02-02 16:36:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o355zjr",
          "author": "audax8177",
          "text": "Image (chatgpt, banana ..) to video.",
          "score": -1,
          "created_utc": "2026-02-02 12:16:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34kw5n",
          "author": "ALLAHPARTY",
          "text": "Regular slop",
          "score": -15,
          "created_utc": "2026-02-02 09:08:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp3svd",
      "title": "VNCCS Pose Studio: Ultimate Character Control in ComfyUI",
      "subreddit": "comfyui",
      "url": "https://www.youtube.com/watch?v=YYclB6414nw",
      "author": "AHEKOT",
      "created_utc": "2026-01-28 06:32:26",
      "score": 239,
      "num_comments": 82,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1qp3svd/vnccs_pose_studio_ultimate_character_control_in/",
      "domain": "youtube.com",
      "is_self": false,
      "comments": [
        {
          "id": "o26cz1s",
          "author": "Snoo20140",
          "text": "NOTE: Comfy Manager hasn't been updated to the correct Github (it won't be a comfyUI\\_name) so it will error if you try using manager at the time of this comment.\n\nEDIT: VNCCS\\_QWEN\\_Encoder doesn't seem to load correctly with either the Manager install version or the Github version. Unless i'm doing something wrong.\n\nEDIT 2: The Encoder is part of the ComfyUI\\_VNCCS repo.",
          "score": 12,
          "created_utc": "2026-01-28 07:36:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o288nnr",
              "author": "dirtybeagles",
              "text": "the encoder is in the [**VNCCS - Visual Novel Character Creation Suite**](https://github.com/AHEKOT/ComfyUI_VNCCS) **node, if you install it that should fix your issue with that.**",
              "score": 5,
              "created_utc": "2026-01-28 15:26:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o298f6m",
                  "author": "Snoo20140",
                  "text": "Any chance u can upload FBX files to ur viewer? Export an animation as a series of images?",
                  "score": 1,
                  "created_utc": "2026-01-28 18:01:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o28lcl2",
          "author": "Vivid-Loss9868",
          "text": "https://preview.redd.it/ogkr9vde84gg1.png?width=1920&format=png&auto=webp&s=351dc66d75ec8e3cc05b3c4f4cc3074553d048a2\n\nlove it! great work, any change we can get a lock in the visual pose studio editor, like lock the image and the pose.bit messy if you pass a lot of time tweaking then you mess up.",
          "score": 4,
          "created_utc": "2026-01-28 16:21:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hvjwh",
              "author": "AHEKOT",
              "text": "I will think what i can do) For now just save your pose to Gallery)",
              "score": 1,
              "created_utc": "2026-01-29 22:33:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26lqaj",
          "author": "Cute_Ad8981",
          "text": "Does this only work with qwen? Or can i use other models like sdxl?",
          "score": 3,
          "created_utc": "2026-01-28 08:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26lv7n",
              "author": "AHEKOT",
              "text": "Lora is only for qwen now. But it can work with any controlnet on any model without this lora.",
              "score": 5,
              "created_utc": "2026-01-28 08:56:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26msom",
          "author": "Ok-Worldliness-9323",
          "text": "not working with klein right?",
          "score": 3,
          "created_utc": "2026-01-28 09:04:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26mzt6",
              "author": "AHEKOT",
              "text": "Should work with controlnet preprocessing. Add openpose and depth from node model, and connect prompt.",
              "score": 2,
              "created_utc": "2026-01-28 09:06:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26prok",
          "author": "SirToki",
          "text": "Is there a way to infer the pose from an image, so you don't have to set it up yourself?",
          "score": 2,
          "created_utc": "2026-01-28 09:32:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26pufv",
              "author": "AHEKOT",
              "text": "Not for now. It's harder then looks.",
              "score": 3,
              "created_utc": "2026-01-28 09:33:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o26q9lm",
                  "author": "SirToki",
                  "text": "Sorry, I wasn't trying to imply it is easy. Thanks for the answer.",
                  "score": 1,
                  "created_utc": "2026-01-28 09:37:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o27g94n",
              "author": "Synor",
              "text": "https://duckduckgo.com/?q=comfyui+openpose+estimate",
              "score": 2,
              "created_utc": "2026-01-28 13:00:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o29s9wy",
          "author": "Far-Map1680",
          "text": "This is amazing my friend! Ive been waiting for a tool like this! Bless you.",
          "score": 2,
          "created_utc": "2026-01-28 19:27:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2c4qfe",
          "author": "Frogy_mcfrogyface",
          "text": "Sweet!",
          "score": 2,
          "created_utc": "2026-01-29 02:16:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fq0ks",
          "author": "Prediccion",
          "text": "thanks, i was struggling with qwen and some poses, thanks to this i dont lose time and i directly get what i want withouth so much try and fail, and time lose.",
          "score": 2,
          "created_utc": "2026-01-29 16:32:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26kcpd",
          "author": "Synor",
          "text": "There is a bug in your Pose and Emotion Studio nodes, they layout-wise keep growing vertically to infinity. Making them unusable. (Firefox and Safari)",
          "score": 1,
          "created_utc": "2026-01-28 08:42:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26kksl",
              "author": "AHEKOT",
              "text": "It's in main VNCCS project, not this one? Would be cool if you can attach screenshot here.",
              "score": 1,
              "created_utc": "2026-01-28 08:44:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o26l5e8",
                  "author": "Synor",
                  "text": "Both projects are affected.\n\nThere is also an issue with your Pose Studio node making http requests to huggingface continously.\n\nHTTP Request: HEAD https://huggingface.co/MIUProject/VNCCS_PoseStudio/resolve/main/model_updater.json \"HTTP/1.1 307 Temporary Redirect\"\n\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/MIUProject/VNCCS_PoseStudio/c8441457da7010724da2e343724336ba4c195ec3/model_updater.json \"HTTP/1.1 200 OK\"",
                  "score": 1,
                  "created_utc": "2026-01-28 08:49:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o26vqzq",
              "author": "crowzor",
              "text": "get the same issue",
              "score": 1,
              "created_utc": "2026-01-28 10:26:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o26skt2",
          "author": "alborden",
          "text": "Can this work with z-image turbo?",
          "score": 1,
          "created_utc": "2026-01-28 09:58:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26sozp",
              "author": "AHEKOT",
              "text": "Can work with any model that support controlnet or have edit function. For better results use openpose + depthmap",
              "score": 5,
              "created_utc": "2026-01-28 09:59:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o27d7mt",
                  "author": "verticalfuzz",
                  "text": "As in... instead of this? In addition to? Could you elaborate?",
                  "score": 1,
                  "created_utc": "2026-01-28 12:41:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o26u13w",
          "author": "crowzor",
          "text": "looks great but the node seems to be broken at the moment",
          "score": 1,
          "created_utc": "2026-01-28 10:11:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26u7u0",
              "author": "AHEKOT",
              "text": "What's not working for you? It would be helpful for me!",
              "score": 1,
              "created_utc": "2026-01-28 10:13:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o271dkq",
                  "author": "crowzor",
                  "text": "https://preview.redd.it/h8n60wryp2gg1.png?width=266&format=png&auto=webp&s=2932fbc4f3ba95cae1692b3a4fdba30e98fd9f4c\n\nthe window keeps expanding down",
                  "score": 1,
                  "created_utc": "2026-01-28 11:14:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o26w720",
          "author": "Nokai77",
          "text": "I haven't tried it, but it would be great if it worked with ZImage. Also, it would be really useful to be able to save poses and then load them. Good job, I've installed it but I need to restart to see if it works.",
          "score": 1,
          "created_utc": "2026-01-28 10:30:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26wzc2",
              "author": "AHEKOT",
              "text": "1. It should, but you will need controlnet.  \n2. it have! Save it, export, import, share with others!",
              "score": 3,
              "created_utc": "2026-01-28 10:37:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26yw6v",
          "author": "crowzor",
          "text": "The window just keeps extending down. Will send a screengrab soon",
          "score": 1,
          "created_utc": "2026-01-28 10:54:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26zhrn",
          "author": "Upset-Virus9034",
          "text": "Can someone share a workflow and guidance to work it properly?üôè",
          "score": 1,
          "created_utc": "2026-01-28 10:59:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26zofx",
              "author": "AHEKOT",
              "text": "https://preview.redd.it/s45so05en2gg1.png?width=893&format=png&auto=webp&s=0944c5def996435db217e512d2be3e965df9de37\n\nIt right on GitHub Readme)  \nOr you can open it in Templates tab inside ComfyUI itself",
              "score": 2,
              "created_utc": "2026-01-28 11:00:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o270svv",
                  "author": "Upset-Virus9034",
                  "text": "Thanks üôè",
                  "score": 1,
                  "created_utc": "2026-01-28 11:10:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o279efy",
          "author": "pepitogrillo221",
          "text": "The transfer pose are very good but the output quality its very PLASTIC EFFECT. Why? Any way to improve this?",
          "score": 1,
          "created_utc": "2026-01-28 12:15:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279opi",
              "author": "AHEKOT",
              "text": "Try this mode first \n\nhttps://preview.redd.it/6tazdmw013gg1.png?width=416&format=png&auto=webp&s=a090a8116935ee9c459dde9a02b12f6c8feb6b38\n\nQWEN not very good at lights. It this will help - then need to do more training with realistic pictures.",
              "score": 1,
              "created_utc": "2026-01-28 12:17:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o29ntfa",
                  "author": "pepitogrillo221",
                  "text": "I were doing with it and no way, same plastic, im using Q6 gguf with my 3090.",
                  "score": 1,
                  "created_utc": "2026-01-28 19:07:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o279m1s",
          "author": "shamomylle",
          "text": "This looks amazing, thanks for sharing, can't wait to try it out <3",
          "score": 1,
          "created_utc": "2026-01-28 12:17:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27py50",
          "author": "Pleasant-Money5481",
          "text": "C'est possible d'utiliser VNCCS avec sdxl ?",
          "score": 1,
          "created_utc": "2026-01-28 13:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27qdu9",
          "author": "bickid",
          "text": "Thx for this. I'm note an expert with comfyui, so let me ask: I have the nodes now. Even could open them in a new workflow to test whether they appear or not. But if I use Qwen Image Edit, how do I integrate these nodes into a Qwen Image Edit-workflow? thx",
          "score": 1,
          "created_utc": "2026-01-28 13:56:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27rfrd",
              "author": "AHEKOT",
              "text": "Check example workflow in github readme!",
              "score": 1,
              "created_utc": "2026-01-28 14:01:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28gpkq",
          "author": "Nevaditew",
          "text": "https://preview.redd.it/dqanxa5354gg1.png?width=842&format=png&auto=webp&s=782a2d9714f63790f52ea12adc1f1186a8b328d5\n\nI tested it and it replicates the pose very accurately, but the quality(Colors, style) degrades.  \nIt's adding strokes to the contours when it shouldn't, and the colors are a bit off. The original hand looks slightly pink, but it's turning out whiter in the output.  -keep original lighting is on- btw",
          "score": 1,
          "created_utc": "2026-01-28 16:01:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29euc1",
              "author": "AHEKOT",
              "text": "Need to improve lora. I think there is way to do this, but it take so long at 5070ti. When it would be done i make a new post with new version)",
              "score": 3,
              "created_utc": "2026-01-28 18:28:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28pbmm",
          "author": "VirtualWishX",
          "text": "Looks really cool, thank you! ‚ù§Ô∏è  \nI installed everything, I also downloaded for the QWEN Loader: q**wen-image-edit-2511-Q8\\_0.gguf** because I'm still a newbie and I don't know how to use the none-GGUF there (I'm with **RTX 5090**),  \nI had to put it on the UNET so the node will allow me to pick it up.\n\nI loaded the image on the loader and run, but it ignores the image this is what I get is the actual 3D MODEL and sometimes I get the ACTUAL image I loaded but with PLASTIC SKIN.\n\n1Ô∏è‚É£ - ~~Can you please share a~~ **~~None-Unet~~** ~~folder / model~~ **~~Workflow~~** ~~so I can try improve quality on RTX 5090~~  \n~~I don't want to break the workflow, and I'm a noob,~~  \nEDIT:  \nIt seems like I just used a different Loader for the Model without ruin anything after all...\n\nUnfortunately I sitll get mostly Plastic smooth AI look skin results, even with different Qwen edit models I tried (none Q or GGUF), I tried 8 steps but it looks even worst.\n\n2Ô∏è‚É£ - I loaded Solid Grey Color but it's not rendering that Background (ignoring it) - How to render with Selected ANY Background (not just solid color) instead of the default background ?\n\n3Ô∏è‚É£ - It's simple to ROTATE but how do I MOVE around the HAND / NECK / LEG etc.. ?\n\nI hope you can help, thanks ahead! üôè\n\nI attached an example (image from [**Pexels** (download here) üëà](https://www.pexels.com/photo/woman-in-studio-on-white-background-6311497/):  \nI always get PLASTIC skin while in normal Qwen (non Q8 usually I get very realistic results in other workflows).\n\nhttps://preview.redd.it/tdb3ry7sb4gg1.jpeg?width=3785&format=pjpg&auto=webp&s=9c449b78b3da8138ac951b24561a21a70a9e8cf2",
          "score": 1,
          "created_utc": "2026-01-28 16:38:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2a9nie",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 2,
              "created_utc": "2026-01-28 20:44:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ahcmw",
                  "author": "VirtualWishX",
                  "text": "Thanks I will give it a try.  \n  \n**EDIT:**  \nI tried you suggestions, I get AMAZING results even on 4 steps on any other workflow with same config Euler / simple (also Euler A / Beta works but less nice) all the other attempts are even MORE plastic look so, I believe it's some other process in the workflow is not forgiving by strength that is maybe higher or overwrite because no matter how hard I try in the specific workflow with the POSE (which is awesome) I get plastic looks.\n\nMaybe the pose editor and anything it uses on the progress behind the hood just make things more plasticky or 3D look instead of photorealistic, and no prompt can save this as well.",
                  "score": 1,
                  "created_utc": "2026-01-28 21:18:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o28sfwi",
          "author": "wbiggs205",
          "text": "When I try to install missing node I getting this error \n\n\\[Installation Errors\\] 'VNCCS - Collection of utility nodes': With the current security level configuration, only custom nodes from the **\"default channel\"** can be installed.",
          "score": 1,
          "created_utc": "2026-01-28 16:52:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o291fgn",
          "author": "NoWrongdoer7363",
          "text": "https://preview.redd.it/bdirfve8l4gg1.jpeg?width=720&format=pjpg&auto=webp&s=6e58a383ebf4b88437ca07d6b72ce0329097785a\n\nÿÆŸÑÿπ ÿßŸÑŸÖŸÑÿßÿ®ÿ≥",
          "score": 1,
          "created_utc": "2026-01-28 17:31:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hsekx",
          "author": "Muted-Animal-8865",
          "text": "im a complete noob but can i ask why you would use this over taking photographs to run through control net. When i asked chatgpt about complex poses and whether you could just take photographs of them poses and then run them through control net ,it said yes, why would you decide to use this instead?",
          "score": 1,
          "created_utc": "2026-01-29 22:17:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hwazi",
              "author": "AHEKOT",
              "text": "Because you can never have too much control. What if you NEED your character to look at a specific point? How can you make sure they fit into your existing composition and that the light falls on them from the right angle? You can have an infinite number of images with poses, but you will be limited by what you have. Here, you can do literally anything you want.",
              "score": 1,
              "created_utc": "2026-01-29 22:37:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2hzpip",
                  "author": "Muted-Animal-8865",
                  "text": "I see . Appreciate the explanation",
                  "score": 1,
                  "created_utc": "2026-01-29 22:54:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2sfzlz",
          "author": "Exydosa",
          "text": "I don't know what happened, but when I click run, it keeps printing this in the log, and the ComfyUI process (running) ended, yet it's still printing logs like this indefinitely.\n\nhttps://preview.redd.it/jvqnjni7yogg1.jpeg?width=981&format=pjpg&auto=webp&s=05f77f0024f093693147ebc94c353e0ef0028eba",
          "score": 1,
          "created_utc": "2026-01-31 13:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sgfuc",
              "author": "AHEKOT",
              "text": "Check that you use 0.4.3 version, there was fix for this. And this log is only node check for lora update, so it cant affect whole workflow. There must be another reason.",
              "score": 2,
              "created_utc": "2026-01-31 14:02:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2shwf2",
                  "author": "Exydosa",
                  "text": "Thanks, it works now. It's very great we have this now! But I feel like the result's likeness is very low, especially when you try anime characters. Any advice?",
                  "score": 1,
                  "created_utc": "2026-01-31 14:11:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2v837v",
          "author": "Sorry-Poem7786",
          "text": "can this tool use a photo to map the pose to the picture? so you dont have spend time noodling the hands and wrists and all of that UGH!!.. because in the examples which look good and accurate but if the hand is not placed with delicate attention it looks off...for some reason the 3d rigging process (in general)  always made me less motiviated to do it..HAHA!!",
          "score": 1,
          "created_utc": "2026-01-31 22:13:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35lrhu",
          "author": "Warthog_Specialist",
          "text": "Omg mate, amazing work, that was exactly what I needed. It's quick and so easy to use. Just when I needed more control frames for my videos. Much love :)",
          "score": 1,
          "created_utc": "2026-02-02 13:55:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38vqox",
          "author": "Successful_Angle_327",
          "text": "Can this work on flux klen 4b and how?",
          "score": 1,
          "created_utc": "2026-02-02 23:20:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ax7a6",
              "author": "AHEKOT",
              "text": "Yes, with openpose and depth map. I tried to make full lora but i can't make it stable. Need someone who know how to train klein properly.",
              "score": 1,
              "created_utc": "2026-02-03 07:06:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpf9n8",
      "title": "LTX2 - Never Fade Away (cover) part2",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/pz3v2z9g44gg1",
      "author": "Warthog_Specialist",
      "created_utc": "2026-01-28 15:59:37",
      "score": 211,
      "num_comments": 50,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1qpf9n8/ltx2_never_fade_away_cover_part2/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o29adxe",
          "author": "Dohwar42",
          "text": "Wow great work! I'm really surprised by how much use this workflow has gotten. This is literally the 3rd or 4th post I've come across that mentioned using the workflow I created a few weeks ago.  \n  \n I really thought it would be of limited use since it was mostly going to be a static camera (due to the lora). There are probably better optimized workflows out there by now which probably haven't gotten as much attention as mine. The workflow  is just a heavily modified workflow of an early and messy \"use your own mp3/audio\" that I found when LTX-2 first came out.   \n  \nBy the way, the steps value in the first pass is actually set really, really high at 25 steps. I meant to update that post with a version 3 to note that you can actually get away with just 15 steps, maybe less in this node. Lowering this allows for higher resolutions or longer videos at certain resolutions. I've seen a few people get up to 40-50s at near 720p if they have your hardware though it is kinda boring watching one shot for that long. I think 15-25 is good for each shot mixed in with non-lip synced audio.   \n\n\nI've taken a bit of a break from Ai generation but it's great to see what people are up to.\n\nhttps://preview.redd.it/gzb5oq6xr4gg1.png?width=724&format=png&auto=webp&s=8098263ea646f6310b29aaef0fd33aad39fee2a1",
          "score": 12,
          "created_utc": "2026-01-28 18:09:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29haj9",
              "author": "Warthog_Specialist",
              "text": "It gave a great foundation I guess for the people to start on, as it's maybe messy but really easy to follow. I modified it some more this week to make use of the first to last frame technique, so I'm planning to take it for another spin this coming weekend. Wonder how it will perform with french lip syncing, as Clair obscur has some amazing songs too, though the art for this game is not as abundant as for CP2077, but I'll try to make something out of it ;)\n\nHuge thanks again for your contribution to the community ü´∂",
              "score": 3,
              "created_utc": "2026-01-28 18:39:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37vlje",
                  "author": "SaadNeo",
                  "text": "Good Job OP , i myself interested in making Q8 Working in any workflow , by that i mean i cant figure out how to free up camera , all i get is static camera shots , would you kindly share your Workflow , i would like to test it out on my rig , thanks",
                  "score": 2,
                  "created_utc": "2026-02-02 20:23:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2bt8b3",
          "author": "i_am_fear_itself",
          "text": "The quality if this literally made me gasp while watching it. WELL-FUCKING-DONE!!!",
          "score": 5,
          "created_utc": "2026-01-29 01:13:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2d0krt",
              "author": "Warthog_Specialist",
              "text": "Thx for such a high praise mate, means a lot :)",
              "score": 2,
              "created_utc": "2026-01-29 05:31:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o292rf5",
          "author": "Cadmium9094",
          "text": "Amazing!",
          "score": 2,
          "created_utc": "2026-01-28 17:37:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o293v62",
              "author": "Warthog_Specialist",
              "text": "Thx mate, glad you liked it :)",
              "score": 2,
              "created_utc": "2026-01-28 17:42:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o29obam",
          "author": "ComputerArtClub",
          "text": "Really enjoyed this! Great work!!",
          "score": 2,
          "created_utc": "2026-01-28 19:09:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29rz2e",
              "author": "Warthog_Specialist",
              "text": "Thanks mate, much appreciated:)",
              "score": 1,
              "created_utc": "2026-01-28 19:25:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2a2w0v",
          "author": "Rythameen",
          "text": "As a fan of both LTX 2 and CP2077, I really enjoyed this, as you said, a few quirks here and there, but really outstanding work.",
          "score": 2,
          "created_utc": "2026-01-28 20:14:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2aabdj",
              "author": "Warthog_Specialist",
              "text": "Thx, really appreciate it :)\n\nAs for the quirks, I think it's more of not enough time spent than the model shortcomings. Almost everyday someone takes a dump on LTX2 and while it's far far from perfect, all in one solution, imo, it gave us so much to work and have fun with:) Shout out to the devs, if you are for some reason reading this, you are amazingüí™",
              "score": 2,
              "created_utc": "2026-01-28 20:47:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2a9b7c",
          "author": "Upset-Virus9034",
          "text": "Great,\nWhat about the part 2, can some one link üîó it here? üôè",
          "score": 2,
          "created_utc": "2026-01-28 20:43:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ae2tt",
              "author": "Warthog_Specialist",
              "text": "Well, I have a 140 second video from the start of the song, it's a bit on the nsfw side so to speak. Nothing crazy, just Panam in a somewhat revealing dress, Panam on the hood of a car and Judy with neon green stockings and green pasties on her breasts. Nothing explicit but my post from another subreddit got removed for being too sexually appealing I guess lol üòÇ So for this second part I swayed a bit into puppy friendly territory. But if the 18+ tag is enough for it to survive here, I'll gladly post it too, it has Misty instead of Aurora at the closing part of a video.",
              "score": 1,
              "created_utc": "2026-01-28 21:04:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2asb3y",
          "author": "Artforartsake99",
          "text": "Wow this is insanely good.  Looks like high quality 3d. üëå",
          "score": 2,
          "created_utc": "2026-01-28 22:05:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2cywho",
              "author": "Warthog_Specialist",
              "text": "Thx, means a lot:)\n\nI was really impressed on how with the right prompting you can control ltx2 to handle movement, so it can stay pretty close to the initial still 3d render to make it into a nice, smooth, 3d animation almost video.",
              "score": 1,
              "created_utc": "2026-01-29 05:19:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2aws5w",
          "author": "_VirtualCosmos_",
          "text": "Fuck, this song... got me so emotional again",
          "score": 2,
          "created_utc": "2026-01-28 22:26:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2czd35",
              "author": "Warthog_Specialist",
              "text": "When my female V started singing it before returning to earth in one of the Hanako endings... yeah ü•≤",
              "score": 2,
              "created_utc": "2026-01-29 05:22:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2bolhi",
          "author": "King_Salomon",
          "text": "great work! may I ask, i know ltx can generate audio, but how can you match the lip sync to an existing audio? i am guessing this song preexisting to the video generation, so if you type in the lyrics in the prompt how can you match it to the actual song? anyway looking really good!\n\nEDIT\nok never mind i see the link to the workflow. tnx!",
          "score": 2,
          "created_utc": "2026-01-29 00:47:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2czuwg",
              "author": "Warthog_Specialist",
              "text": "Thx :) I tried prompting the lyrics too, the results were somewhat inconsistent, so for me just very strict prompting on when and how the mouth should react to the sung lyrics worked best.",
              "score": 2,
              "created_utc": "2026-01-29 05:26:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2dxqnx",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-01-29 10:20:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e0ysc",
              "author": "Warthog_Specialist",
              "text": "Ty, happy to hear that :)",
              "score": 1,
              "created_utc": "2026-01-29 10:49:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2e5xtt",
          "author": "Aware-Swordfish-9055",
          "text": "How are you doing I2V üòÆ?\nMy attempts don't keep the same starting image, it gets distorted or changes identity.",
          "score": 2,
          "created_utc": "2026-01-29 11:30:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e8cuk",
              "author": "Warthog_Specialist",
              "text": "Are you using the same workflow? If yes, try to guide the model through the whole duration of your video, describe to the model everything you want to happen, describe the identity of a person in the first frame, the mood, all the movements that you want and don't want to see. In short be as detailed as possible. Also explicitly tell the model to stick to the starting image as reference.",
              "score": 2,
              "created_utc": "2026-01-29 11:48:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2kyope",
                  "author": "Aware-Swordfish-9055",
                  "text": "Thanks, will try.",
                  "score": 2,
                  "created_utc": "2026-01-30 10:54:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2l01dy",
                  "author": "Aware-Swordfish-9055",
                  "text": "BTW did you stitch 2 shots of the girl in blue?\nHer necklace transforms into something weird after some time.",
                  "score": 2,
                  "created_utc": "2026-01-30 11:06:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2el7p0",
          "author": "Tramagust",
          "text": "Woah you have a 5090 with 64GB?",
          "score": 2,
          "created_utc": "2026-01-29 13:14:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f1oso",
              "author": "Warthog_Specialist",
              "text": "5090 and 64gb of system RAM",
              "score": 2,
              "created_utc": "2026-01-29 14:41:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jg5ep",
          "author": "DirkBelig",
          "text": "Very nice. Meanwhile I can't even get ComfyUI to work. My two attempts using Pinokio over year apart resulted in massive installs that failed when trying to do anything and when I tried to install standalone ComfyUI (twice) resulted in all sorts of errors in installing then it failing to start. Says I need Git, install Git, then it crashes saying I need Git. I give up. The fact I can't even get it to run is a sign to find another hobby.‚òπÔ∏è",
          "score": 2,
          "created_utc": "2026-01-30 03:42:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kjb7h",
              "author": "Warthog_Specialist",
              "text": "Thx :)\n\nWell, it can be a pain yes. I got win10 pro and I use comfy through pinokio. It was actually the least troublesome way for me, worked on a first try, and still works despite the 230gb of stuff I have thrown at it, still hadn't broken down once for some reason üòÖ\n\nMaybe try a clean install of windows?",
              "score": 1,
              "created_utc": "2026-01-30 08:36:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2q677x",
                  "author": "DirkBelig",
                  "text": "Pinokio downloaded tons of stuff - thank Lemmy I have a 1.3 Gbps no limit fiber connection - and I still had to manually DL things for the workflow and manually figure out where they went because the folder structure was documented wrong and after all that it didn't work. You can't open the logs, the whole thing hangs. When I previously tried it in Nov. 2024 it was appalling slow to generate garbage images. As limited as Fooocus was, it was fast (\\~15-20 sec/image with many steps) and didn't crap out.\n\nI stopped messing with AI stuff after a couple of weeks and decided to step back in with all the new models, but as I said, I can't get ComfyUI to work at all and, no, I'm not reinstalling Win11 to make AI slop. I'll give standalone a try again when I find some time, but I've got actual creative projects to work on (I'm a musician) and I'll just admire work by people like you for now.",
                  "score": 2,
                  "created_utc": "2026-01-31 03:06:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2knhss",
          "author": "Zealousideal-Cow4698",
          "text": "You really brought out its soul. I might actually start training on this model.",
          "score": 2,
          "created_utc": "2026-01-30 09:14:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kpxb0",
              "author": "Warthog_Specialist",
              "text": "Thx mate\n\nGood luck and I hope it clicks with you too. The beloved wan 2.2 for some reason didn't do it for me, while ltx2 was a more mutually rewarding experience :)",
              "score": 1,
              "created_utc": "2026-01-30 09:36:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2bu3h0",
          "author": "i_am_fear_itself",
          "text": "/u/savevideo",
          "score": 1,
          "created_utc": "2026-01-29 01:17:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bu3rj",
              "author": "SaveVideo",
              "text": "###[View link](https://rapidsave.com/info?url=/r/comfyui/comments/1qpf9n8/ltx2_never_fade_away_cover_part2/)\n\n\n --- \n [**Info**](https://np.reddit.com/user/SaveVideo/comments/jv323v/info/)&#32;|&#32; [**Feedback**](https://np.reddit.com/message/compose/?to=Kryptonh&subject=Feedback for savevideo)&#32;|&#32;[**Donate**](https://ko-fi.com/getvideo) &#32;|&#32; [**DMCA**](https://np.reddit.com/message/compose/?to=Kryptonh&subject=Content removal request for savevideo&message=https://np.reddit.com//r/comfyui/comments/1qpf9n8/ltx2_never_fade_away_cover_part2/) &#32;|&#32; \n [^(reddit video downloader)](https://rapidsave.com) &#32;|&#32; [^(twitter video downloader)](https://twitsave.com)",
              "score": 1,
              "created_utc": "2026-01-29 01:17:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2bt1du",
          "author": "dirtybeagles",
          "text": "Question, what post processing did you do for these?",
          "score": 1,
          "created_utc": "2026-01-29 01:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2d0dpq",
              "author": "Warthog_Specialist",
              "text": "Just some basic stuff, mainly soft lighting on all the scenes as it takes that \"ai generated\" edge off, snow in the first scene and image glitching on the scene transitions.",
              "score": 2,
              "created_utc": "2026-01-29 05:30:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ebfoj",
          "author": "LyriWinters",
          "text": "You need to actually do some cinematography and not just headshots strung together.",
          "score": 1,
          "created_utc": "2026-01-29 12:10:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f1e5b",
              "author": "Warthog_Specialist",
              "text": "Yeah, had some really nice full body shots in the first 3 scenes for the song, but as it was dimed \"too suggestive\" by some mods at the StableDiffusion subreddit, i went with this waist up/portrait shots, just to be safe üòÖ \n\nOf course I would like to do some more than roll in/roll out stuff, plan to try it at the weekend. I hope first to last frame will help with consistency on those, coz the more you give the model stuff to work with the more hallucinations prone it becomes. We'll see how it goes.\n\nThx for your comment.",
              "score": 2,
              "created_utc": "2026-01-29 14:39:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2fjill",
                  "author": "LyriWinters",
                  "text": "I think the best way to learn is to copy others. Take a music video that's decently popular that matches the genre. Then copy it.  \nAfter youve done that 4-5 times you kind of get the gist of this type of cinematography. What youll notice is that each shot is very seldom longer than 3 seconds.\n\nfirst-last frame is not the solution. For consistency you need a lora for your character :)",
                  "score": 2,
                  "created_utc": "2026-01-29 16:03:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ev09m",
          "author": "OddResearcher1081",
          "text": "Sorry but this is just not watchable.  It is these types of video experiments that make AI look bad.",
          "score": 1,
          "created_utc": "2026-01-29 14:07:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f44a8",
              "author": "Warthog_Specialist",
              "text": "My main drive behind posting this was to show how decent with very little prior knowledge LTX2 can be as a free video model.\n\nCan you elaborate on a negative side some more? It does not have \"crazy stuff happening on screen every 3 seconds\" or that plastic look most of the free video models give by default. What caught your eye as a \"bad ai experiment\"?",
              "score": 1,
              "created_utc": "2026-01-29 14:53:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2d0rnz",
          "author": "Comfortable_Swim_380",
          "text": "Omg it was amazing until she opened her mouth and the rest was just caaaaaaaaw!! ROFL.",
          "score": -1,
          "created_utc": "2026-01-29 05:33:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq55j1",
      "title": "After analyzing 1,000+ viral prompts, I made a system prompt for LLM nodes that auto-generates pro-level image prompts",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1qq55j1/after_analyzing_1000_viral_prompts_i_made_a/",
      "author": "Deep-Huckleberry-752",
      "created_utc": "2026-01-29 10:35:12",
      "score": 202,
      "num_comments": 62,
      "upvote_ratio": 0.91,
      "text": "Been obsessed with prompt optimization lately. Wanted to figure out why some prompts produce stunning results while mine look... mid.\n\nSo I collected and analyzed 1,000+ trending image prompts from X to find patterns.\n\n**What I found:**\n\n1. **Negative constraints still matter** ‚Äî telling the model what NOT to do is effective\n2. **Multi-sensory descriptions help** ‚Äî texture, temperature, even smell make images more vivid\n3. **Group by content type** ‚Äî structure your prompt based on scene type (portrait, food, product, etc.)\n\nBonus: Once you nail the above, JSON format isn't necessary.\n\n**So I made a system prompt that does this automatically.**\n\nJust plug it into your LLM prompt optimization node, feed it a simple idea like \"a bowl of ramen\", and it expands it into a structured prompt with all those pro techniques baked in.\n\nÔøº**How to use in ComfyUI:**\n\nUse any LLM node (e.g., GPT, Claude, local LLM) with this as the system prompt. Your workflow would be:\n\nSimple prompt ‚Üí LLM Node (with this system prompt) ‚Üí Image Generation\n\nÔøº**The System Prompt:**\n\n```\nYou are a professional AI image prompt optimization expert. Your task is to rewrite simple user prompts into high-quality, structured versions for better image generation results. Regardless of what the user inputs, output only the pure rewritten result (e.g., do not include \"Rewritten prompt:\"), and do not use markdown symbols.\n\n---\n\n## Core Rewriting Rules\n\n### Rule 1: Replace Feeling Words with Professional Terms\n\nReplace vague feeling words with professional terminology, proper nouns, brand names, or artist names. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\n| Feeling Words | Professional Terms |\n\n|---------------|-------------------|\n\n| Cinematic, vintage, atmospheric | Wong Kar-wai aesthetics, Saul Leiter style |\n\n| Film look, retro texture | Kodak Vision3 500T, Cinestill 800T |\n\n| Warm tones, soft colors | Sakura Pink, Creamy White |\n\n| Japanese fresh style | Japanese airy feel, Wabi-sabi aesthetics |\n\n| High-end design feel | Swiss International Style, Bauhaus functionalism |\n\nTerm Categories:\n\n- People: Wong Kar-wai, Saul Leiter, Christopher Doyle, Annie Leibovitz\n\n- Film stocks: Kodak Vision3 500T, Cinestill 800T, Fujifilm Superia\n\n- Aesthetics: Wabi-sabi, Bauhaus, Swiss International Style, MUJI visual language\n\n### Rule 2: Replace Adjectives with Quantified Parameters\n\nReplace subjective adjectives with specific technical parameters and values. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\n| Adjectives | Quantified Parameters |\n\n|------------|----------------------|\n\n| Professional photography, high-end feel | 90mm lens, f/1.8, high dynamic range |\n\n| Top-down view, from above | 45-degree overhead angle |\n\n| Soft lighting | Soft side backlight, diffused light |\n\n| Blurred background | Shallow depth of field |\n\n| Tilted composition | Dutch angle |\n\n| Dramatic lighting | Volumetric light |\n\n| Ultra-wide | 16mm wide-angle lens |\n\n### Rule 3: Add Negative Constraints\n\nAdd explicit prohibitions at the end of prompts to prevent unwanted elements.\n\nCommon Negative Constraints:\n\n- No text or words allowed\n\n- No low-key dark lighting or strong contrast\n\n- No high-saturation neon colors or artificial plastic textures\n\n- Product must not be distorted, warped, or redesigned\n\n- Do not obscure the face\n\n### Rule 4: Sensory Stacking\n\nGo beyond pure visual descriptions by adding multiple sensory dimensions to bring the image to life. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\nSensory Dimensions:\n\n- Visual: Color, light and shadow, composition (basics)\n\n- Tactile: \"Texture feels tangible\", \"Soft and tempting\", \"Delicate texture\"\n\n- Olfactory: \"Aroma seems to penetrate the frame\", \"Exudes warm fragrance\"\n\n- Motion: \"Surface gently trembles\", \"Steam wisps slowly descending\"\n\n- Temperature: \"Steamy warmth\", \"Moist\"\n\n### Rule 5: Group and Cluster\n\nFor complex scenes, cluster similar information into groups using subheadings to separate different dimensions.\n\nGrouping Patterns:\n\n- Visual Rules\n\n- Lighting & Style\n\n- Overall Feel\n\n- Constraints\n\n### Rule 6: Format Adaptation\n\nChoose appropriate format based on content complexity:\n\n- Simple scenes (single subject): Natural language paragraphs\n\n- Complex scenes (multiple elements/requirements): Structured groupings\n\n---\n\n## Scene Adaptation Guide\n\nIdentify scene type based on user intent and choose appropriate rewriting strategy. Note: the examples below are for understanding only ‚Äî do not reuse them. Create original expansions based on user descriptions.\n\n| Scene Type | Recommended Terms | Recommended Parameters | Common Constraints |\n\n|------------|------------------|----------------------|-------------------|\n\n| Product Photography | Hasselblad, Apple product aesthetics | Studio lighting, high dynamic range | No product distortion, no text watermarks |\n\n| Portrait Photography | Wong Kar-wai, Annie Leibovitz | 90mm, f/1.8, shallow depth of field | Maintain realistic facial features, preserve identity |\n\n| Food Photography | High-end culinary magazine style | 45-degree overhead, soft side light | No utensil distractions, no text |\n\n| Cinematic | Christopher Doyle, Cinestill 800T | 35mm anamorphic lens, Dutch angle | No low-key dark lighting (unless requested) |\n\n| Japanese Style | Japanese airy feel, Wabi-sabi aesthetics | High-key photography, diffused light | No high-saturation neon colors |\n\n| Design Poster | Swiss International Style, Bauhaus | Grid system, minimal color palette | Clear information hierarchy |\n\n---\n\n## Example\n\n**User Input:\\*\\*\n\na portrait with cinematic feel\n\n**Rewritten Prompt:\\*\\*\n\nCinematic portrait photography, shot through rain-soaked glass at a dimly lit restaurant at night.\n\nVisual Style:\n\nWong Kar-wai and Saul Leiter aesthetics. Deep saturated colors, heavy shadows. Shot with 90mm lens, f/1.8, Kodak Vision3 500T film grain.\n\nLighting & Atmosphere:\n\nNeon green and red city lights refracting through raindrops in the foreground. Soft focus, dreamy, emotionally evocative. The air is filled with moisture, loneliness, and nostalgia.\n\nConstraints:\n\nMaintain realistic facial features. Do not alter identity characteristics.\n\n```\n\n---\n\nÔøº**The dataset is open source too** ‚Äî 1,100+ prompts with image links, all in JSON:\n\nüëâ [ https://github.com/jau123/nanobanana-trending-prompts ](https://github.com/jau123/nanobanana-trending-prompts)\n\nLiveDemo üëâ [meigen.ai](https://www.meigen.ai)\n\nLet me know if you try it out. Curious what results you get.",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1qq55j1/after_analyzing_1000_viral_prompts_i_made_a/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o2esse5",
          "author": "afinalsin",
          "text": "If you don't mind a bit of criticism, I think your methodology and the conclusions you have drawn are a bit flawed. I appreciate the drive to learn it and share, but you've hit a couple traps that are super common when learning image gen.\n\nThis bit immediately caught my attention:\n\n>So I collected and analyzed 1,000+ trending image prompts from X to find patterns.\n\nSorry, but you didn't collect 1000+ trending prompts. Trending prompts don't exist. What you've done is collect 1000+ trending images and grabbed the prompts from those. They're similar, but they aren't the same thing. \n\nRelying on trending images means you are only sourcing the most attention-grabbing results with no regard for how closely the models followed the prompts. Wanna know what draws the most attention in the AI space online? Your .json of trending prompts contains 479 mentions of the keyword \"woman\", 376 mentions of the word \"girl\", and 212 mentions of the word \"female\". \n\nPeople don't care about the prompt, they care about a pretty picture, and models are experts at delivering a pretty picture. That's basically all they're good for. \n\n[Take this image from Nanobanana Pro](https://i.postimg.cc/dqSZtvNj/nano-4.jpg). Looks cool, right? Imagine I'm some guy on X with a following, and this got a couple hundred likes and retweets, enough for it to hit your scrape. It must have a good prompt for it to be so popular, right?\n\nWell, the prompt for that image is:\n\n>Generate a cinematic film still using the following random tags as inspiration:\n\n>inr, tae, repair, ilovemy, eoin, hurricane, allo, dianne, baddest, elondon, turk, grove, hawk, cabine, bonnet, genuine, big, flashbacks, nare, kavanaugh, ellis, boogie, pies, vandalism, bham, cassidy, schal, rout, mol\n\n>You must not include any text.\n\nIt's clear the prompt is nonsense, but the model made a sick image anyway. That's what they do, they take any input and try their best to turn chicken shit into chicken salad. \n\nThat's a good thing, but that strength also leads a lot of people astray. If you have found any similarities between the prompts, try not to draw the conclusion that \"this is in the prompt, the image is good, therefore the prompt must be good.\" \n\nPeople naturally follow the herd and try looking online to find pretty images to see how it's done, they find one and copy the keywords, but the image they've copied *also* copied those keywords from a different image, which in turn copied from another image, and so on, creating a feedback loop of the blind leading the blind. \n\nAsk any of the prompters in the chain why their image is good, they'll respond with \"It's the prompt.\" Ask them *why* they've included what they have in the prompt and you'll get some variation of \"Because it makes the image better.\" \n\nSeriously, the .json dataset is comprised of tons of overused and unnecessary keywords that have been hanging around long past their use-by date and will barely make a difference in the generation. There are 1232 mentions of the keyword \"realistic\" of which 304 are \"photorealistic\" and 191 are \"ultra-realistic\", 130 \"ultra-detailed\", 8 \"best quality\", 29 \"masterpiece\", 55 \"4k\", 308 \"8k\", hell, there's even 1 \"artstation\" that's made its way through. \n\nWhat your dataset primarily shows is the model is good at making pretty images. What it doesn't show is how to make particular pretty images.\n\nNow, I'm not saying all your recommendations are wrong necessarily. A couple look good, others do not (I didn't think I'd have to write this, but don't prompt for smell, or taste, or sound, or touch. These models are trained on visuals, so use visual descriptors.) \n\nWhat I'm saying is you can't draw conclusions based on the popularity of an image. Again, there's more than 1200 mentions of realistic in your dataset, which must mean it's a good keyword since it's so popular, right? No, if you want a realistic image just include the medium in the prompt. An amateur photo, a cinematic film still, a polaroid, whatever. You only need \"realistic\" to reinforce the medium if the rest of the prompt is pushing towards an unrealistic style.\n\nSorry If I came off like a dick at any point here, it really is super cool you're doing this and sharing it. It's hard to be thorough and diplomatic at the same time when trying to point out flaws in someone's idea. \n\nSo I don't look like a complete dickhead just here to shit on someone else's effort, here's a site that will help you out if you feel like scraping more popular images and their prompts: https://civitlab.devix.pl/ It's the civit gallery, but much more easily searchable.",
          "score": 80,
          "created_utc": "2026-01-29 13:55:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ev6c8",
              "author": "Deep-Huckleberry-752",
              "text": "You are definitely a hardcore player‚Äîyou're hitting on the real issues here.\n* On the 'girl' bias: Believe it or not, the ratio in the raw data was actually much higher. What you see is already after my initial filtering, but I plan to curate it even more aggressively moving forward.\n* On 4k/8k: I agree these are junk tags that pros shouldn't need. Not making excuses, but that is simply what the raw data reflects. I am currently debating whether I should intervene and scrub these 'placebo' tags from the dataset entirely.\n* On Sensory Stacking: I‚Äôll reserve judgment on this one for now. I plan to run more tests to see how much weight the model actually gives them.\n* On Data Sources: My main value proposition is keeping a pulse on X/Twitter trends specifically. It‚Äôs a different ecosystem from Civitai. Let's be honest, Civitai definitely has its own heavy bias toward 2.5D and Anime styles too, haha.\nSeriously, thanks for the detailed feedback!",
              "score": -16,
              "created_utc": "2026-01-29 14:07:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2fkmr9",
                  "author": "Haiku-575",
                  "text": ">You are definitely a hardcore player‚Äîyou're hitting on the real issues here.\n\nI wonder if afinalsin was under the impression he was talking t√™te-√†-t√™te, not t√™te-√†-machine.",
                  "score": 14,
                  "created_utc": "2026-01-29 16:08:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2flifs",
                  "author": "mail4youtoo",
                  "text": "If you are going to use chatgpt or some other AI to write a reply, at least try to edit it a little bit to not sound like it came from AI",
                  "score": 2,
                  "created_utc": "2026-01-29 16:12:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2e6rsb",
          "author": "fauni-7",
          "text": "One problem I am already noticing, that it uses negations, like:  \n\"No low-key dark lighting or strong contrast. No high-saturation neon colors or artificial plastic textures. Do not obscure facial expressions\"  \nMaybe you should tell it to not use negations, or to have a separate section for the negative prompt.",
          "score": 16,
          "created_utc": "2026-01-29 11:36:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2edncf",
              "author": "admajic",
              "text": "With zimage turbo you can use negatives on the positive prompt. Go try it out",
              "score": 10,
              "created_utc": "2026-01-29 12:26:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2e7mtz",
              "author": "Deep-Huckleberry-752",
              "text": "That's a great point‚Äîfeel free to submit a PR if you'd like to help improve the structure",
              "score": 3,
              "created_utc": "2026-01-29 11:43:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2h0xme",
                  "author": "fauni-7",
                  "text": "I'll need to play some more and figure it out, thanks. If I get something working I'll open one.",
                  "score": 2,
                  "created_utc": "2026-01-29 20:06:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2eccvu",
          "author": "Justify_87",
          "text": "The thing about negatives is a bit more complicated. The latest models don't use negative prompts anymore, so most people describe the things they don't want to see with \"no ...\". But having the word of the thing you don't want to have in the prompt brings attention to that concept. So at least for me it's better to describe the negative of the thing you don't want. A simple example: instead of \"no blurriness\" use \"everything is in focus\". Or something like that. You get the principle. \n\nIt's harder for some stuff. Or sometimes impossible. For example what's the negative of the color \"blue\".",
          "score": 12,
          "created_utc": "2026-01-29 12:17:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ed4au",
              "author": "Deep-Huckleberry-752",
              "text": "Totally agree regarding the older generation of models (SD/Flux) where negative tokens would often bleed into the image.\n\nBut I've noticed that Nanobanana seems to handle semantic negation much better, likely due to its stronger reasoning/LLM backbone. It treats 'No low-key lighting' as a logic constraint rather than just seeing the token 'low-key'",
              "score": 2,
              "created_utc": "2026-01-29 12:22:43",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2ee1rj",
              "author": "admajic",
              "text": "On flux klein you can say don't overstaturate and qwen3 knows what to do.  Try it",
              "score": 1,
              "created_utc": "2026-01-29 12:29:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2gpub8",
              "author": "dr_lm",
              "text": "Is this still the case with modern LLM text encoders? I'm not arguing here, but asking. \n\nMy guess is that an LLM encodes \"everything is in focus\" and \"nothing is blurry\" to essentially the same latent representation, because their understanding of language is so good. But I'm making loads of assumptions here and not very well informed...",
              "score": 1,
              "created_utc": "2026-01-29 19:13:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ec0sz",
          "author": "Icy_Wrangler5613",
          "text": "Here's my output - \n\n**My input** \\- anime Love under the sky  \n**Prompt after adding the system prompt** \\-   \n  \nVisual Style:\n\nMakoto Shinkai and CoMix Wave Films aesthetics. High-fidelity 2D anime art characterized by hyper-detailed backgrounds, vibrant color palettes, and emotional depth. Kyoto Animation influence for character expressiveness.\n\n\n\nScene and Subject:\n\nA young anime couple standing close together on a wind-swept grassy hill or rooftop, silhouetted against a massive, breathtaking sky. They are holding hands or embracing, gazing upwards with a look of wonder and affection. A gentle breeze ruffles their hair and clothes, adding a sense of motion and transience.\n\n\n\nLighting and Sky:\n\nThe sky is the visual centerpiece, featuring towering majestic cumulonimbus clouds and a gradient transition from deep indigo to burning golden orange (Magic Hour). Volumetric sunbeams, lens flares, and sparkling atmospheric particles. A comet trail or first stars appearing in the twilight.\n\n\n\nTechnical Parameters:\n\n8K resolution, highly detailed cel shading with soft gradients, wide-angle composition to emphasize the scale of the sky, cinematic aspect ratio, sharp line work.\n\n\n\nNegative Constraints:\n\nNo 3D CGI render look, no photorealistic skin textures, no distorted faces, no extra fingers or limbs, no text or watermarks, no low-quality blur, no dull or desaturated colors.\n\nhttps://preview.redd.it/wp5e1uxj5agg1.png?width=1909&format=png&auto=webp&s=311bcdf48173335aaaf12a8911a1cce7fa614bde\n\n**RESULT**",
          "score": 7,
          "created_utc": "2026-01-29 12:15:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2edj6n",
              "author": "Deep-Huckleberry-752",
              "text": "amazing! Use the system prompt?",
              "score": 0,
              "created_utc": "2026-01-29 12:25:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2f020g",
                  "author": "Icy_Wrangler5613",
                  "text": "Yes",
                  "score": 1,
                  "created_utc": "2026-01-29 14:33:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2epmpj",
          "author": "Extension_Building34",
          "text": "Cool, I‚Äôll give this a shot",
          "score": 3,
          "created_utc": "2026-01-29 13:38:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gnhet",
          "author": "Distinct-Expression2",
          "text": "The pattern matching is interesting but viral prompts are viral because of timing and luck, not just structure. Worth testing tho.",
          "score": 3,
          "created_utc": "2026-01-29 19:02:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i6rsn",
              "author": "Deep-Huckleberry-752",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-01-29 23:31:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2e2soc",
          "author": "No_Statement_7481",
          "text": "I wonder if this would actually work in not only nanobanana, I might actually try to generate some Z image after I am done with the lora I am making. Put it in my local LLM and get some promts from it.",
          "score": 2,
          "created_utc": "2026-01-29 11:04:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e5exv",
              "author": "FrankNitty_Enforcer",
              "text": "Definitely, I‚Äôve got several presets (i.e. named system prompts) in LM Studio for things like ‚Äúltx2-i2v-prompter‚Äù, where I just keep pasting key tips and examples from model/workflow-specific prompting guides. I think this OP is going to elevate things a lot where it applies.\n\nAs usual for LLMs at least for me, a lot of the fun is in tweaking the prompt. Though at times I think it‚Äôs good exercise to try writing a good one by hand, just like with coding need to really understand what‚Äôs happening",
              "score": 2,
              "created_utc": "2026-01-29 11:26:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2e4guu",
              "author": "dr_lm",
              "text": "You can use the griptape nodes and a free chutes account to do it automatically within comfyui: https://github.com/griptape-ai/ComfyUI-Griptape",
              "score": 1,
              "created_utc": "2026-01-29 11:18:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ek79t",
          "author": "addandsubtract",
          "text": "Going through the dataset, lots of them use an input image (or several?) as guidance. Are you able to include them as well? It feels like the prompt is only half of the ingredient now.",
          "score": 2,
          "created_utc": "2026-01-29 13:08:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j6cpv",
              "author": "Deep-Huckleberry-752",
              "text": "I have fixed the issue of some prompts being truncated in the previous report, which was caused by an incorrect setting of the maximum character limit. Designed 424 data items",
              "score": 2,
              "created_utc": "2026-01-30 02:46:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ku560",
                  "author": "addandsubtract",
                  "text": "Thank you, great resource!",
                  "score": 1,
                  "created_utc": "2026-01-30 10:15:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2elz4d",
              "author": "Deep-Huckleberry-752",
              "text": "Reference images are not included in the data, and many authors want users to use their own photos.",
              "score": 1,
              "created_utc": "2026-01-29 13:18:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2et4fy",
                  "author": "addandsubtract",
                  "text": "I'm also seeing lots of prompts that are cut off. Are you pulling them from the images or did the authors post them somewhere?",
                  "score": 1,
                  "created_utc": "2026-01-29 13:57:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2f59gy",
          "author": "loneuniverse",
          "text": "Thanks I‚Äôll try this, but I have no clue who Wong Kar-wai or Saul Leite are.",
          "score": 2,
          "created_utc": "2026-01-29 14:58:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f5t3y",
              "author": "Deep-Huckleberry-752",
              "text": "Haha, no worries! That's the magic of AI‚Äîyou don't need to know art history to get the look.\nFor context: Wong Kar-wai is a movie director famous for moody, emotional lighting (like 'In the Mood for Love'), and Saul Leiter was a photographer known for shooting through rainy windows and reflections.\nCombining them creates that specific 'lonely city at night' vibe automatically. Hope you get some cool results!",
              "score": 2,
              "created_utc": "2026-01-29 15:01:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2f92ad",
          "author": "zscan",
          "text": "What you actually want is the relation prompt->image, that is, how good does the image resemble what the prompt wants it to resemble. Sometimes you see these amazing images on civitai or somewhere and then you look at the prompt and the image is great, but it's not what the prompt actually asked it to do and not what the user intended to get.\n\nMy personal go to at the moment is to simply ask another AI to generate the prompt. I tell it my setup and what I want, the AI gives me a customized prompt for the model I'm using. Usually works pretty great and if it doesn't, you can tell the AI what's wrong and it can finetune it.",
          "score": 2,
          "created_utc": "2026-01-29 15:16:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2fd4yj",
              "author": "Deep-Huckleberry-752",
              "text": "Agreed, that's the right approach. I just feel that for most users, it's easier to tweak an existing base than to build one from zero",
              "score": 1,
              "created_utc": "2026-01-29 15:35:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k9h11",
          "author": "cornelln",
          "text": "But each model has its own nuance. I do not understand a general guide like this. Each require their own prompting approach.",
          "score": 2,
          "created_utc": "2026-01-30 07:09:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kakx6",
              "author": "Deep-Huckleberry-752",
              "text": "Yes, the guidelines will not always be effective, and my point of view is: if you are an expert user, this prompt is useless. But if you want to open the workflow to ordinary users so that they can also get passable works, this might be useful.",
              "score": 3,
              "created_utc": "2026-01-30 07:19:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33h1m9",
          "author": "DissenterNet",
          "text": "afinalsin has a good point. I suck at prompting but im good with data. Maybe you did this but Id suggest you look for popular images posted by accounts with lower follower counts, that should exclude a lot of the noise he mentions from mid images that are just liked because OP has a large following. Then if youve got the skills and determination you could run the images thru a prompt from image LLM and get a list of what the LLM \"sees\" in the image and have it or another LLM cross reference the two and weed out the ones where the image was popular but doesnt stick to the prompt very much. Obviously this will not be close to perfect but it will certainly increase the quality of your dataset.",
          "score": 2,
          "created_utc": "2026-02-02 03:46:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33ia49",
              "author": "Deep-Huckleberry-752",
              "text": "The issue you mentioned is exactly where I am hesitating. On one hand, I hope the popularity ranking can help those bloggers who also hope to gain traffic on X. On the other hand, I also hope it can gradually accumulate and evolve into a high-quality database. However, it seems that these two things are somewhat contradictory at the moment, and I am thinking about how to minimize manual involvement to solve this problem.",
              "score": 1,
              "created_utc": "2026-02-02 03:54:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2e0ldl",
          "author": "Wanderer43v3r",
          "text": "Looks wonderful! Thank you very much! Surely I will try.",
          "score": 2,
          "created_utc": "2026-01-29 10:46:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e7dal",
              "author": "Deep-Huckleberry-752",
              "text": "Thanks!",
              "score": 2,
              "created_utc": "2026-01-29 11:41:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2er3ny",
          "author": "SEOldMe",
          "text": "Here is a very good idea... Thanks!",
          "score": 1,
          "created_utc": "2026-01-29 13:46:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f6zrz",
          "author": "manBEARpigBEARman",
          "text": "Every model needs its own, separate system prompt. Best way to do it is feed the official documentation into an llm and ask it to use the doc to create the system prompt specifically for that model. That‚Äôs it.",
          "score": 1,
          "created_utc": "2026-01-29 15:06:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2f86dk",
              "author": "Deep-Huckleberry-752",
              "text": "Couldn't agree more. Ultimately, the creative vision matters more than the technical syntax",
              "score": 0,
              "created_utc": "2026-01-29 15:12:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2h0r9j",
          "author": "fauni-7",
          "text": "I'm having a lot of fun with this. Getting light and angles that I could never get before! Using Qwen.",
          "score": 1,
          "created_utc": "2026-01-29 20:05:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i9hw8",
              "author": "Deep-Huckleberry-752",
              "text": "Happy to helpful!",
              "score": 1,
              "created_utc": "2026-01-29 23:46:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2j5c9k",
          "author": "Deep-Huckleberry-752",
          "text": "I have fixed the issue of some prompts being truncated in the previous report, which was caused by an incorrect setting of the maximum character limit. Designed 424 data items",
          "score": 1,
          "created_utc": "2026-01-30 02:41:15",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2ldpo0",
          "author": "HollowInfinity",
          "text": "Is there some trick to copying your system prompt? The Reddit formatting seems to completely break the markdown, can you make a gist or pastebin of it?",
          "score": 1,
          "created_utc": "2026-01-30 12:46:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lfu2b",
              "author": "Deep-Huckleberry-752",
              "text": "There are downloadable files in the Git repository",
              "score": 1,
              "created_utc": "2026-01-30 12:59:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lm3gd",
                  "author": "HollowInfinity",
                  "text": "Oh, duh! Thanks!",
                  "score": 1,
                  "created_utc": "2026-01-30 13:35:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2e4b41",
          "author": "fauni-7",
          "text": "Nice.",
          "score": 0,
          "created_utc": "2026-01-29 11:17:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e7ems",
              "author": "Deep-Huckleberry-752",
              "text": "Thanks!",
              "score": 0,
              "created_utc": "2026-01-29 11:41:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2fdsb7",
          "author": "LyriWinters",
          "text": "and for which text encoder is this?\n\nNgl your post screams amateur hour instantly to me.",
          "score": -1,
          "created_utc": "2026-01-29 15:37:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2g1rn7",
              "author": "hiemdall_frost",
              "text": "And what might you do to fix this my lord grace us with you infinite wisdom and technical mastery ",
              "score": 5,
              "created_utc": "2026-01-29 17:24:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qs2h6p",
      "title": "\"Replace this character\" workflow with Flux.2 Klein 9B",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1qs2h6p",
      "author": "arthan1011",
      "created_utc": "2026-01-31 13:33:49",
      "score": 181,
      "num_comments": 40,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1qs2h6p/replace_this_character_workflow_with_flux2_klein/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2sh8zc",
          "author": "FreezaSama",
          "text": "Omg I can't wait to try this. I've struggled exactly with what you said having to do multiple random passes praying it would \"get it\". Thanks a bunch.",
          "score": 4,
          "created_utc": "2026-01-31 14:07:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sjhwy",
          "author": "Upset-Virus9034",
          "text": "Amazing",
          "score": 5,
          "created_utc": "2026-01-31 14:20:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2tgq3x",
          "author": "Eydahn",
          "text": "Is there any way to do this but with expressions?",
          "score": 3,
          "created_utc": "2026-01-31 17:07:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o358mlw",
              "author": "arthan1011",
              "text": "I'm currently working on that. Maybe I'll make a post about it later.",
              "score": 2,
              "created_utc": "2026-02-02 12:35:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o35mvff",
                  "author": "Eydahn",
                  "text": "Please do it, it would be a game changer",
                  "score": 1,
                  "created_utc": "2026-02-02 14:02:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38fzc6",
              "author": "pixel8tryx",
              "text": "Oooh.  I left that off my list!  Thanks.  Expression is another good one.  I honestly have been happy to just reproduce the original one, but being able to change it would be great.",
              "score": 1,
              "created_utc": "2026-02-02 22:00:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2swe2t",
          "author": "Whipit",
          "text": "Will this work with photos or only anime?",
          "score": 2,
          "created_utc": "2026-01-31 15:29:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2t0org",
              "author": "arthan1011",
              "text": "It works with photos too. \n\nhttps://preview.redd.it/anm6qa8vhpgg1.png?width=619&format=png&auto=webp&s=e20e32fb940cf9a926979e9cfd290c5ae8db24a6",
              "score": 7,
              "created_utc": "2026-01-31 15:50:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o330k38",
                  "author": "Tall_East_9738",
                  "text": "Why can‚Äôt it maintain the facial expressions?",
                  "score": 1,
                  "created_utc": "2026-02-02 02:10:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2v85hl",
          "author": "NebulaBetter",
          "text": "super useful, thank you!",
          "score": 2,
          "created_utc": "2026-01-31 22:14:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wi93j",
          "author": "VictorDmAlves",
          "text": "That is so cool, work like a charm. Never thought about that. I've adapt my Workflow with this idea in mind, thank you for this!",
          "score": 2,
          "created_utc": "2026-02-01 02:34:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30p6bi",
          "author": "TheGoat7000",
          "text": "Awesome WF, works great.",
          "score": 2,
          "created_utc": "2026-02-01 18:59:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bg398",
          "author": "That_Perspective5759",
          "text": "amazingÔºÅ",
          "score": 2,
          "created_utc": "2026-02-03 10:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ulfaz",
          "author": "Woisek",
          "text": ">Turn your pose reference into mannequin so it only contains information about pose and nothing else + background.\n\nCan you show an example of that?",
          "score": 1,
          "created_utc": "2026-01-31 20:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xieyi",
              "author": "arthan1011",
              "text": "Like this\n\nhttps://preview.redd.it/0aqhqx0wxtgg1.png?width=768&format=png&auto=webp&s=8f89347a66a8666b705b97d95b8d37adba8e84fb",
              "score": 1,
              "created_utc": "2026-02-01 06:46:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2yb2y9",
                  "author": "Woisek",
                  "text": "That looks nice, but also complicated. How did you do that? ü§î",
                  "score": 0,
                  "created_utc": "2026-02-01 11:09:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ursli",
          "author": "Livid_Cartographer33",
          "text": "any for qwen? idk but i struggle with it",
          "score": 1,
          "created_utc": "2026-01-31 20:53:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uxsrz",
              "author": "ANR2ME",
              "text": "Qwen Image already have a few ControlNet Union where you can do this easier.\n\nFor Qwen Image Edit you can also use TeleStyle.",
              "score": 3,
              "created_utc": "2026-01-31 21:23:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3592zt",
              "author": "arthan1011",
              "text": "Attempt to recreate this workflow in Qwen-Image-Edit was unsuccessful. Flux.2 Klein 9B is faster and lighter anyway",
              "score": 2,
              "created_utc": "2026-02-02 12:38:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2uubaf",
          "author": "zekuden",
          "text": "How do i train a lora for 2 img -> 1 img result type of lora?",
          "score": 1,
          "created_utc": "2026-01-31 21:06:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2z8x0u",
          "author": "trollkin34",
          "text": "Ok, but can you have character 1 replaced into the photo of character two where the background pose and clothing are all the same, but the second character is clearly them (face, body type, etc).",
          "score": 1,
          "created_utc": "2026-02-01 14:57:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zcoti",
              "author": "arthan1011",
              "text": "Think of elements you want to put into image1 from image2.  \nImage 1 preprocess: remove hair, face. Keep background and faceless bald figure. (also try specifying target body type)  \nImage 2 preprocess: remove background, clothes. Only keep face and hair.\n\nAt combining step try this prompt: \"Change character on image 1 to match character on image 2\". If something is missing try adding extra details to your prompt.",
              "score": 1,
              "created_utc": "2026-02-01 15:17:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2zegeu",
                  "author": "trollkin34",
                  "text": "I've tried many things and fail every time. If I described it using your pics it would be\n\nGreen Fern in image 1 replaces Mina in image 2 cosplaying as her - wearing the same clothes, in the same pose, but with the same body proportions and detail of image 1\n\nI'm not sure if that's even possible right now, but I'd love to find a way.",
                  "score": 1,
                  "created_utc": "2026-02-01 15:25:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o340bhl",
          "author": "t_mtz",
          "text": "Which folder should i put the files (qwen\\_3\\_8b\\_fp8mixed.safetensors) and (vae / flux2-vae.safetensors)? Im begginer",
          "score": 1,
          "created_utc": "2026-02-02 06:01:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o341bme",
              "author": "arthan1011",
              "text": "From this doc - [https://docs.comfy.org/tutorials/flux/flux-2-klein](https://docs.comfy.org/tutorials/flux/flux-2-klein)  \n  \nüìÇ ComfyUI/\n\n‚îú‚îÄ‚îÄ üìÇ models/\n\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ diffusion\\_models/\n\n‚îÇ   ‚îÇ      ‚îú‚îÄ‚îÄ flux-2-klein-9b-fp8.safetensors\n\n‚îÇ   ‚îÇ      ‚îî‚îÄ‚îÄ flux-2-klein-base-9b-fp8.safetensors\n\n‚îÇ   ‚îú‚îÄ‚îÄ üìÇ text\\_encoders/\n\n‚îÇ   ‚îÇ      ‚îî‚îÄ‚îÄ qwen\\_3\\_8b\\_fp8mixed.safetensors\n\n‚îÇ   ‚îî‚îÄ‚îÄ üìÇ vae/\n\n‚îÇ          ‚îî‚îÄ‚îÄ flux2-vae.safetensors",
              "score": 1,
              "created_utc": "2026-02-02 06:09:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36spg2",
          "author": "aeonsmagic",
          "text": "Excuse me, where is the workflow? And I need a LoRa that I can't find. Thanks.",
          "score": 1,
          "created_utc": "2026-02-02 17:25:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36uv1a",
              "author": "arthan1011",
              "text": "By following the link on (pic. 1) you'll open to the openart website. You'll be able to download the workflow if you click on \"Download\" button (pic. 2). Drag and drop downloaded workflow (json file) into the ComfyUI interface and you'll see the workflow. This workflow works without any LoRAs.\n\nhttps://preview.redd.it/k74x23r1a4hg1.png?width=693&format=png&auto=webp&s=fefcefe33eaddcb2f3307ab13699c136b41ccd50",
              "score": 2,
              "created_utc": "2026-02-02 17:35:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37coar",
                  "author": "aeonsmagic",
                  "text": "Sorry, the link disappeared when I translated the page, I see it now... thanks for your help.",
                  "score": 1,
                  "created_utc": "2026-02-02 18:55:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o375rbs",
          "author": "Fun-Yesterday-4036",
          "text": "i got everytime a nvfp4 error (5090 btw) does anyone have a solution?",
          "score": 1,
          "created_utc": "2026-02-02 18:24:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3765r0",
              "author": "Fun-Yesterday-4036",
              "text": "nevermind, a update of comfy solved it",
              "score": 1,
              "created_utc": "2026-02-02 18:26:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38f0nm",
          "author": "pixel8tryx",
          "text": "It's good to see other people getting creative and actually thinking about this.  FLUX.2 is super powerful and surprises me every day, but I know I need to work on learning how the model \"sees\" things and works best to accomplish complex workflows. \n\nI just started playing with depth maps to decouple this.  Particularly when I want to decouple the virtual 'geometry' from the virtual texture maps. It can specify shape and layout without it learning colors, patterns, lighting, etc. from the reference image.\n\nI guess ultimately one could end up with a number of input references (for chars): 1) character likeness,  2) pose,  3) outfit, 4) outfit materials (if you need to change color or fabric), 5) environment, 6) art style/technique.  \n\nSo far I've done stylized portraits of important people with FLUX.2 and the best results have been using a photo (or painting or whatever exists) as an input reference and prompting for a style.   I've only done \"banknote engraving\" and \"engraving by Albrecht Durer\".  But it worked great!  Kontext often sucked.  It reduced them to things like \"a guy with glasses and a moustache\".  Any guy with glasses and a moustache.  The web is filled with portraits like this and I'm not going to make more.  \n\nAn anime character can be approximated fairly easily, but a certain craggy older man's face contains a tremendous amount of detail and to someone hypersensitive like me, even an iconic character like Einstein can look so wrong.  He's just another old guy with wild hair and a moustache.  Sorry, but I've been on a huge \"likeness\" kick because it appears to be disappearing from the web.  Outside of places like here, where people put lots of effort into character likeness, the rest of the web - even big magazines - are putting forth the least amount of effort and make cheesy, crappy images. And I don't whine so much because it's an assault on my eyes as it's because it all gets trained into the next generation of models.  \\[/end rant\\] \n\nFLUX.2 likeness can be \\~70% absolutely perfect.  I might have to gen a 2nd or 3rd at most.  Not, \"kinda looks like\", or \"good from someone no one really knows\".  But wows me on people I know really well and can spot AI gens of instantly.  I need to explore this further as I've just started to try other art mediums with varying success.",
          "score": 1,
          "created_utc": "2026-02-02 21:55:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3afq7k",
          "author": "Aru_Blanc4",
          "text": "why...oh why does  everything  haveto be in unet loader????  \nI don't want to just have two copies of the same file, ughhhh",
          "score": 1,
          "created_utc": "2026-02-03 04:46:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2vae36",
          "author": "Visual_Weather_7937",
          "text": "Please someone do this in RunPod!",
          "score": -1,
          "created_utc": "2026-01-31 22:25:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32qbwp",
              "author": "alivekta",
              "text": "Run comfyui on runbid and drag and drop the workflow that it",
              "score": 2,
              "created_utc": "2026-02-02 01:12:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqzj6v",
      "title": "ComfyUI-QwenTTS v1.1.0 ‚Äî Voice Clone with reusable VOICE + Whisper STT tools + attention options",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1qqzj6v",
      "author": "Narrow-Particular202",
      "created_utc": "2026-01-30 08:07:28",
      "score": 176,
      "num_comments": 25,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1qqzj6v/comfyuiqwentts_v110_voice_clone_with_reusable/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2l7pe9",
          "author": "Billysm23",
          "text": "Can I clone a voice with added expression/tone (write it in a prompt)?",
          "score": 7,
          "created_utc": "2026-01-30 12:05:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2meo4n",
              "author": "Narrow-Particular202",
              "text": "With Qwen3-TTS, you can clone a speaker from a reference sample, but¬†**prompt-only control of different emotions while keeping the exact same cloned voice isn‚Äôt reliably supported**¬†right now. In practice, strong ‚Äútone/emotion‚Äù prompts often lead to¬†**voice drift**¬†or only subtle/inconsistent emotion changes. If you need consistent emotions, the usual workaround is¬†**separate reference samples per emotion/style**¬†(or using a TTS model that explicitly supports expressive conditioning).\n\nWe‚Äôre also keeping an eye on Qwen3-TTS models updates, if/when reliable emotion/style control for cloned voices becomes available (and fits our integration), we‚Äôll evaluate it and ship support in Rebit as soon as we can.",
              "score": 6,
              "created_utc": "2026-01-30 15:54:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2qmux6",
                  "author": "whyyoutouzhelele",
                  "text": "Thanks for clarification. Hope they will make prompt-only emotion control happen in the next update.",
                  "score": 1,
                  "created_utc": "2026-01-31 04:56:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2l3sru",
          "author": "RIP26770",
          "text": "Why choose Whisper over the new Qwen ASR?",
          "score": 3,
          "created_utc": "2026-01-30 11:36:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mcsfo",
              "author": "Narrow-Particular202",
              "text": "We chose **Whisper** because when this tool was developed, **Qwen3-ASR was not yet available** (it was released only a few days ago). Whisper is also widely adopted, lightweight, and easy for users to run locally‚Äîthe smallest Qwen3-ASR model (0.6B) about 2GB is still larger than Whisper‚Äôs largest model.\n\nThat said, **Qwen3-ASR support is planned** and will be added to the repository soon, so users will be able to choose the ASR model they prefer.",
              "score": 5,
              "created_utc": "2026-01-30 15:45:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2lv7ht",
              "author": "MisterBlackStar",
              "text": "Sharing the node for it here in case anyone missed it:  [ComfyUI-Qwen3-ASR](https://www.reddit.com/r/comfyui/s/Bo3WHEufaF)",
              "score": 3,
              "created_utc": "2026-01-30 14:22:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2pgs4z",
              "author": "Narrow-Particular202",
              "text": "Discover ComfyUI-QwenASR at [https://github.com/1038lab/ComfyUI-QwenASR](https://github.com/1038lab/ComfyUI-QwenASR) we hope you enjoy it!",
              "score": 1,
              "created_utc": "2026-01-31 00:37:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2piobf",
                  "author": "RIP26770",
                  "text": "The requirements.txt looks like it's going to break a lot of ComfyUI installations, as it is! üòÇ\n\n\naccelerate>=1.12.0\nhuggingface_hub\nmodelscope\nnagisa==0.2.11\nsoynlp==0.0.493\nDyNet38==2.2\nnumpy\nsoundfile\ntorch>=2.0.0\ntorchaudio>=2.0.0\ntransformers>=4.57.0",
                  "score": 1,
                  "created_utc": "2026-01-31 00:47:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2l4hrg",
          "author": "lebrandmanager",
          "text": "I have experimented with QwenTTS.for a while now. But whatever I do, I still like Vibevoice a lot better. This mainly comes down to the fact that VV captures the tonality and emotion of the input better (by far) than Qwen. Even with Fine-tuning the output sounds bland and monotone. I admit that the quality itself is good, but the rest is lacking.",
          "score": 3,
          "created_utc": "2026-01-30 11:42:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2p0n85",
              "author": "bigman11",
              "text": "I am salivating at the thought of how good the next generation of models will be.",
              "score": 1,
              "created_utc": "2026-01-30 23:08:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2v2fo2",
              "author": "leepuznowski",
              "text": "I am currently using QwenTTS to create a voice direction I like to then input into VV for final emotional boost. This works well for creating custom voices.",
              "score": 1,
              "created_utc": "2026-01-31 21:46:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l2tfl",
          "author": "MelvinMicky",
          "text": "is it possible to merge voices sort of? so like combining loras providing 2 different voices and get a new one out?",
          "score": 3,
          "created_utc": "2026-01-30 11:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2llpxn",
              "author": "Segaiai",
              "text": "I've wondered this myself",
              "score": 1,
              "created_utc": "2026-01-30 13:33:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2m2gub",
          "author": "QuailLife7760",
          "text": "Example outputs?",
          "score": 2,
          "created_utc": "2026-01-30 14:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lbwhy",
          "author": "howardhus",
          "text": "wow his sounds great. you da real mvp",
          "score": 1,
          "created_utc": "2026-01-30 12:34:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m5mu4",
          "author": "Maydaysos",
          "text": "Any option for voice clone with voice instructions?",
          "score": 1,
          "created_utc": "2026-01-30 15:13:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mi1eg",
              "author": "ronbere13",
              "text": "no",
              "score": 1,
              "created_utc": "2026-01-30 16:09:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ms6jc",
          "author": "CommunicationCalm197",
          "text": "Does it only support the English language?",
          "score": 1,
          "created_utc": "2026-01-30 16:54:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mxhsn",
              "author": "Narrow-Particular202",
              "text": "**Languages**: Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, Italian.",
              "score": 1,
              "created_utc": "2026-01-30 17:18:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2n5nyy",
                  "author": "CommunicationCalm197",
                  "text": "Thanks",
                  "score": 1,
                  "created_utc": "2026-01-30 17:54:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2owvsl",
          "author": "cutter89locater",
          "text": "Any chance supports Chinese (yue) on all?",
          "score": 1,
          "created_utc": "2026-01-30 22:48:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qqpas",
          "author": "Tomatillo_Impressive",
          "text": "I get --> 'Qwen3TTSTalkerConfig' object has no attribute 'pad\\_token\\_id' error and after updating i get \\[Qwen3-TTS\\] Model class is not loaded because the 'qwen\\_tts' package failed to import. Please check the ComfyUI console for the detailed 'Critical Import Error' above.",
          "score": 1,
          "created_utc": "2026-01-31 05:24:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ulbme",
              "author": "Grand_Result6732",
              "text": "Entra na pasta python embeded e da o comando abaixo:  \n\"python.exe -m pip install transformers==4.57.3",
              "score": 2,
              "created_utc": "2026-01-31 20:21:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2vjnnv",
                  "author": "smarkie1337",
                  "text": "this worked, thank you",
                  "score": 1,
                  "created_utc": "2026-01-31 23:14:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qsiqff",
      "title": "Creating a Comfy x Photoshop Plugin",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/u3bta76wurgg1",
      "author": "-JProject-",
      "created_utc": "2026-02-01 00:06:46",
      "score": 169,
      "num_comments": 56,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1qsiqff/creating_a_comfy_x_photoshop_plugin/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2vubus",
          "author": "Low_Drop4592",
          "text": "Please make it available.\n\nAlso, please automatically add a \"reveal all\" layer mask to the inpainted layer to make it easy to paint out the seams.",
          "score": 16,
          "created_utc": "2026-02-01 00:14:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x6cv7",
              "author": "-JProject-",
              "text": "Appreciate your input!\n\nI agree, it would be handy if it automatically adds the reveal layer mask for you to paint in with a black brush :)\n\nI will look at adding this too.",
              "score": 3,
              "created_utc": "2026-02-01 05:11:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2x6qt1",
                  "author": "Synchronauto",
                  "text": "Any chance this will work on older PS CS6?  Or only the subscription PS?",
                  "score": 3,
                  "created_utc": "2026-02-01 05:14:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2y5mid",
                  "author": "embryo10",
                  "text": "Yes, PS CS6 support would be great!!",
                  "score": 3,
                  "created_utc": "2026-02-01 10:19:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2w6bgs",
          "author": "paulatheprogrammer",
          "text": "Very nice! This should help keep my data away from Adobe as well as not pay extra for Firefly!",
          "score": 10,
          "created_utc": "2026-02-01 01:22:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yi30b",
              "author": "superkickstart",
              "text": "Krita + krita ai diffusion plugin and you can ditch photoshop entirely. \n\nhttps://github.com/Acly/krita-ai-diffusion",
              "score": 7,
              "created_utc": "2026-02-01 12:08:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31ox9c",
                  "author": "paulatheprogrammer",
                  "text": "Wow! Sounds amazing! I've actually stopped using Adobe software since they switched to SaaS and introduced Creative Cloud.",
                  "score": 2,
                  "created_utc": "2026-02-01 21:51:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2x9act",
              "author": "-JProject-",
              "text": "Haha yes! Also the sheer lack of control with generative fill in PS has always left more to be desired. \n\nI plan to add more options for controlling comfy in the future - hopefully without making it too overwhelming and messy :)",
              "score": 2,
              "created_utc": "2026-02-01 05:33:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2wg8jc",
          "author": "goose1969x",
          "text": "Super support this. Invoke sold out and abandoned the open source community for a cash grab. Love this project for bootstrapping onto PS, I'd assume it'd be easy enough to also plug into Affinity.",
          "score": 5,
          "created_utc": "2026-02-01 02:22:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x856l",
              "author": "-JProject-",
              "text": "Thanks, I appreciate the support :)\n\nI used to use invoke back in the day but I have always been locked into Photoshop, using hodge podge ways of working with comfy and Photoshop together. I think this helps make things much more seamless, that's the intention anyway!\n\nI don't have any experience in Affinity. Unfortunately I can't really comment on how easy it would be to migrate over, sorry :)",
              "score": 1,
              "created_utc": "2026-02-01 05:24:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2y6kkm",
          "author": "embryo10",
          "text": "I'm currently using this [https://github.com/NimaNzrii/comfyui-photoshop](https://github.com/NimaNzrii/comfyui-photoshop) for newer versions of Photoshop, and although it's kind of abandoned, it still works for my needs (get a masked image input from PS and return the generated image as a smart object).  \nIt works fine, but there are two things I'm thinking about.  \n\\- It might stop working in the future of ComfyUI updates, and  \n\\- No support for PS CS6 (I have to open the bloated PS 26 every time I want to edit an image)\n\nAnyway, thank you for your time and support to the community.. üôè",
          "score": 3,
          "created_utc": "2026-02-01 10:28:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zug2j",
              "author": "EuSouChester",
              "text": "I use a different node. SD-ppp is updated every 3 months. [https://sdppp.zombee.tech/](https://sdppp.zombee.tech/)",
              "score": 1,
              "created_utc": "2026-02-01 16:40:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o300kga",
                  "author": "embryo10",
                  "text": "From a quick look it seems a lot more complicated than the one I use, and I also saw something about **r**egistering a RunningHUB account and getting an API key..  \nI just want an input/output node, nothing more.  \nI do all the rest myself inside the ComfyUI workflow (that's why I can work with anything I want, like Z-Image, Qwen, etc.).  \nThanks for the info though..",
                  "score": 2,
                  "created_utc": "2026-02-01 17:08:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2w3bia",
          "author": "No-Expression6444",
          "text": "Very interested thank you, look forward to the plugin's development, great work.",
          "score": 3,
          "created_utc": "2026-02-01 01:04:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x8b8i",
              "author": "-JProject-",
              "text": "Appreciate the support :)",
              "score": 1,
              "created_utc": "2026-02-01 05:25:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2whzad",
          "author": "TanguayX",
          "text": "REALLY cool. Super interested. I‚Äôm interested in comfy integration with traditional tools for production. This is a great one",
          "score": 3,
          "created_utc": "2026-02-01 02:33:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2wnmxn",
              "author": "guigouz",
              "text": "There's https://kritaaidiffusion.com/",
              "score": 9,
              "created_utc": "2026-02-01 03:07:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2xmety",
                  "author": "Space__Whiskey",
                  "text": "I like Krita but they lack support for newer models and methods.",
                  "score": -1,
                  "created_utc": "2026-02-01 07:22:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2x9ojh",
              "author": "-JProject-",
              "text": "Appreciate your support, thanks!\n\nI have been using comfy alongside Photoshop in my day job but it's always been a cumbersome worfklow, this seems to be helping a fair bit :)",
              "score": 1,
              "created_utc": "2026-02-01 05:36:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2wi14l",
          "author": "cryptoknowitall",
          "text": "fantastic work! really hope you release it one day!  \nare you running SD 1.5 or something newer within comfy?",
          "score": 2,
          "created_utc": "2026-02-01 02:33:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x74it",
              "author": "-JProject-",
              "text": "Thanks, I appreciate it! From the response so far I do hope to get it released for people to use.\n\nThe example in the video is running an SD1.5 checkpoint but I hope to build the option for different models and their corresponding workflow needs into the plugin over time :)",
              "score": 2,
              "created_utc": "2026-02-01 05:17:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2wk1pg",
          "author": "scoobasteve813",
          "text": "Would love to test it out!",
          "score": 2,
          "created_utc": "2026-02-01 02:45:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wqeku",
          "author": "AgreeableAd5260",
          "text": "de donde descargo?",
          "score": 2,
          "created_utc": "2026-02-01 03:24:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2x98b2",
          "author": "optimisticalish",
          "text": "Excellent. One of the problems with the other plugins is that they only work on recent versions of Photoshop. Any chance that yours will work on older versions (i.e. before CC 2019?).",
          "score": 2,
          "created_utc": "2026-02-01 05:32:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xpqz6",
              "author": "-JProject-",
              "text": "I am not too sure at the moment. This is something I will have to look into for the future. I know there was a stability issue with a function prior to version 23.0 of PS that this plugin uses. It might work and be unstable or might just not work at all. I will keep this in mind though and will let everyone know when I have it ready for download.",
              "score": 2,
              "created_utc": "2026-02-01 07:52:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xg1s8",
          "author": "Adventurous-Gold6413",
          "text": "Consider working on photopea as well",
          "score": 2,
          "created_utc": "2026-02-01 06:26:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xgags",
          "author": "agrophobe",
          "text": "I had a big 10 hours of getting up to date with the new stuff around today. I‚Äôve been in another project for a year. While taking a break outside, I pondered about all the cool stuff I would be able to do mixing ai agent and comfy on replicate and comfycloud. Maybe even UE5\n\nAnd then it hit me. Photoshop is such an old software. Were is its node editing? \nBlender, Comfy, Unreal, they all have this ubercool way to explode your imagination.",
          "score": 2,
          "created_utc": "2026-02-01 06:28:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xmm9o",
          "author": "Extra-Fig-7425",
          "text": "Definitely interested :)",
          "score": 2,
          "created_utc": "2026-02-01 07:23:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y1gyf",
          "author": "Nuwan28",
          "text": "Superb! Any plans to develop for Affinity too? Would love to migrate to a fully local workflow",
          "score": 2,
          "created_utc": "2026-02-01 09:41:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y4083",
          "author": "ImpressiveStorm8914",
          "text": "Definitely interested, especially if it‚Äôs possible to have it working on older versions like CS6. Although that may be hoping for too much.",
          "score": 2,
          "created_utc": "2026-02-01 10:04:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yr4ps",
          "author": "Grindora",
          "text": "This is amazing !! Cant wait! Pls release it",
          "score": 2,
          "created_utc": "2026-02-01 13:15:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ztvsy",
          "author": "EuSouChester",
          "text": "Look, a rival to SD-ppp!",
          "score": 2,
          "created_utc": "2026-02-01 16:38:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o301f1y",
              "author": "-JProject-",
              "text": "I didn't even know this existed, this looks cool too :)",
              "score": 1,
              "created_utc": "2026-02-01 17:12:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xnvv4",
          "author": "InoSim",
          "text": "No flips, no boots.",
          "score": 1,
          "created_utc": "2026-02-01 07:35:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ydr8m",
          "author": "razortapes",
          "text": "Does anyone know if there‚Äôs any way to use Klein 9b to edit in Photoshop?",
          "score": 1,
          "created_utc": "2026-02-01 11:32:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ylyo7",
          "author": "extra2AB",
          "text": "I was waiting for something like this for so long, it would be amazing if the editing changes are saved as a NEW LAYER.",
          "score": 1,
          "created_utc": "2026-02-01 12:39:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ytf28",
              "author": "-JProject-",
              "text": "Each comfy render comes in as a new layer every time so it never overwrites what's underneath. :)",
              "score": 1,
              "created_utc": "2026-02-01 13:30:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33rvyr",
          "author": "JagXeolin",
          "text": "What about krita ai?",
          "score": 1,
          "created_utc": "2026-02-02 04:57:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o388g0i",
              "author": "-JProject-",
              "text": "There is another commenter u/superkickstart on this post that creates a cool Krita Plugin :) I will only be developing mine for Photoshop",
              "score": 1,
              "created_utc": "2026-02-02 21:24:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o34pk6n",
          "author": "ramonartist",
          "text": "Can you add support for Affinity?",
          "score": 1,
          "created_utc": "2026-02-02 09:53:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qufdqi",
      "title": "OMG! My comfy skills I've painfully acquired over the past year have finally paid off, I am super happy with what I can accomplish!!! Now I just need to take my time and make longer better stuff!",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/d8h55a2av6hg1",
      "author": "Mean-Band",
      "created_utc": "2026-02-03 02:15:30",
      "score": 137,
      "num_comments": 21,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1qufdqi/omg_my_comfy_skills_ive_painfully_acquired_over/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3apb5e",
          "author": "ANR2ME",
          "text": "Yes, longer (and bigger) are better üòè\n\nNice works thoüëç",
          "score": 9,
          "created_utc": "2026-02-03 05:58:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39wid2",
          "author": "MrChurch2015",
          "text": "Meanwhile, I'm over here struggling to get sdxl to successfully outpaint a scene lol",
          "score": 10,
          "created_utc": "2026-02-03 02:46:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3a99x7",
              "author": "sci032",
              "text": "Search Comfy's templates for    outpaint   The 1st one uses sdxl.\n\nhttps://preview.redd.it/m5d4n3vhe7hg1.png?width=2118&format=png&auto=webp&s=9b8092e16a8edd948d78f1247becdecff8c9d8d4",
              "score": 5,
              "created_utc": "2026-02-03 04:03:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3aqj4d",
                  "author": "MrChurch2015",
                  "text": "I don't have that option",
                  "score": 2,
                  "created_utc": "2026-02-03 06:08:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bf4av",
          "author": "Scrublord_Rat",
          "text": "and here I am, failing to animate an Illustrious pic for 5 secs",
          "score": 3,
          "created_utc": "2026-02-03 09:57:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3cyv0b",
              "author": "BigNaturalTilts",
              "text": "I‚Äôm also stuck here. Hate how VRAM hungry video is and kicking myself for not getting higher VRAM when I had the chance.",
              "score": 2,
              "created_utc": "2026-02-03 15:54:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3chu42",
          "author": "shamomylle",
          "text": "Congratulations! As someone who is just starting to learn comfyUI, this is inspirational, that motivates me to learn more!",
          "score": 3,
          "created_utc": "2026-02-03 14:30:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3clbi9",
          "author": "skyrimer3d",
          "text": "really good, but pls add what tools you used for this.",
          "score": 3,
          "created_utc": "2026-02-03 14:48:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b1pp7",
          "author": "ghouleye",
          "text": "Nice the snail guy was cool",
          "score": 3,
          "created_utc": "2026-02-03 07:47:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3c41m1",
          "author": "Conscious-Citzen",
          "text": "Bruh... This is by far one of the best things I've seen.\nCongrats. I'm following you now. I hope I can get to do something remotely close to that someday. For now I'm just trying to figure it out how to sync wan and mmaudio, lol. \n\nMay I ask you what's Ur system setup?\nCongratulations.",
          "score": 2,
          "created_utc": "2026-02-03 13:13:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d8whw",
              "author": "Mean-Band",
              "text": "4090 i9 64gb ddr5",
              "score": 2,
              "created_utc": "2026-02-03 16:41:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3cy5wg",
          "author": "Busy_Aide7310",
          "text": "It's inspirational. Do you have a link to view it at better resolution?  \nWhat is your hardware?",
          "score": 2,
          "created_utc": "2026-02-03 15:51:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ddxh2",
              "author": "Mean-Band",
              "text": "https://www.tiktok.com/@steven.mcgready?_r=1&_t=ZT-93cNVxtt69m",
              "score": 1,
              "created_utc": "2026-02-03 17:04:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3avqeu",
          "author": "BlackFoxLingerie",
          "text": "How do you do the lipsync thing? I haven't even started messing with video generation yet.",
          "score": 2,
          "created_utc": "2026-02-03 06:53:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bcgxa",
              "author": "DeliciousReference44",
              "text": "I am more interested on the SFX! Was that added with comfyui or post editing?",
              "score": 4,
              "created_utc": "2026-02-03 09:31:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ayg3u",
              "author": "RobMilliken",
              "text": "Wan 2.1 and 2.2 you can put audio with nodes like multitalk.\n\nLTX-2 has speech built into the model (sound effects and singing too, the latter only sounds so so).",
              "score": 5,
              "created_utc": "2026-02-03 07:17:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3c2ouc",
                  "author": "Conscious-Citzen",
                  "text": "I struggle lot with mmaudio. Audio finishes B4 the video, unsynced stuff... Any tip, mate?\n\nI heard it works at 24fps and if wan vid is less than that might be the cause, but I don't know how to work around that.",
                  "score": 2,
                  "created_utc": "2026-02-03 13:05:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3b7zat",
          "author": "Evening_Hedgehog_194",
          "text": "congrats!!!",
          "score": 1,
          "created_utc": "2026-02-03 08:47:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtfnll",
      "title": "Repo with my Workflows",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1qtfnll/repo_with_my_workflows/",
      "author": "VictorDmAlves",
      "created_utc": "2026-02-02 00:19:01",
      "score": 129,
      "num_comments": 11,
      "upvote_ratio": 0.99,
      "text": "Hello everyone!  \nI've been using ComfyUI for over two years now and I've been messing around with the new model that are released. It's so much fun! This experience has only been so satisfying thanks to everyone sharing their knowledge and Workflows here on Reddit and in Discord groups.\n\nWith that in mind, and wanting to create a backup environment for my workflows, I created a repository on GitHub and included all my work so far (I plan to keep updating it).\n\nI wanted to thank this wonderful community and everyone for their contributions. I hope that, at least, these workflows will help someone along the way.\n\nI had a very promising journey a few years ago at Civitai, creating LoRAs of Flux (before the big explosion of censorship and some other topics). I'm thinking about creating a similar repository on Git, sharing techniques for datasets, prompt captures, and training configurations; I'm still figuring out how to do it.\n\nAnyways, see you down the line on this almost endless road of learning and tinkering.  \nCheers!\n\n[https://github.com/VictorDmAlves/comfyui-workflows](https://github.com/VictorDmAlves/comfyui-workflows)",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1qtfnll/repo_with_my_workflows/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o34iqwg",
          "author": "New_Physics_2741",
          "text": "Clean and organized like a champ, nice. Thanks\\~",
          "score": 8,
          "created_utc": "2026-02-02 08:47:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32poet",
          "author": "-SaltyAvocado-",
          "text": "Thanks!",
          "score": 5,
          "created_utc": "2026-02-02 01:08:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34ghlr",
          "author": "SvenVargHimmel",
          "text": "more people should do this. \n\nFunnily  enough on the weekend I'd been working on a tool to publish workflows to github.\n\n  \n[https://github.com/svenhimmelvarg/comfyui-workflows/tree/dev?tab=readme-ov-file](https://github.com/svenhimmelvarg/comfyui-workflows/tree/dev?tab=readme-ov-file)\n\n  \nOn the dev branch is me messing with the templates for the READMEs",
          "score": 6,
          "created_utc": "2026-02-02 08:25:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o332tfj",
          "author": "QikoG35",
          "text": "Thanks for sharing!",
          "score": 3,
          "created_utc": "2026-02-02 02:23:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o338wng",
          "author": "kenjiv",
          "text": "thank you!",
          "score": 3,
          "created_utc": "2026-02-02 02:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o33e9rh",
          "author": "maximebermond",
          "text": "Thank you!",
          "score": 3,
          "created_utc": "2026-02-02 03:29:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o33u9vr",
          "author": "Trickhouse-AI-Agency",
          "text": "Thanks mate",
          "score": 3,
          "created_utc": "2026-02-02 05:14:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o345ykl",
          "author": "Express-Challenge-51",
          "text": "Thank you!",
          "score": 3,
          "created_utc": "2026-02-02 06:49:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34nf8l",
          "author": "ibaitxoMJ",
          "text": "Genial. Gracias!",
          "score": 3,
          "created_utc": "2026-02-02 09:33:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35dfli",
          "author": "Southern-Radio-4954",
          "text": "Hero!",
          "score": 3,
          "created_utc": "2026-02-02 13:07:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36wenf",
          "author": "IAmRyanJ",
          "text": "Thank you. This is excellent.",
          "score": 3,
          "created_utc": "2026-02-02 17:42:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqw0cz",
      "title": "Image to Image w/ Flux Klein 9B (Distilled)",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1qqw0cz",
      "author": "FeelingVanilla2594",
      "created_utc": "2026-01-30 04:52:15",
      "score": 127,
      "num_comments": 8,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1qqw0cz/image_to_image_w_flux_klein_9b_distilled/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2l1ds2",
          "author": "theOliviaRossi",
          "text": "also you can use as prompt: \"increase quality and restore colors of the image, add details to the image, make it more photorealistic\" ... etc.",
          "score": 11,
          "created_utc": "2026-01-30 11:17:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lsw97",
              "author": "ANR2ME",
              "text": "Yeah, this is pretty much works like photo restoration workflows.",
              "score": 2,
              "created_utc": "2026-01-30 14:10:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2kxaoc",
          "author": "Sunny-vibes",
          "text": "No comments?? It's such a good idea :)",
          "score": 3,
          "created_utc": "2026-01-30 10:42:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mhin0",
          "author": "prompt_seeker",
          "text": "4B also quite good to just refine.",
          "score": 3,
          "created_utc": "2026-01-30 16:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lbt6k",
          "author": "Zueuk",
          "text": "anyone knows how to reliably prevent F2K from stretching the image, like it did on \"noodels\" here?",
          "score": 2,
          "created_utc": "2026-01-30 12:34:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lt8ze",
          "author": "FeelingVanilla2594",
          "text": "Tldr, I let another model start an image and klein to finish the image using the same prompt while using reference latent to guide klein.",
          "score": 2,
          "created_utc": "2026-01-30 14:12:35",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2tm0ij",
              "author": "Ugleh",
              "text": "Without looking, are you saying you send the latent from z-image straight through to klein without having to decode it first?",
              "score": 2,
              "created_utc": "2026-01-31 17:33:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2tmdh0",
                  "author": "FeelingVanilla2594",
                  "text": "I decode the image first, and load it as ref image for klein. I think their latents are incompatible, but I haven‚Äôt tried passing directly. Klein uses the new flux 2 vae.\n\nEdit: ok just tried, it doesn‚Äôt work. Zib vae is 16 channels and 8x downscale, klein vae is 128 channels and 16x downscale.",
                  "score": 1,
                  "created_utc": "2026-01-31 17:34:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qt88kg",
      "title": "Z image base teacher model (fp32) leaked accidentally",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1qt88kg",
      "author": "Suitable-League-4447",
      "created_utc": "2026-02-01 19:33:35",
      "score": 126,
      "num_comments": 66,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1qt88kg/z_image_base_teacher_model_fp32_leaked/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o31av7f",
          "author": "BathroomEyes",
          "text": "What makes you think it‚Äôs the teacher model? It could just be the fp32 precision version of the model released last week.\n\nEdit: The source of the confusion is that everyone has been calling the model released last week (Z-Image) by the name of the teacher model Z-Image Base. The teacher model Z-Image base has not been released yet. If the file name is named Z-Image then it‚Äôs likely not the teacher model.",
          "score": 47,
          "created_utc": "2026-02-01 20:43:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o323aum",
              "author": "ImpressiveStorm8914",
              "text": "It didn't help matters that their own documentation called it a base model but they didn't name it a base model. Even the actual base model is called Omni-Base, not just Base. Z-Image on it's own for one model, when the whole range also has that name is poor naming IMO.",
              "score": 9,
              "created_utc": "2026-02-01 23:04:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o34uafz",
              "author": "Tbhmaximillian",
              "text": "what is an teacher model?",
              "score": 4,
              "created_utc": "2026-02-02 10:38:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3azcjd",
                  "author": "INTRUD3R_4L3RT",
                  "text": "It's the one that won't accept a prompt unless you call it Senpai.",
                  "score": 2,
                  "created_utc": "2026-02-03 07:25:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o31ths7",
              "author": "TheSlateGray",
              "text": "I think it would be better to call it version 0.36 instead of full, fp32, teacher or anything else, because that same commit could be converted to any weights. I made an fp16 from that commit, which comes out to the same 11.5GiB as 0.37.\n\nIt'll take me about an hour to upload it though for everyone else to test.",
              "score": 4,
              "created_utc": "2026-02-01 22:14:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o31wemw",
              "author": "Nextil",
              "text": "That's what I expected but after testing it locally, at the same seed, they do produce quite different outputs, more than the typical difference between outputs of different quants, which is usually very minimal. The aesthetic, pose, background elements, etc. remain very close across both though. My guess is the fp32 is an older checkpoint with less SFT, but I find it hard to imagine it went through no SFT at all, because the output is too close.",
              "score": 1,
              "created_utc": "2026-02-01 22:28:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31y4wo",
                  "author": "BathroomEyes",
                  "text": "I took into account how the mistake may have happened. Imagine the fp32 file was in the same directory as the other two quants in their local copy of the repo and forgot to exclude it or add to gitignore. Why would the foundation model be in the same directory as the other two quants?",
                  "score": 3,
                  "created_utc": "2026-02-01 22:37:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o31118k",
          "author": "hyperedge",
          "text": "why post this without a link?\n\nEdit I found this: [https://huggingface.co/notaneimu/z-image-base-comfy-fp32/tree/main](https://huggingface.co/notaneimu/z-image-base-comfy-fp32/tree/main)\n\nUse this flag when starting comfy  --fp32-unet",
          "score": 30,
          "created_utc": "2026-02-01 19:55:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o318ihs",
              "author": "GraftingRayman",
              "text": "what kind of vram are we looking at to use this?",
              "score": 7,
              "created_utc": "2026-02-01 20:31:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38hh9a",
                  "author": "StuccoGecko",
                  "text": "yes.",
                  "score": 3,
                  "created_utc": "2026-02-02 22:07:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o31c64t",
              "author": "StatusBard",
              "text": "How much memory does it require with that parameter?",
              "score": 3,
              "created_utc": "2026-02-01 20:49:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31ee8w",
                  "author": "hyperedge",
                  "text": "it must be a lot because I tried with 5070ti and 64GB of RAM and one step took over a minute and the generation even seemed to slowdown after. I didn't even let it finish.",
                  "score": 4,
                  "created_utc": "2026-02-01 21:00:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o327p7f",
                  "author": "durden111111",
                  "text": "It runs on my 5090 but its slow af. Takes about 1 minute for a 1024x1024 image at 25 steps",
                  "score": 3,
                  "created_utc": "2026-02-01 23:28:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o311h8b",
              "author": "Suitable-League-4447",
              "text": "thought it was added, lemme add it again",
              "score": 2,
              "created_utc": "2026-02-01 19:57:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31vczj",
          "author": "tretizon",
          "text": "f32: https://imgur.com/a/UMRix6m \n\nbf16 base: https://imgur.com/a/XpVzpye\n\ni just slapped it into the basic ZIB workflow and it seems to be working fine. maybe even slightly better but its kinda hard to tell",
          "score": 11,
          "created_utc": "2026-02-01 22:23:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o327z6a",
          "author": "TheSlateGray",
          "text": "Default ComfyUI Z Image workflow. Fixed seed. Left side is v0.37 uploaded by Comfy-Org, Right is 0.36 aka \"FP32\" converted to FP16. (Still uploading the model to HF.)\n\nDefault Comfy prompt:\n\nhttps://preview.redd.it/wmu7rky6vygg1.png?width=2053&format=png&auto=webp&s=b6ebfd63bfc43c71db239af4e630a34ea2af19a8\n\nMore from random prompts I borrowed from Civitai: [https://imgur.com/a/j7QIl27](https://imgur.com/a/j7QIl27)",
          "score": 10,
          "created_utc": "2026-02-01 23:30:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30ylfa",
          "author": "NewEconomy55",
          "text": "context?",
          "score": 6,
          "created_utc": "2026-02-01 19:43:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3112st",
              "author": "Suitable-League-4447",
              "text": "an official of  Tongyi did a mistake by uploading the teacher model instead of a distilled bf16 maybe, so a user caught via the commit history of HF and reverted it in his repo. there's two repo alive on hf for the moment i send you this message. i guess we need to a wait a bit until ostris adapt it to his trainer, if i find a method i update.",
              "score": 6,
              "created_utc": "2026-02-01 19:55:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3122xm",
                  "author": "BigDannyPt",
                  "text": "While, me as a noob coming from github to hugginface, don't know how to recover a commit for a file that I deleted from my repo, so went ahead and upload it again.",
                  "score": 1,
                  "created_utc": "2026-02-01 20:00:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o311x3s",
                  "author": "NewEconomy55",
                  "text": "We could say that they have given us a useless model. The BF16 has accuracy errors and it is not possible to train.",
                  "score": -10,
                  "created_utc": "2026-02-01 19:59:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o30zpmt",
          "author": "8RETRO8",
          "text": "what is a teacher model?",
          "score": 7,
          "created_utc": "2026-02-01 19:48:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3115mn",
              "author": "Suitable-League-4447",
              "text": "the full trained one, the most precise as possible.",
              "score": 8,
              "created_utc": "2026-02-01 19:55:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36adg8",
                  "author": "TekaiGuy",
                  "text": "the progenitor, some might say.",
                  "score": 1,
                  "created_utc": "2026-02-02 16:00:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o350qtn",
              "author": "Kaantr",
              "text": "The main source of all of its models including turbo.¬†",
              "score": 1,
              "created_utc": "2026-02-02 11:35:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31nj5n",
          "author": "luciferianism666",
          "text": "Been using the fp32 ZIB on my 4060(8gb vram), so yeah it ain't all that intense. After a whole lot of tests I ran while using the fp32 flag or using the fp32 dtype on kj's diffusion loader(which both so the same thing), I just found very minimal difference when running the fp32 model default dtype. So unless you want a really slow inference time I'd recommend running the fp32 normally and still get most from it. \n\n\nP.S I did manage to locate the fp32 split files from their original repo thanks to another person who found it from the history, before it was deleted, so I merged it on my own and ran several tests.",
          "score": 6,
          "created_utc": "2026-02-01 21:44:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31pm7x",
              "author": "PaulDallas72",
              "text": "How many steps/CFG for good details with the FP32?",
              "score": 2,
              "created_utc": "2026-02-01 21:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31qdyy",
                  "author": "luciferianism666",
                  "text": "I've been normally running 30 - 50 with zBase in general, however if you use heun or dpm_sde_gpu with beta_57(from res4lyf) scheduler, you can stick with 20 or even lesser steps. Also ZIB works best on higher resolution. So run 2 passes, first pass with 1mp and run a latent upscale of 2x and run around 10 steps for 2nd pass.",
                  "score": 3,
                  "created_utc": "2026-02-01 21:58:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o332ysm",
              "author": "ggRezy",
              "text": "workflow link? i keep getting OOM on my 4060 8gb",
              "score": 1,
              "created_utc": "2026-02-02 02:24:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o33z71o",
                  "author": "luciferianism666",
                  "text": "I'm just using the default ZIT/ZIB workflow, not really doing anything fancy in there. Infact I'm mostly running all my gens over 1MP and I've so far even tried upto 5MP on my 4060.",
                  "score": 1,
                  "created_utc": "2026-02-02 05:52:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3305jc",
              "author": "EndlessZone123",
              "text": "FP32 is for training.",
              "score": 0,
              "created_utc": "2026-02-02 02:08:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o33yw54",
                  "author": "luciferianism666",
                  "text": "https://preview.redd.it/8aoi10mds0hg1.png?width=5120&format=png&auto=webp&s=c4eb33666808fe595065b513323628f37f60e3ab\n\nWhile that may be the case, this is level of difference I found when using the bf16(left) and fp32 with fp32 dtype(right).",
                  "score": 7,
                  "created_utc": "2026-02-02 05:49:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o32dwxc",
          "author": "TheSlateGray",
          "text": "Here's commit 1ac663b (same commit as OP is from) converted to FP16 so people can test it: [https://huggingface.co/OmegaShred/Z-Image-0.36](https://huggingface.co/OmegaShred/Z-Image-0.36)\n\nMy upload is only 20Mbps so it took me a while, sorry.",
          "score": 5,
          "created_utc": "2026-02-02 00:03:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34r5wo",
              "author": "SomeoneSimple",
              "text": "Thank you for your service, works fine on Forge Neo as well.",
              "score": 3,
              "created_utc": "2026-02-02 10:09:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o32fgpl",
          "author": "PixWizardry",
          "text": "Thanks for sharing, i checked the shards and python reporting FP32. I am guessing it is still the Z-image Supervised  Fine Tune model.\n\nI‚Äôm still testing settings and trying to dial in the right flow, and I haven‚Äôt fully locked down what works best yet. That said, I figured it would be more useful to share. If anyone has **suggestions, tips, or insights** on better settings, sampling, or overall workflow for this model, I‚Äôd really appreciate the feedback.\n\nhttps://preview.redd.it/ychg8m5dbzgg1.jpeg?width=1920&format=pjpg&auto=webp&s=8f0433d20fd638769d9816135e1ca9806116121f\n\nWF: [https://github.com/PixWizardry/ComfyUI\\_Z-Image\\_FP32/blob/main/Z-Image-SupervisedFineTune.png](https://github.com/PixWizardry/ComfyUI_Z-Image_FP32/blob/main/Z-Image-SupervisedFineTune.png)",
          "score": 5,
          "created_utc": "2026-02-02 00:11:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31rtif",
          "author": "No_Sheepherder7873",
          "text": "This model is more friendly to nsfw",
          "score": 5,
          "created_utc": "2026-02-01 22:05:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34q1hf",
              "author": "Rheumi",
              "text": "![gif](giphy|140BQZMYDNbN5K)",
              "score": 2,
              "created_utc": "2026-02-02 09:58:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o38hw27",
              "author": "echothought",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 22:09:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31cf3g",
          "author": "Aromatic-Word5492",
          "text": "so... anyone try this ?",
          "score": 3,
          "created_utc": "2026-02-01 20:50:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31oa5v",
              "author": "No_Sheepherder7873",
              "text": "I've tried. limbs are much more accurate than those of bf16.",
              "score": 6,
              "created_utc": "2026-02-01 21:48:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o32jqea",
                  "author": "SDSunDiego",
                  "text": "all the limbs?!?!??! ;p",
                  "score": 3,
                  "created_utc": "2026-02-02 00:35:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o31vblt",
              "author": "BathroomEyes",
              "text": "Yes. Slightly better accuracy and improved fine detail but it took substantially longer to generate. The tradeoff is only worth it if you‚Äôre using this for professional production.",
              "score": 2,
              "created_utc": "2026-02-01 22:23:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31x9xe",
                  "author": "tretizon",
                  "text": "my render times are very similar to bf16",
                  "score": 3,
                  "created_utc": "2026-02-01 22:33:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o34s8sf",
              "author": "SomeoneSimple",
              "text": "I compared several seeds with the original z-image bf16 (0.37). \n\nWith 0.36 images most notably look more bleached and have (much) more natural colors (i.e. white, pinkish skin), whereas 0.37 leans towards lower contrast and a green/yellowish hue (like tone-mapped Movies/Series). \n\n0.36 consistently generates less detailed (i.e. less noisy, simpler) backgrounds. \n\nAnatomy looks identical to me, any changes I would attribute to noise variance.",
              "score": 1,
              "created_utc": "2026-02-02 10:19:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o32y8td",
          "author": "YouYouTheBoss",
          "text": "I love how everyone is trying to say it's a special \"teacher\" model or so WHILE it's just a merged model of the shards from original hf repo. That's it.",
          "score": 2,
          "created_utc": "2026-02-02 01:57:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o310q7i",
          "author": "silenceimpaired",
          "text": "link?",
          "score": 1,
          "created_utc": "2026-02-01 19:53:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3639ti",
          "author": "fernando782",
          "text": "WTF is a teacher model?",
          "score": 1,
          "created_utc": "2026-02-02 15:27:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36n3xa",
              "author": "Khanzaki",
              "text": "[https://www.reddit.com/r/comfyui/comments/1qt88kg/comment/o3115mn/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/comfyui/comments/1qt88kg/comment/o3115mn/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 2,
              "created_utc": "2026-02-02 16:59:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38nfug",
          "author": "Powerful_Evening5495",
          "text": "you can load a quantized model in fp32 and then safe it \n\ni dont think that this a leaked model",
          "score": 1,
          "created_utc": "2026-02-02 22:37:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o311kjn",
          "author": "TheSlateGray",
          "text": "Is it a safetensor form of commit 1ac663b from the official Z Image Huggingface?¬†\n\n\nI see it was uploaded then deleted the same day. Diffusers version \"0.36.0.dev0\" was 3 models, then version \"0.37.0.dev0\" went to the 2 models version we've all known.",
          "score": 1,
          "created_utc": "2026-02-01 19:57:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o311z5i",
              "author": "Suitable-League-4447",
              "text": "ye",
              "score": 0,
              "created_utc": "2026-02-01 19:59:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31upp1",
          "author": "SearchTricky7875",
          "text": "quality is not good, bf16 is way better, I have done this after testing 'rm -rf z\\_image\\_base\\_comfy\\_fp32.safetensors'\n\nhttps://preview.redd.it/hln8wbz8kygg1.png?width=1024&format=png&auto=webp&s=2e9113db839e19ccf802a5177e60b93e314da413",
          "score": 0,
          "created_utc": "2026-02-01 22:20:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o331sev",
              "author": "Suitable-League-4447",
              "text": "something wrong with your steps / cfg for sure!",
              "score": 2,
              "created_utc": "2026-02-02 02:17:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31svhb",
          "author": "iCreatedYouPleb",
          "text": "She looks like that Chinese actress that I shall not name.",
          "score": -1,
          "created_utc": "2026-02-01 22:10:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrc8j3",
      "title": "I Finally Learned About VAE Channels (Core Concept)",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1qrc8j3/i_finally_learned_about_vae_channels_core_concept/",
      "author": "TekaiGuy",
      "created_utc": "2026-01-30 17:39:24",
      "score": 118,
      "num_comments": 26,
      "upvote_ratio": 0.95,
      "text": "With a recent upgrade to a 5090, I can start training loras with hi-res images containing lots of tiny details. Reading through [this lora training guide](https://civitai.com/articles/7777?highlight=1763669) I wondered if training on high resolution images would work for SDXL or would just be a waste of time. That led me down a rabbit hole that would cost me 4 hours, but it was worth it because I found [this blog post](https://medium.com/@efrat_taig/vae-the-latent-bottleneck-why-image-generation-processes-lose-fine-details-a056dcd6015e) which very clearly explains why SDXL always seems to drop the ball when it comes to \"high frequency details\" and why training it with high-quality images would be a waste of time if I wanted to preserve those details in its output.\n\nThe keyword I was missing was the number of **channels** the VAE model uses. The higher the number of channels, the more detail that can be reconstructed during decoding. SDXL (and SD1.5, Qwen) uses a 4-channel VAE, but the number can go higher. When Flux was released, I saw higher quality out of the model, but far slower generation times. That is because it uses a 16-channel VAE. It turns out Flux is not slower than SDXL, it's simply doing more work, and I couldn't properly appreciate that advantage at the time.\n\nFlux, SD3 (which everyone clowned on), and now the popular Z-Image all use 16-channel VAEs which have lower compression than SDXL, which allows them to reconstruct higher fidelity images. So you might be wondering: why not just use a 16-channel VAE on SDXL? The answer is it's not compatible, the model itself will not accept latent images at the compression ratios that 16-channel VAEs encode/decode. You would probably need to re-train the model from the ground up to give it that ability.\n\nHigher channel count comes at a cost though, which materializes in generation time and VRAM. For some, the tradeoff is worth it, but I wanted crystal clarity before I dumped a bunch of time and energy into lora training. I will probably pick 1440x1440 resolution for SDXL loras, and 1728x1728 or higher for Z-Image.\n\nThe resolution itself isn't what the model learns though, that would be the relationships between the pixels, which can be reproduced at ANY resolution. The key is that some pixel relationships (like in text, eyelids, fingernails) are often not represented in the training data with enough pixels either for the model to learn, or for the VAE to reproduce. Even if the model learned the concept of a fishing net and generated a perfect fishing net, the VAE would still destroy that fishing net before spitting it out.\n\nWith all of that in mind, the reason why early models sucked at hands, and full-body shots had jumbled faces is obvious. The model was doing its best to draw those details in latent space, but the VAE simply discarded those details upon decoding the image. And who gets blamed? Who but the star of the show, the model itself, which in retrospect, did nothing wrong. This is why closeup images express more detail than zoomed-out ones.\n\nSo why does the image need to be compressed at all? Because it would be way too computationally expensive to generate full-resolution images, so the job of the VAE is to compress the image into a more manageable size for the model to work with. This compression is always a factor of 8, so from a lora training standpoint, if you want the model to learn any particular detail, that detail should still be clear when the training image is reduced by 8x or else it will just get lost in the noise.\n\n[The more channels, the less information is destroyed](https://preview.redd.it/ltrsxhyytigg1.png?width=324&format=png&auto=webp&s=5d871b7f22f3066adf852063e1381c6663ff0c20)",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1qrc8j3/i_finally_learned_about_vae_channels_core_concept/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o2n5mdk",
          "author": "BathroomEyes",
          "text": "Flux.2 VAE uses 32 channels with 6x compression which is why Flux.2 dev is so slow but so good at representing small text.",
          "score": 22,
          "created_utc": "2026-01-30 17:54:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nepvy",
              "author": "TekaiGuy",
              "text": "https://preview.redd.it/ip9zyyu46jgg1.png?width=926&format=png&auto=webp&s=cd66f89930e3e67660966963b7893a1fda8ba8cc",
              "score": 3,
              "created_utc": "2026-01-30 18:34:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ohvbh",
                  "author": "iCreatedYouPleb",
                  "text": "Man, y‚Äôall rich ü§ë",
                  "score": 5,
                  "created_utc": "2026-01-30 21:34:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2nn0g1",
                  "author": "TechnologyGrouchy679",
                  "text": "What's with all the order cancellations?  Is that you cancelling them or the vendor?",
                  "score": 2,
                  "created_utc": "2026-01-30 19:10:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2szxzb",
                  "author": "bitshifter52",
                  "text": "According to Amazon, this card costs more than 8.5 K. You got some serious AI generation plans.",
                  "score": 1,
                  "created_utc": "2026-01-31 15:46:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2n8697",
          "author": "Drxxxxxx1",
          "text": "Thank you. I have probably read many snippets of this and never grasped what it is really doing or why. You explained it well to my simple mind",
          "score": 13,
          "created_utc": "2026-01-30 18:05:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2p59u3",
              "author": "FrankNitty_Enforcer",
              "text": "I agree, highly valuable post for someone like me who has dozens of bookmarked pages about the theory/practice that I tell myself I‚Äôll read to understand this stuff end to end. But this 1-minute read shines a light right on one specific cross-section which actually sparks more interest to dig further, whereas spending an afternoon reading white papers or blogs/YouTube ‚Äúlet‚Äôs build X from scratch‚Äù always attract me, but rate for me to actually do them",
              "score": 4,
              "created_utc": "2026-01-30 23:33:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ng4sp",
          "author": "jib_reddit",
          "text": "Both Z-Image Turbo and Qwen-image have alternate Custom trained VAE's that can improve image quality quite substantially. \n\nZ-image/ Ultra Flux VAE: https://huggingface.co/Owen777/UltraFlux-v1/tree/main/vae\n\nQwen-Image/WAN Upscale: https://huggingface.co/spacepxl/Wan2.1-VAE-upscale2x/blob/main/Wan2.1_VAE_upscale2x_imageonly_real_v1.safetensors\n\nBut they do have some caveats and both benifit from using custom nodes to utilise fully.\n\nZ-image VAE Merge Nodes:https://civitai.com/models/2231351?modelVersionId=2638152\nAs UltraFluxVAE at 100% can be a bit sharp but 10%-30% merge with the normal Flux VAE makes it perfect \n\nQWEN-image custom VAE required node: https://github.com/spacepxl/ComfyUI-VAE-Utils?tab=readme-ov-file",
          "score": 18,
          "created_utc": "2026-01-30 18:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2q469d",
          "author": "Incognit0ErgoSum",
          "text": "THere's another reason that SD 1.5 in particular sucked at hands.\n\nBack when the laion search site was up, if you searched for \"hands\", most of the stuff that would come up would be these artsy fartsy black and white photos of hands with fingers intertwined in these crazy ways so you couldn't tell which finger came from which hand. It was no wonder it could never figure hands out.",
          "score": 3,
          "created_utc": "2026-01-31 02:53:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o303a0v",
              "author": "TekaiGuy",
              "text": ":o it would be funny if \"interlocked fingers\" was better at hands than \"hands\"",
              "score": 2,
              "created_utc": "2026-02-01 17:21:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ocgya",
          "author": "35point1",
          "text": "I love this. Smart people exploring and sharing to help others do the same. I‚Äôm interested in seeing what your training approach can produce, are you planning to share any realism Lora‚Äôs? \n\nAlso curious where/how you‚Äôre sourcing the high detail data set?",
          "score": 3,
          "created_utc": "2026-01-30 21:09:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ohymk",
              "author": "TekaiGuy",
              "text": "I'm still working on a good pipeline, but I think I can start sharing once I figure it out (on civit and here). Logos are not too hard to remove by erasing them in a drawing program and filling in with inpainting. Dataset is just images I've saved from the internet over the years but the key to giving them quality is using SeedVR2 which is basically cheating in the best way possible. It's one of those things you think is too good to be true until you see the results for yourself.",
              "score": 4,
              "created_utc": "2026-01-30 21:35:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2oer7e",
          "author": "an80sPWNstar",
          "text": "Wow, thank you for explaining this in such depth. I also am struggling with Loras in sdxl. What did you end up doing? Is there a way to make it work?",
          "score": 2,
          "created_utc": "2026-01-30 21:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ppd3j",
          "author": "Dark_Infinity_Art",
          "text": "Good explanation!",
          "score": 2,
          "created_utc": "2026-01-31 01:26:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zw9kh",
              "author": "TekaiGuy",
              "text": "Thanks, you saved me when it came to understanding bucketing. Real mvp.",
              "score": 1,
              "created_utc": "2026-02-01 16:49:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o334pzb",
                  "author": "Dark_Infinity_Art",
                  "text": "I'm just glad its useful and helps others train.",
                  "score": 1,
                  "created_utc": "2026-02-02 02:34:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2o4tzw",
          "author": "CandiceCarter00",
          "text": "Dude thank you so much for posting this. I‚Äôve been using SDXL and ignored the YT tutorials about Flux! YT in itself for learning this stuff is a rabbit hole‚Ä¶ every method/model is always ‚Äúthe best‚Äù and the rest are ‚Äúunreliable‚Äù which is prob why I skipped out on Flux üòÇ",
          "score": 3,
          "created_utc": "2026-01-30 20:33:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zlww4",
          "author": "Barbagiallo",
          "text": "Thanks, good explanation. What about VAE tiling? How does it work?",
          "score": 1,
          "created_utc": "2026-02-01 16:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2nmtu1",
          "author": "Comfortable-Lab4125",
          "text": "Could you help on a custom wan 2.1 vae that outputs 16 bit half float and captures a higher dynamic range?",
          "score": 0,
          "created_utc": "2026-01-30 19:09:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qt6kfh",
      "title": "Title: Realistic Motion Transfer in ComfyUI: Driving Still Images with Reference Video (Wan 2.1)",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/vjrfwgpcfxgg1",
      "author": "Substantial-Cup-9531",
      "created_utc": "2026-02-01 18:35:16",
      "score": 115,
      "num_comments": 13,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/comfyui/comments/1qt6kfh/title_realistic_motion_transfer_in_comfyui/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o31bqqp",
          "author": "Grindora",
          "text": "Not wan2.2?",
          "score": 6,
          "created_utc": "2026-02-01 20:47:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33vqeg",
              "author": "Substantial-Cup-9531",
              "text": "No, not possible with wan move",
              "score": 1,
              "created_utc": "2026-02-02 05:25:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30nxc4",
          "author": "No-Expression6444",
          "text": "This looks very promising. Thanks very much for all of the effort you've put into this.",
          "score": 3,
          "created_utc": "2026-02-01 18:53:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33vrfl",
              "author": "Substantial-Cup-9531",
              "text": "Appriciate!",
              "score": 2,
              "created_utc": "2026-02-02 05:25:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38xlri",
                  "author": "No-Expression6444",
                  "text": "Yep, works nicely, well done.\n\nhttps://i.redd.it/fgqsyxcw16hg1.gif",
                  "score": 1,
                  "created_utc": "2026-02-02 23:30:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o31zmyb",
          "author": "Ok-Flatworm5070",
          "text": "Is there a workflow to download?",
          "score": 2,
          "created_utc": "2026-02-01 22:45:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38xhe0",
              "author": "No-Expression6444",
              "text": "No, he hasn't made one available by link, but if you follow the video tutorial you can assemble it.",
              "score": 1,
              "created_utc": "2026-02-02 23:30:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o310c14",
          "author": "Suitable-League-4447",
          "text": "good 1 i thing it was already something like this like CamCloneMaster right?",
          "score": 1,
          "created_utc": "2026-02-01 19:51:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33vw7g",
              "author": "Substantial-Cup-9531",
              "text": "correct! however the support for it in comfyui is not stable! wan move works out the box",
              "score": 1,
              "created_utc": "2026-02-02 05:26:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o35a2fr",
          "author": "Kauko_Buk",
          "text": "You can even use simple wireframe animations to drive the video: https://github.com/Burgstall-labs/WireframeDesigner",
          "score": 1,
          "created_utc": "2026-02-02 12:45:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38wsn6",
              "author": "No-Expression6444",
              "text": "It works with some proxy geo in a 3d program as well.\n\nhttps://i.redd.it/r3zmmqo316hg1.gif",
              "score": 2,
              "created_utc": "2026-02-02 23:26:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o31ynhh",
          "author": "chuckaholic",
          "text": "Amazing work! The author should open source the workflow. \n\nI could probably watch the whole video and make a list of all the custom nodes and models to download, but man, imagine if there was just a json file in the post comments! \n\nI didn't watch the whole video, but I'm guessing the host is selling the workflow? \n\nKinda like the Andrew Tate of image gen.",
          "score": 0,
          "created_utc": "2026-02-01 22:40:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs1kri",
      "title": "Top down POV phone picture generation",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1qs1kri",
      "author": "Additional-Low324",
      "created_utc": "2026-01-31 12:52:23",
      "score": 110,
      "num_comments": 17,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1qs1kri/top_down_pov_phone_picture_generation/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2s9mrt",
          "author": "ItsZerone",
          "text": "First person, Pov photography. Shot looking straight down, own body visible in shot\n\nThis worked for me\n\nhttps://preview.redd.it/ozbx5p9frogg1.png?width=1024&format=png&auto=webp&s=025c56af853d86ade1b552ae9c72c980384d6666",
          "score": 24,
          "created_utc": "2026-01-31 13:21:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sfpez",
              "author": "plus-minus",
              "text": "Nice. Looks quite burned though. Did you have to use a high guidance value?",
              "score": 2,
              "created_utc": "2026-01-31 13:58:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2sg1py",
                  "author": "ItsZerone",
                  "text": "Nah I just had it set to 2 steps so I could test prompts faster and didn't care enough to adjust for better quality.",
                  "score": 10,
                  "created_utc": "2026-01-31 14:00:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2skg6m",
              "author": "Additional-Low324",
              "text": "Maybe this is because I use a character Lora with the images but I can't get this result, gonna try when I'm back home thanks!",
              "score": 1,
              "created_utc": "2026-01-31 14:25:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2tuk5t",
                  "author": "Seranoth",
                  "text": "hint: if this is not working for you you should try to double or triple the promt. this worked for me.\n\n\nFirst person, Pov photography. Shot looking straight down, own body visible in shot,\nFirst person, Pov photography. Shot looking straight down, own body visible in shot,\nFirst person, Pov photography. Shot looking straight down, own body visible in shot",
                  "score": 4,
                  "created_utc": "2026-01-31 18:13:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2wn2y2",
                  "author": "scoobasteve813",
                  "text": "Yeah character lora is gonna be hard to generate something without the character's face in it. You could generate the whole body top down then i2i to get a different angle without the face but keeping the body.",
                  "score": 2,
                  "created_utc": "2026-02-01 03:03:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2sml42",
                  "author": "ItsZerone",
                  "text": "Ah yeah that makes some sense. You could try turning the lora clip and model strengths down. I have really mixed results using Loras. Trying to learn to make my own this weekend üòÅ",
                  "score": 1,
                  "created_utc": "2026-01-31 14:37:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2tvodv",
          "author": "mogadichu",
          "text": "\"Why?\"\n\n\"Oh, that's why.\"",
          "score": 20,
          "created_utc": "2026-01-31 18:18:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xfqd4",
              "author": "roankr",
              "text": "Got me giggle laughing lmfao\n\nThis tool is going to get wild",
              "score": 2,
              "created_utc": "2026-02-01 06:24:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z2v2s",
          "author": "itsdigitalaf",
          "text": "https://civitai.com/models/2177312/herpov (nsfw)",
          "score": 5,
          "created_utc": "2026-02-01 14:25:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31dp9l",
              "author": "Additional-Low324",
              "text": "You are a god among men",
              "score": 3,
              "created_utc": "2026-02-01 20:57:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o31ma27",
                  "author": "itsdigitalaf",
                  "text": "haha hardly, but I hope it helps. I'm working on a finetune at the moment, when I'm able to, I'll update it for ZIB. Cheers :)",
                  "score": 2,
                  "created_utc": "2026-02-01 21:38:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o372npe",
              "author": "Livid_Cartographer33",
              "text": "any for qwen edit?",
              "score": 1,
              "created_utc": "2026-02-02 18:10:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o379hao",
                  "author": "itsdigitalaf",
                  "text": "I don't have anything for Qwen unfortunately...I'll look into it though. I have a few I'd like to update",
                  "score": 2,
                  "created_utc": "2026-02-02 18:41:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2yehdr",
          "author": "Affen_Brot",
          "text": "You could train a Lora yourself. Just gather enough source images or create a couple yourself with Nano Banana Pro and then just train with AI Toolkit on Z-Image",
          "score": 1,
          "created_utc": "2026-02-01 11:39:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y1j87",
          "author": "CipherCipher1",
          "text": "Hey are you aware that when u send such photos you will have in snapchat \"uploaded media\"\n\nBy any chance do you know how to bypass this?",
          "score": 0,
          "created_utc": "2026-02-01 09:42:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qujri1",
      "title": "Live Motion Capture custom node (EXPERIMENTAL)",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/0kgldizrw7hg1",
      "author": "shamomylle",
      "created_utc": "2026-02-03 05:45:53",
      "score": 102,
      "num_comments": 6,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1qujri1/live_motion_capture_custom_node_experimental/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3bd35a",
          "author": "TonyDRFT",
          "text": "Wow, that looks awesome! Thanks for sharing! I'm wondering if you would be able to use the output of your 3D Viewer node as input for the camera in a video generation?",
          "score": 3,
          "created_utc": "2026-02-03 09:37:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bdzw1",
              "author": "shamomylle",
              "text": "Thanks! Technically these are 3D coordinates, you could drive a rigged 3D model in theory with this data output then render a video for video to video I suppose, but it's easier to use OpenPose skeletons from the image output for controlnet. Not sure if that answer your question?",
              "score": 2,
              "created_utc": "2026-02-03 09:46:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3aw8hg",
          "author": "Frogy_mcfrogyface",
          "text": "Nice :o",
          "score": 1,
          "created_utc": "2026-02-03 06:57:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c1g0g",
              "author": "shamomylle",
              "text": "Thanks :)",
              "score": 1,
              "created_utc": "2026-02-03 12:57:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3c0e1k",
          "author": "Remarkable-Size2155",
          "text": "nice work dude",
          "score": 1,
          "created_utc": "2026-02-03 12:50:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c1erf",
              "author": "shamomylle",
              "text": "Thanks :)",
              "score": 1,
              "created_utc": "2026-02-03 12:57:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqfnro",
      "title": "Full Voice Cloning in ComfyUI with Qwen3-TTS + ASR",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1qqfnro/full_voice_cloning_in_comfyui_with_qwen3tts_asr/",
      "author": "MisterBlackStar",
      "created_utc": "2026-01-29 17:51:55",
      "score": 98,
      "num_comments": 28,
      "upvote_ratio": 0.99,
      "text": "Released ComfyUI nodes for the new Qwen3-ASR (speech-to-text) model, which pairs perfectly with Qwen3-TTS for fully automated voice cloning.\n\nhttps://preview.redd.it/4pqwq01ntbgg1.png?width=1572&format=png&auto=webp&s=17c8768b917e9f93d0e14c5d3a8e960634caac0e\n\n**The workflow is dead simple:**\n\n1. Load your reference audio (5-30 seconds of someone speaking)\n2. ASR auto-transcribes it (no more typing out what they said)\n3. TTS clones the voice and speaks whatever text you want\n\nBoth node packs auto-download models on first use. Works with 52 languages.\n\n**Links:**\n\n* **Qwen3-TTS nodes:** [https://github.com/DarioFT/ComfyUI-Qwen3-TTS](https://github.com/DarioFT/ComfyUI-Qwen3-TTS)\n* **Qwen3-ASR nodes:** [https://github.com/DarioFT/ComfyUI-Qwen3-ASR](https://github.com/DarioFT/ComfyUI-Qwen3-ASR)\n\nModels used:\n\n* ASR: Qwen/Qwen3-ASR-1.7B (or 0.6B for speed)\n* TTS: Qwen/Qwen3-TTS-12Hz-1.7B-Base\n\nThe TTS pack also supports preset voices, voice design from text descriptions, and fine-tuning on your own datasets if you want a dedicated model.",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/comfyui/comments/1qqfnro/full_voice_cloning_in_comfyui_with_qwen3tts_asr/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o2kj62b",
          "author": "Nokai77",
          "text": "We still can't give emotions to cloned voices, can we?",
          "score": 4,
          "created_utc": "2026-01-30 08:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l6st6",
              "author": "MisterBlackStar",
              "text": "That would require finetuning at the moment.",
              "score": 4,
              "created_utc": "2026-01-30 11:59:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38dv5h",
                  "author": "piscoster",
                  "text": "How would you do this? I am super interested!",
                  "score": 3,
                  "created_utc": "2026-02-02 21:50:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o322tst",
          "author": "pencil_the_anus",
          "text": "And which one are we supposed to use?\n\n* Repo 1: https://github.com/mailzwj/ComfyUI-Qwen3-ASR\n \n* Repo 2: https://github.com/kaushiknishchay/ComfyUI-Qwen3-ASR\n\n* Repo 3: https://github.com/1038lab/ComfyUI-QwenASR",
          "score": 2,
          "created_utc": "2026-02-01 23:02:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38e581",
          "author": "piscoster",
          "text": "How would you give emotions to a cloned voice?",
          "score": 2,
          "created_utc": "2026-02-02 21:51:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2h686w",
          "author": "Resident-Swimmer7074",
          "text": "DO you think this is better than Chatterbox?",
          "score": 1,
          "created_utc": "2026-01-29 20:31:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hph5q",
              "author": "MisterBlackStar",
              "text": "It does my native language better, so for my use case I'd say yes.",
              "score": 1,
              "created_utc": "2026-01-29 22:03:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2mg9a0",
                  "author": "Resident-Swimmer7074",
                  "text": "OK",
                  "score": 1,
                  "created_utc": "2026-01-30 16:01:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2i3vr4",
          "author": "Lutha",
          "text": "Thank you for your post, I managed to install the whole thing and it's working just fine, but are there any ways to control the output? Like add pauses, change intonation etc?",
          "score": 1,
          "created_utc": "2026-01-29 23:16:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jqktv",
              "author": "amomynous123",
              "text": "different punctuation create different pauses. a , . - - and : all create different length pauses",
              "score": 1,
              "created_utc": "2026-01-30 04:47:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2i78zd",
          "author": "cutter89locater",
          "text": "I need this I need this. Thank you for sharing ‚ò∫Ô∏è",
          "score": 1,
          "created_utc": "2026-01-29 23:34:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jmecv",
          "author": "zoidbergsintoyou",
          "text": "Is Vibevoice still a main contender? Any reason to use this instead?",
          "score": 1,
          "created_utc": "2026-01-30 04:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jojec",
              "author": "xXNigNogXx",
              "text": "Vibevoice was a pain in the ass for me to set up and the results were mostly bad. In 10 tries you get maybe 1-2 okayish results, the rest is intelligible singing/rambling with music in the background.\nQwen TTS was super easy for me to set up, the results are not 100% perfect but 100% better and reliable than vibevoice.",
              "score": 2,
              "created_utc": "2026-01-30 04:34:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2k2mx1",
                  "author": "zoidbergsintoyou",
                  "text": "Really? Hmm I found vibe voice super easy and would make really good results... Maybe I should just try this And compare myself.",
                  "score": 2,
                  "created_utc": "2026-01-30 06:14:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2m5x0p",
                  "author": "tanoshimi",
                  "text": "Vibevoice (and Chatterbox/Qwen) just worked out-of-the-box for me using the ComfyUI Audio-TTS suite.\nI think each have strengths - some are more consistent, some better at longer dialogues/multiple speakers, and some are more expressive. Nice to have the choice available!",
                  "score": 1,
                  "created_utc": "2026-01-30 15:14:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2wo0w1",
              "author": "aeroumbria",
              "text": "The 7B version (both TTS and ASR) are quite good, if you can put up with some randomness in TTS generation (occasional voice change or unexpected emotions). The Qwen TTS runs faster and is more predictable, so might be more useful for building projects like personal assistants. I found Qwen ASR to be less reliable than VibeVoice ASR, but only tried a few clips so far.",
              "score": 1,
              "created_utc": "2026-02-01 03:09:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o30f99q",
                  "author": "PixWizardry",
                  "text": "Have a link to the VibeVoice ASR comfy node?",
                  "score": 1,
                  "created_utc": "2026-02-01 18:15:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2l08z1",
          "author": "jd3k",
          "text": "Still no speech to speech ü•≤",
          "score": 1,
          "created_utc": "2026-01-30 11:07:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l6qsc",
              "author": "MisterBlackStar",
              "text": "Well, connecting the output of the ASR node to the voice clone one with a different voice to clone will give you exactly that.",
              "score": 1,
              "created_utc": "2026-01-30 11:58:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2nlscd",
          "author": "P1xelthrower",
          "text": "When I try to install ASR after TTS I get the following Error:\n\nInstalling collected packages: itsdangerous, cython, blinker, av, flask, DyNet38, soynlp, nagisa, transformers, qwen-omni-utils, qwen-asr\n\n  Attempting uninstall: transformers\n\nFound existing installation: transformers 4.57.3\n\nUninstalling transformers-4.57.3:\n\nSuccessfully uninstalled transformers-4.57.3\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\nqwen-tts 0.0.5 requires transformers==4.57.3, but you have transformers 4.57.6 which is incompatible.",
          "score": 1,
          "created_utc": "2026-01-30 19:05:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2o5n9o",
              "author": "MisterBlackStar",
              "text": "Hm weird, I haven't run into that. I'll investigate, it seems like the Qwen guys have different transformer versions on their python libraries.",
              "score": 1,
              "created_utc": "2026-01-30 20:37:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2onx6k",
          "author": "Vektast",
          "text": "Is this real time? Can I talk with my pc?",
          "score": 1,
          "created_utc": "2026-01-30 22:03:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2p9khk",
          "author": "Lutha",
          "text": "It's strange - the default wf gives me the 15s output maximum missing the rest of the text I typed. What can be a problem here? I'm using Russian language",
          "score": 1,
          "created_utc": "2026-01-30 23:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y55b6",
          "author": "pencil_the_anus",
          "text": "I wonder if you have any idea?\nSee 2nd last line. /Wanted to avoid asking a GPT so thought I'd ask.\n\nThis is after running pip install -r requirements.txt \n\n    Successfully built sox\n    Installing collected packages: pytz, pydub, brotli, werkzeug, uvicorn, tomlkit, threadpoolctl, soxr, sox, semantic-version, python-multipart, orjson, msgpack, llvmlite, lazy_loader, joblib, itsdangerous, groovy, ffmpy, cython, blinker, audioread, annotated-doc, starlette, soundfile, scikit-learn, pooch, pandas, numba, modelscope, flask, DyNet38, soynlp, safehttpx, nagisa, librosa, gradio-client, fastapi, transformers, qwen-omni-utils, gradio, accelerate, qwen-asr\n      Attempting uninstall: blinker\n        Found existing installation: blinker 1.4\n       ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/43 [blinker]\n    [notice] A new release of pip is available: 25.3 -> 26.0\n    [notice] To update, run: python3.12 -m pip install --upgrade pip\n    error: uninstall-distutils-installed-package\n    \n    √ó Cannot uninstall blinker 1.4\n    ‚ï∞‚îÄ> It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.",
          "score": 1,
          "created_utc": "2026-02-01 10:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zhizv",
          "author": "Tiny_Technician5466",
          "text": "Does the 97ms latency apply to cloned voices as well, or only to pre-made ones? Also, can I apply style instructions (like 'angry' or 'shy') to cloned voices, or is this feature restricted to pre-made voices?",
          "score": 1,
          "created_utc": "2026-02-01 15:40:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gx9rb",
          "author": "No_Praline_3451",
          "text": "Can You provide a workflow, please?",
          "score": -1,
          "created_utc": "2026-01-29 19:48:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hpeg9",
              "author": "MisterBlackStar",
              "text": "Hey, the workflow from the screenshot is on the example\\_workflows folder in any of the repos.",
              "score": 7,
              "created_utc": "2026-01-29 22:03:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qschfg",
      "title": "[WIP] Using multiple images in ZimageTurbo with adjustable weighting",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/0oo6s2nlnqgg1.png",
      "author": "deadsoulinside",
      "created_utc": "2026-01-31 19:57:00",
      "score": 84,
      "num_comments": 11,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1qschfg/wip_using_multiple_images_in_zimageturbo_with/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2v0jlh",
          "author": "skyrimer3d",
          "text": "that's really cool, pls update when it's ready.",
          "score": 6,
          "created_utc": "2026-01-31 21:36:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2vqmpo",
          "author": "Fi3br",
          "text": "This is sick af.",
          "score": 5,
          "created_utc": "2026-01-31 23:53:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yny1d",
          "author": "SvenVargHimmel",
          "text": "How is this different or similar to this node - have you seen it ? \n\nhttps://preview.redd.it/bbhiru8brvgg1.png?width=768&format=png&auto=webp&s=33de812a146c6ef1bfc50985fa42344750ef813c",
          "score": 3,
          "created_utc": "2026-02-01 12:53:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yz9hy",
              "author": "deadsoulinside",
              "text": "The node you see in my workflow (Latent weighted blend resize) is similar to that, but it's my own custom node I created yesterday in Python (hence why I cannot post the workflow yet, since I have to create some form of repository for that node). I was using blend latents before, but the blend ratio was driving me nuts, so I created the weighted one as my own way to deal assign direct weights to images.\n\nI am still testing this node as with the ability to set resolution output comes potential for errors as I initially resize images by it's max size to 1024. Both of the nodes below in this picture are my own nodes.\n\nhttps://preview.redd.it/jkzauwdu3wgg1.png?width=612&format=png&auto=webp&s=dea630f0eb9047d604c5083ef2647ad20000af04",
              "score": 1,
              "created_utc": "2026-02-01 14:05:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yucl9",
          "author": "SvenVargHimmel",
          "text": "so I've experimented a bit with existing blend nodes and I am not seeing it.  So i think I am doing something off.  Thoughts? \n\nhttps://preview.redd.it/7vhh6v4tyvgg1.png?width=1721&format=png&auto=webp&s=b36eae72b934cabaf5ace8f684065a143c075e3e",
          "score": 2,
          "created_utc": "2026-02-01 13:35:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z01nh",
              "author": "deadsoulinside",
              "text": "This is the workflow that I previously was using before creating my own nodes. You are on a close path. I exploded this out to hopefully help understand it. The Repeat Latent Batch is not needed technically in either image node, that was for trying to work with setting batches in case people want to batch images at once versus batching multiple jobs.\n\nThe only word for the wise here is that .50 is middle ground for blending, .50-1 and 0-.50 leans you into either image. The main reason for creating my weighted node was more of similar way, but making it simple.\n\nhttps://preview.redd.it/m3bnu6r34wgg1.png?width=1718&format=png&auto=webp&s=905080b793f8102d74ad4fe3ff43ecc5b35bb729",
              "score": 3,
              "created_utc": "2026-02-01 14:09:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o315arj",
          "author": "Corrupt_file32",
          "text": "That's actually quite clever.\n\nI can see other possibilities with this, masked weighted blending, noise masks and differential diffusion etc.\n\nQuite interesting to see something simple that works. üëç",
          "score": 2,
          "created_utc": "2026-02-01 20:15:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2x2xt0",
          "author": "CheeseWithPizza",
          "text": "No consistency. Prompt is doing the work. you don't need 2nd image",
          "score": 1,
          "created_utc": "2026-02-01 04:47:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x7pqp",
              "author": "deadsoulinside",
              "text": "if you look at the background what appears to be a crane in the final image is from the second images gun. Where the circular sign is in the second image is where the circular tank is in the main. Second image becomes more of background noise than input.\n\nHere is a better example of a blend where both elements are visible in the final output. And yes, from my experience with anything text related on image to image with Z Image, you need to state the text in order for it to translate, so that is why it's in the prompt.\n\nhttps://preview.redd.it/64n2cs20itgg1.png?width=1824&format=png&auto=webp&s=b1f5343d72b8cd2a844141458110bf5a1f244d8c",
              "score": 3,
              "created_utc": "2026-02-01 05:21:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ztwe3",
                  "author": "CheeseWithPizza",
                  "text": "that's a good example. thanks for clarifying.",
                  "score": 2,
                  "created_utc": "2026-02-01 16:38:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2zf6ij",
              "author": "deadsoulinside",
              "text": "Here is the output ran in an image compare node against the 2nd image to highlight what I mean here. A part of the woman even becomes part of the background. But like one headlight for the truck becomes the headlight for the mech spider in the output.\n\nhttps://preview.redd.it/7zr3pmugiwgg1.png?width=1502&format=png&auto=webp&s=74f8885531ded8ad12aa8586758d78736dd3ea8d",
              "score": 1,
              "created_utc": "2026-02-01 15:29:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qu69c9",
      "title": "A sketchpad i am working for comfyui.",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/u4ttrlcl25hg1",
      "author": "Vivid-Loss9868",
      "created_utc": "2026-02-02 20:14:57",
      "score": 82,
      "num_comments": 17,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "No workflow",
      "permalink": "https://reddit.com/r/comfyui/comments/1qu69c9/a_sketchpad_i_am_working_for_comfyui/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o38349u",
          "author": "theoctopusmagician",
          "text": "I'm not seeing a link to the workflow",
          "score": 8,
          "created_utc": "2026-02-02 20:59:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38fo54",
          "author": "K0owa",
          "text": "We can find it now?",
          "score": 3,
          "created_utc": "2026-02-02 21:58:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3853ks",
          "author": "blastcat4",
          "text": "Very cool! I would definitely use this! Would save me doing the sketching on my iPad and then copying it over to my PC to paste into comfyui.",
          "score": 2,
          "created_utc": "2026-02-02 21:08:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o387of6",
              "author": "ANR2ME",
              "text": "Wait.. why not you accessed ComfyUI webui using the browser in your iPad? ü§î if both (PC and iPad) are connected to the same wifi, you can just changed the 127.0.0.1 (which usually used to access ComfyUI on the PC) to your PC's LAN IP (ie. 192.168.x.x/172.16.x.x) and accessed ComfyUI directly from your iPad's browser.\n\nIf both PC & iPad are connected to the same VPN (ie. radmin/hamachi/zero tier) you can even accessed the ComfyUI that ran on your PC from anywhere through the internet using your iPad.",
              "score": 2,
              "created_utc": "2026-02-02 21:20:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38j8hf",
                  "author": "blastcat4",
                  "text": "I did previously try accessing my PC's comfyui from my iPad (they're on the same home network), but it didn't work. I only looked into it briefly, but seems like I have to add a parameter in the bat file to enable this. I'll look into this further.\n\nI also have an old Wacom drawing tablet that I can hook up to the PC running comfyui. This plugin could allow me to bypass using the iPad, which would be nice!",
                  "score": 1,
                  "created_utc": "2026-02-02 22:16:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3adag9",
          "author": "an80sPWNstar",
          "text": "The question that needs to be asked: can it do NSFW?",
          "score": 2,
          "created_utc": "2026-02-03 04:30:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3azk56",
              "author": "pierrenoir2017",
              "text": "Start with practicing bananas and melons :)",
              "score": 2,
              "created_utc": "2026-02-03 07:27:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37w7rg",
          "author": "Prestigious_Bug7482",
          "text": "good job !",
          "score": 1,
          "created_utc": "2026-02-02 20:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o385wva",
          "author": "pixel8tryx",
          "text": "Nice!  I've been loathe to install Adobe on my gen boxes and use them for ComfyUI only.  On my old PC I pruned my Photoshop brushes, again, and it still takes ages to fire up and ignores memory restrictions and tries to allocate it all. üôÑ It's bad enough trying to keep it running alongside a browser and Cinema 4D.  \n\nAnd it's all overkill if you just want to scribble something quickly.  This looks nice because it's not overwrought and packed with weird special features.",
          "score": 1,
          "created_utc": "2026-02-02 21:12:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o386mn0",
          "author": "mcai8rw2",
          "text": "yeah! This is a useful tool. great work :)",
          "score": 1,
          "created_utc": "2026-02-02 21:15:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39bq9k",
          "author": "wh33t",
          "text": "Outstanding idea!",
          "score": 1,
          "created_utc": "2026-02-03 00:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39ky45",
          "author": "elswamp",
          "text": "code?",
          "score": 1,
          "created_utc": "2026-02-03 01:40:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a3o0j",
          "author": "fiselledpluttinog",
          "text": "just draw what makes you happy and comfy",
          "score": 1,
          "created_utc": "2026-02-03 03:28:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a548s",
          "author": "Rivarr",
          "text": "Great stuff. I gave up trying to create anything complex like that because the frontend updates constantly break them.",
          "score": 1,
          "created_utc": "2026-02-03 03:37:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o380bxs",
          "author": "RIP26770",
          "text": "This is simple and efficient! Well done üëç",
          "score": 0,
          "created_utc": "2026-02-02 20:46:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3828li",
          "author": "maxtablets",
          "text": "awesome",
          "score": 0,
          "created_utc": "2026-02-02 20:55:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39szv3",
          "author": "Conscious_Sock2989",
          "text": "[https://discord.gg/RwGMr9FB](https://discord.gg/RwGMr9FB)",
          "score": -6,
          "created_utc": "2026-02-03 02:26:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp4uq5",
      "title": "Please finally integrate ComfyUI Manager!",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1qp4uq5/please_finally_integrate_comfyui_manager/",
      "author": "-5m",
      "created_utc": "2026-01-28 07:32:56",
      "score": 77,
      "num_comments": 34,
      "upvote_ratio": 0.91,
      "text": "This keeps popping up in the issues and it keeps getting ignored..\nEVERYONE uses the Manager and EVERYONE has to install it manually.... Why??",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1qp4uq5/please_finally_integrate_comfyui_manager/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o26dy0t",
          "author": "_roblaughter_",
          "text": "They already have...",
          "score": 25,
          "created_utc": "2026-01-28 07:44:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2779jx",
              "author": "spacemidget75",
              "text": "Seems strange that Manager itself brings up \"Depricated API\" messages given this.",
              "score": 11,
              "created_utc": "2026-01-28 12:00:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o28d7l5",
                  "author": "_roblaughter_",
                  "text": "Honestly, rather than try to go back and rip out all of the old stuff, I just backed up and reinstalled Comfy. It was about time for a refresh anyway.",
                  "score": 3,
                  "created_utc": "2026-01-28 15:46:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o277wih",
              "author": "-5m",
              "text": "hmm..not on portable then I guess?",
              "score": 6,
              "created_utc": "2026-01-28 12:05:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o27q00t",
                  "author": "Wretched_Hare",
                  "text": "It is, I use it. There is a new flag for it. If you are using any of the newer releases and don‚Äôt see it then you might need to add the flag, I don‚Äôt remember it but it‚Äôs in the comfy repo instructions. It‚Äôs pretty new like a month or two.",
                  "score": 3,
                  "created_utc": "2026-01-28 13:54:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o28cxk5",
                  "author": "_roblaughter_",
                  "text": "[https://docs.comfy.org/manager/install#portable-users](https://docs.comfy.org/manager/install#portable-users)",
                  "score": 2,
                  "created_utc": "2026-01-28 15:45:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o26f6ui",
          "author": "VladyCzech",
          "text": "I think people who try to keep sanity and NOT breaking ComfyUI install by custom nodes dependencies do it manually anyway. It only takes one wrong requirements.txt to break your install. Good luck recovering.",
          "score": 11,
          "created_utc": "2026-01-28 07:55:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26jb88",
              "author": "sorvis",
              "text": "Oh new workflow needs new nodes cool...\n\n/Uninstalls dependencies in your other nodes \n\nNow only that workflows usable.\n\nBeen there, won't make that mistake for the 6th time XD...",
              "score": 16,
              "created_utc": "2026-01-28 08:32:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o27qtt1",
              "author": "TheSlateGray",
              "text": "There's a PR to fix it, sort of. I could see it working well for anyone who can read the logs and understand version numbers, but might just add more complexity for new users. [https://github.com/Comfy-Org/ComfyUI-Manager/pull/2516](https://github.com/Comfy-Org/ComfyUI-Manager/pull/2516)",
              "score": 3,
              "created_utc": "2026-01-28 13:58:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o26zpvo",
              "author": "DrStalker",
              "text": "Recovery is easy; just restore everything from backup.\n\n\nIf you don't have backups of your working ComfyUi setup including the python virtual environment, consider this a reminder to back it up before you have to spend three days arguing with python to fix it.",
              "score": 3,
              "created_utc": "2026-01-28 11:01:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o27idhh",
                  "author": "Abject-Recognition-9",
                  "text": "wich are the folders that need to be backup? honeslty having to backup the entire folder on whatever new node install is a pain in the ass",
                  "score": 3,
                  "created_utc": "2026-01-28 13:12:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ca1f5",
              "author": "Winter_unmuted",
              "text": "> I think people who try to keep sanity and NOT breaking ComfyUI install by custom nodes dependencies do it manually anyway. It only takes one wrong requirements.txt to break your install. Good luck recovering.\n\nI used to be driven mad by this, then I learned to just put my error into chatGPT and say what I did, and what I want to get back. \n\nIt says \"open cmd, type pip install....\" whatever and fixes it right away. Might end up that your new node pack used the dumb newest version of Numpy. It tells you if that's that case, too. \n\nSolved so many late nights doing venv resets! game changer.",
              "score": 1,
              "created_utc": "2026-01-29 02:45:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o26frda",
          "author": "GeroldMeisinger",
          "text": "How to solve everything forever:\n\n[https://www.reddit.com/r/comfyui/comments/1q3k5q6/how\\_to\\_solve\\_everything\\_forever\\_broken/](https://www.reddit.com/r/comfyui/comments/1q3k5q6/how_to_solve_everything_forever_broken/)",
          "score": 6,
          "created_utc": "2026-01-28 08:00:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2bi6np",
          "author": "comfyanonymous",
          "text": "Portable is supposed to be the bare bones \"I cloned the git repo and installed the basic dependencies\" version of ComfyUI. This makes it easier to maintain for me.\n\nIf you want manager preinstalled use the desktop app.",
          "score": 2,
          "created_utc": "2026-01-29 00:14:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26i7gu",
          "author": "FinalCap2680",
          "text": "I was using it, until there was no way to turn automatic updates off. \n\nSo - please DO NOT!!! Not everyone is using it. Or at least bring back option to disable updates.",
          "score": 2,
          "created_utc": "2026-01-28 08:22:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26kwiv",
              "author": "_roblaughter_",
              "text": "It's already integrated into Comfy Core. It's enabled by default in Comfy Desktop, but other installs require the --enable-manager flag. If you don't want to use it, you don't have to...",
              "score": 7,
              "created_utc": "2026-01-28 08:47:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o26s06j",
                  "author": "FinalCap2680",
                  "text": "Thank you. I have manual install on Linux (so no Desctop here), that is several years old. I just need (easy) control on what and when is installed if at all.",
                  "score": 4,
                  "created_utc": "2026-01-28 09:53:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o26rgip",
              "author": "MsHSB",
              "text": "Good to know but since when? Because i updated the manager somewhere around release of ZIT and i have no automatic Updates. I only use it to have a better overview of missing notes or to see if there are big version updates of my main nodes available/have a direct link to the repo. But always disabling the old version and do a fresh git clone. If there were autoupdates my env would broke immediently xD",
              "score": 1,
              "created_utc": "2026-01-28 09:48:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o27ex2l",
                  "author": "FinalCap2680",
                  "text": "Not sure.  But at some point only options I had  were \"to Stable version\" and \"to Nightly version\". No option to disable, so I just removed it.",
                  "score": 1,
                  "created_utc": "2026-01-28 12:52:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o26tmt5",
          "author": "Traveljack1000",
          "text": "I half expected last week with a fresh install that it was there, but it's not a biggy to do it manually..",
          "score": 1,
          "created_utc": "2026-01-28 10:08:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o275e6m",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 2,
              "created_utc": "2026-01-28 11:46:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o28dnvj",
                  "author": "Traveljack1000",
                  "text": "I use the stand alone version. That comes without manager. That's what I've learned.",
                  "score": 2,
                  "created_utc": "2026-01-28 15:48:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27wigv",
          "author": "ANR2ME",
          "text": "They did integrates Manager into ComfyUI in December 2025 https://www.reddit.com/r/comfyui/s/8WTTjAhkr5",
          "score": 1,
          "created_utc": "2026-01-28 14:27:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28f04l",
          "author": "Professional-Cut-297",
          "text": "Just installed comfyui on Linux to try to get better performance out of my 9070xt and the manager is still missing. No matter how much I re download. I spent 3 hours yesterday with grok to try to get it to show up. The terminal says it's there, but it's not on the screen. Even in legacy UI.",
          "score": 1,
          "created_utc": "2026-01-28 15:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28rja7",
          "author": "jonesaid",
          "text": "I tried the new built-in manager via the enable flag, and only a few of my custom nodes appeared there. So I went back to the old one.",
          "score": 1,
          "created_utc": "2026-01-28 16:48:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o298kei",
          "author": "Traveljack1000",
          "text": "I wouldn't know. My guess is the same as anyone's.  Maybe one day it will...",
          "score": 1,
          "created_utc": "2026-01-28 18:02:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2cera5",
          "author": "Emotional_Egg_251",
          "text": "> EVERYONE uses the Manager\n\nAs someone who has image, audio, video, and 3D under the same venv: I do not, and when I did keeping the system from breaking was much, much harder for me.\n\nI find it slow, reinventing the wheel, and with the recent registry security scare - no safer.",
          "score": 1,
          "created_utc": "2026-01-29 03:11:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27ml4q",
          "author": "shaolinmaru",
          "text": ">EVERYONE uses the Manager\n\n\nI don't.¬†\n\n\nI hate the way Manager... Manages the packages and run.¬†\n\n\nI prefer to do it manually to keep track of what needs to be changed when install/update a node.¬†",
          "score": 1,
          "created_utc": "2026-01-28 13:36:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26qvlz",
          "author": "Distinct-Expression2",
          "text": "Keeping it separate is actually the right call. The Manager has its own release cycle and breaking changes. Bundling it means every ComfyUI update could break node management, and every Manager update could break ComfyUI. It's a 30-second install ‚Äî the real pain point is dependency hell from custom nodes, and integrating the Manager wouldn't fix that.",
          "score": 0,
          "created_utc": "2026-01-28 09:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29ji7o",
              "author": "Sarashana",
              "text": "I don't really agree with that. Custom nodes are such a central feature of Comfy that not having the manager inside the main release feels somewhat odd. Also, IIRC the dev of the manager is a part of the ComfyUI team, so that makes it even more odd.",
              "score": 4,
              "created_utc": "2026-01-28 18:48:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1quemnv",
      "title": "Open Sourcing the Qwen Image Edit 2511 Multiple Angles LoRA!!",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/ex9yplqb7ecg1",
      "author": "Important-Respect-12",
      "created_utc": "2026-02-03 01:43:03",
      "score": 73,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1quemnv/open_sourcing_the_qwen_image_edit_2511_multiple/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3cywpi",
          "author": "stonerich",
          "text": "Cool!",
          "score": 1,
          "created_utc": "2026-02-03 15:54:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3amocf",
          "author": "no_witty_username",
          "text": "good stuff. !",
          "score": 1,
          "created_utc": "2026-02-03 05:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b16iw",
          "author": "seattleman74",
          "text": "Incredible",
          "score": 0,
          "created_utc": "2026-02-03 07:42:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}