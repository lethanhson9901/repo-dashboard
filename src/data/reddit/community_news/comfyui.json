{
  "metadata": {
    "last_updated": "2026-02-28 16:44:10",
    "time_filter": "week",
    "subreddit": "comfyui",
    "total_items": 20,
    "total_comments": 181,
    "file_size_bytes": 194027
  },
  "items": [
    {
      "id": "1rcemhe",
      "title": "Best faceswap with Flux2-Klein-9b and face enhance",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1rcemhe",
      "author": "TheNeonGrid",
      "created_utc": "2026-02-23 11:08:23",
      "score": 239,
      "num_comments": 60,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1rcemhe/best_faceswap_with_flux2klein9b_and_face_enhance/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6xzx27",
          "author": "Swimming_Dragonfly72",
          "text": "I noticed that result depends of original area input. Instead of sending the entire image to the input, it's better to crop the area around the shoulders. In my experience, the transfer works better when the model isn't obscured by secondary details.",
          "score": 18,
          "created_utc": "2026-02-23 12:57:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yy1at",
              "author": "eidrag",
              "text": "what I do is make 1 new workflow just to extract face and hair from straight forward with no/white bg, try until you got convincing face. Then use that face to swap",
              "score": 3,
              "created_utc": "2026-02-23 16:01:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6y23ib",
              "author": "blue_banana_on_me",
              "text": "Do you mean cropping the target photo‚Äôs head and perform the faceswap there? How do you blend the faceswapped cropped image into the actual final image?",
              "score": 2,
              "created_utc": "2026-02-23 13:11:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6yb2k7",
                  "author": "Swimming_Dragonfly72",
                  "text": "kj has a crop nodes with crop data. after cropping region and processing it you can paste this region back to the original image.",
                  "score": 2,
                  "created_utc": "2026-02-23 14:04:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6y2ntb",
                  "author": "TheNeonGrid",
                  "text": "in the subgraph workflow there is some inpaint crop node, so i guess this should do it",
                  "score": 1,
                  "created_utc": "2026-02-23 13:14:53",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o7tr74j",
                  "author": "robeph",
                  "text": "I just feed klein a black square,  and tell klein to remove only the head from image 2 and place the cropped head into the black space of image 1.   but then I'm lazy af... ",
                  "score": 1,
                  "created_utc": "2026-02-28 04:21:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o70pv0d",
          "author": "Sudden_List_2693",
          "text": "I'm speechless.  \nFlux.2 Klein has been around for what it feels like ages, and now we're getting back to the basic of the basic, almost sample workflows praised?   \nA simple \"replace the face on image 1 with the face on image 2\" using the default template can do this...",
          "score": 14,
          "created_utc": "2026-02-23 20:58:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o71e8lt",
              "author": "DrinksAtTheSpaceBar",
              "text": "I was about to say the exact same thing. Klein's native face swap abilities are among the best I've ever experienced. You don't even need a single LoRA or custom node for any of it.",
              "score": 10,
              "created_utc": "2026-02-23 23:01:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o73hf7p",
              "author": "D0wly",
              "text": "Same here. Been using the stock workflow and faceswap works just fine.",
              "score": 3,
              "created_utc": "2026-02-24 07:01:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o73jwd2",
              "author": "Odd_Newspaper_2413",
              "text": "It's not simple. There's significant variation depending on the image. Sometimes the contrast between the face and body doesn't match, making me wonder if it's better to just cut and paste using Photoshop.",
              "score": -1,
              "created_utc": "2026-02-24 07:23:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7trdlb",
                  "author": "robeph",
                  "text": "You can fix that,  I just use color match node and have klein generate a gradiant that has the 3 or 4 colors I want to tone out over the other's to fix it.  ",
                  "score": 1,
                  "created_utc": "2026-02-28 04:22:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6xxydc",
          "author": "MrCoolest",
          "text": "It's not the same face",
          "score": 13,
          "created_utc": "2026-02-23 12:44:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xzgqk",
              "author": "TheNeonGrid",
              "text": "well the second image has a broader face, so it adjusts it accordingly. if you want the same proportions you need to find a body image with similar facial structures",
              "score": 7,
              "created_utc": "2026-02-23 12:54:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ym35f",
                  "author": "HSLB66",
                  "text": "A head swap instead of a face swap takes care of that¬†",
                  "score": 7,
                  "created_utc": "2026-02-23 15:03:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78f43i",
          "author": "Famous-Sport7862",
          "text": "This is the huggingface page of the original creator of the workflow, you can find the lora there : [https://huggingface.co/Alissonerdx/BFS-Best-Face-Swap](https://huggingface.co/Alissonerdx/BFS-Best-Face-Swap)",
          "score": 3,
          "created_utc": "2026-02-24 23:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xpwes",
          "author": "Powerful_Evening5495",
          "text": "https://preview.redd.it/p11enyqoe8lg1.png?width=1024&format=png&auto=webp&s=5157d3144ed128ab1f61ed5b213be834836e0fd9\n\ni love this model \n\ni never go back to reactor \n\n",
          "score": 6,
          "created_utc": "2026-02-23 11:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xqif1",
              "author": "Powerful_Evening5495",
              "text": "i love how it add stuff and blend it quick , wow , i hated edit models before this one\n\nhttps://preview.redd.it/dexqe0hlf8lg1.png?width=656&format=png&auto=webp&s=2bb3e41f84a877629bac75174e91ecc4613e42a5\n\n",
              "score": 3,
              "created_utc": "2026-02-23 11:47:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o72abwv",
          "author": "Bracero925",
          "text": "Where can i get the lora ?",
          "score": 2,
          "created_utc": "2026-02-24 02:02:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78h9rq",
              "author": "Famous-Sport7862",
              "text": "This is the creator of the original workflow, you can find the lora there. [https://huggingface.co/Alissonerdx/BFS-Best-Face-Swap](https://huggingface.co/Alissonerdx/BFS-Best-Face-Swap)",
              "score": 3,
              "created_utc": "2026-02-25 00:03:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7b3i6a",
                  "author": "TheNeonGrid",
                  "text": "thanks!",
                  "score": 3,
                  "created_utc": "2026-02-25 11:18:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o74c7lp",
              "author": "TheNeonGrid",
              "text": "which one?",
              "score": 1,
              "created_utc": "2026-02-24 11:43:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o77t7zk",
          "author": "karpuzikov",
          "text": "what are image 3 4 5 for? great workflow thou",
          "score": 2,
          "created_utc": "2026-02-24 21:58:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b3evk",
              "author": "TheNeonGrid",
              "text": "if you want to put a photo of a necklace or more headphotos",
              "score": 1,
              "created_utc": "2026-02-25 11:17:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7d19es",
                  "author": "karpuzikov",
                  "text": "so they can be sources for additional elements? if I use more photos as head sources isrelust image will be more accurate?",
                  "score": 1,
                  "created_utc": "2026-02-25 17:35:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6z3nrs",
          "author": "YMIR_THE_FROSTY",
          "text": "Created some odd area around shoulder on swapped face.\n\nNot sure who is that girl before face swap, but she is really pretty. Apart that, not best pic for face swap target, due extreme low DOF. Thats something like 50/1.2 or so result.",
          "score": 1,
          "created_utc": "2026-02-23 16:27:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zr9w1",
              "author": "TheNeonGrid",
              "text": "yeah i didnt have some better photos and not much time when i posted this. the girl is some ai girl",
              "score": 1,
              "created_utc": "2026-02-23 18:17:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o71bmav",
                  "author": "YMIR_THE_FROSTY",
                  "text": "Both those pics are AI girl? I mean, that plastic one I would understand, but I genuinely thought that with super shallow DOF is real. With what was it made, some SDXL and extra face LoRA?",
                  "score": 1,
                  "created_utc": "2026-02-23 22:47:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zoq6v",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-23 18:05:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zzlle",
              "author": "Temporary-Roof2867",
              "text": "It works great but it's terribly slow on my computer üëÄüëÄ",
              "score": 1,
              "created_utc": "2026-02-23 18:54:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ztfzd",
          "author": "VirusCharacter",
          "text": "Not a true face swap though. More of a create-a-similar-image-with-this-face-instead, but it is good at it",
          "score": 1,
          "created_utc": "2026-02-23 18:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o71778m",
          "author": "Zealousideal_Elk7161",
          "text": "Intente cargar el JSON pero al ejecutar me sale este error pero ademas como que el KSampler tambien tiene algo \n\nhttps://preview.redd.it/buu3cct4lblg1.png?width=1348&format=png&auto=webp&s=b03aa98c18a7f74169f296b26860cc2dfb6ba877\n\n",
          "score": 1,
          "created_utc": "2026-02-23 22:24:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o718qp6",
              "author": "TheNeonGrid",
              "text": "open the subworkflow (the upper image edit node) and check if flux klein enhancer is installed. you can also remove it. its not so important.",
              "score": 1,
              "created_utc": "2026-02-23 22:32:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o719tyf",
                  "author": "Zealousideal_Elk7161",
                  "text": "Funciono! Gracias!!!",
                  "score": 2,
                  "created_utc": "2026-02-23 22:37:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o71oz1d",
          "author": "ChicoTallahassee",
          "text": "Which prompt do you use for the blending?",
          "score": 1,
          "created_utc": "2026-02-24 00:01:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o71qds4",
              "author": "TheNeonGrid",
              "text": "its in the workflow filled out",
              "score": 2,
              "created_utc": "2026-02-24 00:08:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73of9a",
          "author": "NeedleworkerOdd2783",
          "text": "why do you want to replace a real one?",
          "score": 1,
          "created_utc": "2026-02-24 08:05:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74c73r",
              "author": "TheNeonGrid",
              "text": "it's just an example",
              "score": 1,
              "created_utc": "2026-02-24 11:43:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73qd2d",
          "author": "Successful_AI",
          "text": "why would enhancer be installed in some and not for others?",
          "score": 1,
          "created_utc": "2026-02-24 08:23:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74c5dl",
              "author": "TheNeonGrid",
              "text": "the mysterious ways of comfy",
              "score": 2,
              "created_utc": "2026-02-24 11:42:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o75fiwi",
          "author": "Rich-Waltz442",
          "text": "do we need to use the character's lora whose face we are trying to swap on the base image ? or just image will do the work ?",
          "score": 1,
          "created_utc": "2026-02-24 15:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75ttmd",
              "author": "TheNeonGrid",
              "text": "Just the image",
              "score": 1,
              "created_utc": "2026-02-24 16:33:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o77382r",
          "author": "Sco0by_",
          "text": "Thanks for the workflow, one thing i still have not been able to do with any headswap workflow is to use the head from image 1 onto the body of image 2... but keep the face expression and head orientation of image 2.\n\nDo you think this is even possible ?",
          "score": 1,
          "created_utc": "2026-02-24 19:57:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aymw2",
              "author": "TheNeonGrid",
              "text": "Yeah that is hard. But you can either put a prompt in the image edit node or use the second workflow to edit the outcome image to your needs",
              "score": 1,
              "created_utc": "2026-02-25 10:36:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o77780q",
          "author": "tanoshimi",
          "text": "Both source images are looking directly at viewer. Swapped image completely changes the posture and expression.\n\nI still find Reactor way more reliable than Klein tbh.",
          "score": 1,
          "created_utc": "2026-02-24 20:16:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6znmsn",
          "author": "Zealousideal_Elk7161",
          "text": "Esta muy completo, ahora mismo lo estoy descargando para probar. Gracias",
          "score": 1,
          "created_utc": "2026-02-23 18:00:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o702a2z",
          "author": "skyrimer3d",
          "text": "i'm getting this error: \"SyntaxError: Unexpected non-whitespace character after JSON at position 4 (line 1 column 5)\" with this workflow:  [https://drive.google.com/file/d/1MD6L3K1gHHtJMj23FUPJCShqsJzyD6X-](https://drive.google.com/file/d/1MD6L3K1gHHtJMj23FUPJCShqsJzyD6X-)\n\n",
          "score": 1,
          "created_utc": "2026-02-23 19:06:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o705uzr",
              "author": "TheNeonGrid",
              "text": "open the subworkflow (the upper image edit node) and check if flux klein enhancer is installed. you can also remove it. its not so important.",
              "score": 2,
              "created_utc": "2026-02-23 19:23:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7101ic",
                  "author": "skyrimer3d",
                  "text": "That was exactly it, i deleted it and it worked fine, and thank God i did, this workflow is absolutely fantastic, i had one with klein 4b that was good and another with klein 9b that was better but with lighthing issues between face/body, this one smokes both, amazing!",
                  "score": 2,
                  "created_utc": "2026-02-23 21:49:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ymdu8",
          "author": "changqing89",
          "text": "What comfyui version are you using? The workflow has errors for me.",
          "score": 0,
          "created_utc": "2026-02-23 15:04:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zrq3i",
              "author": "TheNeonGrid",
              "text": "[**ComfyUI 0.14.1**](https://github.com/comfyanonymous/ComfyUI) [**ComfyUI\\_frontend v1.38.14**](https://github.com/Comfy-Org/ComfyUI_frontend)",
              "score": 1,
              "created_utc": "2026-02-23 18:19:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o71gsqh",
          "author": "Antyto2021",
          "text": "![gif](giphy|dOl2LFw0RbTMc)\n\n",
          "score": -8,
          "created_utc": "2026-02-23 23:15:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re7fwn",
      "title": "I made an in-app \"Beginner Bible\" for ComfyUI: a searchable, drag-and-drop dictionary of 136 core nodes explained for absolute beginners",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/d7bso33wmllg1.png",
      "author": "shamomylle",
      "created_utc": "2026-02-25 08:11:44",
      "score": 204,
      "num_comments": 38,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1re7fwn/i_made_an_inapp_beginner_bible_for_comfyui_a/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7aouvu",
          "author": "Imaginary_Error_1268",
          "text": "This is awesome! As a complete beginner, this is exactly what I needed. Simple explanations + drag-and-drop inside ComfyUI ‚Äî thank you so much! Going to use it a lot while learning.",
          "score": 6,
          "created_utc": "2026-02-25 09:05:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7avcbs",
              "author": "shamomylle",
              "text": "You're welcome, glad it can help :)",
              "score": 4,
              "created_utc": "2026-02-25 10:05:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7aque7",
          "author": "Formal-Exam-8767",
          "text": "Isn't \"Apply ControlNet\" node deprecated and should not be used?",
          "score": 5,
          "created_utc": "2026-02-25 09:24:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aubgz",
              "author": "shamomylle",
              "text": "Yes you are right, it just happens to be one of the core node so I left it in there, there are a couple deprecated node, but I wanted to mirror the nodes in the wiki as they are the default ones.  \nThanks for pointing it out!",
              "score": 4,
              "created_utc": "2026-02-25 09:56:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ax4pp",
                  "author": "addandsubtract",
                  "text": "Could you mark them as deprecated? Would be good to know which nodes to avoid / replace.",
                  "score": 4,
                  "created_utc": "2026-02-25 10:22:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ayidk",
                  "author": "Formal-Exam-8767",
                  "text": "Personally, I would hide deprecated nodes by default behind Show deprecated switch.",
                  "score": 2,
                  "created_utc": "2026-02-25 10:35:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7d44xq",
                  "author": "NoneedForAaaaa",
                  "text": "as a beginner, what does deprecated mean in this context? outdated? unusable?",
                  "score": 1,
                  "created_utc": "2026-02-25 17:48:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7bsr2j",
          "author": "Material_Echidna4297",
          "text": "You are doing god‚Äôs work. Thanks for this.",
          "score": 3,
          "created_utc": "2026-02-25 14:03:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7divtj",
              "author": "shamomylle",
              "text": "Thanks for the kind words! You're welcome :)",
              "score": 3,
              "created_utc": "2026-02-25 18:54:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7alczo",
          "author": "Various-News7286",
          "text": "Thank you (From a beginner)",
          "score": 3,
          "created_utc": "2026-02-25 08:32:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7avakt",
              "author": "shamomylle",
              "text": "You're welcome!",
              "score": 5,
              "created_utc": "2026-02-25 10:05:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7anycn",
          "author": "1Clou",
          "text": "‚ù§Ô∏è thanks",
          "score": 3,
          "created_utc": "2026-02-25 08:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7avas0",
              "author": "shamomylle",
              "text": "You're welcome!",
              "score": 3,
              "created_utc": "2026-02-25 10:05:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7c39ek",
          "author": "bsenftner",
          "text": "This is really great, and I applaud you for having the mind and patience to put this all together. I'm a AI developer coder, that writes ComfyUI nodes, yet I don't understand all this that you've laid out. This is, well, as someone already said here, \"God's work\". I thank you, deeply. ",
          "score": 3,
          "created_utc": "2026-02-25 14:58:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dj9vk",
              "author": "shamomylle",
              "text": "Coming from you it really means a lot, thanks!",
              "score": 3,
              "created_utc": "2026-02-25 18:55:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cikfx",
          "author": "Justify_87",
          "text": "This kinda thing should be part of comfyui to be honest. Some sort of beginner mode you can turn on/off in the settings or something like that. It was a pain in the ass to get into comfyui many years ago. and many threads here could prevented with this kinda help inside the UI",
          "score": 2,
          "created_utc": "2026-02-25 16:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7din4o",
              "author": "shamomylle",
              "text": "Thanks for the kind words! I really appreciate it, there is certainly room for improvement too, maybe in the future I could try to also have an option to add a \"mini workflow button\" for each node to show use case examples.",
              "score": 1,
              "created_utc": "2026-02-25 18:53:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7c4duw",
          "author": "GGG001PT2",
          "text": "thanks!",
          "score": 1,
          "created_utc": "2026-02-25 15:03:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dira4",
              "author": "shamomylle",
              "text": "You're welcome :)",
              "score": 1,
              "created_utc": "2026-02-25 18:53:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cws09",
          "author": "kakallukyam",
          "text": "I've been dreaming of this, thank you",
          "score": 1,
          "created_utc": "2026-02-25 17:14:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dht22",
              "author": "shamomylle",
              "text": "You're welcome :)",
              "score": 2,
              "created_utc": "2026-02-25 18:49:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7eaego",
                  "author": "kakallukyam",
                  "text": "Can we hope for a French translation? I thought we could highlight the help text and translate it using Google Translate, but I just installed it and unfortunately it's not possible, and being rather bad at English (without Google Translate) I find myself in pretty much the same situation. And I don't know if this is normal, but when I want to drag a node directly from the help to drag it into the workflow, The node doesn't appear where I dragged it, and I have to zoom out to find it in the workflow. I don't understand why.",
                  "score": 1,
                  "created_utc": "2026-02-25 21:02:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7heck3",
          "author": "SnooWoofers186",
          "text": "i just came across this comfy AI, is there any minimal system requirement for it? And if i just want to do image AI stuff but not video?\n\nI wasn't good with many program related stuff.",
          "score": 1,
          "created_utc": "2026-02-26 08:37:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hq5rb",
              "author": "shamomylle",
              "text": "I think for image you have a lot more flexibility, I am personally running things with 8GB Vram which is on the low end, it feels like the minimum requirement to get anything decent done.",
              "score": 2,
              "created_utc": "2026-02-26 10:30:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mab1e",
          "author": "PlantainExtension937",
          "text": "Ë∞¢Ë∞¢ÔºåÊúÄÂ•ΩÂä†‰∏ä‰∏ÄÈîÆÂàÜÊûê„ÄÅÊõøÊç¢ÈóÆÈ¢òËäÇÁÇπ„ÄÅÊ®°ÂûãÁöÑÂäüËÉΩÔºÅ",
          "score": 1,
          "created_utc": "2026-02-27 00:57:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mx9do",
              "author": "shamomylle",
              "text": "Thanks for the feedback! However, auto-analyzing and replacing missing nodes/models is a bit outside the scope of this project, as this is just meant to be a dictionary/reference guide. For fixing missing nodes, I highly recommend using the **ComfyUI Manager** ('Install Missing Custom Nodes' feature) as it already does exactly that perfectly!",
              "score": 1,
              "created_utc": "2026-02-27 03:10:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mhq2f",
          "author": "DigitalbathRxx",
          "text": "I will definitely be adding this when I get home.  Appreciate your effort!  Just started with Comfy last week and it‚Äôs a bit of a hill to climb.  Thank you!",
          "score": 1,
          "created_utc": "2026-02-27 01:40:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mwrpr",
              "author": "shamomylle",
              "text": "You're welcome! Hope it helps, good luck :)",
              "score": 2,
              "created_utc": "2026-02-27 03:07:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ca1ad",
          "author": "LordBrandon",
          "text": "Can it list out all the contradictions?",
          "score": 1,
          "created_utc": "2026-02-25 15:30:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dm68o",
              "author": "shamomylle",
              "text": "Haha, if you mean religious contradictions, then no! \n\nBut if you mean ComfyUI contradictions (like plugging an SDXL prompt into an SD1.5 model), the \"Beginner Tips\" on the cards do warn you about some of those common mistakes!",
              "score": 3,
              "created_utc": "2026-02-25 19:09:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rer6ls",
      "title": "[Update] ComfyUI-MotionCapture: moving camera support + SMPL viewer with \"through camera\" view",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/ivsp9s86pplg1",
      "author": "ant_drinker",
      "created_utc": "2026-02-25 21:54:26",
      "score": 192,
      "num_comments": 22,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/comfyui/comments/1rer6ls/update_comfyuimotioncapture_moving_camera_support/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7f5bs2",
          "author": "jalbust",
          "text": "Just wow!",
          "score": 4,
          "created_utc": "2026-02-25 23:34:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fp3q7",
          "author": "shamomylle",
          "text": "Hello, this looks great! I'm new to comfyUI so sorry for the noob question, but is your node extracting 3D coordinates like point clouds ? Is it possible to get a BHV or FBX rig animation?\n\nI just recently created a custom node which reads animations from glb/fbx/BHV files and apply them to a 3D openPose compatible skeleton and humanoid character to render OpenPose/depth/Canny/normal passes. \nIt could be interesting to use your node in combination with mine if that was the case!",
          "score": 3,
          "created_utc": "2026-02-26 01:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7fyqnj",
              "author": "ant_drinker",
              "text": "It deffo can apply to a mixamo rigged character! and any character can be rigged with mixamo using unirig node :) [https://github.com/PozzettiAndrea/ComfyUI-UniRig/](https://github.com/PozzettiAndrea/ComfyUI-UniRig/)",
              "score": 5,
              "created_utc": "2026-02-26 02:19:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7g36d4",
                  "author": "shamomylle",
                  "text": "Thanks so much! I will definitely play with this!",
                  "score": 1,
                  "created_utc": "2026-02-26 02:44:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7fzzt1",
          "author": "yotraxx",
          "text": "This is HUGE !!! √¥O\nThank you ! I need to try your nodes asap",
          "score": 2,
          "created_utc": "2026-02-26 02:26:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7geleo",
          "author": "PixarX",
          "text": "Any videos showing the workflow? I ran the earlier Sam3 workflows and they were impressive. P.S. some nodes like Cam trajectory are not loading.",
          "score": 2,
          "created_utc": "2026-02-26 03:52:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7gfap8",
              "author": "ant_drinker",
              "text": "The workflow is in the repo itself! :) \"[GVHMR\\_cameramotion.json](https://github.com/PozzettiAndrea/ComfyUI-MotionCapture/blob/main/workflows/GVHMR_cameramotion.json)\"",
              "score": 1,
              "created_utc": "2026-02-26 03:57:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7g2soq",
          "author": "Simple-Variation5456",
          "text": "Does this also work for objects like helicopters or cars?",
          "score": 1,
          "created_utc": "2026-02-26 02:42:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gb7na",
          "author": "angelarose210",
          "text": "This is great! I have some uses for this.",
          "score": 1,
          "created_utc": "2026-02-26 03:31:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gfh81",
          "author": "PixarX",
          "text": "I meant running through it in a video. Like how the camera tracking is extracted etc.",
          "score": 1,
          "created_utc": "2026-02-26 03:58:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gouip",
          "author": "Ecstatic_Signal_1301",
          "text": "Would be nice to know disk space usage and install location of depedencies, so it wont populate C drive with 30+GB",
          "score": 1,
          "created_utc": "2026-02-26 05:01:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l3mi1",
              "author": "ant_drinker",
              "text": "[https://pozzettiandrea.github.io/ComfyUI-MotionCapture/#main](https://pozzettiandrea.github.io/ComfyUI-MotionCapture/#main) if you could bother clicking twice you would find that information.",
              "score": 2,
              "created_utc": "2026-02-26 21:14:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7hiwe1",
          "author": "BlackFoxLingerie",
          "text": "Holy shit, this is incredible, absolutely incredible!! Be sure to post this in the blender subreddit as well as other major 3d softwares. I see people in those subs crying all the time about AI and how it's the worst but they don't ever see tools as useful as this!",
          "score": 1,
          "created_utc": "2026-02-26 09:21:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ht28n",
          "author": "ngatao",
          "text": "noticed the dependency package \"comfy-env\" is trying to kick off sudo commands?...\n\nimho would be best to leave system level installs to the user",
          "score": 1,
          "created_utc": "2026-02-26 10:57:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l3t1w",
              "author": "ant_drinker",
              "text": "I agree that it would be better! But I can't ensure a smooth one click installation without it... what in particular was the command you are mentioning?",
              "score": 1,
              "created_utc": "2026-02-26 21:15:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7lafbr",
                  "author": "ngatao",
                  "text": "Well I'm on non-debian linux so first \"dpkg\" failed. To me a looked a bit scary it was trying to execute this so started digging... So noticed apt-get update and install python3-dev. \n\nIdk.. With all security concerns around comfy custom nodes, I would leave these installs to the user. If it means no one click install, so be it.. my 2c :-)\n\nBut anyway, thanks for your amazing work on these nodes though!",
                  "score": 2,
                  "created_utc": "2026-02-26 21:46:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7lkwhg",
                  "author": "qiang_shi",
                  "text": "yes you can. you're just shit at linux.",
                  "score": 1,
                  "created_utc": "2026-02-26 22:38:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7m6y1w",
          "author": "PlantainExtension937",
          "text": "https://preview.redd.it/os0nco6nmxlg1.png?width=1212&format=png&auto=webp&s=a290a23bcd2f893e8d339826b73bd81577cac17f\n\nË∞¢Ë∞¢‰Ω†ÁöÑÂ∑•‰ΩúÊµÅÔºåÊàëÂØºÂÖ•Âêé‰∏ÄÁõ¥Á∫¢Ê°Ü„ÄÇ‰πüÂÆâË£Ö‰∫Ü‰Ω†ÁöÑComfyUI-MotionCaptureÊèí‰ª∂„ÄÇ‰ΩÜÂÆÉ‰∏çËÆ§ÔºüÊ±ÇËß£„ÄÇ",
          "score": 1,
          "created_utc": "2026-02-27 00:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7n7g6z",
          "author": "Lower-Cap7381",
          "text": "This is super awesome dude congrats thanks for this",
          "score": 1,
          "created_utc": "2026-02-27 04:14:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nkc26",
          "author": "Snoo20140",
          "text": "![gif](giphy|gW9YgAKyDEOzQV1PA3)\n\n",
          "score": 1,
          "created_utc": "2026-02-27 05:45:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1reo6jn",
      "title": "[Update] ComfyUI-SAM3 ‚Äî Interactive click-to-segment (in-canvas prompting)",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/uwo4bf8t5plg1",
      "author": "ant_drinker",
      "created_utc": "2026-02-25 20:03:57",
      "score": 158,
      "num_comments": 21,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/comfyui/comments/1reo6jn/update_comfyuisam3_interactive_clicktosegment/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7ebyah",
          "author": "ramonartist",
          "text": "I haven't updated your nodes since last year because they were working perfectly fine you did a great job, but now that I updated, I am getting model downloading errors, when I already have \"**sam3.safetensors**\", \"**sam3.pt**\" models in **models/sam3** path is there a reason why you needed to change the **Load SAM3 model** node?\n\nAlso your node now auto-installs [https://github.com/PozzettiAndrea/ComfyUI-SAM3/blob/main/comfy-env-root.toml](https://github.com/PozzettiAndrea/ComfyUI-SAM3/blob/main/comfy-env-root.toml) these extra nodes which I don't need, why?\n\n`[cuda]`\n\n`packages = [\"cc_torch\", \"torch_generic_nms\", \"flash-attn\", \"sageattention\"]`\n\n`[node_reqs]`\n\n`ComfyUI-VideoHelperSuite = \"Kosinkadink/ComfyUI-VideoHelperSuite\"`\n\n`ComfyUI-Multiband = \"PozzettiAndrea/ComfyUI-Multiband\"`\n\n`ComfyUI-Env-Manager = \"PozzettiAndrea/ComfyUI-Env-Manager\"`\n\n[https://github.com/PozzettiAndrea/ComfyUI-Multiband](https://github.com/PozzettiAndrea/ComfyUI-Multiband)  \n[https://github.com/PozzettiAndrea/comfy-env](https://github.com/PozzettiAndrea/comfy-env)",
          "score": 9,
          "created_utc": "2026-02-25 21:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7edeao",
              "author": "ant_drinker",
              "text": "Hi! :) sorry about the model downloading errors, please open an issue on GitHub, I'm sure I can address it fast. Regarding why comfy-env needs to be installed, it's because it handles GPU/PyTorch/CUDA auto detection so you don't have to go and fetch the attention/cc\\_torch/nms cuda wheels by yourself.\n\nIt also installs other nodes that are useful for SAM3.\n\n  \nIf you don't like this version, feel free to keep using the old one!",
              "score": -6,
              "created_utc": "2026-02-25 21:16:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7joztt",
                  "author": "lacerating_aura",
                  "text": "This update borked my perfectly working environment. Now z and qwen are broken cause of the funky attention installations. Usually that requires me passing sage attention arg during launch, but your node pack has made it the default overall in my environment?\n\nEdit: Sigh, does anyone know how to fix this. Disabling the node packs or Uninstaller it does not revert the changes. Passing global flash attention does not help. Forcefully removing Env manager, as is does not show up in installed node packs, does not fix. Sigh, am I gonna have to remake my environment and reset my custom node installations?\n\nEdit2: Remove all the custom nodes that were installed by the update along with the sam3 node pack. Go to the venv and uninstall comfy-env. Use find command to remove any traces of comfy-env. Then remove your main.py and pull a fresh one from github. Thats how to fix it.",
                  "score": 12,
                  "created_utc": "2026-02-26 17:17:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7jn6tk",
                  "author": "Violent_Walrus",
                  "text": "Your custom node wants to manage my CUDA and torch installation? Oh hell no. You don't get to touch my environment. Stay in your lane.\n",
                  "score": 14,
                  "created_utc": "2026-02-26 17:08:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7mclsa",
          "author": "DeepHomage",
          "text": "This custom node completely broke my working ComfyUI install.  Has taken me hours to troubleshoot the baffling issues it caused with other ComfyUI custom nodes and uninstall the peculiar environment-breaking requirements. I'd suggest a warning to potential users that the node should be installed in a separate python environment, with no other custom nodes.  ",
          "score": 3,
          "created_utc": "2026-02-27 01:10:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fd3hw",
          "author": "Eisegetical",
          "text": "I'm a huge fan of nodes that add extra live ui features on nodes. \n\nthis is great! I'll definitely grab this\n\nedit - oh, you're the SAM3D Body repo guy. Been playing with that recently. Is there any way at all to get the relative camera position from a 3d body solve as well? I get the 3d geo but there's no way to get the original relative camera coords as well",
          "score": 2,
          "created_utc": "2026-02-26 00:17:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h6hba",
          "author": "crowzor",
          "text": "was playing aroung with the old version a few days ago. i had a video where the thing i wanted to mask was out of frame for the first second as the camera rotated towards them.  Is there a way to get that to work that it masks when it comes into frame?",
          "score": 1,
          "created_utc": "2026-02-26 07:23:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7f59cc",
          "author": "jalbust",
          "text": "This helps thanks!!",
          "score": 0,
          "created_utc": "2026-02-25 23:34:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g11ts",
          "author": "Odd-Mirror-2412",
          "text": "It's cool! Thanks",
          "score": 0,
          "created_utc": "2026-02-26 02:32:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re4jzm",
      "title": "Getting the hang of consistency. Check the paint scratches and stuff. Not perfect. Stay tuned, I'm not ready yet to share the how, I'm working on it.",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1re4jzm",
      "author": "oodelay",
      "created_utc": "2026-02-25 05:28:42",
      "score": 134,
      "num_comments": 44,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "No workflow",
      "permalink": "https://reddit.com/r/comfyui/comments/1re4jzm/getting_the_hang_of_consistency_check_the_paint/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7ahwjb",
          "author": "AntelopeOld3943",
          "text": "I am not ready yet to give a Like. Im working on it.",
          "score": 80,
          "created_utc": "2026-02-25 08:00:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b85xa",
              "author": "oodelay",
              "text": "Laughs in gaussian",
              "score": -13,
              "created_utc": "2026-02-25 11:55:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7d51p0",
                  "author": "0__O0--O0_0",
                  "text": "Dont do it man. Backgrounds are the last thing keeping the fake Instagram girls recognizably fake. If I can‚Äôt call out the skirting board inverting into a bathroom cabinet I‚Äôm screwed.",
                  "score": 7,
                  "created_utc": "2026-02-25 17:52:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7a66ri",
          "author": "Aggressive_Collar135",
          "text": "if i have to guess, its probably gaussian splatting",
          "score": 21,
          "created_utc": "2026-02-25 06:17:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aicbn",
              "author": "Joe_Kingly",
              "text": "I would freakin' love it if it was! I'm excited to play/learn more with that!",
              "score": 7,
              "created_utc": "2026-02-25 08:04:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7b8cb4",
                  "author": "oodelay",
                  "text": "Get learnin' on them splats",
                  "score": 2,
                  "created_utc": "2026-02-25 11:57:09",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7b8an1",
              "author": "oodelay",
              "text": "![gif](giphy|MdXl4KwZogSzAn6Xx4|downsized)",
              "score": 0,
              "created_utc": "2026-02-25 11:56:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bcenw",
                  "author": "Aggressive_Collar135",
                  "text": "Im honestly impressed that the breaking and chipping across the wooden parts are mostly retained in the multiple shots. Thanks for sharing good output achievable with the technique!",
                  "score": 3,
                  "created_utc": "2026-02-25 12:26:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7a5o88",
          "author": "Kuldeep_music",
          "text": "Well which model ? ",
          "score": 11,
          "created_utc": "2026-02-25 06:13:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a9a29",
          "author": "Quantical-Capybara",
          "text": "Looks cool. I'm struggling with environment consistency, so if you have any good tips.",
          "score": 6,
          "created_utc": "2026-02-25 06:43:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bp2pu",
          "author": "oodelay",
          "text": "https://preview.redd.it/t2zqseq4anlg1.jpeg?width=630&format=pjpg&auto=webp&s=1782c93046a5a9bf0f0eb3e7a02d75ba7ade713a\n\nConsistant paint chips make me tingly",
          "score": 5,
          "created_utc": "2026-02-25 13:43:45",
          "is_submitter": true,
          "replies": [
            {
              "id": "o7cts06",
              "author": "Noob_Krusher3000",
              "text": "That might be lead",
              "score": 5,
              "created_utc": "2026-02-25 17:00:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cwsv5",
                  "author": "oodelay",
                  "text": "Lead paint: Delicious but DEADLY",
                  "score": 5,
                  "created_utc": "2026-02-25 17:14:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7a46ig",
          "author": "No-Expression6444",
          "text": "look forward to you sharing your findings, looks very promising.",
          "score": 9,
          "created_utc": "2026-02-25 06:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7an6sf",
          "author": "Infninfn",
          "text": "Can the shamanic rituals also make the lighting more realistic and take care of the excessive amount of dynamic range in the shadows? I blame the overly processed photos on the web that get trawled into the training dataset.",
          "score": 4,
          "created_utc": "2026-02-25 08:49:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b7zxk",
              "author": "oodelay",
              "text": "The first image comes from z-image base, hence the weird details but rich image. I left the weird items in to see if he would follow through.",
              "score": 1,
              "created_utc": "2026-02-25 11:54:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7axvn1",
          "author": "Elvarien2",
          "text": "The consistency you got is really good. However the base quality of your render is really poor. \n\nIs it possible to maintain such consistency in output that is of quality?",
          "score": 4,
          "created_utc": "2026-02-25 10:29:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b8vbu",
              "author": "oodelay",
              "text": "Base image for inspiration was generated through z-image base. Its crappy but rich in details like my face.",
              "score": 9,
              "created_utc": "2026-02-25 12:01:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bhuyc",
                  "author": "Elvarien2",
                  "text": "Ah, so it can work just fine on higher quality output and remain as consistent as this with the paint flecks and damage?  \n\nThat's very neat then.",
                  "score": 1,
                  "created_utc": "2026-02-25 13:01:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ajhk1",
          "author": "Ok-Outside3494",
          "text": "Super cool, enlight us",
          "score": 2,
          "created_utc": "2026-02-25 08:14:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7anrx9",
          "author": "karijoart",
          "text": "looks great OP. My guess is also image - gaussian splat - move camera - denoise. Looking forward to an update, let me know cheers",
          "score": 2,
          "created_utc": "2026-02-25 08:55:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aufzi",
              "author": "ErnestoPresto80",
              "text": "If the consistency is so good... perhaps Gaussian splatting could be improved with each new image?",
              "score": 3,
              "created_utc": "2026-02-25 09:57:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7aype6",
                  "author": "karijoart",
                  "text": "that's a good point. I have not tested gaussian splatting yet. But why not: Step 1) base image1 - gaussian splat - move camera - denoise - new POV image2.  Step 2) base image1 + new POV image2 - more complete gaussian splat - move camera - denoise - new POV image3. Step3) keep iterating. Automate the process with  fixed camera rotations based on optimal gaussian splat POV distribution for each step -> high quality gaussian splat?",
                  "score": 3,
                  "created_utc": "2026-02-25 10:36:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7b7r5q",
              "author": "oodelay",
              "text": "Gaussian is involved, yes! 2511 too.",
              "score": 3,
              "created_utc": "2026-02-25 11:52:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7azp6d",
          "author": "Subject-Pineapple837",
          "text": "There‚Äôs a giant spider on the stove",
          "score": 2,
          "created_utc": "2026-02-25 10:45:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bdvkq",
              "author": "oodelay",
              "text": "It's like AI is always on the end of acid trip",
              "score": 1,
              "created_utc": "2026-02-25 12:36:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7b5e62",
          "author": "You_Havent_SeenYet",
          "text": "nice, but still very \"nervous\" details all over the image.",
          "score": 2,
          "created_utc": "2026-02-25 11:34:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b8qr7",
              "author": "oodelay",
              "text": "Yeah for the older gen it really feels like a LSD-end-of-trip. Things are almost fine but then you realize you're staring at the melting cabinets",
              "score": 1,
              "created_utc": "2026-02-25 12:00:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7bnpga",
          "author": "skyrimer3d",
          "text": "can't wait",
          "score": 2,
          "created_utc": "2026-02-25 13:36:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7byoe1",
          "author": "PastorNTraining",
          "text": "Well done!",
          "score": 2,
          "created_utc": "2026-02-25 14:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m1bfs",
          "author": "BluetownA1",
          "text": "Could be: 1. Reference Image -> 2. simple gaussian splat with 1 image. -> 2. slightly turning/moving splat, -> 3. enhancing/upscale the image -> 4. repeat until you have enough angles -> 5. using all images for further splats until you have a scene?  ",
          "score": 2,
          "created_utc": "2026-02-27 00:07:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m4yr4",
              "author": "oodelay",
              "text": "sorta",
              "score": 1,
              "created_utc": "2026-02-27 00:27:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7auhgg",
          "author": "sucr4m",
          "text": "ignoring that the oven/stove  makes no sense at all, the thing hanging above it changes drastically through out the pictures. also the window above it is broken in different ways on different pictures. those are the most obvious ones. there is way more changes in finer details all over those pictures though.",
          "score": 3,
          "created_utc": "2026-02-25 09:58:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7be76d",
              "author": "oodelay",
              "text": "The base image was z-image base which is great to create lots of details but most lf those details are weird. I agree my base image could have been better but I wanted details and a eerie feeling, generated a whole bunch and chose this one for its simplicity and paint job.",
              "score": 2,
              "created_utc": "2026-02-25 12:38:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ai6x1",
          "author": "Joe_Kingly",
          "text": "Whoa! That's both impressive and inspiring!",
          "score": 1,
          "created_utc": "2026-02-25 08:02:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aigc8",
          "author": "Wild24",
          "text": "Looks promising to me. ",
          "score": 1,
          "created_utc": "2026-02-25 08:05:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bcjyw",
          "author": "Babyface_Assassin",
          "text": "Why are there 5 knobs on the stove but only one (maybe 2) burners",
          "score": 1,
          "created_utc": "2026-02-25 12:27:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bdm9c",
              "author": "oodelay",
              "text": "Obviously you don't know how to cook in AI. One of those knobs is for the integrated [plumbus](https://youtu.be/eMJk4y9NGvE?si=zTnlCLwUScU4VGxu)",
              "score": 2,
              "created_utc": "2026-02-25 12:34:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7c7vqz",
                  "author": "Babyface_Assassin",
                  "text": "Touch√©",
                  "score": 1,
                  "created_utc": "2026-02-25 15:20:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7c7tal",
          "author": "Petroale",
          "text": "Impressive consistency!",
          "score": 1,
          "created_utc": "2026-02-25 15:20:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7d4rzr",
          "author": "bickid",
          "text": "so how'd you do it?",
          "score": 1,
          "created_utc": "2026-02-25 17:51:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l88qt",
          "author": "qcodec",
          "text": "https://preview.redd.it/oh5twxxxqwlg1.png?width=284&format=png&auto=webp&s=e4d8e17b419ebb65c7da6b09add0ce38e0bc6668\n\nSomething else stands out. It should be broken glass, but it looks like a broken mirror.",
          "score": 1,
          "created_utc": "2026-02-26 21:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bjgjt",
          "author": "kornuolis",
          "text": "https://preview.redd.it/3ejhl91e4nlg1.png?width=356&format=png&auto=webp&s=111fb4e54797fd0141b1e0a416b1fd2e7d101875\n\nWonder what reve is",
          "score": -2,
          "created_utc": "2026-02-25 13:11:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdkg4y",
      "title": "I made an LTX-2 workflow for midrange to lower-midrange computers, and I call it: Weird Science",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/y9dxxy6ovglg1.png",
      "author": "Toby101125",
      "created_utc": "2026-02-24 16:12:14",
      "score": 110,
      "num_comments": 44,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1rdkg4y/i_made_an_ltx2_workflow_for_midrange_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o75tz4z",
          "author": "Illynir",
          "text": "I'll test this, thanks for sharing. :)  \nHowever, I hope it's REALLY for low/mid spec PCs, not like the others that say the workflow is designed for 8 or 12 GB VRAM but actually requires 64 GB RAM. xD",
          "score": 4,
          "created_utc": "2026-02-24 16:34:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75vtlt",
              "author": "Toby101125",
              "text": "My specs in the summary are truthful. What to expect:\n\nAt least a 5 minute pre-load of all models and the CLIP text encoder, probably longer if you have 3 different prompts + About 5 minutes of sampling + And lastly 1 minute of tiled decoding.\n\nSo once it's all loaded and as long as you stick with the same prompts, you'll get 6 minute outputs. The CLIP time is why I added 3 prompt options.",
              "score": 3,
              "created_utc": "2026-02-24 16:42:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o76q4im",
              "author": "Bietooeffin",
              "text": "Low vram always means for the current video models that you either have to compensate that with system ram or a hefty page file, even with the smallest acceptable quants (q4).",
              "score": 1,
              "created_utc": "2026-02-24 18:58:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76u1o1",
              "author": "Toby101125",
              "text": "I should clarify my VRAM: 8 GB from GPU and then like 16 from VRAM.",
              "score": 1,
              "created_utc": "2026-02-24 19:15:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o77oqia",
                  "author": "MarcusMagnus",
                  "text": "What would happen if I used this workflow with my 5090?  It looks great.",
                  "score": 1,
                  "created_utc": "2026-02-24 21:37:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7a5nxt",
                  "author": "Final_Discount_1310",
                  "text": "Sorry I'm dumb here. \n\nare you saying you have 2 sources of VRAM? \n\n>and then like 16 from VRAM\n\nAre you saying that you're getting 16 GB of VRAM not from your GPU?",
                  "score": 1,
                  "created_utc": "2026-02-25 06:12:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7j58bs",
                  "author": "brocolongo",
                  "text": "8gb Vram and 16gb vram? something is wrong there ",
                  "score": 1,
                  "created_utc": "2026-02-26 15:46:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o764ren",
          "author": "Derispan",
          "text": "I dont need that (still prefer WAN), but mate, this is C L E A N workflow. Very nice.",
          "score": 7,
          "created_utc": "2026-02-24 17:22:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7685ep",
              "author": "Toby101125",
              "text": "The node group thing is really nice",
              "score": 5,
              "created_utc": "2026-02-24 17:38:28",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o780a71",
              "author": "Jesus__Skywalker",
              "text": "it kills me that wan is still so much better.",
              "score": 2,
              "created_utc": "2026-02-24 22:32:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o782csy",
                  "author": "Toby101125",
                  "text": "Why? If it's working for you, keep on keeping on. My issue with Wan2.2 was lighting models still needed 15 minutes for an 8 second video and the animations were abyssmal.",
                  "score": 3,
                  "created_utc": "2026-02-24 22:43:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75pybr",
          "author": "Toby101125",
          "text": "Reddit filters DO NOT like my cover image at all. This platform sucks.",
          "score": 3,
          "created_utc": "2026-02-24 16:16:28",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o75xs8f",
          "author": "ltx_model",
          "text": "Nice name :) ",
          "score": 3,
          "created_utc": "2026-02-24 16:51:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75z4a1",
              "author": "Toby101125",
              "text": "Thanks. I wish Reddit would allow me to post the cover image, which I had fun working on, but apparently it thinks it's explicit loli or whatever.",
              "score": 1,
              "created_utc": "2026-02-24 16:57:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o77z3mv",
          "author": "Jesus__Skywalker",
          "text": "ltx has honestly been kinda disappointing to me. I mean you can get some really good results occasionally. But it's so hit and miss.",
          "score": 3,
          "created_utc": "2026-02-24 22:26:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78254d",
              "author": "Toby101125",
              "text": "My problem with Wan2.2 is my system can only hand lightning, and the results are terribly stiff. You're right that it's hit and miss, but a good prompt can really make a difference. I have no perfected the best prompt hierarchy yet, but I'm getting there.",
              "score": 3,
              "created_utc": "2026-02-24 22:41:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o76i699",
          "author": "Desperate_News_5116",
          "text": "I'm new to this image to video thing so sorry for stupid questions.\n\nDoes this flow work only SFW? Does this flow only work with any specific checkpoint?",
          "score": 1,
          "created_utc": "2026-02-24 18:22:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76jdzx",
              "author": "Toby101125",
              "text": "There's a lot of notes in the workflow about what it needs and links to get you there.\n\nI've had ok success with it working with NSFW source images. It's all about how good your image and prompt is.",
              "score": 2,
              "created_utc": "2026-02-24 18:28:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o76x7cq",
          "author": "oneFookinLegend",
          "text": "how long does it take you to generate whatever you generate?",
          "score": 1,
          "created_utc": "2026-02-24 19:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o772w2f",
              "author": "Toby101125",
              "text": "About:\n\n2 minute model load\n\n2 minute CLIP load each\n\n5 minute sampling\n\n1 minute tiled decode\n\nThen it's just 6 minutes per new seed.¬†\n",
              "score": 3,
              "created_utc": "2026-02-24 19:56:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o77f8f5",
                  "author": "oneFookinLegend",
                  "text": "excelent answer. thank you",
                  "score": 2,
                  "created_utc": "2026-02-24 20:54:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77s7rm",
          "author": "pervyprawn",
          "text": "Gyatdamm can‚Äôt wait to try on my 5070 TI lol",
          "score": 1,
          "created_utc": "2026-02-24 21:53:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hme2d",
          "author": "Maximum_Astronaut114",
          "text": "Heyyyy thanks so much for such a beautiful and clean workflow.\n\nI allowed myself to drop you a DM related to some high level issue/weirdness with LTX2 that I ran into.\n\nWould greatly greatly appreciate receiving your responce.\n\nAnd thanks again!",
          "score": 1,
          "created_utc": "2026-02-26 09:55:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7kao97",
          "author": "brocolongo",
          "text": "Any idea why im getting this kind of outputs? \n\nhttps://preview.redd.it/3112aojtyvlg1.png?width=482&format=png&auto=webp&s=65e7e9f3f98292b364c6007c1ad543bd7df7be07\n\n",
          "score": 1,
          "created_utc": "2026-02-26 18:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7knatr",
              "author": "Toby101125",
              "text": "Mind dropping the Lydia or Chun-Li json and png into Comfy and checking if those have the same problem?",
              "score": 1,
              "created_utc": "2026-02-26 19:56:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7w3oo7",
                  "author": "brocolongo",
                  "text": "Seems to have the same issue, It only happens on your workflow thats weird ",
                  "score": 1,
                  "created_utc": "2026-02-28 15:22:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76sapo",
          "author": "kakallukyam",
          "text": "That's great work, as a beginner, it saves me from seeing knots and cables everywhere, well done for that. However, I don't understand where I should put the prompts. I tried it without changing anything and in the end I got three almost identical videos, two of which had no audio and each time the person moved very little, as if in slow motion with text appearing on top of them as if it were an advertisement, is that normal? Where should we put our prompts? In the \"basic description\", \"subject action R, G and B\" nodes? I'm sorry, I can't understand which node corresponds to what, can you help me please?",
          "score": 1,
          "created_utc": "2026-02-24 19:07:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o783fly",
              "author": "Toby101125",
              "text": "Do you still need help?",
              "score": 2,
              "created_utc": "2026-02-24 22:48:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7cu1g5",
                  "author": "kakallukyam",
                  "text": "Yes, please. I tested it with Lydia's and Chun-Li's .json files, and again I didn't understand the results. For example, with Lydia, I uploaded an image of a Viking woman to match the prompt because I didn't want to change anything for testing purposes, but during generation, only the beginning of the video corresponds to the uploaded image on all 3 videos; a few seconds later, at the change of scene, I find myself with another person who no longer resembles the one in the uploaded image. And I'm having trouble understanding the order of the \"subject\" windows and what they correspond to. If you could clarify this for me, that would be great; thanks",
                  "score": 1,
                  "created_utc": "2026-02-25 17:02:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o76sy94",
              "author": "Toby101125",
              "text": "I have to run errands but I'll be back later this afternoon. Have a look at the Lydia and Chun-Li json in the meantime.",
              "score": 1,
              "created_utc": "2026-02-24 19:10:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o78pjjc",
          "author": "Grimm-Fandango",
          "text": "This is indeed a nice looking workflow, kudos for that. I checked the sample video on the link, but yeh LTX-2 quality is abysmal. The faces deforms weirdly in that sample, very unrealistic. That's a fault of the model though, not the workflow ofc.",
          "score": 1,
          "created_utc": "2026-02-25 00:47:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ay0st",
              "author": "Toby101125",
              "text": "The Chun-Li prompt has like 3 difference facial expression tokens in it. The Lydia one has far less. What I learned from this is that LTX can be quite expressive.\n\nI'll agree that there are some quality issues. Right now I'm noticing the sound is low qual. But I will take the speed of this workflow over slow, boring, lightning Wan any day.",
              "score": 1,
              "created_utc": "2026-02-25 10:30:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rf73le",
      "title": "üé¨ Big Update for Yedp Action Director: Multi-characters setup+camera animation to render Pose, Depth, Normal, and Canny batches from FBX/GLB/BHV animations files (Mixamo)",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/dr1uw2uiktlg1",
      "author": "shamomylle",
      "created_utc": "2026-02-26 10:52:47",
      "score": 109,
      "num_comments": 10,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1rf73le/big_update_for_yedp_action_director/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7juehs",
          "author": "erogio",
          "text": "That's fantastic!  Any idea if it's possible to go the other direction too? Video to editable skeleton and then export the animation to fbx?  (basically ComfyUI mocap I guess?)",
          "score": 3,
          "created_utc": "2026-02-26 17:42:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7md7ap",
              "author": "shamomylle",
              "text": "Hello! Thanks, that's a great question:\n\nSo there are a couple ways to do it, I haven't tested it yet but Andrea Pozzetti did release a great node for ComfyUI doing just that:\n[ComfyUI-MotionCapture](https://github.com/PozzettiAndrea/ComfyUI-MotionCapture)\n\nOther online solutions exist such as: [Rokoko](https://www.rokoko.com/products/video) and [Deepmotion](https://www.deepmotion.com/)\n\nFinally for another direction also directly inside ComfyUI, you can go the route of prompt-to-3D animation with [HY-MOTION](https://github.com/jtydhr88/ComfyUI-HY-Motion1) which also have an option to save FBX animations compatible with Mixamo.\n\nI hope these will help you :)\n\n\nAs a bonus, (if you want to go experimental!) I designed a suite of nodes for MoCap directly inside ComfyUI, which exports 3D data using mediapipe as a json file, you'd need to go through some process to get some conversion going and redirect that 3D data to a 3D rig.\nOr you can experiment with my MoCap nodes to directly use the output (openpose skeleton), here's the link in case : \n[ComfyUI-Yedp-Mocap](https://github.com/yedp123/ComfyUI-Yedp-Mocap)",
              "score": 2,
              "created_utc": "2026-02-27 01:13:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7mhgxr",
                  "author": "erogio",
                  "text": "Thank you!",
                  "score": 1,
                  "created_utc": "2026-02-27 01:38:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7k8fcf",
          "author": "Mean-Band",
          "text": "WOW, can't wait to try!",
          "score": 2,
          "created_utc": "2026-02-26 18:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lgf69",
          "author": "rabidrooster3",
          "text": "Crazy work dude, looks awesome",
          "score": 2,
          "created_utc": "2026-02-26 22:16:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mg3w5",
              "author": "shamomylle",
              "text": "Thanks for the kind words :)",
              "score": 2,
              "created_utc": "2026-02-27 01:30:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rv8td",
          "author": "IL-MAN",
          "text": "Is this only for video generating models? Does it make sense to use this with SDXL models?",
          "score": 2,
          "created_utc": "2026-02-27 21:37:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7spror",
              "author": "shamomylle",
              "text": "If you mean a single image generation, you could do it with this node I suppose although it would be more of a \"hack\":\nYou'd have to render a sequence of pictures up to the frame you want, go to the output folder (or temp folder if you output preview) and select the frame you need as input for your image generation.\nThe baking process is extremely fast so rendering a sequence shouldn't take you long, that's a valid point though, thanks for bringing it up!",
              "score": 2,
              "created_utc": "2026-02-28 00:25:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ilegn",
          "author": "Fit_Film735",
          "text": "N√£o consigo baixar, pede login e senha do github, por√©m n√£o consigo digitar a senha no terminal, lembrando que eu uso powershel\n\n",
          "score": 0,
          "created_utc": "2026-02-26 14:08:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7imvac",
              "author": "shamomylle",
              "text": "You can also go on the github page and click on the green code button, download zip. Install everything in your comfyUI/custom_nodes/ComfyUI-Yedp-Action-Director folder\nJust remember to put your animations files from mixamo in your input/yedp_anims folder.\nHope that helps!",
              "score": 2,
              "created_utc": "2026-02-26 14:15:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1re9wbr",
      "title": "Workflow to replace 3D characters with people",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/niecxbqp8mlg1.jpeg",
      "author": "Reactive-Robin",
      "created_utc": "2026-02-25 10:41:53",
      "score": 99,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1re9wbr/workflow_to_replace_3d_characters_with_people/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7b6z6f",
          "author": "berlinbaer",
          "text": "comfyui has default templates for a lot of things, that are mostly good enough to perfect. have you tried the default [klein image edit workflow ?](https://i.imgur.com/oFYX6Sh.png)",
          "score": 11,
          "created_utc": "2026-02-25 11:46:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7be6md",
              "author": "Reactive-Robin",
              "text": "I'll give them another look. didn't realise they probably already could what I needed. thanks!",
              "score": 2,
              "created_utc": "2026-02-25 12:38:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7b7cdz",
          "author": "sk4v3n",
          "text": "https://preview.redd.it/y3m5rbr4pmlg1.jpeg?width=1170&format=pjpg&auto=webp&s=c3778bcbfa6f12bb001405cc0b87eafacdcf6cdb\n\ndonno, I used a really simple inpaint workflow with flux2 klein 9b, just draw the mask and make the prompt. the res/sharpness depends on your original resolution, with the mask it will only work on that part of the image anyway and I doubt that those ppl will be huge.\n\nmaybe you should check the basic pixaroma tutorials on youtube and try his workflows first before making something more advanced.",
          "score": 2,
          "created_utc": "2026-02-25 11:49:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7badhk",
              "author": "berlinbaer",
              "text": "you don't even need a mask. i just prompted \"replace the marionette with a woman in blue scrubs\".",
              "score": 10,
              "created_utc": "2026-02-25 12:12:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7bu8qr",
                  "author": "sk4v3n",
                  "text": "Yeah, probably, but if you have a 4k / 6k render with some ppl on it then probably it‚Äôs better to use a mask to be more precise and save some memory. For a small image like this, it doesn‚Äôt matter. \n\nMy final renders are always 4k+ images, so I use masks to target specific areas.",
                  "score": 4,
                  "created_utc": "2026-02-25 14:11:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7viz23",
                  "author": "Sudden_List_2693",
                  "text": "Not only will it be slow, but it will also mess up unwanted details, change minor things it's not supposed to. ",
                  "score": 1,
                  "created_utc": "2026-02-28 13:24:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7cjaxx",
                  "author": "Mid-Pri6170",
                  "text": "we all know the marionette on his local instal is posed very diffferently!\n\n\namirite?",
                  "score": 0,
                  "created_utc": "2026-02-25 16:13:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7bcqpu",
              "author": "Reactive-Robin",
              "text": "maybe I've overcomplictaed the process lol. I'll take a look and try with some simpler workflows and see how it comes out. Thanks!",
              "score": 1,
              "created_utc": "2026-02-25 12:28:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bn80n",
                  "author": "Skipper_Carlos",
                  "text": "If you have a render already just prompt it no need to do anything else. If you want to put people on background that‚Äôs a different story unfortunately.",
                  "score": 1,
                  "created_utc": "2026-02-25 13:33:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7c1xlr",
              "author": "hyxon4",
              "text": "Could you share your workflow?",
              "score": 1,
              "created_utc": "2026-02-25 14:51:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ca56l",
          "author": "Pure-Produce-2428",
          "text": "This is the thing about comfy‚Ä¶ I can do this instantly with nano banan pro. Or even seedance inside comfy. Is the main thing here that you can do this locally and without cost? \n\nSame with a lot of the video inpainting stuff. Kling /Wan/ Beeple etc have amazing video inpainting stuff..but comfy seems so complicated to set up. \n\nMy background is VFX but I don‚Äôt really see the benefit of comfy vs some of the other tools, but that might be because the tutorials I see for comfy video inpainting are absolutely wildly complicated. \n\nI‚Äôm not trying to bash I‚Äôd love resources because I‚Äôd love comfyUI to have better solutions than beeble or Kling Omni etc.",
          "score": 1,
          "created_utc": "2026-02-25 15:31:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bvcvx",
          "author": "Unis_Torvalds",
          "text": "Are there ControlNets for Flux2 or were those only an SD/SDXL thing?",
          "score": 1,
          "created_utc": "2026-02-25 14:17:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cxy1k",
              "author": "novmikvis",
              "text": "Flux 2 (Klein, Dev, Pro, Max etc) all understand Pose, Canny, Depth maps as a native image input, eg. \"Put a person (describing person details) from image 1 to a pose in image 2 (describing pose details in image 2)\" ",
              "score": 3,
              "created_utc": "2026-02-25 17:20:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7dtttk",
                  "author": "Unis_Torvalds",
                  "text": "Sweet thanks",
                  "score": 1,
                  "created_utc": "2026-02-25 19:44:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7c1a9q",
              "author": "FreezaSama",
              "text": "I want this too. Usually flux edit ends up making a mix mess out of the two images :S",
              "score": 2,
              "created_utc": "2026-02-25 14:48:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7c97za",
          "author": "FitPhilosophy3669",
          "text": "\"works but it also changes the surroundings which is not desired\"   \nwhy not add a last step like remove background ? this way you have a mask only for character ",
          "score": 1,
          "created_utc": "2026-02-25 15:26:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cj5lg",
          "author": "Mid-Pri6170",
          "text": "openpose?",
          "score": 1,
          "created_utc": "2026-02-25 16:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ctyc7",
          "author": "austinh1999",
          "text": "A strong openpose control net with the head turned off should get you exactly that",
          "score": 1,
          "created_utc": "2026-02-25 17:01:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lqyua",
          "author": "ZerOne82",
          "text": "https://preview.redd.it/paymim6k7xlg1.jpeg?width=1984&format=pjpg&auto=webp&s=1fb1c44a0b652bb0b96cbccca712cc6e61dc454d\n\nKlein 4B distilled \\*.sft fp8  \nprompt: \"inpaint the red line. replace the figure with a nurse in exact pose. long pants. proper shoes.\"\n\n\\* \"inpaint the red line\" was to remove your red arrow :)",
          "score": 1,
          "created_utc": "2026-02-26 23:10:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rg3hra",
      "title": "Google Colab finally adds modern GPUs! RTX 6000 Pro for $0.87/hr, H100 for $1.86/hr",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1rg3hra/google_colab_finally_adds_modern_gpus_rtx_6000/",
      "author": "1filipis",
      "created_utc": "2026-02-27 10:49:10",
      "score": 97,
      "num_comments": 44,
      "upvote_ratio": 0.95,
      "text": "As the title says, Colab now has RTX 6000 and H100. \n\nRTX 6000 is TWICE as cheap as RunPod. Just in time as I was looking to train some LoRAs\n\nFor me, it's a huge deal. I've been using Colab for quite some time, but its GPU options haven't been updated for like 5 years. A100 and L4 are incredibly slow for today's standards.\n\nAnd obviously there are ready-made notebooks for it as well:\n\n* ComfyUI https://colab.research.google.com/github/ltdrdata/ComfyUI-Manager/blob/main/notebooks/comfyui_colab_with_manager.ipynb\n\n* AI Toolkit https://github.com/ostris/ai-toolkit/blob/main/notebooks/",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/comfyui/comments/1rg3hra/google_colab_finally_adds_modern_gpus_rtx_6000/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o7paaup",
          "author": "riwritingreddit",
          "text": "https://preview.redd.it/j4dzv4u6n1mg1.png?width=558&format=png&auto=webp&s=29a23bdf32fd87e13133eb238e83438560a57167\n\nI can only see H100 is added,there is no RTX6000.",
          "score": 8,
          "created_utc": "2026-02-27 14:02:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pcrgv",
              "author": "1filipis",
              "text": "Right next to it, G4",
              "score": 5,
              "created_utc": "2026-02-27 14:16:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pd11f",
                  "author": "1filipis",
                  "text": "https://preview.redd.it/qgtq2syyp1mg1.png?width=2232&format=png&auto=webp&s=a476eeac64a00eae8e6c713de0e6cc95817ec9cf\n\n",
                  "score": 2,
                  "created_utc": "2026-02-27 14:17:30",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o7pi45z",
                  "author": "riwritingreddit",
                  "text": "Thanks didn't know that.",
                  "score": 2,
                  "created_utc": "2026-02-27 14:44:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ovlz1",
          "author": "biocin",
          "text": "I was just considering buying my own gpu, but this pricing changes the game. Is there a proper tutorial I can follow for this? Is it like I have a virtual machine and I just upload my models there and connect to it with comfyui?",
          "score": 4,
          "created_utc": "2026-02-27 12:33:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ox0kc",
              "author": "1filipis",
              "text": "If you've ever used RunPod, it's essentially the same stuff. You get a Python notebook and a terminal. ComfyUI notebook is the one I use daily\n\nI also lately realized you could set up any AI coder there, and it can set up any repo or environment faster that you could read through its docs",
              "score": 3,
              "created_utc": "2026-02-27 12:43:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7spda3",
                  "author": "lxe",
                  "text": "Isn‚Äôt there a restriction on AI usage?",
                  "score": 1,
                  "created_utc": "2026-02-28 00:22:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pfr74",
              "author": "sitefall",
              "text": "This is not going to be their pricing for long.",
              "score": 2,
              "created_utc": "2026-02-27 14:32:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rp75n",
                  "author": "EdgyUsername_0529",
                  "text": "I've been been using A100's for over a year there, pricing hasn't changed yet. We'll see about these new ones, but so far they've seemed stable.",
                  "score": 1,
                  "created_utc": "2026-02-27 21:06:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7pxdnu",
          "author": "Mirandah333",
          "text": "Maybe a stupid question, but i never used paid Colab. When I am uploading files to the rent space, is it charged or just when i use the GPU?",
          "score": 3,
          "created_utc": "2026-02-27 15:58:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qzt29",
              "author": "scioba1005",
              "text": "It‚Äôs best to pay a few bucks for google drive and link it to your colab (if you want persistent storage). It‚Äôs dirt cheap compared to runpod. Runpod charges me $14 per month for 200 GB. My Google Drive subscription for 200 GB is around ‚Ç¨3 if I pay monthly.\n\nL.E: plus you can always access google drive to clean up files, see your generations or adjust them locally without having the colab running. Which I‚Äôve not been able to do with runpod network storage. Maybe I‚Äôm just too dumb to access it without deploying a pod. Or maybe it is time to go back to google colab‚Ä¶",
              "score": 7,
              "created_utc": "2026-02-27 19:00:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7r21ze",
                  "author": "Mirandah333",
                  "text": "good tip, thanks. I already have a google pro account.",
                  "score": 1,
                  "created_utc": "2026-02-27 19:11:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7qegl9",
              "author": "1filipis",
              "text": "Yes, once you purchase credits, every instance will cost as long as it's running. CPU is just really cheap, something like $0.007/hr",
              "score": 3,
              "created_utc": "2026-02-27 17:19:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qjotp",
                  "author": "Mirandah333",
                  "text": "Cause runpod eats your credits so easily, has to be carefull. Need to test Colab, thanks a lot!",
                  "score": 3,
                  "created_utc": "2026-02-27 17:44:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7r9kux",
                  "author": "ANR2ME",
                  "text": "For CPU-only it's better to use free tier account, you can use it for free for 12 hours per day as i remembered.ü§î\n\nPS: i use multiple free-tier accounts to generate image & video (Wan2.2 A14B Q8) on T4 GPU, and share the same GDrive on all of them, so all the models, output, and workflows are shared. The notebook is shared too, so i can easily switched account.\n\nI also bought a 1TB GDrive for $2 (one-time payment for a lifetime subscription) from a shady seller at local online marketplace üòÖ it's probably an illegally sold organization account, so i won't be using it for any personal files, and also enabled F2A, just in case.\n\nThe notebook i use is a modified version (mainly to use VENV) of that comfyui_colab_with_manager https://gist.github.com/anr2me  \nBut it takes more than 30 minutes to setup everything before i can use the ComfyUI üòÖ since i have a bunch of custom nodes installed and updated automatically when running the notebook. I also update my notebook often, mostly to fix dependency issue after ComfyUI/custom nodes update.",
                  "score": 2,
                  "created_utc": "2026-02-27 19:48:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7q25je",
          "author": "Exply",
          "text": "IS there even a reason to buy a rtx 6000 instead of renting it on runpod or collab at those terms?",
          "score": 3,
          "created_utc": "2026-02-27 16:21:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qxgm6",
              "author": "SwingNinja",
              "text": "NSFW stuff, maybe?",
              "score": 2,
              "created_utc": "2026-02-27 18:49:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7qzb23",
                  "author": "scioba1005",
                  "text": "How does using runpod or colab prevent that? You can do nsfw just as well as anything else.",
                  "score": 3,
                  "created_utc": "2026-02-27 18:57:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qls1f",
          "author": "EdgyUsername_0529",
          "text": "Wasn't seeing the G4/RTX6000 at first when I saw your post, refreshed and sure enough it's there now and let me connect. Gonna see how it performs vs the A100, cost is  basically the same at 8.x units per hour, curious to see if there's much difference in gen times. Quick tests on mage gen in A1111 is always pretty quick but seems faster with this, so i'm definitely hopeful about wan on comfy. \n\nI've been seeing the H100 available for a couple months now, but every time i try to use it, it's not available so kicks me down to another GPU when I try. I keep trying at odd hours, over the weekend etc but same results. I'm guessing it's not just an option since you get bumped to the back of the line unless you're on Colab Pro+ (priority access to more powerful premuim GPU's hell yeah), so I'll upgrade and try. I've been on Pro at $9/mo using pay as you go to buy extra units as I need them, but at this point I'm always buying at least 500 more per month so the upgrade to the $50/mo plan with 600 units included makes sense. I've been using A100 since they became available last year, only thing that made playing with video gen even tolerable for me. Stoked to see what H100 can do, even at double+ the cost.\n\nAnd for those asking the question about rent vs buy; yes i've been saying for a long time that it's better to rent at $.80/hr than spend 5-6K on a gpu that's outdated in a couple years unless you have a solid business case for doing so; as in you're genning professionally for actual money, running 10+ hours a day, can write off your system as a business expense, etc. As a hobby user I usually go through $75-100 worth of units monthly genning a fair amount of \"content\" in my spare time on an A100 at \\~$.80/hr. Where's the breakeven  on that vs buying your own, plus a system that can run it? Yeah sure there's a point where the math makes sense but until genning content is actually what makes you money and genning *more* content makes you *more* money, i just can't see it.",
          "score": 2,
          "created_utc": "2026-02-27 17:54:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qrbuc",
              "author": "1filipis",
              "text": "I'm super happy. Was testing in on LTX today - 1080p x 481 frames in 5 minutes on default workflow. Distilled will probably be close to a minute. \n\nModels load crazy fast.\n\nFlux Klein takes less than a minute in cold start. 4 step gens are almost instant.\n\nAnd obviously LoRA training got 2x cheaper, though 112GB disk space still sucks. It now has more RAM than disk. Doesn't make any sense to me\n\nVery good upgrade and long overdue",
              "score": 1,
              "created_utc": "2026-02-27 18:20:28",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7r1swl",
              "author": "ptwonline",
              "text": "> And for those asking the question about rent vs buy; yes i've been saying for a long time that it's better to rent at $.80/hr than spend 5-6K on a gpu that's outdated in a couple years unless you have a solid business case for doing so;\n\nI suppose buying helps to lock in your cost in case that rented GPU gets a lot more expensive in the future, but yeah generally speaking it seems to make a lot more sense to rent than to buy for a higher end CPU assuming you trust all the security/privacy.\n\nHow are the loading/spin-up times and do you have to pay for them? That is a complaint with some of these services and why I was iniitially interested in ComfyCloud until their actual prices went through the roof.",
              "score": 1,
              "created_utc": "2026-02-27 19:09:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rhk0s",
                  "author": "EdgyUsername_0529",
                  "text": "You do have to pay for loading time, but time/cost probably depends on a few things like if you're using persistent storage vs if you have to DL models every time etc. I run comfy on colab using my google drive, so my models, loras etc are always there. If models have to DL every time that'll change a lot, obviously. Probly depends on the kind of service you're using and if persistent storage is available, cost etc. \n\n  \nMy early comfy configs used to take a long time to load, but after I had to wipe my install at one point and clear out the cruft - all the nodes I was initially experimenting with, all the packages they required, etc, it made a HUGE difference. Blank out the pip install line and only add back in the stuff I need now, and spinup and load that used to take \\~45 minutes from run button to first gen now takes less than 20. Now if I had to do this multiple times per day or something maybe I'd wonder how efficient it is. But doing it once to gen for a couple hours in my spare time, it's not enough to make me sweat at 80 cents an hour. \n\nRising costs would change the math, yeah. The rule still applies though I think. And I haven't seen costs go up on Colab, jsut my desire for more speed. That's all that ends up costing me more. G4 from A100 is a no brainer for me. H100, I really gotta think about. Gonna be awesome to have the option for sure, but at over double the cost. My primary question as always: How many margaritas per month will this cost me?",
                  "score": 1,
                  "created_utc": "2026-02-27 20:28:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ra17t",
              "author": "EdgyUsername_0529",
              "text": "Update 1: G4 notable increase in gen speed over A100 for i2v gen. my usual A100 375-400 sec for wan 2.2 1024x768 81 frames using tripleksampler base/lightning models is now taking \\~195 secs on the G4. Very cool bump for the same cost. Trying the H100 next...",
              "score": 1,
              "created_utc": "2026-02-27 19:50:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ojhkw",
          "author": "Snoo20140",
          "text": "How long would it take to train an LTX or Zimage Lora on one of these?",
          "score": 4,
          "created_utc": "2026-02-27 11:00:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7oldln",
              "author": "1filipis",
              "text": "\"How long\" is a very vague question. RTX 6000 has been the fastest in terms of it/s out of all the GPUs that Nvidia has at the moment. Plus, no offloading whatsoever, it can load the whole model and run at full speed",
              "score": 5,
              "created_utc": "2026-02-27 11:16:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7t4tb5",
          "author": "MrCoolest",
          "text": "Anyone got a good comfyui setup script?",
          "score": 1,
          "created_utc": "2026-02-28 01:56:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7twmbk",
          "author": "AIWaifLover2000",
          "text": "I might have to look into this. That's almost the same price as renting a 5090 on RunPod. ",
          "score": 1,
          "created_utc": "2026-02-28 05:00:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7r342p",
          "author": "LostPrune2143",
          "text": "Per-minute billing helps a lot with this. With hourly billing you end up paying for dead time while tweaking prompts or waiting for downloads.\n\nWe do H100 PCIe at $1.99/hr on [barrack.ai](http://barrack.ai) with per-minute billing, zero egress fees, and no session timeouts. You get SSH access and set up your own ComfyUI environment ‚Äî no notebook limitations.\n\nFull disclosure ‚Äî I'm the founder. Happy to drop some free credits if you want to compare it against Colab. Dm me.",
          "score": 1,
          "created_utc": "2026-02-27 19:16:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7sdkc0",
              "author": "sosawho",
              "text": "Holy fuck at least take the EM dashes out",
              "score": 3,
              "created_utc": "2026-02-27 23:14:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7rial2",
              "author": "EdgyUsername_0529",
              "text": "Ah, good to know, thanks.",
              "score": 1,
              "created_utc": "2026-02-27 20:32:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7trr6s",
              "author": "NowThatsMalarkey",
              "text": "Do you even have B300s available, or this this wishful thinking? üòê\n\nhttps://preview.redd.it/ltj5jy3ax5mg1.jpeg?width=1320&format=pjpg&auto=webp&s=b7207695c9850e18ed56a223df57128c2119a791",
              "score": 1,
              "created_utc": "2026-02-28 04:25:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7w8e05",
                  "author": "LostPrune2143",
                  "text": "B300s are high demand and they come in and out of stock pretty quickly. You'd need to keep an eye on it and grab one when it's up. That screenshot's from our live pricing calculator, not wishful thinking üòÑ\n\nThe reason it's listed even when out of stock is so you can check pricing upfront and spin one up the moment it's available. No surprises on cost, no waiting around to figure out rates.\n\nAs of right now, we have B200 SXM6 180GB, H200 SXM5, and H100 SXM5 available on-demand with per minute billing. If you need bare metal or higher volume with longer commitments, you can contact us!\n\nhttps://preview.redd.it/ajpxmglga9mg1.png?width=1496&format=png&auto=webp&s=6973ee59d114099523deb9301bb9570e6e9b9c65\n\nStock for each fluctuates by the minute. And the models in pic are what we have at the moment of this reply,",
                  "score": 1,
                  "created_utc": "2026-02-28 15:46:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7owzg8",
          "author": "Fit-Pattern-2724",
          "text": "ComfyUI Cloud is pretty cheap too",
          "score": -1,
          "created_utc": "2026-02-27 12:43:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7p0qup",
              "author": "Diabolicor",
              "text": "I don't think comfyui cloud can be used for training",
              "score": 2,
              "created_utc": "2026-02-27 13:07:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rbas2n",
      "title": "Editing Timelapse for 1-Min Short",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/j2h3e8m9qykg1",
      "author": "pftq",
      "created_utc": "2026-02-22 03:10:47",
      "score": 83,
      "num_comments": 9,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1rbas2n/editing_timelapse_for_1min_short/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6qk77c",
          "author": "Technical-Detail-203",
          "text": "Thank you!",
          "score": 3,
          "created_utc": "2026-02-22 07:40:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qaphs",
          "author": "Violent_Walrus",
          "text": "Are you going to post this every day from now on?",
          "score": -7,
          "created_utc": "2026-02-22 06:12:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r0uei",
              "author": "Separate_Height2899",
              "text": "![gif](giphy|wIxBzHWegpOUM)\n\n",
              "score": 1,
              "created_utc": "2026-02-22 10:19:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qcpnv",
          "author": "CATLLM",
          "text": "Seeddance 2.0 just made this obsolete",
          "score": -16,
          "created_utc": "2026-02-22 06:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rh89h",
              "author": "roverowl",
              "text": "Seems like it made your thinking obsolete first",
              "score": 3,
              "created_utc": "2026-02-22 12:44:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wyt6c",
                  "author": "CATLLM",
                  "text": "Bro, go look at the Seedance 2.0 generatoins. The future is knowing how to develop a point of view and taste like art school 101 stuff - not roto and keyframing. ",
                  "score": 1,
                  "created_utc": "2026-02-23 07:24:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rdjvy8",
      "title": "Major open-source release! Flux2-Klein detail enhancement for LoRA",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/mgazfie2sglg1.jpeg",
      "author": "Daniel81528",
      "created_utc": "2026-02-24 15:51:51",
      "score": 79,
      "num_comments": 16,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1rdjvy8/major_opensource_release_flux2klein_detail/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o75qoue",
          "author": "8RETRO8",
          "text": "What's so special about it?",
          "score": 19,
          "created_utc": "2026-02-24 16:19:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77ychk",
              "author": "DigThatData",
              "text": "my impression is that it is more conservative than the default behavior, preserving more of the original image's style, lighting, and color palette, whereas the default effect gravitates more towards realism (at least natural skin tone) and brighter lighting.\n\nhonestly, I kinda wonder if you couldn't get the same effect just using lower CFG or otherwise tweaking knobs that are available w/o adding a LoRA.",
              "score": 3,
              "created_utc": "2026-02-24 22:23:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7cumbv",
              "author": "mnmtai",
              "text": "You really didn't check the tutorial link or the HF or even this post.",
              "score": 0,
              "created_utc": "2026-02-25 17:04:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7666xn",
          "author": "Bananadite",
          "text": "\"major\" 4 likes",
          "score": 14,
          "created_utc": "2026-02-24 17:29:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7623g5",
          "author": "Derispan",
          "text": "Major? So its WAN 3 working on Amiga 500?",
          "score": 9,
          "created_utc": "2026-02-24 17:10:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77knp4",
          "author": "Smile_Clown",
          "text": "lol that title.",
          "score": 5,
          "created_utc": "2026-02-24 21:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o767fzx",
          "author": "Primary_Brain_2595",
          "text": "It made all the images worse, not gonna lie.",
          "score": 11,
          "created_utc": "2026-02-24 17:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77xlc8",
          "author": "DigThatData",
          "text": "FYI: It might be helpful if next time you put the original image in the middle column. It took me a while to figure out what the desired effect of the LoRA was because I kept comparing it against the default output and being like \"that looks like a better image to me\". it makes a lot more sense with the lora effect next to the original image.",
          "score": 2,
          "created_utc": "2026-02-24 22:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75prbx",
          "author": "No-Expression6444",
          "text": "thank you as always, Daniel!",
          "score": 2,
          "created_utc": "2026-02-24 16:15:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76e3oo",
          "author": "Ok-Outside3494",
          "text": "Thank you. It's Flux2Klein9B and not 9B-base?",
          "score": 1,
          "created_utc": "2026-02-24 18:05:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7arnl2",
          "author": "pianogospel",
          "text": "Thanks!!",
          "score": 1,
          "created_utc": "2026-02-25 09:31:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ft038",
          "author": "suspicious_Jackfruit",
          "text": "You should share the full Res examples or some more examples because I can't load civitai on phone and I want to know if my Lora is better :3",
          "score": 1,
          "created_utc": "2026-02-26 01:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hkzws",
          "author": "Current-Row-159",
          "text": "waiting for V2 .. ",
          "score": 1,
          "created_utc": "2026-02-26 09:42:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75vxco",
          "author": "Fit-Pattern-2724",
          "text": "Wow thanks for sharing!",
          "score": 1,
          "created_utc": "2026-02-24 16:43:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76xpse",
          "author": "RepresentativeRude63",
          "text": "for the color correction will try. already satisfied with how pure klein handles transformation.",
          "score": 1,
          "created_utc": "2026-02-24 19:32:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75rxb5",
          "author": "haberdasher42",
          "text": "Will it help make dark, poorly lit or underexposed images? It's hard to add realism when everything is so bright. I'm pretty far from building a LoRA yet but maybe I'll try that as my contribution to the crowd.",
          "score": 0,
          "created_utc": "2026-02-24 16:25:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1resmvu",
      "title": "Qwen Image Edit 2511 Easy Inpainting and Face Replacement Tip!",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1resmvu/qwen_image_edit_2511_easy_inpainting_and_face/",
      "author": "dpacker780",
      "created_utc": "2026-02-25 22:48:45",
      "score": 77,
      "num_comments": 15,
      "upvote_ratio": 0.98,
      "text": "I just found this out, maybe others are aware, but there's a really easy/simple way to do inpainting with Qwen Image Edit, without a complex workflow.  I just stumbled on this last night and will work in many ways to solve basic cases.  You can even do face replacement.\n\nInstead of creating using and creating a mask and a typical inpainting workflow, instead open the mask tool and use the PAINTBRUSH, select a color like RED, and if you have multiple things use different colors.  Then just tell Qwen to \"Replace red area with face from image 2\" or \"Place coffee cup on table in red area\".\n\nSure, if you have more complex needs for masking, blur, etc... then inpainting is the way to go, but this little hack actually solves a lot of basic inpainting type work.   ",
      "is_original_content": false,
      "link_flair_text": "No workflow",
      "permalink": "https://reddit.com/r/comfyui/comments/1resmvu/qwen_image_edit_2511_easy_inpainting_and_face/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o7f1qd9",
          "author": "Maqoba",
          "text": "Thanks for the tip!",
          "score": 6,
          "created_utc": "2026-02-25 23:15:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fafy3",
          "author": "SubstantialYak6572",
          "text": "I only found out how to use the Mask feature in QIE yesterday when someone posted about the Encode Latent Mask node that I had no idea about and I also learned about the Blur Mask node as well. I was wondering what the different colours were for in the mask editor and this post makes it make sense. I had seen someone post previously about adding Magenta padding to an image to expand the size of the image by saying \"Remove the magenta areas and reveal what's underneath\", simple yet effective.\n\nGreat tip for us beginners, thank you for posting.",
          "score": 3,
          "created_utc": "2026-02-26 00:03:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7fef48",
              "author": "madgolin",
              "text": "In flux Klein works too!",
              "score": 3,
              "created_utc": "2026-02-26 00:25:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7fvw2j",
          "author": "NoLlamaDrama15",
          "text": "Love it!\n\nHow do you get the AI to know what image 2 or image 3 is? Is there a way to do this easy in comfyui?",
          "score": 2,
          "created_utc": "2026-02-26 02:03:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7g3s1m",
              "author": "dpacker780",
              "text": "In Qwen Image Edit, you can reference the input images as image 1, image 2, ... You have to have the EditModelReferenceMethod set to index\\_timestep\\_zero.  That node connects to the positive input on the KSampler, so wherever your positive conditioning is coming from to the KSampler that node needs to be there.",
              "score": 5,
              "created_utc": "2026-02-26 02:48:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7isgov",
                  "author": "fabulas_",
                  "text": "Am I the only one who can't get this post to work even after adding this node? I tried changing the face by coloring it red, but I got the same photo as in image 2 with the same clothes instead of just changing the face... so it's as if I hadn't put on any mask... where am I going wrong?",
                  "score": 3,
                  "created_utc": "2026-02-26 14:45:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ifzzu",
                  "author": "polystorm",
                  "text": "No shit! Thanks for sharing that!",
                  "score": 1,
                  "created_utc": "2026-02-26 13:38:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7gn1mw",
          "author": "xb1n0ry",
          "text": "Well, the UNCROP lora does exactly that.\nNo need for fancy workflows.\nCombine it with the consistency lora and you are good to go.",
          "score": 2,
          "created_utc": "2026-02-26 04:48:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7iuqp5",
              "author": "fabulas_",
              "text": "Does UNCROP exist for ‚Äúqwen edit image‚Äù? I couldn't find it... is it really called ‚Äúuncrop‚Äù?",
              "score": 1,
              "created_utc": "2026-02-26 14:56:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7liadv",
                  "author": "xb1n0ry",
                  "text": "[https://civitai.com/models/2106308?modelVersionId=2547946](https://civitai.com/models/2106308?modelVersionId=2547946)",
                  "score": 1,
                  "created_utc": "2026-02-26 22:25:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7lagl0",
              "author": "The_Land_Before",
              "text": "Yes and no. I found with 2511 sometimes without the LoRA it's better to retain the original image. But be free to experiment",
              "score": 1,
              "created_utc": "2026-02-26 21:47:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7exhuy",
          "author": "0BIT_ANUS_ABIT_0NUS",
          "text": "genius‚Ä¶",
          "score": 2,
          "created_utc": "2026-02-25 22:52:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7f9zpn",
          "author": "ynvesoohnka7nn",
          "text": "For those of you who come from 3d applications like 3ds max or blender, there are render passes that can be save out for such instances. I personally use the mtlid pass and have different materials set to different id's and max and vray give me perfect matching masks of different colors as a separate render pass.",
          "score": 1,
          "created_utc": "2026-02-26 00:00:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7iol23",
          "author": "fabulas_",
          "text": "u/dpacker780 Hello, I have been waiting for a long time to find a solution for impanting that works. I tried it immediately, but it did not work. I have sent you a private message. Please check your message requests if you would like to help me understand where I am going wrong. Thank you.",
          "score": 1,
          "created_utc": "2026-02-26 14:24:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rffv3o",
      "title": "Some more Insta with Zimage turbo",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1rffv3o",
      "author": "Suspicious-Peak5436",
      "created_utc": "2026-02-26 17:07:22",
      "score": 77,
      "num_comments": 23,
      "upvote_ratio": 0.72,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1rffv3o/some_more_insta_with_zimage_turbo/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7qjcpn",
          "author": "littlegreenfish",
          "text": "All the subjects that are meant to look Indian, look European. ",
          "score": 3,
          "created_utc": "2026-02-27 17:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7k2atl",
          "author": "oodelay",
          "text": "It's crazy how people generate a few images of women and they think they are \"artists\". You are basically showing us what you like to goon on. No other images, no other subjects. \n\nAnd then the boys come here and say \"ohhh such grace\", \"a true work of art\"... \n\nIts waifus. \n\nYou showed us your waifus.",
          "score": -8,
          "created_utc": "2026-02-26 18:18:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7k93vt",
              "author": "obj-g",
              "text": "sorry, are we on r/artists or something? he said \"here are some pics I generated\" -- not seeing the claims or artistry or whatever. so butthurt, lol",
              "score": 13,
              "created_utc": "2026-02-26 18:49:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7kb72h",
                  "author": "oodelay",
                  "text": "You sure got me there. Kudos to you! \n\nSoooo... You like to look at other people's mastubatory material? Doesn't sound strange at all.",
                  "score": -16,
                  "created_utc": "2026-02-26 18:58:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7n5rui",
              "author": "Upper-Reflection7997",
              "text": "You forgot that heterosexual sexual males exists? What wrong with generating images of beautiful women?",
              "score": 2,
              "created_utc": "2026-02-27 04:03:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7mqoze",
              "author": "roverowl",
              "text": "Post nut clarity?",
              "score": 1,
              "created_utc": "2026-02-27 02:32:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lpeml",
          "author": "MahaVakyas001",
          "text": "very nice. what are some of the LoRA you are using for the sarees?",
          "score": 0,
          "created_utc": "2026-02-26 23:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n4xqy",
              "author": "Suspicious-Peak5436",
              "text": "Hi thanks, I don't use any specific loras for saree, zimage and klein are pretty good at doing that. The loras which I mostly use are mentioned in my WF.",
              "score": -1,
              "created_utc": "2026-02-27 03:57:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7n078y",
          "author": "Cultural_Bat9098",
          "text": "Awesome thanks.",
          "score": 0,
          "created_utc": "2026-02-27 03:28:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7n0i60",
          "author": "Cultural_Bat9098",
          "text": "OP could you please share some prompts that you used with your workflow?",
          "score": 0,
          "created_utc": "2026-02-27 03:30:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n4mim",
              "author": "Suspicious-Peak5436",
              "text": "I use chatgpt for prompts, just feed in the image u like and ask it to generate prompt from that. Then u can experiment from there using different samplers. Euler with beta57, res multistep with beta57 and res2s with bong tangent r my favourite. The aspect ratio also matters.",
              "score": 1,
              "created_utc": "2026-02-27 03:55:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7nfne3",
                  "author": "Cultural_Bat9098",
                  "text": "Cool .. thanks.",
                  "score": -1,
                  "created_utc": "2026-02-27 05:10:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7jvzuk",
          "author": "EstablishmentIll7156",
          "text": "Prompt for image 8!!?. The background detail here is insane. Want to know the technique/workflow used to get everything so sharp?",
          "score": -2,
          "created_utc": "2026-02-26 17:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ltjd4",
          "author": "superstarbootlegs",
          "text": "I'm finding the 2 sampler method with a latent upscaler in the middle really good just with zimage. fast too. then seedvr2.5 to push it to 4K. also fast. even on a 3060 RTX 12 GB VRAM.",
          "score": 0,
          "created_utc": "2026-02-26 23:24:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lno06",
          "author": "tzn001",
          "text": "What is your HW for these generations?",
          "score": -1,
          "created_utc": "2026-02-26 22:52:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lp6vo",
              "author": "abnormal_human",
              "text": "ZIT is pretty resource light..it works on most consumer GPUs without contortions.",
              "score": 1,
              "created_utc": "2026-02-26 23:00:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7n4wsc",
          "author": "aar550",
          "text": "Is there a way to use a different single image face of someone ? Without using a character Lora?",
          "score": -1,
          "created_utc": "2026-02-27 03:57:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n5ibc",
              "author": "Suspicious-Peak5436",
              "text": "Yes, I think best way to do that is use qwen image edit 2511, klein tends to change faces, whereas qwen can keep them consistent if prompted correctly. YouTube will definitely help u.",
              "score": 0,
              "created_utc": "2026-02-27 04:01:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1reo13i",
      "title": "[Release] ComfyUI-CADabra -> CAD loading, meshing & surface reconstruction nodes  (OCC + GMSH)",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/dq9jmzl64plg1",
      "author": "ant_drinker",
      "created_utc": "2026-02-25 19:58:44",
      "score": 63,
      "num_comments": 0,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/comfyui/comments/1reo13i/release_comfyuicadabra_cad_loading_meshing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rc0t06",
      "title": "I fixed up the last workflow I shared you can make lots of next scene or pose your character\\load the pic you made+new character\\pose them together",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1rc0t06",
      "author": "o0ANARKY0o",
      "created_utc": "2026-02-22 23:11:25",
      "score": 63,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1rc0t06/i_fixed_up_the_last_workflow_i_shared_you_can/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6uz156",
          "author": "PastorNTraining",
          "text": "This is cool OP, looking at this workflow I can‚Äôt help but think of much time this would save a Indie game studio.\n\nThis could be used to prototype a scene, cinematic or character designs.  For Mattel, creating or prototyping a figure, this would be a great way to gather feedback or create a whole series of looks. Hell I bet even a great sketch by a designer could be used to build a model with this flow.\n\nI bet you could prototype an entire series over the weekend and be ready to pitch it by Monday morning.\n\nExcellent work, friend.",
          "score": 4,
          "created_utc": "2026-02-22 23:21:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wrpcl",
          "author": "zthrx",
          "text": "Would it be able to load DAZ poses? ",
          "score": 2,
          "created_utc": "2026-02-23 06:20:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x1tg2",
              "author": "o0ANARKY0o",
              "text": "I have no idea",
              "score": 1,
              "created_utc": "2026-02-23 07:53:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wzav1",
          "author": "prepperdrone",
          "text": "Is there some way to turn off the muscle/fat mesh?  I tried using this, but it wanted to make my original character fit the body mesh.  I really just want the pose.  yeah, I mean, I guess you could adjust every little parameter to match the mesh to your original character, but that'd take forever.  ",
          "score": 2,
          "created_utc": "2026-02-23 07:29:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x4f1q",
              "author": "o0ANARKY0o",
              "text": "Body mesh would only effect it if you had it on depth map",
              "score": 1,
              "created_utc": "2026-02-23 08:18:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xdh4d",
          "author": "Ok-Option-6683",
          "text": "I tried the previous one yesterday both with Klein and 2511. It works really good. I'll try this one tonight. Thanks for sharing it!",
          "score": 2,
          "created_utc": "2026-02-23 09:48:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xipf5",
              "author": "o0ANARKY0o",
              "text": "This one is gunna go under the radar but wait till you try it! You can just edit your 4k pics in 2k if nothing else, you can disconnect the pose studio node and hook up another load image an place two people in one background, if you load a background image into the pose studio node and it has another character in you'll get there pose aswell as the character you pose, and more",
              "score": 1,
              "created_utc": "2026-02-23 10:37:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yibm2",
          "author": "GarudoGAI",
          "text": "Is it possible to pose two characters simultaneously with this?",
          "score": 2,
          "created_utc": "2026-02-23 14:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ym3px",
              "author": "o0ANARKY0o",
              "text": "Not simultaneously, pose one load that Pic and the other character then pose and prompt, also and separately if you use the background picture in the pose studio node and it has another character in it you will have their control map aswell.",
              "score": 1,
              "created_utc": "2026-02-23 15:03:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zcqxd",
          "author": "kakallukyam",
          "text": "It looks quite interesting but complicated for beginners, which is a shame. Could we hope for a short tutorial?",
          "score": 2,
          "created_utc": "2026-02-23 17:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zmaof",
              "author": "o0ANARKY0o",
              "text": "I posted some pictures to show some of the things it can do. you can disconnect the aio node and plug a load image node instead, you can bypass the image 2 and 3 slots and just edit your images, you can prompt like below to get alot of next scenes of you character in similar environments or the same doing whatever you want\n\nnext scene: short prompt\n\nnext scene: short prompt\n\nnext scene: short prompt\n\n(no spaces between the drop down lines tho)",
              "score": 1,
              "created_utc": "2026-02-23 17:54:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o703ynp",
                  "author": "kakallukyam",
                  "text": "Thanks for your help, but I'm really a beginner and I'm trying to get by with simpler workflows at first, and it's already not easy, but I'll keep yours aside for later, when I'm a little more skilled with all this.",
                  "score": 3,
                  "created_utc": "2026-02-23 19:14:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6v6zlw",
          "author": "o0ANARKY0o",
          "text": "https://preview.redd.it/kf3czomhy4lg1.png?width=3840&format=png&auto=webp&s=da642765f420ee71981828ec5006b350067c42ec\n\n",
          "score": 1,
          "created_utc": "2026-02-23 00:06:28",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6vbknl",
          "author": "o0ANARKY0o",
          "text": "https://preview.redd.it/29ryiwk435lg1.png?width=3840&format=png&auto=webp&s=163526e67db20cc8bb996f26f52e3b51a2bbf642\n\n",
          "score": 1,
          "created_utc": "2026-02-23 00:32:28",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6wuo0d",
          "author": "fiojoy",
          "text": "PoseNextScene.json has 9.52 MB ???",
          "score": 1,
          "created_utc": "2026-02-23 06:46:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x25eo",
              "author": "o0ANARKY0o",
              "text": "Is that not normal? I just exported the workflow and uploaded to Google drive.",
              "score": 2,
              "created_utc": "2026-02-23 07:56:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6x5ar8",
                  "author": "fiojoy",
                  "text": "RTX 3090 + i9-12900KF + 128GB RAM (DDR4, 3200MT/s) ‚Äì Will this setup run the PoseNextScene.json workflow perfectly?",
                  "score": 2,
                  "created_utc": "2026-02-23 08:26:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rca60d",
      "title": "Is there any other place in the world we can put these useless messages?",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/8p22o722w6lg1.png",
      "author": "EroticManga",
      "created_utc": "2026-02-23 06:37:34",
      "score": 60,
      "num_comments": 17,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1rca60d/is_there_any_other_place_in_the_world_we_can_put/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6xu8vv",
          "author": "bymyself___",
          "text": "Will add a \"clear all error toasts\" button, appreciate the feedback, that definitely is an annoying experience.",
          "score": 28,
          "created_utc": "2026-02-23 12:17:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ywwmw",
              "author": "MrChurch2015",
              "text": "Y'all should have stackable toasts, like, if you have more than one of the same, it just shows a little counter and then at that point you can choose to ignore that particular warning/error until next ui reboot. Or maybe that coupled with putting notifications in their own panel.",
              "score": 5,
              "created_utc": "2026-02-23 15:55:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o70hcwt",
              "author": "cosmicr",
              "text": "It's more so that they appear on top of pretty much the most important ui section people use.",
              "score": 3,
              "created_utc": "2026-02-23 20:17:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o70qbbt",
              "author": "suspicious_Jackfruit",
              "text": "Yeah, that's great but I think they need to stack or simply be hidden somewhere because this error is the only one I get and in the nicest way possible it is bordering on useless information and taking up screen space. What asset gaddamnit? And why do I need to know about it every time I open the render queue!? It's not an asset im trying to interact with nor am using in my workflow so it's usefulness is limited.\n\nAlso (and probably the actual cause of the toasts) why does the assets side nav open any time I interact/view a previous image from the queue history? I would prefer the two separate, recent 100 generations in history is a comfyUI staple!",
              "score": 3,
              "created_utc": "2026-02-23 21:00:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xir6r",
          "author": "Elvarien2",
          "text": "I think you should find that asset.",
          "score": 13,
          "created_utc": "2026-02-23 10:38:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xjlaa",
              "author": "OcelotUseful",
              "text": "But what if ASSET WOULD NOT BE FOUND IN MEDIA ASSETS PANEL?",
              "score": 11,
              "created_utc": "2026-02-23 10:46:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6xjrje",
                  "author": "Elvarien2",
                  "text": "I think you set it on fire.",
                  "score": 5,
                  "created_utc": "2026-02-23 10:47:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zabug",
          "author": "3deal",
          "text": "i hate that new UX, why are they hiring people who have no experience in UX design?",
          "score": 4,
          "created_utc": "2026-02-23 16:58:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x41hq",
          "author": "EroticManga",
          "text": "ASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL\n\nASSET NOT FOUND IN THE MEDIA ASSETS PANEL",
          "score": 13,
          "created_utc": "2026-02-23 08:14:20",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6xhmm7",
              "author": "HellkerN",
              "text": "Hello friend, I'm not sure if you have noticed that ASSET NOT FOUND IN THE MEDIA ASSETS PANEL",
              "score": 8,
              "created_utc": "2026-02-23 10:27:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yv7sb",
          "author": "MrChurch2015",
          "text": "Oh hey, just so you know...ASSET NOT FOUND IN THE MEDIA ASSETS PANEL",
          "score": 2,
          "created_utc": "2026-02-23 15:48:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xpjf6",
          "author": "ZerOne82",
          "text": "https://preview.redd.it/xx3sdkd1d8lg1.jpeg?width=354&format=pjpg&auto=webp&s=3c41f721c155bdc2c5ebd86aff8668fa491c1c5e\n\nThere are so many other concerning issues in ComfyUI ecosystem not just in UI part that are being neglected, because they can. Look at the flood of folders of ComfyUI in site-package of python installation, all of these could be a single package, a single folder. This non-standard odd naive unprofessional childish tendency is annoying and is seen in structure, naming, UI  and etc.  \nFor comparison ComfyUI entire code base is much smaller than Pytorch, Numpy, PyQT and any of standard professional code bases which are a single package and a single folder.",
          "score": -5,
          "created_utc": "2026-02-23 11:39:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xqo8i",
              "author": "ZerOne82",
              "text": "This issue originates from the recent reality where programmers are no longer a life long developer with years of hard practice, experience and following strict rules but a yesterday someone who all of a sudden became a self-titled code developer. This situation will worsen as it goes. AI assistance won't help when there is no internal understanding of ethic of coding and rules of publishing.",
              "score": 0,
              "created_utc": "2026-02-23 11:49:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6xr8yy",
                  "author": "addandsubtract",
                  "text": "Comfy existed before LLMs were able to code, though. The issue is more likely feature creep and trying to incorporate and please everyone.",
                  "score": 4,
                  "created_utc": "2026-02-23 11:53:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ynut4",
              "author": "HSLB66",
              "text": "So believe it or not but it‚Äôs a free program you don‚Äôt have to use",
              "score": 0,
              "created_utc": "2026-02-23 15:12:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6yy4st",
                  "author": "MrChurch2015",
                  "text": "That does not mean they don't need to clean stuff up and make it more optimized or fix long running issues. The issue is is that it can become unusable in and of itself",
                  "score": 1,
                  "created_utc": "2026-02-23 16:01:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rffl1m",
      "title": "Help needed with SAM3 Video Masking - Final output is just a solid green screen! (8GB VRAM setup)",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1rffl1m/help_needed_with_sam3_video_masking_final_output/",
      "author": "Necessary_Piglet_354",
      "created_utc": "2026-02-26 16:57:35",
      "score": 57,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "I'm trying to create a green screen effect from a 1080p 60fps video using the **ComfyUI-SAM3** nodes (PozzettiAndrea's version). Since I'm working with a strict **8GB VRAM** limit, I'm downscaling the frames to 856x480 (or 864x480) and processing them in small batches (`frame_load_cap` = 16) to avoid OOM errors.\n\nHere is my current workflow (screenshots attached):\n\n1. **VHS Load Video**: Downscaling the video and limiting the frame count. (I selected 'AnimateDiff' format here just to force the custom width/height options to appear).\n2. **Image Resize**: Making sure the frames are exactly 856x480 before feeding them to SAM3.\n3. **SAM3 Pipeline**: `SAM3 Video Segmentation` (text prompt: \"person\") -> `SAM3 Propagate` \\-> `SAM3 Video Output`.\n4. **Compositing**: I used an `Image Composite Masked` node.\n   * Destination: A solid green image (856x480).\n   * Image (Source): The resized original video frames.\n   * Mask: The `masks` output from SAM3 Video Output.\n\n**The Problem:** My final output from the `Video Combine` node is just a completely 100% solid green screen. The masked person is not showing up at all.\n\nIt seems like either SAM3 is outputting a completely blank/black mask, or my composite node is set up wrong. I've checked the connections multiple times.\n\nDoes anyone see what I'm doing wrong in the attached screenshots? Any advice for a low-VRAM SAM3 setup would be hugely appreciated! Thanks!\n\nhttps://preview.redd.it/p5zki8wgdvlg1.jpg?width=1610&format=pjpg&auto=webp&s=1cd742c02fb488affc6fe434ea3b91ba0004a288\n\n",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1rffl1m/help_needed_with_sam3_video_masking_final_output/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o7jorc7",
          "author": "TheDailySpank",
          "text": "Mask-to-image the SAM mask and see what it looks like by itself then go from there.",
          "score": 2,
          "created_utc": "2026-02-26 17:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mj57h",
          "author": "roverowl",
          "text": "My advice is dont use SAM3 and search for combination between SAM2 and Matanyone node",
          "score": 0,
          "created_utc": "2026-02-27 01:48:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcrmnu",
      "title": "Civitai alternatives?",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1rcrmnu/civitai_alternatives/",
      "author": "laniepartyxo",
      "created_utc": "2026-02-23 19:42:51",
      "score": 53,
      "num_comments": 35,
      "upvote_ratio": 0.82,
      "text": "Now that civitai seems to have much less nsfw resources have any decent alternatives come along?",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1rcrmnu/civitai_alternatives/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o70loe5",
          "author": "CaptSpalding",
          "text": "Last week someone posted up that they had create a nsfw alternative to civitai called  rawdiffusion.com \nI haven't tried it so YMMV.",
          "score": 34,
          "created_utc": "2026-02-23 20:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74znhi",
              "author": "siegekeebsofficial",
              "text": "oh no, sarah peterson learned about it... ruined",
              "score": 12,
              "created_utc": "2026-02-24 14:10:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o71rrr3",
              "author": "Killovicz",
              "text": "It's still up and look more and more promising. However it's way more likely than not that it'll get shut down :(. So hurry and download all you can while you still can..",
              "score": 3,
              "created_utc": "2026-02-24 00:16:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76aggp",
                  "author": "WalkAffectionate2683",
                  "text": "The website looks kinda empty or it's just me? Most tabs are empty¬†",
                  "score": 3,
                  "created_utc": "2026-02-24 17:48:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o74pdzg",
                  "author": "deadsoulinside",
                  "text": "Yeah, going live, then looking into how to block users from making CSAM material, was kind of shocking to say the least.",
                  "score": 1,
                  "created_utc": "2026-02-24 13:13:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o73p838",
              "author": "blkhawk",
              "text": "The amount of Illustrious Loras on there really surprised me./s",
              "score": 1,
              "created_utc": "2026-02-24 08:12:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o71tlsj",
          "author": "MrChurch2015",
          "text": "Not seeing nsfw content is probably your settings. They have more nsfw than you know what to do with",
          "score": 27,
          "created_utc": "2026-02-24 00:26:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o71x3zr",
              "author": "ooopspagett",
              "text": "Yea it's basically a porn site for me. Maybe that says more about my activity on the site than the site itself. Still, I do have some sort of morbid curiosity about how much wilder it gets, and what exactly the models on civ archive did to get thrown off",
              "score": 13,
              "created_utc": "2026-02-24 00:46:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o73ulyk",
                  "author": "gabrielconroy",
                  "text": "I think most of the ones that got removed were celebrity loras, edit loras to remove clothes (which could be used for deepfake stuff), stuff like that.",
                  "score": 2,
                  "created_utc": "2026-02-24 09:04:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o725jml",
              "author": "ToronoYYZ",
              "text": "Some of the things on there are highly disturbing sometimes.",
              "score": 3,
              "created_utc": "2026-02-24 01:35:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o75yepv",
              "author": "Jesus__Skywalker",
              "text": "there has not been much added for wan 2.2 lately, certainly nowhere near what it was before.",
              "score": 1,
              "created_utc": "2026-02-24 16:54:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o70pnu1",
          "author": "kakallukyam",
          "text": "There is also \"civarchive.com\"",
          "score": 20,
          "created_utc": "2026-02-23 20:57:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o71xeve",
              "author": "ooopspagett",
              "text": "I see mostly the same stuff on the archive that I do on the main. What should I be looking for to see the really depraved shit that got it thrown off Civitai? I'm not asking for a friend, I really wanna know",
              "score": 8,
              "created_utc": "2026-02-24 00:47:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o720ci7",
                  "author": "Choice_Celery9481",
                  "text": "the archive has filter for deleted stuffs. just turn the filter on.",
                  "score": 8,
                  "created_utc": "2026-02-24 01:04:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o71czdx",
          "author": "pfn0",
          "text": "I'm confused, I open up civitai and I am flooded with so many nsfw loras that I have no idea what to even use.",
          "score": 16,
          "created_utc": "2026-02-23 22:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74olwa",
              "author": "Desperate_News_5116",
              "text": "I'm confused like you, I also enter civitai and there is so much nfsw that I have to check that no one sees my screen.",
              "score": 1,
              "created_utc": "2026-02-24 13:08:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o75u3ig",
              "author": "alberist",
              "text": "Mostly stuff that should be removed. Celebrity stuff and loras made specifically for turning SFW images into porn. Though there are also some niche bodily fluid fetishes that get removed. Vomit, pee, etc. Not trying to kinkshame if that's the case.",
              "score": 0,
              "created_utc": "2026-02-24 16:34:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o70s8k8",
          "author": "gladias9",
          "text": "seaart is decent, you can actually download celeb and public figure loras there",
          "score": 4,
          "created_utc": "2026-02-23 21:11:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73ryrc",
          "author": "Mid-Pri6170",
          "text": "civarchive",
          "score": 2,
          "created_utc": "2026-02-24 08:39:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74tzj6",
          "author": "Nkt_31",
          "text": "wait are you actually using civitai for generation or just grabbing models? if youre running stuff locally nothing changed, if you need a platform with fewer filters then Mage Space lets you toggle mature mode but yeah for downloading models civitai is still fine despite the drama",
          "score": 2,
          "created_utc": "2026-02-24 13:39:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76kcjg",
          "author": "Select_Custard_4116",
          "text": "Yorespot check it out first you'll never look anywhere else again",
          "score": 0,
          "created_utc": "2026-02-24 18:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o791pen",
          "author": "MagicitePower",
          "text": "honestly, best resource for uncensored is DarLink AI... super deep chat/rp and excellent image/video gen...",
          "score": 0,
          "created_utc": "2026-02-25 01:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79jnmb",
          "author": "kriper1412",
          "text": "for uncensored stuff (image+video),DarLink AI is easy #1 in 2026...",
          "score": -1,
          "created_utc": "2026-02-25 03:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75zj34",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -6,
          "created_utc": "2026-02-24 16:59:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76d4z1",
              "author": "OkBill2025",
              "text": "jajajaja",
              "score": 1,
              "created_utc": "2026-02-24 18:00:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76hlbz",
                  "author": "Robertkr1986",
                  "text": "Um ok",
                  "score": 1,
                  "created_utc": "2026-02-24 18:20:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rc4ves",
      "title": "I let my kids ‚Äúdirect‚Äù an AI commercial",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/nhn9q6ahk5lg1",
      "author": "desublimate",
      "created_utc": "2026-02-23 02:09:43",
      "score": 52,
      "num_comments": 5,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1rc4ves/i_let_my_kids_direct_an_ai_commercial/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6vyyep",
          "author": "ThePoetPyronius",
          "text": "I love it because it's made of bread, cheese, lettuce, patty and more bread. Take my money.",
          "score": 7,
          "created_utc": "2026-02-23 02:52:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yagnv",
              "author": "desublimate",
              "text": "It‚Äôs what cats crave!",
              "score": 4,
              "created_utc": "2026-02-23 14:00:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6za0zn",
          "author": "Nokita_is_Back",
          "text": "Cool. I'll give it a go with mine. What models and workflows did you use?",
          "score": 3,
          "created_utc": "2026-02-23 16:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72ai97",
              "author": "desublimate",
              "text": "Grok reference image to turn their drawings into fully colored illustrations, some photoshop cleanup and then Vidu q3 to animate shots, kept it 720p and no more then 5 seconds per shot/shots‚Ä¶ 5070TI would spit em out in about 1-2 min. Then we cut the shots together in premiere‚Ä¶ ü§∑üèª‚Äç‚ôÇÔ∏è",
              "score": 1,
              "created_utc": "2026-02-24 02:03:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o711p5m",
          "author": "TanguayX",
          "text": "Ship it. No notes!",
          "score": 3,
          "created_utc": "2026-02-23 21:56:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rf7byp",
      "title": "LTX-2 Mastering Guide: Pro Video & Audio Sync",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1rf7byp/ltx2_mastering_guide_pro_video_audio_sync/",
      "author": "Aliya_Rassian37",
      "created_utc": "2026-02-26 11:06:19",
      "score": 50,
      "num_comments": 8,
      "upvote_ratio": 0.96,
      "text": "I‚Äôve been doing some serious research and testing over the past few weeks, and I‚Äôve finally distilled the \"chaos\" into a repeatable strategy.\n\nWhether you‚Äôre a filmmaker or just messing around with digital art, understanding how LTX-2 handles motion and timing is key. I've put together this guide based on my findings‚Äîcovering everything from 5s micro-shots to full 20s mini-narratives. Here‚Äôs what I‚Äôve learned.\n\n**Core Principles of LTX-2**\n\nThe core idea behind LTX-2 prompting is simple but crucial: you need to describe a complete, natural, start-to-finish visual story. It‚Äôs not about listing visual elements. It‚Äôs about describing a continuous event that unfolds over time.\n\nThink of your prompt like a mini screenplay. Every action should flow naturally into the next. Every camera movement should have intention. Every element should serve the overall pacing and narrative rhythm.\n\nLTX-2 reads prompts the way a cinematographer reads a director‚Äôs notes. It responds best to descriptions that clearly define:\n\n* Camera movement: how the camera moves, what it focuses on, how the framing evolves\n* Temporal flow: the order of actions and their pacing\n* Atmospheric detail: lighting, color, texture, and emotional tone\n* Physical precision: accurate descriptions of motion, gestures, and spatial relationships\n\nWhen you approach prompts this way, you‚Äôre not just generating a clip. You‚Äôre directing a scene.\n\n**Core Elements**\n\n**Shot Setup-Start by defining the opening framing and camera position using cinematic language that fits the genre.**\n\n**Examples**\n\nA high altitude wide aerial shot of a plane\n\nAn extreme close up of the wing details\n\nA top down view of a city at night\n\nA low angle shot looking up at a rocket launch\n\n**Pro tip**\n\nMatch your camera language to the style. Documentary scenes work well with handheld descriptions and subtle shake. More cinematic scenes benefit from smooth movements like a slow dolly push or a controlled crane lift.\n\n**Scene Design-When describing the environment, focus on lighting, color palette, texture, and overall atmosphere.**\n\n**Key elements**\n\n**Lighting**\n\nPolar cold white light\n\nNeon gradient glow\n\nHarsh desert noon sunlight\n\n**Color palette**\n\nCyberpunk purple and teal contrast\n\nEarthy ochre and deep moss green\n\nHigh contrast black and white\n\n**Atmosphere**\n\nTurbulent clouds at high altitude\n\nCold mist beneath the aurora\n\nDiffused light within a sandstorm\n\n**Texture**\n\nMatte metal shell\n\nFrozen lake surface\n\nRough volcanic rock\n\n**Example**\n\nA futuristic airport in heavy rain. Cold blue ground lights trace the runway. Lightning tears across the edges of dark storm clouds. The surface reflects like wet carbon fiber under the storm.\n\n**Action Description-Use present tense verbs and describe actions in a clear sequence.**\n\n**Best practices**\n\n**Use present tense**\n\nTakes off, dives, unfolds, rotates\n\n**Write actions in order**\n\nThe aircraft gains altitude, breaks through the clouds, and stabilizes into level flight\n\n**Add subtle detail**\n\nThe tail fin makes slight directional adjustments\n\n**Show cause and effect**\n\nThe cabin door opens and a rush of air bursts inward\n\n**Weak example**\n\nThe pilot is calm\n\n**Strong example**\n\nThe pilot‚Äôs gaze stays locked forward. His fingers make steady adjustments on the control stick. He leans slightly into the motion, maintaining control through the turbulence.\n\n**Character Design-Define characters through appearance, wardrobe, posture, and physical detail. Let emotion show through action.**\n\n**Appearance**\n\nA man in his twenties with short, sharp hair\n\n**Clothing**\n\nAn orange flight suit with windproof goggles\n\n**Posture**\n\nUpright stance, focused eyes\n\n**Emotion through action**\n\nBack straight, gestures controlled and deliberate\n\n**Tip**\n\nAvoid abstract words like nervous or confident. Instead of saying he is nervous, write his palms are slightly damp, his fingers tighten briefly, his breathing slows as he steadies himself.\n\n**Camera Movement-Be specific about how the camera moves, when it moves, and what effect it creates.**\n\n**Common movements**\n\n**Static**\n\nTripod locked off, frame completely stable\n\n**Pan**\n\nSlowly pans right following the aircraft\n\nQuick sweep across the skyline\n\n**Tilt**\n\nTilts upward toward the stars\n\nTilts down to the runway\n\n**Push¬†and pull**\n\nPushes forward tracking the aircraft\n\nGradually pulls back to reveal the full landscape\n\n**Tracking**\n\nMoves alongside from the side\n\nFollows closely from behind\n\n**Crane¬†and vertical movement**\n\nRises to reveal the entire area\n\nDescends slowly from high above\n\n**Advanced tip**\n\nTie camera movement directly to the action. As the aircraft dives, the camera tracks with it. At the moment it pulls up, the camera stabilizes and hovers in place.\n\n**Audio Description-Clearly define environmental sounds, sound effects, music, dialogue, and vocal characteristics.**\n\n**Audio elements**\n\n**Ambient sound**\n\nEngine roar\n\nWind rushing past\n\nRadar beeping\n\n**Sound effects**\n\nMechanical clank as the landing gear deploys\n\nA sharp burst as the aircraft breaks through clouds\n\n**Music**\n\nEpic orchestral score\n\nCold minimal electronic tones\n\nTense atmospheric drones\n\n**Dialogue**\n\nUse quotation marks for spoken lines\n\nRequesting takeoff clearance, he reports calmly\n\n**Example**\n\nThe roar of the engines fills the airspace. Clear instructions come through the radio. ‚ÄúWe‚Äôve reached the designated altitude.‚Äù The pilot reports in a steady, controlled voice.\n\n# Prompt Practice\n\n# Single Paragraph Continuous Description\n\nStructure your prompt as one smooth, flowing paragraph. Avoid line breaks, bullet points, or fragmented phrases. This helps LTX-2 better understand temporal continuity and how the scene unfolds over time.\n\n**Weak structure**\n\n¬†¬†Desert explorer\n\n¬†¬†Noon\n\n¬†¬†Heat waves\n\n¬†¬†Walking steadily\n\n**Stronger structure**\n\nA lone explorer walks through the scorching desert at noon, heat waves rippling across the sand as his boots press into the ground with a soft crunch. The camera follows steadily from behind and slightly to the side, capturing the rhythm of each step. A metal canteen swings gently at his waist, catching and reflecting the harsh sunlight. In the distance, a mirage flickers along the horizon, wavering in the rising heat as he continues forward without slowing down.\n\n# Use Present Tense Verbs\n\nDescribe every action in present tense to clearly convey motion and the passage of time. Present tense keeps the scene alive and unfolding in real time.\n\n**Good examples**\n\nTrekking\n\nEvaporating\n\nFlickering\n\nAscending\n\nAvoid\n\nTreked\n\nIs evaporating\n\nHas flickered\n\nWill ascend\n\n# Be Direct About Camera Behavior\n\nAlways specify the camera‚Äôs position, angle, movement, and speed. Don‚Äôt assume the model will infer how the scene is framed.\n\n**VagueÔºö**¬†A man in the desert\n\n**ClearÔºö**¬†The camera begins with a low angle shot looking up as a man stands on top of a sand dune, gazing into the distance. The camera slowly pushes forward, focusing on strands of hair blown loose by the wind. His silhouette shimmers slightly through the rising heat waves.\n\n# Use Precise Physical Detail\n\nSmall, measurable movements and specific gestures make interactions feel real.\n\n**GenericÔºö**¬†He looks exhausted\n\n**PreciseÔºö**¬†His shoulders drop slightly, his knees bend just a little, and his breathing turns shallow and uneven. With each step, he reaches out to brace himself against the rock wall before continuing forward.\n\n# Build Atmosphere Through Sensory Detail\n\nUse lighting, sound, texture, and environmental cues to shape mood.\n\n**Lighting examplesÔºö**\n\n* Cold neon tubes cast warped blue and violet reflections across the rain soaked street\n* Colored light filters through stained glass windows, scattering fractured shapes across the church floor\n* A stage spotlight locks onto center frame, leaving everything else swallowed in deep shadow\n\n**Atmosphere examplesÔºö**\n\n* Fine rain slants through the air, forming a delicate curtain that glows beneath the streetlights\n* The subtle grinding of metal gears echoes repeatedly through an empty factory hall\n* Ocean wind carries a salty chill, pushing grains of sand slowly across the beach\n\n**Use Temporal Connectors for Flow**\n\nConnective words help actions transition naturally and reinforce a sense of time passing. Words like when, then, as, before, after, while keep the sequence clear.\n\n**ExampleÔºö**\n\nA heavy metal hatch slides open along the corridor of a space station, and cold mist spills out from the vents. As the camera holds a steady wide shot, a figure in a spacesuit steps forward through the fog. Then the camera tracks sideways, following the figure as they move steadily down the illuminated alloy corridor.\n\n# Advanced Practice\n\n# The Six Part Structured Prompt for 4K Video\n\nIf you‚Äôre aiming for the best possible 4K output, it helps to structure your prompt in a clear, layered format like this.\n\n1. **Scene Anchor**¬†Define the location, time of day, and overall atmosphere.\n\n**Example**\n\nAn abandoned rocket launch site at dusk, orange red sunset clouds stretching across the sky, rusted metal structures towering in silence\n\n1. **Subject and Action**¬†Specify who or what is present, paired with a strong verb.\n\n**Example**\n\nA silver drone skims low over the ground, its mechanical arms unfolding slowly as it scans the scattered debris\n\n1. **Camera and Lens**¬†Describe movement, focal length, aperture, and framing.\n\n**Example**\n\nFast forward tracking shot, 24mm lens, f1.8, ultra wide angle, stabilized handheld rig\n\n1. **Visual Style**¬†Define color science, grading approach, or film emulation.\n\n**Example**\n\nHigh contrast image, cool blue green grading, Fujifilm Provia 100F film texture\n\n1. **Motion and Time Cues**¬†Indicate speed, frame rate feel, and shutter characteristics.\n\n**Example**\n\nSubtle motion blur, 60fps feel, equivalent to a 1 over 120 shutter\n\n1. **Guardrails**¬†Clearly state what should be avoided.\n\n**Example**\n\nNo distortion, no blown highlights, no AI artifacts\n\nWhen you use this structure, you‚Äôre essentially giving LTX-2 a production blueprint instead of a loose description. That clarity often makes the difference between a decent clip and something that genuinely feels cinematic.\n\n# Lens and Shutter Language\n\nUsing specific camera terminology helps control motion continuity and realism, especially when you‚Äôre aiming for cinematic consistency.\n\nFocal length examples:\n\n* 24mm wide angle creates a strong sense of space and environmental scale\n* 50mm standard lens gives a natural, human eye perspective\n* 85mm portrait lens adds compression and intimacy\n* 200mm telephoto compresses depth and isolates the subject from the background\n\nShutter descriptions:\n\n* 180 degree shutter equivalent produces classic cinematic motion blur\n* Natural motion blur enhances realism in moving subjects\n* Fast shutter with crisp motion creates a sharp, high energy action feel\n\n# Keywords for Smooth 50 FPS Motion\n\nIf you‚Äôre targeting fluid movement at 50fps, the language you use really matters.\n\nCamera stability:\n\n* Stable dolly push\n* Smooth gimbal stabilization\n* Tripod locked off\n* Constant speed pan\n\nMotion quality:\n\n* Natural motion blur\n* Fluid movement\n* Controlled motion\n* Stable tracking\n\nAvoid at 50fps:\n\n* Chaotic handheld movement, which often introduces warping\n* Shaky camera\n* Irregular motion\n\n# Pro Tip: Long Take Prompting Strategy (for that 20s max duration)\n\nIf you're pushing for those 20-second clips, stop thinking in terms of single prompts and start treating them like¬†**mini-scenes**. Here‚Äôs the structure I‚Äôve been using to keep the AI from hallucinating or losing the plot:\n\n**The Framework:**\n\n* **Scene Heading:**¬†Location and Time of Day (Keep it specific).\n* **Brief Description:**¬†The overall vibe and atmosphere you‚Äôre aiming for.\n* **Blocking:**¬†The sequence of the subject's actions and camera movements. This is the \"meat\" of the long take.\n* **Dialogue/Cues:**¬†Any specific performance notes (wrapped in parentheses).\n\n**Check out this 15s Long Take prompt structure.**\n\n`Blocking:`¬†`Start with a`¬†`macro shot`¬†`of a pilot‚Äôs gloved hand brushing against a flight stick; metallic reflections catch the dying sunlight. As he pushes the throttle forward, the camera`¬†`slowly pulls back`¬†`into a medium shot, revealing his clenched jaw and the cold glow of the cockpit dashboard. His expression shifts from pure focus to a hint of grim determination. The camera`¬†`continues to dolly back\\`\\`, eventually revealing the entire tarmac behind him‚Äîrusted fighter jets, scattered debris, and a sky bled orange-red by the sunset.`\n\nhttps://reddit.com/link/1rf7byp/video/8brzyhfpmtlg1/player\n\n# AV Sync Techniques for LTX-2\n\nSince LTX-2 generates audio and video simultaneously, you can use these specific prompting techniques to tighten up the synchronization:\n\n**Temporal CueingÔºö**\n\n* **\"On the heavy drum beat\"**¬†‚Äì Perfectly aligns action with the musical rhythm.\n* **\"On the third bass hit\"**¬†‚Äì For precise timing of a specific event.\n* **\"Laser beam fires at the 3-second mark\"**¬†‚Äì Use timestamps to specify exact moments.\n\n**Action RegularityÔºö**\n\n* **\"Constant speed tracking shot\"**¬†‚Äì Keeps camera movement predictable for the AI.\n* **\"Rhythmic robotic arm oscillation\"**¬†‚Äì Creates movements at regular intervals.\n* **\"Steady heartbeat pulse\"**¬†‚Äì Maintains a consistent audio-visual pattern.\n\n**Prompt¬†Example:**\n\n\"A robotic arm precisely grabs a component on the bass hit, its metallic pincers opening and closing in a perfect rhythm. The camera remains steady in a close-up, while each grab produces a crisp metallic clank that echoes through the sterile, dust-free lab.\"\n\n**Core Competencies & Strengths**\n\n|Core Domain|Key Strengths & Performance|\n|:-|:-|\n||\n|**Cinematic Composition**|Controlled camera movement (Dolly, Crane, Tracking); clearly defined depth of field; mastery of classic cinematography and genre-specific framing.|\n|**Emotional Character Moments**|Subtle facial expressions; natural body language; authentic emotional responses and nuanced character interactions.|\n|**Atmospheric Scenes**|Environmental storytelling; weather effects (fog, rain, snow); mood-driven lighting and high-texture environments.|\n|**Clear Visual Language**|Defined shot types; purposeful movement; consistent framing and professional-grade technical execution.|\n|**Stylized Aesthetics**|Film stock emulation; professional color grading; genre-specific VFX and artistic post-processing.|\n|**Precise Lighting Control**|Motivated light sources; dramatic shadowing; accurate color temperature and light quality rendering.|\n|**Multilingual Dubbing/Audio**|Natural dialogue delivery; accent-specific specs; diverse voice characterization with multi-language support.|\n\n**Showcase Example 1: Nature Scene ‚Äì Rainforest Expedition**\n\n**Prompt:**¬†\n\nAn explorer treks through a dense rainforest before a storm, the dry leaves crunching underfoot. The camera glides in a low-angle slow tracking shot from the side-rear, following his steady pace. His headlamp casts a cold white beam that flickers against damp foliage, while massive vines sway gently in the overhead canopy. Distant primate calls echo through the humid air as a fine mist begins to fall, beading on his waterproof jacket. His trekking pole jabs rhythmically into the humus, each strike leaving a distinct imprint in the mud.\n\nhttps://reddit.com/link/1rf7byp/video/5uce18lrmtlg1/player\n\n**Why This¬†Prompt¬†Works:**\n\n* **Precise Camera Movement:**¬†Using \"low-angle slow tracking shot from the side-rear\" gives the AI a clear vector for motion.\n* **Temporal Progression:**¬†The action naturally evolves from walking to the first drops of rain, creating a logical timeline.\n* **Atmospheric Layering:**¬†Captures the pre-storm humidity, dense vegetation, and the specific texture of mist.\n* **Audio Integration:**¬†Combines foley (crunching leaves), ambient nature (primate calls), and weather (rain sounds) for a full soundscape.\n* **Physics Accuracy:**¬†Detailed interactions like the trekking pole sinking into humus and water beading on fabric ground the scene in reality.\n\n**Showcase Example 2: Character Close-up ‚Äì Archeological Site**\n\n**Prompt:**¬†\n\nAn archeologist kneels in a desert excavation pit under the harsh midday sun, meticulously cleaning an artifact. The camera starts in a medium close-up at knee height, then slowly dollies forward to focus on his hands. His right hand grips a brush while his left gently steadies the edge of a pottery shard. As a distant shout from a teammate echoes, his fingers tighten slightly, and the brush pauses mid-air. The camera remains steady with a shallow depth of field, capturing the focus in his wrists against the blurred, silent silhouette of a pyramid peak in the background. Ambient Audio: The howl of wind-blown sand and distant camel bells create an ancient, solemn atmosphere.\n\nhttps://reddit.com/link/1rf7byp/video/p9oirkvsmtlg1/player\n\n**Why This¬†Prompt¬†Works:**\n\n* **Specific Camera Progression:**¬†The transition from \"medium close-up to close-up dolly\" gives the shot a professional, intentional feel.\n* **Precise Physical Details:**¬†Specific hand positioning, the tightening of fingers, and the brush pausing mid-air ground the AI in physical reality.\n* **Emotional Beats through Action:**¬†Using the reaction to a distant shout and the momentary pause to convey focus and narrative tension.\n* **Depth of Field Specs:**¬†Explicitly using \"shallow depth of field\" to force the focus onto the intricate textures of the artifact and hands.\n* **Atmospheric Audio:**¬†The howl of wind and camel bells instantly build a world beyond the frame.\n\n# Short-Form Video Strategy (Under 5s)\n\nFor short clips, less is more. You want to focus on a¬†**single, high-impact movement**¬†or a fleeting moment, stripping away any elements that might distract from the core message.\n\n**The Structure:**\n\n* **One Clear Action:**¬†No subplots or secondary movements.\n* **Simple Camera Work:**¬†Either a static shot or a very basic pan/zoom.\n* **Minimal Scene Complexity:**¬†Keep the background clean to avoid hallucinations.\n\n**Short-Form Example:**\n\n**Prompt:**¬†A silver coin is flicked from a thumb, flipping rapidly through the air before landing precisely back in a palm.¬†**Close-up, shallow depth of field**, with crisp, cold metallic reflections.\n\nhttps://reddit.com/link/1rf7byp/video/kuui3j4vmtlg1/player\n\n**Mid-Form Video Strategy (5‚Äì10 Seconds)**\n\nAt this duration, you want to develop a¬†**short sequence**¬†with a clear beginning, middle, and end. Think of it as a micro-narrative with a distinct \"arc.\"\n\n**The Structure:**\n\n* **2‚Äì3 Connected Actions:**¬†A logical progression of movement.\n* **One Fluid Camera Motion:**¬†Avoid jerky cuts; stick to one consistent path.\n* **Clear Progression:**¬†A sense of moving from one state to another.\n\n**Mid-Form Example:**\n\n**Prompt:**¬†\n\nAn astronaut reaches out to touch the viewport, her fingertips gliding across the cold glass as she gazes at the swirling blue planet outside. The camera slowly dollies forward, shifting the focus from her immediate reflection to the vast, shimmering expanse of the cosmos.\n\nhttps://reddit.com/link/1rf7byp/video/n0clt0iwmtlg1/player\n\n",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/comfyui/comments/1rf7byp/ltx2_mastering_guide_pro_video_audio_sync/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "o7o0hib",
          "author": "TheDudeWithThePlan",
          "text": "Thanks GPT",
          "score": 6,
          "created_utc": "2026-02-27 08:02:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hvi78",
          "author": "Mirandah333",
          "text": "Great job! Thanks a lot. Wondering why did you not talked about the Multimodal Guider. In my tests improves a lot the result and a give a more smooth result",
          "score": 3,
          "created_utc": "2026-02-26 11:18:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7iun2m",
          "author": "switch2stock",
          "text": "Hello u/WildSpeaker7315,  \nDoes your prompt enhancer take these into consideration?",
          "score": 1,
          "created_utc": "2026-02-26 14:55:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7j2yhy",
              "author": "WildSpeaker7315",
              "text": "Most of them, it's generally meant to be more of a dumb input something output tool, revised version in a next day or so been working on it between training",
              "score": 1,
              "created_utc": "2026-02-26 15:35:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7j7z6o",
                  "author": "switch2stock",
                  "text": "Cool, thanks!",
                  "score": 1,
                  "created_utc": "2026-02-26 15:58:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7j3c03",
          "author": "wh33t",
          "text": "Am I mistaken, but do the audio queues not work in your video examples?",
          "score": 1,
          "created_utc": "2026-02-26 15:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ltb83",
          "author": "MrWeirdoFace",
          "text": "The example links are all \"page not found.\"",
          "score": 1,
          "created_utc": "2026-02-26 23:23:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m4erh",
          "author": "rm_rf_all_files",
          "text": "The distilled model is so ez to tell. The quality is extremely disappointing. You should use only the \\`dev\\` model.",
          "score": 1,
          "created_utc": "2026-02-27 00:24:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}